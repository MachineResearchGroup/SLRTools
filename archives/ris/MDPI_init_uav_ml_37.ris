TY  - EJOU
AU  - Liu, Chunting
AU  - Jia, Guozhu
TI  - Industrial Big Data and Computational Sustainability: Multi-Method Comparison Driven by High-Dimensional Data for Improving Reliability and Sustainability of Complex Systems
T2  - Sustainability

PY  - 2019
VL  - 11
IS  - 17
SN  - 2071-1050

AB  - Sustainable development is of great significance. The emerging research on data-driven computational sustainability has become an effective way to solve this problem. This paper presents a fault diagnosis and prediction framework for complex systems based on multi-dimensional data and multi-method comparison, aimed at improving the reliability and sustainability of the system by selecting methods with relatively superior performance. This study took the avionics system in the industrial field as an example. Based on the literature research on typical fault modes and fault diagnosis requirements of avionics systems, three popular high-dimensional data-driven fault diagnosis methods&mdash;support vector machine, convolutional neural network, and long- and short-term memory neural network&mdash;were comprehensively analyzed and compared. Finally, the actual bearing failure data were used for programming in order to verify and compare various methods and the process of selecting the superior method driven by high-dimensional data was fully demonstrated. We attempt to provide a sustainable development idea that continuously explores multi-method integration and comparison, aimed at improving the calculation efficiency and accuracy of reliability assessments, optimizing system performance, and ultimately achieving the goal of long-term improvement of system reliability and sustainability.
KW  - industrial big data
KW  - computational sustainability
KW  - multi-method comparison
KW  - reliability and sustainability
KW  - high-dimensional data
DO  - 10.3390/su11174557
TY  - EJOU
AU  - Hamdi, Zayd M.
AU  - Brandmeier, Melanie
AU  - Straub, Christoph
TI  - Forest Damage Assessment Using Deep Learning on High Resolution Remote Sensing Data
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 17
SN  - 2072-4292

AB  - Storms can cause significant damage to forest areas, affecting biodiversity and infrastructure and leading to economic loss. Thus, rapid detection and mapping of windthrows are crucially important for forest management. Recent advances in computer vision have led to highly-accurate image classification algorithms such as Convolutional Neural Network (CNN) architectures. In this study, we tested and implemented an algorithm based on CNNs in an ArcGIS environment for automatic detection and mapping of damaged areas. The algorithm was trained and tested on a forest area in Bavaria, Germany. . It is a based on a modified U-Net architecture that was optimized for the pixelwise classification of multispectral aerial remote sensing data. The neural network was trained on labeled damaged areas from after-storm aerial orthophotos of a ca.     109 k  m 2      forest area with RGB and NIR bands and 0.2-m spatial resolution. Around     10 7     pixels of labeled data were used in the process. Once the network is trained, predictions on further datasets can be computed within seconds, depending on the size of the input raster and the computational power used. The overall accuracy on our test dataset was     92 %    . During visual validation, labeling errors were found in the reference data that somewhat biased the results because the algorithm in some instance performed better than the human labeling procedure, while missing areas affected by shadows. Our results are very good in terms of precision, and the methods introduced in this paper have several additional advantages compared to traditional methods: CNNs automatically detect high- and low-level features in the data, leading to high classification accuracies, while only one after-storm image is needed in comparison to two images for approaches based on change detection. Furthermore, flight parameters do not affect the results in the same way as for approaches that require DSMs and DTMs as the classification is only based on the image data themselves, and errors occurring in the computation of DSMs and DTMs do not affect the results with respect to the z component. The integration into the ArcGIS Platform allows a streamlined workflow for forest management, as the results can be accessed by mobile devices in the field to allow for high-accuracy ground-truthing and additional mapping that can be synchronized back into the database. Our results and the provided automatic workflow highlight the potential of deep learning on high-resolution imagery and GIS for fast and efficient post-disaster damage assessment as a first step of disaster management.
KW  - forest damage assessment
KW  - windthrow
KW  - convolutional neural networks
KW  - GIS
KW  - remote sensing
DO  - 10.3390/rs11171976
TY  - EJOU
AU  - Wu, Ruidong
AU  - Liu, Bing
AU  - Fu, Jiafeng
AU  - Xu, Mingzhu
AU  - Fu, Ping
AU  - Li, Junbao
TI  - Research and Implementation of ε-SVR Training Method Based on FPGA
T2  - Electronics

PY  - 2019
VL  - 8
IS  - 9
SN  - 2079-9292

AB  - Online training of Support Vector Regression (SVR) in the field of machine learning is a computationally complex algorithm. Due to the need for multiple iterative processing in training, SVR training is usually implemented on computer, and the existing training methods cannot be directly implemented on Field-Programmable Gate Array (FPGA), which restricts the application range. This paper reconstructs the training framework and implementation without precision loss to reduce the total latency required for matrix update, reducing time consumption by 90%. A general &epsilon;-SVR training system with low latency is implemented on Zynq platform. Taking the regression of samples in two-dimensional as an example, the maximum acceleration ratio is 27.014&times; compared with microcontroller platform and the energy consumption is 12.449% of microcontroller. From the experiments for the University of California, Riverside (UCR) time series data set. The regression results obtain excellent regression effects. The minimum coefficient of determination is 0.996, and running time is less than 30 ms, which can meet the requirements of different applications for real-time regression.
KW  - training method
KW  - Field-Programmable Gate Array (FPGA)
KW  - Support Vector Regression (SVR)
KW  - Zynq
DO  - 10.3390/electronics8090919
TY  - EJOU
AU  - Lu, Bing
AU  - He, Yuhong
TI  - Evaluating Empirical Regression, Machine Learning, and Radiative Transfer Modelling for Estimating Vegetation Chlorophyll Content Using Bi-Seasonal Hyperspectral Images
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 17
SN  - 2072-4292

AB  - Different types of methods have been developed to retrieve vegetation attributes from remote sensing data, including conventional empirical regressions (i.e., linear regression (LR)), advanced empirical regressions (e.g., multivariable linear regression (MLR), partial least square regression (PLSR)), machine learning (e.g., random forest regression (RFR), decision tree regression (DTR)), and radiative transfer modelling (RTM, e.g., PROSAIL). Given that each algorithm has its own strengths and weaknesses, it is essential to compare them and evaluate their effectiveness. Previous studies have mainly used single-date multispectral imagery or ground-based hyperspectral reflectance data for evaluating the models, while multi-seasonal hyperspectral images have been rarely used. Extensive spectral and spatial information in hyperspectral images, as well as temporal variations of landscapes, potentially influence the model performance. In this research, LR, PLSR, RFR, and PROSAIL, representing different types of methods, were evaluated for estimating vegetation chlorophyll content from bi-seasonal hyperspectral images (i.e., a middle- and a late-growing season image, respectively). Results show that the PLSR and RFR generally performed better than LR and PROSAIL. RFR achieved the highest accuracy for both images. This research provides insights on the effectiveness of different models for estimating vegetation chlorophyll content using hyperspectral images, aiming to support future vegetation monitoring research.
KW  - vegetation properties
KW  - empirical regression
KW  - machine learning
KW  - radiative transfer modelling
KW  - hyperspectral
KW  - chlorophyll content
DO  - 10.3390/rs11171979
TY  - EJOU
AU  - Mansour, Mostafa
AU  - Davidson, Pavel
AU  - Stepanov, Oleg
AU  - Piché, Robert
TI  - Relative Importance of Binocular Disparity and Motion Parallax for Depth Estimation: A Computer Vision Approach
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 17
SN  - 2072-4292

AB  - Binocular disparity and motion parallax are the most important cues for depth estimation in human and computer vision. Here, we present an experimental study to evaluate the accuracy of these two cues in depth estimation to stationary objects in a static environment. Depth estimation via binocular disparity is most commonly implemented using stereo vision, which uses images from two or more cameras to triangulate and estimate distances. We use a commercial stereo camera mounted on a wheeled robot to create a depth map of the environment. The sequence of images obtained by one of these two cameras as well as the camera motion parameters serve as the input to our motion parallax-based depth estimation algorithm. The measured camera motion parameters include translational and angular velocities. Reference distance to the tracked features is provided by a LiDAR. Overall, our results show that at short distances stereo vision is more accurate, but at large distances the combination of parallax and camera motion provide better depth estimation. Therefore, by combining the two cues, one obtains depth estimation with greater range than is possible using either cue individually.
KW  - binocular disparity
KW  - motion parallax
KW  - depth perception
KW  - proprioceptive sensors
KW  - unscented Kalman filter
DO  - 10.3390/rs11171990
TY  - EJOU
AU  - Ćwiąkała, Paweł
TI  - Testing Procedure of Unmanned Aerial Vehicles (UAVs) Trajectory in Automatic Missions
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 17
SN  - 2076-3417

AB  - This paper describes an experimental test campaign while using an Unmanned Aerial Vehicle (UAV) and measuring the obtained UAV positions during different flight tasks and in different operative conditions. A new test procedure has been presented and tested for different devices in various weather conditions. This paper describes and analyses the measurements of the flight trajectory of the UAV that was performed with the use of a robotic total station (RTS), as compared to the design data and the data recorded in the internal memory of the UAV. Five different test tasks have been conducted. The obtained results have allowed for the assessment of the correctness of task performance as compared to the design and to determine the flying accuracy of the entire UAV set. The proposed set of tasks can be successfully utilised to control the correctness of operation of various types of UAVs and it may be implemented as a universal test to verify the algorithms optimising take-offs and landings, test flights of the objects, as well as flight planning in various terrain and weather conditions, which will increase the safety of the flights while using UAVs.
KW  - unmanned aerial vehicle
KW  - UAV navigation
KW  - path planning
KW  - flight trajectory
KW  - positioning accuracy
KW  - barometric altitude
DO  - 10.3390/app9173488
TY  - EJOU
AU  - Jeziorska, Justyna
TI  - UAS for Wetland Mapping and Hydrological Modeling
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 17
SN  - 2072-4292

AB  - The miniaturization and affordable production of integrated microelectronics have improved in recent years, making unmanned aerial systems (UAS) accessible to consumers and igniting their interest. Researchers have proposed UAS-based solutions for almost any conceivable problem, but the greatest impact will likely be in applications that exploit the unique advantages of the technology: work in dangerous or difficult-to-access areas, high spatial resolution and/or frequent measurements of environmental phenomena, and deployment of novel sensing technology over small to moderate spatial scales. Examples of such applications may be the identification of wetland areas and use of high-resolution spatial data for hydrological modeling. However, because of the large&mdash;and growing&mdash;assortment of aircraft and sensors available on the market, an evolving regulatory environment, and limited practical guidance or examples of wetland mapping with UAS, it has been difficult to confidently devise or recommend UAS-based monitoring strategies for these applications. This paper provides a comprehensive review of UAS hardware, software, regulations, scientific applications, and data collection/post-processing procedures that are relevant for wetland monitoring and hydrological modeling.
KW  - UAS
KW  - UAV
KW  - drone
KW  - wetlands
KW  - hydrological modeling
DO  - 10.3390/rs11171997
TY  - EJOU
AU  - Khoufi, Ines
AU  - Laouiti, Anis
AU  - Adjih, Cedric
TI  - A Survey of Recent Extended Variants of the Traveling Salesman and Vehicle Routing Problems for Unmanned Aerial Vehicles
T2  - Drones

PY  - 2019
VL  - 3
IS  - 3
SN  - 2504-446X

AB  - The use of Unmanned Aerial Vehicles (UAVs) is rapidly growing in popularity. Initially introduced for military purposes, over the past few years, UAVs and related technologies have successfully transitioned to a whole new range of civilian applications such as delivery, logistics, surveillance, entertainment, and so forth. They have opened new possibilities such as allowing operation in otherwise difficult or hazardous areas, for instance. For all applications, one foremost concern is the selection of the paths and trajectories of UAVs, and at the same time, UAVs control comes with many challenges, as they have limited energy, limited load capacity and are vulnerable to difficult weather conditions. Generally, efficiently operating a drone can be mathematically formalized as a path optimization problem under some constraints. This shares some commonalities with similar problems that have been extensively studied in the context of urban vehicles and it is only natural that the recent literature has extended the latter to fit aerial vehicle constraints. The knowledge of such problems, their formulation, the resolution methods proposed—through the variants induced specifically by UAVs features—are of interest for practitioners for any UAV application. Hence, in this study, we propose a review of existing literature devoted to such UAV path optimization problems, focusing specifically on the sub-class of problems that consider the mobility on a macroscopic scale. These are related to the two existing general classic ones—the Traveling Salesman Problem and the Vehicle Routing Problem. We analyze the recent literature that adapted the problems to the UAV context, provide an extensive classification and taxonomy of their problems and their formulation and also give a synthetic overview of the resolution techniques, performance metrics and obtained numerical results.
KW  - UAVs
KW  - optimization problems
KW  - TSP
KW  - VRP
DO  - 10.3390/drones3030066
TY  - EJOU
AU  - Yang, Qinchen
AU  - Liu, Man
AU  - Zhang, Zhitao
AU  - Yang, Shuqin
AU  - Ning, Jifeng
AU  - Han, Wenting
TI  - Mapping Plastic Mulched Farmland for High Resolution Images of Unmanned Aerial Vehicle Using Deep Semantic Segmentation
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 17
SN  - 2072-4292

AB  - With increasing consumption, plastic mulch benefits agriculture by promoting crop quality and yield, but the environmental and soil pollution is becoming increasingly serious. Therefore, research on the monitoring of plastic mulched farmland (PMF) has received increasing attention. Plastic mulched farmland in unmanned aerial vehicle (UAV) remote images due to the high resolution, shows a prominent spatial pattern, which brings difficulties to the task of monitoring PMF. In this paper, through a comparison between two deep semantic segmentation methods, SegNet and fully convolutional networks (FCN), and a traditional classification method, Support Vector Machine (SVM), we propose an end-to-end deep-learning method aimed at accurately recognizing PMF for UAV remote sensing images from Hetao Irrigation District, Inner Mongolia, China. After experiments with single-band, three-band and six-band image data, we found that deep semantic segmentation models built via single-band data which only use the texture pattern of PMF can identify it well; for example, SegNet reaching the highest accuracy of 88.68% in a 900 nm band. Furthermore, with three visual bands and six-band data (3 visible bands and 3 near-infrared bands), deep semantic segmentation models combining the texture and spectral features further improve the accuracy of PMF identification, whereas six-band data obtains an optimal performance for FCN and SegNet. In addition, deep semantic segmentation methods, FCN and SegNet, due to their strong feature extraction capability and direct pixel classification, clearly outperform the traditional SVM method in precision and speed. Among three classification methods, SegNet model built on three-band and six-band data obtains the optimal average accuracy of 89.62% and 90.6%, respectively. Therefore, the proposed deep semantic segmentation model, when tested against the traditional classification method, provides a promising path for mapping PMF in UAV remote sensing images.
KW  - plastic mulched farmland
KW  - fully convolutional networks
KW  - unmanned aerial vehicle remote sensing image
KW  - deep semantic segmentation
DO  - 10.3390/rs11172008
TY  - EJOU
AU  - Ghorbanzadeh, Omid
AU  - Meena, Sansar R.
AU  - Blaschke, Thomas
AU  - Aryal, Jagannath
TI  - UAV-Based Slope Failure Detection Using Deep-Learning Convolutional Neural Networks
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 17
SN  - 2072-4292

AB  - Slope failures occur when parts of a slope collapse abruptly under the influence of gravity, often triggered by a rainfall event or earthquake. The resulting slope failures often cause problems in mountainous or hilly regions, and the detection of slope failure is therefore an important topic for research. Most of the methods currently used for mapping and modelling slope failures rely on classification algorithms or feature extraction, but the spatial complexity of slope failures, the uncertainties inherent in expert knowledge, and problems in transferability, all combine to inhibit slope failure detection. In an attempt to overcome some of these problems we have analyzed the potential of deep learning convolutional neural networks (CNNs) for slope failure detection, in an area along a road section in the northern Himalayas, India. We used optical data from unmanned aerial vehicles (UAVs) over two separate study areas. Different CNN designs were used to produce eight different slope failure distribution maps, which were then compared with manually extracted slope failure polygons using different accuracy assessment metrics such as the precision, F-score, and mean intersection-over-union (mIOU). A slope failure inventory data set was produced for each of the study areas using a frequency-area distribution (FAD). The CNN approach that was found to perform best (precision accuracy assessment of almost 90% precision, F-score 85%, mIOU 74%) was one that used a window size of 64 &times; 64 pixels for the sample patches, and included slope data as an additional input layer. The additional information from the slope data helped to discriminate between slope failure areas and roads, which had similar spectral characteristics in the optical imagery. We concluded that the effectiveness of CNNs for slope failure detection was strongly dependent on their design (i.e., the window size selected for the sample patch, the data used, and the training strategies), but that CNNs are currently only designed by trial and error. While CNNs can be powerful tools, such trial and error strategies make it difficult to explain why a particular pooling or layer numbering works better than any other.
KW  - landslide
KW  - unmanned aerial vehicle (UAV)
KW  - deep learning
KW  - frequency area distribution (FAD)
KW  - mean intersection-over-union (mIOU)
KW  - sample patches selection
DO  - 10.3390/rs11172046
TY  - EJOU
AU  - Li, Kexin
AU  - Wang, Jun
AU  - Qi, Dawei
TI  - An Intelligent Warning Method for Diagnosing Underwater Structural Damage
T2  - Algorithms

PY  - 2019
VL  - 12
IS  - 9
SN  - 1999-4893

AB  - A number of intelligent warning techniques have been implemented for detecting underwater infrastructure diagnosis to partially replace human-conducted on-site inspections. However, the extensively varying real-world situation (e.g., the adverse environmental conditions, the limited sample space, and the complex defect types) can lead to challenges to the wide adoption of intelligent warning techniques. To overcome these challenges, this paper proposed an intelligent algorithm combing gray level co-occurrence matrix (GLCM) with self-organization map (SOM) for accurate diagnosis of the underwater structural damage. In order to optimize the generative criterion for GLCM construction, a triangle algorithm was proposed based on orthogonal experiments. The constructed GLCM were utilized to evaluate the texture features of the regions of interest (ROI) of micro-injury images of underwater structures and extracted damage image texture characteristic parameters. The digital feature screening (DFS) method was used to obtain the most relevant features as the input for the SOM network. According to the unique topology information of the SOM network, the classification result, recognition efficiency, parameters, such as the network layer number, hidden layer node, and learning step, were optimized. The robustness and adaptability of the proposed approach were tested on underwater structure images through the DFS method. The results showed that the proposed method revealed quite better performances and can diagnose structure damage in underwater realistic situations.
KW  - structural health monitoring
KW  - digital image processing
KW  - damage
KW  - gray level co-occurrence matrix
KW  - self-organization map
DO  - 10.3390/a12090183
TY  - EJOU
AU  - Stodola, Petr
AU  - Drozd, Jan
AU  - Mazal, Jan
AU  - Hodický, Jan
AU  - Procházka, Dalibor
TI  - Cooperative Unmanned Aerial System Reconnaissance in a Complex Urban Environment and Uneven Terrain
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 17
SN  - 1424-8220

AB  - Using unmanned robotic systems in military operations such as reconnaissance or surveillance, as well as in many civil applications, is common practice. In this article, the problem of monitoring the specified area of interest by a fleet of unmanned aerial systems is examined. The monitoring is planned via the Cooperative Aerial Model, which deploys a number of waypoints in the area; these waypoints are visited successively by unmanned systems. The original model proposed in the past assumed that the area to be explored is perfectly flat. A new formulation of this model is introduced in this article so that the model can be used in a complex environment with uneven terrain and/or with many obstacles, which may occlude some parts of the area of interest. The optimization algorithm based on the simulated annealing principles is proposed for positioning of waypoints to cover as large an area as possible. A set of scenarios has been designed to verify and evaluate the proposed approach. The key experiments are aimed at finding the minimum number of waypoints needed to explore at least the minimum requested portion of the area. Furthermore, the results are compared to the algorithm based on the lawnmower pattern.
KW  - cooperative aerial reconnaissance
KW  - unmanned aerial systems
KW  - reconnaissance operation
KW  - simulated annealing
KW  - art gallery problem
KW  - waypoint optimization
KW  - occlusion effect
DO  - 10.3390/s19173754
TY  - EJOU
AU  - Shafi, Uferah
AU  - Mumtaz, Rafia
AU  - García-Nieto, José
AU  - Hassan, Syed A.
AU  - Zaidi, Syed A.
AU  - Iqbal, Naveed
TI  - Precision Agriculture Techniques and Practices: From Considerations to Applications
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 17
SN  - 1424-8220

AB  - Internet of Things (IoT)-based automation of agricultural events can change the agriculture sector from being static and manual to dynamic and smart, leading to enhanced production with reduced human efforts. Precision Agriculture (PA) along with Wireless Sensor Network (WSN) are the main drivers of automation in the agriculture domain. PA uses specific sensors and software to ensure that the crops receive exactly what they need to optimize productivity and sustainability. PA includes retrieving real data about the conditions of soil, crops and weather from the sensors deployed in the fields. High-resolution images of crops are obtained from satellite or air-borne platforms (manned or unmanned), which are further processed to extract information used to provide future decisions. In this paper, a review of near and remote sensor networks in the agriculture domain is presented along with several considerations and challenges. This survey includes wireless communication technologies, sensors, and wireless nodes used to assess the environmental behaviour, the platforms used to obtain spectral images of crops, the common vegetation indices used to analyse spectral images and applications of WSN in agriculture. As a proof of concept, we present a case study showing how WSN-based PA system can be implemented. We propose an IoT-based smart solution for crop health monitoring, which is comprised of two modules. The first module is a wireless sensor network-based system to monitor real-time crop health status. The second module uses a low altitude remote sensing platform to obtain multi-spectral imagery, which is further processed to classify healthy and unhealthy crops. We also highlight the results obtained using a case study and list the challenges and future directions based on our work.
KW  - smart agriculture
KW  - precision agriculture
KW  - vegetation index
KW  - Internet of Things
DO  - 10.3390/s19173796
TY  - EJOU
AU  - Kim, Minwoo
AU  - Cho, Jaechan
AU  - Lee, Seongjoo
AU  - Jung, Yunho
TI  - IMU Sensor-Based Hand Gesture Recognition for Human-Machine Interfaces
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 18
SN  - 1424-8220

AB  - We propose an efficient hand gesture recognition (HGR) algorithm, which can cope with time-dependent data from an inertial measurement unit (IMU) sensor and support real-time learning for various human-machine interface (HMI) applications. Although the data extracted from IMU sensors are time-dependent, most existing HGR algorithms do not consider this characteristic, which results in the degradation of recognition performance. Because the dynamic time warping (DTW) technique considers the time-dependent characteristic of IMU sensor data, the recognition performance of DTW-based algorithms is better than that of others. However, the DTW technique requires a very complex learning algorithm, which makes it difficult to support real-time learning. To solve this issue, the proposed HGR algorithm is based on a restricted column energy (RCE) neural network, which has a very simple learning scheme in which neurons are activated when necessary. By replacing the metric calculation of the RCE neural network with DTW distance, the proposed algorithm exhibits superior recognition performance for time-dependent sensor data while supporting real-time learning. Our verification results on a field-programmable gate array (FPGA)-based test platform show that the proposed HGR algorithm can achieve a recognition accuracy of 98.6% and supports real-time learning and recognition at an operating frequency of 150 MHz.
KW  - dynamic time warping (DTW)
KW  - hand gesture recognition (HGR)
KW  - inertial measurement unit (IMU)
KW  - machine learning
KW  - real-time learning
KW  - restricted coulomb energy (RCE) neural network
DO  - 10.3390/s19183827
TY  - EJOU
AU  - Tan, Liguo
AU  - Wu, Juncheng
AU  - Yang, Xiaoyan
AU  - Song, Senmin
TI  - Research on Optimal Landing Trajectory Planning Method between an UAV and a Moving Vessel
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 18
SN  - 2076-3417

AB  - The location, velocity, and flight path angle of an autonomous unmanned aerial vehicle (UAV) landing on a moving vessel are key factors for an optimal landing trajectory. To tackle this challenge, this paper proposes a method for calculating the optimal approach landing trajectory between an UAV and a small vessel. A numerical approach (iterative method) is used to calculate the optimal approach landing trajectory, and the initial lead is introduced in the calculation process of the UAV trajectory for the inclination and heading angle for accuracy improvement, so that the UAV can track and calculate the optimal landing trajectory with high precision. Compared with the variational method, the proposed method can calculate an optimal turning direction angle for the UAV during the landing. Simulation experiments verify the effectiveness of the proposed algorithm and give optimal initialization values.
KW  - unmanned aerial system (UAS)
KW  - ship
KW  - trajectory planning
KW  - dichotomy search
DO  - 10.3390/app9183708
TY  - EJOU
AU  - Bhardwaj, Anshuman
AU  - Sam, Lydia
AU  - Martín-Torres, F. J.
AU  - Zorzano, María-Paz
AU  - Ramírez Luque, Juan A.
TI  - UAV Imaging of a Martian Brine Analogue Environment in a Fluvio-Aeolian Setting
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 18
SN  - 2072-4292

AB  - Understanding extraterrestrial environments and landforms through remote sensing and terrestrial analogy has gained momentum in recent years due to advances in remote sensing platforms, sensors, and computing efficiency. The seasonal brines of the largest salt plateau on Earth in Salar de Uyuni (Bolivian Altiplano) have been inadequately studied for their localized hydrodynamics and the regolith volume transport across the freshwater-brine mixing zones. These brines have recently been projected as a new analogue site for the proposed Martian brines, such as recurring slope lineae (RSL) and slope streaks. The Martian brines have been postulated to be the result of ongoing deliquescence-based salt-hydrology processes on contemporary Mars, similar to the studied Salar de Uyuni brines. As part of a field-site campaign during the cold and dry season in the latter half of August 2017, we deployed an unmanned aerial vehicle (UAV) at two sites of the Salar de Uyuni to perform detailed terrain mapping and geomorphometry. We generated high-resolution (2 cm/pixel) photogrammetric digital elevation models (DEMs) for observing and quantifying short-term terrain changes within the brines and their surroundings. The achieved co-registration for the temporal DEMs was considerably high, from which precise inferences regarding the terrain dynamics were derived. The observed average rate of bottom surface elevation change for brines was ~1.02 mm/day, with localized signs of erosion and deposition. Additionally, we observed short-term changes in the adjacent geomorphology and salt cracks. We conclude that the transferred regolith volume via such brines can be extremely low, well within the resolution limits of the remote sensors that are currently orbiting Mars, thereby making it difficult to resolve the topographic relief and terrain perturbations that are produced by such flows on Mars. Thus, the absence of observable erosion and deposition features within or around most of the proposed Martian RSL and slope streaks cannot be used to dismiss the possibility of fluidized flow within these features.
KW  - unmanned aerial vehicle (UAV)
KW  - photogrammetry
KW  - salt flat
KW  - geomorphometry
KW  - analogue research
DO  - 10.3390/rs11182104
TY  - EJOU
AU  - Moon, Jiyoun
AU  - Lee, Beom-Hee
TI  - PDDL Planning with Natural Language-Based Scene Understanding for UAV-UGV Cooperation
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 18
SN  - 2076-3417

AB  - Natural-language-based scene understanding can enable heterogeneous robots to cooperate efficiently in large and unconstructed environments. However, studies on symbolic planning rarely consider the semantic knowledge acquisition problem associated with the surrounding environments. Further, recent developments in deep learning methods show outstanding performance for semantic scene understanding using natural language. In this paper, a cooperation framework that connects deep learning techniques and a symbolic planner for heterogeneous robots is proposed. The framework is largely composed of the scene understanding engine, planning agent, and knowledge engine. We employ neural networks for natural-language-based scene understanding to share environmental information among robots. We then generate a sequence of actions for each robot using a planning domain definition language planner. JENA-TDB is used for knowledge acquisition storage. The proposed method is validated using simulation results obtained from one unmanned aerial and three ground vehicles.
KW  - mission planning
KW  - language descriptions
KW  - semantic graphs
KW  - autonomous robots
KW  - artificial intelligence
DO  - 10.3390/app9183789
TY  - EJOU
AU  - Torres-Sospedra, Joaquín
AU  - Nebot, Patricio
TI  - Combining Satellite Images and Cadastral Information for Outdoor Autonomous Mapping and Navigation: A Proof-of-Concept Study in Citric Groves
T2  - Algorithms

PY  - 2019
VL  - 12
IS  - 9
SN  - 1999-4893

AB  - The development of robotic applications for agricultural environments has several problems which are not present in the robotic systems used for indoor environments. Some of these problems can be solved with an efficient navigation system. In this paper, a new system is introduced to improve the navigation tasks for those robots which operate in agricultural environments. Concretely, the paper focuses on the problem related to the autonomous mapping of agricultural parcels (i.e., an orange grove). The map created by the system will be used to help the robots navigate into the parcel to perform maintenance tasks such as weed removal, harvest, or pest inspection. The proposed system connects to a satellite positioning service to obtain the real coordinates where the robotic system is placed. With these coordinates, the parcel information is downloaded from an online map service in order to autonomously obtain a map of the parcel in a readable format for the robot. Finally, path planning is performed by means of Fast Marching techniques using the robot or a team of two robots. This paper introduces the proof-of-concept and describes all the necessary steps and algorithms to obtain the path planning just from the initial coordinates of the robot.
KW  - orange groves
KW  - autonomous mapping
KW  - satellite images
KW  - outdoor navigation
DO  - 10.3390/a12090193
TY  - EJOU
AU  - Fan, Shurui
AU  - Li, Zirui
AU  - Xia, Kewen
AU  - Hao, Dongxia
TI  - Quantitative and Qualitative Analysis of Multicomponent Gas Using Sensor Array
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 18
SN  - 1424-8220

AB  - The gas sensor array has long been a major tool for measuring gas due to its high sensitivity, quick response, and low power consumption. This goal, however, faces a difficult challenge because of the cross-sensitivity of the gas sensor. This paper presents a novel gas mixture analysis method for gas sensor array applications. The features extracted from the raw data utilizing principal component analysis (PCA) were used to complete random forest (RF) modeling, which enabled qualitative identification. Support vector regression (SVR), optimized by the particle swarm optimization (PSO) algorithm, was used to select hyperparameters C and &gamma; to establish the optimal regression model for the purpose of quantitative analysis. Utilizing the dataset, we evaluated the effectiveness of our approach. Compared with logistic regression (LR) and support vector machine (SVM), the average recognition rate of PCA combined with RF was the highest (97%). The fitting effect of SVR optimized by PSO for gas concentration was better than that of SVR and solved the problem of hyperparameters selection.
KW  - gas sensor array
KW  - cross-sensitivity
KW  - PCA
KW  - random forest
KW  - particle swarm optimization
DO  - 10.3390/s19183917
TY  - EJOU
AU  - Liu, Xiaolei
AU  - Liu, Liansheng
AU  - Wang, Lulu
AU  - Guo, Qing
AU  - Peng, Xiyuan
TI  - Performance Sensing Data Prediction for an Aircraft Auxiliary Power Unit Using the Optimized Extreme Learning Machine
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 18
SN  - 1424-8220

AB  - The aircraft auxiliary power unit (APU) is responsible for environmental control in the cabin and the main engines starting the aircraft. The prediction of its performance sensing data is significant for condition-based maintenance. As a complex system, its performance sensing data have a typically nonlinear feature. In order to monitor this process, a model with strong nonlinear fitting ability needs to be formulated. A neural network has advantages of solving a nonlinear problem. Compared with the traditional back propagation neural network algorithm, an extreme learning machine (ELM) has features of a faster learning speed and better generalization performance. To enhance the training of the neural network with a back propagation algorithm, an ELM is employed to predict the performance sensing data of the APU in this study. However, the randomly generated weights and thresholds of the ELM often may result in unstable prediction results. To address this problem, a restricted Boltzmann machine (RBM) is utilized to optimize the ELM. In this way, a stable performance parameter prediction model of the APU can be obtained and better performance parameter prediction results can be achieved. The proposed method is evaluated by the real APU sensing data of China Southern Airlines Company Limited Shenyang Maintenance Base. Experimental results show that the optimized ELM with an RBM is more stable and can obtain more accurate prediction results.
KW  - auxiliary power unit
KW  - improved neural network
KW  - stable prediction
KW  - performance sensing data prediction
DO  - 10.3390/s19183935
TY  - EJOU
AU  - Tan, Yumin
AU  - Li, Yunxin
TI  - UAV Photogrammetry-Based 3D Road Distress Detection
T2  - ISPRS International Journal of Geo-Information

PY  - 2019
VL  - 8
IS  - 9
SN  - 2220-9964

AB  - The timely and proper rehabilitation of damaged roads is essential for road maintenance, and an effective method to detect road surface distress with high efficiency and low cost is urgently needed. Meanwhile, unmanned aerial vehicles (UAVs), with the advantages of high flexibility, low cost, and easy maneuverability, are a new fascinating choice for road condition monitoring. In this paper, road images from UAV oblique photogrammetry are used to reconstruct road three-dimensional (3D) models, from which road pavement distress is automatically detected and the corresponding dimensions are extracted using the developed algorithm. Compared with a field survey, the detection result presents a high precision with an error of around 1 cm in the height dimension for most cases, demonstrating the potential of the proposed method for future engineering practice.
KW  - UAV
KW  - road distress detection
KW  - digital surface model
KW  - point cloud
KW  - region growing algorithm
DO  - 10.3390/ijgi8090409
TY  - EJOU
AU  - Han, Seongkyun
AU  - Yoo, Jisang
AU  - Kwon, Soonchul
TI  - Real-Time Vehicle-Detection Method in Bird-View Unmanned-Aerial-Vehicle Imagery
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 18
SN  - 1424-8220

AB  - Vehicle detection is an important research area that provides background information for the diversity of unmanned-aerial-vehicle (UAV) applications. In this paper, we propose a vehicle-detection method using a convolutional-neural-network (CNN)-based object detector. We design our method, DRFBNet300, with a Deeper Receptive Field Block (DRFB) module that enhances the expressiveness of feature maps to detect small objects in the UAV imagery. We also propose the UAV-cars dataset that includes the composition and angular distortion of vehicles in UAV imagery to train our DRFBNet300. Lastly, we propose a Split Image Processing (SIP) method to improve the accuracy of the detection model. Our DRFBNet300 achieves 21 mAP with 45 FPS in the MS COCO metric, which is the highest score compared to other lightweight single-stage methods running in real time. In addition, DRFBNet300, trained on the UAV-cars dataset, obtains the highest AP score at altitudes of 20&ndash;50 m. The gap of accuracy improvement by applying the SIP method became larger when the altitude increases. The DRFBNet300 trained on the UAV-cars dataset with SIP method operates at 33 FPS, enabling real-time vehicle detection.
KW  - vehicle detection
KW  - object detection
KW  - UAV imagery
KW  - convolutional neural network
DO  - 10.3390/s19183958
TY  - EJOU
AU  - Bjaoui, Marwen
AU  - Khiari, Brahim
AU  - Benadli, Ridha
AU  - Memni, Mouad
AU  - Sellami, Anis
TI  - Practical Implementation of the Backstepping Sliding Mode Controller MPPT for a PV-Storage Application
T2  - Energies

PY  - 2019
VL  - 12
IS  - 18
SN  - 1996-1073

AB  - This study presents a design and an implementation of a robust Maximum Power Point Tracking (MPPT) for a stand-alone photovoltaic (PV) system with battery storage. A new control scheme is applied for the boost converter based on the combination of the adaptive perturb and observe fuzzy logic controller (P&amp;O-FLC) MPPT technique and the backstepping sliding mode control (BS-SMC) approach. The MPPT controller design was used to accurately track the PV operating point to its maximum power point (MPP) under changing climatic conditions. The presented MPPT based on the P&amp;O-FLC technique generates the reference PV voltage and then a cascade control loop type, based on the BS-SMC approach is used. The aims of this approach are applied to regulate the inductor current and then the PV voltage to its reference values. In order to reduce system costs and complexity, a high gain observer (HGO) was designed, based on the model of the PV system, to estimate online the real value of the boost converter&rsquo;s inductor current. The performance and the robustness of the BS-SMC approach are evaluated using a comparative simulation with a conventional proportional integral (PI) controller implemented in the MATLAB/Simulink environment. The obtained results demonstrate that the proposed approach not only provides a near-perfect tracking performance (dynamic response, overshoot, steady-state error), but also offers greater robustness and stability than the conventional PI controller. Experimental results fitted with dSPACE software reveal that the PV module could reach the MPP and achieve the performance and robustness of the designed BS-SMC MPPT controller.
KW  - photovoltaic system
KW  - maximum power point tracking
KW  - backstepping sliding mode control
KW  - high gain observer
KW  - stability analysis
DO  - 10.3390/en12183539
TY  - EJOU
AU  - Wang, Jie
AU  - Simeonova, Sandra
AU  - Shahbazi, Mozhdeh
TI  - Orientation- and Scale-Invariant Multi-Vehicle Detection and Tracking from Unmanned Aerial Videos
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 18
SN  - 2072-4292

AB  - Along with the advancement of light-weight sensing and processing technologies, unmanned aerial vehicles (UAVs) have recently become popular platforms for intelligent traffic monitoring and control. UAV-mounted cameras can capture traffic-flow videos from various perspectives providing a comprehensive insight into road conditions. To analyze the traffic flow from remotely captured videos, a reliable and accurate vehicle detection-and-tracking approach is required. In this paper, we propose a deep-learning framework for vehicle detection and tracking from UAV videos for monitoring traffic flow in complex road structures. This approach is designed to be invariant to significant orientation and scale variations in the videos. The detection procedure is performed by fine-tuning a state-of-the-art object detector, You Only Look Once (YOLOv3), using several custom-labeled traffic datasets. Vehicle tracking is conducted following a tracking-by-detection paradigm, where deep appearance features are used for vehicle re-identification, and Kalman filtering is used for motion estimation. The proposed methodology is tested on a variety of real videos collected by UAVs under various conditions, e.g., in late afternoons with long vehicle shadows, in dawn with vehicles lights being on, over roundabouts and interchange roads where vehicle directions change considerably, and from various viewpoints where vehicles&rsquo; appearance undergo substantial perspective distortions. The proposed tracking-by-detection approach performs efficiently at 11 frames per second on color videos of 2720p resolution. Experiments demonstrated that high detection accuracy could be achieved with an average F1-score of 92.1%. Besides, the tracking technique performs accurately, with an average multiple-object tracking accuracy (MOTA) of 81.3%. The proposed approach also addressed the shortcomings of the state-of-the-art in multi-object tracking regarding frequent identity switching, resulting in a total of only one identity switch over every 305 tracked vehicles.
KW  - traffic monitoring
KW  - vehicle detection
KW  - multi-vehicle tracking
KW  - vehicle re-identification
KW  - unmanned aerial vehicles
KW  - deep convolutional neural network.
DO  - 10.3390/rs11182155
TY  - EJOU
AU  - Mei, Wenjuan
AU  - Liu, Zhen
AU  - Su, Yuanzhang
AU  - Du, Li
AU  - Huang, Jianguo
TI  - Evolved-Cooperative Correntropy-Based Extreme Learning Machine for Robust Prediction
T2  - Entropy

PY  - 2019
VL  - 21
IS  - 9
SN  - 1099-4300

AB  - In recent years, the correntropy instead of the mean squared error has been widely taken as a powerful tool for enhancing the robustness against noise and outliers by forming the local similarity measurements. However, most correntropy-based models either have too simple descriptions of the correntropy or require too many parameters to adjust in advance, which is likely to cause poor performance since the correntropy fails to reflect the probability distributions of the signals. Therefore, in this paper, a novel correntropy-based extreme learning machine (ELM) called ECC-ELM has been proposed to provide a more robust training strategy based on the newly developed multi-kernel correntropy with the parameters that are generated using cooperative evolution. To achieve an accurate description of the correntropy, the method adopts a cooperative evolution which optimizes the bandwidths by switching delayed particle swarm optimization (SDPSO) and generates the corresponding influence coefficients that minimizes the minimum integrated error (MIE) to adaptively provide the best solution. The simulated experiments and real-world applications show that cooperative evolution can achieve the optimal solution which provides an accurate description on the probability distribution of the current error in the model. Therefore, the multi-kernel correntropy that is built with the optimal solution results in more robustness against the noise and outliers when training the model, which increases the accuracy of the predictions compared with other methods.
KW  - correntropy
KW  - information theory extreme learning machine
KW  - evolved cooperation
DO  - 10.3390/e21090912
TY  - EJOU
AU  - Salameh, Edward
AU  - Frappart, Frédéric
AU  - Almar, Rafael
AU  - Baptista, Paulo
AU  - Heygster, Georg
AU  - Lubac, Bertrand
AU  - Raucoules, Daniel
AU  - Almeida, Luis P.
AU  - Bergsma, Erwin W. J.
AU  - Capo, Sylvain
AU  - De Michele, Marcello
AU  - Idier, Deborah
AU  - Li, Zhen
AU  - Marieu, Vincent
AU  - Poupardin, Adrien
AU  - Silva, Paulo A.
AU  - Turki, Imen
AU  - Laignel, Benoit
TI  - Monitoring Beach Topography and Nearshore Bathymetry Using Spaceborne Remote Sensing: A Review
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 19
SN  - 2072-4292

AB  - With high anthropogenic pressure and the effects of climate change (e.g., sea level rise) on coastal regions, there is a greater need for accurate and up-to-date information about the topography of these systems. Reliable topography and bathymetry information are fundamental parameters for modelling the morpho-hydrodynamics of coastal areas, for flood forecasting, and for coastal management. Traditional methods such as ground, ship-borne, and airborne surveys suffer from limited spatial coverage and temporal sampling due to logistical constraints and high costs which limit their ability to provide the needed information. The recent advancements of spaceborne remote sensing techniques, along with their ability to acquire data over large spatial areas and to provide high frequency temporal monitoring, has made them very attractive for topography and bathymetry mapping. In this review, we present an overview of the current state of spaceborne-based remote sensing techniques used to estimate the topography and bathymetry of beaches, intertidal, and nearshore areas. We also provide some insights about the potential of these techniques when using data provided by new and future satellite missions.
KW  - spaceborne remote sensing
KW  - satellite
KW  - beaches
KW  - intertidal
KW  - nearshore
KW  - shallow waters
KW  - topography
KW  - bathymetry
KW  - digital elevation model (DEM)
DO  - 10.3390/rs11192212
TY  - EJOU
AU  - Guo, Qiwei
AU  - Chen, Yayong
AU  - Tang, Yu
AU  - Zhuang, Jiajun
AU  - He, Yong
AU  - Hou, Chaojun
AU  - Chu, Xuan
AU  - Zhong, Zhenyu
AU  - Luo, Shaoming
TI  - Lychee Fruit Detection Based on Monocular Machine Vision in Orchard Environment
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 19
SN  - 1424-8220

AB  - Due to the change of illumination environment and overlapping conditions caused by the neighboring fruits and other background objects, the simple application of the traditional machine vision method limits the detection accuracy of lychee fruits in natural orchard environments. Therefore, this research presented a detection method based on monocular machine vision to detect lychee fruits growing in overlapped conditions. Specifically, a combination of contrast limited adaptive histogram equalization (CLAHE), red/blue chromatic mapping, Otsu thresholding and morphology operations were adopted to segment the foreground regions of the lychees. A stepwise method was proposed for extracting individual lychee fruit from the lychee foreground region. The first step in this process was based on the relative position relation of the Hough circle and an equivalent area circle (equal to the area of the potential lychee foreground region) and was designed to distinguish lychee fruits growing in isolated or overlapped states. Then, a process based on the three-point definite circle theorem was performed to extract individual lychee fruits from the foreground regions of overlapped lychee fruit clusters. Finally, to enhance the robustness of the detection method, a local binary pattern support vector machine (LBP-SVM) was adopted to filter out the false positive detections generated by background chaff interferences. The performance of the presented method was evaluated using 485 images captured in a natural lychee orchard in Conghua (Area), Guangzhou. The detection results showed that the recall rate was 86.66%, the precision rate was greater than 87% and the F1-score was 87.07%.
KW  - overlapped lychee detection
KW  - monocular vision
KW  - Hough circle
KW  - three-point definite circle
KW  - LBP-SVM
DO  - 10.3390/s19194091
TY  - EJOU
AU  - Petliak, Helen
AU  - Cerovski-Darriau, Corina
AU  - Zaliva, Vadim
AU  - Stock, Jonathan
TI  - Where’s the Rock: Using Convolutional Neural Networks to Improve Land Cover Classification
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 19
SN  - 2072-4292

AB  - While machine learning techniques have been increasingly applied to land cover classification problems, these techniques have not focused on separating exposed bare rock from soil covered areas. Therefore, we built a convolutional neural network (CNN) to differentiate exposed bare rock (rock) from soil cover (other). We made a training dataset by mapping exposed rock at eight test sites across the Sierra Nevada Mountains (California, USA) using USDA’s 0.6 m National Aerial Inventory Program (NAIP) orthoimagery. These areas were then used to train and test the CNN. The resulting machine learning approach classifies bare rock in NAIP orthoimagery with a 0.95     F 1     score. Comparatively, the classical OBIA approach gives only a 0.84     F 1     score. This is an improvement over existing land cover maps, which underestimate rock by almost 90%. The resulting CNN approach is likely scalable but dependent on high-quality imagery and high-performance algorithms using representative training sets informed by expert mapping. As image quality and quantity continue to increase globally, machine learning models that incorporate high-quality training data informed by geologic, topographic, or other topical maps may be applied to more effectively identify exposed rock in large image collections.
KW  - remote sensing
KW  - environment
KW  - geology
KW  - land cover
KW  - land use
KW  - classification
DO  - 10.3390/rs11192211
TY  - EJOU
AU  - Abouheaf, Mohammed
AU  - Gueaieb, Wail
AU  - Spinello, Davide
TI  - Online Multi-Objective Model-Independent Adaptive Tracking Mechanism for Dynamical Systems
T2  - Robotics

PY  - 2019
VL  - 8
IS  - 4
SN  - 2218-6581

AB  - The optimal tracking problem is addressed in the robotics literature by using a variety of robust and adaptive control approaches. However, these schemes are associated with implementation limitations such as applicability in uncertain dynamical environments with complete or partial model-based control structures, complexity and integrity in discrete-time environments, and scalability in complex coupled dynamical systems. An online adaptive learning mechanism is developed to tackle the above limitations and provide a generalized solution platform for a class of tracking control problems. This scheme minimizes the tracking errors and optimizes the overall dynamical behavior using simultaneous linear feedback control strategies. Reinforcement learning approaches based on value iteration processes are adopted to solve the underlying Bellman optimality equations. The resulting control strategies are updated in real time in an interactive manner without requiring any information about the dynamics of the underlying systems. Means of adaptive critics are employed to approximate the optimal solving value functions and the associated control strategies in real time. The proposed adaptive tracking mechanism is illustrated in simulation to control a flexible wing aircraft under uncertain aerodynamic learning environment.
KW  - adaptive tracking systems
KW  - optimal control
KW  - machine learning
KW  - reinforcement learning
KW  - adaptive critics
DO  - 10.3390/robotics8040082
TY  - EJOU
AU  - Bai, Guoxing
AU  - Meng, Yu
AU  - Liu, Li
AU  - Luo, Weidong
AU  - Gu, Qing
AU  - Liu, Li
TI  - Review and Comparison of Path Tracking Based on Model Predictive Control
T2  - Electronics

PY  - 2019
VL  - 8
IS  - 10
SN  - 2079-9292

AB  - Recently, model predictive control (MPC) is increasingly applied to path tracking of mobile devices, such as mobile robots. The characteristics of these MPC-based controllers are not identical due to the different approaches taken during design. According to the differences in the prediction models, we believe that the existing MPC-based path tracking controllers can be divided into four categories. We named them linear model predictive control (LMPC), linear error model predictive control (LEMPC), nonlinear model predictive control (NMPC), and nonlinear error model predictive control (NEMPC). Subsequently, we built these four controllers for the same mobile robot and compared them. By comparison, we got some conclusions. The real-time performance of LMPC and LEMPC is good, but they are less robust to reference paths and positioning errors. NMPC performs well when the reference velocity is high and the radius of the reference path is small. It is also robust to positioning errors. However, the real-time performance of NMPC is slightly worse. NEMPC has many disadvantages. Like LMPC and LEMPC, it performs poorly when the reference velocity is high and the radius of the reference path is small. Its real-time performance is also not good enough.
KW  - path tracking
KW  - model predictive control
KW  - review
KW  - comparison
DO  - 10.3390/electronics8101077

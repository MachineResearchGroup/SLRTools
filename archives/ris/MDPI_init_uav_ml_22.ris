TY  - EJOU
AU  - Parvaresh, Ahmad
AU  - Abrazeh, Saber
AU  - Mohseni, Saeid-Reza
AU  - Zeitouni, Meisam J.
AU  - Gheisarnejad, Meysam
AU  - Khooban, Mohammad-Hassan
TI  - A Novel Deep Learning Backstepping Controller-Based Digital Twins Technology for Pitch Angle Control of Variable Speed Wind Turbine
T2  - Designs

PY  - 2020
VL  - 4
IS  - 2
SN  - 2411-9660

AB  - This paper proposes a deep deterministic policy gradient (DDPG) based nonlinear integral backstepping (NIB) in combination with model free control (MFC) for pitch angle control of variable speed wind turbine. In particular, the controller has been presented as a digital twin (DT) concept, which is an increasingly growing method in a variety of applications. In DDPG-NIB-MFC, the pitch angle is considered as the control input that depends on the optimal rotor speed, which is usually derived from effective wind speed. The system stability according to the Lyapunov theory can be achieved by the recursive nature of the backstepping theory and the integral action has been used to compensate for the steady-state error. Moreover, due to the nonlinear characteristics of wind turbines, the MFC aims to handle the un-modeled system dynamics and disturbances. The DDPG algorithm with actor-critic structure has been added in the proposed control structure to efficiently and adaptively tune the controller parameters embedded in the NIB controller. Under this effort, a digital twin of a presented controller is defined as a real-time and probabilistic model which is implemented on the digital signal processor (DSP) computing device. To ensure the performance of the proposed approach and output behavior of the system, software-in-loop (SIL) and hardware-in-loop (HIL) testing procedures have been considered. From the simulation and implementation outcomes, it can be concluded that the proposed backstepping controller based DDPG is more effective, robust, and adaptive than the backstepping and proportional-integral (PI) controllers optimized by particle swarm optimization (PSO) in the presence of uncertainties and disturbances.
KW  - pitch angle control
KW  - DDPG algorithm
KW  - backstepping controller
KW  - digital twin (DT)
KW  - DSP
KW  - software-in-loop
KW  - hardware-in-Loop
DO  - 10.3390/designs4020015
TY  - EJOU
AU  - Panagiotou, Emmanouil
AU  - Chochlakis, Georgios
AU  - Grammatikopoulos, Lazaros
AU  - Charou, Eleni
TI  - Generating Elevation Surface from a Single RGB Remotely Sensed Image Using Deep Learning
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 12
SN  - 2072-4292

AB  - Generating Digital Elevation Models (DEM) from satellite imagery or other data sources constitutes an essential tool for a plethora of applications and disciplines, ranging from 3D flight planning and simulation, autonomous driving and satellite navigation, such as GPS, to modeling water flow, precision farming and forestry. The task of extracting this 3D geometry from a given surface hitherto requires a combination of appropriately collected corresponding samples and/or specialized equipment, as inferring the elevation from single image data is out of reach for contemporary approaches. On the other hand, Artificial Intelligence (AI) and Machine Learning (ML) algorithms have experienced unprecedented growth in recent years as they can extrapolate rules in a data-driven manner and retrieve convoluted, nonlinear one-to-one mappings, such as an approximate mapping from satellite imagery to DEMs. Therefore, we propose an end-to-end Deep Learning (DL) approach to construct this mapping and to generate an absolute or relative point cloud estimation of a DEM given a single RGB satellite (Sentinel-2 imagery in this work) or drone image. The model has been readily extended to incorporate available information from the non-visible electromagnetic spectrum. Unlike existing methods, we only exploit one image for the production of the elevation data, rendering our approach less restrictive and constrained, but suboptimal compared to them at the same time. Moreover, recent advances in software and hardware allow us to make the inference and the generation extremely fast, even on moderate hardware. We deploy Conditional Generative Adversarial networks (CGAN), which are the state-of-the-art approach to image-to-image translation. We expect our work to serve as a springboard for further development in this field and to foster the integration of such methods in the process of generating, updating and analyzing DEMs.
KW  - deep learning
KW  - remote sensing
KW  - digital elevation models
KW  - generative adversarial networks
KW  - 3D point cloud
KW  - satellite imagery
KW  - drones
KW  - height maps
DO  - 10.3390/rs12122002
TY  - EJOU
AU  - Kucharczyk, Maja
AU  - Hay, Geoffrey J.
AU  - Ghaffarian, Salar
AU  - Hugenholtz, Chris H.
TI  - Geographic Object-Based Image Analysis: A Primer and Future Directions
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 12
SN  - 2072-4292

AB  - Geographic object-based image analysis (GEOBIA) is a remote sensing image analysis paradigm that defines and examines image-objects: groups of neighboring pixels that represent real-world geographic objects. Recent reviews have examined methodological considerations and highlighted how GEOBIA improves upon the 30+ year pixel-based approach, particularly for H-resolution imagery. However, the literature also exposes an opportunity to improve guidance on the application of GEOBIA for novice practitioners. In this paper, we describe the theoretical foundations of GEOBIA and provide a comprehensive overview of the methodological workflow, including: (i) software-specific approaches (open-source and commercial); (ii) best practices informed by research; and (iii) the current status of methodological research. Building on this foundation, we then review recent research on the convergence of GEOBIA with deep convolutional neural networks, which we suggest is a new form of GEOBIA. Specifically, we discuss general integrative approaches and offer recommendations for future research. Overall, this paper describes the past, present, and anticipated future of GEOBIA in a novice-accessible format, while providing innovation and depth to experienced practitioners.
KW  - geographic object-based image analysis
KW  - GEOBIA
KW  - object-based image analysis
KW  - OBIA
KW  - machine learning
KW  - deep learning
KW  - convolutional neural network
KW  - CNN
KW  - GEOCNN
DO  - 10.3390/rs12122012
TY  - EJOU
AU  - Barbedo, Jayme G.
TI  - Detecting and Classifying Pests in Crops Using Proximal Images and Machine Learning: A Review
T2  - AI

PY  - 2020
VL  - 1
IS  - 2
SN  - 2673-2688

AB  - Pest management is among the most important activities in a farm. Monitoring all different species visually may not be effective, especially in large properties. Accordingly, considerable research effort has been spent towards the development of effective ways to remotely monitor potential infestations. A growing number of solutions combine proximal digital images with machine learning techniques, but since species and conditions associated to each study vary considerably, it is difficult to draw a realistic picture of the actual state of the art on the subject. In this context, the objectives of this article are (1) to briefly describe some of the most relevant investigations on the subject of automatic pest detection using proximal digital images and machine learning; (2) to provide a unified overview of the research carried out so far, with special emphasis to research gaps that still linger; (3) to propose some possible targets for future research.
KW  - pest monitoring
KW  - machine learning
KW  - agricultural crops
KW  - insects
DO  - 10.3390/ai1020021
TY  - EJOU
AU  - Bowler, Ellen
AU  - Fretwell, Peter T.
AU  - French, Geoffrey
AU  - Mackiewicz, Michal
TI  - Using Deep Learning to Count Albatrosses from Space: Assessing Results in Light of Ground Truth Uncertainty
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 12
SN  - 2072-4292

AB  - Many wildlife species inhabit inaccessible environments, limiting researchers ability to conduct essential population surveys. Recently, very high resolution (sub-metre) satellite imagery has enabled remote monitoring of certain species directly from space; however, manual analysis of the imagery is time-consuming, expensive and subjective. State-of-the-art deep learning approaches can automate this process; however, often image datasets are small, and uncertainty in ground truth labels can affect supervised training schemes and the interpretation of errors. In this paper, we investigate these challenges by conducting both manual and automated counts of nesting Wandering Albatrosses on four separate islands, captured by the 31 cm resolution WorldView-3 sensor. We collect counts from six observers, and train a convolutional neural network (U-Net) using leave-one-island-out cross-validation and different combinations of ground truth labels. We show that (1) interobserver variation in manual counts is significant and differs between the four islands, (2) the small dataset can limit the networks ability to generalise to unseen imagery and (3) the choice of ground truth labels can have a significant impact on our assessment of network performance. Our final results show the network detects albatrosses as accurately as human observers for two of the islands, while in the other two misclassifications are largely caused by the presence of noise, cloud cover and habitat, which was not present in the training dataset. While the results show promise, we stress the importance of considering these factors for any study where data is limited and observer confidence is variable.
KW  - WorldView-3
KW  - convolutional neural network
KW  - VHR satellite imagery
KW  - wildlife monitoring
KW  - observer uncertainty
KW  - Wandering Albatross
DO  - 10.3390/rs12122026
TY  - EJOU
AU  - Pamart, Anthony
AU  - Morlet, François
AU  - De Luca, Livio
AU  - Veron, Philippe
TI  - A Robust and Versatile Pipeline for Automatic Photogrammetric-Based Registration of Multimodal Cultural Heritage Documentation
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 12
SN  - 2072-4292

AB  - Imaging techniques and Image Based-Modeling (IBM) practices in the field of Cultural Heritage (CH) studies are nowadays no longer used as one-shot applications but as various and complex scenarios involving multiple modalities; sensors, scales, spectral bands and temporalities utilized by various experts. Current use of Structure from Motion and photogrammetric methods necessitates some improvements in iterative registration to ease the growing complexity in the management of the scientific imaging applied on heritage assets. In this context, the co-registration of photo-documentation among other imaging resources is a key step in order to move towards data fusion and collaborative semantic enrichment scenarios. This paper presents the recent development of a Totally Automated Co-registration and Orientation library (TACO) based on the interoperability of open-source solutions to conduct photogrammetric-based registration. The proposed methodology addresses and solves some gaps in term of robustness and versatility in the field of incremental and global orientation of image-sets dedicated to CH practices.
KW  - close-range photogrammetry
KW  - structure from motion
KW  - MicMac
KW  - OpenMVG
KW  - data-fusion
KW  - remote-computing
KW  - multimodal imaging
KW  - cultural heritage
DO  - 10.3390/rs12122051
TY  - EJOU
AU  - Muhadi, Nur A.
AU  - Abdullah, Ahmad F.
AU  - Bejo, Siti K.
AU  - Mahadi, Muhammad R.
AU  - Mijic, Ana
TI  - Image Segmentation Methods for Flood Monitoring System
T2  - Water

PY  - 2020
VL  - 12
IS  - 6
SN  - 2073-4441

AB  - Flood disasters are considered annual disasters in Malaysia due to their consistent occurrence. They are among the most dangerous disasters in the country. Lack of data during flood events is the main constraint to improving flood monitoring systems. With the rapid development of information technology, flood monitoring systems using a computer vision approach have gained attention over the last decade. Computer vision requires an image segmentation technique to understand the content of the image and to facilitate analysis. Various segmentation algorithms have been developed to improve results. This paper presents a comparative study of image segmentation techniques used in extracting water information from digital images. The segmentation methods were evaluated visually and statistically. To evaluate the segmentation methods statistically, the dice similarity coefficient and the Jaccard index were calculated to measure the similarity between the segmentation results and the ground truth images. Based on the experimental results, the hybrid technique obtained the highest values among the three methods, yielding an average of 97.70% for the dice score and 95.51% for the Jaccard index. Therefore, we concluded that the hybrid technique is a promising segmentation method compared to the others in extracting water features from digital images.
KW  - computer vision
KW  - dice similarity coefficient
KW  - floods
KW  - hybrid technique
KW  - image segmentation
KW  - Jaccard index
DO  - 10.3390/w12061825
TY  - EJOU
AU  - Zhang, Qichen
AU  - Zhu, Meiqiang
AU  - Zou, Liang
AU  - Li, Ming
AU  - Zhang, Yong
TI  - Learning Reward Function with Matching Network for Mapless Navigation
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 13
SN  - 1424-8220

AB  - Deep reinforcement learning (DRL) has been successfully applied in mapless navigation. An important issue in DRL is to design a reward function for evaluating actions of agents. However, designing a robust and suitable reward function greatly depends on the designer&rsquo;s experience and intuition. To address this concern, we consider employing reward shaping from trajectories on similar navigation tasks without human supervision, and propose a general reward function based on matching network (MN). The MN-based reward function is able to gain the experience by pre-training through trajectories on different navigation tasks and accelerate the training speed of DRL in new tasks. The proposed reward function keeps the optimal strategy of DRL unchanged. The simulation results on two static maps show that the DRL converge with less iterations via the learned reward function than the state-of-the-art mapless navigation methods. The proposed method performs well in dynamic maps with partially moving obstacles. Even when test maps are different from training maps, the proposed strategy is able to complete the navigation tasks without additional training.
KW  - deep reinforcement learning
KW  - reward shaping
KW  - matching network
KW  - navigation
DO  - 10.3390/s20133664
TY  - EJOU
AU  - Lin, Yao-Chin
AU  - Yeh, Ching-Chuan
AU  - Chen, Wei-Hung
AU  - Liu, Wei-Chun
AU  - Wang, Jyun-Jie
TI  - The Use of Big Data for Sustainable Development in Motor Production Line Issues
T2  - Sustainability

PY  - 2020
VL  - 12
IS  - 13
SN  - 2071-1050

AB  - This study explores big data gathered from motor production lines to gain a better understanding of production line issues. Motor products from Solen Electric Company&rsquo;s motor production lines were used to predict failure points based on big data analytics, where 3606 datapoints from the company&rsquo;s testing equipment were statistically analyzed. The current study focused on secondary data and expert interview results to further define the relevant statistical dimensions. Only 14 of the original 88 detection parameters were required for monitoring the production line. The relationships between these parameters and the relevant motor components were established to indicate how an abnormal reading may be interpreted to quickly resolve an issue. Thus, a theoretical model for the monitoring of the motor production line was proposed. Further implications and practical suggestions are also offered to improve the production lines. This study explores big data analysis and smart manufacturing and demonstrates the promise of these technologies in improving production line efficiency and reducing waste to promote sustainable production goals. Big data thus constitute the core technology for advancing production lines into Industry 4.0 and promoting industry sustainability.
KW  - motor production line
KW  - manufacturing
KW  - big data
KW  - Industry 4.0
KW  - life cycle prediction
KW  - process monitoring
DO  - 10.3390/su12135323
TY  - EJOU
AU  - Ghaffarian, Saman
AU  - Rezaie Farhadabad, Ali
AU  - Kerle, Norman
TI  - Post-Disaster Recovery Monitoring with Google Earth Engine
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 13
SN  - 2076-3417

AB  - Post-disaster recovery is a complex process in terms of measuring its progress after a disaster and understanding its components and influencing factors. During this process, disaster planners and governments need reliable information to make decisions towards building the affected region back to normal (pre-disaster), or even improved, conditions. Hence, it is essential to use methods to understand the dynamics/variables of the post-disaster recovery process, and rapid and cost-effective data and tools to monitor the process. Google Earth Engine (GEE) provides free access to vast amounts of remote sensing (RS) data and a powerful computing environment in a cloud platform, making it an attractive tool to analyze earth surface data. In this study we assessed the suitability of GEE to analyze and track recovery. To do so, we employed GEE to assess the recovery process over a three-year period after Typhoon Haiyan, which struck Leyte island, in the Philippines, in 2013. We developed an approach to (i) generate cloud and shadow-free image composites from Landsat 7 and 8 satellite imagery and produce land cover classification data using the Random Forest method, and (ii) generate damage and recovery maps based on post-classification change analysis. The method produced land cover maps with accuracies &gt;88%. We used the model to produce damage and three time-step recovery maps for 62 municipalities on Leyte island. The results showed that most of the municipalities had recovered after three years in terms of returning to the pre-disaster situation based on the selected land cover change analysis. However, more analysis (e.g., functional assessment) based on detailed data (e.g., land use maps) is needed to evaluate the more complex and subtle socio-economic aspects of the recovery. The study showed that GEE has good potential for monitoring the recovery process for extensive regions. However, the most important limitation is the lack of very-high-resolution RS data that are critical to assess the process in detail, in particular in complex urban environments.
KW  - disaster
KW  - damage
KW  - recovery
KW  - monitoring
KW  - assessment
KW  - remote sensing
KW  - satellite imagery
KW  - Landsat
KW  - Google Earth Engine
KW  - Typhoon Haiyan
KW  - cloud computing
DO  - 10.3390/app10134574
TY  - EJOU
AU  - Veeranampalayam Sivakumar, Arun N.
AU  - Li, Jiating
AU  - Scott, Stephen
AU  - Psota, Eric
AU  - J. Jhala, Amit
AU  - Luck, Joe D.
AU  - Shi, Yeyin
TI  - Comparison of Object Detection and Patch-Based Classification Deep Learning Models on Mid- to Late-Season Weed Detection in UAV Imagery
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 13
SN  - 2072-4292

AB  - Mid- to late-season weeds that escape from the routine early-season weed management threaten agricultural production by creating a large number of seeds for several future growing seasons. Rapid and accurate detection of weed patches in field is the first step of site-specific weed management. In this study, object detection-based convolutional neural network models were trained and evaluated over low-altitude unmanned aerial vehicle (UAV) imagery for mid- to late-season weed detection in soybean fields. The performance of two object detection models, Faster RCNN and the Single Shot Detector (SSD), were evaluated and compared in terms of weed detection performance using mean Intersection over Union (IoU) and inference speed. It was found that the Faster RCNN model with 200 box proposals had similar good weed detection performance to the SSD model in terms of precision, recall, f1 score, and IoU, as well as a similar inference time. The precision, recall, f1 score and IoU were 0.65, 0.68, 0.66 and 0.85 for Faster RCNN with 200 proposals, and 0.66, 0.68, 0.67 and 0.84 for SSD, respectively. However, the optimal confidence threshold of the SSD model was found to be much lower than that of the Faster RCNN model, which indicated that SSD might have lower generalization performance than Faster RCNN for mid- to late-season weed detection in soybean fields using UAV imagery. The performance of the object detection model was also compared with patch-based CNN model. The Faster RCNN model yielded a better weed detection performance than the patch-based CNN with and without overlap. The inference time of Faster RCNN was similar to patch-based CNN without overlap, but significantly less than patch-based CNN with overlap. Hence, Faster RCNN was found to be the best model in terms of weed detection performance and inference time among the different models compared in this study. This work is important in understanding the potential and identifying the algorithms for an on-farm, near real-time weed detection and management.
KW  - CNN
KW  - Faster RCNN
KW  - SSD
KW  - Inception v2
KW  - patch-based CNN
KW  - MobileNet v2
KW  - detection performance
KW  - inference time
DO  - 10.3390/rs12132136
TY  - EJOU
AU  - Arce, Samuel
AU  - Vernon, Cory A.
AU  - Hammond, Joshua
AU  - Newell, Valerie
AU  - Janson, Joseph
AU  - Franke, Kevin W.
AU  - Hedengren, John D.
TI  - Automated 3D Reconstruction Using Optimized View-Planning Algorithms for Iterative Development of Structure-from-Motion Models
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 13
SN  - 2072-4292

AB  - Unsupervised machine learning algorithms (clustering, genetic, and principal component analysis) automate Unmanned Aerial Vehicle (UAV) missions as well as the creation and refinement of iterative 3D photogrammetric models with a next best view (NBV) approach. The novel approach uses Structure-from-Motion (SfM) to achieve convergence to a specified orthomosaic resolution by identifying edges in the point cloud and planning cameras that &ldquo;view&rdquo; the holes identified by edges without requiring an initial model. This iterative UAV photogrammetric method successfully runs in various Microsoft AirSim environments. Simulated ground sampling distance (GSD) of models reaches as low as     3.4     cm per pixel, and generally, successive iterations improve resolution. Besides analogous application in simulated environments, a field study of a retired municipal water tank illustrates the practical application and advantages of automated UAV iterative inspection of infrastructure using     63 %     fewer photographs than a comparable manual flight with analogous density point clouds obtaining a GSD of less than 3 cm per pixel. Each iteration qualitatively increases resolution according to a logarithmic regression, reduces holes in models, and adds details to model edges.
KW  - Structure-from-Motion
KW  - Unmanned Aerial Vehicles
KW  - iterative inspection
KW  - automated inspection
KW  - multi-scale
KW  - view-planning
KW  - unsupervised machine learning
KW  - autonomous flight
KW  - iterative optimization
DO  - 10.3390/rs12132169
TY  - EJOU
AU  - García-Martínez, Héctor
AU  - Flores-Magdaleno, Héctor
AU  - Ascencio-Hernández, Roberto
AU  - Khalil-Gardezi, Abdul
AU  - Tijerina-Chávez, Leonardo
AU  - Mancilla-Villa, Oscar R.
AU  - Vázquez-Peña, Mario A.
TI  - Corn Grain Yield Estimation from Vegetation Indices, Canopy Cover, Plant Density, and a Neural Network Using Multispectral and RGB Images Acquired with Unmanned Aerial Vehicles
T2  - Agriculture

PY  - 2020
VL  - 10
IS  - 7
SN  - 2077-0472

AB  - Corn yields vary spatially and temporally in the plots as a result of weather, altitude, variety, plant density, available water, nutrients, and planting date; these are the main factors that influence crop yield. In this study, different multispectral and red-green-blue (RGB) vegetation indices were analyzed, as well as the digitally estimated canopy cover and plant density, in order to estimate corn grain yield using a neural network model. The relative importance of the predictor variables was also analyzed. An experiment was established with five levels of nitrogen fertilization (140, 200, 260, 320, and 380 kg/ha) and four replicates, in a completely randomized block design, resulting in 20 experimental polygons. Crop information was captured using two sensors (Parrot Sequoia_4.9, and DJI FC6310_8.8) mounted on an unmanned aerial vehicle (UAV) for two flight dates at 47 and 79 days after sowing (DAS). The correlation coefficient between the plant density, obtained through the digital count of corn plants, and the corn grain yield was 0.94; this variable was the one with the highest relative importance in the yield estimation according to Garson&rsquo;s algorithm. The canopy cover, digitally estimated, showed a correlation coefficient of 0.77 with respect to the corn grain yield, while the relative importance of this variable in the yield estimation was 0.080 and 0.093 for 47 and 79 DAS, respectively. The wide dynamic range vegetation index (WDRVI), plant density, and canopy cover showed the highest correlation coefficient and the smallest errors (R = 0.99, mean absolute error (MAE) = 0.028 t ha&minus;1, root mean square error (RMSE) = 0.125 t ha&minus;1) in the corn grain yield estimation at 47 DAS, with the WDRVI index and the density being the variables with the highest relative importance for this crop development date. For the 79 DAS flight, the combination of the normalized difference vegetation index (NDVI), normalized difference red edge (NDRE), WDRVI, excess green (EXG), triangular greenness index (TGI), and visible atmospherically resistant index (VARI), as well as plant density and canopy cover, generated the highest correlation coefficient and the smallest errors (R = 0.97, MAE = 0.249 t ha&minus;1, RMSE = 0.425 t ha&minus;1) in the corn grain yield estimation, where the density and the NDVI were the variables with the highest relative importance, with values of 0.295 and 0.184, respectively. However, the WDRVI, plant density, and canopy cover estimated the corn grain yield with acceptable precision (R = 0.96, MAE = 0.209 t ha&minus;1, RMSE = 0.449 t ha&minus;1). The generated neural network models provided a high correlation coefficient between the estimated and the observed corn grain yield, and also showed acceptable errors in the yield estimation. The spectral information registered through remote sensors mounted on unmanned aerial vehicles and its processing in vegetation indices, canopy cover, and plant density allowed the characterization and estimation of corn grain yield. Such information is very useful for decision-making and agricultural activities planning.
KW  - vegetation indices
KW  - UAV
KW  - neural network
KW  - corn plant density
KW  - corn canopy cover
KW  - yield prediction
DO  - 10.3390/agriculture10070277
TY  - EJOU
AU  - Niculescu, Simona
AU  - Boissonnat, Jean-Baptiste
AU  - Lardeux, Cédric
AU  - Roberts, Dar
AU  - Hanganu, Jenica
AU  - Billey, Antoine
AU  - Constantinescu, Adrian
AU  - Doroftei, Mihai
TI  - Synergy of High-Resolution Radar and Optical Images Satellite for Identification and Mapping of Wetland Macrophytes on the Danube Delta
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 14
SN  - 2072-4292

AB  - In wetland environments, vegetation has an important role in ecological functioning. The main goal of this work was to identify an optimal combination of Sentinel-1 (S1), Sentinel-2 (S2), and Pleiades data using ground-reference data to accurately map wetland macrophytes in the Danube Delta. We tested several combinations of optical and Synthetic Aperture Radar (SAR) data rigorously at two levels. First, in order to reduce the confusion between reed (Phragmites australis (Cav.) Trin. ex Steud.) and other macrophyte communities, a time series analysis of S1 data was performed. The potential of S1 for detection of compact reed on plaur, compact reed on plaur/reed cut, open reed on plaur, pure reed, and reed on salinized soil was evaluated through time series of backscatter coefficient and coherence ratio images, calculated mainly according to the phenology of the reed. The analysis of backscattering coefficients allowed separation of reed classes that strongly overlapped. The coherence coefficient showed that C-band SAR repeat pass interferometric coherence for cut reed detection is feasible. In the second section, random forest (RF) classification was applied to the S2, Pleiades, and S1 data and in situ observations to discriminate and map reed against other aquatic macrophytes (submerged aquatic vegetation (SAV), emergent macrophytes, some floating broad-leaved and floating vegetation of delta lakes). In addition, different optical indices were included in the RF. A total of 67 classification models were made in several sensor combinations with two series of validation samples (with the reed and without reed) using both a simple and more detailed classification schema. The results showed that reed is completely discriminable compared to other macrophyte communities with all sensor combinations. In all combinations, the model-based producer’s accuracy (PA) and user’s accuracy (UA) for reed with both nomenclatures were over 90%. The diverse combinations of sensors were valuable for improving the overall classification accuracy of all of the communities of aquatic macrophytes except Myriophyllum spicatum L.
KW  - wetland vegetation
KW  - Danube Delta
KW  - backscatter coefficient
KW  - coherence ratio
KW  - stacking of times series radar and optical
KW  - random forest
DO  - 10.3390/rs12142188
TY  - EJOU
AU  - Justa, Josef
AU  - Šmídl, Václav
AU  - Hamáček, Aleš
TI  - Fast AHRS Filter for Accelerometer, Magnetometer, and Gyroscope Combination with Separated Sensor Corrections
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 14
SN  - 1424-8220

AB  - A new predictor&ndash;corrector filter for attitude and heading reference systems (AHRS) using data from an orthogonal sensor combination of three accelerometers, three magnetometers and three gyroscopes is proposed. The filter uses the predictor&mdash;corrector structure, with prediction based on gyroscopes and independent correction steps for acceleration and magnetic field sensors. We propose two variants of the filter: (i) one using mathematical operations of special orthogonal group SO(3), that are accurate for nonlinear operations, for highest possible accuracy, and (ii) one using linearization of nonlinear operations for fast evaluation. Both approaches are quaternion-based filter realizations without redundant steps. The filters are compared to state of the art methods in this field on data recorded using low-cost microelectromechanical systems (MEMS) sensors with ground truth measured by the VICON optical system. Both filters achieved better accuracy than conventional methods at lower computational cost. The recorded data with ground truth reference and the source codes of both filters are publicly available.
KW  - attitude estimation
KW  - complementary filter
KW  - gradient descent filter
KW  - sensor fusion
DO  - 10.3390/s20143824
TY  - EJOU
AU  - McClellan, Miranda
AU  - Cervelló-Pastor, Cristina
AU  - Sallent, Sebastià
TI  - Deep Learning at the Mobile Edge: Opportunities for 5G Networks
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 14
SN  - 2076-3417

AB  - Mobile edge computing (MEC) within 5G networks brings the power of cloud computing, storage, and analysis closer to the end user. The increased speeds and reduced delay enable novel applications such as connected vehicles, large-scale IoT, video streaming, and industry robotics. Machine Learning (ML) is leveraged within mobile edge computing to predict changes in demand based on cultural events, natural disasters, or daily commute patterns, and it prepares the network by automatically scaling up network resources as needed. Together, mobile edge computing and ML enable seamless automation of network management to reduce operational costs and enhance user experience. In this paper, we discuss the state of the art for ML within mobile edge computing and the advances needed in automating adaptive resource allocation, mobility modeling, security, and energy efficiency for 5G networks.
KW  - 5G
KW  - edge network
KW  - deep learning
KW  - reinforcement learning
KW  - caching
KW  - task offloading
KW  - mobile computing
KW  - edge computing
KW  - mobile edge computing
KW  - cloud computing
KW  - network function virtualization
KW  - slicing
KW  - 5G network standardization
DO  - 10.3390/app10144735
TY  - EJOU
AU  - Liang, Chao
AU  - Shanmugam, Bharanidharan
AU  - Azam, Sami
AU  - Karim, Asif
AU  - Islam, Ashraful
AU  - Zamani, Mazdak
AU  - Kavianpour, Sanaz
AU  - Idris, Norbik B.
TI  - Intrusion Detection System for the Internet of Things Based on Blockchain and Multi-Agent Systems
T2  - Electronics

PY  - 2020
VL  - 9
IS  - 7
SN  - 2079-9292

AB  - With the popularity of Internet of Things (IoT) technology, the security of the IoT network has become an important issue. Traditional intrusion detection systems have their limitations when applied to the IoT network due to resource constraints and the complexity. This research focusses on the design, implementation and testing of an intrusion detection system which uses a hybrid placement strategy based on a multi-agent system, blockchain and deep learning algorithms. The system consists of the following modules: data collection, data management, analysis, and response. The National security lab&ndash;knowledge discovery and data mining NSL-KDD dataset is used to test the system. The results demonstrate the efficiency of deep learning algorithms when detecting attacks from the transport layer. The experiment indicates that deep learning algorithms are suitable for intrusion detection in IoT network environment.
KW  - blockchain
KW  - Internet of Things
KW  - intrusion detection system
KW  - multi-agent system
DO  - 10.3390/electronics9071120
TY  - EJOU
AU  - Kong, Weiren
AU  - Zhou, Deyun
AU  - Yang, Zhen
AU  - Zhao, Yiyang
AU  - Zhang, Kai
TI  - UAV Autonomous Aerial Combat Maneuver Strategy Generation with Observation Error Based on State-Adversarial Deep Deterministic Policy Gradient and Inverse Reinforcement Learning
T2  - Electronics

PY  - 2020
VL  - 9
IS  - 7
SN  - 2079-9292

AB  - With the development of unmanned aerial vehicle (UAV) and artificial intelligence (AI) technology, Intelligent UAV will be widely used in future autonomous aerial combat. Previous researches on autonomous aerial combat within visual range (WVR) have limitations due to simplifying assumptions, limited robustness, and ignoring sensor errors. In this paper, in order to consider the error of the aircraft sensors, we model the aerial combat WVR as a state-adversarial Markov decision process (SA-MDP), which introduce the small adversarial perturbations on state observations and these perturbations do not alter the environment directly, but can mislead the agent into making suboptimal decisions. Meanwhile, we propose a novel autonomous aerial combat maneuver strategy generation algorithm with high-performance and high-robustness based on state-adversarial deep deterministic policy gradient algorithm (SA-DDPG), which add a robustness regularizers related to an upper bound on performance loss at the actor-network. At the same time, a reward shaping method based on maximum entropy (MaxEnt) inverse reinforcement learning algorithm (IRL) is proposed to improve the aerial combat strategy generation algorithm&rsquo;s efficiency. Finally, the efficiency of the aerial combat strategy generation algorithm and the performance and robustness of the resulting aerial combat strategy is verified by simulation experiments. Our main contributions are three-fold. First, to introduce the observation errors of UAV, we are modeling air combat as SA-MDP. Second, to make the strategy network of air combat maneuver more robust in the presence of observation errors, we introduce regularizers into the policy gradient. Third, to solve the problem that air combat&rsquo;s reward function is too sparse, we use MaxEnt IRL to design a shaping reward to accelerate the convergence of SA-DDPG.
KW  - aerial combat
KW  - reinforcement learning
KW  - robustness
KW  - sensor errors
KW  - network training
KW  - UAV
DO  - 10.3390/electronics9071121
TY  - EJOU
AU  - Gao, Zongmei
AU  - Luo, Zhongwei
AU  - Zhang, Wen
AU  - Lv, Zhenzhen
AU  - Xu, Yanlei
TI  - Deep Learning Application in Plant Stress Imaging: A Review
T2  - AgriEngineering

PY  - 2020
VL  - 2
IS  - 3
SN  - 2624-7402

AB  - Plant stress is one of major issues that cause significant economic loss for growers. The labor-intensive conventional methods for identifying the stressed plants constrain their applications. To address this issue, rapid methods are in urgent needs. Developments of advanced sensing and machine learning techniques trigger revolutions for precision agriculture based on deep learning and big data. In this paper, we reviewed the latest deep learning approaches pertinent to the image analysis of crop stress diagnosis. We compiled the current sensor tools and deep learning principles involved in plant stress phenotyping. In addition, we reviewed a variety of deep learning applications/functions with plant stress imaging, including classification, object detection, and segmentation, of which are closely intertwined. Furthermore, we summarized and discussed the current challenges and future development avenues in plant phenotyping.
KW  - deep learning
KW  - convolutional neural network
KW  - crop stress
KW  - precision phenotyping
DO  - 10.3390/agriengineering2030029
TY  - EJOU
AU  - Jamil, Sonain
AU  - Fawad
AU  - Rahman, MuhibUr
AU  - Ullah, Amin
AU  - Badnava, Salman
AU  - Forsat, Masoud
AU  - Mirjavadi, Seyed S.
TI  - Malicious UAV Detection Using Integrated Audio and Visual Features for Public Safety Applications
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 14
SN  - 1424-8220

AB  - Unmanned aerial vehicles (UAVs) have become popular in surveillance, security, and remote monitoring. However, they also pose serious security threats to public privacy. The timely detection of a malicious drone is currently an open research issue for security provisioning companies. Recently, the problem has been addressed by a plethora of schemes. However, each plan has a limitation, such as extreme weather conditions and huge dataset requirements. In this paper, we propose a novel framework consisting of the hybrid handcrafted and deep feature to detect and localize malicious drones from their sound and image information. The respective datasets include sounds and occluded images of birds, airplanes, and thunderstorms, with variations in resolution and illumination. Various kernels of the support vector machine (SVM) are applied to classify the features. Experimental results validate the improved performance of the proposed scheme compared to other related methods.
KW  - AlexNet
KW  - feature extraction
KW  - localization
KW  - public safety
KW  - malicious drones
KW  - surveillance
DO  - 10.3390/s20143923
TY  - EJOU
AU  - Shahmoradi, Javad
AU  - Talebi, Elaheh
AU  - Roghanchi, Pedram
AU  - Hassanalian, Mostafa
TI  - A Comprehensive Review of Applications of Drone Technology in the Mining Industry
T2  - Drones

PY  - 2020
VL  - 4
IS  - 3
SN  - 2504-446X

AB  - This paper aims to provide a comprehensive review of the current state of drone technology and its applications in the mining industry. The mining industry has shown increased interest in the use of drones for routine operations. These applications include 3D mapping of the mine environment, ore control, rock discontinuities mapping, postblast rock fragmentation measurements, and tailing stability monitoring, to name a few. The article offers a review of drone types, specifications, and applications of commercially available drones for mining applications. Finally, the research needs for the design and implementation of drones for underground mining applications are discussed.
KW  - drones
KW  - remote sensing
KW  - surface mining
KW  - underground mining
KW  - abandoned mining
DO  - 10.3390/drones4030034
TY  - EJOU
AU  - Akçay, Hüseyin G.
AU  - Kabasakal, Bekir
AU  - Aksu, Duygugül
AU  - Demir, Nusret
AU  - Öz, Melih
AU  - Erdoğan, Ali
TI  - Automated Bird Counting with Deep Learning for Regional Bird Distribution Mapping
T2  - Animals

PY  - 2020
VL  - 10
IS  - 7
SN  - 2076-2615

AB  - A challenging problem in the field of avian ecology is deriving information on bird population movement trends. This necessitates the regular counting of birds which is usually not an easily-achievable task. A promising attempt towards solving the bird counting problem in a more consistent and fast way is to predict the number of birds in different regions from their photos. For this purpose, we exploit the ability of computers to learn from past data through deep learning which has been a leading sub-field of AI for image understanding. Our data source is a collection of on-ground photos taken during our long run of birding activity. We employ several state-of-the-art generic object-detection algorithms to learn to detect birds, each being a member of one of the 38 identified species, in natural scenes. The experiments revealed that computer-aided counting outperformed the manual counting with respect to both accuracy and time. As a real-world application of image-based bird counting, we prepared the spatial bird order distribution and species diversity maps of Turkey by utilizing the geographic information system (GIS) technology. Our results suggested that deep learning can assist humans in bird monitoring activities and increase citizen scientists&rsquo; participation in large-scale bird surveys.
KW  - computer vision
KW  - machine learning
KW  - deep learning
KW  - bird detection
KW  - bird counting
KW  - bird monitoring
KW  - bird population mapping
KW  - bird diversity
KW  - GIS
KW  - citizen science
DO  - 10.3390/ani10071207
TY  - EJOU
AU  - Coviello, Luca
AU  - Cristoforetti, Marco
AU  - Jurman, Giuseppe
AU  - Furlanello, Cesare
TI  - GBCNet: In-Field Grape Berries Counting for Yield Estimation by Dilated CNNs
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 14
SN  - 2076-3417

AB  - We introduce here the Grape Berries Counting Net (GBCNet), a tool for accurate fruit yield estimation from smartphone cameras, by adapting Deep Learning algorithms originally developed for crowd counting. We test GBCNet using cross-validation procedure on two original datasets CR1 and CR2 of grape pictures taken in-field before veraison. A total of 35,668 berries have been manually annotated for the task. GBCNet achieves good performances on both the seven grape varieties dataset CR1, although with a different accuracy level depending on the variety, and on the single variety dataset CR2: in particular Mean Average Error (MAE) ranges from 0.85% for Pinot Gris to 11.73% for Marzemino on CR1 and reaches 7.24% on the Teroldego CR2 dataset.
KW  - digital agriculture
KW  - grape yield estimate
KW  - berries counting
KW  - deep learning
KW  - Dilated CNN
DO  - 10.3390/app10144870
TY  - EJOU
AU  - Fu, Wenpeng
AU  - Liu, Ran
AU  - Wang, Heng
AU  - Ali, Rashid
AU  - He, Yongping
AU  - Cao, Zhiqiang
AU  - Qin, Zhenghong
TI  - A Method of Multiple Dynamic Objects Identification and Localization Based on Laser and RFID
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 14
SN  - 1424-8220

AB  - In an indoor environment, object identification and localization are paramount for human-object interaction. Visual or laser-based sensors can achieve the identification and localization of the object based on its appearance, but these approaches are computationally expensive and not robust against the environment with obstacles. Radio Frequency Identification (RFID) has a unique tag ID to identify the object, but it cannot accurately locate it. Therefore, in this paper, the data of RFID and laser range finder are fused for the better identification and localization of multiple dynamic objects in an indoor environment. The main method is to use the laser range finder to estimate the radial velocities of objects in a certain environment, and match them with the object&rsquo;s radial velocities estimated by the RFID phase. The method also uses a fixed time series as &ldquo;sliding time window&rdquo; to find the cluster with the highest similarity of each RFID tag in each window. Moreover, the Pearson correlation coefficient (PCC) is used in the update stage of the particle filter (PF) to estimate the moving path of each cluster in order to improve the accuracy in a complex environment with obstacles. The experiments were verified by a SCITOS G5 robot. The results show that this method can achieve an matching rate of 90.18% and a localization accuracy of 0.33m in an environment with the presence of obstacles. This method effectively improves the matching rate and localization accuracy of multiple objects in indoor scenes when compared to the Bray-Curtis (BC) similarity matching-based approach as well as the particle filter-based approach.
KW  - dynamic objects identification and localization
KW  - laser cluster
KW  - radial velocity similarity
KW  - Pearson correlation coefficient
KW  - particle filter
DO  - 10.3390/s20143948
TY  - EJOU
AU  - Klemmt, Hans-Joachim
AU  - Seitz, Rudolf
AU  - Straub, Christoph
TI  - Application of Haralick’s Texture Features for Rapid Detection of Windthrow Hotspots in Orthophotos
T2  - Forests

PY  - 2020
VL  - 11
IS  - 7
SN  - 1999-4907

AB  - Windthrow and storm damage are crucial issues in practical forestry. We propose a method for rapid detection of windthrow hotspots in airborne digital orthophotos. Therefore, we apply Haralick&rsquo;s texture features on 50 &times; 50 m cells of the orthophotos and classify the cells with a random forest algorithm. We apply the classification results from a training data set on a validation set. The overall classification accuracy of the proposed method varies between 76% for fine distinction of the cells and 96% for a distinction level that tried to detect only severe damaged cells. The proposed method enables the rapid detection of windthrow hotspots in forests immediately after their occurrence in single-date data. It is not adequate for the determination of areas with only single fallen trees. Future research will investigate the possibilities and limitations when applying the method on other data sources (e.g., optical satellite data).
KW  - aerial image
KW  - airborne orthophoto
KW  - Haralick
KW  - storm damage
KW  - texture feature
KW  - windthrow
DO  - 10.3390/f11070763
TY  - EJOU
AU  - Ahmed, Habib
AU  - La, Hung M.
AU  - Gucunski, Nenad
TI  - Review of Non-Destructive Civil Infrastructure Evaluation for Bridges: State-of-the-Art Robotic Platforms, Sensors and Algorithms
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 14
SN  - 1424-8220

AB  - The non-destructive evaluation (NDE) of civil infrastructure has been an active area of research in recent decades. The traditional inspection of civil infrastructure mostly relies on visual inspection using human inspectors. To facilitate this process, different sensors for data collection and techniques for data analyses have been used to effectively carry out this task in an automated fashion. This review-based study will examine some of the recent developments in the field of autonomous robotic platforms for NDE and the structural health monitoring (SHM) of bridges. Some of the salient features of this review-based study will be discussed in the light of the existing surveys and reviews that have been published in the recent past, which will enable the clarification regarding the novelty of the present review-based study. The review methodology will be discussed in sufficient depth, which will provide insights regarding some of the primary aspects of the review methodology followed by this review-based study. In order to provide an in-depth examination of the state-of-the-art, the current research will examine the three major research streams. The first stream relates to technological robotic platforms developed for NDE of bridges. The second stream of literature examines myriad sensors used for the development of robotic platforms for the NDE of bridges. The third stream of literature highlights different algorithms for the surface- and sub-surface-level analysis of bridges that have been developed by studies in the past. A number of challenges towards the development of robotic platforms have also been discussed.
KW  - non-destructive evaluation (NDE)
KW  - structural health monitoring (SHM)
KW  - electric resistivity (ER) sensors
KW  - ground-penetrating radar (GPR)
KW  - infrared (IR) thermography
KW  - impact echo (IE)
KW  - NDE sensor fusion
KW  - convolutional neural network (CNNs)
KW  - concrete crack detection
KW  - rebar detection and localization
DO  - 10.3390/s20143954
TY  - EJOU
AU  - Al-Buraiki, Omar
AU  - Wu, Wenbo
AU  - Payeur, Pierre
TI  - Probabilistic Allocation of Specialized Robots on Targets Detected Using Deep Learning Networks
T2  - Robotics

PY  - 2020
VL  - 9
IS  - 3
SN  - 2218-6581

AB  - Task allocation for specialized unmanned robotic agents is addressed in this paper. Based on the assumptions that each individual robotic agent possesses specialized capabilities and that targets representing the tasks to be performed in the surrounding environment impose specific requirements, the proposed approach computes task-agent fitting probabilities to efficiently match the available robotic agents with the detected targets. The framework is supported by a deep learning method with an object instance segmentation capability, Mask R-CNN, that is adapted to provide target object recognition and localization estimates from vision sensors mounted on the robotic agents. Experimental validation, for indoor search-and-rescue (SAR) scenarios, is conducted and results demonstrate the reliability and efficiency of the proposed approach.
KW  - task allocation
KW  - multi-agent systems
KW  - specialized robots
KW  - probabilistic representation
KW  - target object detection
KW  - deep learning
KW  - Mask R-CNN
KW  - classification
KW  - segmentation
DO  - 10.3390/robotics9030054
TY  - EJOU
AU  - Xue, Dan
AU  - Yuan, Weiqi
TI  - Dynamic Partition Gaussian Crack Detection Algorithm Based on Projection Curve Distribution
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 14
SN  - 1424-8220

AB  - When detecting the cracks in the tunnel lining image, due to uneven illumination, there are generally differences in brightness and contrast between the cracked pixels and the surrounding background pixels as well as differences in the widths of the cracked pixels, which bring difficulty in detecting and extracting cracks. Therefore, this paper proposes a dynamic partitioned Gaussian crack detection algorithm based on the projection curve distribution. First, according to the distribution of the image projection curve, the background pixels are dynamically partitioned. Second, a new dynamic partitioned Gaussian (DPG) model was established, and the set rules of partition boundary conditions, partition number, and partition corresponding threshold were defined. Then, the threshold and multi-scale Gaussian factors corresponding to different crack widths were substituted into the Gaussian model to detect cracks. Finally, crack morphology and the breakpoint connection algorithm were combined to complete the crack extraction. The algorithm was tested on the lining gallery captured on the site of the Tang-Ling-Shan Tunnel in Liaoning Province, China. The optimal parameters in the algorithm were estimated through the Recall, Precision, and Time curves. From two aspects of qualitative and quantitative analysis, the experimental results demonstrate that this algorithm could effectively eliminate the effect of uneven illumination on crack detection. After detection, Recall could reach more than 96%, and after extraction, Precision was increased by more than 70%.
KW  - tunnel crack detection
KW  - dynamic partitioned Gaussian
KW  - gray projection curve distribution
KW  - uneven illumination
DO  - 10.3390/s20143973
TY  - EJOU
AU  - Muhadi, Nur A.
AU  - Abdullah, Ahmad F.
AU  - Bejo, Siti K.
AU  - Mahadi, Muhammad R.
AU  - Mijic, Ana
TI  - The Use of LiDAR-Derived DEM in Flood Applications: A Review
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 14
SN  - 2072-4292

AB  - Flood occurrence is increasing due to escalated urbanization and extreme climate change; hence, various studies on this issue and methods of flood monitoring and mapping are also increasing to reduce the severe impacts of flood disasters. The advancement of current technologies such as light detection and ranging (LiDAR) systems facilitated and improved flood applications. In a LiDAR system, a laser emits light that travels to the ground and reflects off objects like buildings and trees. The reflected light energy returns to the sensor, whereby the time interval is recorded. Since the conventional methods cannot produce high-resolution digital elevation model (DEM) data, which results in low accuracy of flood simulation results, LiDAR data are extensively used as an alternative. This review aims to study the potential and the applications of LiDAR-derived DEM in flood studies. It also provides insight into the operating principles of different LiDAR systems, system components, and advantages and disadvantages of each system. This paper discusses several topics relevant to flood studies from a LiDAR-derived DEM perspective. Furthermore, the challenges and future perspectives regarding DEM LiDAR data for flood mapping and assessment are also reviewed. This study demonstrates that LiDAR-derived data are useful in flood risk management, especially in the future assessment of flood-related problems.
KW  - airborne LiDAR
KW  - DEM
KW  - flood inundation
KW  - flood map
KW  - flood model
KW  - LiDAR
KW  - terrestrial LiDAR
DO  - 10.3390/rs12142308
TY  - EJOU
AU  - El Mahrad, Badr
AU  - Newton, Alice
AU  - Icely, John D.
AU  - Kacimi, Ilias
AU  - Abalansa, Samuel
AU  - Snoussi, Maria
TI  - Contribution of Remote Sensing Technologies to a Holistic Coastal and Marine Environmental Management Framework: A Review
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 14
SN  - 2072-4292

AB  - Coastal and marine management require the evaluation of multiple environmental threats and issues. However, there are gaps in the necessary data and poor access or dissemination of existing data in many countries around the world. This research identifies how remote sensing can contribute to filling these gaps so that environmental agencies, such as the United Nations Environmental Programme, European Environmental Agency, and International Union for Conservation of Nature, can better implement environmental directives in a cost-effective manner. Remote sensing (RS) techniques generally allow for uniform data collection, with common acquisition and reporting methods, across large areas. Furthermore, these datasets are sometimes open-source, mainly when governments finance satellite missions. Some of these data can be used in holistic, coastal and marine environmental management frameworks, such as the DAPSI(W)R(M) framework (Drivers–Activities–Pressures–State changes–Impacts (on Welfare)–Responses (as Measures), an updated version of Drivers–Pressures–State–Impact–Responses. The framework is a useful and holistic problem-structuring framework that can be used to assess the causes, consequences, and responses to change in the marine environment. Six broad classifications of remote data collection technologies are reviewed for their potential contribution to integrated marine management, including Satellite-based Remote Sensing, Aerial Remote Sensing, Unmanned Aerial Vehicles, Unmanned Surface Vehicles, Unmanned Underwater Vehicles, and Static Sensors. A significant outcome of this study is practical inputs into each component of the DAPSI(W)R(M) framework. The RS applications are not expected to be all-inclusive; rather, they provide insight into the current use of the framework as a foundation for developing further holistic resource technologies for management strategies in the future. A significant outcome of this research will deliver practical insights for integrated coastal and marine management and demonstrate the usefulness of RS to support the implementation of environmental goals, descriptors, targets, and policies, such as the Water Framework Directive, Marine Strategy Framework Directive, Ocean Health Index, and United Nations Sustainable Development Goals. Additionally, the opportunities and challenges of these technologies are discussed.
KW  - remote sensing
KW  - DPSIR
KW  - coastal and marine management
KW  - environmental policies and directives
KW  - WFD
KW  - MSFD
KW  - ocean health index
KW  - sustainable development goals
DO  - 10.3390/rs12142313

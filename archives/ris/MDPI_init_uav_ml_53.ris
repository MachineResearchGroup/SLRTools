TY  - EJOU
AU  - Crusiol, Luís G.
AU  - Nanni, Marcos R.
AU  - Furlanetto, Renato H.
AU  - Sibaldelli, Rubson N.
AU  - Cezar, Everson
AU  - Sun, Liang
AU  - Foloni, José S.
AU  - Mertz-Henning, Liliane M.
AU  - Nepomuceno, Alexandre L.
AU  - Neumaier, Norman
AU  - Farias, José R.
TI  - Yield Prediction in Soybean Crop Grown under Different Levels of Water Availability Using Reflectance Spectroscopy and Partial Least Squares Regression
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 5
SN  - 2072-4292

AB  - Soybean grain yield has regularly been impaired by drought periods, and the future climatic scenarios for soybean production might drastically impact yields worldwide. In this context, the knowledge of soybean yield is extremely important to subsidize government and corporative decisions over technical issues. This paper aimed to predict grain yield in soybean crop grown under different levels of water availability using reflectance spectroscopy and partial least square regression (PLSR). Field experiments were undertaken at Embrapa Soja (Brazilian Agricultural Research Corporation) in the 2016/2017, 2017/2018 and 2018/2019 cropping seasons. The data collected were analyzed following a split plot model in a randomized complete block design, with four blocks. The following water conditions were distributed in the field plots: irrigated (IRR), non-irrigated (NIRR) and water deficit induced at the vegetative (WDV) and reproductive stages (WDR) using rainout shelters. Soybean genotypes with different responses to water deficit were distributed in the subplots. Soil moisture and weather data were monitored daily. A total of 7216 leaf reflectance (from 400 to 2500 nm, measured by the FieldSpec 3 Jr spectroradiometer) was collected at 24 days in the three cropping seasons. The PLSR (p ≤ 0.05) was performed to predict soybean grain yield by its leaf-based reflectance spectroscopy. The results demonstrated the highest accuracy in soybean grain yield prediction at the R5 phenological stage, corresponding to the period when grains are being formed (R2 ranging from 0.731 to 0.924 and the RMSE from 334 to 403 kg ha−1—7.77 to 11.33%). Analyzing the three cropping seasons into a single PLSR model at R5 stage, R2 equal to 0.775, 0.730 and 0.688 were obtained at the calibration, cross-validation and external validation stages, with RMSE lower than 634 kg ha−1 (13.34%). The PLSR demonstrated higher accuracy in plants submitted to water deficit both at the vegetative and reproductive periods in comparison to plants under natural rainfall or irrigation.
KW  - Glycine max (L.) Merrill
KW  - drought stress
KW  - soybean genotypes
KW  - leaf-based data
KW  - hyperspectral reflectance
DO  - 10.3390/rs13050977
TY  - EJOU
AU  - Solis, Jorge
AU  - Karlsson, Christoffer
AU  - Johansson, Simon
AU  - Richardsson, Kristoffer
TI  - Towards the Development of an Automatic UAV-Based Indoor Environmental Monitoring System: Distributed Off-Board Control System for a Micro Aerial Vehicle
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 5
SN  - 2076-3417

AB  - This research aims to develop an automatic unmanned aerial vehicle (UAV)-based indoor environmental monitoring system for the acquisition of data at a very fine scale to detect rapid changes in environmental features of plants growing in greenhouses. Due to the complexity of the proposed research, in this paper we proposed an off-board distributed control system based on visual input for a micro aerial vehicle (MAV) able to hover, navigate, and fly to a desired target location without considerably affecting the effective flight time. Based on the experimental results, the MAV was able to land on the desired location within a radius of about 10 cm from the center point of the landing pad, with a reduction in the effective flight time of about 28%.
KW  - micro aerial vehicles
KW  - visual-based control
KW  - Kalman filter
DO  - 10.3390/app11052347
TY  - EJOU
AU  - Gebrehiwot, Asmamaw A.
AU  - Hashemi-Beni, Leila
TI  - Three-Dimensional Inundation Mapping Using UAV Image Segmentation and Digital Surface Model
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 3
SN  - 2220-9964

AB  - Flood occurrence is increasing due to the expansion of urbanization and extreme weather like hurricanes; hence, research on methods of inundation monitoring and mapping has increased to reduce the severe impacts of flood disasters. This research studies and compares two methods for inundation depth estimation using UAV images and topographic data. The methods consist of three main stages: (1) extracting flooded areas and create 2D inundation polygons using deep learning; (2) reconstructing 3D water surface using the polygons and topographic data; and (3) deriving a water depth map using the 3D reconstructed water surface and a pre-flood DEM. The two methods are different at reconstructing the 3D water surface (stage 2). The first method uses structure from motion (SfM) for creating a point cloud of the area from overlapping UAV images, and the water polygons resulted from stage 1 is applied for water point cloud classification. While the second method reconstructs the water surface by intersecting the water polygons and a pre-flood DEM created using the pre-flood LiDAR data. We evaluate the proposed methods for inundation depth mapping over the Town of Princeville during a flooding event during Hurricane Matthew. The methods are compared and validated using the USGS gauge water level data acquired during the flood event. The RMSEs for water depth using the SfM method and integrated method based on deep learning and DEM were 0.34m and 0.26m, respectively.
KW  - 3D inundation mapping
KW  - remote sensing
KW  - CNN
KW  - SfM
KW  - LiDAR
KW  - GFI
DO  - 10.3390/ijgi10030144
TY  - EJOU
AU  - Nemer, Ibrahim
AU  - Sheltami, Tarek
AU  - Ahmad, Irfan
AU  - Yasar, Ansar U.
AU  - Abdeen, Mohammad A. R.
TI  - RF-Based UAV Detection and Identification Using Hierarchical Learning Approach
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 6
SN  - 1424-8220

AB  - Unmanned Aerial Vehicles (UAVs) are widely available in the current market to be used either for recreation as a hobby or to serve specific industrial requirements, such as agriculture and construction. However, illegitimate and criminal usage of UAVs is also on the rise which introduces their effective identification and detection as a research challenge. This paper proposes a novel machine learning-based for efficient identification and detection of UAVs. Specifically, an improved UAV identification and detection approach is presented using an ensemble learning based on the hierarchical concept, along with pre-processing and feature extraction stages for the Radio Frequency (RF) data. Filtering is applied on the RF signals in the detection approach to improve the output. This approach consists of four classifiers and they are working in a hierarchical way. The sample will pass the first classifier to check the availability of the UAV, and then it will specify the type of the detected UAV using the second classifier. The last two classifiers will handle the sample that is related to Bebop and AR to specify their mode. Evaluation of the proposed approach with publicly available dataset demonstrates better efficiency compared to existing detection systems in the literature. It has the ability to investigate whether a UAV is flying within the area or not, and it can directly identify the type of UAV and then the flight mode of the detected UAV with accuracy around 99%.
KW  - radio frequency
KW  - unmanned aerial vehicles
KW  - machine learning
KW  - detection and identification
DO  - 10.3390/s21061947
TY  - EJOU
AU  - Dainelli, Riccardo
AU  - Toscano, Piero
AU  - Di Gennaro, Salvatore F.
AU  - Matese, Alessandro
TI  - Recent Advances in Unmanned Aerial Vehicle Forest Remote Sensing—A Systematic Review. Part I: A General Framework
T2  - Forests

PY  - 2021
VL  - 12
IS  - 3
SN  - 1999-4907

AB  - Natural, semi-natural, and planted forests are a key asset worldwide, providing a broad range of positive externalities. For sustainable forest planning and management, remote sensing (RS) platforms are rapidly going mainstream. In a framework where scientific production is growing exponentially, a systematic analysis of unmanned aerial vehicle (UAV)-based forestry research papers is of paramount importance to understand trends, overlaps and gaps. The present review is organized into two parts (Part I and Part II). Part II inspects specific technical issues regarding the application of UAV-RS in forestry, together with the pros and cons of different UAV solutions and activities where additional effort is needed, such as the technology transfer. Part I systematically analyzes and discusses general aspects of applying UAV in natural, semi-natural and artificial forestry ecosystems in the recent peer-reviewed literature (2018–mid-2020). The specific goals are threefold: (i) create a carefully selected bibliographic dataset that other researchers can draw on for their scientific works; (ii) analyze general and recent trends in RS forest monitoring (iii) reveal gaps in the general research framework where an additional activity is needed. Through double-step filtering of research items found in the Web of Science search engine, the study gathers and analyzes a comprehensive dataset (226 articles). Papers have been categorized into six main topics, and the relevant information has been subsequently extracted. The strong points emerging from this study concern the wide range of topics in the forestry sector and in particular the retrieval of tree inventory parameters often through Digital Aerial Photogrammetry (DAP), RGB sensors, and machine learning techniques. Nevertheless, challenges still exist regarding the promotion of UAV-RS in specific parts of the world, mostly in the tropical and equatorial forests. Much additional research is required for the full exploitation of hyperspectral sensors and for planning long-term monitoring.
KW  - UAV
KW  - drone
KW  - forest
KW  - precision forestry
KW  - remote sensing
KW  - meta-analysis
KW  - management
KW  - natural woodland
KW  - plantation forests
DO  - 10.3390/f12030327
TY  - EJOU
AU  - Ma, Qian
AU  - Han, Wenting
AU  - Huang, Shenjin
AU  - Dong, Shide
AU  - Li, Guang
AU  - Chen, Haipeng
TI  - Distinguishing Planting Structures of Different Complexity from UAV Multispectral Images
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 6
SN  - 1424-8220

AB  - This study explores the classification potential of a multispectral classification model for farmland with planting structures of different complexity. Unmanned aerial vehicle (UAV) remote sensing technology is used to obtain multispectral images of three study areas with low-, medium-, and high-complexity planting structures, containing three, five, and eight types of crops, respectively. The feature subsets of three study areas are selected by recursive feature elimination (RFE). Object-oriented random forest (OB-RF) and object-oriented support vector machine (OB-SVM) classification models are established for the three study areas. After training the models with the feature subsets, the classification results are evaluated using a confusion matrix. The OB-RF and OB-SVM models’ classification accuracies are 97.09% and 99.13%, respectively, for the low-complexity planting structure. The equivalent values are 92.61% and 99.08% for the medium-complexity planting structure and 88.99% and 97.21% for the high-complexity planting structure. For farmland with fragmentary plots and a high-complexity planting structure, as the planting structure complexity changed from low to high, both models’ overall accuracy levels decreased. The overall accuracy of the OB-RF model decreased by 8.1%, and that of the OB-SVM model only decreased by 1.92%. OB-SVM achieves an overall classification accuracy of 97.21%, and a single-crop extraction accuracy of at least 85.65%. Therefore, UAV multispectral remote sensing can be used for classification applications in highly complex planting structures.
KW  - UAV
KW  - multispectral remote sensing
KW  - farmland objects
KW  - classification
KW  - RF
KW  - SVM
DO  - 10.3390/s21061994
TY  - EJOU
AU  - Peng, Xingshuo
AU  - Han, Wenting
AU  - Ao, Jianyi
AU  - Wang, Yi
TI  - Assimilation of LAI Derived from UAV Multispectral Data into the SAFY Model to Estimate Maize Yield
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 6
SN  - 2072-4292

AB  - In this study, we develop a method to estimate corn yield based on remote sensing data and ground monitoring data under different water treatments. Spatially explicit information on crop yields is essential for farmers and agricultural agencies to make well-informed decisions. One approach to estimate crop yield with remote sensing is data assimilation, which integrates sequential observations of canopy development from remote sensing into model simulations of crop growth processes. We found that leaf area index (LAI) inversion based on unmanned aerial vehicle (UAV) vegetation index has a high accuracy, with R2 and root mean square error (RMSE) values of 0.877 and 0.609, respectively. Maize yield estimation based on UAV remote sensing data and simple algorithm for yield (SAFY) crop model data assimilation has different yield estimation accuracy under different water treatments. This method can be used to estimate corn yield, where R2 is 0.855 and RMSE is 692.8kg/ha. Generally, the higher the water stress, the lower the estimation accuracy. Furthermore, we perform the yield estimate mapping at 2 m spatial resolution, which has a higher spatial resolution and accuracy than satellite remote sensing. The great potential of incorporating UAV observations with crop data to monitor crop yield, and improve agricultural management is therefore indicated.
KW  - UAV
KW  - leaf area index
KW  - yield estimation
KW  - yield
KW  - SAFY model
KW  - EnKF
DO  - 10.3390/rs13061094
TY  - EJOU
AU  - Fossette, Sabrina
AU  - Loewenthal, Graham
AU  - Peel, Lauren R.
AU  - Vitenbergs, Anna
AU  - Hamel, Melanie A.
AU  - Douglas, Corrine
AU  - Tucker, Anton D.
AU  - Mayer, Florian
AU  - Whiting, Scott D.
TI  - Using Aerial Photogrammetry to Assess Stock-Wide Marine Turtle Nesting Distribution, Abundance and Cumulative Exposure to Industrial Activity
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 6
SN  - 2072-4292

AB  - The lack of accurate distribution maps and reliable abundance estimates for marine species can limit the ability of managers to design scale-appropriate management measures for a stock or population. Here, we tested the utility of aerial photogrammetry for conducting large-scale surveys of nesting marine turtles at remote locations, with a focus on the flatback turtle (Natator depressus) in the Pilbara region of Western Australia. Aerial surveys were conducted between 29 November and 6 December 2016 to overlap with the peak nesting season for flatback turtles and collected imagery was used to examine marine turtle distribution, abundance, and cumulative exposure to industrial activity relative to overlap with protected areas. Two observers independently reviewed aerial georeferenced photographs of 644 beaches and recorded turtle tracks and other evidence of turtle nesting activity. A total of 375 beaches showed signs of nesting activity by either flatback, green (Chelonia mydas) or hawksbill (Eretmochelys imbricata) turtles. Most of these beaches (85.3%) were located on islands, and the rest (14.7%) on the mainland. Half (n = 174) of the active beaches showed evidence of fresh (0–36 h. old) flatback nesting activity, with track abundance varying from 1.0 to 222.0 tracks·night−1. Six rookeries accounted for 62% of the Pilbara flatback stock. Remarkably, 77% of identified flatback rookeries occurred within protected areas. However, one-third (34%) of those were also located within 5 km of a major industrial site, including eight of the highest abundance beaches (50–250 tracks·night−1). Several key rookeries were also identified as being relatively unexposed to industry-related pressures but currently unprotected, highlighting the need for a cumulative impact assessment to be completed for this flatback stock. Finally, our aerial tallies and multiple ground-survey flatback track tallies were highly correlated and together with low intra- and inter-observer errors suggested that reliable data can be collected via aerial photogrammetry for nesting marine turtles. Such large-scale digitized surveys can therefore be used to assess the cumulative exposure of marine turtles to pressures, and to reveal new conservation opportunities.
KW  - aerial survey
KW  - cumulative impact
KW  - marine turtles
KW  - nesting distribution
KW  - population trends
DO  - 10.3390/rs13061116
TY  - EJOU
AU  - Swinney, Carolyn J.
AU  - Woods, John C.
TI  - Unmanned Aerial Vehicle Operating Mode Classification Using Deep Residual Learning Feature Extraction
T2  - Aerospace

PY  - 2021
VL  - 8
IS  - 3
SN  - 2226-4310

AB  - Unmanned Aerial Vehicles (UAVs) undoubtedly pose many security challenges. We need only look to the December 2018 Gatwick Airport incident for an example of the disruption UAVs can cause. In total, 1000 flights were grounded for 36 h over the Christmas period which was estimated to cost over 50 million pounds. In this paper, we introduce a novel approach which considers UAV detection as an imagery classification problem. We consider signal representations Power Spectral Density (PSD); Spectrogram, Histogram and raw IQ constellation as graphical images presented to a deep Convolution Neural Network (CNN) ResNet50 for feature extraction. Pre-trained on ImageNet, transfer learning is utilised to mitigate the requirement for a large signal dataset. We evaluate performance through machine learning classifier Logistic Regression. Three popular UAVs are classified in different modes; switched on; hovering; flying; flying with video; and no UAV present, creating a total of 10 classes. Our results, validated with 5-fold cross validation and an independent dataset, show PSD representation to produce over 91% accuracy for 10 classifications. Our paper treats UAV detection as an imagery classification problem by presenting signal representations as images to a ResNet50, utilising the benefits of transfer learning and outperforming previous work in the field.
KW  - unmanned aerial vehicles
KW  - UAV detection
KW  - RF spectrum analysis
KW  - machine learning classification
KW  - deep learning
KW  - convolutional neural network
KW  - transfer learning
KW  - signal analysis
DO  - 10.3390/aerospace8030079
TY  - EJOU
AU  - Emin, Mirzat
AU  - Anwar, Erpan
AU  - Liu, Suhong
AU  - Emin, Bilal
AU  - Mamut, Maryam
AU  - Abdukeram, Abduwali
AU  - Liu, Ting
TI  - Target Detection-Based Tree Recognition in a Spruce Forest Area with a High Tree Density—Implications for Estimating Tree Numbers
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 6
SN  - 2071-1050

AB  - Here, unmanned aerial vehicle (UAV) remote sensing and machine vision were used to automatically, accurately, and efficiently count Tianshan spruce and improve the efficiency of scientific forest management, focusing on a typical Tianshan spruce forest on Tianshan Mountain, middle Asia. First, the UAV in the sampling area was cropped from the image, and a target-labeling tool was used. The Tianshan spruce trees were annotated to construct a data set, and four models were used to identify and verify them in three different areas (low, medium, and high canopy closures). Finally, the combined number of trees was calculated. The average accuracy of the detection frame, mean accuracy and precision (mAP), was used to determine the target detection accuracy. The Faster Region Convolutional Neural Network (Faster-RCNN) model achieved the highest accuracies (96.36%, 96.32%, and 95.54% under low, medium, and high canopy closures, respectively) and the highest mAP (85%). Canopy closure affected the detection and recognition accuracy; YOLOv3, YOLOv4, and Faster-RCNN all showed varying spruce recognition accuracies at different densities. The accuracy of the Faster-RCNN model decreased by at least 0.82%. Combining UAV remote sensing with target detection networks can identify and quantify statistics regarding Tianshan spruce. This solves the shortcomings of traditional monitoring methods and is significant for understanding and monitoring forest ecosystems.
KW  - Tianshan spruce
KW  - target detection
KW  - UAV
KW  - forest inventory
DO  - 10.3390/su13063279
TY  - EJOU
AU  - El-Alem, Anas
AU  - Chokmani, Karem
AU  - Venkatesan, Aarthi
AU  - Rachid, Lhissou
AU  - Agili, Hachem
AU  - Dedieu, Jean-Pierre
TI  - How Accurate Is an Unmanned Aerial Vehicle Data-Based Model Applied on Satellite Imagery for Chlorophyll-a Estimation in Freshwater Bodies?
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 6
SN  - 2072-4292

AB  - Optical sensors are increasingly sought to estimate the amount of chlorophyll a (chl_a) in freshwater bodies. Most, whether empirical or semi-empirical, are data-oriented. Two main limitations are often encountered in the development of such models. The availability of data needed for model calibration, validation, and testing and the locality of the model developed—the majority need a re-parameterization from lake to lake. An Unmanned aerial vehicle (UAV) data-based model for chl_a estimation is developed in this work and tested on Sentinel-2 imagery without any re-parametrization. The Ensemble-based system (EBS) algorithm was used to train the model. The leave-one-out cross validation technique was applied to evaluate the EBS, at a local scale, where results were satisfactory (R2 = Nash = 0.94 and RMSE = 5.6 µg chl_a L−1). A blind database (collected over 89 lakes) was used to challenge the EBS’ Sentine-2-derived chl_a estimates at a regional scale. Results were relatively less good, yet satisfactory (R2 = 0.85, RMSE= 2.4 µg chl_a L−1, and Nash = 0.79). However, the EBS has shown some failure to correctly retrieve chl_a concentration in highly turbid waterbodies. This particularity nonetheless does not affect EBS performance, since turbid waters can easily be pre-recognized and masked before the chl_a modeling.
KW  - Sentinel-2
KW  - unmanned aerial vehicle
KW  - remote sensing
KW  - chlorophyll-a
KW  - machine learning
KW  - ensemble-based system
KW  - freshwaters
KW  - water quality
DO  - 10.3390/rs13061134
TY  - EJOU
AU  - Yavariabdi, Amir
AU  - Kusetogullari, Huseyin
AU  - Celik, Turgay
AU  - Cicek, Hasan
TI  - FastUAV-NET: A Multi-UAV Detection Algorithm for Embedded Platforms
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 6
SN  - 2079-9292

AB  - In this paper, a real-time deep learning-based framework for detecting and tracking Unmanned Aerial Vehicles (UAVs) in video streams captured by a fixed-wing UAV is proposed. The proposed framework consists of two steps, namely intra-frame multi-UAV detection and the inter-frame multi-UAV tracking. In the detection step, a new multi-scale UAV detection Convolutional Neural Network (CNN) architecture based on a shallow version of You Only Look Once version 3 (YOLOv3-tiny) widened by Inception blocks is designed to extract local and global features from input video streams. Here, the widened multi-UAV detection network architecture is termed as FastUAV-NET and aims to improve UAV detection accuracy while preserving computing time of one-step deep detection algorithms in the context of UAV-UAV tracking. To detect UAVs, the FastUAV-NET architecture uses five inception units and adopts a feature pyramid network to detect UAVs. To obtain a high frame rate, the proposed method is applied to every nth frame and then the detected UAVs are tracked in intermediate frames using scalable Kernel Correlation Filter algorithm. The results on the generated UAV-UAV dataset illustrate that the proposed framework obtains 0.7916 average precision with 29 FPS performance on Jetson-TX2. The results imply that the widening of CNN network is a much more effective way than increasing the depth of CNN and leading to a good trade-off between accurate detection and real-time performance. The FastUAV-NET model will be publicly available to the research community to further advance multi-UAV-UAV detection algorithms.
KW  - deep learning
KW  - CNN
KW  - detection and tracking
KW  - Unmanned Aerial Vehicle
KW  - UAVs pursuit-evasion
DO  - 10.3390/electronics10060724
TY  - EJOU
AU  - Hou, Yuewu
AU  - Liu, Zhaoying
AU  - Zhang, Ting
AU  - Li, Yujian
TI  - C-UNet: Complement UNet for Remote Sensing Road Extraction
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 6
SN  - 1424-8220

AB  - Roads are important mode of transportation, which are very convenient for people’s daily work and life. However, it is challenging to accuratly extract road information from a high-resolution remote sensing image. This paper presents a road extraction method for remote sensing images with a complement UNet (C-UNet). C-UNet contains four modules. Firstly, the standard UNet is used to roughly extract road information from remote sensing images, getting the first segmentation result; secondly, a fixed threshold is utilized to erase partial extracted information; thirdly, a multi-scale dense dilated convolution UNet (MD-UNet) is introduced to discover the complement road areas in the erased masks, obtaining the second segmentation result; and, finally, we fuse the extraction results of the first and the third modules, getting the final segmentation results. Experimental results on the Massachusetts Road dataset indicate that our C-UNet gets the higher results than the state-of-the-art methods, demonstrating its effectiveness.
KW  - UNet
KW  - complementary UNet
KW  - fixed threshold
KW  - dilated convolution
KW  - remote sensing
DO  - 10.3390/s21062153
TY  - EJOU
AU  - Liu, Chang
AU  - Szirányi, Tamás
TI  - Real-Time Human Detection and Gesture Recognition for On-Board UAV Rescue
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 6
SN  - 1424-8220

AB  - Unmanned aerial vehicles (UAVs) play an important role in numerous technical and scientific fields, especially in wilderness rescue. This paper carries out work on real-time UAV human detection and recognition of body and hand rescue gestures. We use body-featuring solutions to establish biometric communications, like yolo3-tiny for human detection. When the presence of a person is detected, the system will enter the gesture recognition phase, where the user and the drone can communicate briefly and effectively, avoiding the drawbacks of speech communication. A data-set of ten body rescue gestures (i.e., Kick, Punch, Squat, Stand, Attention, Cancel, Walk, Sit, Direction, and PhoneCall) has been created by a UAV on-board camera. The two most important gestures are the novel dynamic Attention and Cancel which represent the set and reset functions respectively. When the rescue gesture of the human body is recognized as Attention, the drone will gradually approach the user with a larger resolution for hand gesture recognition. The system achieves 99.80% accuracy on testing data in body gesture data-set and 94.71% accuracy on testing data in hand gesture data-set by using the deep learning method. Experiments conducted on real-time UAV cameras confirm our solution can achieve our expected UAV rescue purpose.
KW  - unmanned aerial vehicles (UAVs)
KW  - search and rescue (SAR)
KW  - UAV human communication
KW  - body gesture recognition
KW  - hand gesture recognition
KW  - neural networks
KW  - deep learning
DO  - 10.3390/s21062180
TY  - EJOU
AU  - Holst, Christoph
AU  - Janßen, Jannik
AU  - Schmitz, Berit
AU  - Blome, Martin
AU  - Dercks, Malte
AU  - Schoch-Baumann, Anna
AU  - Blöthe, Jan
AU  - Schrott, Lothar
AU  - Kuhlmann, Heiner
AU  - Medic, Tomislav
TI  - Increasing Spatio-Temporal Resolution for Monitoring Alpine Solifluction Using Terrestrial Laser Scanners and 3D Vector Fields
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 6
SN  - 2072-4292

AB  - This article investigates the usage of terrestrial laser scanner (TLS) point clouds for monitoring the gradual movements of soil masses due to freeze–thaw activity and water saturation, commonly referred to as solifluction. Solifluction is a geomorphic process which is characteristic for hillslopes in (high-)mountain areas, primarily alpine periglacial areas and the arctic. The movement can reach millimetre-to-centimetre per year velocities, remaining well below the typical displacement mangitudes of other frequently monitored natural objects, such as landslides and glaciers. Hence, a better understanding of solifluction processes requires increased spatial and temporal resolution with relatively high measurement accuracy. To that end, we developed a workflow for TLS point cloud processing, providing a 3D vector field that can capture soil mass displacement due to solifluction with high fidelity. This is based on the common image-processing techniques of feature detection and tracking. The developed workflow is tested on a study area placed in Hohe Tauern range of the Austrian Alps with a prominent assemblage of solifluction lobes. The derived displacements were compared with the established geomonitoring approach with total station and signalized markers and point cloud deformation monitoring approaches. The comparison indicated that the achieved results were in the same accuracy range as the established methods, with an advantage of notably higher spatial resolution. This improvement allowed for new insights considering the solifluction processes.
KW  - terrestrial laser scanning
KW  - deformation monitoring
KW  - 3D vector fields
KW  - point clouds
KW  - change detection
KW  - total station
KW  - geodetic network
KW  - LiDAR
KW  - solifluction lobes
KW  - feature detection and tracking
DO  - 10.3390/rs13061192
TY  - EJOU
AU  - Liu, Bi-Yuan
AU  - Chen, Huai-Xin
AU  - Huang, Zhou
AU  - Liu, Xing
AU  - Yang, Yun-Zhi
TI  - ZoomInNet: A Novel Small Object Detector in Drone Images with Cross-Scale Knowledge Distillation
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 6
SN  - 2072-4292

AB  - Drone-based object detection has been widely applied in ground object surveillance, urban patrol, and some other fields. However, the dramatic scale changes and complex backgrounds of drone images usually result in weak feature representation of small objects, which makes it challenging to achieve high-precision object detection. Aiming to improve small objects detection, this paper proposes a novel cross-scale knowledge distillation (CSKD) method, which enhances the features of small objects in a manner similar to image enlargement, so it is termed as ZoomInNet. First, based on an efficient feature pyramid network structure, the teacher and student network are trained with images in different scales to introduce the cross-scale feature. Then, the proposed layer adaption (LA) and feature level alignment (FA) mechanisms are applied to align the feature size of the two models. After that, the adaptive key distillation point (AKDP) algorithm is used to get the crucial positions in feature maps that need knowledge distillation. Finally, the position-aware L2 loss is used to measure the difference between feature maps from cross-scale models, realizing the cross-scale information compression in a single model. Experiments on the challenging Visdrone2018 dataset show that the proposed method draws on the advantages of the image pyramid methods, while avoids the large calculation of them and significantly improves the detection accuracy of small objects. Simultaneously, the comparison with mainstream methods proves that our method has the best performance in small object detection.
KW  - small object detection
KW  - drone image
KW  - image pyramid
KW  - feature enhancement
KW  - cross-scale knowledge distillation
DO  - 10.3390/rs13061198
TY  - EJOU
AU  - Park, Kyung H.
AU  - Park, Eunji
AU  - Kim, Huy K.
TI  - Unsupervised Fault Detection on Unmanned Aerial Vehicles: Encoding and Thresholding Approach
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 6
SN  - 1424-8220

AB  - Unmanned Aerial Vehicles are expected to create enormous benefits to society, but there are safety concerns in recognizing faults at the vehicle’s control component. Prior studies proposed various fault detection approaches leveraging heuristics-based rules and supervised learning-based models, but there were several drawbacks. The rule-based approaches required an engineer to update the rules on every type of fault, and the supervised learning-based approaches necessitated the acquisition of a finely-labeled training dataset. Moreover, both prior approaches commonly include a limit that the detection model can identify the trained type of faults only, but fail to recognize the unseen type of faults. In pursuit of resolving the aforementioned drawbacks, we proposed a fault detection model utilizing a stacked autoencoder that lies under unsupervised learning. The autoencoder was trained with data from safe UAV states, and its reconstruction loss was examined to distinguish the safe states and faulty states. The key contributions of our study are, as follows. First, we presented a series of analyses to extract essential features from raw UAV flight logs. Second, we designed a fault detection model consisting of the stacked autoencoder and the classifier. Lastly, we validated our approach’s fault detection performance with two datasets consisting of different types of UAV faults.
KW  - Unmanned Aerial Vehicle
KW  - fault detection
KW  - anomaly detection
KW  - unsupervised learning
KW  - autoencoder
DO  - 10.3390/s21062208
TY  - EJOU
AU  - Passafiume, Marco
AU  - Rojhani, Neda
AU  - Collodi, Giovanni
AU  - Cidronali, Alessandro
TI  - Modeling Small UAV Micro-Doppler Signature Using Millimeter-Wave FMCW Radar
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 6
SN  - 2079-9292

AB  - With the increase in small unmanned aerial vehicle (UAV) applications in several technology areas, detection and small UAVs classification have become of interest. To cope with small radar cross-sections (RCSs), slow-flying speeds, and low flying altitudes, the micro-Doppler signature provides some of the most distinctive information to identify and classify targets in many radar systems. In this paper, we introduce an effective model for the micro-Doppler effect that is suitable for frequency-modulated continuous-wave (FMCW) radar applications, and exploit it to investigate UAV signatures. The latter depends on the number of UAV motors, which are considered vibrational sources, and their rotation speed. To demonstrate the reliability of the proposed model, it is used to build simulated FMCW radar images, which are compared with experimental data acquired by a 77 GHz FMCW multiple-input multiple-output (MIMO) cost-effective automotive radar platform. The experimental results confirm the model’s ability to estimate the class of the UAV, namely its number of motors, in different operative scenarios. In addition, the experimental results show that the motors rotation speed does not imprint a significant signature on the classification of the UAV; thus, the estimation of the number of motors represents the only viable parameter for small UAV classification using the micro-Doppler effect.
KW  - UAV classification
KW  - feature extraction
KW  - micro-Doppler signature
KW  - FMCW radar
KW  - automotive radar
DO  - 10.3390/electronics10060747
TY  - EJOU
AU  - Fan, Pan
AU  - Lang, Guodong
AU  - Yan, Bin
AU  - Lei, Xiaoyan
AU  - Guo, Pengju
AU  - Liu, Zhijie
AU  - Yang, Fuzeng
TI  - A Method of Segmenting Apples Based on Gray-Centered RGB Color Space
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 6
SN  - 2072-4292

AB  - In recent years, many agriculture-related problems have been evaluated with the integration of artificial intelligence techniques and remote sensing systems. The rapid and accurate identification of apple targets in an illuminated and unstructured natural orchard is still a key challenge for the picking robot’s vision system. In this paper, by combining local image features and color information, we propose a pixel patch segmentation method based on gray-centered red–green–blue (RGB) color space to address this issue. Different from the existing methods, this method presents a novel color feature selection method that accounts for the influence of illumination and shadow in apple images. By exploring both color features and local variation in apple images, the proposed method could effectively distinguish the apple fruit pixels from other pixels. Compared with the classical segmentation methods and conventional clustering algorithms as well as the popular deep-learning segmentation algorithms, the proposed method can segment apple images more accurately and effectively. The proposed method was tested on 180 apple images. It offered an average accuracy rate of 99.26%, recall rate of 98.69%, false positive rate of 0.06%, and false negative rate of 1.44%. Experimental results demonstrate the outstanding performance of the proposed method.
KW  - fruit detection
KW  - fruit segmentation
KW  - color space
KW  - segmentation algorithm
DO  - 10.3390/rs13061211
TY  - EJOU
AU  - Li, Ke
AU  - Zhang, Kun
AU  - Zhang, Zhenchong
AU  - Liu, Zekun
AU  - Hua, Shuai
AU  - He, Jianliang
TI  - A UAV Maneuver Decision-Making Algorithm for Autonomous Airdrop Based on Deep Reinforcement Learning
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 6
SN  - 1424-8220

AB  - How to operate an unmanned aerial vehicle (UAV) safely and efficiently in an interactive environment is challenging. A large amount of research has been devoted to improve the intelligence of a UAV while performing a mission, where finding an optimal maneuver decision-making policy of the UAV has become one of the key issues when we attempt to enable the UAV autonomy. In this paper, we propose a maneuver decision-making algorithm based on deep reinforcement learning, which generates efficient maneuvers for a UAV agent to execute the airdrop mission autonomously in an interactive environment. Particularly, the training set of the learning algorithm by the Prioritized Experience Replay is constructed, that can accelerate the convergence speed of decision network training in the algorithm. It is shown that a desirable and effective maneuver decision-making policy can be found by extensive experimental results.
KW  - UAV
KW  - maneuver decision-making
KW  - autonomous airdrop
KW  - deep reinforcement learning
KW  - prioritized experience replay
DO  - 10.3390/s21062233
TY  - EJOU
AU  - Kaivosoja, Jere
AU  - Hautsalo, Juho
AU  - Heikkinen, Jaakko
AU  - Hiltunen, Lea
AU  - Ruuttunen, Pentti
AU  - Näsi, Roope
AU  - Niemeläinen, Oiva
AU  - Lemsalu, Madis
AU  - Honkavaara, Eija
AU  - Salonen, Jukka
TI  - Reference Measurements in Developing UAV Systems for Detecting Pests, Weeds, and Diseases
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 7
SN  - 2072-4292

AB  - The development of UAV (unmanned aerial vehicle) imaging technologies for precision farming applications is rapid, and new studies are published frequently. In cases where measurements are based on aerial imaging, there is the need to have ground truth or reference data in order to develop reliable applications. However, in several precision farming use cases such as pests, weeds, and diseases detection, the reference data can be subjective or relatively difficult to capture. Furthermore, the collection of reference data is usually laborious and time consuming. It also appears that it is difficult to develop generalisable solutions for these areas. This review studies previous research related to pests, weeds, and diseases detection and mapping using UAV imaging in the precision farming context, underpinning the applied reference measurement techniques. The majority of the reviewed studies utilised subjective visual observations of UAV images, and only a few applied in situ measurements. The conclusion of the review is that there is a lack of quantitative and repeatable reference data measurement solutions in the areas of mapping pests, weeds, and diseases. In addition, the results that the studies present should be reflected in the applied references. An option in the future approach could be the use of synthetic data as reference.
KW  - UAS
KW  - drone
KW  - unmanned aerial vehicle
KW  - in situ
KW  - reference data
KW  - ground truth
KW  - monitoring
KW  - precision agriculture
KW  - smart farming
DO  - 10.3390/rs13071238
TY  - EJOU
AU  - Oliveira, Luiz F. P.
AU  - Moreira, António P.
AU  - Silva, Manuel F.
TI  - Advances in Agriculture Robotics: A State-of-the-Art Review and Challenges Ahead
T2  - Robotics

PY  - 2021
VL  - 10
IS  - 2
SN  - 2218-6581

AB  - The constant advances in agricultural robotics aim to overcome the challenges imposed by population growth, accelerated urbanization, high competitiveness of high-quality products, environmental preservation and a lack of qualified labor. In this sense, this review paper surveys the main existing applications of agricultural robotic systems for the execution of land preparation before planting, sowing, planting, plant treatment, harvesting, yield estimation and phenotyping. In general, all robots were evaluated according to the following criteria: its locomotion system, what is the final application, if it has sensors, robotic arm and/or computer vision algorithm, what is its development stage and which country and continent they belong. After evaluating all similar characteristics, to expose the research trends, common pitfalls and the characteristics that hinder commercial development, and discover which countries are investing into Research and Development (R&amp;D) in these technologies for the future, four major areas that need future research work for enhancing the state of the art in smart agriculture were highlighted: locomotion systems, sensors, computer vision algorithms and communication technologies. The results of this research suggest that the investment in agricultural robotic systems allows to achieve short—harvest monitoring—and long-term objectives—yield estimation.
KW  - agricultural robots
KW  - agriculture 4.0
KW  - precision agriculture
DO  - 10.3390/robotics10020052
TY  - EJOU
AU  - Liu, Chuanyang
AU  - Wu, Yiquan
AU  - Liu, Jingjing
AU  - Sun, Zuo
TI  - Improved YOLOv3 Network for Insulator Detection in Aerial Images with Diverse Background Interference
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 7
SN  - 2079-9292

AB  - Automatic inspection of insulators from high-voltage transmission lines is of paramount importance to the safety and reliable operation of the power grid. Due to different size insulators and the complex background of aerial images, it is a difficult task to recognize insulators in aerial views. Most of the traditional image processing methods and machine learning methods cannot achieve sufficient performance for insulator detection when diverse background interference is present. In this study, a deep learning method—based on You Only Look Once (YOLO)—will be proposed, capable of detecting insulators from aerial images with complex backgrounds. Firstly, aerial images with common aerial scenes were collected by Unmanned Aerial Vehicle (UAV), and a novel insulator dataset was constructed. Secondly, to enhance feature reuse and propagation, on the basis of YOLOv3 and Dense-Blocks, the YOLOv3-dense network was utilized for insulator detection. To improve detection accuracy for different sized insulators, a structure of multiscale feature fusion was adapted to the YOLOv3-dense network. To obtain abundant semantic information of upper and lower layers, multilevel feature mapping modules were employed across the YOLOv3-dense network. Finally, the YOLOv3-dense network and compared networks were trained and tested on the testing set. The average precision of YOLOv3-dense, YOLOv3, and YOLOv2 were 94.47%, 90.31%, and 83.43%, respectively. Experimental results and analysis validate the claim that the proposed YOLOv3-dense network achieves good performance in the detection of different size insulators amid diverse background interference.
KW  - aerial image
KW  - insulator detection
KW  - YOLO
KW  - background interference
KW  - image processing
KW  - deep learning
KW  - Dense-Block
DO  - 10.3390/electronics10070771
TY  - EJOU
AU  - He, Shaokun
AU  - Gu, Lei
AU  - Tian, Jing
AU  - Deng, Lele
AU  - Yin, Jiabo
AU  - Liao, Zhen
AU  - Zeng, Ziyue
AU  - Shen, Youjiang
AU  - Hui, Yu
TI  - Machine Learning Improvement of Streamflow Simulation by Utilizing Remote Sensing Data and Potential Application in Guiding Reservoir Operation
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 7
SN  - 2071-1050

AB  - Hydro-meteorological datasets are key components for understanding physical hydrological processes, but the scarcity of observational data hinders their potential application in poorly gauged regions. Satellite-retrieved and atmospheric reanalysis products exhibit considerable advantages in filling the spatial gaps in in-situ gauging networks and are thus forced to drive the physically lumped hydrological models for long-term streamflow simulation in data-sparse regions. As machine learning (ML)-based techniques can capture the relationship between different elements, they may have potential in further exploring meteorological predictors and hydrological responses. To examine the application prospects of a physically constrained ML algorithm using earth observation data, we used a short-series hydrological observation of the Hanjiang River basin in China as a case study. In this study, the prevalent modèle du Génie Rural à 9 paramètres Journalier (GR4J-9) hydrological model was used to initially simulate streamflow, and then, the simulated series and remote sensing data were used to train the long short-term memory (LSTM) method. The results demonstrated that the advanced GR4J9–LSTM model chain effectively improves the performance of the streamflow simulation by using more remote sensing data related to the hydrological response variables. Additionally, we derived a reservoir operation model by feeding the LSTM-based simulation outputs, which further revealed the potential application of our proposed technique.
KW  - ungauged basin
KW  - machine learning
KW  - streamflow simulation
KW  - satellite precipitation
KW  - atmospheric reanalysis
DO  - 10.3390/su13073645
TY  - EJOU
AU  - López-Andreu, Francisco J.
AU  - Erena, Manuel
AU  - Dominguez-Gómez, Jose A.
AU  - López-Morales, Juan A.
TI  - Sentinel-2 Images and Machine Learning as Tool for Monitoring of the Common Agricultural Policy: Calasparra Rice as a Case Study
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 4
SN  - 2073-4395

AB  - The European Commission introduces the Control by Monitoring through new technologies to manage Common Agricultural Policy funds through the Regulation 2018/746. The advances in remote sensing have been considered one of these new technologies, mainly since the European Space Agency designed the Copernicus Programme. The Sentinel-1 (radar range) and Sentinel-2 (optical range) satellites have been designed for monitoring agricultural problems based on the characteristics they provide. The data provided by the Sentinel 2 missions, together with the emergence of different scientific disciplines in artificial intelligence —especially machine learning— offer the perfect basis for identifying and classifying any crop and its phenological state. Our research is based on developing and evaluating a pixel-based supervised classification scheme to produce accurate rice crop mapping in a smallholder agricultural zone in Calasparra, Murcia, Spain. Several models are considered to obtain the most suitable model for each element of the time series used; pixel-based classification is performed and finished with a statistical treatment. The highly accurate results obtained, especially across the most significant vegetative development dates, indicate the benefits of using Sentinel-2 data combined with Machine Learning techniques to identify rice crops. It should be noted that it was possible to locate rice crop areas with an overall accuracy of 94% and standard deviation of 1%, which could be increased to 96% (±1%) if we focus on the months of the crop’s highest development state. Thanks to the proposed methodology, the on-site inspections carried out, 5% of the files, have been replaced by remote sensing evaluations of 100% of the analyzed season files. Besides, by adjusting the model input data, it is possible to detect unproductive or abandoned plots.
KW  - multispectral remote sensing
KW  - Copernicus
KW  - sentinel
KW  - image processing
KW  - machine learning
KW  - agriculture
KW  - land cover
KW  - rice crop
KW  - common agricultural policy
DO  - 10.3390/agronomy11040621
TY  - EJOU
AU  - Dike, Happiness U.
AU  - Zhou, Yimin
TI  - A Robust Quadruplet and Faster Region-Based CNN for UAV Video-Based Multiple Object Tracking in Crowded Environment
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 7
SN  - 2079-9292

AB  - Multiple object tracking (MOT) from unmanned aerial vehicle (UAV) videos has faced several challenges such as motion capture and appearance, clustering, object variation, high altitudes, and abrupt motion. Consequently, the volume of objects captured by the UAV is usually quite small, and the target object appearance information is not always reliable. To solve these issues, a new technique is presented to track objects based on a deep learning technique that attains state-of-the-art performance on standard datasets, such as Stanford Drone and Unmanned Aerial Vehicle Benchmark: Object Detection and Tracking (UAVDT) datasets. The proposed faster RCNN (region-based convolutional neural network) framework was enhanced by integrating a series of activities, including the proper calibration of key parameters, multi-scale training, hard negative mining, and feature collection to improve the region-based CNN baseline. Furthermore, a deep quadruplet network (DQN) was applied to track the movement of the captured objects from the crowded environment, and it was modelled to utilize new quadruplet loss function in order to study the feature space. A deep 6 Rectified linear units (ReLU) convolution was used in the faster RCNN to mine spatial–spectral features. The experimental results on the standard datasets demonstrated a high performance accuracy. Thus, the proposed method can be used to detect multiple objects and track their trajectories with a high accuracy.
KW  - quadruplet network
KW  - deep convolutional neural network
KW  - visual detection and tracking
KW  - unmanned aerial vehicle
DO  - 10.3390/electronics10070795
TY  - EJOU
AU  - Li, Tong
AU  - Cui, Lizhen
AU  - Xu, Zhihong
AU  - Hu, Ronghai
AU  - Joshi, Pawan K.
AU  - Song, Xiufang
AU  - Tang, Li
AU  - Xia, Anquan
AU  - Wang, Yanfen
AU  - Guo, Da
AU  - Zhu, Jiapei
AU  - Hao, Yanbin
AU  - Song, Lan
AU  - Cui, Xiaoyong
TI  - Quantitative Analysis of the Research Trends and Areas in Grassland Remote Sensing: A Scientometrics Analysis of Web of Science from 1980 to 2020
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 7
SN  - 2072-4292

AB  - Grassland remote sensing (GRS) is an important research topic that applies remote sensing technology to grassland ecosystems, reflects the number of grassland resources and grassland health promptly, and provides inversion information used in sustainable development management. A scientometrics analysis based on Science Citation Index-Expanded (SCI-E) was performed to understand the research trends and areas of focus in GRS research studies. A total of 2692 papers related to GRS research studies and 82,208 references published from 1980 to 2020 were selected as the research objects. A comprehensive overview of the field based on the annual documents, research areas, institutions, influential journals, core authors, and temporal trends in keywords were presented in this study. The results showed that the annual number of documents increased exponentially, and more than 100 papers were published each year since 2010. Remote sensing, environmental sciences, and ecology were the most popular Web of Science research areas. The journal Remote Sensing was one of the most popular for researchers to publish documents and shows high development and publishing potential in GRS research studies. The institution with the greatest research documents and most citations was the Chinese Academy of Sciences. Guo X.L., Hill M.J., and Zhang L. were the most productive authors across the 40-year study period in terms of the number of articles published. Seven clusters of research areas were identified that generated contributions to this topic by keyword co-occurrence analysis. We also detected 17 main future directions of GRS research studies by document co-citation analysis. Emerging or underutilized methodologies and technologies, such as unmanned aerial systems (UASs), cloud computing, and deep learning, will continue to further enhance GRS research in the process of achieving sustainable development goals. These results can help related researchers better understand the past and future of GRS research studies.
KW  - grassland
KW  - remote sensing
KW  - CiteSpace
KW  - scientometrics analysis
KW  - research progress
KW  - network analysis
KW  - visualization
KW  - Web of Science
DO  - 10.3390/rs13071279
TY  - EJOU
AU  - Grekhov, Andrii
AU  - Kondratiuk, Vasyl
AU  - Ilnytska, Svitlana
TI  - Data Traffic Modeling in RPAS/UAV Networks with Different Architectures
T2  - Modelling

PY  - 2021
VL  - 2
IS  - 2
SN  - 2673-3951

AB  - Deploying of Fifth Generation and Beyond Fifth Generation (5G/B5G) wireless networks will require wider coverage, flexible connectivity, low latency, support for a large number of user devices, and more bandwidth. This article explores the paradigm that Remotely Piloted Air Systems (RPASs) or Unmanned Aerial Vehicles (UAVs) are integrated as a communication platform with cellular networks using radio access. It is important to know the possibilities and ways of such integration for effective interaction with RPASs. This paper studies the issues of ensuring the required Quality of Service (QoS) during heavy traffic and the choice of necessary data transmission modes for this. Models of RPAS communication channels with different architectures were created. The relationships between models’ performance and traffic parameters were obtained using the NetCracker Professional 4.1 software. The dependencies of the Average Utilization (AU) on the Transaction Size (TS) were analyzed. The effects of different bandwidths and the Bit Error Rate (BER) were studied. The traffic characteristics in all models were compared.
KW  - remotely piloted air systems (RPAS)
KW  - unmanned aerial vehicles (UAVs)
KW  - 5G/B5G
KW  - data traffic
KW  - transaction size
KW  - average utilization
KW  - BER
KW  - bandwidth
DO  - 10.3390/modelling2020011
TY  - EJOU
AU  - Campos, Javier
AU  - García-Ruíz, Francisco
AU  - Gil, Emilio
TI  - Assessment of Vineyard Canopy Characteristics from Vigour Maps Obtained Using UAV and Satellite Imagery
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 7
SN  - 1424-8220

AB  - Canopy characterisation is a key factor for the success and efficiency of the pesticide application process in vineyards. Canopy measurements to determine the optimal volume rate are currently conducted manually, which is time-consuming and limits the adoption of precise methods for volume rate selection. Therefore, automated methods for canopy characterisation must be established using a rapid and reliable technology capable of providing precise information about crop structure. This research providedregression models for obtaining canopy characteristics of vineyards from unmanned aerial vehicle (UAV) and satellite images collected in three significant growth stages. Between 2018 and 2019, a total of 1400 vines were characterised manually and remotely using a UAV and a satellite-based technology. The information collected from the sampled vines was analysed by two different procedures. First, a linear relationship between the manual and remote sensing data was investigated considering every single vine as a data point. Second, the vines were clustered based on three vigour levels in the parcel, and regression models were fitted to the average values of the ground-based and remote sensing-estimated canopy parameters. Remote sensing could detect the changes in canopy characteristics associated with vegetation growth. The combination of normalised differential vegetation index (NDVI) and projected area extracted from the UAV images is correlated with the tree row volume (TRV) when raw point data were used. This relationship was improved and extended to canopy height, width, leaf wall area, and TRV when the data were clustered. Similarly, satellite-based NDVI yielded moderate coefficients of determination for canopy width with raw point data, and for canopy width, height, and TRV when the vines were clustered according to the vigour. The proposed approach should facilitate the estimation of canopy characteristics in each area of a field using a cost-effective, simple, and reliable technology, allowing variable rate application in vineyards.
KW  - vineyard
KW  - pesticide application
KW  - variable rate application
KW  - unmanned aerial vehicle
KW  - satellite
KW  - nanosatellite
DO  - 10.3390/s21072363
TY  - EJOU
AU  - Xu, Danqing
AU  - Wu, Yiquan
TI  - FE-YOLO: A Feature Enhancement Network for Remote Sensing Target Detection
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 7
SN  - 2072-4292

AB  - In the past few decades, target detection from remote sensing images gained from aircraft or satellites has become one of the hottest topics. However, the existing algorithms are still limited by the detection of small remote sensing targets. Benefiting from the great development of computing power, deep learning has also made great breakthroughs. Due to a large number of small targets and complexity of background, the task of remote sensing target detection is still a challenge. In this work, we establish a series of feature enhancement modules for the network based on YOLO (You Only Look Once) -V3 to improve the performance of feature extraction. Therefore, we term our proposed network as FE-YOLO. In addition, to realize fast detection, the original Darknet-53 was simplified. Experimental results on remote sensing datasets show that our proposed FE-YOLO performs better than other state-of-the-art target detection models.
KW  - target detection
KW  - remote sensing images
KW  - YOLO-V3
KW  - feature enhancement
KW  - deep learning
DO  - 10.3390/rs13071311
TY  - EJOU
AU  - Ammar, Adel
AU  - Koubaa, Anis
AU  - Ahmed, Mohanned
AU  - Saad, Abdulrahman
AU  - Benjdira, Bilel
TI  - Vehicle Detection from Aerial Images Using Deep Learning: A Comparative Study
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 7
SN  - 2079-9292

AB  - This paper addresses the problem of car detection from aerial images using Convolutional Neural Networks (CNNs). This problem presents additional challenges as compared to car (or any object) detection from ground images because the features of vehicles from aerial images are more difficult to discern. To investigate this issue, we assess the performance of three state-of-the-art CNN algorithms, namely Faster R-CNN, which is the most popular region-based algorithm, as well as YOLOv3 and YOLOv4, which are known to be the fastest detection algorithms. We analyze two datasets with different characteristics to check the impact of various factors, such as the UAV’s (unmanned aerial vehicle) altitude, camera resolution, and object size. A total of 52 training experiments were conducted to account for the effect of different hyperparameter values. The objective of this work is to conduct the most robust and exhaustive comparison between these three cutting-edge algorithms on the specific domain of aerial images. By using a variety of metrics, we show that the difference between YOLOv4 and YOLOv3 on the two datasets is statistically insignificant in terms of Average Precision (AP) (contrary to what was obtained on the COCO dataset). However, both of them yield markedly better performance than Faster R-CNN in most configurations. The only exception is that both of them exhibit a lower recall when object sizes and scales in the testing dataset differ largely from those in the training dataset.
KW  - car detection
KW  - convolutional neural networks
KW  - deep learning
KW  - Faster R-CNN
KW  - unmanned aerial vehicles
KW  - YOLOv3
KW  - YOLOv4
DO  - 10.3390/electronics10070820
TY  - EJOU
AU  - Kuçak, Ramazan A.
AU  - Erol, Serdar
AU  - Erol, Bihter
TI  - An Experimental Study of a New Keypoint Matching Algorithm for Automatic Point Cloud Registration
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 4
SN  - 2220-9964

AB  - Light detection and ranging (LiDAR) data systems mounted on a moving or stationary platform provide 3D point cloud data for various purposes. In applications where the interested area or object needs to be measured twice or more with a shift, precise registration of the obtained point clouds is crucial for generating a healthy model with the combination of the overlapped point clouds. Automatic registration of the point clouds in the common coordinate system using the iterative closest point (ICP) algorithm or its variants is one of the frequently applied methods in the literature, and a number of studies focus on improving the registration process algorithms for achieving better results. This study proposed and tested a different approach for automatic keypoint detecting and matching in coarse registration of the point clouds before fine registration using the ICP algorithm. In the suggested algorithm, the keypoints were matched considering their geometrical relations expressed by means of the angles and distances among them. Hence, contributing the quality improvement of the 3D model obtained through the fine registration process, which is carried out using the ICP method, was our aim. The performance of the new algorithm was assessed using the root mean square error (RMSE) of the 3D transformation in the rough alignment stage as well as a-prior and a-posterior RMSE values of the ICP algorithm. The new algorithm was also compared with the point feature histogram (PFH) descriptor and matching algorithm, accompanying two commonly used detectors. In result of the comparisons, the superiorities and disadvantages of the suggested algorithm were discussed. The measurements for the datasets employed in the experiments were carried out using scanned data of a 6 cm × 6 cm × 10 cm Aristotle sculpture in the laboratory environment, and a building facade in the outdoor as well as using the publically available Stanford bunny sculpture data. In each case study, the proposed algorithm provided satisfying performance with superior accuracy and less iteration number in the ICP process compared to the other coarse registration methods. From the point clouds where coarse registration has been made with the proposed method, the fine registration accuracies in terms of RMSE values with ICP iterations are calculated as ~0.29 cm for Aristotle and Stanford bunny sculptures, ~2.0 cm for the building facade, respectively.
KW  - automatic matching
KW  - keypoint detection
KW  - point cloud
KW  - registration
KW  - transformation
KW  - iterative closest point (ICP)
DO  - 10.3390/ijgi10040204
TY  - EJOU
AU  - Al-Darraji, Izzat
AU  - Piromalis, Dimitrios
AU  - Kakei, Ayad A.
AU  - Khan, Fazal Q.
AU  - Stojmenovic, Milos
AU  - Tsaramirsis, Georgios
AU  - Papageorgas, Panagiotis G.
TI  - Adaptive Robust Controller Design-Based RBF Neural Network for Aerial Robot Arm Model
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 7
SN  - 2079-9292

AB  - Aerial Robot Arms (ARAs) enable aerial drones to interact and influence objects in various environments. Traditional ARA controllers need the availability of a high-precision model to avoid high control chattering. Furthermore, in practical applications of aerial object manipulation, the payloads that ARAs can handle vary, depending on the nature of the task. The high uncertainties due to modeling errors and an unknown payload are inversely proportional to the stability of ARAs. To address the issue of stability, a new adaptive robust controller, based on the Radial Basis Function (RBF) neural network, is proposed. A three-tier approach is also followed. Firstly, a detailed new model for the ARA is derived using the Lagrange–d’Alembert principle. Secondly, an adaptive robust controller, based on a sliding mode, is designed to manipulate the problem of uncertainties, including modeling errors. Last, a higher stability controller, based on the RBF neural network, is implemented with the adaptive robust controller to stabilize the ARAs, avoiding modeling errors and unknown payload issues. The novelty of the proposed design is that it takes into account high nonlinearities, coupling control loops, high modeling errors, and disturbances due to payloads and environmental conditions. The model was evaluated by the simulation of a case study that includes the two proposed controllers and ARA trajectory tracking. The simulation results show the validation and notability of the presented control algorithm.
KW  - aerial robot arms
KW  - modeling of aerial robot arms
KW  - adaptive controller
KW  - robust controller
KW  - sliding mode controller
KW  - RBF neural network
KW  - stability of aerial robot arms
KW  - trajectory tracking
KW  - high modeling errors
DO  - 10.3390/electronics10070831
TY  - EJOU
AU  - You, Hojun
AU  - Kim, Dongsu
TI  - Development of an Image Registration Technique for Fluvial Hyperspectral Imagery Using an Optical Flow Algorithm
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 7
SN  - 1424-8220

AB  - Fluvial remote sensing has been used to monitor diverse riverine properties through processes such as river bathymetry and visual detection of suspended sediment, algal blooms, and bed materials more efficiently than laborious and expensive in-situ measurements. Red–green–blue (RGB) optical sensors have been widely used in traditional fluvial remote sensing. However, owing to their three confined bands, they rely on visual inspection for qualitative assessments and are limited to performing quantitative and accurate monitoring. Recent advances in hyperspectral imaging in the fluvial domain have enabled hyperspectral images to be geared with more than 150 spectral bands. Thus, various riverine properties can be quantitatively characterized using sensors in low-altitude unmanned aerial vehicles (UAVs) with a high spatial resolution. Many efforts are ongoing to take full advantage of hyperspectral band information in fluvial research. Although geo-referenced hyperspectral images can be acquired for satellites and manned airplanes, few attempts have been made using UAVs. This is mainly because the synthesis of line-scanned images on top of image registration using UAVs is more difficult owing to the highly sensitive and heavy image driven by dense spatial resolution. Therefore, in this study, we propose a practical technique for achieving high spatial accuracy in UAV-based fluvial hyperspectral imaging through efficient image registration using an optical flow algorithm. Template matching algorithms are the most common image registration technique in RGB-based remote sensing; however, they require many calculations and can be error-prone depending on the user, as decisions regarding various parameters are required. Furthermore, the spatial accuracy of this technique needs to be verified, as it has not been widely applied to hyperspectral imagery. The proposed technique resulted in an average reduction of spatial errors by 91.9%, compared to the case where the image registration technique was not applied, and by 78.7% compared to template matching.
KW  - fluvial remote sensing
KW  - hyperspectral imagery
KW  - optical flow
KW  - image registration
DO  - 10.3390/s21072407
TY  - EJOU
AU  - Wang, Fei
AU  - Liu, Zhendong
AU  - Zhu, Hongchun
AU  - Wu, Pengda
AU  - Li, Chengming
TI  - An Improved Method for Stable Feature Points Selection in Structure-from-Motion Considering Image Semantic and Structural Characteristics
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 7
SN  - 1424-8220

AB  - Feature matching plays a crucial role in the process of 3D reconstruction based on the structure from motion (SfM) technique. For a large collection of oblique images, feature matching is one of the most time-consuming steps, and the matching result directly affects the accuracy of subsequent tasks. Therefore, how to extract the reasonable feature points robustly and efficiently to improve the matching speed and quality has received extensive attention from scholars worldwide. Most studies perform quantitative feature point selection based on image Difference-of-Gaussian (DoG) pyramids in practice. However, the stability and spatial distribution of feature points are not considered enough, resulting in selected feature points that may not adequately reflect the scene structures and cannot guarantee the matching rate and the aerial triangulation accuracy. To address these issues, an improved method for stable feature point selection in SfM considering image semantic and structural characteristics is proposed. First, the visible-band difference vegetation index is used to identify the vegetation areas from oblique images, and the line feature in the image is extracted by the optimized line segment detector algorithm. Second, the feature point two-tuple classification model is established, in which the vegetation area recognition result is used as the semantic constraint, the line feature extraction result is used as the structural constraint, and the feature points are divided into three types. Finally, a progressive selection algorithm for feature points is proposed, in which feature points in the DoG pyramid are selected by classes and levels until the number of feature points is satisfied. Oblique images of a 40-km2 area in Dongying city, China, were used for validation. The experimental results show that compared to the state-of-the-art method, the method proposed in this paper not only effectively reduces the number of feature points but also better reflects the scene structure. At the same time, the average reprojection error of the aerial triangulation decrease by 20%, the feature point matching rate increase by 3%, the selected feature points are more stable and reasonable.
KW  - 3D reconstruction
KW  - oblique images
KW  - feature point selection
KW  - image semantic and structural characteristics
KW  - two-tuple classification model
DO  - 10.3390/s21072416
TY  - EJOU
AU  - Araújo, Sara O.
AU  - Peres, Ricardo S.
AU  - Barata, José
AU  - Lidon, Fernando
AU  - Ramalho, José C.
TI  - Characterising the Agriculture 4.0 Landscape—Emerging Trends, Challenges and Opportunities
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 4
SN  - 2073-4395

AB  - Investment in technological research is imperative to stimulate the development of sustainable solutions for the agricultural sector. Advances in Internet of Things, sensors and sensor networks, robotics, artificial intelligence, big data, cloud computing, etc. foster the transition towards the Agriculture 4.0 era. This fourth revolution is currently seen as a possible solution for improving agricultural growth, ensuring the future needs of the global population in a fair, resilient and sustainable way. In this context, this article aims at characterising the current Agriculture 4.0 landscape. Emerging trends were compiled using a semi-automated process by analysing relevant scientific publications published in the past ten years. Subsequently, a literature review focusing these trends was conducted, with a particular emphasis on their applications in real environments. From the results of the study, some challenges are discussed, as well as opportunities for future research. Finally, a high-level cloud-based IoT architecture is presented, serving as foundation for designing future smart agricultural systems. It is expected that this work will positively impact the research around Agriculture 4.0 systems, providing a clear characterisation of the concept along with guidelines to assist the actors in a successful transition towards the digitalisation of the sector.
KW  - Agriculture 4.0
KW  - artificial intelligence
KW  - cloud computing
KW  - decision support system
KW  - internet of things
KW  - robotics
KW  - sensors
DO  - 10.3390/agronomy11040667
TY  - EJOU
AU  - Appeltans, Simon
AU  - Pieters, Jan G.
AU  - Mouazen, Abdul M.
TI  - Detection of Leek Rust Disease under Field Conditions Using Hyperspectral Proximal Sensing and Machine Learning
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 7
SN  - 2072-4292

AB  - Rust disease is an important problem for leek cultivation worldwide. It reduces market value and in extreme cases destroys the entire harvest. Farmers have to resort to periodical full-field fungicide applications to prevent the spread of disease, once every 1 to 5 weeks, depending on the cultivar and weather conditions. This implies an economic cost for the farmer and an environmental cost for society. Hyperspectral sensors have been extensively used to address this issue in research, but their application in the field has been limited to a relatively low number of crops, excluding leek, due to the high investment costs and complex data gathering and analysis associated with these sensors. To fill this gap, a methodology was developed for detecting leek rust disease using hyperspectral proximal sensing data combined with supervised machine learning. First, a hyperspectral library was constructed containing 43,416 spectra with a waveband range of 400–1000 nm, measured under field conditions. Then, an extensive evaluation of 11 common classifiers was performed using the scikit-learn machine learning library in Python, combined with a variety of wavelength selection techniques and preprocessing strategies. The best performing model was a (linear) logistic regression model that was able to correctly classify rust disease with an accuracy of 98.14%, using reflectance values at 556 and 661 nm, combined with the value of the first derivative at 511 nm. This model was used to classify unlabelled hyperspectral images, confirming that the model was able to accurately classify leek rust disease symptoms. It can be concluded that the results in this work are an important step towards the mapping of leek rust disease, and that future research is needed to overcome certain challenges before variable rate fungicide applications can be adopted against leek rust disease.
KW  - hyperspectral
KW  - proximal sensing
KW  - disease detection
KW  - leek
KW  - rust
KW  - machine learning
DO  - 10.3390/rs13071341
TY  - EJOU
AU  - Vélez-Nicolás, Mercedes
AU  - García-López, Santiago
AU  - Barbero, Luis
AU  - Ruiz-Ortiz, Verónica
AU  - Sánchez-Bellón, Ángel
TI  - Applications of Unmanned Aerial Systems (UASs) in Hydrology: A Review
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 7
SN  - 2072-4292

AB  - In less than two decades, UASs (unmanned aerial systems) have revolutionized the field of hydrology, bridging the gap between traditional satellite observations and ground-based measurements and allowing the limitations of manned aircraft to be overcome. With unparalleled spatial and temporal resolutions and product-tailoring possibilities, UAS are contributing to the acquisition of large volumes of data on water bodies, submerged parameters and their interactions in different hydrological contexts and in inaccessible or hazardous locations. This paper provides a comprehensive review of 122 works on the applications of UASs in surface water and groundwater research with a purpose-oriented approach. Concretely, the review addresses: (i) the current applications of UAS in surface and groundwater studies, (ii) the type of platforms and sensors mainly used in these tasks, (iii) types of products generated from UAS-borne data, (iv) the associated advantages and limitations, and (v) knowledge gaps and future prospects of UASs application in hydrology. The first aim of this review is to serve as a reference or introductory document for all researchers and water managers who are interested in embracing this novel technology. The second aim is to unify in a single document all the possibilities, potential approaches and results obtained by different authors through the implementation of UASs.
KW  - drone applications
KW  - surface water
KW  - groundwater
KW  - photogrammetry
KW  - optical sensing
KW  - thermal infrared
DO  - 10.3390/rs13071359
TY  - EJOU
AU  - Park, Jonghyuk
AU  - Park, Jonghun
AU  - Shin, Dongmin
AU  - Choi, Yerim
TI  - A BCI Based Alerting System for Attention Recovery of UAV Operators
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 7
SN  - 1424-8220

AB  - As unmanned aerial vehicles have become popular, the number of accidents caused by an operator’s inattention have increased. To prevent such accidents, the operator should maintain an attention status. However, limited research has been conducted on the brain-computer interface (BCI)-based system with an alerting module for the operator’s attention recovery of unmanned aerial vehicles. Therefore, we introduce a detection and alerting system that prevents an unmanned aerial vehicle operator from falling into inattention status by using the operator’s electroencephalogram signal. The proposed system consists of the following three components: a signal processing module, which collects and preprocesses an electroencephalogram signal of an operator, an inattention detection module, which determines whether an inattention status occurred based on the preprocessed signal, and, lastly, an alert providing module that presents stimulus to an operator when inattention is detected. As a result of evaluating the performance with a real-world dataset, it was shown that the proposed system successfully contributed to the recovery of operator attention in the evaluating dataset, although statistical significance could not be established due to the small number of subjects.
KW  - brain computer interaction
KW  - unmanned aerial vehicle
KW  - EEG-signal
KW  - attention recovery
KW  - alerting system
KW  - graphical user interface
DO  - 10.3390/s21072447
TY  - EJOU
AU  - Huang, Yixin
AU  - Xiang, Xiaojia
AU  - Zhou, Han
AU  - Tang, Dengqing
AU  - Sun, Yihao
TI  - Online Identification-Verification-Prediction Method for Parallel System Control of UAVs
T2  - Aerospace

PY  - 2021
VL  - 8
IS  - 4
SN  - 2226-4310

AB  - In order to solve the problem of how to efficiently control a large-scale swarm Unmanned Aerial Vehicle (UAV) system, which performs complex tasks with limited manpower in a non-ideal environment, this paper proposes a parallel UAV swarm control method. The key technology of parallel control is to establish a one-to-one artificial UAV system corresponding to the aerial swarm UAV on the ground. This paper focuses on the computational experiments algorithm for artificial UAV system establishment, including data processing, model identification, model verification and state prediction. Furthermore, this paper performs a comprehensive flight mission with four common modes (climbing, level flighting, turning and descending) for verification. The results of the identification experiment present a good consistency between the outputs of the refined dynamics model and the real flight data. The prediction experiment results show that the prediction method in this paper can basically guarantee that the prediction states error is kept within 10% about 16 s.
KW  - parallel system
KW  - Unmanned Aerial Vehicle (UAV)
KW  - system identification
KW  - state prediction
DO  - 10.3390/aerospace8040099
TY  - EJOU
AU  - Wang, Junshu
AU  - Yang, Yue
AU  - Chen, Yuan
AU  - Han, Yuxing
TI  - LighterGAN: An Illumination Enhancement Method for Urban UAV Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 7
SN  - 2072-4292

AB  - In unmanned aerial vehicle based urban observation and monitoring, the performance of computer vision algorithms is inevitably limited by the low illumination and light pollution caused degradation, therefore, the application image enhancement is a considerable prerequisite for the performance of subsequent image processing algorithms. Therefore, we proposed a deep learning and generative adversarial network based model for UAV low illumination image enhancement, named LighterGAN. The design of LighterGAN refers to the CycleGAN model with two improvements—attention mechanism and semantic consistency loss—having been proposed to the original structure. Additionally, an unpaired dataset that was captured by urban UAV aerial photography has been used to train this unsupervised learning model. Furthermore, in order to explore the advantages of the improvements, both the performance in the illumination enhancement task and the generalization ability improvement of LighterGAN were proven in the comparative experiments combining subjective and objective evaluations. In the experiments with five cutting edge image enhancement algorithms, in the test set, LighterGAN achieved the best results in both visual perception and PIQE (perception based image quality evaluator, a MATLAB build-in function, the lower the score, the higher the image quality) score of enhanced images, scores were 4.91 and 11.75 respectively, better than EnlightenGAN the state-of-the-art. In the enhancement of low illumination sub-dataset Y (containing 2000 images), LighterGAN also achieved the lowest PIQE score of 12.37, 2.85 points lower than second place. Moreover, compared with the CycleGAN, the improvement of generalization ability was also demonstrated. In the test set generated images, LighterGAN was 6.66 percent higher than CycleGAN in subjective authenticity assessment and 3.84 lower in PIQE score, meanwhile, in the whole dataset generated images, the PIQE score of LighterGAN is 11.67, 4.86 lower than CycleGAN.
KW  - UAV
KW  - unsupervised learning
KW  - LighterGAN
KW  - unpaired dataset
KW  - illumination enhancement
KW  - attention mechanism
KW  - semantic consistency loss
KW  - PIQE
KW  - generalization ability
DO  - 10.3390/rs13071371
TY  - EJOU
AU  - Han, Dongyeob
AU  - Lee, Suk B.
AU  - Song, Mihwa
AU  - Cho, Jun S.
TI  - Change Detection in Unmanned Aerial Vehicle Images for Progress Monitoring of Road Construction
T2  - Buildings

PY  - 2021
VL  - 11
IS  - 4
SN  - 2075-5309

AB  - Currently, unmanned aerial vehicles are increasingly being used in various construction projects such as housing developments, road construction, and bridge maintenance. If a drone is used at a road construction site, elevation information and orthoimages can be generated to acquire the construction status quantitatively. However, the detection of detailed changes in the site owing to construction depends on visual video interpretation. This study develops a method for automatic detection of the construction area using multitemporal images and a deep learning method. First, a deep learning model was trained using images of the changing area as reference. Second, we obtained an effective application method by applying various parameters to the deep learning process. The application of the time-series images of a construction site to the selected deep learning model enabled more effective identification of the changed areas than the existing pixel-based change detection. The proposed method is expected to be very helpful in construction management by aiding in the development of smart construction technology.
KW  - convolutional Siamese network
KW  - multitemporal
KW  - construction project
KW  - change detection
DO  - 10.3390/buildings11040150
TY  - EJOU
AU  - Dandrifosse, Sébastien
AU  - Carlier, Alexis
AU  - Dumont, Benjamin
AU  - Mercatoris, Benoît
TI  - Registration and Fusion of Close-Range Multimodal Wheat Images in Field Conditions
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 7
SN  - 2072-4292

AB  - Multimodal images fusion has the potential to enrich the information gathered by multi-sensor plant phenotyping platforms. Fusion of images from multiple sources is, however, hampered by the technical lock of image registration. The aim of this paper is to provide a solution to the registration and fusion of multimodal wheat images in field conditions and at close range. Eight registration methods were tested on nadir wheat images acquired by a pair of red, green and blue (RGB) cameras, a thermal camera and a multispectral camera array. The most accurate method, relying on a local transformation, aligned the images with an average error of 2 mm but was not reliable for thermal images. More generally, the suggested registration method and the preprocesses necessary before fusion (plant mask erosion, pixel intensity averaging) would depend on the application. As a consequence, the main output of this study was to identify four registration-fusion strategies: (i) the REAL-TIME strategy solely based on the cameras’ positions, (ii) the FAST strategy suitable for all types of images tested, (iii) and (iv) the ACCURATE and HIGHLY ACCURATE strategies handling local distortion but unable to deal with images of very different natures. These suggestions are, however, limited to the methods compared in this study. Further research should investigate how recent cutting-edge registration methods would perform on the specific case of wheat canopy.
KW  - image registration
KW  - proxy-sensing
KW  - high-throughput phenotyping
KW  - winter wheat
KW  - thermography
KW  - multispectral
DO  - 10.3390/rs13071380
TY  - EJOU
AU  - Fernandez-Beltran, Ruben
AU  - Baidar, Tina
AU  - Kang, Jian
AU  - Pla, Filiberto
TI  - Rice-Yield Prediction with Multi-Temporal Sentinel-2 Data and 3D CNN: A Case Study in Nepal
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 7
SN  - 2072-4292

AB  - Crop yield estimation is a major issue of crop monitoring which remains particularly challenging in developing countries due to the problem of timely and adequate data availability. Whereas traditional agricultural systems mainly rely on scarce ground-survey data, freely available multi-temporal and multi-spectral remote sensing images are excellent tools to support these vulnerable systems by accurately monitoring and estimating crop yields before harvest. In this context, we introduce the use of Sentinel-2 (S2) imagery, with a medium spatial, spectral and temporal resolutions, to estimate rice crop yields in Nepal as a case study. Firstly, we build a new large-scale rice crop database (RicePAL) composed by multi-temporal S2 and climate/soil data from the Terai districts of Nepal. Secondly, we propose a novel 3D Convolutional Neural Network (CNN) adapted to these intrinsic data constraints for the accurate rice crop yield estimation. Thirdly, we study the effect of considering different temporal, climate and soil data configurations in terms of the performance achieved by the proposed approach and several state-of-the-art regression and CNN-based yield estimation methods. The extensive experiments conducted in this work demonstrate the suitability of the proposed CNN-based framework for rice crop yield estimation in the developing country of Nepal using S2 data.
KW  - Sentinel-2
KW  - rice-yield estimation
KW  - regression
KW  - deep learning
KW  - Nepal
DO  - 10.3390/rs13071391
TY  - EJOU
AU  - Doukhi, Oualid
AU  - Lee, Deok-Jin
TI  - Deep Reinforcement Learning for End-to-End Local Motion Planning of Autonomous Aerial Robots in Unknown Outdoor Environments: Real-Time Flight Experiments
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 7
SN  - 1424-8220

AB  - Autonomous navigation and collision avoidance missions represent a significant challenge for robotics systems as they generally operate in dynamic environments that require a high level of autonomy and flexible decision-making capabilities. This challenge becomes more applicable in micro aerial vehicles (MAVs) due to their limited size and computational power. This paper presents a novel approach for enabling a micro aerial vehicle system equipped with a laser range finder to autonomously navigate among obstacles and achieve a user-specified goal location in a GPS-denied environment, without the need for mapping or path planning. The proposed system uses an actor–critic-based reinforcement learning technique to train the aerial robot in a Gazebo simulator to perform a point-goal navigation task by directly mapping the noisy MAV’s state and laser scan measurements to continuous motion control. The obtained policy can perform collision-free flight in the real world while being trained entirely on a 3D simulator. Intensive simulations and real-time experiments were conducted and compared with a nonlinear model predictive control technique to show the generalization capabilities to new unseen environments, and robustness against localization noise. The obtained results demonstrate our system’s effectiveness in flying safely and reaching the desired points by planning smooth forward linear velocity and heading rates.
KW  - autonomous navigation
KW  - collision-free
KW  - deep reinforcement learning
KW  - unmanned aerial vehicle
DO  - 10.3390/s21072534
TY  - EJOU
AU  - Felemban, Emad
AU  - Sheikh, Adil A.
AU  - Naseer, Atif
TI  - Improving Response Time for Crowd Management in Hajj
T2  - Computers

PY  - 2021
VL  - 10
IS  - 4
SN  - 2073-431X

AB  - Flying Adhoc Network (FANET) is a particular type of Mobile Adhoc Network (MANET) that consists of flying drones or unmanned aerial vehicles (UAVs). MANETs are especially useful in rural and remote areas, where the lack of public networks necessitates data delivery through mobile nodes. Additionally, FANETs provide better coverage where there is a lack of roads. Generally, the goal of FANETs is to provide multimedia data to applications such as search and rescue operations, forest fire detection, surveillance and patrol, environmental monitoring, and traffic and urban monitoring. The above applications’ performance and efficiency depend on the quality and timely delivery of these essential data from an area of interest to control centers. This paper presents a Priority-based Routing Framework for Flying Adhoc Networks (PRoFFAN) for the expedited delivery of essential multimedia data to control centers. PRoFFAN reduces the FANET application’s response time by prioritizing the sending and forwarding of critical image data from the UAV to the control center. Our motivation application is crowd management; we believe that having important image features as early as possible will save lives and enhance the crowd’s safety and flow. We integrated PRoFFAN over the RPL routing layer of Contiki-NG’s IPv6 network stack. We used simulations in Cooja to demonstrate the benefit of PRoFFAN over conventional ZigBee.
KW  - FANET
KW  - Priority Routing
KW  - image transmission
KW  - simulations
KW  - drones
DO  - 10.3390/computers10040046
TY  - EJOU
AU  - Speranza, Nicholas A.
AU  - Rave, Christopher J.
AU  - Pei, Yong
TI  - Energy-Efficient On-Platform Target Classification for Electric Air Transportation Systems
T2  - Electricity

PY  - 2021
VL  - 2
IS  - 2
SN  - 2673-4826

AB  - Due to the predicted rise of Unmanned Aircraft Systems (UAS) in commercial, civil, and military operations, there is a desire to make UASs more energy efficient so they can proliferate with ease of deployment and maximal life per charge. To address current limitations, a three-tiered approach is investigated to mitigate Unmanned Aerial Vehicle (UAV) hover time, reduce network datalink transmission to a ground station, and provide a real-time framework for Sense-and-Avoidance (SAA) target classification. An energy-efficient UAS architecture framework is presented, and a corresponding SAA prototype is developed using commercial hardware to validate the proposed architecture using an experimental methodology. The proposed architecture utilizes classical computer vision methods within the Detection Subsystem coupled with deeply learned Convolutional Neural Networks (CNN) within the Classification Subsystem. Real-time operations of three frames per second are realized enabling UAV hover time and associated energy consumption during SAA processing to be effectively eliminated. Additional energy improvements are not addressed in the scope of this work. Inference accuracy is improved by 19% over baseline COTS models and current non-adaptive, single-stage SAA architectures. Overall, by pushing SAA processing to the edge of the sensors, network offload transmissions and reductions in processing time and energy consumption are feasible and realistic in future battery-powered electric air transportation systems.
KW  - edge-centric
KW  - edge computing
KW  - electric transportation
KW  - energy efficiency
KW  - Sense-and-Avoidance (SAA)
KW  - Unmanned Aerial Vehicle (UAV)
DO  - 10.3390/electricity2020007
TY  - EJOU
AU  - Martínez, Anselmo
AU  - Belmonte, Lidia M.
AU  - García, Arturo S.
AU  - Fernández-Caballero, Antonio
AU  - Morales, Rafael
TI  - Facial Emotion Recognition from an Unmanned Flying Social Robot for Home Care of Dependent People
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 7
SN  - 2079-9292

AB  - This work is part of an ongoing research project to develop an unmanned flying social robot to monitor dependants at home in order to detect the person’s state and bring the necessary assistance. In this sense, this paper focuses on the description of a virtual reality (VR) simulation platform for the monitoring process of an avatar in a virtual home by a rotatory-wing autonomous unmanned aerial vehicle (UAV). This platform is based on a distributed architecture composed of three modules communicated through the message queue telemetry transport (MQTT) protocol: the UAV Simulator implemented in MATLAB/Simulink, the VR Visualiser developed in Unity, and the new emotion recognition (ER) system developed in Python. Using a face detection algorithm and a convolutional neural network (CNN), the ER System is able to detect the person’s face in the image captured by the UAV’s on-board camera and classify the emotion among seven possible ones (surprise; fear; happiness; sadness; disgust; anger; or neutral expression). The experimental results demonstrate the correct integration of this new computer vision module within the VR platform, as well as the good performance of the designed CNN, with around 85% in the F1-score, a mean of the precision and recall of the model. The developed emotion detection system can be used in the future implementation of the assistance UAV that monitors dependent people in a real environment, since the methodology used is valid for images of real people.
KW  - flying social robot
KW  - autonomous unmanned aerial vehicle (UAV)
KW  - emotion recognition
KW  - convolution neural network (CNN)
KW  - virtual reality (VR)
KW  - unity
KW  - MATLAB/Simulink
KW  - python
DO  - 10.3390/electronics10070868
TY  - EJOU
AU  - Bao, Min
AU  - Chala Urgessa, Guyo
AU  - Xing, Mengdao
AU  - Han, Liang
AU  - Chen, Rui
TI  - Toward More Robust and Real-Time Unmanned Aerial Vehicle Detection and Tracking via Cross-Scale Feature Aggregation Based on the Center Keypoint
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - Unmanned aerial vehicles (UAVs) play an essential role in various applications, such as transportation and intelligent environmental sensing. However, due to camera motion and complex environments, it can be difficult to recognize the UAV from its surroundings thus, traditional methods often miss detection of UAVs and generate false alarms. To address these issues, we propose a novel method for detecting and tracking UAVs. First, a cross-scale feature aggregation CenterNet (CFACN) is constructed to recognize the UAVs. CFACN is a free anchor-based center point estimation method that can effectively decrease the false alarm rate, the misdetection of small targets, and computational complexity. Secondly, the region of interest-scale-crop-resize (RSCR) method is utilized to merge CFACN and region-of-interest (ROI) CFACN (ROI-CFACN) further, in order to improve the accuracy at a lower computational cost. Finally, the Kalman filter is adopted to track the UAV. The effectiveness of our method is validated using a collected UAV dataset. The experimental results demonstrate that our methods can achieve higher accuracy with lower computational cost, being superior to BiFPN, CenterNet, YoLo, and their variants on the same dataset.
KW  - cross-scale feature aggregation
KW  - center point estimation
KW  - region of interest
KW  - unmanned aerial vehicle
DO  - 10.3390/rs13081416
TY  - EJOU
AU  - Tang, Mingliang
AU  - Esmaeili, Kamran
TI  - Heap Leach Pad Surface Moisture Monitoring Using Drone-Based Aerial Images and Convolutional Neural Networks: A Case Study at the El Gallo Mine, Mexico
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - An efficient metal recovery in heap leach operations relies on uniform distribution of leaching reagent solution over the heap leach pad surface. However, the current practices for heap leach pad (HLP) surface moisture monitoring often rely on manual inspection, which is labor-intensive, time-consuming, discontinuous, and intermittent. In order to complement the manual monitoring process and reduce the frequency of exposing technical manpower to the hazardous leaching reagent (e.g., dilute cyanide solution in gold leaching), this manuscript describes a case study of implementing an HLP surface moisture monitoring method based on drone-based aerial images and convolutional neural networks (CNNs). Field data collection was conducted on a gold HLP at the El Gallo mine, Mexico. A commercially available hexa-copter drone was equipped with one visible-light (RGB) camera and one thermal infrared sensor to acquire RGB and thermal images from the HLP surface. The collected data had high spatial and temporal resolutions. The high-quality aerial images were used to generate surface moisture maps of the HLP based on two CNN approaches. The generated maps provide direct visualization of the different moisture zones across the HLP surface, and such information can be used to detect potential operational issues related to distribution of reagent solution and to facilitate timely decision making in heap leach operations.
KW  - heap leach pad monitoring
KW  - convolutional neural network
KW  - surface moisture mapping
KW  - unmanned aerial vehicle
KW  - drone
KW  - gold leaching
KW  - mining
DO  - 10.3390/rs13081420
TY  - EJOU
AU  - Marang, Ian J.
AU  - Filippi, Patrick
AU  - Weaver, Tim B.
AU  - Evans, Bradley J.
AU  - Whelan, Brett M.
AU  - Bishop, Thomas F. A.
AU  - Murad, Mohammed O. F.
AU  - Al-Shammari, Dhahi
AU  - Roth, Guy
TI  - Machine Learning Optimised Hyperspectral Remote Sensing Retrieves Cotton Nitrogen Status
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - Hyperspectral imaging spectrometers mounted on unmanned aerial vehicle (UAV) can capture high spatial and spectral resolution to provide cotton crop nitrogen status for precision agriculture. The aim of this research was to explore machine learning use with hyperspectral datacubes over agricultural fields. Hyperspectral imagery was collected over a mature cotton crop, which had high spatial (~5.2 cm) and spectral (5 nm) resolution over the spectral range 475–925 nm that allowed discrimination of individual crop rows and field features as well as a continuous spectral range for calculating derivative spectra. The nominal reflectance and its derivatives clearly highlighted the different treatment blocks and were strongly related to N concentration in leaf and petiole samples, both in traditional vegetation indices (e.g., Vogelman 1, R2 = 0.8) and novel combinations of spectra (R2 = 0.85). The key hyperspectral bands identified were at the red-edge inflection point (695–715 nm). Satellite multispectral was compared against the UAV hyperspectral remote sensing’s performance by testing the ability of Sentinel MSI to predict N concentration using the bands in VIS-NIR spectral region. The Sentinel 2A Green band (B3; mid-point 559.8 nm) explained the same amount of variation in N as the hyperspectral data and more than the Sentinel Red Edge Point 1 (B5; mid-point 704.9 nm) with the lower 10 m resolution Green band reporting an R2 = 0.85, compared with the R2 = 0.78 of downscaled Sentinel Red Edge Point 1 at 5 m. The remaining Sentinel bands explained much lower variation (maximum was NIR at R2 = 0.48). Investigation of the red edge peak region in the first derivative showed strong promise with RIDAmid (R2 = 0.81) being the best index. The machine learning approach narrowed the range of bands required to investigate plant condition over this trial site, greatly improved processing time and reduced processing complexity. While Sentinel performed well in this comparison and would be useful in a broadacre crop production context, the impact of pixel boundaries relative to a region of interest and coarse spatial and temporal resolution impacts its utility in a research capacity.
KW  - remote sensing
KW  - hyperspectral
KW  - multispectral
KW  - machine learning
KW  - nitrogen
KW  - cotton
DO  - 10.3390/rs13081428
TY  - EJOU
AU  - Zhang, Xixin
AU  - Yang, Yuhang
AU  - Li, Zhiyong
AU  - Ning, Xin
AU  - Qin, Yilang
AU  - Cai, Weiwei
TI  - An Improved Encoder-Decoder Network Based on Strip Pool Method Applied to Segmentation of Farmland Vacancy Field
T2  - Entropy

PY  - 2021
VL  - 23
IS  - 4
SN  - 1099-4300

AB  - In the research of green vegetation coverage in the field of remote sensing image segmentation, crop planting area is often obtained by semantic segmentation of images taken from high altitude. This method can be used to obtain the rate of cultivated land in a region (such as a country), but it does not reflect the real situation of a particular farmland. Therefore, this paper takes low-altitude images of farmland to build a dataset. After comparing several mainstream semantic segmentation algorithms, a new method that is more suitable for farmland vacancy segmentation is proposed. Additionally, the Strip Pooling module (SPM) and the Mixed Pooling module (MPM), with strip pooling as their core, are designed and fused into the semantic segmentation network structure to better extract the vacancy features. Considering the high cost of manual data annotation, this paper uses an improved ResNet network as the backbone of signal transmission, and meanwhile uses data augmentation to improve the performance and robustness of the model. As a result, the accuracy of the proposed method in the test set is 95.6%, mIoU is 77.6%, and the error rate is 7%. Compared to the existing model, the mIoU value is improved by nearly 4%, reaching the level of practical application.
KW  - semantic segmentation
KW  - farmland vacancy segmentation
KW  - strip pooling
KW  - crop growth assessment
KW  - encoder–decoder
DO  - 10.3390/e23040435
TY  - EJOU
AU  - Kang, Myung S.
AU  - An, Yun-Kyu
TI  - Deep Learning-Based Automated Background Removal for Structural Exterior Image Stitching
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 8
SN  - 2076-3417

AB  - This paper presents a deep learning-based automated background removal technique for structural exterior image stitching. In order to establish an exterior damage map of a structure using an unmanned aerial vehicle (UAV), a close-up vision scanning is typically required. However, unwanted background objects are often captured within the scanned digital images. Since the unnecessary background objects often cause serious distortion on the image stitching process, they should be removed. In this paper, the automated background removal technique using deep learning-based depth estimation is proposed. Based on the fact that the region of interest has closer working distance than the background ones from the camera, the background region within the digital images can be automatically removed using a deep learning-based depth estimation network. In addition, an optimal digital image selection based on feature matching-based overlap ratio is proposed. The proposed technique is experimentally validated using UAV-scanned digital images acquired from an in-situ high-rise building structure. The validation test results show that the optimal digital images obtained from the proposed technique produce the precise structural exterior map with computational cost reduction of 85.7%, while raw scanned digital images fail to construct the structural exterior map and cause serious stitching distortion.
KW  - digital image stitching
KW  - automated background removal
KW  - region of interest extraction
KW  - deep learning-based depth estimation
KW  - structure exterior map
DO  - 10.3390/app11083339
TY  - EJOU
AU  - Choi, Daegyun
AU  - Bell, William
AU  - Kim, Donghoon
AU  - Kim, Jichul
TI  - UAV-Driven Structural Crack Detection and Location Determination Using Convolutional Neural Networks
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 8
SN  - 1424-8220

AB  - Structural cracks are a vital feature in evaluating the health of aging structures. Inspectors regularly monitor structures’ health using visual information because early detection of cracks on highly trafficked structures is critical for maintaining the public’s safety. In this work, a framework for detecting cracks along with their locations is proposed. Image data provided by an unmanned aerial vehicle (UAV) is stitched using image processing techniques to overcome limitations in the resolution of cameras. This stitched image is analyzed to identify cracks using a deep learning model that makes judgements regarding the presence of cracks in the image. Moreover, cracks’ locations are determined using data from UAV sensors. To validate the system, cracks forming on an actual building are captured by a UAV, and these images are analyzed to detect and locate cracks. The proposed framework is proven as an effective way to detect cracks and to represent the cracks’ locations.
KW  - crack detection
KW  - deep learning
KW  - convolutional neural network
KW  - image processing
KW  - unmanned aerial vehicle
DO  - 10.3390/s21082650
TY  - EJOU
AU  - Yang, Yukun
AU  - Ma, Bo
AU  - Liu, Xiangdong
AU  - Zhao, Liang
AU  - Huang, Shoudong
TI  - GSAP: A Global Structure Attention Pooling Method for Graph-Based Visual Place Recognition
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - The Visual Place Recognition problem aims to use an image to recognize the location that has been visited before. In most of the scenes revisited, the appearance and view are drastically different. Most previous works focus on the 2-D image-based deep learning method. However, the convolutional features are not robust enough to the challenging scenes mentioned above. In this paper, in order to take advantage of the information that helps the Visual Place Recognition task in these challenging scenes, we propose a new graph construction approach to extract the useful information from an RGB image and a depth image and fuse them in graph data. Then, we deal with the Visual Place Recognition problem as a graph classification problem. We propose a new Global Pooling method—Global Structure Attention Pooling (GSAP), which improves the classification accuracy by improving the expression ability of the Global Pooling component. The experiments show that our GSAP method improves the accuracy of graph classification by approximately 2–5%, the graph construction method improves the accuracy of graph classification by approximately 4–6%, and that the whole Visual Place Recognition model is robust to appearance change and view change.
KW  - graph construction
KW  - graph neural networks
KW  - graph convolution
KW  - graph global pooling
KW  - visual place recognition
DO  - 10.3390/rs13081467
TY  - EJOU
AU  - Chmielewski, Piotr
AU  - Sibilski, Krzysztof
TI  - Ground Speed Optical Estimator for Miniature UAV
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 8
SN  - 1424-8220

AB  - In a conventional Unmanned aerial vehicles (UAV) navigational system Global Navigation Satellite System (GNSS) sensor is often a main source of data for trajectory generation. Even video tracking based systems need some GNSS data for proper work. The goal of this study is to develop an optics-based system to estimate the ground speed of the UAV in the case of the GNSS failure, jamming, or unavailability. The proposed approach uses a camera mounted on the fuselage belly of the UAV. We can obtain the ground speed of the airplane by using the digital cropping, the stabilization of the real time image, and template matching algorithms. By combining the ground speed vector components with measurements of airspeed and altitude, the wind velocity and drift are computed. The obtained data were used to improve efficiency of the video-tracking based on a navigational system. An algorithm allows this computation to be performed in real time on board of a UAV. The algorithm was tested in Software-in-the-loop and implemented on the UAV hardware. Its effectiveness has been demonstrated through the experimental test results. The presented work could be useful for upgrading the existing MUAV products (with embedded cameras) already delivered to the customers only by updating their software. It is especially significant in the case when any necessary hardware upgrades would be economically unjustified or even impossible to be carried out.
KW  - drift estimation
KW  - template matching
KW  - optical sensor
KW  - UAV
KW  - MUAV
DO  - 10.3390/s21082754
TY  - EJOU
AU  - Bang, Hyuntae
AU  - Min, Jiyoung
AU  - Jeon, Haemin
TI  - Deep Learning-Based Concrete Surface Damage Monitoring Method Using Structured Lights and Depth Camera
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 8
SN  - 1424-8220

AB  - Due to the increase in aging structures and the decrease in construction workforce, there is an increasing interest in automating structural damage monitoring. Surface damage on concrete structures, such as cracks, delamination, and rebar exposure, is one of the important parameters that can be used to estimate the condition of the structure. In this paper, deep learning-based detection and quantification of structural damage using structured lights and a depth camera is proposed. The proposed monitoring system is composed of four lasers and a depth camera. The lasers are projected on the surface of the structures, and the camera captures images of the structures while measuring distance. By calculating an image homography, the captured images are calibrated when the structure and sensing system are not in parallel. The Faster RCNN (Region-based Convolutional Neural Network) with Inception Resnet v2 architecture is used to detect three types of surface damage: (i) cracks; (ii) delamination; and (iii) rebar exposure. The detected damage is quantified by calculating the positions of the projected laser beams with the measured distance. The experimental results show that structural damage was detected with an F1 score of 0.83 and a median value of the quantified relative error of less than 5%.
KW  - damage detection
KW  - quantification
KW  - deep learning
KW  - structured light
KW  - depth camera
DO  - 10.3390/s21082759
TY  - EJOU
AU  - Kang, Yeseong
AU  - Nam, Jinwoo
AU  - Kim, Younggwang
AU  - Lee, Seongtae
AU  - Seong, Deokgyeong
AU  - Jang, Sihyeong
AU  - Ryu, Chanseok
TI  - Assessment of Regression Models for Predicting Rice Yield and Protein Content Using Unmanned Aerial Vehicle-Based Multispectral Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - Unmanned aerial vehicle-based multispectral imagery including five spectral bands (blue, green, red, red-edge, and near-infrared) for a rice field in the ripening stage was used to develop regression models for predicting the rice yield and protein content and to select the most suitable regression analysis method for the year-invariant model: partial least squares regression, ridge regression, and artificial neural network (ANN). The regression models developed with six vegetation indices (green normalization difference vegetation index (GNDVI), normalization difference red-edge index (NDRE), chlorophyll index red edge (CIrededge), difference NIR/Green green difference vegetation index (GDVI), green-red NDVI (GRNDVI), and medium resolution imaging spectrometer terrestrial chlorophyll index (MTCI)), calculated from the spectral bands, were applied to single years (2018, 2019, and 2020) and multiple years (2018 + 2019, 2018 + 2020, 2019 + 2020, and all years). The regression models were cross-validated through mutual prediction against the vegetation indices in nonoverlapping years, and the prediction errors were evaluated via root mean squared error of prediction (RMSEP). The ANN model was reproducible, with low and sustained prediction errors of 24.2 kg/1000 m2 ≤ RMSEP ≤ 59.1 kg/1000 m2 in rice yield and 0.14% ≤ RMSEP ≤ 0.28% in rice-protein content in all single-year and multiple-year analyses. When the importance of each vegetation index of the regression models was evaluated, only the ANN model showed the same ranking in the vegetation index of the first (MTCI in both rice yield and protein content) and second importance (CIrededge in rice yield and GRNDVI in rice-protein content). Overall, this means that the ANN model has the highest potential for developing a year-invariant model with stable RMSEP and consistent variable ranking.
KW  - multispectral imagery
KW  - mutual prediction
KW  - regression model
KW  - rice-protein content
KW  - rice yield
DO  - 10.3390/rs13081508
TY  - EJOU
AU  - Xiong, Quan
AU  - Di, Liping
AU  - Feng, Quanlong
AU  - Liu, Diyou
AU  - Liu, Wei
AU  - Zan, Xuli
AU  - Zhang, Lin
AU  - Zhu, Dehai
AU  - Liu, Zhe
AU  - Yao, Xiaochuang
AU  - Zhang, Xiaodong
TI  - Deriving Non-Cloud Contaminated Sentinel-2 Images with RGB and Near-Infrared Bands from Sentinel-1 Images Based on a Conditional Generative Adversarial Network
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - Sentinel-2 images have been widely used in studying land surface phenomena and processes, but they inevitably suffer from cloud contamination. To solve this critical optical data availability issue, it is ideal to fuse Sentinel-1 and Sentinel-2 images to create fused, cloud-free Sentinel-2-like images for facilitating land surface applications. In this paper, we propose a new data fusion model, the Multi-channels Conditional Generative Adversarial Network (MCcGAN), based on the conditional generative adversarial network, which is able to convert images from Domain A to Domain B. With the model, we were able to generate fused, cloud-free Sentinel-2-like images for a target date by using a pair of reference Sentinel-1/Sentinel-2 images and target-date Sentinel-1 images as inputs. In order to demonstrate the superiority of our method, we also compared it with other state-of-the-art methods using the same data. To make the evaluation more objective and reliable, we calculated the root-mean-square-error (RSME), R2, Kling–Gupta efficiency (KGE), structural similarity index (SSIM), spectral angle mapper (SAM), and peak signal-to-noise ratio (PSNR) of the simulated Sentinel-2 images generated by different methods. The results show that the simulated Sentinel-2 images generated by the MCcGAN have a higher quality and accuracy than those produced via the previous methods.
KW  - Sentinel-1
KW  - Sentinel-2
KW  - generative adversarial network
KW  - non-cloud contamination
KW  - data fusion
DO  - 10.3390/rs13081512
TY  - EJOU
AU  - Liu, Li-Wei
AU  - Hsieh, Sheng-Hsin
AU  - Lin, Su-Ju
AU  - Wang, Yu-Min
AU  - Lin, Wen-Shin
TI  - Rice Blast (Magnaporthe oryzae) Occurrence Prediction and the Key Factor Sensitivity Analysis by Machine Learning
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 4
SN  - 2073-4395

AB  - This study aimed to establish a machine learning (ML)-based rice blast predicting model to decrease the appreciable losses based on short-term environment data. The average, highest and lowest air temperature, average relative humidity, soil temperature and solar energy were selected for model development. The developed multilayer perceptron (MLP), support vector machine (SVM), Elman recurrent neural network (Elman RNN) and probabilistic neural network (PNN) were evaluated by F-measures. Finally, a sensitivity analysis (SA) was conducted for the factor importance assessment. The study result shows that the PNN performed best with the F-measure (β = 2) of 96.8%. The SA was conducted in the PNN model resulting in the main effect period is 10 days before the rice blast happened. The key factors found are minimum air temperature, followed by solar energy and equaled sensitivity of average relative humidity, maximum air temperature and soil temperature. The temperature phase lag in air and soil may cause a lower dew point and suitable for rice blast pathogens growth. Through this study’s results, rice blast warnings can be issued 10 days in advance, increasing the response time for farmers preparing related preventive measures, further reducing the losses caused by rice blast.
KW  - rice disease
KW  - precision agriculture
KW  - artificial neural networks (ANN)
KW  - soil temperature
KW  - confusion matrix
KW  - F-measure
DO  - 10.3390/agronomy11040771
TY  - EJOU
AU  - Hou, Xiaoyu
AU  - Zhang, Kunlin
AU  - Xu, Jihui
AU  - Huang, Wei
AU  - Yu, Xinmiao
AU  - Xu, Huaiyu
TI  - Object Detection in Drone Imagery via Sample Balance Strategies and Local Feature Enhancement
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 8
SN  - 2076-3417

AB  - With the advent of drones, new potential applications have emerged for the unconstrained analysis of images and videos from aerial view cameras. Despite the tremendous success of the generic object detection methods developed using ground-based photos, a considerable performance drop is observed when these same methods are directly applied to images captured by Unmanned Aerial Vehicles (UAVs). Usually, most of the work goes into improving the performance of the detector in aspects such as design loss, training sample selection, feature enhancement, and so forth. This paper proposes a detection framework based on an anchor-free detector with several modules, including a sample balance strategies module and super-resolved generated feature module, to improve performance. We proposed the sample balance strategies module to optimize the imbalance among training samples, especially the imbalance between positive and negative, and easy and hard samples. Due to the high frequencies and noisy representation of the small objects in images captured by drones, the detection task is extraordinarily challenging. However, when compared with other algorithms of this kind, our method achieves better results. We also propose a super-resolved generated GAN (Generative Adversarial Network) module with center-ness weights to effectively enhance the local feature map. Finally, we demonstrate our method’s effectiveness with the proposed modules by carrying out a state-of-the-art performance on Visdrone2020 benchmarks.
KW  - object detection
KW  - drones
KW  - deep learning
KW  - sample imbalance
KW  - super-resolve GAN
DO  - 10.3390/app11083547
TY  - EJOU
AU  - Jiang, Yufeng
AU  - Zhang, Li
AU  - Yan, Min
AU  - Qi, Jianguo
AU  - Fu, Tianmeng
AU  - Fan, Shunxiang
AU  - Chen, Bowei
TI  - High-Resolution Mangrove Forests Classification with Machine Learning Using Worldview and UAV Hyperspectral Data
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - Mangrove forests, as important ecological and economic resources, have suffered a loss in the area due to natural and human activities. Monitoring the distribution of and obtaining accurate information on mangrove species is necessary for ameliorating the damage and protecting and restoring mangrove forests. In this study, we compared the performance of UAV Rikola hyperspectral images, WorldView-2 (WV-2) satellite-based multispectral images, and a fusion of data from both in the classification of mangrove species. We first used recursive feature elimination‒random forest (RFE-RF) to select the vegetation’s spectral and texture feature variables, and then implemented random forest (RF) and support vector machine (SVM) algorithms as classifiers. The results showed that the accuracy of the combined data was higher than that of UAV and WV-2 data; the vegetation index features of UAV hyperspectral data and texture index of WV-2 data played dominant roles; the overall accuracy of the RF algorithm was 95.89% with a Kappa coefficient of 0.95, which is more accurate and efficient than SVM. The use of combined data and RF methods for the classification of mangrove species could be useful in biomass estimation and breeding cultivation.
KW  - mangrove species classification
KW  - hyperspectral
KW  - WorldView-2
KW  - feature selection
KW  - machine learning
DO  - 10.3390/rs13081529
TY  - EJOU
AU  - Chao, Luomeng
AU  - Wu, Celimuge
AU  - Yoshinaga, Tsutomu
AU  - Bao, Wugedele
AU  - Ji, Yusheng
TI  - A Brief Review of Multipath TCP for Vehicular Networks
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 8
SN  - 1424-8220

AB  - Multipath TCP (MPTCP) is one of the most important extensions to TCP that enables the use of multiple paths in data transmissions for a TCP connection. In MPTCP, the end hosts transmit data across a number of TCP subflows simultaneously on one connection. MPTCP can sufficiently utilize the bandwidth resources to improve the transmission efficiency while providing TCP fairness to other TCP connections. Meanwhile, it also offers resilience due to multipath data transfers. MPTCP attracts tremendous attention from the academic and industry field due to the explosive data growth in recent times and limited network bandwidth for each single available communication interface. The vehicular Internet-of-Things systems, such as cooperative autonomous driving, require reliable high speed data transmission and robustness. MPTCP could be a promising approach to solve these challenges. In this paper, we first conduct a brief survey of existing MPTCP studies and give a brief overview to multipath routing. Then we discuss the significance technical challenges in applying MPTCP for vehicular networks and point out future research directions.
KW  - MPTCP
KW  - multipath routing
KW  - vehicular networks
DO  - 10.3390/s21082793
TY  - EJOU
AU  - Song, Yongze
AU  - Wu, Peng
TI  - Earth Observation for Sustainable Infrastructure: A Review
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - Infrastructure is a fundamental sector for sustainable development and Earth observation has great potentials for sustainable infrastructure development (SID). However, implementations of the timely, large–scale and multi–source Earth observation are still limited in satisfying the huge global requirements of SID. This study presents a systematical literature review to identify trends of Earth observation for sustainable infrastructure (EOSI), investigate the relationship between EOSI and Sustainable Development Goals (SDGs), and explore challenges and future directions of EOSI. Results reveal the close associations of infrastructure, urban development, ecosystems, climate, Earth observation and GIS in EOSI, and indicate their relationships. In addition, from the perspective of EOSI–SDGs relationship, the huge potentials of EOSI are demonstrated from the 70% of the infrastructure influenced targets that can be directly or indirectly derived from Earth observation data, but have not been included in current SDG indicators. Finally, typical EOSI cases are presented to indicate challenges and future research directions. This review emphasizes the contributions and potentials of Earth observation to SID and EOSI is a powerful pathway to deliver on SDGs.
KW  - sustainable infrastructure
KW  - earth observation
KW  - remote sensing
KW  - earth big data
KW  - Sustainable Development Goals (SDGs)
KW  - SDG targets
KW  - bibliographic analysis
DO  - 10.3390/rs13081528
TY  - EJOU
AU  - Xu, Gaofei
AU  - Guo, Wei
AU  - Zhao, Yang
AU  - Zhou, Yue
AU  - Zhang, Yinlong
AU  - Liu, Xinyu
AU  - Xu, Gaopeng
AU  - Li, Guangwei
TI  - Online Learning Based Underwater Robotic Thruster Fault Detection
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 8
SN  - 2076-3417

AB  - This paper presents a novel online learning-based fault detection designed for underwater robotic thruster health monitoring. In the fault detection algorithm, we build a mathematical model between the control variable and the propeller speed by fitting collected online work status data to the model. To improve the accuracy of online modeling, a multi-center PSO algorithm with memory ability is utilized to optimize the modeling parameters. Additionally, a model online update mechanism is designed to accommodate the model to the change of thruster work status and sea environment. During the operation, propeller speed of the underwater robot is predicted through the online learning-based model, and the model residuals are used for thruster health monitoring. To avoid false alarm, an adaptive fault detection strategy is established based on model online update mechanism. The proposed method has been extensively evaluated using different underwater robotics, through a sea trial data simulation, a pool test fault detection experiment and a sea trial fault detection experiment. Compared with fixed model-based method, speed prediction MAE of the online learning model is at least 37.9% lower than that of the fixed model. The online learning-based method show no misdiagnosis in experiments, while the fixed model-based method is misdiagnosed. Experimental results show that the proposed method is competitive in terms of accuracy, adaptability, and robustness.
KW  - underwater robotic
KW  - thruster system
KW  - time delay estimation
KW  - particle swarm optimization
KW  - online learning
KW  - adaptive fault detection
DO  - 10.3390/app11083586
TY  - EJOU
AU  - He, Yixin
AU  - Zhai, Daosen
AU  - Huang, Fanghui
AU  - Wang, Dawei
AU  - Tang, Xiao
AU  - Zhang, Ruonan
TI  - Joint Task Offloading, Resource Allocation, and Security Assurance for Mobile Edge Computing-Enabled UAV-Assisted VANETs
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - In this paper, we propose a mobile edge computing (MEC)-enabled unmanned aerial vehicle (UAV)-assisted vehicular ad hoc network (VANET) architecture, based on which a number of vehicles are served by UAVs equipped with computation resource. Each vehicle has to offload its computing tasks to the proper MEC server on the UAV due to the limited computation ability. To counter the problems above, we first model and analyze the transmission model and the security assurance model from the vehicle to the MEC server on UAV, and the task computation model of the local vehicle and the edge UAV. Then, the vehicle offloading problem is formulated as a multi-objective optimization problem by jointly considering the task offloading, the resource allocation, and the security assurance. For tackling this hard problem, we decouple the multi-objective optimization problem as two subproblems and propose an efficient iterative algorithm to jointly make the MEC selection decision based on the criteria of load balancing and optimize the offloading ratio and the computation resource according to the Lagrangian dual decomposition. Finally, the simulation results demonstrate that our proposed scheme achieves significant performance superiority compared with other schemes in terms of the successful task processing ratio and the task processing delay.
KW  - mobile edge computing (MEC)
KW  - unmanned aerial vehicle (UAV)
KW  - resource allocation
KW  - task offloading
KW  - vehicular ad hoc networks (VANETs)
DO  - 10.3390/rs13081547
TY  - EJOU
AU  - Coluccia, Angelo
AU  - Fascista, Alessio
AU  - Schumann, Arne
AU  - Sommer, Lars
AU  - Dimou, Anastasios
AU  - Zarpalas, Dimitrios
AU  - Méndez, Miguel
AU  - de la Iglesia, David
AU  - González, Iago
AU  - Mercier, Jean-Philippe
AU  - Gagné, Guillaume
AU  - Mitra, Arka
AU  - Rajashekar, Shobha
TI  - Drone vs. Bird Detection: Deep Learning Algorithms and Results from a Grand Challenge
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 8
SN  - 1424-8220

AB  - Adopting effective techniques to automatically detect and identify small drones is a very compelling need for a number of different stakeholders in both the public and private sectors. This work presents three different original approaches that competed in a grand challenge on the “Drone vs. Bird” detection problem. The goal is to detect one or more drones appearing at some time point in video sequences where birds and other distractor objects may be also present, together with motion in background or foreground. Algorithms should raise an alarm and provide a position estimate only when a drone is present, while not issuing alarms on birds, nor being confused by the rest of the scene. In particular, three original approaches based on different deep learning strategies are proposed and compared on a real-world dataset provided by a consortium of universities and research centers, under the 2020 edition of the Drone vs. Bird Detection Challenge. Results show that there is a range in difficulty among different test sequences, depending on the size and the shape visibility of the drone in the sequence, while sequences recorded by a moving camera and very distant drones are the most challenging ones. The performance comparison reveals that the different approaches perform somewhat complementary, in terms of correct detection rate, false alarm rate, and average precision.
KW  - drone detection
KW  - deep learning
KW  - drone vs. bird
KW  - automatic recognition
KW  - image and video signal processing
DO  - 10.3390/s21082824
TY  - EJOU
AU  - Li, Joan Y. Q.
AU  - Duce, Stephanie
AU  - Joyce, Karen E.
AU  - Xiang, Wei
TI  - SeeCucumbers: Using Deep Learning and Drone Imagery to Detect Sea Cucumbers on Coral Reef Flats
T2  - Drones

PY  - 2021
VL  - 5
IS  - 2
SN  - 2504-446X

AB  - Sea cucumbers (Holothuroidea or holothurians) are a valuable fishery and are also crucial nutrient recyclers, bioturbation agents, and hosts for many biotic associates. Their ecological impacts could be substantial given their high abundance in some reef locations and thus monitoring their populations and spatial distribution is of research interest. Traditional in situ surveys are laborious and only cover small areas but drones offer an opportunity to scale observations more broadly, especially if the holothurians can be automatically detected in drone imagery using deep learning algorithms. We adapted the object detection algorithm YOLOv3 to detect holothurians from drone imagery at Hideaway Bay, Queensland, Australia. We successfully detected 11,462 of 12,956 individuals over 2.7ha with an average density of 0.5 individual/m2. We tested a range of hyperparameters to determine the optimal detector performance and achieved 0.855 mAP, 0.82 precision, 0.83 recall, and 0.82 F1 score. We found as few as ten labelled drone images was sufficient to train an acceptable detection model (0.799 mAP). Our results illustrate the potential of using small, affordable drones with direct implementation of open-source object detection models to survey holothurians and other shallow water sessile species.
KW  - holothurian
KW  - remote sensing
KW  - UAV
KW  - machine learning
KW  - object detection
KW  - YOLOv3
KW  - Great Barrier Reef
KW  - marine ecology
KW  - ecological monitoring
KW  - FAIR data
DO  - 10.3390/drones5020028
TY  - EJOU
AU  - Kazaz, Billur
AU  - Poddar, Subhadipto
AU  - Arabi, Saeed
AU  - Perez, Michael A.
AU  - Sharma, Anuj
AU  - Whitman, J. B.
TI  - Deep Learning-Based Object Detection for Unmanned Aerial Systems (UASs)-Based Inspections of Construction Stormwater Practices
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 8
SN  - 1424-8220

AB  - Construction activities typically create large amounts of ground disturbance, which can lead to increased rates of soil erosion. Construction stormwater practices are used on active jobsites to protect downstream waterbodies from offsite sediment transport. Federal and state regulations require routine pollution prevention inspections to ensure that temporary stormwater practices are in place and performing as intended. This study addresses the existing challenges and limitations in the construction stormwater inspections and presents a unique approach for performing unmanned aerial system (UAS)-based inspections. Deep learning-based object detection principles were applied to identify and locate practices installed on active construction sites. The system integrates a post-processing stage by clustering results. The developed framework consists of data preparation with aerial inspections, model training, validation of the model, and testing for accuracy. The developed model was created from 800 aerial images and was used to detect four different types of construction stormwater practices at 100% accuracy on the Mean Average Precision (MAP) with minimal false positive detections. Results indicate that object detection could be implemented on UAS-acquired imagery as a novel approach to construction stormwater inspections and provide accurate results for site plan comparisons by rapidly detecting the quantity and location of field-installed stormwater practices.
KW  - construction stormwater management
KW  - inspections
KW  - unmanned aerial systems
KW  - photogrammetry
KW  - deep learning-based object detection
DO  - 10.3390/s21082834
TY  - EJOU
AU  - Poudel, Sabitri
AU  - Moh, Sangman
TI  - Hybrid Path Planning for Efficient Data Collection in UAV-Aided WSNs for Emergency Applications
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 8
SN  - 1424-8220

AB  - In unmanned aerial vehicle (UAV)-aided wireless sensor networks (UWSNs), a UAV is employed as a mobile sink to gather data from sensor nodes. Incorporating UAV helps prolong the network lifetime and avoid the energy-hole problem faced by sensor networks. In emergency applications, timely data collection from sensor nodes and transferal of the data to the base station (BS) is a prime requisite. The timely and safe path of UAV is one of the fundamental premises for effective UWSN operations. It is essential and challenging to identify a suitable path in an environment comprising various obstacles and to ensure that the path can efficiently reach the target point. This paper proposes a hybrid path planning (HPP) algorithm for efficient data collection by assuring the shortest collision-free path for UAV in emergency environments. In the proposed HPP scheme, the probabilistic roadmap (PRM) algorithm is used to design the shortest trajectory map and the optimized artificial bee colony (ABC) algorithm to improve different path constraints in a three-dimensional environment. Our simulation results show that the proposed HPP outperforms the PRM and conventional ABC schemes significantly in terms of flight time, energy consumption, convergence time, and flight path.
KW  - wireless sensor network
KW  - data gathering
KW  - unmanned aerial vehicle
KW  - path planning
KW  - artificial bee colony
KW  - collision avoidance
KW  - delay minimization
KW  - probabilistic roadmap
DO  - 10.3390/s21082839
TY  - EJOU
AU  - Ge, Xiangyu
AU  - Ding, Jianli
AU  - Jin, Xiuliang
AU  - Wang, Jingzhe
AU  - Chen, Xiangyue
AU  - Li, Xiaohang
AU  - Liu, Jie
AU  - Xie, Boqiang
TI  - Estimating Agricultural Soil Moisture Content through UAV-Based Hyperspectral Images in the Arid Region
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - Unmanned aerial vehicle (UAV)-based hyperspectral remote sensing is an important monitoring technology for the soil moisture content (SMC) of agroecological systems in arid regions. This technology develops precision farming and agricultural informatization. However, hyperspectral data are generally used in data mining. In this study, UAV-based hyperspectral imaging data with a resolution o 4 cm and totaling 70 soil samples (0–10 cm) were collected from farmland (2.5 × 104 m2) near Fukang City, Xinjiang Uygur Autonomous Region, China. Four estimation strategies were tested: the original image (strategy I), first- and second-order derivative methods (strategy II), the fractional-order derivative (FOD) technique (strategy III), and the optimal fractional order combined with the optimal multiband indices (strategy IV). These strategies were based on the eXtreme Gradient Boost (XGBoost) algorithm, with the aim of building the best estimation model for agricultural SMC in arid regions. The results demonstrated that FOD technology could effectively mine information (with an absolute maximum correlation coefficient of 0.768). By comparison, strategy IV yielded the best estimates out of the methods tested (R2val = 0.921, RMSEP = 1.943, and RPD = 2.736) for the SMC. The model derived from the order of 0.4 within strategy IV worked relatively well among the different derivative methods (strategy I, II, and III). In conclusion, the combination of FOD technology and the optimal multiband indices generated a highly accurate model within the XGBoost algorithm for SMC estimation. This research provided a promising data mining approach for UAV-based hyperspectral imaging data.
KW  - fractional-order derivatives
KW  - ensemble learning
KW  - hyperspectral data
KW  - precision agriculture
DO  - 10.3390/rs13081562
TY  - EJOU
AU  - Zulkifley, Muhammad A.
AU  - Behjati, Mehran
AU  - Nordin, Rosdiadee
AU  - Zakaria, Mohamad S.
TI  - Mobile Network Performance and Technical Feasibility of LTE-Powered Unmanned Aerial Vehicle
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 8
SN  - 1424-8220

AB  - Conventional and license-free radio-controlled drone activities are limited to a line-of-sight (LoS) operational range. One of the alternatives to operate the drones beyond the visual line-of-sight (BVLoS) range is replacing the drone wireless communications system from the conventional industrial, scientific, and medical (ISM) radio band to a licensed cellular-connected system. The Long Term Evolution (LTE) technology that has been established for the terrestrial area allows command-and-control and payload communications between drone and ground station in real-time. However, with increasing height above the ground, the radio environment changes, and utilizing terrestrial cellular networks for drone communications may face new challenges. In this regard, this paper aims to develop an LTE-based control system prototype for low altitude small drones and investigate the feasibility and performance of drone cellular connectivity at different altitudes with measuring parameters such as latency, handover, and signal strength. The measurement results have shown that by increasing flight height from ground to 170 m the received signal power and the signal quality levels were reduced by 20 dBm and 10 dB respectively, the downlink data rate decreased to 70%, and latency increased up to 94 ms. It is concluded that although the existing LTE network can provide a minimum requirement for drone cellular connectivity, further improvements are still needed to enhance aerial coverage, eliminate interference, and reduce network latency.
KW  - UAV
KW  - drone
KW  - BVLoS
KW  - wireless
KW  - cellular
KW  - 4G
KW  - LTE
DO  - 10.3390/s21082848
TY  - EJOU
AU  - Peng, Xing
AU  - Kong, Lingbao
AU  - Fuh, Jerry Y.
AU  - Wang, Hao
TI  - A Review of Post-Processing Technologies in Additive Manufacturing
T2  - Journal of Manufacturing and Materials Processing

PY  - 2021
VL  - 5
IS  - 2
SN  - 2504-4494

AB  - Additive manufacturing (AM) technology has rapidly evolved with research advances related to AM processes, materials, and designs. The advantages of AM over conventional techniques include an augmented capability to produce parts with complex geometries, operational flexibility, and reduced production time. However, AM processes also face critical issues, such as poor surface quality and inadequate mechanical properties. Therefore, several post-processing technologies are applied to improve the surface quality of the additively manufactured parts. This work aims to document post-processing technologies and their applications concerning different AM processes. Various types of post-process treatments are reviewed and their integrations with AM process are discussed.
KW  - additive manufacturing
KW  - post-processing
KW  - surface quality
KW  - mechanical properties
DO  - 10.3390/jmmp5020038
TY  - EJOU
AU  - Haque, Amlan
AU  - Islam, Nahina
AU  - Samrat, Nahidul H.
AU  - Dey, Shuvashis
AU  - Ray, Biplob
TI  - Smart Farming through Responsible Leadership in Bangladesh: Possibilities, Opportunities, and Beyond
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 8
SN  - 2071-1050

AB  - Smart farming has the potential to overcome the challenge of 2050 to feed 10 billion people. Both artificial intelligence (AI) and the internet of things (IoT) have become critical prerequisites to smart farming due to their high interoperability, sensors, and cutting-edge technologies. Extending the role of responsible leadership, this paper proposes an AI and IoT based smart farming system in Bangladesh. With a comprehensive literature review, this paper counsels the need to go beyond the simple application of traditional farming and irrigation practices and recommends implementing smart farming enabling responsible leadership to uphold sustainable agriculture. It contributes to the current literature of smart farming in several ways. First, this paper helps to understand the prospect and challenges of both AI and IoT and the requirement of smart farming in a nonwestern context. Second, it clarifies the interventions of responsible leadership into Bangladesh’s agriculture sector and justifies the demand for sustainable smart farming. Third, this paper is a step forward to explore future empirical studies for the effective and efficient use of AI and IoT to adopt smart farming. Finally, this paper will help policymakers to take responsible initiatives to plan and apply smart farming in a developing economy like Bangladesh.
KW  - sustainable farming
KW  - artificial intelligence (AI)
KW  - internet of things (IoT)
KW  - smart farming
KW  - responsible leadership
KW  - remote communication
DO  - 10.3390/su13084511
TY  - EJOU
AU  - Gibert Martínez, Isaac
AU  - Afonso, Frederico
AU  - Rodrigues, Simão
AU  - Lau, Fernando
TI  - A Sequential Approach for Aerodynamic Shape Optimization with Topology Optimization of Airfoils
T2  - Mathematical and Computational Applications

PY  - 2021
VL  - 26
IS  - 2
SN  - 2297-8747

AB  - The objective of this work is to study the coupling of two efficient optimization techniques, Aerodynamic Shape Optimization (ASO) and Topology Optimization (TO), in 2D airfoils. To achieve such goal two open-source codes, SU2 and Calculix, are employed for ASO and TO, respectively, using the Sequential Least SQuares Programming (SLSQP) and the Bi-directional Evolutionary Structural Optimization (BESO) algorithms; the latter is well-known for allowing the addition of material in the TO which constitutes, as far as our knowledge, a novelty for this kind of application. These codes are linked by means of a script capable of reading the geometry and pressure distribution obtained from the ASO and defining the boundary conditions to be applied in the TO. The Free-Form Deformation technique is chosen for the definition of the design variables to be used in the ASO, while the densities of the inner elements are defined as design variables of the TO. As a test case, a widely used benchmark transonic airfoil, the RAE2822, is chosen here with an internal geometric constraint to simulate the wing-box of a transonic wing. First, the two optimization procedures are tested separately to gain insight and then are run in a sequential way for two test cases with available experimental data: (i) Mach 0.729 at α=2.31°; and (ii) Mach 0.730 at α=2.79°. In the ASO problem, the lift is fixed and the drag is minimized; while in the TO problem, compliance minimization is set as the objective for a prescribed volume fraction. Improvements in both aerodynamic and structural performance are found, as expected: the ASO reduced the total pressure on the airfoil surface in order to minimize drag, which resulted in lower stress values experienced by the structure.
KW  - aerodynamic shape optimization
KW  - computational fluid dynamics
KW  - topology optimization
KW  - airfoil
DO  - 10.3390/mca26020034
TY  - EJOU
AU  - Seitsonen, Oula
AU  - Ikäheimo, Janne
TI  - Detecting Archaeological Features with Airborne Laser Scanning in the Alpine Tundra of Sápmi, Northern Finland
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - Open access airborne laser scanning (ALS) data have been available in Finland for over a decade and have been actively applied by the Finnish archaeologists in that time. The low resolution of this laser scanning 2008–2019 dataset (0.5 points/m2), however, has hindered its usability for archaeological prospection. In the summer of 2020, the situation changed markedly, when the Finnish National Land Survey started a new countrywide ALS survey with a higher resolution of 5 points/m2. In this paper we present the first results of applying this newly available ALS material for archaeological studies. Finnish LIDARK consortium has initiated the development of semi-automated approaches for visualizing, detecting, and analyzing archaeological features with this new dataset. Our first case studies are situated in the Alpine tundra environment of Sápmi in northern Finland, and the assessed archaeological features range from prehistoric sites to indigenous Sámi reindeer herding features and Second Word War-era German military structures. Already the initial analyses of the new ALS-5p data show their huge potential for locating, mapping, and assessing archaeological material. These results also suggest an imminent burst in the number of known archaeological sites, especially in the poorly accessible and little studied northern wilderness areas, when more data become available.
KW  - archaeology
KW  - airborne laser scanning
KW  - LiDAR
KW  - Finland
KW  - Lapland
KW  - Sápmi
KW  - tundra
DO  - 10.3390/rs13081599
TY  - EJOU
AU  - Hrúz, Michal
AU  - Bugaj, Martin
AU  - Novák, Andrej
AU  - Kandera, Branislav
AU  - Badánik, Benedikt
TI  - The Use of UAV with Infrared Camera and RFID for Airframe Condition Monitoring
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 9
SN  - 2076-3417

AB  - The new progressive smart technologies announced in the fourth industrial revolution in aviation—Aviation 4.0—represent new possibilities and big challenges in aircraft maintenance processes. The main benefit of these technologies is the possibility to monitor, transfer, store, and analyze huge datasets. Based on analysis outputs, there is a possibility to improve current preventive maintenance processes and implement predictive maintenance processes. These solutions lower the downtime, save manpower, and extend the components’ lifetime; thus, the maximum effectivity and safety is achieved. The article deals with the possible implementation of an unmanned aerial vehicle (UAV) with an infrared camera and Radio Frequency Identification (RFID) as two of the smart hangar technologies for airframe condition monitoring. The presented implementations of smart technologies follow up the specific results of a case study focused on trainer aircraft failure monitoring and its impact on maintenance strategy changes. The case study failure indexes show the critical parts of aircraft that are subjected to damage the most. The aim of the article was to justify the need for thorough monitoring of critical parts of the aircraft and then analyze and propose a more effective and the most suitable form of technical condition monitoring of aircraft critical parts. The article describes the whole process of visual inspection performed by an unmanned aerial vehicle (UAV) with an IR camera and its related processes; in addition, it covers the possible usage of RFID tags as a labeling tool supporting the visual inspection. The implementations criteria apply to the repair and overhaul small aircraft maintenance organization, and later, it can also increase operational efficiency. The final suggestions describe the possible usage of proposed solutions, their main benefits, and also the limitations of their implementations in maintenance of trainer aircraft.
KW  - smart technologies
KW  - smart hangar
KW  - technical condition monitoring
KW  - UAV
KW  - RFID
DO  - 10.3390/app11093737
TY  - EJOU
AU  - Yan, Bin
AU  - Fan, Pan
AU  - Lei, Xiaoyan
AU  - Liu, Zhijie
AU  - Yang, Fuzeng
TI  - A Real-Time Apple Targets Detection Method for Picking Robot Based on Improved YOLOv5
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - The apple target recognition algorithm is one of the core technologies of the apple picking robot. However, most of the existing apple detection algorithms cannot distinguish between the apples that are occluded by tree branches and occluded by other apples. The apples, grasping end-effector and mechanical picking arm of the robot are very likely to be damaged if the algorithm is directly applied to the picking robot. Based on this practical problem, in order to automatically recognize the graspable and ungraspable apples in an apple tree image, a light-weight apple targets detection method was proposed for picking robot using improved YOLOv5s. Firstly, BottleneckCSP module was improved designed to BottleneckCSP-2 module which was used to replace the BottleneckCSP module in backbone architecture of original YOLOv5s network. Secondly, SE module, which belonged to the visual attention mechanism network, was inserted to the proposed improved backbone network. Thirdly, the bonding fusion mode of feature maps, which were inputs to the target detection layer of medium size in the original YOLOv5s network, were improved. Finally, the initial anchor box size of the original network was improved. The experimental results indicated that the graspable apples, which were unoccluded or only occluded by tree leaves, and the ungraspable apples, which were occluded by tree branches or occluded by other fruits, could be identified effectively using the proposed improved network model in this study. Specifically, the recognition recall, precision, mAP and F1 were 91.48%, 83.83%, 86.75% and 87.49%, respectively. The average recognition time was 0.015 s per image. Contrasted with original YOLOv5s, YOLOv3, YOLOv4 and EfficientDet-D0 model, the mAP of the proposed improved YOLOv5s model increased by 5.05%, 14.95%, 4.74% and 6.75% respectively, the size of the model compressed by 9.29%, 94.6%, 94.8% and 15.3% respectively. The average recognition speeds per image of the proposed improved YOLOv5s model were 2.53, 1.13 and 3.53 times of EfficientDet-D0, YOLOv4 and YOLOv3 and model, respectively. The proposed method can provide technical support for the real-time accurate detection of multiple fruit targets for the apple picking robot.
KW  - artificial intelligence
KW  - convolutional neural network
KW  - YOLOv5
KW  - object detection
KW  - apple picking robot
KW  - lightweight
KW  - real-time detection
DO  - 10.3390/rs13091619
TY  - EJOU
AU  - Kwak, Geun-Ho
AU  - Park, Chan-won
AU  - Lee, Kyung-do
AU  - Na, Sang-il
AU  - Ahn, Ho-yong
AU  - Park, No-Wook
TI  - Potential of Hybrid CNN-RF Model for Early Crop Mapping with Limited Input Data
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - When sufficient time-series images and training data are unavailable for crop classification, features extracted from convolutional neural network (CNN)-based representative learning may not provide useful information to discriminate crops with similar spectral characteristics, leading to poor classification accuracy. In particular, limited input data are the main obstacles to obtain reliable classification results for early crop mapping. This study investigates the potential of a hybrid classification approach, i.e., CNN-random forest (CNN-RF), in the context of early crop mapping, that combines the automatic feature extraction capability of CNN with the superior discrimination capability of an RF classifier. Two experiments on incremental crop classification with unmanned aerial vehicle images were conducted to compare the performance of CNN-RF with that of CNN and RF with respect to the length of the time-series and training data sizes. When sufficient time-series images and training data were used for the classification, the accuracy of CNN-RF was slightly higher or comparable with that of CNN. In contrast, when fewer images and the smallest training data were used at the early crop growth stage, CNN-RF was substantially beneficial and the overall accuracy increased by maximum 6.7%p and 4.6%p in the two study areas, respectively, compared to CNN. This is attributed to its ability to discriminate crops from features with insufficient information using a more sophisticated classifier. The experimental results demonstrate that CNN-RF is an effective classifier for early crop mapping when only limited input images and training samples are available.
KW  - crop classification
KW  - convolution neural networks
KW  - random forest
KW  - hybrid model
KW  - training data
KW  - time-series images
DO  - 10.3390/rs13091629
TY  - EJOU
AU  - Ge, Haixiao
AU  - Xiang, Haitao
AU  - Ma, Fei
AU  - Li, Zhenwang
AU  - Qiu, Zhengchao
AU  - Tan, Zhengzheng
AU  - Du, Changwen
TI  - Estimating Plant Nitrogen Concentration of Rice through Fusing Vegetation Indices and Color Moments Derived from UAV-RGB Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - Estimating plant nitrogen concentration (PNC) has been conducted using vegetation indices (VIs) from UAV-based imagery, but color features have been rarely considered as additional variables. In this study, the VIs and color moments (color feature) were calculated from UAV-based RGB images, then partial least square regression (PLSR) and random forest regression (RF) models were established to estimate PNC through fusing VIs and color moments. The results demonstrated that the fusion of VIs and color moments as inputs yielded higher accuracies of PNC estimation compared to VIs or color moments as input; the RF models based on the combination of VIs and color moments (R2 ranging from 0.69 to 0.91 and NRMSE ranging from 0.07 to 0.13) showed similar performances to the PLSR models (R2 ranging from 0.68 to 0.87 and NRMSE ranging from 0.10 to 0.29); Among the top five important variables in the RF models, there was at least one variable which belonged to the color moments in different datasets, indicating the significant contribution of color moments in improving PNC estimation accuracy. This revealed the great potential of combination of RGB-VIs and color moments for the estimation of rice PNC.
KW  - UAV
KW  - plant nitrogen concentration
KW  - RGB-VIs
KW  - color moments
KW  - PLSR
KW  - RF
DO  - 10.3390/rs13091620
TY  - EJOU
AU  - Pourroostaei Ardakani, Saeid
TI  - MINDS: Mobile Agent Itinerary Planning Using Named Data Networking in Wireless Sensor Networks
T2  - Journal of Sensor and Actuator Networks

PY  - 2021
VL  - 10
IS  - 2
SN  - 2224-2708

AB  - Mobile agents have the potential to offer benefits, as they are able to either independently or cooperatively move throughout networks and collect/aggregate sensory data samples. They are programmed to autonomously move and visit sensory data stations through optimal paths, which are established according to the application requirements. However, mobile agent routing protocols still suffer heavy computation/communication overheads, lack of route planning accuracy and long-delay mobile agent migrations. For this, mobile agent route planning protocols aim to find the best-fitted paths for completing missions (e.g., data collection) with minimised delay, maximised performance and minimised transmitted traffic. This article proposes a mobile agent route planning protocol for sensory data collection called MINDS. The key goal of this MINDS is to reduce network traffic, maximise data robustness and minimise delay at the same time. This protocol utilises the Hamming distance technique to partition a sensor network into a number of data-centric clusters. In turn, a named data networking approach is used to form the cluster-heads as a data-centric, tree-based communication infrastructure. The mobile agents utilise a modified version of the Depth-First Search algorithm to move through the tree infrastructure according to a hop-count-aware fashion. As the simulation results show, MINDS reduces path length, reduces network traffic and increases data robustness as compared with two conventional benchmarks (ZMA and TBID) in dense and large wireless sensor networks.
KW  - wireless sensor networks
KW  - named data networking
KW  - mobile agents
KW  - itinerary planning
DO  - 10.3390/jsan10020028
TY  - EJOU
AU  - Azar, Ahmad T.
AU  - Koubaa, Anis
AU  - Ali Mohamed, Nada
AU  - Ibrahim, Habiba A.
AU  - Ibrahim, Zahra F.
AU  - Kazim, Muhammad
AU  - Ammar, Adel
AU  - Benjdira, Bilel
AU  - Khamis, Alaa M.
AU  - Hameed, Ibrahim A.
AU  - Casalino, Gabriella
TI  - Drone Deep Reinforcement Learning: A Review
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 9
SN  - 2079-9292

AB  - Unmanned Aerial Vehicles (UAVs) are increasingly being used in many challenging and diversified applications. These applications belong to the civilian and the military fields. To name a few; infrastructure inspection, traffic patrolling, remote sensing, mapping, surveillance, rescuing humans and animals, environment monitoring, and Intelligence, Surveillance, Target Acquisition, and Reconnaissance (ISTAR) operations. However, the use of UAVs in these applications needs a substantial level of autonomy. In other words, UAVs should have the ability to accomplish planned missions in unexpected situations without requiring human intervention. To ensure this level of autonomy, many artificial intelligence algorithms were designed. These algorithms targeted the guidance, navigation, and control (GNC) of UAVs. In this paper, we described the state of the art of one subset of these algorithms: the deep reinforcement learning (DRL) techniques. We made a detailed description of them, and we deduced the current limitations in this area. We noted that most of these DRL methods were designed to ensure stable and smooth UAV navigation by training computer-simulated environments. We realized that further research efforts are needed to address the challenges that restrain their deployment in real-life scenarios.
KW  - unmanned aerial vehicles
KW  - UAVs
KW  - guidance
KW  - navigation
KW  - control
KW  - machine learning
KW  - deep reinforcement learning (DRL)
KW  - literature review
DO  - 10.3390/electronics10090999
TY  - EJOU
AU  - Kashyap, Bhuwan
AU  - Kumar, Ratnesh
TI  - Sensing Methodologies in Agriculture for Monitoring Biotic Stress in Plants Due to Pathogens and Pests
T2  - Inventions

PY  - 2021
VL  - 6
IS  - 2
SN  - 2411-5134

AB  - Reducing agricultural losses is an effective way to sustainably increase agricultural output efficiency to meet our present and future needs for food, fiber, fodder, and fuel. Our ever-improving understanding of the ways in which plants respond to stress, biotic and abiotic, has led to the development of innovative sensing technologies for detecting crop stresses/stressors and deploying efficient measures. This article aims to present the current state of the methodologies applied in the field of agriculture towards the detection of biotic stress in crops. Key sensing methodologies for plant pathogen (or phytopathogen), as well as herbivorous insects/pests are presented, where the working principles are described, and key recent works discussed. The detection methods overviewed for phytopathogen-related stress identification include nucleic acid-based methods, immunological methods, imaging-based techniques, spectroscopic methods, phytohormone biosensing methods, monitoring methods for plant volatiles, and active remote sensing technologies. Whereas the pest-related sensing techniques include machine-vision-based methods, pest acoustic-emission sensors, and volatile organic compound-based stress monitoring methods. Additionally, Comparisons have been made between different sensing techniques as well as recently reported works, where the strengths and limitations are identified. Finally, the prospective future directions for monitoring biotic stress in crops are discussed.
KW  - biosensors
KW  - hyperspectral
KW  - thermography
KW  - electrochemical
KW  - hormones
KW  - fluorescence
KW  - acoustic
KW  - spectroscopy
KW  - remote sensing
KW  - volatile organic compounds
DO  - 10.3390/inventions6020029
TY  - EJOU
AU  - Gargees, Rasha S.
AU  - Scott, Grant J.
TI  - Large-Scale, Multiple Level-of-Detail Change Detection from Remote Sensing Imagery Using Deep Visual Feature Clustering
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - In the era of big data, where massive amounts of remotely sensed imagery can be obtained from various satellites accompanied by the rapid change in the surface of the Earth, new techniques for large-scale change detection are necessary to facilitate timely and effective human understanding of natural and human-made phenomena. In this research, we propose a chip-based change detection method that is enabled by using deep neural networks to extract visual features. These features are transformed into deep orthogonal visual features that are then clustered based on land cover characteristics. The resulting chip cluster memberships allow arbitrary level-of-detail change analysis that can also support irregular geospatial extent based agglomerations. The proposed methods naturally support cross-resolution temporal scenes without requiring normalization of the pixel resolution across scenes and without requiring pixel-level coregistration processes. This is achieved with configurable spatial locality comparisons between years, where the aperture of a unit of measure can be a single chip, a small neighborhood of chips, or a large irregular geospatial region. The performance of our proposed method has been validated using various quantitative and statistical metrics in addition to presenting the visual geo-maps and the percentage of the change. The results show that our proposed method efficiently detected the change from a large scale area.
KW  - change detection
KW  - big data
KW  - deep features
KW  - fuzzy clustering
KW  - transfer learning
KW  - land cover
DO  - 10.3390/rs13091661
TY  - EJOU
AU  - Öztürk, Ali E.
AU  - Erçelebi, Ergun
TI  - Real UAV-Bird Image Classification Using CNN with a Synthetic Dataset
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 9
SN  - 2076-3417

AB  - A large amount of training image data is required for solving image classification problems using deep learning (DL) networks. In this study, we aimed to train DL networks with synthetic images generated by using a game engine and determine the effects of the networks on performance when solving real-image classification problems. The study presents the results of using corner detection and nearest three-point selection (CDNTS) layers to classify bird and rotary-wing unmanned aerial vehicle (RW-UAV) images, provides a comprehensive comparison of two different experimental setups, and emphasizes the significant improvements in the performance in deep learning-based networks due to the inclusion of a CDNTS layer. Experiment 1 corresponds to training the commonly used deep learning-based networks with synthetic data and an image classification test on real data. Experiment 2 corresponds to training the CDNTS layer and commonly used deep learning-based networks with synthetic data and an image classification test on real data. In experiment 1, the best area under the curve (AUC) value for the image classification test accuracy was measured as 72%. In experiment 2, using the CDNTS layer, the AUC value for the image classification test accuracy was measured as 88.9%. A total of 432 different combinations of trainings were investigated in the experimental setups. The experiments were trained with various DL networks using four different optimizers by considering all combinations of batch size, learning rate, and dropout hyperparameters. The test accuracy AUC values for networks in experiment 1 ranged from 55% to 74%, whereas the test accuracy AUC values in experiment 2 networks with a CDNTS layer ranged from 76% to 89.9%. It was observed that the CDNTS layer has considerable effects on the image classification accuracy performance of deep learning-based networks. AUC, F-score, and test accuracy measures were used to validate the success of the networks.
KW  - image classification
KW  - deep learning
KW  - CNN
KW  - corner detection
KW  - rotary-wing UAV
KW  - synthetic image generation
KW  - corner detection and nearest three-point selection (CDNTS)
DO  - 10.3390/app11093863
TY  - EJOU
AU  - Islam, Nahina
AU  - Rashid, Md M.
AU  - Wibowo, Santoso
AU  - Xu, Cheng-Yuan
AU  - Morshed, Ahsan
AU  - Wasimi, Saleh A.
AU  - Moore, Steven
AU  - Rahman, Sk M.
TI  - Early Weed Detection Using Image Processing and Machine Learning Techniques in an Australian Chilli Farm
T2  - Agriculture

PY  - 2021
VL  - 11
IS  - 5
SN  - 2077-0472

AB  - This paper explores the potential of machine learning algorithms for weed and crop classification from UAV images. The identification of weeds in crops is a challenging task that has been addressed through orthomosaicing of images, feature extraction and labelling of images to train machine learning algorithms. In this paper, the performances of several machine learning algorithms, random forest (RF), support vector machine (SVM) and k-nearest neighbours (KNN), are analysed to detect weeds using UAV images collected from a chilli crop field located in Australia. The evaluation metrics used in the comparison of performance were accuracy, precision, recall, false positive rate and kappa coefficient. MATLAB is used for simulating the machine learning algorithms; and the achieved weed detection accuracies are 96% using RF, 94% using SVM and 63% using KNN. Based on this study, RF and SVM algorithms are efficient and practical to use, and can be implemented easily for detecting weed from UAV images.
KW  - weed detection
KW  - smart farming
KW  - machine learning
KW  - remote sensing
KW  - image processing
DO  - 10.3390/agriculture11050387
TY  - EJOU
AU  - Avola, Danilo
AU  - Cinque, Luigi
AU  - Diko, Anxhelo
AU  - Fagioli, Alessio
AU  - Foresti, Gian L.
AU  - Mecca, Alessio
AU  - Pannone, Daniele
AU  - Piciarelli, Claudio
TI  - MS-Faster R-CNN: Multi-Stream Backbone for Improved Faster R-CNN Object Detection and Aerial Tracking from UAV Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - Tracking objects across multiple video frames is a challenging task due to several difficult issues such as occlusions, background clutter, lighting as well as object and camera view-point variations, which directly affect the object detection. These aspects are even more emphasized when analyzing unmanned aerial vehicles (UAV) based images, where the vehicle movement can also impact the image quality. A common strategy employed to address these issues is to analyze the input images at different scales to obtain as much information as possible to correctly detect and track the objects across video sequences. Following this rationale, in this paper, we introduce a simple yet effective novel multi-stream (MS) architecture, where different kernel sizes are applied to each stream to simulate a multi-scale image analysis. The proposed architecture is then used as backbone for the well-known Faster-R-CNN pipeline, defining a MS-Faster R-CNN object detector that consistently detects objects in video sequences. Subsequently, this detector is jointly used with the Simple Online and Real-time Tracking with a Deep Association Metric (Deep SORT) algorithm to achieve real-time tracking capabilities on UAV images. To assess the presented architecture, extensive experiments were performed on the UMCD, UAVDT, UAV20L, and UAV123 datasets. The presented pipeline achieved state-of-the-art performance, confirming that the proposed multi-stream method can correctly emulate the robust multi-scale image analysis paradigm.
KW  - UAV
KW  - object detection
KW  - tracking
KW  - deep learning
KW  - aerial images
DO  - 10.3390/rs13091670
TY  - EJOU
AU  - Song, Bonggeun
AU  - Park, Kyunghun
TI  - Comparison of Outdoor Compost Pile Detection Using Unmanned Aerial Vehicle Images and Various Machine Learning Techniques
T2  - Drones

PY  - 2021
VL  - 5
IS  - 2
SN  - 2504-446X

AB  - Since outdoor compost piles (OCPs) contain large amounts of nitrogen and phosphorus, they act as a major pollutant that deteriorates water quality, such as eutrophication and green algae, when the OCPs enter the river during rainfall. In South Korea, OCPs are frequently used, but there is a limitation that a lot of manpower and budget are consumed to investigate the current situation, so it is necessary to efficiently investigate the OCPs. This study compared the accuracy of various machine learning techniques for the efficient detection and management of outdoor compost piles (OCPs), a non-point pollution source in agricultural areas in South Korea, using unmanned aerial vehicle (UAV) images. RGB, multispectral, and thermal infrared UAV images were taken in August and October 2019. Additionally, vegetation indices (NDVI, NDRE, ENDVI, and GNDVI) and surface temperature were also considered. Four machine learning techniques, including support vector machine (SVM), decision tree (DT), random forest (RF), and k-NN, were implemented, and the machine learning technique with the highest accuracy was identified by adjusting several variables. The accuracy of all machine learning techniques was very high, reaching values of up to 0.96. Particularly, the accuracy of the RF method with the number of estimators set to 10 was highest, reaching 0.989 in August and 0.987 in October. The proposed method allows for the prediction of OCP location and area over large regions, thereby foregoing the need for OCP field measurements. Therefore, our findings provide highly useful data for the improvement of OCP management strategies and water quality.
KW  - non-point pollutant
KW  - random forest
KW  - SVM
KW  - decision tree
KW  - k-NN
KW  - python
DO  - 10.3390/drones5020031
TY  - EJOU
AU  - Khan, Nawab
AU  - Ray, Ram L.
AU  - Sargani, Ghulam R.
AU  - Ihtisham, Muhammad
AU  - Khayyam, Muhammad
AU  - Ismail, Sohaib
TI  - Current Progress and Future Prospects of Agriculture Technology: Gateway to Sustainable Agriculture
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 9
SN  - 2071-1050

AB  - The agricultural industry is getting more data-centric and requires precise, more advanced data and technologies than before, despite being familiar with agricultural processes. The agriculture industry is being advanced by various information and advanced communication technologies, such as the Internet of Things (IoT). The rapid emergence of these advanced technologies has restructured almost all other industries, as well as advanced agriculture, which has shifted the industry from a statistical approach to a quantitative one. This radical change has shaken existing farming techniques and produced the latest prospects in a series of challenges. This comprehensive review article enlightens the potential of the IoT in the advancement of agriculture and the challenges faced when combining these advanced technologies with conventional agricultural systems. A brief analysis of these advanced technologies with sensors is presented in advanced agricultural applications. Numerous sensors that can be implemented for specific agricultural practices require best management practices (e.g., land preparation, irrigation systems, insect, and disease management). This review includes the integration of all suitable techniques, from sowing to harvesting, packaging, transportation, and advanced technologies available for farmers throughout the cropping system. Besides, this review article highlights the utilization of other tools such as unmanned aerial vehicles (UAVs) for crop monitoring and other beneficiary measures, such as optimizing crop yields. In addition, advanced programs based on the IoT are also discussed. Finally, based on our comprehensive review, we identified advanced prospects regarding the IoT, which are essential tools for sustainable agriculture.
KW  - IoT
KW  - agriculture advancement
KW  - UAVs
KW  - sustainable agriculture
DO  - 10.3390/su13094883
TY  - EJOU
AU  - Bi, Shusheng
AU  - Yuan, Chang
AU  - Liu, Chang
AU  - Cheng, Jun
AU  - Wang, Wei
AU  - Cai, Yueri
TI  - A Survey of Low-Cost 3D Laser Scanning Technology
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 9
SN  - 2076-3417

AB  - By moving a commercial 2D LiDAR, 3D maps of the environment can be built, based on the data of a 2D LiDAR and its movements. Compared to a commercial 3D LiDAR, a moving 2D LiDAR is more economical. A series of problems need to be solved in order for a moving 2D LiDAR to perform better, among them, improving accuracy and real-time performance. In order to solve these problems, estimating the movements of a 2D LiDAR, and identifying and removing moving objects in the environment, are issues that should be studied. More specifically, calibrating the installation error between the 2D LiDAR and the moving unit, the movement estimation of the moving unit, and identifying moving objects at low scanning frequencies, are involved. As actual applications are mostly dynamic, and in these applications, a moving 2D LiDAR moves between multiple moving objects, we believe that, for a moving 2D LiDAR, how to accurately construct 3D maps in dynamic environments will be an important future research topic. Moreover, how to deal with moving objects in a dynamic environment via a moving 2D LiDAR has not been solved by previous research.
KW  - 3D laser scanning
KW  - low-cost
KW  - 2D LiDAR
KW  - a moving 2D LiDAR
DO  - 10.3390/app11093938
TY  - EJOU
AU  - Allouch, Azza
AU  - Cheikhrouhou, Omar
AU  - Koubâa, Anis
AU  - Toumi, Khalifa
AU  - Khalgui, Mohamed
AU  - Nguyen Gia, Tuan
TI  - UTM-Chain: Blockchain-Based Secure Unmanned Traffic Management for Internet of Drones
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 9
SN  - 1424-8220

AB  - Unmanned aerial systems (UAVs) are dramatically evolving and promoting several civil applications. However, they are still prone to many security issues that threaten public safety. Security becomes even more challenging when they are connected to the Internet as their data stream is exposed to attacks. Unmanned traffic management (UTM) represents one of the most important topics for small unmanned aerial systems for beyond-line-of-sight operations in controlled low-altitude airspace. However, without securing the flight path exchanges between drones and ground stations or control centers, serious security threats may lead to disastrous situations. For example, a predefined flight path could be easily altered to make the drone perform illegal operations. Motivated by these facts, this paper discusses the security issues for UTM’s components and addresses the security requirements for such systems. Moreover, we propose UTM-Chain, a lightweight blockchain-based security solution using hyperledger fabric for UTM of low-altitude UAVs which fits the computational and storage resources limitations of UAVs. Moreover, UTM-Chain provides secure and unalterable traffic data between the UAVs and their ground control stations. The performance of the proposed system related to transaction latency and resource utilization is analyzed by using cAdvisor. Finally, the analysis of security aspects demonstrates that the proposed UTM-Chain scheme is feasible and extensible for the secure sharing of UAV data.
KW  - Internet-of-Drones
KW  - IoD
KW  - unmanned aerial systems
KW  - UAV
KW  - unmanned traffic management
KW  - hyperledger
KW  - ground control station
DO  - 10.3390/s21093049
TY  - EJOU
AU  - Wang, Zhaojun
AU  - Wang, Jiangning
AU  - Lin, Congtian
AU  - Han, Yan
AU  - Wang, Zhaosheng
AU  - Ji, Liqiang
TI  - Identifying Habitat Elements from Bird Images Using Deep Convolutional Neural Networks
T2  - Animals

PY  - 2021
VL  - 11
IS  - 5
SN  - 2076-2615

AB  - With the rapid development of digital technology, bird images have become an important part of ornithology research data. However, due to the rapid growth of bird image data, it has become a major challenge to effectively process such a large amount of data. In recent years, deep convolutional neural networks (DCNNs) have shown great potential and effectiveness in a variety of tasks regarding the automatic processing of bird images. However, no research has been conducted on the recognition of habitat elements in bird images, which is of great help when extracting habitat information from bird images. Here, we demonstrate the recognition of habitat elements using four DCNN models trained end-to-end directly based on images. To carry out this research, an image database called Habitat Elements of Bird Images (HEOBs-10) and composed of 10 categories of habitat elements was built, making future benchmarks and evaluations possible. Experiments showed that good results can be obtained by all the tested models. ResNet-152-based models yielded the best test accuracy rate (95.52%); the AlexNet-based model yielded the lowest test accuracy rate (89.48%). We conclude that DCNNs could be efficient and useful for automatically identifying habitat elements from bird images, and we believe that the practical application of this technology will be helpful for studying the relationships between birds and habitat elements.
KW  - bird images
KW  - deep convolutional neural networks
KW  - habitat elements
DO  - 10.3390/ani11051263
TY  - EJOU
AU  - de Camargo, Tibor
AU  - Schirrmann, Michael
AU  - Landwehr, Niels
AU  - Dammer, Karl-Heinz
AU  - Pflanz, Michael
TI  - Optimized Deep Learning Model as a Basis for Fast UAV Mapping of Weed Species in Winter Wheat Crops
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - Weed maps should be available quickly, reliably, and with high detail to be useful for site-specific management in crop protection and to promote more sustainable agriculture by reducing pesticide use. Here, the optimization of a deep residual convolutional neural network (ResNet-18) for the classification of weed and crop plants in UAV imagery is proposed. The target was to reach sufficient performance on an embedded system by maintaining the same features of the ResNet-18 model as a basis for fast UAV mapping. This would enable online recognition and subsequent mapping of weeds during UAV flying operation. Optimization was achieved mainly by avoiding redundant computations that arise when a classification model is applied on overlapping tiles in a larger input image. The model was trained and tested with imagery obtained from a UAV flight campaign at low altitude over a winter wheat field, and classification was performed on species level with the weed species Matricaria chamomilla L., Papaver rhoeas L., Veronica hederifolia L., and Viola arvensis ssp. arvensis observed in that field. The ResNet-18 model with the optimized image-level prediction pipeline reached a performance of 2.2 frames per second with an NVIDIA Jetson AGX Xavier on the full resolution UAV image, which would amount to about 1.78 ha h−1 area output for continuous field mapping. The overall accuracy for determining crop, soil, and weed species was 94%. There were some limitations in the detection of species unknown to the model. When shifting from 16-bit to 32-bit model precision, no improvement in classification accuracy was observed, but a strong decline in speed performance, especially when a higher number of filters was used in the ResNet-18 model. Future work should be directed towards the integration of the mapping process on UAV platforms, guiding UAVs autonomously for mapping purpose, and ensuring the transferability of the models to other crop fields.
KW  - ResNet
KW  - deep residual networks
KW  - UAV imagery
KW  - embedded systems
KW  - crop monitoring
KW  - image classification
KW  - site-specific weed management
KW  - real-time mapping
DO  - 10.3390/rs13091704
TY  - EJOU
AU  - Xu, Dandan
AU  - Wang, Haobin
AU  - Xu, Weixin
AU  - Luan, Zhaoqing
AU  - Xu, Xia
TI  - LiDAR Applications to Estimate Forest Biomass at Individual Tree Scale: Opportunities, Challenges and Future Perspectives
T2  - Forests

PY  - 2021
VL  - 12
IS  - 5
SN  - 1999-4907

AB  - Accurate forest biomass estimation at the individual tree scale is the foundation of timber industry and forest management. It plays an important role in explaining ecological issues and small-scale processes. Remotely sensed images, across a range of spatial and temporal resolutions, with their advantages of non-destructive monitoring, are widely applied in forest biomass monitoring at global, ecoregion or community scales. However, the development of remote sensing applications for forest biomass at the individual tree scale has been relatively slow due to the constraints of spatial resolution and evaluation accuracy of remotely sensed data. With the improvements in platforms and spatial resolutions, as well as the development of remote sensing techniques, the potential for forest biomass estimation at the single tree level has been demonstrated. However, a comprehensive review of remote sensing of forest biomass scaled at individual trees has not been done. This review highlights the theoretical bases, challenges and future perspectives for Light Detection and Ranging (LiDAR) applications of individual trees scaled to whole forests. We summarize research on estimating individual tree volume and aboveground biomass (AGB) using Terrestrial Laser Scanning (TLS), Airborne Laser Scanning (ALS), Unmanned Aerial Vehicle Laser Scanning (UAV-LS) and Mobile Laser Scanning (MLS, including Vehicle-borne Laser Scanning (VLS) and Backpack Laser Scanning (BLS)) data.
KW  - forest aboveground biomass
KW  - LiDAR
KW  - individual tree scale
KW  - UAV-LS
KW  - Backpack Laser Scanning
DO  - 10.3390/f12050550
TY  - EJOU
AU  - Kuzmin, Anton
AU  - Korhonen, Lauri
AU  - Kivinen, Sonja
AU  - Hurskainen, Pekka
AU  - Korpelainen, Pasi
AU  - Tanhuanpää, Topi
AU  - Maltamo, Matti
AU  - Vihervaara, Petteri
AU  - Kumpula, Timo
TI  - Detection of European Aspen (Populus tremula L.) Based on an Unmanned Aerial Vehicle Approach in Boreal Forests
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - European aspen (Populus tremula L.) is a keystone species for biodiversity of boreal forests. Large-diameter aspens maintain the diversity of hundreds of species, many of which are threatened in Fennoscandia. Due to a low economic value and relatively sparse and scattered occurrence of aspen in boreal forests, there is a lack of information of the spatial and temporal distribution of aspen, which hampers efficient planning and implementation of sustainable forest management practices and conservation efforts. Our objective was to assess identification of European aspen at the individual tree level in a southern boreal forest using high-resolution photogrammetric point cloud (PPC) and multispectral (MSP) orthomosaics acquired with an unmanned aerial vehicle (UAV). The structure-from-motion approach was applied to generate RGB imagery-based PPC to be used for individual tree-crown delineation. Multispectral data were collected using two UAV cameras: Parrot Sequoia and MicaSense RedEdge-M. Tree-crown outlines were obtained from watershed segmentation of PPC data and intersected with multispectral mosaics to extract and calculate spectral metrics for individual trees. We assessed the role of spectral data features extracted from PPC and multispectral mosaics and a combination of it, using a machine learning classifier—Support Vector Machine (SVM) to perform two different classifications: discrimination of aspen from the other species combined into one class and classification of all four species (aspen, birch, pine, spruce) simultaneously. In the first scenario, the highest classification accuracy of 84% (F1-score) for aspen and overall accuracy of 90.1% was achieved using only RGB features from PPC, whereas in the second scenario, the highest classification accuracy of 86 % (F1-score) for aspen and overall accuracy of 83.3% was achieved using the combination of RGB and MSP features. The proposed method provides a new possibility for the rapid assessment of aspen occurrence to enable more efficient forest management as well as contribute to biodiversity monitoring and conservation efforts in boreal forests.
KW  - tree species classification
KW  - European aspen
KW  - UAV
KW  - biodiversity
KW  - deciduous trees
KW  - machine learning
KW  - multispectral data
KW  - boreal forest
DO  - 10.3390/rs13091723
TY  - EJOU
AU  - Chen, Ang
AU  - Yang, Xiuchun
AU  - Xu, Bin
AU  - Jin, Yunxiang
AU  - Guo, Jian
AU  - Xing, Xiaoyu
AU  - Yang, Dong
AU  - Wang, Ping
AU  - Zhu, Libo
TI  - Monitoring the Spatiotemporal Dynamics of Aeolian Desertification Using Google Earth Engine
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - Northern China has been long threatened by aeolian desertification. In recent years, all levels of the Chinese government have performed a series of ecological protection and sand control projects. To grasp the implementation effects of these projects and adjust policies in time, it is necessary to understand the process of aeolian desertification quickly and accurately. Remote sensing technologies play an irreplaceable role in aeolian desertification monitoring. In this study, the Zhenglan Banner, which is in the hinterland of the Hunshandake Sandy Land, was considered as the research area. Based on unmanned aerial vehicle (UAV) images, ground survey data, and Landsat images called in Google Earth Engine (GEE), the aeolian desertified land (ADL) in 2000, 2004, 2010, 2015, and 2019 was extracted using spectral mixture analysis. A desertification index (DI) was constructed to evaluate the spatial and temporal dynamics of the ADL in the Zhenglan Banner. Finally, a residual analysis explored the driving forces of aeolian desertification. The results showed that (1) the ADL area in the Zhenglan Banner has been trending downwards over the past 20 years but rebounded from 2004 to 2010; (2) over the past 20 years, the area of slightly, moderately, and severely desertified land has decreased at annual rates of 0.4%, 2.7%, and 3.4%, respectively; (3) human activities had significantly positive and negative impacts on the aeolian desertification trend for 20.0% and 21.0% of the study area, respectively, but not for the rest. This paper explored new techniques for rapid aeolian desertification monitoring and is of great significance for controlling and managing aeolian desertification in this region.
KW  - aeolian desertification
KW  - Google Earth Engine (GEE)
KW  - unmanned aerial vehicle (UAV)
KW  - human activity
KW  - climate change
DO  - 10.3390/rs13091730
TY  - EJOU
AU  - Jiménez-Jiménez, Sergio I.
AU  - Ojeda-Bustamante, Waldo
AU  - Marcial-Pablo, Mariana D.
AU  - Enciso, Juan
TI  - Digital Terrain Models Generated with Low-Cost UAV Photogrammetry: Methodology and Accuracy
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 5
SN  - 2220-9964

AB  - Digital terrain model (DTM) generation is essential to recreating terrain morphology once the external elements are removed. Traditional survey methods are still used to collect accurate geographic data on the land surface. Given the emergence of unmanned aerial vehicles (UAVs) equipped with low-cost digital cameras and better photogrammetric methods for digital mapping, efficient approaches are necessary to allow rapid land surveys with high accuracy. This paper provides a review, complemented with the authors’ experience, regarding the UAV photogrammetric process and field survey parameters for DTM generation using popular commercial photogrammetric software to process images obtained with fixed-wing or multicopter UAVs. We analyzed the quality and accuracy of the DTMs based on four categories: (i) the UAV system (UAV platforms and camera); (ii) flight planning and image acquisition (flight altitude, image overlap, UAV speed, orientation of the flight line, camera configuration, and georeferencing); (iii) photogrammetric DTM generation (software, image alignment, dense point cloud generation, and ground filtering); (iv) geomorphology and land use/cover. For flat terrain, UAV photogrammetry provided a horizontal root mean square error (RMSE) between 1 to 3 × the ground sample distance (GSD) and a vertical RMSE between 1 to 4.5 × GSD, and, for complex topography, a horizontal RMSE between 1 to 7 × GSD and a vertical RMSE between 1.5 to 5 × GSD. Finally, we stress that UAV photogrammetry can provide DTMs with high accuracy when the photogrammetric process variables are optimized.
KW  - SfM data mapping
KW  - ground control point
KW  - flight plan
KW  - ground filtering
KW  - DTM
KW  - autonomous systems
DO  - 10.3390/ijgi10050285
TY  - EJOU
AU  - Hobley, Brandon
AU  - Arosio, Riccardo
AU  - French, Geoffrey
AU  - Bremner, Julie
AU  - Dolphin, Tony
AU  - Mackiewicz, Michal
TI  - Semi-Supervised Segmentation for Coastal Monitoring Seagrass Using RPA Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - Intertidal seagrass plays a vital role in estimating the overall health and dynamics of coastal environments due to its interaction with tidal changes. However, most seagrass habitats around the globe have been in steady decline due to human impacts, disturbing the already delicate balance in the environmental conditions that sustain seagrass. Miniaturization of multi-spectral sensors has facilitated very high resolution mapping of seagrass meadows, which significantly improves the potential for ecologists to monitor changes. In this study, two analytical approaches used for classifying intertidal seagrass habitats are compared—Object-based Image Analysis (OBIA) and Fully Convolutional Neural Networks (FCNNs). Both methods produce pixel-wise classifications in order to create segmented maps. FCNNs are an emerging set of algorithms within Deep Learning. Conversely, OBIA has been a prominent solution within this field, with many studies leveraging in-situ data and multiresolution segmentation to create habitat maps. This work demonstrates the utility of FCNNs in a semi-supervised setting to map seagrass and other coastal features from an optical drone survey conducted at Budle Bay, Northumberland, England. Semi-supervision is also an emerging field within Deep Learning that has practical benefits of achieving state of the art results using only subsets of labelled data. This is especially beneficial for remote sensing applications where in-situ data is an expensive commodity. For our results, we show that FCNNs have comparable performance with the standard OBIA method used by ecologists.
KW  - deep learning
KW  - computer vision
KW  - remote sensing
KW  - supervised learning
KW  - semi-supervised learning
KW  - segmentation
KW  - seagrass mapping
DO  - 10.3390/rs13091741
TY  - EJOU
AU  - Liang, Peng
AU  - Shi, Wenzhong
AU  - Ding, Yixing
AU  - Liu, Zhiqiang
AU  - Shang, Haolv
TI  - Road Extraction from High Resolution Remote Sensing Images Based on Vector Field Learning
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 9
SN  - 1424-8220

AB  - Accurate and up-to-date road network information is very important for the Geographic Information System (GIS) database, traffic management and planning, automatic vehicle navigation, emergency response and urban pollution sources investigation. In this paper, we use vector field learning to extract roads from high resolution remote sensing imaging. This method is usually used for skeleton extraction in nature image, but seldom used in road extraction. In order to improve the accuracy of road extraction, three vector fields are constructed and combined respectively with the normal road mask learning by a two-task network. The results show that all the vector fields are able to significantly improve the accuracy of road extraction, no matter the field is constructed in the road area or completely outside the road. The highest F1 score is 0.7618, increased by 0.053 compared with using only mask learning.
KW  - road extraction
KW  - vector field learning
KW  - high resolution remote sensing image
KW  - encoder-decoder
KW  - DCNN
DO  - 10.3390/s21093152
TY  - EJOU
AU  - Feroz, Sainab
AU  - Abu Dabous, Saleh
TI  - UAV-Based Remote Sensing Applications for Bridge Condition Assessment
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - Deterioration of bridge infrastructure is a serious concern to transport and government agencies as it declines serviceability and reliability of bridges and jeopardizes public safety. Maintenance and rehabilitation needs of bridge infrastructure are periodically monitored and assessed, typically every two years. Existing inspection techniques, such as visual inspection, are time-consuming, subjective, and often incomplete. Non-destructive testing (NDT) using Unmanned Aerial Vehicles (UAVs) have been gaining momentum for bridge monitoring in the recent years, particularly due to enhanced accessibility and cost efficiency, deterrence of traffic closure, and improved safety during inspection. The primary objective of this study is to conduct a comprehensive review of the application of UAVs in bridge condition monitoring, used in conjunction with remote sensing technologies. Remote sensing technologies such as visual imagery, infrared thermography, LiDAR, and other sensors, integrated with UAVs for data acquisition are analyzed in depth. This study compiled sixty-five journal and conference papers published in the last two decades scrutinizing NDT-based UAV systems. In addition to comparison of stand-alone and integrated NDT-UAV methods, the facilitation of bridge inspection using UAVs is thoroughly discussed in the present article in terms of ease of use, accuracy, cost-efficiency, employed data collection tools, and simulation platforms. Additionally, challenges and future perspectives of the reviewed UAV-NDT technologies are highlighted.
KW  - unmanned aerial vehicles
KW  - drones
KW  - condition monitoring
KW  - remote sensing
KW  - non-destructive testing
KW  - remotely piloted aircraft
DO  - 10.3390/rs13091809
TY  - EJOU
AU  - Muharam, Farrah M.
AU  - Nurulhuda, Khairudin
AU  - Zulkafli, Zed
AU  - Tarmizi, Mohamad A.
AU  - Abdullah, Asniyani N.
AU  - Che Hashim, Muhamad F.
AU  - Mohd Zad, Siti N.
AU  - Radhwane, Derraz
AU  - Ismail, Mohd R.
TI  - UAV- and Random-Forest-AdaBoost (RFA)-Based Estimation of Rice Plant Traits
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 5
SN  - 2073-4395

AB  - Rapid, accurate and inexpensive methods are required to analyze plant traits throughout all crop growth stages for plant phenotyping. Few studies have comprehensively evaluated plant traits from multispectral cameras onboard UAV platforms. Additionally, machine learning algorithms tend to over- or underfit data and limited attention has been paid to optimizing their performance through an ensemble learning approach. This study aims to (1) comprehensively evaluate twelve rice plant traits estimated from aerial unmanned vehicle (UAV)-based multispectral images and (2) introduce Random Forest AdaBoost (RFA) algorithms as an optimization approach for estimating plant traits. The approach was tested based on a farmer’s field in Terengganu, Malaysia, for the off-season from February to June 2018, involving five rice cultivars and three nitrogen (N) rates. Four bands, thirteen indices and Random Forest-AdaBoost (RFA) regression models were evaluated against the twelve plant traits according to the growth stages. Among the plant traits, plant height, green leaf and storage organ biomass, and foliar nitrogen (N) content were estimated well, with a coefficient of determination (R2) above 0.80. In comparing the bands and indices, red, Normalized Difference Vegetation Index (NDVI), Ratio Vegetation Index (RVI), Red-Edge Wide Dynamic Range Vegetation Index (REWDRVI) and Red-Edge Soil Adjusted Vegetation Index (RESAVI) were remarkable in estimating all plant traits at tillering, booting and milking stages with R2 values ranging from 0.80–0.99 and root mean square error (RMSE) values ranging from 0.04–0.22. Milking was found to be the best growth stage to conduct estimations of plant traits. In summary, our findings demonstrate that an ensemble learning approach can improve the accuracy as well as reduce under/overfitting in plant phenotyping algorithms.
KW  - rice
KW  - phenotyping
KW  - multispectral images
KW  - machine learning
KW  - boosting algorithm
DO  - 10.3390/agronomy11050915
TY  - EJOU
AU  - Chen, Shuo
AU  - Zhang, Kefei
AU  - Zhao, Yindi
AU  - Sun, Yaqin
AU  - Ban, Wei
AU  - Chen, Yu
AU  - Zhuang, Huifu
AU  - Zhang, Xuewei
AU  - Liu, Jinxiang
AU  - Yang, Tao
TI  - An Approach for Rice Bacterial Leaf Streak Disease Segmentation and Disease Severity Estimation
T2  - Agriculture

PY  - 2021
VL  - 11
IS  - 5
SN  - 2077-0472

AB  - Rice bacterial leaf streak (BLS) is a serious disease in rice leaves and can seriously affect the quality and quantity of rice growth. Automatic estimation of disease severity is a crucial requirement in agricultural production. To address this, a new method (termed BLSNet) was proposed for rice and BLS leaf lesion recognition and segmentation based on a UNet network in semantic segmentation. An attention mechanism and multi-scale extraction integration were used in BLSNet to improve the accuracy of lesion segmentation. We compared the performance of the proposed network with that of DeepLabv3+ and UNet as benchmark models used in semantic segmentation. It was found that the proposed BLSNet model demonstrated higher segmentation and class accuracy. A preliminary investigation of BLS disease severity estimation was carried out based on our BLS segmentation results, and it was found that the proposed BLSNet method has strong potential to be a reliable automatic estimator of BLS disease severity.
KW  - rice bacterial leaf streak
KW  - leaf disease recognition
KW  - lesion segmentation
KW  - semantic segmentation
KW  - deep learning
KW  - convolutional neural network
KW  - disease severity estimation
DO  - 10.3390/agriculture11050420
TY  - EJOU
AU  - Alshawabkeh, Yahya
AU  - Baik, Ahmad
AU  - Miky, Yehia
TI  - Integration of Laser Scanner and Photogrammetry for Heritage BIM Enhancement
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 5
SN  - 2220-9964

AB  - Digital 3D capture and reliable reproduction of architectural features is the first and most difficult step towards defining a heritage BIM. Three-dimensional digital survey technologies, such as TLS and photogrammetry, enable experts to scan buildings with a new level of detail. Challenges in the tracing of parametric objects in a TLS point cloud include the reconstruction of occluded parts, measurement of uncertainties relevant to surface reflectivity, and edge detection and location. In addition to image-based techniques being considered cost effective, highly flexible, and efficient in producing a high-quality 3D textured model, they also provide a better interpretation of surface linear characteristics. This article addresses an architecture survey workflow using photogrammetry and TLS to optimize a point cloud that is sufficient for a reliable HBIM. Fusion-based workflows were proposed during the recording of two heritage sites—the Matbouli House Museum in Historic Jeddah, a UNESCO World Heritage Site; and Asfan Castle. In the Matbouli House Museum building, which is rich with complex architectural features, multi-sensor recording was implemented at different resolutions and levels of detail. The TLS data were used to reconstruct the basic shape of the main structural elements, while the imagery’s superior radiometric data and accessibility were effectively used to enhance the TLS point clouds for improving the geometry, data interpretation, and parametric tracing of irregular objects in the facade. Furthermore, in the workflow that is considered to be the ragged terrain of the Castle of Asfan, here, the TLS point cloud was supplemented with UAV data in the upper building zones where the shadow data originated. Both datasets were registered using an ICP algorithm to scale the photogrammetric data and define their actual position in the construction system. The hybrid scans were imported and processed in the BIM environment. The building components were segmented and classified into regular and irregular surfaces, in order to perform detailed building information modeling of the architectural elements. The proposed workflows demonstrated an appropriate performance in terms of reliable and complete BIM mapping in the complex structures.
KW  - HBIM
KW  - laser scanner
KW  - photogrammetry
KW  - data fusion
KW  - multi-resolution data
DO  - 10.3390/ijgi10050316
TY  - EJOU
AU  - Yoon, Sugjoon
AU  - Shin, Dongcho
AU  - Choi, Younghoon
AU  - Park, Kyungtae
TI  - Development of a Flexible and Expandable UTM Simulator Based on Open Sources and Platforms
T2  - Aerospace

PY  - 2021
VL  - 8
IS  - 5
SN  - 2226-4310

AB  - In order to study air traffic control of UAS’s (Unmanned Aerial Systems) in very low altitudes, the UTM (UAS Traffic Management) simulator has to be as flexible and expandable as other research simulators because relevant technologies and regulations are not matured enough at this stage. Available approaches using open sources and platforms are investigated to be used in the UTM simulator. The fundamental rationale for selection is availability of necessary resources to build a UTM simulator. Integration efforts to build a UTM simulator are elaborated, using Ardupilot, MavProxi, Cesium, and VWorld, which are selected from the thorough field study. Design requirements of a UTM simulator are determined by analyzing UTM services defined by NASA (National Aeronautics and Space Administration) and Eurocontrol. The UTM simulator, named eUTM, is composed of three components: UOS (UTM Operating System), UTM, and multiple GCSs (Ground Control Stations). GCSs are responsible for generation of flight paths of various UASs. UTM component copies functions of a real UTM such as monitoring and controlling air spaces. UOS provides simulation of environment such as weather, and controls the whole UTM simulator system. UOS also generates operation scenarios of UTM, and resides on the same UTM computer as an independent process. Two GCS simulators are connected to the UTM simulator in the present configuration, but the UTM simulator can be expanded to include up to 10 GCS simulators in the present design. In order to demonstrate the flexibility and expandability of eUTM simulator, several operation scenarios are realized and typical deconfliction scenarios among them are tested with a deconfliction algorithm. During the study, some limits are identified with applied open sources and platforms, which have to be resolved in order to obtain a flexible and expandable UTM simulator supporting relevant studies. Most of them are related to interfacing individual sources and platforms which use different program languages and communication drivers.
KW  - UTM
KW  - open sources and platforms
KW  - Ardupilot and MavProxi
KW  - design requirements
KW  - integration efforts
DO  - 10.3390/aerospace8050133
TY  - EJOU
AU  - Mahmud, Md S.
AU  - Zahid, Azlan
AU  - He, Long
AU  - Martin, Phillip
TI  - Opportunities and Possibilities of Developing an Advanced Precision Spraying System for Tree Fruits
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 9
SN  - 1424-8220

AB  - Reducing risk from pesticide applications has been gaining serious attention in the last few decades due to the significant damage to human health, environment, and ecosystems. Pesticide applications are an essential part of current agriculture, enhancing cultivated crop productivity and quality and preventing losses of up to 45% of the world food supply. However, inappropriate and excessive use of pesticides is a major rising concern. Precision spraying addresses these concerns by precisely and efficiently applying pesticides to the target area and substantially reducing pesticide usage while maintaining efficacy at preventing crop losses. This review provides a systematic summary of current technologies used for precision spraying in tree fruits and highlights their potential, briefly discusses factors affecting spraying parameters, and concludes with possible solutions to reduce excessive agrochemical uses. We conclude there is a critical need for appropriate sensing techniques that can accurately detect the target. In addition, air jet velocity, travel speed, wind speed and direction, droplet size, and canopy characteristics need to be considered for successful droplet deposition by the spraying system. Assessment of terrain is important when field elevation has significant variability. Control of airflow during spraying is another important parameter that needs to be considered. Incorporation of these variables in precision spraying systems will optimize spray decisions and help reduce excessive agrochemical applications.
KW  - crop protection
KW  - canopy detection
KW  - canopy density
KW  - canopy volume
KW  - deep learning
KW  - machine vision
KW  - sensing
DO  - 10.3390/s21093262
TY  - EJOU
AU  - Guffogg, Jenna A.
AU  - Soto-Berelov, Mariela
AU  - Jones, Simon D.
AU  - Bellman, Chris J.
AU  - Lavers, Jennifer L.
AU  - Skidmore, Andrew K.
TI  - Towards the Spectral Mapping of Plastic Debris on Beaches
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - Floating and washed ashore marine plastic debris (MPD) is a growing environmental challenge. It has become evident that secluded locations including the Arctic, Antarctic, and remote islands are being impacted by plastic pollution generated thousands of kilometers away. Optical remote sensing of MPD is an emerging field that can aid in monitoring remote environments where in-person observation and data collection is not always feasible. Here we evaluate MPD spectral features in the visible to shortwave infrared regions for detecting varying quantities of MPD that have accumulated on beaches using a spectroradiometer. Measurements were taken from a range of in situ MPD accumulations ranging from 0.08% to 7.94% surface coverage. Our results suggest that spectral absorption features at 1215 nm and 1732 nm are useful for detecting varying abundance levels of MPD in a complex natural environment, however other absorption features at 931 nm, 1045 nm and 2046 nm could not detect in situ MPD. The reflectance of some in situ MPD accumulations was statistically different from samples that only contained organic debris and sand between 1.56% and 7.94% surface cover; however other samples with similar surface cover did not have reflectance that was statistically different from samples containing no MPD. Despite MPD being detectable against a background of sand and organic beach debris, a clear relationship between the surface cover of MPD and the strength of key absorption features could not be established. Additional research is needed to advance our understanding of the factors, such as type of MPD assemblage, that contribute to the bulk reflectance of MPD contaminated landscapes.
KW  - Cocos (Keeling) Islands
KW  - plastic debris
KW  - proximal remote sensing
KW  - macroplastics
KW  - spectral absorption features
KW  - shortwave infrared
KW  - spectroscopy
KW  - hyperspectral
DO  - 10.3390/rs13091850
TY  - EJOU
AU  - Jin, Xing
AU  - Tang, Ping
AU  - Zhang, Zheng
TI  - Sequence Image Datasets Construction via Deep Convolution Networks
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - Remote-sensing time-series datasets are significant for global change research and a better understanding of the Earth. However, remote-sensing acquisitions often provide sparse time series due to sensor resolution limitations and environmental factors such as cloud noise for optical data. Image transformation is the method that is often used to deal with this issue. This paper considers the deep convolution networks to learn the complex mapping between sequence images, called adaptive filter generation network (AdaFG), convolution long short-term memory network (CLSTM), and cycle-consistent generative adversarial network (CyGAN) for construction of sequence image datasets. AdaFG network uses a separable 1D convolution kernel instead of 2D kernels to capture the spatial characteristics of input sequence images and then is trained end-to-end using sequence images. CLSTM network can map between different images using the state information of multiple time-series images. CyGAN network can map an image from a source domain to a target domain without additional information. Our experiments, which were performed with unmanned aerial vehicle (UAV) and Landsat-8 datasets, show that the deep convolution networks are effective to produce high-quality time-series image datasets, and the data-driven deep convolution networks can better simulate complex and diverse nonlinear data information.
KW  - sequence image datasets
KW  - adaptive filter generation network
KW  - convolution long short-term memory network
KW  - cycle-consistent generative adversarial network
KW  - UAV dataset
KW  - Landsat-8 dataset
DO  - 10.3390/rs13091853
TY  - EJOU
AU  - Cheng, Zhenzhen
AU  - Qi, Lijun
AU  - Cheng, Yifan
TI  - Cherry Tree Crown Extraction from Natural Orchard Images with Complex Backgrounds
T2  - Agriculture

PY  - 2021
VL  - 11
IS  - 5
SN  - 2077-0472

AB  - Highly effective pesticide applications require a continual adjustment of the pesticide spray flow rate that attends to different canopy characterizations. Real-time image processing with rapid target detection and data-processing technologies is vital for precision pesticide application. However, the extant studies do not provide an efficient and reliable method of extracting individual trees with irregular tree-crown shapes and complicated backgrounds. This paper on our study proposes a Mahalanobis distance and conditional random field (CRF)-based segmentation model to extract cherry trees accurately in a natural orchard environment. This study computed Mahalanobis distance from the image’s color, brightness and location features to acquire an initial classification of the canopy and background. A CRF was then created by using the Mahalanobis distance calculations as unary potential energy and the Gaussian kernel function based on the image color and pixels distance as binary potential energy. Finally, the study completed image segmentation using mean-field approximation. The results show that the proposed method displays a higher accuracy rate than the traditional algorithms K-means and GrabCut algorithms and lower labeling and training costs than the deep learning algorithm DeepLabv3+, with 92.1%, 94.5% and 93.3% of the average P, R and F1-score, respectively. Moreover, experiments on datasets with different overlap conditions and image acquisition times, as well as in different years and seasons, show that this method performs well under complex background conditions, with an average F1-score higher than 87.7%.
KW  - agricultural computer vision
KW  - tree-crown segmentation
KW  - complex scene
KW  - natural orchard environment
DO  - 10.3390/agriculture11050431
TY  - EJOU
AU  - Bashir, Syed M.
AU  - Wang, Yi
TI  - Small Object Detection in Remote Sensing Images with Residual Feature Aggregation-Based Super-Resolution and Object Detector Network
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - This paper deals with detecting small objects in remote sensing images from satellites or any aerial vehicle by utilizing the concept of image super-resolution for image resolution enhancement using a deep-learning-based detection method. This paper provides a rationale for image super-resolution for small objects by improving the current super-resolution (SR) framework by incorporating a cyclic generative adversarial network (GAN) and residual feature aggregation (RFA) to improve detection performance. The novelty of the method is threefold: first, a framework is proposed, independent of the final object detector used in research, i.e., YOLOv3 could be replaced with Faster R-CNN or any object detector to perform object detection; second, a residual feature aggregation network was used in the generator, which significantly improved the detection performance as the RFA network detected complex features; and third, the whole network was transformed into a cyclic GAN. The image super-resolution cyclic GAN with RFA and YOLO as the detection network is termed as SRCGAN-RFA-YOLO, which is compared with the detection accuracies of other methods. Rigorous experiments on both satellite images and aerial images (ISPRS Potsdam, VAID, and Draper Satellite Image Chronology datasets) were performed, and the results showed that the detection performance increased by using super-resolution methods for spatial resolution enhancement; for an IoU of 0.10, AP of 0.7867 was achieved for a scale factor of 16.
KW  - object detection in satellite images
KW  - image classification
KW  - vehicle detection
KW  - remote sensing
KW  - deep learning
KW  - generative adversarial networks
KW  - residual feature aggregation (RFA)
DO  - 10.3390/rs13091854
TY  - EJOU
AU  - Ioannou, Konstantinos
AU  - Myronidis, Dimitrios
TI  - Automatic Detection of Photovoltaic Farms Using Satellite Imagery and Convolutional Neural Networks
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 9
SN  - 2071-1050

AB  - The number of solar photovoltaic (PV) arrays in Greece has increased rapidly during the recent years. As a result, there is an increasing need for high quality updated information regarding the status of PV farms. This information includes the number of PV farms, power capacity and the energy generated. However, access to this data is obsolete, mainly due to the fact that there is a difficulty tracking PV investment status (from licensing to investment completion and energy production). This article presents a novel approach, which uses free access high resolution satellite imagery and a deep learning algorithm (a convolutional neural network—CNN) for the automatic detection of PV farms. Furthermore, in an effort to create an algorithm capable of generalizing better, all the current locations with installed PV farms (data provided from the Greek Energy Regulator Authority) in the Greek Territory (131,957 km2) were used. According to our knowledge this is the first time such an algorithm is used in order to determine the existence of PV farms and the results showed satisfying accuracy.
KW  - PV farms
KW  - deep learning
KW  - satellite imagery
KW  - CNN
KW  - automatic detection
DO  - 10.3390/su13095323
TY  - EJOU
AU  - Pozzer, Sandra
AU  - Dalla Rosa, Francisco
AU  - Pravia, Zacarias M.
AU  - Rezazadeh Azar, Ehsan
AU  - Maldague, Xavier
TI  - Long-Term Numerical Analysis of Subsurface Delamination Detection in Concrete Slabs via Infrared Thermography
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 10
SN  - 2076-3417

AB  - One of the concerns about the use of passive Infrared Thermography (IRT) for structural health monitoring (SHM) is the determination of a favorable period to conduct the inspections. This paper investigates the use of numerical simulations to find appropriate periods for IRT-based detection of subsurface damages in concrete bridge slabs under passive heating along a 1 year of time span. A model was built using the Finite Element Method (FEM) and calibrated using the results of a set of thermographic field inspections on a concrete slab sample. The results showed that the numerical simulation properly reproduced the experimental thermographic measurements of the concrete structure under passive heating, allowing the analysis to be extended for a longer testing period. The long-term FEM results demonstrated that the months of spring and summer are the most suitable for passive IRT inspections in this study, with around 17% more detections compared to the autumn and winter periods in Brazil. By enhancing the possibility of using FEM beyond the design stage, we demonstrate that this computation tool can provide support to long-term SHM.
KW  - infrared thermography
KW  - concrete bridges
KW  - non-destructive test
KW  - delamination
KW  - finite element method
DO  - 10.3390/app11104323
TY  - EJOU
AU  - Park, Gun
AU  - Lee, Jae H.
AU  - Yoon, Hyungchul
TI  - Semantic Structure from Motion for Railroad Bridges Using Deep Learning
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 10
SN  - 2076-3417

AB  - Current maintenance practices consume significant time, cost, and manpower. Thus, a new technique for maintenance is required. Construction information technologies, including building information modeling (BIM), have recently been applied to the field to carry out systematic and productive planning, design, construction, and maintenance. Although BIM is increasingly being applied to new structures, its application to existing structures has been limited. To apply BIM to an existing structure, a three-dimensional (3D) model of the structure that accurately represents the as-is status should be constructed and each structural component should be specified manually. This study proposes a method that constructs a 3D model and specifies the structural component automatically using photographic data with a camera installed on an unmanned aerial vehicle. This procedure is referred to as semantic structure from motion because it constructs a 3D point cloud model together with semantic information. A validation test was carried out on a railroad bridge to validate the performance of the proposed system. The average precision, intersection over union, and BF scores were 80.87%, 66.66%, and 56.33%, respectively. The proposed method could improve the current scan-to-BIM procedure by generating the as-is 3D point cloud model by specifying the structural component automatically.
KW  - semantic structure from motion
KW  - deep learning
KW  - structural component classification
KW  - structure from motion
KW  - scan to building information modeling
DO  - 10.3390/app11104332
TY  - EJOU
AU  - Lama, Giuseppe F.
AU  - Crimaldi, Mariano
AU  - Pasquino, Vittorio
AU  - Padulano, Roberta
AU  - Chirico, Giovanni B.
TI  - Bulk Drag Predictions of Riparian Arundo donax Stands through UAV-Acquired Multispectral Images
T2  - Water

PY  - 2021
VL  - 13
IS  - 10
SN  - 2073-4441

AB  - Estimating the main hydrodynamic features of real vegetated water bodies is crucial to assure a balance between their hydraulic conveyance and environmental quality. Riparian vegetation stands have a high impact on vegetated channels. The present work has the aim to integrate riparian vegetation’s reflectance indices and hydrodynamics of real vegetated water flows to assess the impact of riparian vegetation morphometry on bulk drag coefficients distribution along an abandoned vegetated drainage channel fully covered by 9–10 m high Arundo donax (commonly known as giant reed) stands, starting from flow average velocities measurements at 30 cross-sections identified along the channel. A map of riparian vegetation cover was obtained through digital processing of Unnamed Aerial Vehicle (UAV)-acquired multispectral images, which represent a fast way to observe riparian plants’ traits in hardly accessible areas such as vegetated water bodies in natural conditions. In this study, the portion of riparian plants effectively interacting with flow was expressed in terms of ground-based Leaf Area Index measurements (LAI), which easily related to UAV-based Normalized Difference Vegetation Index (NDVI). The comparative analysis between Arundo donax stands NDVI and LAI map enabled the analysis of the impact of UAV-acquired multispectral imagery on bulk drag predictions along the vegetated drainage channel.
KW  - ecohydraulics
KW  - bulk drag coefficients
KW  - vegetated flows
KW  - Arundo donax stands
KW  - multispectral images
KW  - UAV
DO  - 10.3390/w13101333
TY  - EJOU
AU  - Mattivi, Pietro
AU  - Pappalardo, Salvatore E.
AU  - Nikolić, Nebojša
AU  - Mandolesi, Luca
AU  - Persichetti, Antonio
AU  - De Marchi, Massimo
AU  - Masin, Roberta
TI  - Can Commercial Low-Cost Drones and Open-Source GIS Technologies Be Suitable for Semi-Automatic Weed Mapping for Smart Farming? A Case Study in NE Italy
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 10
SN  - 2072-4292

AB  - Weed management is a crucial issue in agriculture, resulting in environmental in-field and off-field impacts. Within Agriculture 4.0, adoption of UASs combined with spatially explicit approaches may drastically reduce doses of herbicides, increasing sustainability in weed management. However, Agriculture 4.0 technologies are barely adopted in small-medium size farms. Recently, small and low-cost UASs, together with open-source software packages, may represent a low-cost spatially explicit system to map weed distribution in crop fields. The general aim is to map weed distribution by a low-cost UASs and a replicable workflow, completely based on open GIS software and algorithms: OpenDroneMap, QGIS, SAGA and OpenCV classification algorithms. Specific objectives are: (i) testing a low-cost UAS for weed mapping; (ii) assessing open-source packages for semi-automatic weed classification; (iii) performing a sustainable management scenario by prescription maps. Results showed high performances along the whole process: in orthomosaic generation at very high spatial resolution (0.01 m/pixel), in testing weed detection (Matthews Correlation Coefficient: 0.67–0.74), and in the production of prescription maps, reducing herbicide treatment to only 3.47% of the entire field. This study reveals the feasibility of low-cost UASs combined with open-source software, enabling a spatially explicit approach for weed management in small-medium size farmlands.
KW  - site-specific weed management
KW  - precision farming
KW  - OpenDroneMap
KW  - open photogrammetry
KW  - open-source mapping
DO  - 10.3390/rs13101869
TY  - EJOU
AU  - Duarte, Lia
AU  - Teodoro, Ana C.
AU  - Sousa, Joaquim J.
AU  - Pádua, Luís
TI  - QVigourMap: A GIS Open Source Application for the Creation of Canopy Vigour Maps
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 5
SN  - 2073-4395

AB  - In a precision agriculture context, the amount of geospatial data available can be difficult to interpret in order to understand the crop variability within a given terrain parcel, raising the need for specific tools for data processing and analysis. This is the case for data acquired from Unmanned Aerial Vehicles (UAV), in which the high spatial resolution along with data from several spectral wavelengths makes data interpretation a complex process regarding vegetation monitoring. Vegetation Indices (VIs) are usually computed, helping in the vegetation monitoring process. However, a crop plot is generally composed of several non-crop elements, which can bias the data analysis and interpretation. By discarding non-crop data, it is possible to compute the vigour distribution for a specific crop within the area under analysis. This article presents QVigourMaps, a new open source application developed to generate useful outputs for precision agriculture purposes. The application was developed in the form of a QGIS plugin, allowing the creation of vigour maps, vegetation distribution maps and prescription maps based on the combination of different VIs and height information. Multi-temporal data from a vineyard plot and a maize field were used as case studies in order to demonstrate the potential and effectiveness of the QVigourMaps tool. The presented application can contribute to making the right management decisions by providing indicators of crop variability, and the outcomes can be used in the field to apply site-specific treatments according to the levels of vigour.
KW  - precision agriculture
KW  - multispectral imagery
KW  - variable rate
KW  - precision viticulture
KW  - GIS
DO  - 10.3390/agronomy11050952
TY  - EJOU
AU  - Quan, Longzhe
AU  - Wu, Bing
AU  - Mao, Shouren
AU  - Yang, Chunjie
AU  - Li, Hengda
TI  - An Instance Segmentation-Based Method to Obtain the Leaf Age and Plant Centre of Weeds in Complex Field Environments
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 10
SN  - 1424-8220

AB  - Leaf age and plant centre are important phenotypic information of weeds, and accurate identification of them plays an important role in understanding the morphological structure of weeds, guiding precise targeted spraying and reducing the use of herbicides. In this work, a weed segmentation method based on BlendMask is proposed to obtain the phenotypic information of weeds under complex field conditions. This study collected images from different angles (front, side, and top views) of three kinds of weeds (Solanum nigrum, barnyard grass (Echinochloa crus-galli), and Abutilon theophrasti Medicus) in a maize field. Two datasets (with and without data enhancement) and two backbone networks (ResNet50 and ResNet101) were replaced to improve model performance. Finally, seven evaluation indicators are used to evaluate the segmentation results of the model under different angles. The results indicated that data enhancement and ResNet101 as the backbone network could enhance the model performance. The F1 value of the plant centre is 0.9330, and the recognition accuracy of leaf age can reach 0.957. The mIOU value of the top view is 0.642. Therefore, deep learning methods can effectively identify weed leaf age and plant centre, which is of great significance for variable spraying.
KW  - weeds
KW  - phenotype
KW  - deep learning
KW  - image segmentation
DO  - 10.3390/s21103389
TY  - EJOU
AU  - Li, Jing
AU  - Liu, Yong
AU  - Zhang, Yindan
AU  - Zhang, Yang
TI  - Cascaded Attention DenseUNet (CADUNet) for Road Extraction from Very-High-Resolution Images
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 5
SN  - 2220-9964

AB  - The use of very-high-resolution images to extract urban, suburban and rural roads has important application value. However, it is still a problem to effectively extract the road area occluded by roadside tree canopy or high-rise buildings to maintain the integrity of the extracted road area, the smoothness of the sideline and the connectivity of the road network. This paper proposes an innovative Cascaded Attention DenseUNet (CADUNet) semantic segmentation model by embedding two attention modules, such as global attention and core attention modules, in the DenseUNet framework. First, a set of cascaded global attention modules are introduced to obtain the contextual information of the road; secondly, a set of cascaded core attention modules are embedded to ensure that the road information is transmitted to the greatest extent among the dense blocks in the network, and further assist the global attention module in acquiring multi-scale road information, thereby improving the connectivity of the road network while restoring the integrity of the road area shaded by the tree canopy and high-rise buildings. Based on binary cross entropy, an adaptive loss function is proposed for network parameter tuning. Experiments on the Massachusetts road dataset and the DeepGlobe-CVPR 2018 road dataset show that this semantic segmentation model can effectively extract the road area shaded by tree canopy and improve the connectivity of the road network.
KW  - deep learning
KW  - road
KW  - DenseUNet
KW  - attention module
KW  - semantic segmentation
KW  - remote sensing
DO  - 10.3390/ijgi10050329
TY  - EJOU
AU  - Liu, Boda
AU  - Yang, Bin
AU  - Xiao, Jianzhuang
AU  - Zhu, Dayu
AU  - Zhang, Binghan
AU  - Wang, Zhichen
AU  - Dong, Miaosi
TI  - Review of Optimization Dynamically Applied in the Construction and the Application Potential of ICT
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 10
SN  - 2071-1050

AB  - Currently, construction projects are getting more complex, applying more information and communication technologies (ICT), while few studies use real-time data to dynamically optimize construction. The purpose of this article is to study the current development status of the optimization applied dynamically in the construction phase and their potential for applying real data collected by ICT. This article reviews 72 relevant optimization methods and identified some of the ICT research studies that can provide them with dynamic data. The dynamic triggering mode of each research is first analyzed, then its dynamic way, dynamic data, data resource, optimization object, and method are identified and formulated. The results reveal the great value of dynamic optimization in dealing with the complicated and uncertain contextual conditions in construction. Different dynamic triggering modes have different affinities with real data. Then, through the analysis of ICT articles, the huge potential of these dynamic optimization methods in applying real data is shown. This paper points out the most practical dynamic mode for engineers or managers to continuously apply optimization methods to solve dynamic problems in construction, and put forward scientific questions for related researchers: How does one combine ICT with the event dynamics or uncertain parameters? Based on this, the research gap of this area is identified a conceptual solution is proposed.
KW  - optimization
KW  - construction
KW  - information and communication technology (ICT)
KW  - scheduling
KW  - construction planning
KW  - building information modelling (BIM)
DO  - 10.3390/su13105478
TY  - EJOU
AU  - Ostrowski, Bartłomiej
AU  - Pióro, Michał
AU  - Tomaszewski, Artur
TI  - Multicast Traffic Throughput Maximization through Joint Dynamic Modulation and Coding Schemes Assignment, and Transmission Power Control in Wireless Sensor Networks
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 10
SN  - 1424-8220

AB  - The paper concerns multicast packet traffic throughput maximization in multi-hop wireless sensor networks with time division multiple access to radio channel. We assume that the modulation and coding schemes (MCSs) that are used by the (broadcasting) nodes as well as the transmission power of the nodes are adjustable. This leads to the main research question studied in this paper: to what extent traffic throughput can be increased by proper MCSs assignment and transmission power control (TPC) at the nodes? To answer this question, we introduce mixed-integer programming formulations for joint MCSs assignment and TPC optimization, together with a solution algorithm. Finally, we present a numerical study illustrating the considerations of the paper. The numerical results show a significant gain being achieved by proper MCSs assignment, which is further increased by applying TPC.
KW  - wireless sensor networks
KW  - multicast traffic
KW  - throughput maximization
KW  - transmission scheduling
KW  - TDMA
KW  - transmission power control
KW  - IoT
KW  - MCS
KW  - mixed-integer programming
DO  - 10.3390/s21103411
TY  - EJOU
AU  - Burdziakowski, Pawel
AU  - Zakrzewska, Angelika
TI  - A New Adaptive Method for the Extraction of Steel Design Structures from an Integrated Point Cloud
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 10
SN  - 1424-8220

AB  - The continuous and intensive development of measurement technologies for reality modelling with appropriate data processing algorithms is currently being observed. The most popular methods include remote sensing techniques based on reflected-light digital cameras, and on active methods in which the device emits a beam. This research paper presents the process of data integration from terrestrial laser scanning (TLS) and image data from an unmanned aerial vehicle (UAV) that was aimed at the spatial mapping of a complicated steel structure, and a new automatic structure extraction method. We proposed an innovative method to minimize the data size and automatically extract a set of points (in the form of structural elements) that is vital from the perspective of engineering and comparative analyses. The outcome of the research was a complete technology for the acquisition of precise information with regard to complex and high steel structures. The developed technology includes such elements as a data integration method, a redundant data elimination method, integrated photogrammetric data filtration and a new adaptive method of structure edge extraction. In order to extract significant geometric structures, a new automatic and adaptive algorithm for edge extraction from a random point cloud was developed and presented herein. The proposed algorithm was tested using real measurement data. The developed algorithm is able to realistically reduce the amount of redundant data and correctly extract stable edges representing the geometric structures of a studied object without losing important data and information. The new algorithm automatically self-adapts to the received data. It does not require any pre-setting or initial parameters. The detection threshold is also adaptively selected based on the acquired data.
KW  - photogrammetry
KW  - TLS
KW  - UAV
KW  - steel structure
KW  - monitoring
KW  - integration
KW  - fusion
DO  - 10.3390/s21103416
TY  - EJOU
AU  - Jo, Yongwon
AU  - Lee, Soobin
AU  - Lee, Youngjae
AU  - Kahng, Hyungu
AU  - Park, Seonghun
AU  - Bae, Seounghun
AU  - Kim, Minkwan
AU  - Han, Sungwon
AU  - Kim, Seoungbum
TI  - Semantic Segmentation of Cabbage in the South Korea Highlands with Images by Unmanned Aerial Vehicles
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 10
SN  - 2076-3417

AB  - Identifying agricultural fields that grow cabbage in the highlands of South Korea is critical for accurate crop yield estimation. Only grown for a limited time during the summer, highland cabbage accounts for a significant proportion of South Korea’s annual cabbage production. Thus, it has a profound effect on the formation of cabbage prices. Traditionally, labor-extensive and time-consuming field surveys are manually carried out to derive agricultural field maps of the highlands. Recently, high-resolution overhead images of the highlands have become readily available with the rapid development of unmanned aerial vehicles (UAV) and remote sensing technology. In addition, deep learning-based semantic segmentation models have quickly advanced by recent improvements in algorithms and computational resources. In this study, we propose a semantic segmentation framework based on state-of-the-art deep learning techniques to automate the process of identifying cabbage cultivation fields. We operated UAVs and collected 2010 multispectral images under different spatiotemporal conditions to measure how well semantic segmentation models generalize. Next, we manually labeled these images at a pixel-level to obtain ground truth labels for training. Our results demonstrate that our framework performs well in detecting cabbage fields not only in areas included in the training data but also in unseen areas not included in the training data. Moreover, we analyzed the effects of infrared wavelengths on the performance of identifying cabbage fields. Based on the results of our framework, we expect agricultural officials to reduce time and manpower when identifying information about highlands cabbage fields by replacing field surveys.
KW  - land-cover classification
KW  - semantic segmentation
KW  - unmanned aerial vehicles
DO  - 10.3390/app11104493
TY  - EJOU
AU  - Saha, Subrata
AU  - Vasegaard, Alex E.
AU  - Nielsen, Izabela
AU  - Hapka, Aneta
AU  - Budzisz, Henryk
TI  - UAVs Path Planning under a Bi-Objective Optimization Framework for Smart Cities
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 10
SN  - 2079-9292

AB  - Unmanned aerial vehicles (UAVs) have been used extensively for search and rescue operations, surveillance, disaster monitoring, attacking terrorists, etc. due to their growing advantages of low-cost, high maneuverability, and easy deployability. This study proposes a mixed-integer programming model under a multi-objective optimization framework to design trajectories that enable a set of UAVs to execute surveillance tasks. The first objective maximizes the cumulative probability of target detection to aim for mission planning success. The second objective ensures minimization of cumulative path length to provide a higher resource utilization goal. A two-step variable neighborhood search (VNS) algorithm is offered, which addresses the combinatorial optimization issue for determining the near-optimal sequence for cell visiting to reach the target. Numerical experiments and simulation results are evaluated in numerous benchmark instances. Results demonstrate that the proposed approach can favorably support practical deployability purposes.
KW  - unmanned aerial vehicles (UAVs)
KW  - multi-objective optimization
KW  - integer programming
KW  - GLPK
KW  - variable neighborhood search
KW  - search and rescue
DO  - 10.3390/electronics10101193
TY  - EJOU
AU  - Chaidas, Konstantinos
AU  - Tataris, George
AU  - Soulakellis, Nikolaos
TI  - Seismic Damage Semantics on Post-Earthquake LOD3 Building Models Generated by UAS
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 5
SN  - 2220-9964

AB  - In a post-earthquake scenario, the semantic enrichment of 3D building models with seismic damage is crucial from the perspective of disaster management. This paper aims to present the methodology and the results for the Level of Detail 3 (LOD3) building modelling (after an earthquake) with the enrichment of the semantics of the seismic damage based on the European Macroseismic Scale (EMS-98). The study area is the Vrisa traditional settlement on the island of Lesvos, Greece, which was affected by a devastating earthquake of Mw = 6.3 on 12 June 2017. The applied methodology consists of the following steps: (a) unmanned aircraft systems (UAS) nadir and oblique images are acquired and photogrammetrically processed for 3D point cloud generation, (b) 3D building models are created based on 3D point clouds and (c) 3D building models are transformed into a LOD3 City Geography Markup Language (CityGML) standard with enriched semantics of the related seismic damage of every part of the building (walls, roof, etc.). The results show that in following this methodology, CityGML LOD3 models can be generated and enriched with buildings’ seismic damage. These models can assist in the decision-making process during the recovery phase of a settlement as well as be the basis for its monitoring over time. Finally, these models can contribute to the estimation of the reconstruction cost of the buildings.
KW  - post-earthquake
KW  - LOD3
KW  - CityGML
KW  - semantics
KW  - 3D building models
KW  - 3D point cloud
KW  - UAS
KW  - seismic damage
DO  - 10.3390/ijgi10050345
TY  - EJOU
AU  - Chen, Fang
AU  - Wang, Ning
AU  - Yu, Bo
AU  - Qin, Yuchu
AU  - Wang, Lei
TI  - A Strategy of Parallel Seed-Based Image Segmentation Algorithms for Handling Massive Image Tiles over the Spark Platform
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 10
SN  - 2072-4292

AB  - The volume of remote sensing images continues to grow as image sources become more diversified and with increasing spatial and spectral resolution. The handling of such large-volume datasets, which exceed available CPU memory, in a timely and efficient manner is becoming a challenge for single machines. The distributed cluster provides an effective solution with strong calculation power. There has been an increasing number of big data technologies that have been adopted to deal with large images using mature parallel technology. However, since most commercial big data platforms are not specifically developed for the remote sensing field, two main issues exist in processing large images with big data platforms using a distributed cluster. On the one hand, the quantities and categories of official algorithms used to process remote sensing images in big data platforms are limited compared to large amounts of sequential algorithms. On the other hand, the sequential algorithms employed directly to process large images in parallel over a distributed cluster may lead to incomplete objects in the tile edges and the generation of large communication volumes at the shuffle stage. It is, therefore, necessary to explore the distributed strategy and adapt the sequential algorithms over the distributed cluster. In this research, we employed two seed-based image segmentation algorithms to construct a distributed strategy based on the Spark platform. The proposed strategy focuses on modifying the incomplete objects by processing border areas and reducing the communication volume to a reasonable size by limiting the auxiliary bands and the buffer size to a small range during the shuffle stage. We calculated the F-measure and execution time to evaluate the accuracy and execution efficiency. The statistical data reveal that both segmentation algorithms maintained high accuracy, as achieved in the reference image segmented in the sequential way. Moreover, generally the strategy took less execution time compared to significantly larger auxiliary bands and buffer sizes. The proposed strategy can modify incomplete objects, with execution time being twice as fast as the strategies that do not employ communication volume reduction in the distributed cluster.
KW  - segmentation algorithm
KW  - distributed computation
KW  - image processing
KW  - spark platform
KW  - digital disaster reduction
DO  - 10.3390/rs13101969
TY  - EJOU
AU  - Wang, Lin
AU  - Zhou, Yuzhen
AU  - Hu, Qiao
AU  - Tang, Zhenghong
AU  - Ge, Yufeng
AU  - Smith, Adam
AU  - Awada, Tala
AU  - Shi, Yeyin
TI  - Early Detection of Encroaching Woody Juniperus virginiana and Its Classification in Multi-Species Forest Using UAS Imagery and Semantic Segmentation Algorithms
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 10
SN  - 2072-4292

AB  - Woody plant encroachment into grasslands ecosystems causes significantly ecological destruction and economic losses. Effective and efficient management largely benefits from accurate and timely detection of encroaching species at an early development stage. Recent advances in unmanned aircraft systems (UAS) enabled easier access to ultra-high spatial resolution images at a centimeter level, together with the latest machine learning based image segmentation algorithms, making it possible to detect small-sized individuals of target species at early development stage and identify them when mixed with other species. However, few studies have investigated the optimal practical spatial resolution of early encroaching species detection. Hence, we investigated the performance of four popular semantic segmentation algorithms (decision tree, DT; random forest, RF; AlexNet; and ResNet) on a multi-species forest classification case with UAS-collected RGB images in original and down-sampled coarser spatial resolutions. The objective of this study was to explore the optimal segmentation algorithm and spatial resolution for eastern redcedar (Juniperus virginiana, ERC) early detection and its classification within a multi-species forest context. To be specific, firstly, we implemented and compared the performance of the four semantic segmentation algorithms with images in the original spatial resolution (0.694 cm). The highest overall accuracy was 0.918 achieved by ResNet with a mean interaction over union at 85.0%. Secondly, we evaluated the performance of ResNet algorithm with images in down-sampled spatial resolutions (1 cm to 5 cm with 0.5 cm interval). When applied on the down-sampled images, ERC segmentation performance decreased with decreasing spatial resolution, especially for those images coarser than 3 cm spatial resolution. The UAS together with the state-of-the-art semantic segmentation algorithms provides a promising tool for early-stage detection and localization of ERC and the development of effective management strategies for mixed-species forest management.
KW  - forest classification
KW  - aggressive native species
KW  - invasive species
KW  - biodiversity
KW  - remote sensing
KW  - UAV
KW  - machine learning
KW  - deep learning
DO  - 10.3390/rs13101975
TY  - EJOU
AU  - Hamdi, Slim
AU  - Bouindour, Samir
AU  - Snoussi, Hichem
AU  - Wang, Tian
AU  - Abid, Mohamed
TI  - End-to-End Deep One-Class Learning for Anomaly Detection in UAV Video Stream
T2  - Journal of Imaging

PY  - 2021
VL  - 7
IS  - 5
SN  - 2313-433X

AB  - In recent years, the use of drones for surveillance tasks has been on the rise worldwide. However, in the context of anomaly detection, only normal events are available for the learning process. Therefore, the implementation of a generative learning method in an unsupervised mode to solve this problem becomes fundamental. In this context, we propose a new end-to-end architecture capable of generating optical flow images from original UAV images and extracting compact spatio-temporal characteristics for anomaly detection purposes. It is designed with a custom loss function as a sum of three terms, the reconstruction loss (Rl), the generation loss (Gl) and the compactness loss (Cl) to ensure an efficient classification of the “deep-one” class. In addition, we propose to minimize the effect of UAV motion in video processing by applying background subtraction on optical flow images. We tested our method on very complex datasets called the mini-drone video dataset, and obtained results surpassing existing techniques’ performances with an AUC of 85.3.
KW  - anomaly detection
KW  - UAV videos
KW  - deep one-class
DO  - 10.3390/jimaging7050090
TY  - EJOU
AU  - Krul, Sander
AU  - Pantos, Christos
AU  - Frangulea, Mihai
AU  - Valente, João
TI  - Visual SLAM for Indoor Livestock and Farming Using a Small Drone with a Monocular Camera: A Feasibility Study
T2  - Drones

PY  - 2021
VL  - 5
IS  - 2
SN  - 2504-446X

AB  - Real-time data collection and decision making with drones will play an important role in precision livestock and farming. Drones are already being used in precision agriculture. Nevertheless, this is not the case for indoor livestock and farming environments due to several challenges and constraints. These indoor environments are limited in physical space and there is the localization problem, due to GPS unavailability. Therefore, this work aims to give a step toward the usage of drones for indoor farming and livestock management. To investigate on the drone positioning in these workspaces, two visual simultaneous localization and mapping (VSLAM)—LSD-SLAM and ORB-SLAM—algorithms were compared using a monocular camera onboard a small drone. Several experiments were carried out in a greenhouse and a dairy farm barn with the absolute trajectory and the relative pose error being analyzed. It was found that the approach that suits best these workspaces is ORB-SLAM. This algorithm was tested by performing waypoint navigation and generating maps from the clustered areas. It was shown that aerial VSLAM could be achieved within these workspaces and that plant and cattle monitoring could benefit from using affordable and off-the-shelf drone technology.
KW  - farming
KW  - livestock
KW  - drones
KW  - unmanned aerial vehicles (UAV)
KW  - visual SLAM
DO  - 10.3390/drones5020041
TY  - EJOU
AU  - Liu, Chuanyang
AU  - Wu, Yiquan
AU  - Liu, Jingjing
AU  - Sun, Zuo
AU  - Xu, Huajie
TI  - Insulator Faults Detection in Aerial Images from High-Voltage Transmission Lines Based on Deep Learning Model
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 10
SN  - 2076-3417

AB  - Insulator fault detection is one of the essential tasks for high-voltage transmission lines’ intelligent inspection. In this study, a modified model based on You Only Look Once (YOLO) is proposed for detecting insulator faults in aerial images with a complex background. Firstly, aerial images with one fault or multiple faults are collected in diverse scenes, and then a novel dataset is established. Secondly, to increase feature reuse and propagation in the low-resolution feature layers, a Cross Stage Partial Dense YOLO (CSPD-YOLO) model is proposed based on YOLO-v3 and the Cross Stage Partial Network. The feature pyramid network and improved loss function are adopted to the CSPD-YOLO model, improving the accuracy of insulator fault detection. Finally, the proposed CSPD-YOLO model and compared models are trained and tested on the established dataset. The average precision of CSPD-YOLO model is 4.9% and 1.8% higher than that of YOLO-v3 and YOLO-v4, and the running time of CSPD-YOLO (0.011 s) model is slightly longer than that of YOLO-v3 (0.01 s) and YOLO-v4 (0.01 s). Compared with the excellent object detection models YOLO-v3 and YOLO-v4, the experimental results and analysis demonstrate that the proposed CSPD-YOLO model performs better in insulator fault detection from high-voltage transmission lines with a complex background.
KW  - fault detection
KW  - aerial image
KW  - complex background
KW  - deep learning
KW  - image processing
KW  - intelligent inspection
DO  - 10.3390/app11104647
TY  - EJOU
AU  - Tullu, Abera
AU  - Endale, Bedada
AU  - Wondosen, Assefinew
AU  - Hwang, Ho-Yon
TI  - Machine Learning Approach to Real-Time 3D Path Planning for Autonomous Navigation of Unmanned Aerial Vehicle
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 10
SN  - 2076-3417

AB  - The need for civilian use of Unmanned Aerial Vehicles (UAVs) has drastically increased in recent years. Their potential applications for civilian use include door-to-door package delivery, law enforcement, first aid, and emergency services in urban areas, which put the UAVs into obstacle collision risk. Therefore, UAVs are required to be equipped with sensors so as to acquire Artificial Intelligence (AI) to avoid potential risks during mission execution. The AI comes with intensive training of an on-board machine that is responsible to autonomously navigate the UAV. The training enables the UAV to develop humanoid perception of the environment it is to be navigating in. During the mission, this perception detects and localizes objects in the environment. It is based on this AI that this work proposes a real-time three-dimensional (3D) path planner that maneuvers the UAV towards destination through obstacle-free path. The proposed path planner has a heuristic sense of A⋆ algorithm, but requires no frontier nodes to be stored in a memory unlike A⋆. The planner relies on relative locations of detected objects (obstacles) and determines collision-free paths. This path planner is light-weight and hence a fast guidance method for real-time purposes. Its performance efficiency is proved through rigorous Software-In-The-Loop (SITL) simulations in constrained-environment and preliminary real flight tests.
KW  - vision-based navigation
KW  - cluttered environment
KW  - three-dimensional path planner
KW  - obstacle avoidance
KW  - machine learning
DO  - 10.3390/app11104706
TY  - EJOU
AU  - Mores, Antonia
AU  - Borrelli, Grazia M.
AU  - Laidò, Giovanni
AU  - Petruzzino, Giuseppe
AU  - Pecchioni, Nicola
AU  - Amoroso, Luca G.
AU  - Desiderio, Francesca
AU  - Mazzucotelli, Elisabetta
AU  - Mastrangelo, Anna M.
AU  - Marone, Daniela
TI  - Genomic Approaches to Identify Molecular Bases of Crop Resistance to Diseases and to Develop Future Breeding Strategies
T2  - International Journal of Molecular Sciences

PY  - 2021
VL  - 22
IS  - 11
SN  - 1422-0067

AB  - Plant diseases are responsible for substantial crop losses each year and affect food security and agricultural sustainability. The improvement of crop resistance to pathogens through breeding represents an environmentally sound method for managing disease and minimizing these losses. The challenge is to breed varieties with a stable and broad-spectrum resistance. Different approaches, from markers to recent genomic and ‘post-genomic era’ technologies, will be reviewed in order to contribute to a better understanding of the complexity of host–pathogen interactions and genes, including those with small phenotypic effects and mechanisms that underlie resistance. An efficient combination of these approaches is herein proposed as the basis to develop a successful breeding strategy to obtain resistant crop varieties that yield higher in increasing disease scenarios.
KW  - crop
KW  - disease resistance
KW  - genes
KW  - marker-assisted selection
KW  - meta-analysis
KW  - genomic selection
KW  - effectoromics
KW  - new breeding technologies
DO  - 10.3390/ijms22115423
TY  - EJOU
AU  - Behera, Mukunda D.
AU  - Barnwal, Surbhi
AU  - Paramanik, Somnath
AU  - Das, Pulakesh
AU  - Bhattyacharya, Bimal K.
AU  - Jagadish, Buddolla
AU  - Roy, Parth S.
AU  - Ghosh, Sujit M.
AU  - Behera, Soumit K.
TI  - Species-Level Classification and Mapping of a Mangrove Forest Using Random Forest—Utilisation of AVIRIS-NG and Sentinel Data
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 11
SN  - 2072-4292

AB  - Although studies on species-level classification and mapping using multisource data and machine learning approaches are plenty, the use of data with ideal placement of central wavelength and bandwidth at appropriate spatial resolution, for the classification of mangrove species is underreported. The species composition of a mangrove forest has been estimated utilising the red-edge spectral bands and chlorophyll absorption information from AVIRIS-NG and Sentinel-2 data. In this study, three dominant species, Heritiera fomes, Excoecaria agallocha and Avicennia officinalis, have been classified using the random forest (RF) model for a mangrove forest in Bhitarkanika Wildlife Sanctuary, India. Various combinations of reflectance/backscatter bands and vegetation indices derived from Sentinel-2, AVIRIS-NG, and Sentinel-1 were used for species-level discrimination and mapping. The RF model showed maximum accuracy using Sentinel-2, followed by the AVIRIS-NG, in discriminating three dominant species and two mixed compositions. This study indicates the potential of Sentinel-2 data for discriminating various mangrove species owing to the appropriate placement of central wavelength and bandwidth in Sentinel-2 at ≥10 m spatial resolution. The variable importance plots proved that species-level classification could be attempted using red edge and chlorophyll absorption information. This study has wider applicability in other mangrove forests around the world.
KW  - AVIRIS-NG
KW  - red edge
KW  - Bhitarkanika Wildlife Sanctuary
KW  - random forest
KW  - species-level classification
DO  - 10.3390/rs13112027
TY  - EJOU
AU  - Wu, Zhangnan
AU  - Chen, Yajun
AU  - Zhao, Bo
AU  - Kang, Xiaobing
AU  - Ding, Yuanyuan
TI  - Review of Weed Detection Methods Based on Computer Vision
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 11
SN  - 1424-8220

AB  - Weeds are one of the most important factors affecting agricultural production. The waste and pollution of farmland ecological environment caused by full-coverage chemical herbicide spraying are becoming increasingly evident. With the continuous improvement in the agricultural production level, accurately distinguishing crops from weeds and achieving precise spraying only for weeds are important. However, precise spraying depends on accurately identifying and locating weeds and crops. In recent years, some scholars have used various computer vision methods to achieve this purpose. This review elaborates the two aspects of using traditional image-processing methods and deep learning-based methods to solve weed detection problems. It provides an overview of various methods for weed detection in recent years, analyzes the advantages and disadvantages of existing methods, and introduces several related plant leaves, weed datasets, and weeding machinery. Lastly, the problems and difficulties of the existing weed detection methods are analyzed, and the development trend of future research is prospected.
KW  - weed detection
KW  - computer vision
KW  - image processing
KW  - deep learning
KW  - machine learning
DO  - 10.3390/s21113647
TY  - EJOU
AU  - Moreira, Bruno M.
AU  - Goyanes, Gabriel
AU  - Pina, Pedro
AU  - Vassilev, Oleg
AU  - Heleno, Sandra
TI  - Assessment of the Influence of Survey Design and Processing Choices on the Accuracy of Tree Diameter at Breast Height (DBH) Measurements Using UAV-Based Photogrammetry
T2  - Drones

PY  - 2021
VL  - 5
IS  - 2
SN  - 2504-446X

AB  - This work provides a systematic evaluation of how survey design and computer processing choices (such as the software used or the workflow/parameters chosen) influence unmanned aerial vehicle (UAV)-based photogrammetry retrieval of tree diameter at breast height (DBH), an important 3D structural parameter in forest inventory and biomass estimation. The study areas were an agricultural field located in the province of Málaga, Spain, where a small group of olive trees was chosen for the UAV surveys, and an open woodland area in the outskirts of Sofia, the capital of Bulgaria, where a 10 ha area grove, composed mainly of birch trees, was overflown. A DJI Phantom 4 Pro quadcopter UAV was used for the image acquisition. We applied structure from motion (SfM) to generate 3D point clouds of individual trees, using Agisoft and Pix4D software packages. The estimation of DBH in the point clouds was made using a RANSAC-based circle fitting tool from the TreeLS R package. All trees modeled had their DBH tape-measured on the ground for accuracy assessment. In the first study site, we executed many diversely designed flights, to identify which parameters (flying altitude, camera tilt, and processing method) gave us the most accurate DBH estimations; then, the resulting best settings configuration was used to assess the replicability of the method in the forested area in Bulgaria. The best configuration tested (flight altitudes of about 25 m above tree canopies, camera tilt 60°, forward and side overlaps of 90%, Agisoft ultrahigh processing) resulted in root mean square errors (RMSEs; %) of below 5% of the tree diameters in the first site and below 12.5% in the forested area. We demonstrate that, when carefully designed methodologies are used, SfM can measure the DBH of single trees with very good accuracy, and to our knowledge, the results presented here are the best achieved so far using (above-canopy) UAV-based photogrammetry.
KW  - unmanned aerial vehicle (UAV)
KW  - photogrammetry
KW  - structure from motion
KW  - 3D point cloud
KW  - diameter at breast height (DBH)
KW  - forest inventory
KW  - remote sensing
DO  - 10.3390/drones5020043
TY  - EJOU
AU  - Fetai, Bujar
AU  - Račič, Matej
AU  - Lisec, Anka
TI  - Deep Learning for Detection of Visible Land Boundaries from UAV Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 11
SN  - 2072-4292

AB  - Current efforts aim to accelerate cadastral mapping through innovative and automated approaches and can be used to both create and update cadastral maps. This research aims to automate the detection of visible land boundaries from unmanned aerial vehicle (UAV) imagery using deep learning. In addition, we wanted to evaluate the advantages and disadvantages of programming-based deep learning compared to commercial software-based deep learning. For the first case, we used the convolutional neural network U-Net, implemented in Keras, written in Python using the TensorFlow library. For commercial software-based deep learning, we used ENVINet5. UAV imageries from different areas were used to train the U-Net model, which was performed in Google Collaboratory and tested in the study area in Odranci, Slovenia. The results were compared with the results of ENVINet5 using the same datasets. The results showed that both models achieved an overall accuracy of over 95%. The high accuracy is due to the problem of unbalanced classes, which is usually present in boundary detection tasks. U-Net provided a recall of 0.35 and a precision of 0.68 when the threshold was set to 0.5. A threshold can be viewed as a tool for filtering predicted boundary maps and balancing recall and precision. For equitable comparison with ENVINet5, the threshold was increased. U-Net provided more balanced results, a recall of 0.65 and a precision of 0.41, compared to ENVINet5 recall of 0.84 and a precision of 0.35. Programming-based deep learning provides a more flexible yet complex approach to boundary mapping than software-based, which is rigid and does not require programming. The predicted visible land boundaries can be used both to speed up the creation of cadastral maps and to automate the revision of existing cadastral maps and define areas where updates are needed. The predicted boundaries cannot be considered final at this stage but can be used as preliminary cadastral boundaries.
KW  - land
KW  - cadastral mapping
KW  - visible boundary
KW  - UAV
KW  - deep learning
DO  - 10.3390/rs13112077
TY  - EJOU
AU  - Dronova, Iryna
AU  - Kislik, Chippie
AU  - Dinh, Zack
AU  - Kelly, Maggi
TI  - A Review of Unoccupied Aerial Vehicle Use in Wetland Applications: Emerging Opportunities in Approach, Technology, and Data
T2  - Drones

PY  - 2021
VL  - 5
IS  - 2
SN  - 2504-446X

AB  - Recent developments in technology and data processing for Unoccupied Aerial Vehicles (UAVs) have revolutionized the scope of ecosystem monitoring, providing novel pathways to fill the critical gap between limited-scope field surveys and limited-customization satellite and piloted aerial platforms. These advances are especially ground-breaking for supporting management, restoration, and conservation of landscapes with limited field access and vulnerable ecological systems, particularly wetlands. This study presents a scoping review of the current status and emerging opportunities in wetland UAV applications, with particular emphasis on ecosystem management goals and remaining research, technology, and data needs to even better support these goals in the future. Using 122 case studies from 29 countries, we discuss which wetland monitoring and management objectives are most served by this rapidly developing technology, and what workflows were employed to analyze these data. This review showcases many ways in which UAVs may help reduce or replace logistically demanding field surveys and can help improve the efficiency of UAV-based workflows to support longer-term monitoring in the face of wetland environmental challenges and management constraints. We also highlight several emerging trends in applications, technology, and data and offer insights into future needs.
KW  - wetland
KW  - unoccupied aerial vehicle
KW  - UAV
KW  - UAS
KW  - drone
KW  - management
KW  - conservation
KW  - restoration
KW  - monitoring
KW  - high spatial resolution
DO  - 10.3390/drones5020045
TY  - EJOU
AU  - Ahmed, Shibbir
AU  - Qiu, Baijing
AU  - Ahmad, Fiaz
AU  - Kong, Chun-Wei
AU  - Xin, Huang
TI  - A State-of-the-Art Analysis of Obstacle Avoidance Methods from the Perspective of an Agricultural Sprayer UAV’s Operation Scenario
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 6
SN  - 2073-4395

AB  - Over the last decade, Unmanned Aerial Vehicles (UAVs), also known as drones, have been broadly utilized in various agricultural fields, such as crop management, crop monitoring, seed sowing, and pesticide spraying. Nonetheless, autonomy is still a crucial limitation faced by the Internet of Things (IoT) UAV systems, especially when used as sprayer UAVs, where data needs to be captured and preprocessed for robust real-time obstacle detection and collision avoidance. Moreover, because of the objective and operational difference between general UAVs and sprayer UAVs, not every obstacle detection and collision avoidance method will be sufficient for sprayer UAVs. In this regard, this article seeks to review the most relevant developments on all correlated branches of the obstacle avoidance scenarios for agricultural sprayer UAVs, including a UAV sprayer’s structural details. Furthermore, the most relevant open challenges for current UAV sprayer solutions are enumerated, thus paving the way for future researchers to define a roadmap for devising new-generation, affordable autonomous sprayer UAV solutions. Agricultural UAV sprayers require data-intensive algorithms for the processing of the images acquired, and expertise in the field of autonomous flight is usually needed. The present study concludes that UAV sprayers are still facing obstacle detection challenges due to their dynamic operating and loading conditions.
KW  - agricultural sprayer UAVs
KW  - Internet of Things
KW  - obstacles on farmland
KW  - operation pattern
KW  - obstacle detection
KW  - collision avoidance
KW  - path planning
KW  - spray coverage
DO  - 10.3390/agronomy11061069
TY  - EJOU
AU  - Quemada, Carlos
AU  - Pérez-Escudero, José M.
AU  - Gonzalo, Ramón
AU  - Ederra, Iñigo
AU  - Santesteban, Luis G.
AU  - Torres, Nazareth
AU  - Iriarte, Juan C.
TI  - Remote Sensing for Plant Water Content Monitoring: A Review
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 11
SN  - 2072-4292

AB  - This paper reviews the different remote sensing techniques found in the literature to monitor plant water status, allowing farmers to control the irrigation management and to avoid unnecessary periods of water shortage and a needless waste of valuable water. The scope of this paper covers a broad range of 77 references published between the years 1981 and 2021 and collected from different search web sites, especially Scopus. Among them, 74 references are research papers and the remaining three are review papers. The different collected approaches have been categorized according to the part of the plant subjected to measurement, that is, soil (12.2%), canopy (33.8%), leaves (35.1%) or trunk (18.9%). In addition to a brief summary of each study, the main monitoring technologies have been analyzed in this review. Concerning the presentation of the data, different results have been obtained. According to the year of publication, the number of published papers has increased exponentially over time, mainly due to the technological development over the last decades. The most common sensor is the radiometer, which is employed in 15 papers (20.3%), followed by continuous-wave (CW) spectroscopy (12.2%), camera (10.8%) and THz time-domain spectroscopy (TDS) (10.8%). Excluding two studies, the minimum coefficient of determination (R2) obtained in the references of this review is 0.64. This indicates the high degree of correlation between the estimated and measured data for the different technologies and monitoring methods. The five most frequent water indicators of this study are: normalized difference vegetation index (NDVI) (12.2%), backscattering coefficients (10.8%), spectral reflectance (8.1%), reflection coefficient (8.1%) and dielectric constant (8.1%).
KW  - backscattering coefficients
KW  - canopy water content
KW  - continuous-wave spectroscopy
KW  - leaf water content
KW  - NDVI
KW  - plant water content
KW  - radiometer
KW  - remote sensing
KW  - soil water content
KW  - xylem water content
DO  - 10.3390/rs13112088
TY  - EJOU
AU  - Reis, João
AU  - Cohen, Yuval
AU  - Melão, Nuno
AU  - Costa, Joana
AU  - Jorge, Diana
TI  - High-Tech Defense Industries: Developing Autonomous Intelligent Systems
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 11
SN  - 2076-3417

AB  - After the Cold War, the defense industries found themselves at a crossroads. However, it seems that they are gaining new momentum, as new technologies such as robotics and artificial intelligence are enabling the development of autonomous, highly innovative and disruptive intelligent systems. Despite this new impetus, there are still doubts about where to invest limited financial resources to boost high-tech defense industries. In order to shed some light on the topic, we decided to conduct a systematic literature review by using the PRISMA protocol and content analysis. The results indicate that autonomous intelligent systems are being developed by the defense industry and categorized into three different modes—fully autonomous operations, partially autonomous operations, and smart autonomous decision-making. In addition, it is also important to note that, at a strategic level of war, there is limited room for automation given the need for human intervention. However, at the tactical level of war, there is a high probability of growth in industrial defense, since, at this level, structured decisions and complex analytical-cognitive tasks are carried out. In the light of carrying out those decisions and tasks, robotics and artificial intelligence can make a contribution far superior to that of human beings.
KW  - artificial intelligence
KW  - defense industry
KW  - high technology
KW  - intelligent systems
KW  - level of war
KW  - robotics
DO  - 10.3390/app11114920
TY  - EJOU
AU  - Choudhury, MD A.
AU  - Marcheggiani, Ernesto
AU  - Galli, Andrea
AU  - Modica, Giuseppe
AU  - Somers, Ben
TI  - Mapping the Urban Atmospheric Carbon Stock by LiDAR and WorldView-3 Data
T2  - Forests

PY  - 2021
VL  - 12
IS  - 6
SN  - 1999-4907

AB  - Currently, the worsening impacts of urbanizations have been impelled to the importance of monitoring and management of existing urban trees, securing sustainable use of the available green spaces. Urban tree species identification and evaluation of their roles in atmospheric Carbon Stock (CS) are still among the prime concerns for city planners regarding initiating a convenient and easily adaptive urban green planning and management system. A detailed methodology on the urban tree carbon stock calibration and mapping was conducted in the urban area of Brussels, Belgium. A comparative analysis of the mapping outcomes was assessed to define the convenience and efficiency of two different remote sensing data sources, Light Detection and Ranging (LiDAR) and WorldView-3 (WV-3), in a unique urban area. The mapping results were validated against field estimated carbon stocks. At the initial stage, dominant tree species were identified and classified using the high-resolution WorldView3 image, leading to the final carbon stock mapping based on the dominant species. An object-based image analysis approach was employed to attain an overall accuracy (OA) of 71% during the classification of the dominant species. The field estimations of carbon stock for each plot were done utilizing an allometric model based on the field tree dendrometric data. Later based on the correlation among the field data and the variables (i.e., Normalized Difference Vegetation Index, NDVI and Crown Height Model, CHM) extracted from the available remote sensing data, the carbon stock mapping and validation had been done in a GIS environment. The calibrated NDVI and CHM had been used to compute possible carbon stock in either case of the WV-3 image and LiDAR data, respectively. A comparative discussion has been introduced to bring out the issues, especially for the developing countries, where WV-3 data could be a better solution over the hardly available LiDAR data. This study could assist city planners in understanding and deciding the applicability of remote sensing data sources based on their availability and the level of expediency, ensuring a sustainable urban green management system.
KW  - urban trees
KW  - Geospatial Object-Based Image Analysis (GEOBIA)
KW  - Carbon Stock (CS) mapping
KW  - allometric model
KW  - WorldView-3 (WV-3) imagery
KW  - aerial Light Detection and Ranging (LiDAR) data
DO  - 10.3390/f12060692
TY  - EJOU
AU  - Aeberli, Aaron
AU  - Johansen, Kasper
AU  - Robson, Andrew
AU  - Lamb, David W.
AU  - Phinn, Stuart
TI  - Detection of Banana Plants Using Multi-Temporal Multispectral UAV Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 11
SN  - 2072-4292

AB  - Unoccupied aerial vehicles (UAVs) have become increasingly commonplace in aiding planning and management decisions in agricultural and horticultural crop production. The ability of UAV-based sensing technologies to provide high spatial (&lt;1 m) and temporal (on-demand) resolution data facilitates monitoring of individual plants over time and can provide essential information about health, yield, and growth in a timely and quantifiable manner. Such applications would be beneficial for cropped banana plants due to their distinctive growth characteristics. Limited studies have employed UAV data for mapping banana crops and to our knowledge only one other investigation features multi-temporal detection of banana crowns. The purpose of this study was to determine the suitability of multiple-date UAV-captured multi-spectral data for the automated detection of individual plants using convolutional neural network (CNN), template matching (TM), and local maximum filter (LMF) methods in a geographic object-based image analysis (GEOBIA) software framework coupled with basic classification refinement. The results indicate that CNN returns the highest plant detection accuracies, with the developed rule set and model providing greater transferability between dates (F-score ranging between 0.93 and 0.85) than TM (0.86–0.74) and LMF (0.86–0.73) approaches. The findings provide a foundation for UAV-based individual banana plant counting and crop monitoring, which may be used for precision agricultural applications to monitor health, estimate yield, and to inform on fertilizer, pesticide, and other input requirements for optimized farm management.
KW  - unoccupied aerial vehicle
KW  - UAV
KW  - banana plant
KW  - geographic object-based image analysis
KW  - convolutional neural network
KW  - CNN
KW  - template matching
KW  - local maximum filter
DO  - 10.3390/rs13112123
TY  - EJOU
AU  - de Castro, Ana I.
AU  - Shi, Yeyin
AU  - Maja, Joe M.
AU  - Peña, Jose M.
TI  - UAVs for Vegetation Monitoring: Overview and Recent Scientific Contributions
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 11
SN  - 2072-4292

AB  - This paper reviewed a set of twenty-one original and innovative papers included in a special issue on UAVs for vegetation monitoring, which proposed new methods and techniques applied to diverse agricultural and forestry scenarios. Three general categories were considered: (1) sensors and vegetation indices used, (2) technological goals pursued, and (3) agroforestry applications. Some investigations focused on issues related to UAV flight operations, spatial resolution requirements, and computation and data analytics, while others studied the ability of UAVs for characterizing relevant vegetation features (mainly canopy cover and crop height) or for detecting different plant/crop stressors, such as nutrient content/deficiencies, water needs, weeds, and diseases. The general goal was proposing UAV-based technological solutions for a better use of agricultural and forestry resources and more efficient production with relevant economic and environmental benefits.
KW  - drone
KW  - RGB
KW  - multispectral
KW  - hyperspectral
KW  - thermal
KW  - machine learning
KW  - water stress
KW  - nutrient deficiency
KW  - weed detection
KW  - disease diagnosis
KW  - plant trails
DO  - 10.3390/rs13112139
TY  - EJOU
AU  - Bai, Hao
AU  - Bai, Tingzhu
AU  - Li, Wei
AU  - Liu, Xun
TI  - A Building Segmentation Network Based on Improved Spatial Pyramid in Remote Sensing Images
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 11
SN  - 2076-3417

AB  - Building segmentation is widely used in urban planning, disaster prevention, human flow monitoring and environmental monitoring. However, due to the complex landscapes and highdensity settlements, automatically characterizing building in the urban village or cities using remote sensing images is very challenging. Inspired by the rencent deep learning methods, this paper proposed a novel end-to-end building segmentation network for segmenting buildings from remote sensing images. The network includes two branches: one branch uses Widely Adaptive Spatial Pyramid (WASP) structure to extract multi-scale features, and the other branch uses a deep residual network combined with a sub-pixel up-sampling structure to enhance the detail of building boundaries. We compared our proposed method with three state-of-the-art networks: DeepLabv3+, ENet, ESPNet. Experiments were performed using the publicly available Inria Aerial Image Labelling dataset (Inria aerial dataset) and the Satellite dataset II(East Asia). The results showed that our method outperformed the other networks in the experiments, with Pixel Accuracy reaching 0.8421 and 0.8738, respectively and with mIoU reaching 0.9034 and 0.8936 respectively. Compared with the basic network, it has increased by about 25% or more. It can not only extract building footprints, but also especially small building objects.
KW  - CNN
KW  - semantic segmentation
KW  - super resolution
KW  - remote sensing
KW  - spatial pyramid
KW  - ResNet
DO  - 10.3390/app11115069
TY  - EJOU
AU  - Lee, Seunghyeon
AU  - Song, Youngkeun
AU  - Kil, Sung-Ho
TI  - Feasibility Analyses of Real-Time Detection of Wildlife Using UAV-Derived Thermal and RGB Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 11
SN  - 2072-4292

AB  - Wildlife monitoring is carried out for diverse reasons, and monitoring methods have gradually advanced through technological development. Direct field investigations have been replaced by remote monitoring methods, and unmanned aerial vehicles (UAVs) have recently become the most important tool for wildlife monitoring. Many previous studies on detecting wild animals have used RGB images acquired from UAVs, with most of the analyses depending on machine learning–deep learning (ML–DL) methods. These methods provide relatively accurate results, and when thermal sensors are used as a supplement, even more accurate detection results can be obtained through complementation with RGB images. However, because most previous analyses were based on ML–DL methods, a lot of time was required to generate training data and train detection models. This drawback makes ML–DL methods unsuitable for real-time detection in the field. To compensate for the disadvantages of the previous methods, this paper proposes a real-time animal detection method that generates a total of six applicable input images depending on the context and uses them for detection. The proposed method is based on the Sobel edge algorithm, which is simple but can detect edges quickly based on change values. The method can detect animals in a single image without training data. The fastest detection time per image was 0.033 s, and all frames of a thermal video could be analyzed. Furthermore, because of the synchronization of the properties of the thermal and RGB images, the performance of the method was above average in comparison with previous studies. With target images acquired at heights below 100 m, the maximum detection precision and detection recall of the most accurate input image were 0.804 and 0.699, respectively. However, the low resolution of the thermal sensor and its shooting height limitation were hindrances to wildlife detection. The aim of future research will be to develop a detection method that can improve these shortcomings.
KW  - thermal sensing
KW  - unmanned aerial vehicle
KW  - object-based animal detection
KW  - instant and automated detection
KW  - mixed image analysis
KW  - wildlife monitoring
KW  - multiple height shooting
DO  - 10.3390/rs13112169
TY  - EJOU
AU  - Lulić, Luka
AU  - Ožić, Karlo
AU  - Kišiček, Tomislav
AU  - Hafner, Ivan
AU  - Stepinac, Mislav
TI  - Post-Earthquake Damage Assessment—Case Study of the Educational Building after the Zagreb Earthquake
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 11
SN  - 2071-1050

AB  - In the wake of recent strong earthquakes in Croatia, there is a need for a detailed and more comprehensive post-earthquake damage assessment. Given that masonry structures are highly vulnerable to horizontal actions caused by earthquakes and a majority of the Croatian building stock is made of masonry, this field is particularly important for Croatia. In this paper, a complete assessment of an educational building in Zagreb Lower Town is reported. An extensive program of visual inspection and geometrical surveys has been planned and performed. Additionally, an in situ shear strength test is presented. After extensive fieldwork, collected data and results were input in 3Muri software for structural modeling. Moreover, a non-linear static (pushover) analysis was performed to individuate the possible failure mechanisms and to compare real-life damage to software results.
KW  - assessment
KW  - earthquake
KW  - Zagreb
KW  - case study
KW  - cultural heritage
DO  - 10.3390/su13116353
TY  - EJOU
AU  - Yuan, Ningge
AU  - Gong, Yan
AU  - Fang, Shenghui
AU  - Liu, Yating
AU  - Duan, Bo
AU  - Yang, Kaili
AU  - Wu, Xianting
AU  - Zhu, Renshan
TI  - UAV Remote Sensing Estimation of Rice Yield Based on Adaptive Spectral Endmembers and Bilinear Mixing Model
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 11
SN  - 2072-4292

AB  - The accurate estimation of rice yield using remote sensing (RS) technology is crucially important for agricultural decision-making. The rice yield estimation model based on the vegetation index (VI) is commonly used when working with RS methods, however, it is affected by irrelevant organs and background especially at heading stage. The spectral mixture analysis (SMA) can quantitatively obtain the abundance information and mitigate the impacts. Furthermore, according to the spectral variability and information complexity caused by the rice cropping system and canopy characteristics of reflection and scattering, in this study, the multi-endmember extraction by the pure pixel index (PPI) and the nonlinear unmixing method based on the bandwise generalized bilinear mixing model (NU-BGBM) were applied for SMA, and the VIE (VIs recalculated from endmember spectra) was integrated with abundance data to establish the yield estimation model at heading stage. In two paddy fields of different cultivation settings, multispectral images were collected by an unmanned aerial vehicle (UAV) at booting and heading stage. The correlation of several widely-used VIs and rice yield was tested and weaker at heading stage. In order to improve the yield estimation accuracy of rice at heading stage, the VIE and foreground abundances from SMA were combined to develop a linear yield estimation model. The results showed that VIE incorporated with abundances exhibited a better estimation ability than VI alone or the product of VI and abundances. In addition, when the structural difference of plants was obvious, the addition of the product of VIF (VIs recalculated from bilinear endmember spectra) and the corresponding bilinear abundances to the original product of VIE and abundances, enhanced model reliability. VIs using the near-infrared bands improved more significantly with the estimation error below 8.1%. This study verified the validation of the targeted SMA strategy while estimating crop yield by remotely sensed VI, especially for objects with obvious different spectra and complex structures.
KW  - rice
KW  - yield
KW  - remote sensing (RS)
KW  - spectral mixture analysis (SMA)
KW  - multiple endmembers
KW  - bilinear mixing model (BMM)
DO  - 10.3390/rs13112190
TY  - EJOU
AU  - Paturkar, Abhipray
AU  - Sen Gupta, Gourab
AU  - Bailey, Donald
TI  - Making Use of 3D Models for Plant Physiognomic Analysis: A Review
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 11
SN  - 2072-4292

AB  - Use of 3D sensors in plant phenotyping has increased in the last few years. Various image acquisition, 3D representations, 3D model processing and analysis techniques exist to help the researchers. However, a review of approaches, algorithms, and techniques used for 3D plant physiognomic analysis is lacking. In this paper, we investigate the techniques and algorithms used at various stages of processing and analysing 3D models of plants, and identify their current limiting factors. This review will serve potential users as well as new researchers in this field. The focus is on exploring studies monitoring the plant growth of single plants or small scale canopies as opposed to large scale monitoring in the field.
KW  - plant phenotyping
KW  - plant growth monitoring
KW  - point cloud processing
KW  - 3D point cloud
KW  - SfM
KW  - structural parameter
KW  - 3D measurements
DO  - 10.3390/rs13112232
TY  - EJOU
AU  - Hara, Patryk
AU  - Piekutowska, Magdalena
AU  - Niedbała, Gniewko
TI  - Selection of Independent Variables for Crop Yield Prediction Using Artificial Neural Network Models with Remote Sensing Data
T2  - Land

PY  - 2021
VL  - 10
IS  - 6
SN  - 2073-445X

AB  - Knowing the expected crop yield in the current growing season provides valuable information for farmers, policy makers, and food processing plants. One of the main benefits of using reliable forecasting tools is generating more income from grown crops. Information on the amount of crop yielding before harvesting helps to guide the adoption of an appropriate strategy for managing agricultural products. The difficulty in creating forecasting models is related to the appropriate selection of independent variables. Their proper selection requires a perfect knowledge of the research object. The following article presents and discusses the most commonly used independent variables in agricultural crop yield prediction modeling based on artificial neural networks (ANNs). Particular attention is paid to environmental variables, such as climatic data, air temperature, total precipitation, insolation, and soil parameters. The possibility of using plant productivity indices and vegetation indices, which are valuable predictors obtained due to the application of remote sensing techniques, are analyzed in detail. The paper emphasizes that the increasingly common use of remote sensing and photogrammetric tools enables the development of precision agriculture. In addition, some limitations in the application of certain input variables are specified, as well as further possibilities for the development of non-linear modeling, using artificial neural networks as a tool supporting the practical use of and improvement in precision farming techniques.
KW  - crop yield prediction
KW  - independent variables
KW  - ANN
KW  - remote sensing
DO  - 10.3390/land10060609
TY  - EJOU
AU  - Al-amri, Redhwan
AU  - Murugesan, Raja K.
AU  - Man, Mustafa
AU  - Abdulateef, Alaa F.
AU  - Al-Sharafi, Mohammed A.
AU  - Alkahtani, Ammar A.
TI  - A Review of Machine Learning and Deep Learning Techniques for Anomaly Detection in IoT Data
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 12
SN  - 2076-3417

AB  - Anomaly detection has gained considerable attention in the past couple of years. Emerging technologies, such as the Internet of Things (IoT), are known to be among the most critical sources of data streams that produce massive amounts of data continuously from numerous applications. Examining these collected data to detect suspicious events can reduce functional threats and avoid unseen issues that cause downtime in the applications. Due to the dynamic nature of the data stream characteristics, many unresolved problems persist. In the existing literature, methods have been designed and developed to evaluate certain anomalous behaviors in IoT data stream sources. However, there is a lack of comprehensive studies that discuss all the aspects of IoT data processing. Thus, this paper attempts to fill this gap by providing a complete image of various state-of-the-art techniques on the major problems and core challenges in IoT data. The nature of data, anomaly types, learning mode, window model, datasets, and evaluation criteria are also presented. Research challenges related to data evolving, feature-evolving, windowing, ensemble approaches, nature of input data, data complexity and noise, parameters selection, data visualizations, heterogeneity of data, accuracy, and large-scale and high-dimensional data are investigated. Finally, the challenges that require substantial research efforts and future directions are summarized.
KW  - anomaly detection
KW  - data stream
KW  - deep learning
KW  - Internet of Things
KW  - machine learning
DO  - 10.3390/app11125320
TY  - EJOU
AU  - Lamonaca, Francesco
AU  - Carnì, Domenico L.
TI  - Evaluation of the Effects of Mobile Smart Object to Boost IoT Network Synchronization
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 12
SN  - 1424-8220

AB  - This paper deals with the synchronization of Mobile Smart Objects (MSOs). Today, this scenario is becoming typical in Industrial IoT applications due to the plethora of MSOs available as robots, drones and wearables, equipped by sensors making them measurement instruments cooperating in distributed measurement systems. In this context, the synchronization accuracy is directly tied with the accuracy of the performed measurements. In hierarchical synchronization approaches, the presence of an MSO makes the network topology time varying, and this could prevent the synchronization of the whole network. Peer to peer approaches do not need node hierarchy to synchronize but could not converge to a common sense of time. To overcome these challenges, this paper proposes a consensus-based approach for which the convergence to a common sense of time is here demonstrated. The proposal deploys the MSO to bring the common sense of time from an SO to another, establishing new paths among SOs. The new paths are temporary and depend on the MSO’s route. In the paper, the influence of the MSO’s route on the synchronization accuracy σ and the time interval to synchronize all the SOs ∆TIS is investigated, also. The mathematical proof, the simulations and the experimental tests confirm that the MSO can reduce both the values of σ and ∆TIS, because the new connections introduced by the MSO can boost the exchange of information among SOs. Consequently, the criteria to a priori select the route ameliorating σ and ∆TIS values are proposed.
KW  - synchronization
KW  - consensus
KW  - mobile object
KW  - IoT network synchronization
KW  - IoT network topology
DO  - 10.3390/s21123957
TY  - EJOU
AU  - de Oliveira, Gabriel S.
AU  - Marcato Junior, José
AU  - Polidoro, Caio
AU  - Osco, Lucas P.
AU  - Siqueira, Henrique
AU  - Rodrigues, Lucas
AU  - Jank, Liana
AU  - Barrios, Sanzio
AU  - Valle, Cacilda
AU  - Simeão, Rosângela
AU  - Carromeu, Camilo
AU  - Silveira, Eloise
AU  -  André de Castro Jorge, Lúcio
AU  - Gonçalves, Wesley
AU  - Santos, Mateus
AU  - Matsubara, Edson
TI  - Convolutional Neural Networks to Estimate Dry Matter Yield in a Guineagrass Breeding Program Using UAV Remote Sensing
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 12
SN  - 1424-8220

AB  - Forage dry matter is the main source of nutrients in the diet of ruminant animals. Thus, this trait is evaluated in most forage breeding programs with the objective of increasing the yield. Novel solutions combining unmanned aerial vehicles (UAVs) and computer vision are crucial to increase the efficiency of forage breeding programs, to support high-throughput phenotyping (HTP), aiming to estimate parameters correlated to important traits. The main goal of this study was to propose a convolutional neural network (CNN) approach using UAV-RGB imagery to estimate dry matter yield traits in a guineagrass breeding program. For this, an experiment composed of 330 plots of full-sib families and checks conducted at Embrapa Beef Cattle, Brazil, was used. The image dataset was composed of images obtained with an RGB sensor embedded in a Phantom 4 PRO. The traits leaf dry matter yield (LDMY) and total dry matter yield (TDMY) were obtained by conventional agronomic methodology and considered as the ground-truth data. Different CNN architectures were analyzed, such as AlexNet, ResNeXt50, DarkNet53, and two networks proposed recently for related tasks named MaCNN and LF-CNN. Pretrained AlexNet and ResNeXt50 architectures were also studied. Ten-fold cross-validation was used for training and testing the model. Estimates of DMY traits by each CNN architecture were considered as new HTP traits to compare with real traits. Pearson correlation coefficient r between real and HTP traits ranged from 0.62 to 0.79 for LDMY and from 0.60 to 0.76 for TDMY; root square mean error (RSME) ranged from 286.24 to 366.93 kg·ha−1 for LDMY and from 413.07 to 506.56 kg·ha−1 for TDMY. All the CNNs generated heritable HTP traits, except LF-CNN for LDMY and AlexNet for TDMY. Genetic correlations between real and HTP traits were high but varied according to the CNN architecture. HTP trait from ResNeXt50 pretrained achieved the best results for indirect selection regardless of the dry matter trait. This demonstrates that CNNs with remote sensing data are highly promising for HTP for dry matter yield traits in forage breeding programs.
KW  - deep learning
KW  - forage dry matter yield
KW  - high-throughput phenotyping
KW  - Brazilian pasture
DO  - 10.3390/s21123971
TY  - EJOU
AU  - Sangjan, Worasit
AU  - Carter, Arron H.
AU  - Pumphrey, Michael O.
AU  - Jitkov, Vadim
AU  - Sankaran, Sindhuja
TI  - Development of a Raspberry Pi-Based Sensor System for Automated In-Field Monitoring to Support Crop Breeding Programs
T2  - Inventions

PY  - 2021
VL  - 6
IS  - 2
SN  - 2411-5134

AB  - Sensor applications for plant phenotyping can advance and strengthen crop breeding programs. One of the powerful sensing options is the automated sensor system, which can be customized and applied for plant science research. The system can provide high spatial and temporal resolution data to delineate crop interaction with weather changes in a diverse environment. Such a system can be integrated with the internet to enable the internet of things (IoT)-based sensor system development for real-time crop monitoring and management. In this study, the Raspberry Pi-based sensor (imaging) system was fabricated and integrated with a microclimate sensor to evaluate crop growth in a spring wheat breeding trial for automated phenotyping applications. Such an in-field sensor system will increase the reproducibility of measurements and improve the selection efficiency by investigating dynamic crop responses as well as identifying key growth stages (e.g., heading), assisting in the development of high-performing crop varieties. In the low-cost system developed here-in, a Raspberry Pi computer and multiple cameras (RGB and multispectral) were the main components. The system was programmed to automatically capture and manage the crop image data at user-defined time points throughout the season. The acquired images were suitable for extracting quantifiable plant traits, and the images were automatically processed through a Python script (an open-source programming language) to extract vegetation indices, representing crop growth and overall health. Ongoing efforts are conducted towards integrating the sensor system for real-time data monitoring via the internet that will allow plant breeders to monitor multiple trials for timely crop management and decision making.
KW  - sensor
KW  - high-throughput phenotyping
KW  - internet of things
KW  - Raspberry Pi
DO  - 10.3390/inventions6020042
TY  - EJOU
AU  - Chen, Hualong
AU  - Wen, Yuanqiao
AU  - Zhu, Man
AU  - Huang, Yamin
AU  - Xiao, Changshi
AU  - Wei, Tao
AU  - Hahn, Axel
TI  - From Automation System to Autonomous System: An Architecture Perspective
T2  - Journal of Marine Science and Engineering

PY  - 2021
VL  - 9
IS  - 6
SN  - 2077-1312

AB  - Autonomy is the core capability of future systems, and architecture design is one of the critical issues in system development and implementation. To discuss the architecture of autonomous systems in the future, this paper reviews the developing progress of architectures from automation systems to autonomous systems. Firstly, the autonomy and autonomous systems in different fields are summarized. The article classifies and summarizes the architecture of typical automated systems and infer three suggestions for building an autonomous system architecture: extensibility, evolvability, and collaborability. Accordingly, this paper builds an autonomous waterborne transportation system, and the architecture is composed of the object layer, cyberspace layer, cognition layer, and application layer, the proposed suggestions made in the construction of the architecture are reflected in the inter-relationships at all layers. Through the cooperation of four layers, the autonomous waterborne transportation system can autonomously complete the system functions, such as system control and transportation service. In the end, the characteristics of autonomous systems are concluded, from which the future primary research directions and the challenges of autonomous systems are provided.
KW  - autonomous systems
KW  - autonomy
KW  - architecture
KW  - automation system
KW  - waterway transportation system
DO  - 10.3390/jmse9060645
TY  - EJOU
AU  - Zheng, Ke
AU  - Jia, Guozhu
AU  - Yang, Linchao
AU  - Wang, Jiaqing
TI  - A Compound Fault Labeling and Diagnosis Method Based on Flight Data and BIT Record of UAV
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 12
SN  - 2076-3417

AB  - In the process of Unmanned Aerial Vehicle (UAV) flight testing, plenty of compound faults exist, which could be composed of concurrent single faults or over-limit states alarmed by Built-In-Test (BIT) equipment. At present, there still lacks a suitable automatic labeling approach for UAV flight data, effectively utilizing the information of the BIT record. The performance of the originally employed flight data-driven fault diagnosis models based on machine learning needs to be improved as well. A compound fault labeling and diagnosis method based on actual flight data and the BIT record of the UAV during flight test phase is proposed, through labeling the flight data with compound fault modes corresponding to concurrent single faults recorded by the BIT system, and upgrading the original diagnosis model based on Gradient Boosting Decision Tree (GBDT) and Fully Convolutional Network (FCNN), to eXtreme Gradient Boosting (XGBoost), Light Gradient Boosting Machine (LightGBM) and modified Convolutional Neural Network (CNN). The experimental results based on actual test flight data show that the proposed method could effectively label the flight data and obtain a significant improvement in diagnostic performance, appearing to be practical in the UAV test flight process.
KW  - fault diagnosis
KW  - data labeling
KW  - UAV
KW  - flight data and BIT record
KW  - machine learning
DO  - 10.3390/app11125410
TY  - EJOU
AU  - Sun, Fengjie
AU  - Wang, Xianchang
AU  - Zhang, Rui
TI  - Improved Q-Learning Algorithm Based on Approximate State Matching in Agricultural Plant Protection Environment
T2  - Entropy

PY  - 2021
VL  - 23
IS  - 6
SN  - 1099-4300

AB  - An Unmanned Aerial Vehicle (UAV) can greatly reduce manpower in the agricultural plant protection such as watering, sowing, and pesticide spraying. It is essential to develop a Decision-making Support System (DSS) for UAVs to help them choose the correct action in states according to the policy. In an unknown environment, the method of formulating rules for UAVs to help them choose actions is not applicable, and it is a feasible solution to obtain the optimal policy through reinforcement learning. However, experiments show that the existing reinforcement learning algorithms cannot get the optimal policy for a UAV in the agricultural plant protection environment. In this work we propose an improved Q-learning algorithm based on similar state matching, and we prove theoretically that there has a greater probability for UAV choosing the optimal action according to the policy learned by the algorithm we proposed than the classic Q-learning algorithm in the agricultural plant protection environment. This proposed algorithm is implemented and tested on datasets that are evenly distributed based on real UAV parameters and real farm information. The performance evaluation of the algorithm is discussed in detail. Experimental results show that the algorithm we proposed can efficiently learn the optimal policy for UAVs in the agricultural plant protection environment.
KW  - decision-making support system
KW  - reinforcement learning
KW  - Q-learning
DO  - 10.3390/e23060737
TY  - EJOU
AU  - Brandoli, Bruno
AU  - de Geus, André R.
AU  - Souza, Jefferson R.
AU  - Spadon, Gabriel
AU  - Soares, Amilcar
AU  - Rodrigues, Jose F.
AU  - Komorowski, Jerzy
AU  - Matwin, Stan
TI  - Aircraft Fuselage Corrosion Detection Using Artificial Intelligence
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 12
SN  - 1424-8220

AB  - Corrosion identification and repair is a vital task in aircraft maintenance to ensure continued structural integrity. Regarding fuselage lap joints, typically, visual inspections are followed by non-destructive methodologies, which are time-consuming. The visual inspection of large areas suffers not only from subjectivity but also from the variable probability of corrosion detection, which is aggravated by the multiple layers used in fuselage construction. In this paper, we propose a methodology for automatic image-based corrosion detection of aircraft structures using deep neural networks. For machine learning, we use a dataset that consists of D-Sight Aircraft Inspection System (DAIS) images from different lap joints of Boeing and Airbus aircrafts. We also employ transfer learning to overcome the shortage of aircraft corrosion images. With precision of over 93%, we demonstrate that our approach detects corrosion with a precision comparable to that of trained operators, aiding to reduce the uncertainties related to operator fatigue or inadequate training. Our results indicate that our methodology can support specialists and engineers in corrosion monitoring in the aerospace industry, potentially contributing to the automation of condition-based maintenance protocols.
KW  - aircraft corrosion inspection
KW  - automatic corrosion detection
KW  - material fatigue
KW  - corrosion science
KW  - rust detection
KW  - aviation maintenance
KW  - deep learning
DO  - 10.3390/s21124026
TY  - EJOU
AU  - Burdziakowski, Pawel
TI  - Polymodal Method of Improving the Quality of Photogrammetric Images and Models
T2  - Energies

PY  - 2021
VL  - 14
IS  - 12
SN  - 1996-1073

AB  - Photogrammetry using unmanned aerial vehicles has become very popular and is already commonly used. The most frequent photogrammetry products are an orthoimage, digital terrain model and a 3D object model. When executing measurement flights, it may happen that there are unsuitable lighting conditions, and the flight itself is fast and not very stable. As a result, noise and blur appear on the images, and the images themselves can have too low of a resolution to satisfy the quality requirements for a photogrammetric product. In such cases, the obtained images are useless or will significantly reduce the quality of the end-product of low-level photogrammetry. A new polymodal method of improving measurement image quality has been proposed to avoid such issues. The method discussed in this article removes degrading factors from the images and, as a consequence, improves the geometric and interpretative quality of a photogrammetric product. The author analyzed 17 various image degradation cases, developed 34 models based on degraded and recovered images, and conducted an objective analysis of the quality of the recovered images and models. As evidenced, the result was a significant improvement in the interpretative quality of the images themselves and a better geometry model.
KW  - UAV
KW  - neural networks
KW  - deblur
KW  - denoise
KW  - super resolution
KW  - neural network
DO  - 10.3390/en14123457
TY  - EJOU
AU  - Zhang, Wentao
AU  - Liu, Yucheng
AU  - Zhang, Shaohui
AU  - Long, Tuzhi
AU  - Liang, Jinglun
TI  - Error Fusion of Hybrid Neural Networks for Mechanical Condition Dynamic Prediction
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 12
SN  - 1424-8220

AB  - It is important for equipment to operate safely and reliably so that the working state of mechanical parts pushes forward an immense influence. Therefore, in order to enhance the dependability and security of mechanical equipment, to accurately predict the changing trend of mechanical components in advance plays a significant role. This paper introduces a novel condition prediction method, named error fusion of hybrid neural networks (EFHNN), by combining the error fusion of multiple sparse auto-encoders with convolutional neural networks for predicting the mechanical condition. First, to improve prediction accuracy, we can use the error fusion of multiple sparse auto-encoders to collect multi-feature information, and obtain a trend curve representing machine condition as well as a threshold line that can indicate the beginning of mechanical failure by computing the square prediction error (SPE). Then, convolutional neural networks predict the state of the machine according to the original data when the SPE value exceeds the threshold line. It can be seen from this result that the EFHNN method in the prediction of mechanical fault time series is available and superior.
KW  - mechanical equipment
KW  - error fusion of multiple SAEs (EFMSAE)
KW  - convolutional neural networks (CNN)
KW  - prediction
DO  - 10.3390/s21124043
TY  - EJOU
AU  - Aslahishahri, Masoomeh
AU  - Stanley, Kevin G.
AU  - Duddu, Hema
AU  - Shirtliffe, Steve
AU  - Vail, Sally
AU  - Stavness, Ian
TI  - Spatial Super Resolution of Real-World Aerial Images for Image-Based Plant Phenotyping
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 12
SN  - 2072-4292

AB  - Unmanned aerial vehicle (UAV) imaging is a promising data acquisition technique for image-based plant phenotyping. However, UAV images have a lower spatial resolution than similarly equipped in field ground-based vehicle systems, such as carts, because of their distance from the crop canopy, which can be particularly problematic for measuring small-sized plant features. In this study, the performance of three deep learning-based super resolution models, employed as a pre-processing tool to enhance the spatial resolution of low resolution images of three different kinds of crops were evaluated. To train a super resolution model, aerial images employing two separate sensors co-mounted on a UAV flown over lentil, wheat and canola breeding trials were collected. A software workflow to pre-process and align real-world low resolution and high-resolution images and use them as inputs and targets for training super resolution models was created. To demonstrate the effectiveness of real-world images, three different experiments employing synthetic images, manually downsampled high resolution images, or real-world low resolution images as input to the models were conducted. The performance of the super resolution models demonstrates that the models trained with synthetic images cannot generalize to real-world images and fail to reproduce comparable images with the targets. However, the same models trained with real-world datasets can reconstruct higher-fidelity outputs, which are better suited for measuring plant phenotypes.
KW  - aerial imaging
KW  - super resolution
KW  - pixel size
KW  - raw data pre-processing
KW  - radiometric calibration
KW  - real-world dataset
KW  - plant phenotyping
DO  - 10.3390/rs13122308
TY  - EJOU
AU  - Mokhtari, Ali
AU  - Ahmadi, Arman
AU  - Daccache, Andre
AU  - Drechsler, Kelley
TI  - Actual Evapotranspiration from UAV Images: A Multi-Sensor Data Fusion Approach
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 12
SN  - 2072-4292

AB  - Multispectral imaging using Unmanned Aerial Vehicles (UAVs) has changed the pace of precision agriculture. Actual evapotranspiration (ETa) from the very high spatial resolution of UAV images over agricultural fields can help farmers increase their production at the lowest possible cost. ETa estimation using UAVs requires a full package of sensors capturing the visible/infrared and thermal portions of the spectrum. Therefore, this study focused on a multi-sensor data fusion approach for ETa estimation (MSDF-ET) independent of thermal sensors. The method was based on sharpening the Landsat 8 pixels to UAV spatial resolution by considering the relationship between reference ETa fraction (ETrf) and a Vegetation Index (VI). Four Landsat 8 images were processed to calculate ETa of three UAV images over three almond fields. Two flights coincided with the overpasses and one was in between two consecutive Landsat 8 images. ETrf was chosen instead of ETa to interpolate the Landsat 8-derived ETrf images to obtain an ETrf image on the UAV flight. ETrf was defined as the ratio of ETa to grass reference evapotranspiration (ETr), and the VIs tested in this study included the Normalized Difference Vegetation Index (NDVI), Soil Adjusted Vegetation Index (SAVI), Enhanced Vegetation Index (EVI), Normalized Difference Water Index (NDWI), and Land Surface Water Index (LSWI). NDVI performed better under the study conditions. The MSDF-ET-derived ETa showed strong correlations against measured ETa, UAV- and Landsat 8-based METRIC ETa. Also, visual comparison of the MSDF-ET ETa maps was indicative of a promising performance of the method. In sum, the resulting ETa had a higher spatial resolution compared with thermal-based ETa without the need for the Albedo and hot/cold pixels selection procedure. However, wet soils were poorly detected, and in cases of continuous cloudy Landsat pixels the long interval between the images may cause biases in ETa estimation from the MSDF-ET method. Generally, the MSDF-ET method reduces the need for very high resolution thermal information from the ground, and the calculations can be conducted on a moderate-performance computer system because the main image processing is applied on Landsat images with coarser spatial resolutions.
KW  - actual evapotranspiration
KW  - multi-sensor data fusion
KW  - Landsat 8
KW  - unmanned aerial vehicle
KW  - vegetation indices
DO  - 10.3390/rs13122315
TY  - EJOU
AU  - Lema, Darío G.
AU  - Pedrayes, Oscar D.
AU  - Usamentiaga, Rubén
AU  - García, Daniel F.
AU  - Alonso, Ángela
TI  - Cost-Performance Evaluation of a Recognition Service of Livestock Activity Using Aerial Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 12
SN  - 2072-4292

AB  - The recognition of livestock activity is essential to be eligible for subsides, to automatically supervise critical activities and to locate stray animals. In recent decades, research has been carried out into animal detection, but this paper also analyzes the detection of other key elements that can be used to verify the presence of livestock activity in a given terrain: manure piles, feeders, silage balls, silage storage areas, and slurry pits. In recent years, the trend is to apply Convolutional Neuronal Networks (CNN) as they offer significantly better results than those obtained by traditional techniques. To implement a livestock activity detection service, the following object detection algorithms have been evaluated: YOLOv2, YOLOv4, YOLOv5, SSD, and Azure Custom Vision. Since YOLOv5 offers the best results, producing a mean average precision (mAP) of 0.94, this detector is selected for the creation of a livestock activity recognition service. In order to deploy the service in the best infrastructure, the performance/cost ratio of various Azure cloud infrastructures are analyzed and compared with a local solution. The result is an efficient and accurate service that can help to identify the presence of livestock activity in a specified terrain.
KW  - livestock activity recognition
KW  - Azure
KW  - cloud service deployment and cost-performance evaluation
KW  - aerial images
KW  - CNNs
KW  - YOLOv2
KW  - YOLOv4
KW  - YOLOv5
KW  - SSD
KW  - Azure Custom Vision
DO  - 10.3390/rs13122318
TY  - EJOU
AU  - Saad, Mohamad H.
AU  - Hamdan, Nurul M.
AU  - Sarker, Mahidur R.
TI  - State of the Art of Urban Smart Vertical Farming Automation System: Advanced Topologies, Issues and Recommendations
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 12
SN  - 2079-9292

AB  - The global economy is now under threat due to the ongoing domestic and international lockdown for COVID-19. Many have already lost their jobs, and businesses have been unstable in the Corona era. Apart from educational institutions, banks, privately owned institutions, and agriculture, there are signs of economic recession in almost all sectors. The roles of modern technology, the Internet of things, and artificial intelligence are undeniable in helping the world achieve economic prosperity in the post-COVID-19 economic downturn. Food production must increase by 60% by 2050 to meet global food security demands in the face of uncertainty such as the COVID-19 pandemic and a growing population. Given COVID 19’s intensity and isolation, improving food production and distribution systems is critical to combating hunger and addressing the double burden of malnutrition. As the world’s population is growing day by day, according to an estimation world’s population reaches 9.6 billion by 2050, so there is a growing need to modify the agriculture methods, technologies so that maximum crops can be attained and human effort can be reduced. The urban smart vertical farming (USVF) is a solution to secure food production, which can be introduced at any adaptive reuse, retrofit, or new buildings in vertical manners. This paper aims to provide a comprehensive review of the concept of USVF using various techniques to enhance productivity as well as its types, topologies, technologies, control systems, social acceptance, and benefits. This review has focused on numerous issues, challenges, and recommendations in the development of the system, vertical farming management, and modern technologies approach.
KW  - automation
KW  - smart vertical farming
KW  - sensors
KW  - Internet of Things
KW  - urban farming
DO  - 10.3390/electronics10121422
TY  - EJOU
AU  - Kim, Jingyeom
AU  - Lee, Joohyung
AU  - Kim, Taeyeon
TI  - AdaMM: Adaptive Object Movement and Motion Tracking in Hierarchical Edge Computing System
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 12
SN  - 1424-8220

AB  - This paper presents a novel adaptive object movement and motion tracking (AdaMM) framework in a hierarchical edge computing system for achieving GPU memory footprint reduction of deep learning (DL)-based video surveillance services. DL-based object movement and motion tracking requires a significant amount of resources, such as (1) GPU processing power for the inference phase and (2) GPU memory for model loading. Despite the absence of an object in the video, if the DL model is loaded, the GPU memory must be kept allocated for the loaded model. Moreover, in several cases, video surveillance tries to capture events that rarely occur (e.g., abnormal object behaviors); therefore, such standby GPU memory might be easily wasted. To alleviate this problem, the proposed AdaMM framework categorizes the tasks used for the object movement and motion tracking procedure in an increasing order of the required processing and memory resources as task (1) frame difference calculation, task (2) object detection, and task (3) object motion and movement tracking. The proposed framework aims to adaptively release the unnecessary standby object motion and movement tracking model to save GPU memory by utilizing light tasks, such as frame difference calculation and object detection in a hierarchical manner. Consequently, object movement and motion tracking are adaptively triggered if the object is detected within the specified threshold time; otherwise, the GPU memory for the model of task (3) can be released. Moreover, object detection is also adaptively performed if the frame difference over time is greater than the specified threshold. We implemented the proposed AdaMM framework using commercial edge devices by considering a three-tier system, such as the 1st edge node for both tasks (1) and (2), the 2nd edge node for task (3), and the cloud for sending a push alarm. A measurement-based experiment reveals that the proposed framework achieves a maximum GPU memory reduction of 76.8% compared to the baseline system, while requiring a 2680 ms delay for loading the model for object movement and motion tracking.
KW  - EdgeAI
KW  - hierarchical edge computing
KW  - deep learning
KW  - object detection and tracking
KW  - software implementation
DO  - 10.3390/s21124089
TY  - EJOU
AU  - Tasseron, Paolo
AU  - van Emmerik, Tim
AU  - Peller, Joseph
AU  - Schreyers, Louise
AU  - Biermann, Lauren
TI  - Advancing Floating Macroplastic Detection from Space Using Experimental Hyperspectral Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 12
SN  - 2072-4292

AB  - Airborne and spaceborne remote sensing (RS) collecting hyperspectral imagery provides unprecedented opportunities for the detection and monitoring of floating riverine and marine plastic debris. However, a major challenge in the application of RS techniques is the lack of a fundamental understanding of spectral signatures of water-borne plastic debris. Recent work has emphasised the case for open-access hyperspectral reflectance reference libraries of commonly used polymer items. In this paper, we present and analyse a high-resolution hyperspectral image database of a unique mix of 40 virgin macroplastic items and vegetation. Our double camera setup covered the visible to shortwave infrared (VIS-SWIR) range from 400 to 1700 nm in a darkroom experiment with controlled illumination. The cameras scanned the samples floating in water and captured high-resolution images in 336 spectral bands. Using the resulting reflectance spectra of 1.89 million pixels in linear discriminant analyses (LDA), we determined the importance of each spectral band for discriminating between water and mixed floating debris, and vegetation and plastics. The absorption peaks of plastics (1215 nm, 1410 nm) and vegetation (710 nm, 1450 nm) are associated with high LDA weights. We then compared Sentinel-2 and Worldview-3 satellite bands with these outcomes and identified 12 satellite bands to overlap with important wavelengths for discrimination between the classes. Lastly, the Normalised Vegetation Difference Index (NDVI) and Floating Debris Index (FDI) were calculated to determine why they work, and how they could potentially be improved. These findings could be used to enhance existing efforts in monitoring macroplastic pollution, as well as form a baseline for the design of future multispectral RS systems.
KW  - remote sensing
KW  - Sentinel-2
KW  - earth observation
KW  - plastic monitoring
KW  - spectral reflectance
DO  - 10.3390/rs13122335
TY  - EJOU
AU  - Hwang, Kyunghun
AU  - Park, Joonghoo
AU  - Kim, Heejung
AU  - Kuc, Tea-Yong
AU  - Lim, Sejoon
TI  - Development of a Simple Robotic Driver System (SimRoDS) to Test Fuel Economy of Hybrid Electric and Plug-In Hybrid Electric Vehicles Using Fuzzy-PI Control
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 12
SN  - 2079-9292

AB  - Over the past decade, new models of hybrid electric vehicles have been released worldwide, and the fuel efficiency of said vehicles has increased by more than 5%. To further improve fuel efficiency, vehicle manufacturers have made efforts to design modules (e.g., engines, motors, transmissions, and batteries) with the highest efficiency possible. To do so, the fuel economy test process, which is conducted primarily using a chassis dynamometer, must produce reliable and accurate results. To accurately analyze the fuel efficiency improvement rate of each module, it is necessary to reduce the test deviation. When the test conducted by human drivers, the test deviation is somewhat large. When the test is conducted by a physical robot driver, the test deviation is improved; however, these robots are expensive and time-consuming to install and take up considerable amount of space in the driver’s seat. To compensate for these shortcomings, we propose a simple, structured robot system that manipulates electrical signals without using mechanical link structures. The controller of this robot driver uses the widely used PI controller. Although PI controllers are simple and perform well, since the dynamics of each test vehicle is different (e.g., acceleration response), the PI controller has a disadvantage in that it cannot determine the optimal PI gain value for each vehicles. In this work, the fuzzy control theorem is applied to overcome this disadvantage. By using fuzzy control to deduce the optimal value of the PI gain, we confirmed that our proposed system is available to conduct tests on vehicles with different dynamics.
KW  - robot driver
KW  - fuzzy control
KW  - PI gain tuning
KW  - fuel economy
KW  - acceleration position signal
KW  - brake position signal
DO  - 10.3390/electronics10121444
TY  - EJOU
AU  - Geng, Liying
AU  - Che, Tao
AU  - Ma, Mingguo
AU  - Tan, Junlei
AU  - Wang, Haibo
TI  - Corn Biomass Estimation by Integrating Remote Sensing and Long-Term Observation Data Based on Machine Learning Techniques
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 12
SN  - 2072-4292

AB  - The accurate and timely estimation of regional crop biomass at different growth stages is of great importance in guiding crop management decision making. The recent availability of long time series of remote sensing data offers opportunities for crop monitoring. In this paper, four machine learning models, namely random forest (RF), support vector machine (SVM), artificial neural network (ANN), and extreme gradient boosting (XGBoost) were adopted to estimate the seasonal corn biomass based on field observation data and moderate resolution imaging spectroradiometer (MODIS) reflectance data from 2012 to 2019 in the middle reaches of the Heihe River basin, China. Nine variables were selected with the forward feature selection approach from among twenty-seven variables potentially influencing corn biomass: soil-adjusted total vegetation index (SATVI), green ratio vegetation index (GRVI), Nadir_B7 (2105–2155 nm), Nadir_B6 (1628–1652 nm), land surface water index (LSWI), normalized difference vegetation index (NDVI), Nadir_B4 (545–565 nm), and Nadir_B3 (459–479 nm). The results indicated that the corn biomass was suitably estimated (the coefficient of determination (R2) was between 0.72 and 0.78) with the four machine learning models. The XGBoost model performed better than the other three models (R2 = 0.78, root mean squared error (RMSE) = 2.86 t/ha and mean absolute error (MAE) = 1.86 t/ha). Moreover, the RF model was an effective method (R2 = 0.77, RMSE = 2.91 t/ha and MAE = 1.91 t/ha), with a performance comparable to that of the XGBoost model. This study provides a reference for estimating crop biomass from MOD43A4 datasets. In addition, the research demonstrates the potential of machine learning techniques to achieve a relatively accurate estimation of daily corn biomass at a large scale.
KW  - corn
KW  - biomass
KW  - field data
KW  - MODIS
KW  - machine learning models
DO  - 10.3390/rs13122352
TY  - EJOU
AU  - Zeng, Linglin
AU  - Hu, Yuchao
AU  - Wang, Rui
AU  - Zhang, Xiang
AU  - Peng, Guozhang
AU  - Huang, Zhenyu
AU  - Zhou, Guoqing
AU  - Xiang, Daxiang
AU  - Meng, Ran
AU  - Wu, Weixiong
AU  - Hu, Shun
TI  - 8-Day and Daily Maximum and Minimum Air Temperature Estimation via Machine Learning Method on a Climate Zone to Global Scale
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 12
SN  - 2072-4292

AB  - Air temperature (Ta) is a required input in a wide range of applications, e.g., agriculture. Land Surface Temperature (LST) products from Moderate Resolution Imaging Spectroradiometer (MODIS) are widely used to estimate Ta. Previous studies of these products in Ta estimation, however, were generally applied in small areas and with a small number of meteorological stations. This study designed both temporal and spatial experiments to estimate 8-day and daily maximum and minimum Ta (Tmax and Tmin) on three spatial scales: climate zone, continental and global scales from 2009 to 2018, using the Random Forest (RF) method based on MODIS LST products and other auxiliary data. Factors contributing to the relation between LST and Ta were determined based on physical models and equations. Temporal and spatial experiments were defined by the rules of dividing the training and validation datasets for the RF method, in which the stations selected in the training dataset were all included or not in the validation dataset. The RF model was first trained and validated on each spatial scale, respectively. On a global scale, model accuracy with a determination coefficient (R2) &gt; 0.96 and root mean square error (RMSE) &lt; 1.96 °C and R2 &gt; 0.95 and RMSE &lt; 2.55 °C was achieved for 8-day and daily Ta estimations, respectively, in both temporal and spatial experiments. Then the model was trained and cross-validated on each spatial scale. The results showed that the data size and station distribution of the study area were the main factors influencing the model performance at different spatial scales. Finally, the spatial patterns of the model performance and variable importance were analyzed. Both daytime and nighttime LST had a significant contribution in the 8-day Tmax estimation on all the three spatial scales; while their contribution in daily Tmax estimation varied over different continents or climate zones. This study was expected to improve our understanding of Ta estimation in terms of accuracy variations and influencing variables on different spatial and temporal scales. The future work mainly includes identifying underlying mechanisms of estimation errors and the uncertainty sources of Ta estimation from a local to a global scale.
KW  - MODIS
KW  - air temperature estimation
KW  - remote sensing
KW  - land surface temperature
KW  - nighttime LST
DO  - 10.3390/rs13122355
TY  - EJOU
AU  - Planke, Lars J.
AU  - Gardi, Alessandro
AU  - Sabatini, Roberto
AU  - Kistan, Trevor
AU  - Ezer, Neta
TI  - Online Multimodal Inference of Mental Workload for Cognitive Human Machine Systems
T2  - Computers

PY  - 2021
VL  - 10
IS  - 6
SN  - 2073-431X

AB  - With increasingly higher levels of automation in aerospace decision support systems, it is imperative that the human operator maintains the required level of situational awareness in different operational conditions and a central role in the decision-making process. While current aerospace systems and interfaces are limited in their adaptability, a Cognitive Human Machine System (CHMS) aims to perform dynamic, real-time system adaptation by estimating the cognitive states of the human operator. Nevertheless, to reliably drive system adaptation of current and emerging aerospace systems, there is a need to accurately and repeatably estimate cognitive states, particularly for Mental Workload (MWL), in real-time. As part of this study, two sessions were performed during a Multi-Attribute Task Battery (MATB) scenario, including a session for offline calibration and validation and a session for online validation of eleven multimodal inference models of MWL. The multimodal inference model implemented included an Adaptive Neuro Fuzzy Inference System (ANFIS), which was used in different configurations to fuse data from an Electroencephalogram (EEG) model’s output, four eye activity features and a control input feature. The online validation of the ANFIS models produced good results, while the best performing model (containing all four eye activity features and the control input feature) showed an average Mean Absolute Error (MAE) = 0.67 ± 0.18 and Correlation Coefficient (CC) = 0.71 ± 0.15. The remaining six ANFIS models included data from the EEG model’s output, which had an offset discrepancy. This resulted in an equivalent offset for the online multimodal fusion. Nonetheless, the efficacy of these ANFIS models could be confirmed by the pairwise correlation with the task level, where one model demonstrated a CC = 0.77 ± 0.06, which was the highest among all of the ANFIS models tested. Hence, this study demonstrates the suitability for online multimodal fusion of features extracted from EEG signals, eye activity and control inputs to produce an accurate and repeatable inference of MWL.
KW  - mental workload
KW  - EEG
KW  - eye tracking
KW  - control inputs
KW  - closed loop system adaptation
KW  - adaptive automation
KW  - multimodal data fusion
KW  - machine learning
KW  - ANFIS
DO  - 10.3390/computers10060081
TY  - EJOU
AU  - Linaza, Maria T.
AU  - Posada, Jorge
AU  - Bund, Jürgen
AU  - Eisert, Peter
AU  - Quartulli, Marco
AU  - Döllner, Jürgen
AU  - Pagani, Alain
AU  - G. Olaizola, Igor
AU  - Barriguinha, Andre
AU  - Moysiadis, Theocharis
AU  - Lucat, Laurent
TI  - Data-Driven Artificial Intelligence Applications for Sustainable Precision Agriculture
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 6
SN  - 2073-4395

AB  - One of the main challenges for the implementation of artificial intelligence (AI) in agriculture includes the low replicability and the corresponding difficulty in systematic data gathering, as no two fields are exactly alike. Therefore, the comparison of several pilot experiments in different fields, weather conditions and farming techniques enhances the collective knowledge. Thus, this work provides a summary of the most recent research activities in the form of research projects implemented and validated by the authors in several European countries, with the objective of presenting the already achieved results, the current investigations and the still open technical challenges. As an overall conclusion, it can be mentioned that even though in their primary stages in some cases, AI technologies improve decision support at farm level, monitoring conditions and optimizing production to allow farmers to apply the optimal number of inputs for each crop, thereby boosting yields and reducing water use and greenhouse gas emissions. Future extensions of this work will include new concepts based on autonomous and intelligent robots for plant and soil sample retrieval, and effective livestock management.
KW  - agriculture
KW  - artificial intelligence
KW  - data analysis
KW  - computer vision
KW  - robotics
DO  - 10.3390/agronomy11061227
TY  - EJOU
AU  - Siemiatkowska, Barbara
AU  - Stecz, Wojciech
TI  - A Framework for Planning and Execution of Drone Swarm Missions in a Hostile Environment
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 12
SN  - 1424-8220

AB  - This article presents a framework for planning a drone swarm mission in a hostile environment. Elements of the planning framework are discussed in detail, including methods of planning routes for drone swarms using mixed integer linear programming (MILP) and methods of detecting potentially dangerous objects using EO/IR camera images and synthetic aperture radar (SAR). Methods of detecting objects in the field are used in the mission planning process to re-plan the swarm’s flight paths. The route planning model is discussed using the example of drone formations managed by one UAV that communicates through another UAV with the ground control station (GCS). This article presents practical examples of using algorithms for detecting dangerous objects for re-planning of swarm routes. A novelty in the work is the development of these algorithms in such a way that they can be implemented on mobile computers used by UAVs and integrated with MILP tasks. The methods of detection and classification of objects in real time by UAVs equipped with SAR and EO/IR are presented. Different sensors require different methods to detect objects. In the case of infrared or optoelectronic sensors, a convolutional neural network is used. For SAR images, a rule-based system is applied. The experimental results confirm that the stream of images can be analyzed in real-time.
KW  - mission planning
KW  - UAV swarms
KW  - object detection
KW  - CNN
KW  - SAR
KW  - EO
DO  - 10.3390/s21124150
TY  - EJOU
AU  - Lee, Thomas
AU  - Mckeever, Susan
AU  - Courtney, Jane
TI  - Flying Free: A Research Overview of Deep Learning in Drone Navigation Autonomy
T2  - Drones

PY  - 2021
VL  - 5
IS  - 2
SN  - 2504-446X

AB  - With the rise of Deep Learning approaches in computer vision applications, significant strides have been made towards vehicular autonomy. Research activity in autonomous drone navigation has increased rapidly in the past five years, and drones are moving fast towards the ultimate goal of near-complete autonomy. However, while much work in the area focuses on specific tasks in drone navigation, the contribution to the overall goal of autonomy is often not assessed, and a comprehensive overview is needed. In this work, a taxonomy of drone navigation autonomy is established by mapping the definitions of vehicular autonomy levels, as defined by the Society of Automotive Engineers, to specific drone tasks in order to create a clear definition of autonomy when applied to drones. A top–down examination of research work in the area is conducted, focusing on drone navigation tasks, in order to understand the extent of research activity in each area. Autonomy levels are cross-checked against the drone navigation tasks addressed in each work to provide a framework for understanding the trajectory of current research. This work serves as a guide to research in drone autonomy with a particular focus on Deep Learning-based solutions, indicating key works and areas of opportunity for development of this area in the future.
KW  - artificial intelligence
KW  - deep learning
KW  - neural networks
KW  - artificial neural networks
KW  - multi-layer neural network
KW  - neural network hardware
KW  - autonomous systems
KW  - internet of things
KW  - machine vision
KW  - unmanned autonomous vehicles
KW  - unmanned aerial vehicles
DO  - 10.3390/drones5020052
TY  - EJOU
AU  - An, Kang
AU  - Chen, Yixin
AU  - Wang, Suhong
AU  - Xiao, Zhifeng
TI  - RCBi-CenterNet: An Absolute Pose Policy for 3D Object Detection in Autonomous Driving
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 12
SN  - 2076-3417

AB  - 3D Object detection is a critical mission of the perception system of a self-driving vehicle. Existing bounding box-based methods are hard to train due to the need to remove duplicated detections in the post-processing stage. In this paper, we propose a center point-based deep neural network (DNN) architecture named RCBi-CenterNet that predicts the absolute pose for each detected object in the 3D world space. RCBi-CenterNet is composed of a recursive composite network with a dual-backbone feature extractor and a bi-directional feature pyramid network (BiFPN) for cross-scale feature fusion. In the detection head, we predict a confidence heatmap that is used to determine the position of detected objects. The other pose information, including depth and orientation, is regressed. We conducted extensive experiments on the Peking University/Baidu-Autonomous Driving dataset, which contains more than 60,000 labeled 3D vehicle instances from 5277 real-world images, and each vehicle object is annotated with the absolute pose described by the six degrees of freedom (6DOF). We validated the design choices of various data augmentation methods and the backbone options. Through an ablation study and an overall comparison with the state-of-the-art (SOTA), namely CenterNet, we showed that the proposed RCBi-CenterNet presents performance gains of 2.16%, 2.76%, and 5.24% in Top 1, Top 3, and Top 10 mean average precision (mAP). The model and the result could serve as a credible benchmark for future research in center point-based object detection.
KW  - object detection
KW  - CenterNet
KW  - absolute pose
KW  - feature fusion
KW  - autonomous driving
KW  - feature pyramid network
DO  - 10.3390/app11125621
TY  - EJOU
AU  - Marin, Ivana
AU  - Mladenović, Saša
AU  - Gotovac, Sven
AU  - Zaharija, Goran
TI  - Deep-Feature-Based Approach to Marine Debris Classification
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 12
SN  - 2076-3417

AB  - The global community has recognized an increasing amount of pollutants entering oceans and other water bodies as a severe environmental, economic, and social issue. In addition to prevention, one of the key measures in addressing marine pollution is the cleanup of debris already present in marine environments. Deployment of machine learning (ML) and deep learning (DL) techniques can automate marine waste removal, making the cleanup process more efficient. This study examines the performance of six well-known deep convolutional neural networks (CNNs), namely VGG19, InceptionV3, ResNet50, Inception-ResNetV2, DenseNet121, and MobileNetV2, utilized as feature extractors according to three different extraction schemes for the identification and classification of underwater marine debris. We compare the performance of a neural network (NN) classifier trained on top of deep CNN feature extractors when the feature extractor is (1) fixed; (2) fine-tuned on the given task; (3) fixed during the first phase of training and fine-tuned afterward. In general, fine-tuning resulted in better-performing models but is much more computationally expensive. The overall best NN performance showed the fine-tuned Inception-ResNetV2 feature extractor with an accuracy of 91.40% and F1-score 92.08%, followed by fine-tuned InceptionV3 extractor. Furthermore, we analyze conventional ML classifiers’ performance when trained on features extracted with deep CNNs. Finally, we show that replacing NN with a conventional ML classifier, such as support vector machine (SVM) or logistic regression (LR), can further enhance the classification performance on new data.
KW  - deep learning
KW  - marine litter classification
KW  - feature vectors
KW  - transfer learning
KW  - computer vision
DO  - 10.3390/app11125644
TY  - EJOU
AU  - Peprah, Clement O.
AU  - Yamashita, Megumi
AU  - Yamaguchi, Tomoaki
AU  - Sekino, Ryo
AU  - Takano, Kyohei
AU  - Katsura, Keisuke
TI  - Spatio-Temporal Estimation of Biomass Growth in Rice Using Canopy Surface Model from Unmanned Aerial Vehicle Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 12
SN  - 2072-4292

AB  - The awareness of spatial and temporal variations in site-specific crop parameters, such as aboveground biomass (total dry weight: (TDW), plant length (PL) and leaf area index (LAI), help in formulating appropriate management decisions. However, conventional monitoring methods rely on time-consuming manual field operations. In this study, the feasibility of using an unmanned aerial vehicle (UAV)-based remote sensing approach for monitoring growth in rice was evaluated using a digital surface model (DSM). Approximately 160 images of paddy fields were captured during each UAV survey campaign over two vegetation seasons. The canopy surface model (CSM) was developed based on the differences observed between each DSM and the first DSM after transplanting. Mean canopy height (CH) was used as a variable for the estimation models of LAI and TDW. The mean CSM of the mesh covering several hills was sufficient to explain the PL (R2 = 0.947). TDW and LAI prediction accuracy of the model were high (relative RMSE of 20.8% and 28.7%, and RMSE of 0.76 m2 m−2 and 141.4 g m−2, respectively) in the rice varieties studied (R2 = 0.937 (Basmati370), 0.837 (Nipponbare and IR64) for TDW, and 0.894 (Basmati370), 0.866 (Nipponbare and IR64) for LAI). The results of this study support the assertion of the benefits of DSM-derived CH for predicting biomass development. In addition, LAI and TDW could be estimated temporally and spatially using the UAV-based CSM, which is not easily affected by weather conditions.
KW  - precision agriculture
KW  - unmanned aerial vehicle
KW  - digital surface model
KW  - leaf area index
KW  - rice
KW  - biomass
DO  - 10.3390/rs13122388
TY  - EJOU
AU  - Albuquerque, Rafael W.
AU  - Ferreira, Manuel E.
AU  - Olsen, Søren I.
AU  - Tymus, Julio R.
AU  - Balieiro, Cintia P.
AU  - Mansur, Hendrik
AU  - Moura, Ciro J.
AU  - Costa, João V.
AU  - Branco, Maurício R.
AU  - Grohmann, Carlos H.
TI  - Forest Restoration Monitoring Protocol with a Low-Cost Remotely Piloted Aircraft: Lessons Learned from a Case Study in the Brazilian Atlantic Forest
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 12
SN  - 2072-4292

AB  - Traditional forest restoration (FR) monitoring methods employ spreadsheets and photos taken at the ground level. Since remotely piloted aircraft (RPA) generate a panoramic high resolution and georeferenced view of the entire area of interest, this technology has high potential to improve the traditional FR monitoring methods. This study evaluates how low-cost RPA data may contribute to FR monitoring of the Brazilian Atlantic Forest by the automatic remote measurement of Tree Density, Tree Height, Vegetation Cover (area covered by trees), and Grass Infestation. The point cloud data was processed to map the Tree Density, Tree Height, and Vegetation Cover parameters. The orthomosaic was used for a Random Forest classification that considered trees and grasses as a single land cover class. The Grass Infestation parameter was mapped by the difference between this land cover class (which considered trees and grasses) and the Vegetation Cover results (obtained by the point cloud data processing). Tree Density, Vegetation Cover, and Grass Infestation parameters presented F_scores of 0.92, 0.85, and 0.64, respectively. Tree Height accuracy was indicated by the Error Percentage considering the traditional fieldwork and the RPA results. The Error Percentage was equal to 0.13 and was considered accurate because it estimated a 13% shorter height for trees that averaged 1.93 m tall. Thus, this study showed that the FR structural parameters were accurately measured by the low-cost RPA, a technology that contributes to FR monitoring. Despite accurately measuring the structural parameters, this study reinforced the challenge of measuring the Biodiversity parameter via remote sensing because the classification of tree species was not possible. After all, the Brazilian Atlantic Forest is a biodiversity hotspot, and thus different species have similar spectral responses in the visible spectrum and similar geometric forms. Therefore, until improved automatic classification methods become available for tree species, traditional fieldwork remains necessary for a complete FR monitoring diagnostic.
KW  - Atlantic Forest
KW  - drones
KW  - SfM-MVS
KW  - structural parameters
KW  - unmanned aerial vehicle
DO  - 10.3390/rs13122401
TY  - EJOU
AU  - Perich, Gregor
AU  - Aasen, Helge
AU  - Verrelst, Jochem
AU  - Argento, Francesco
AU  - Walter, Achim
AU  - Liebisch, Frank
TI  - Crop Nitrogen Retrieval Methods for Simulated Sentinel-2 Data Using In-Field Spectrometer Data
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 12
SN  - 2072-4292

AB  - Nitrogen (N) is one of the key nutrients supplied in agricultural production worldwide. Over-fertilization can have negative influences on the field and the regional level (e.g., agro-ecosystems). Remote sensing of the plant N of field crops presents a valuable tool for the monitoring of N flows in agro-ecosystems. Available data for validation of satellite-based remote sensing of N is scarce. Therefore, in this study, field spectrometer measurements were used to simulate data of the Sentinel-2 (S2) satellites developed for vegetation monitoring by the ESA. The prediction performance of normalized ratio indices (NRIs), random forest regression (RFR) and Gaussian processes regression (GPR) for plant-N-related traits was assessed on a diverse real-world dataset including multiple crops, field sites and years. The plant N traits included the mass-based N measure, N concentration in the biomass (Nconc), and an area-based N measure approximating the plant N uptake (NUP). Spectral indices such as normalized ratio indices (NRIs) performed well, but the RFR and GPR methods outperformed the NRIs. Key spectral bands for each trait were identified using the RFR variable importance measure and the Gaussian processes regression band analysis tool (GPR-BAT), highlighting the importance of the short-wave infrared (SWIR) region for estimation of plant Nconc—and to a lesser extent the NUP. The red edge (RE) region was also important. The GPR-BAT showed that five bands were sufficient for plant N trait and leaf area index (LAI) estimation and that a surplus of bands effectively reduced prediction performance. A global sensitivity analysis (GSA) was performed on all traits simultaneously, showing the dominance of the LAI in the mixed remote sensing signal. To delineate the plant-N-related traits from this signal, regional and/or national data collection campaigns producing large crop spectral libraries (CSL) are needed. An improved database will likely enable the mapping of N at the agro-ecosystem level or for use in precision farming by farmers in the future.
KW  - nitrogen
KW  - chlorophyll
KW  - leaf area index
KW  - agro-ecosystem monitoring
KW  - spectral indices
KW  - random forest
KW  - gaussian processes regression
KW  - ARTMO toolbox
DO  - 10.3390/rs13122404
TY  - EJOU
AU  - Li, Minhui
AU  - Shamshiri, Redmond R.
AU  - Schirrmann, Michael
AU  - Weltzien, Cornelia
TI  - Impact of Camera Viewing Angle for Estimating Leaf Parameters of Wheat Plants from 3D Point Clouds
T2  - Agriculture

PY  - 2021
VL  - 11
IS  - 6
SN  - 2077-0472

AB  - Estimation of plant canopy using low-altitude imagery can help monitor the normal growth status of crops and is highly beneficial for various digital farming applications such as precision crop protection. However, extracting 3D canopy information from raw images requires studying the effect of sensor viewing angle by taking into accounts the limitations of the mobile platform routes inside the field. The main objective of this research was to estimate wheat (Triticum aestivum L.) leaf parameters, including leaf length and width, from the 3D model representation of the plants. For this purpose, experiments with different camera viewing angles were conducted to find the optimum setup of a mono-camera system that would result in the best 3D point clouds. The angle-control analytical study was conducted on a four-row wheat plot with a row spacing of 0.17 m and with two seeding densities and growth stages as factors. Nadir and six oblique view image datasets were acquired from the plot with 88% overlapping and were then reconstructed to point clouds using Structure from Motion (SfM) and Multi-View Stereo (MVS) methods. Point clouds were first categorized into three classes as wheat canopy, soil background, and experimental plot. The wheat canopy class was then used to extract leaf parameters, which were then compared with those values from manual measurements. The comparison between results showed that (i) multiple-view dataset provided the best estimation for leaf length and leaf width, (ii) among the single-view dataset, canopy, and leaf parameters were best modeled with angles vertically at −45° and horizontally at 0° (VA −45, HA 0), while (iii) in nadir view, fewer underlying 3D points were obtained with a missing leaf rate of 70%. It was concluded that oblique imagery is a promising approach to effectively estimate wheat canopy 3D representation with SfM-MVS using a single camera platform for crop monitoring. This study contributes to the improvement of the proximal sensing platform for crop health assessment.
KW  - digital agriculture
KW  - 3D photogrammetry
KW  - response surface methodology
KW  - structure from motion (SfM)
KW  - multi-view stereo (MVS)
DO  - 10.3390/agriculture11060563
TY  - EJOU
AU  - Chen, Fang
TI  - Comparing Methods for Segmenting Supra-Glacial Lakes and Surface Features in the Mount Everest Region of the Himalayas Using Chinese GaoFen-3 SAR Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - Glaciers and numerous glacial lakes that are produced by glacier melting are key indicators of climate change. Often overlooked, supra-glacial lakes develop in the melting area in the low-lying part of a glacier and appear to be highly variable in their size, shape, and location. The lifespan of these lakes is thought to be quite transient, since the lakes may be completely filled by water and burst out within several weeks. Changes in supra-glacial lake outlines and other surface features such as supra-glacial rivers and crevasses on the glaciers are useful indicators for the direct monitoring of glacier changes. Synthetic aperture radar (SAR) is not affected by weather and climate, and is an effective tool for study of glaciated areas. The development of the Chinese GaoFen-3 (GF-3) SAR, which has high spatial and temporal resolution and high-precision observation performance, has made it possible to obtain dynamic information about glaciers in more detail. In this paper, the classical Canny operator, the variational B-spline level-set method, and U-Net-based deep-learning model were applied and compared to extract glacial lake outlines and other surface features using different modes and Chinese GF-3 SAR imagery in the Mount Everest Region of the Himalayas. Particularly, the U-Net-based deep-learning method, which was independent of auxiliary data and had a high degree of automation, was used for the first time in this context. The experimental results showed that the U-Net-based deep-learning model worked best in the segmentation of supra-glacial lakes in terms of accuracy (Precision = 98.45% and Recall = 95.82%) and segmentation efficiency, and was good at detecting small, elongated, and ice-covered supra-glacial lakes. We also found that it was useful for accurately identifying the location of supra-glacial streams and ice crevasses on glaciers, and quantifying their width. Finally, based on the time series of the mapping results, the spatial characteristics and temporal evolution of these features over the glaciers were comprehensively analyzed. Overall, this study presents a novel approach to improve the detection accuracy of glacier elements that could be leveraged for dynamic monitoring in future research.
KW  - GF-3
KW  - supra-glacial lakes
KW  - supra-glacial streams
KW  - ice crevasses
KW  - segmentation
KW  - digital disaster reduction
DO  - 10.3390/rs13132429
TY  - EJOU
AU  - Calamita, Federico
AU  - Imran, Hafiz A.
AU  - Vescovo, Loris
AU  - Mekhalfi, Mohamed L.
AU  - La Porta, Nicola
TI  - Early Identification of Root Rot Disease by Using Hyperspectral Reflectance: The Case of Pathosystem Grapevine/Armillaria
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - Armillaria genus represents one of the most common causes of chronic root rot disease in woody plants. Prompt recognition of diseased plants is crucial to control the pathogen. However, the current disease detection methods are limited at a field scale. Therefore, an alternative approach is needed. In this study, we investigated the potential of hyperspectral techniques to identify fungi-infected vs. healthy plants of Vitis vinifera. We used the hyperspectral imaging sensor Specim-IQ to acquire leaves’ reflectance data of the Teroldego Rotaliano grapevine cultivar. We analyzed three different groups of plants: healthy, asymptomatic, and diseased. Highly significant differences were found in the near-infrared (NIR) spectral region with a decreasing pattern from healthy to diseased plants attributable to the leaf mesophyll changes. Asymptomatic plants emerged from the other groups due to a lower reflectance in the red edge spectrum (around 705 nm), ascribable to an accumulation of secondary metabolites involved in plant defense strategies. Further significant differences were observed in the wavelengths close to 550 nm in diseased vs. asymptomatic plants. We evaluated several machine learning paradigms to differentiate the plant groups. The Naïve Bayes (NB) algorithm, combined with the most discriminant variables among vegetation indices and spectral narrow bands, provided the best results with an overall accuracy of 90% and 75% in healthy vs. diseased and healthy vs. asymptomatic plants, respectively. To our knowledge, this study represents the first report on the possibility of using hyperspectral data for root rot disease diagnosis in woody plants. Although further validation studies are required, it appears that the spectral reflectance technique, possibly implemented on unmanned aerial vehicles (UAVs), could be a promising tool for a cost-effective, non-invasive method of Armillaria disease diagnosis and mapping in-field, contributing to a significant step forward in precision viticulture.
KW  - agriculture 4.0
KW  - chlorophyll
KW  - early diagnosis
KW  - fungal tree pathogens
KW  - mycology
KW  - plant disease
KW  - plant pathology
KW  - smart viticulture
KW  - vegetation indices
KW  - wine grapes
DO  - 10.3390/rs13132436
TY  - EJOU
AU  - Lan, Tingting
AU  - Qin, Danyang
AU  - Sun, Guanyu
TI  - Joint Optimization on Trajectory, Cache Placement, and Transmission Power for Minimum Mission Time in UAV-Aided Wireless Networks
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 7
SN  - 2220-9964

AB  - In recent years, due to the strong mobility, easy deployment, and low cost of unmanned aerial vehicles (UAV), great interest has arisen in utilizing UAVs to assist in wireless communication, especially for on-demand deployment in emergency situations and temporary events. However, UAVs can only provide users with data transmission services through wireless backhaul links established with a ground base station, and the limited capacity of the wireless backhaul link would limit the transmission speed of UAVs. Therefore, this paper designed a UAV-assisted wireless communication system that used cache technology and realized the transmission of multi-user data by using the mobility of UAVs and wireless cache technology. Considering the limited storage space and energy of UAVs, the joint optimization problem of the UAV’s trajectory, cache placement, and transmission power was established to minimize the mission time of the UAV. Since this problem was a non-convex problem, it was decomposed into three sub-problems: trajectory optimization, cache placement optimization, and power allocation optimization. An iterative algorithm based on the successive convex approximation and alternate optimization techniques was proposed to solve these three optimization problems. Finally, in the power allocation optimization, the proposed algorithm was improved by changing the optimization objective function. Numerical results showed that the algorithm had good performance and could effectively reduce the task completion time of the UAV.
KW  - UAV
KW  - trajectory
KW  - cache placement
KW  - transmission power
DO  - 10.3390/ijgi10070426
TY  - EJOU
AU  - Martos, Vanesa
AU  - Ahmad, Ali
AU  - Cartujo, Pedro
AU  - Ordoñez, Javier
TI  - Ensuring Agricultural Sustainability through Remote Sensing in the Era of Agriculture 5.0
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 13
SN  - 2076-3417

AB  - Timely and reliable information about crop management, production, and yield is considered of great utility by stakeholders (e.g., national and international authorities, farmers, commercial units, etc.) to ensure food safety and security. By 2050, according to Food and Agriculture Organization (FAO) estimates, around 70% more production of agricultural products will be needed to fulfil the demands of the world population. Likewise, to meet the Sustainable Development Goals (SDGs), especially the second goal of “zero hunger”, potential technologies like remote sensing (RS) need to be efficiently integrated into agriculture. The application of RS is indispensable today for a highly productive and sustainable agriculture. Therefore, the present study draws a general overview of RS technology with a special focus on the principal platforms of this technology, i.e., satellites and remotely piloted aircrafts (RPAs), and the sensors used, in relation to the 5th industrial revolution. Nevertheless, since 1957, RS technology has found applications, through the use of satellite imagery, in agriculture, which was later enriched by the incorporation of remotely piloted aircrafts (RPAs), which is further pushing the boundaries of proficiency through the upgrading of sensors capable of higher spectral, spatial, and temporal resolutions. More prominently, wireless sensor technologies (WST) have streamlined real time information acquisition and programming for respective measures. Improved algorithms and sensors can, not only add significant value to crop data acquisition, but can also devise simulations on yield, harvesting and irrigation periods, metrological data, etc., by making use of cloud computing. The RS technology generates huge sets of data that necessitate the incorporation of artificial intelligence (AI) and big data to extract useful products, thereby augmenting the adeptness and efficiency of agriculture to ensure its sustainability. These technologies have made the orientation of current research towards the estimation of plant physiological traits rather than the structural parameters possible. Futuristic approaches for benefiting from these cutting-edge technologies are discussed in this study. This study can be helpful for researchers, academics, and young students aspiring to play a role in the achievement of sustainable agriculture.
KW  - agriculture 5.0
KW  - drones
KW  - remotely piloted aircrafts (RPAs)
KW  - precision agriculture
KW  - remote sensing
KW  - Internet of Things (IoT)
KW  - digital agriculture
KW  - sustainable development goals
KW  - sensors
KW  - agricultural robots
DO  - 10.3390/app11135911
TY  - EJOU
AU  - Meng, Baoping
AU  - Yang, Zhigui
AU  - Yu, Hongyan
AU  - Qin, Yu
AU  - Sun, Yi
AU  - Zhang, Jianguo
AU  - Chen, Jianjun
AU  - Wang, Zhiwei
AU  - Zhang, Wei
AU  - Li, Meng
AU  - Lv, Yanyan
AU  - Yi, Shuhua
TI  - Mapping of Kobresia pygmaea Community Based on Umanned Aerial Vehicle Technology and Gaofen Remote Sensing Data in Alpine Meadow Grassland: A Case Study in Eastern of Qinghai–Tibetan Plateau
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - The Kobresia pygmaea (KP) community is a key succession stage of alpine meadow degradation on the Qinghai–Tibet Plateau (QTP). However, most of the grassland classification and mapping studies have been performed at the grassland type level. The spatial distribution and impact factors of KP on the QTP are still unclear. In this study, field measurements of the grassland vegetation community in the eastern part of the QTP (Counties of Zeku, Henan and Maqu) from 2015 to 2019 were acquired using unmanned aerial vehicle (UAV) technology. The machine learning algorithms for grassland vegetation community classification were constructed by combining Gaofen satellite images and topographic indices. Then, the spatial distribution of KP community was mapped. The results showed that: (1) For all field observed sites, the alpine meadow vegetation communities demonstrated a considerable spatial heterogeneity. The traditional classification methods can hardly distinguish those communities due to the high similarity of their spectral characteristics. (2) The random forest method based on the combination of satellite vegetation indices, texture feature and topographic indices exhibited the best performance in three counties, with overall accuracy and Kappa coefficient ranged from 74.06% to 83.92% and 0.65 to 0.80, respectively. (3) As a whole, the area of KP community reached 1434.07 km2, and accounted for 7.20% of the study area. We concluded that the combination of satellite remote sensing, UAV surveying and machine learning can be used for KP classification and mapping at community level.
KW  - Kobresia pygmaea community
KW  - unmanned aerial vehicle
KW  - Gaofen satellite
KW  - spatial distribution
DO  - 10.3390/rs13132483
TY  - EJOU
AU  - Zamboni, Pedro
AU  - Junior, José M.
AU  - Silva, Jonathan D.
AU  - Miyoshi, Gabriela T.
AU  - Matsubara, Edson T.
AU  - Nogueira, Keiller
AU  - Gonçalves, Wesley N.
TI  - Benchmarking Anchor-Based and Anchor-Free State-of-the-Art Deep Learning Methods for Individual Tree Detection in RGB High-Resolution Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - Urban forests contribute to maintaining livability and increase the resilience of cities in the face of population growth and climate change. Information about the geographical distribution of individual trees is essential for the proper management of these systems. RGB high-resolution aerial images have emerged as a cheap and efficient source of data, although detecting and mapping single trees in an urban environment is a challenging task. Thus, we propose the evaluation of novel methods for single tree crown detection, as most of these methods have not been investigated in remote sensing applications. A total of 21 methods were investigated, including anchor-based (one and two-stage) and anchor-free state-of-the-art deep-learning methods. We used two orthoimages divided into 220 non-overlapping patches of 512 × 512 pixels with a ground sample distance (GSD) of 10 cm. The orthoimages were manually annotated, and 3382 single tree crowns were identified as the ground-truth. Our findings show that the anchor-free detectors achieved the best average performance with an AP50 of 0.686. We observed that the two-stage anchor-based and anchor-free methods showed better performance for this task, emphasizing the FSAF, Double Heads, CARAFE, ATSS, and FoveaBox models. RetinaNet, which is currently commonly applied in remote sensing, did not show satisfactory performance, and Faster R-CNN had lower results than the best methods but with no statistically significant difference. Our findings contribute to a better understanding of the performance of novel deep-learning methods in remote sensing applications and could be used as an indicator of the most suitable methods in such applications.
KW  - object detection
KW  - convolutional neural network
KW  - remote sensing
DO  - 10.3390/rs13132482
TY  - EJOU
AU  - Ouhami, Maryam
AU  - Hafiane, Adel
AU  - Es-Saady, Youssef
AU  - El Hajji, Mohamed
AU  - Canals, Raphael
TI  - Computer Vision, IoT and Data Fusion for Crop Disease Detection Using Machine Learning: A Survey and Ongoing Research
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - Crop diseases constitute a serious issue in agriculture, affecting both quality and quantity of agriculture production. Disease control has been a research object in many scientific and technologic domains. Technological advances in sensors, data storage, computing resources and artificial intelligence have shown enormous potential to control diseases effectively. A growing body of literature recognizes the importance of using data from different types of sensors and machine learning approaches to build models for detection, prediction, analysis, assessment, etc. However, the increasing number and diversity of research studies requires a literature review for further developments and contributions in this area. This paper reviews state-of-the-art machine learning methods that use different data sources, applied to plant disease detection. It lists traditional and deep learning methods associated with the main data acquisition modalities, namely IoT, ground imaging, unmanned aerial vehicle imaging and satellite imaging. In addition, this study examines the role of data fusion for ongoing research in the context of disease detection. It highlights the advantage of intelligent data fusion techniques, from heterogeneous data sources, to improve plant health status prediction and presents the main challenges facing this field. The study concludes with a discussion of several current issues and research trends.
KW  - plant disease
KW  - machine learning
KW  - remote sensing
KW  - intelligent sensors
KW  - data fusion
DO  - 10.3390/rs13132486
TY  - EJOU
AU  - Fu, Wei
AU  - Yu, Shuang
AU  - Wang, Xin
TI  - A Novel Method to Determine Basic Probability Assignment Based on Adaboost and Its Application in Classification
T2  - Entropy

PY  - 2021
VL  - 23
IS  - 7
SN  - 1099-4300

AB  - In the framework of evidence theory, one of the open and crucial issues is how to determine the basic probability assignment (BPA), which is directly related to whether the decision result is correct. This paper proposes a novel method for obtaining BPA based on Adaboost. The method uses training data to generate multiple strong classifiers for each attribute model, which is used to determine the BPA of the singleton proposition since the weights of classification provide necessary information for fundamental hypotheses. The BPA of the composite proposition is quantified by calculating the area ratio of the singleton proposition’s intersection region. The recursive formula of the area ratio of the intersection region is proposed, which is very useful for computer calculation. Finally, BPAs are combined by Dempster’s rule of combination. Using the proposed method to classify the Iris dataset, the experiment concludes that the total recognition rate is 96.53% and the classification accuracy is 90% when the training percentage is 10%. For the other datasets, the experiment results also show that the proposed method is reasonable and effective, and the proposed method performs well in the case of insufficient samples.
KW  - Dempster-Shafer evidence theory
KW  - basic probability assignment
KW  - Adaboost
KW  - multiple strong classifiers
KW  - area ratio of the intersection region
DO  - 10.3390/e23070812
TY  - EJOU
AU  - Nabwire, Shona
AU  - Suh, Hyun-Kwon
AU  - Kim, Moon S.
AU  - Baek, Insuck
AU  - Cho, Byoung-Kwan
TI  - Review: Application of Artificial Intelligence in Phenomics
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 13
SN  - 1424-8220

AB  - Plant phenomics has been rapidly advancing over the past few years. This advancement is attributed to the increased innovation and availability of new technologies which can enable the high-throughput phenotyping of complex plant traits. The application of artificial intelligence in various domains of science has also grown exponentially in recent years. Notably, the computer vision, machine learning, and deep learning aspects of artificial intelligence have been successfully integrated into non-invasive imaging techniques. This integration is gradually improving the efficiency of data collection and analysis through the application of machine and deep learning for robust image analysis. In addition, artificial intelligence has fostered the development of software and tools applied in field phenotyping for data collection and management. These include open-source devices and tools which are enabling community driven research and data-sharing, thereby availing the large amounts of data required for the accurate study of phenotypes. This paper reviews more than one hundred current state-of-the-art papers concerning AI-applied plant phenotyping published between 2010 and 2020. It provides an overview of current phenotyping technologies and the ongoing integration of artificial intelligence into plant phenotyping. Lastly, the limitations of the current approaches/methods and future directions are discussed.
KW  - artificial intelligence
KW  - deep learning
KW  - plant phenomics
KW  - field phenotyping
KW  - high throughput phenotyping
KW  - image-based phenotyping
DO  - 10.3390/s21134363
TY  - EJOU
AU  - Shrestha, Rakesh
AU  - Omidkar, Atefeh
AU  - Roudi, Sajjad A.
AU  - Abbas, Robert
AU  - Kim, Shiho
TI  - Machine-Learning-Enabled Intrusion Detection System for Cellular Connected UAV Networks
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 13
SN  - 2079-9292

AB  - The recent development and adoption of unmanned aerial vehicles (UAVs) is due to its wide variety of applications in public and private sector from parcel delivery to wildlife conservation. The integration of UAVs, 5G, and satellite technologies has prompted telecommunication networks to evolve to provide higher-quality and more stable service to remote areas. However, security concerns with UAVs are growing as UAV nodes are becoming attractive targets for cyberattacks due to enormously growing volumes and poor and weak inbuilt security. In this paper, we propose a UAV- and satellite-based 5G-network security model that can harness machine learning to effectively detect of vulnerabilities and cyberattacks. The solution is divided into two main parts: the model creation for intrusion detection using various machine learning (ML) algorithms and the implementation of ML-based model into terrestrial or satellite gateways. The system identifies various attack types using realistic CSE-CIC IDS-2018 network datasets published by Canadian Establishment for Cybersecurity (CIC). It consists of seven different types of new and contemporary attack types. This paper demonstrates that ML algorithms can be used to classify benign or malicious packets in UAV networks to enhance security. Finally, the tested ML algorithms are compared for effectiveness in terms of accuracy rate, precision, recall, F1-score, and false-negative rate. The decision tree algorithm performed well by obtaining a maximum accuracy rate of 99.99% and a minimum false negative rate of 0% in detecting various attacks as compared to all other types of ML classifiers.
KW  - UAV
KW  - machine learning
KW  - intrusion detection system
KW  - cybersecurity attacks
KW  - software-defined security
DO  - 10.3390/electronics10131549
TY  - EJOU
AU  - Khoroshevsky, Faina
AU  - Khoroshevsky, Stanislav
AU  - Bar-Hillel, Aharon
TI  - Parts-per-Object Count in Agricultural Images: Solving Phenotyping Problems via a Single Deep Neural Network
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - Solving many phenotyping problems involves not only automatic detection of objects in an image, but also counting the number of parts per object. We propose a solution in the form of a single deep network, tested for three agricultural datasets pertaining to bananas-per-bunch, spikelets-per-wheat-spike, and berries-per-grape-cluster. The suggested network incorporates object detection, object resizing, and part counting as modules in a single deep network, with several variants tested. The detection module is based on a Retina-Net architecture, whereas for the counting modules, two different architectures are examined: the first based on direct regression of the predicted count, and the other on explicit parts detection and counting. The results are promising, with the mean relative deviation between estimated and visible part count in the range of 9.2% to 11.5%. Further inference of count-based yield related statistics is considered. For banana bunches, the actual banana count (including occluded bananas) is inferred from the count of visible bananas. For spikelets-per-wheat-spike, robust estimation methods are employed to get the average spikelet count across the field, which is an effective yield estimator.
KW  - phenotyping problems
KW  - deep learning
KW  - parts-per-object count
KW  - object detection
KW  - robust estimation
DO  - 10.3390/rs13132496
TY  - EJOU
AU  - Salehi Hikouei, Iman
AU  - Kim, S. S.
AU  - Mishra, Deepak R.
TI  - Machine-Learning Classification of Soil Bulk Density in Salt Marsh Environments
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 13
SN  - 1424-8220

AB  - Remotely sensed data from both in situ and satellite platforms in visible, near-infrared, and shortwave infrared (VNIR–SWIR, 400–2500 nm) regions have been widely used to characterize and model soil properties in a direct, cost-effective, and rapid manner at different scales. In this study, we assess the performance of machine-learning algorithms including random forest (RF), extreme gradient boosting machines (XGBoost), and support vector machines (SVM) to model salt marsh soil bulk density using multispectral remote-sensing data from the Landsat-7 Enhanced Thematic Mapper Plus (ETM+) platform. To our knowledge, use of remote-sensing data for estimating salt marsh soil bulk density at the vegetation rooting zone has not been investigated before. Our study reveals that blue (band 1; 450–520 nm) and NIR (band 4; 770–900 nm) bands of Landsat-7 ETM+ ranked as the most important spectral features for bulk density prediction by XGBoost and RF, respectively. According to XGBoost, band 1 and band 4 had relative importance of around 41% and 39%, respectively. We tested two soil bulk density classes in order to differentiate salt marshes in terms of their capability to support vegetation that grows in either low (0.032 to 0.752 g/cm3) or high (0.752 g/cm3 to 1.893 g/cm3) bulk density areas. XGBoost produced a higher classification accuracy (88%) compared to RF (87%) and SVM (86%), although discrepancies in accuracy between these models were small (&lt;2%). XGBoost correctly classified 178 out of 186 soil samples labeled as low bulk density and 37 out of 62 soil samples labeled as high bulk density. We conclude that remote-sensing-based machine-learning models can be a valuable tool for ecologists and engineers to map the soil bulk density in wetlands to select suitable sites for effective restoration and successful re-establishment practices.
KW  - soil characterization
KW  - random forest
KW  - XGBoost
KW  - machine learning
KW  - coastal wetlands
KW  - Landsat-7 (ETM+)
DO  - 10.3390/s21134408
TY  - EJOU
AU  - Ukaegbu, Uchechi F.
AU  - Tartibu, Lagouge K.
AU  - Okwu, Modestus O.
AU  - Olayode, Isaac O.
TI  - Development of a Light-Weight Unmanned Aerial Vehicle for Precision Agriculture
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 13
SN  - 1424-8220

AB  - This paper describes the development of a modular unmanned aerial vehicle for the detection and eradication of weeds on farmland. Precision agriculture entails solving the problem of poor agricultural yield due to competition for nutrients by weeds and provides a faster approach to eliminating the problematic weeds using emerging technologies. This research has addressed the aforementioned problem. A quadcopter was built, and components were assembled with light-weight materials. The system consists of the electric motor, electronic speed controller, propellers, frame, lithium polymer (li-po) battery, flight controller, a global positioning system (GPS), and receiver. A sprayer module which consists of a relay, Raspberry Pi 3, spray pump, 12 V DC source, water hose, and the tank was built. It operated in such a way that when a weed is detected based on the deep learning algorithms deployed on the Raspberry Pi, general purpose input/output (GPIO) 17 or GPIO 18 (of the Raspberry Pi) were activated to supply 3.3 V, which turned on a DC relay to spray herbicides accordingly. The sprayer module was mounted on the quadcopter and from the test-running operation conducted, broadleaf and grass weeds were accurately detected and the spraying of herbicides according to the weed type occurred in less than a second.
KW  - unmanned aerial vehicle (UAV)
KW  - deep learning
KW  - Raspberry Pi 3
KW  - industry 4.0
KW  - precision agriculture
DO  - 10.3390/s21134417
TY  - EJOU
AU  - Gili, Piero
AU  - Civera, Marco
AU  - Roy, Rinto
AU  - Surace, Cecilia
TI  - An Unmanned Lighter-Than-Air Platform for Large Scale Land Monitoring
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - The concept and preliminary design of an unmanned lighter-than-air (LTA) platform instrumented with different remote sensing technologies is presented. The aim is to assess the feasibility of using a remotely controlled airship for the land monitoring of medium sized (up to 107 m2) urban or rural areas at relatively low altitudes (below 1000 m) and its potential convenience with respect to other standard remote and in-situ sensing systems. The proposal includes equipment for high-definition visual, thermal, and hyperspectral imaging as well as LiDAR scanning. The data collected from these different sources can be then combined to obtain geo-referenced products such as land use land cover (LULC), soil water content (SWC), land surface temperature (LSC), and leaf area index (LAI) maps, among others. The potential uses for diffuse structural health monitoring over built-up areas are discussed as well. Several mission typologies are considered.
KW  - unmanned aircraft systems (UASs)
KW  - UAS-based remote sensing
KW  - airship design
KW  - hyperspectral imaging
KW  - thermal imaging
KW  - LiDAR
DO  - 10.3390/rs13132523
TY  - EJOU
AU  - Al-Nuaimi, Mohammed
AU  - Wibowo, Sapto
AU  - Qu, Hongyang
AU  - Aitken, Jonathan
AU  - Veres, Sandor
TI  - Hybrid Verification Technique for Decision-Making of Self-Driving Vehicles
T2  - Journal of Sensor and Actuator Networks

PY  - 2021
VL  - 10
IS  - 3
SN  - 2224-2708

AB  - The evolution of driving technology has recently progressed from active safety features and ADAS systems to fully sensor-guided autonomous driving. Bringing such a vehicle to market requires not only simulation and testing but formal verification to account for all possible traffic scenarios. A new verification approach, which combines the use of two well-known model checkers: model checker for multi-agent systems (MCMAS) and probabilistic model checker (PRISM), is presented for this purpose. The overall structure of our autonomous vehicle (AV) system consists of: (1) A perception system of sensors that feeds data into (2) a rational agent (RA) based on a belief–desire–intention (BDI) architecture, which uses a model of the environment and is connected to the RA for verification of decision-making, and (3) a feedback control systems for following a self-planned path. MCMAS is used to check the consistency and stability of the BDI agent logic during design-time. PRISM is used to provide the RA with the probability of success while it decides to take action during run-time operation. This allows the RA to select movements of the highest probability of success from several generated alternatives. This framework has been tested on a new AV software platform built using the robot operating system (ROS) and virtual reality (VR) Gazebo Simulator. It also includes a parking lot scenario to test the feasibility of this approach in a realistic environment. A practical implementation of the AV system was also carried out on the experimental testbed.
KW  - self-driving vehicle
KW  - formal verification
KW  - model checking
KW  - rational agent
KW  - decision-making
KW  - ROS
DO  - 10.3390/jsan10030042
TY  - EJOU
AU  - Niu, Zijie
AU  - Deng, Juntao
AU  - Zhang, Xu
AU  - Zhang, Jun
AU  - Pan, Shijia
AU  - Mu, Haotian
TI  - Identifying the Branch of Kiwifruit Based on Unmanned Aerial Vehicle (UAV) Images Using Deep Learning Method
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 13
SN  - 1424-8220

AB  - It is important to obtain accurate information about kiwifruit vines to monitoring their physiological states and undertake precise orchard operations. However, because vines are small and cling to trellises, and have branches laying on the ground, numerous challenges exist in the acquisition of accurate data for kiwifruit vines. In this paper, a kiwifruit canopy distribution prediction model is proposed on the basis of low-altitude unmanned aerial vehicle (UAV) images and deep learning techniques. First, the location of the kiwifruit plants and vine distribution are extracted from high-precision images collected by UAV. The canopy gradient distribution maps with different noise reduction and distribution effects are generated by modifying the threshold and sampling size using the resampling normalization method. The results showed that the accuracies of the vine segmentation using PSPnet, support vector machine, and random forest classification were 71.2%, 85.8%, and 75.26%, respectively. However, the segmentation image obtained using depth semantic segmentation had a higher signal-to-noise ratio and was closer to the real situation. The average intersection over union of the deep semantic segmentation was more than or equal to 80% in distribution maps, whereas, in traditional machine learning, the average intersection was between 20% and 60%. This indicates the proposed model can quickly extract the vine distribution and plant position, and is thus able to perform dynamic monitoring of orchards to provide real-time operation guidance.
KW  - deep learning
KW  - unmanned aerial vehicle
KW  - kiwifruit
KW  - image segmentation
DO  - 10.3390/s21134442
TY  - EJOU
AU  - Shin, Jisun
AU  - Jo, Young-Heon
AU  - Ryu, Joo-Hyung
AU  - Khim, Boo-Keun
AU  - Kim, Soo M.
TI  - High Spatial-Resolution Red Tide Detection in the Southern Coast of Korea Using U-Net from PlanetScope Imagery
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 13
SN  - 1424-8220

AB  - Red tides caused by Margalefidinium polykrikoides occur continuously along the southern coast of Korea, where there are many aquaculture cages, and therefore, prompt monitoring of bloom water is required to prevent considerable damage. Satellite-based ocean-color sensors are widely used for detecting red tide blooms, but their low spatial resolution restricts coastal observations. Contrarily, terrestrial sensors with a high spatial resolution are good candidate sensors, despite the lack of spectral resolution and bands for red tide detection. In this study, we developed a U-Net deep learning model for detecting M. polykrikoides blooms along the southern coast of Korea from PlanetScope imagery with a high spatial resolution of 3 m. The U-Net model was trained with four different datasets that were constructed with randomly or non-randomly chosen patches consisting of different ratios of red tide and non-red tide pixels. The qualitative and quantitative assessments of the conventional red tide index (RTI) and four U-Net models suggest that the U-Net model, which was trained with a dataset of non-randomly chosen patches including non-red tide patches, outperformed RTI in terms of sensitivity, precision, and F-measure level, accounting for an increase of 19.84%, 44.84%, and 28.52%, respectively. The M. polykrikoides map derived from U-Net provides the most reasonable red tide patterns in all water areas. Combining high spatial resolution images and deep learning approaches represents a good solution for the monitoring of red tides over coastal regions.
KW  - Margalefidinium polykrikoides
KW  - PlanetScope
KW  - southern coast of Korea
KW  - convolutional neural network
KW  - U-Net
DO  - 10.3390/s21134447
TY  - EJOU
AU  - Habibi, Luthfan N.
AU  - Watanabe, Tomoya
AU  - Matsui, Tsutomu
AU  - Tanaka, Takashi S. T.
TI  - Machine Learning Techniques to Predict Soybean Plant Density Using UAV and Satellite-Based Remote Sensing
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - The plant density of soybean is a critical factor affecting plant canopy structure and yield. Predicting the spatial variability of plant density would be valuable for improving agronomic practices. The objective of this study was to develop a model for plant density measurement using several data sets with different spatial resolutions, including unmanned aerial vehicle (UAV) imagery, PlanetScope satellite imagery, and climate data. The model establishment process includes (1) performing the high-throughput measurement of actual plant density from UAV imagery with the You Only Look Once version 3 (YOLOv3) object detection algorithm, which was further treated as a response variable of the estimation models in the next step, and (2) developing regression models to estimate plant density in the extended areas using various combinations of predictors derived from PlanetScope imagery and climate data. Our results showed that the YOLOv3 model can accurately measure actual soybean plant density from UAV imagery data with a root mean square error (RMSE) value of 0.96 plants m−2. Furthermore, the two regression models, partial least squares and random forest (RF), successfully expanded the plant density prediction areas with RMSE values ranging from 1.78 to 3.67 plant m−2. Model improvement was conducted using the variable importance feature in RF, which improved prediction accuracy with an RMSE value of 1.72 plant m−2. These results demonstrated that the established model had an acceptable prediction accuracy for estimating plant density. Although the model could not often evaluate the within-field spatial variability of soybean plant density, the predicted values were sufficient for informing the field-specific status.
KW  - PlanetScope
KW  - random forest
KW  - partial least squares regression
KW  - spatial variation
KW  - spectral reflectance
KW  - YOLOv3
DO  - 10.3390/rs13132548
TY  - EJOU
AU  - Yoosefzadeh-Najafabadi, Mohsen
AU  - Tulpan, Dan
AU  - Eskandari, Milad
TI  - Using Hybrid Artificial Intelligence and Evolutionary Optimization Algorithms for Estimating Soybean Yield and Fresh Biomass Using Hyperspectral Vegetation Indices
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - Recent advanced high-throughput field phenotyping combined with sophisticated big data analysis methods have provided plant breeders with unprecedented tools for a better prediction of important agronomic traits, such as yield and fresh biomass (FBIO), at early growth stages. This study aimed to demonstrate the potential use of 35 selected hyperspectral vegetation indices (HVI), collected at the R5 growth stage, for predicting soybean seed yield and FBIO. Two artificial intelligence algorithms, ensemble-bagging (EB) and deep neural network (DNN), were used to predict soybean seed yield and FBIO using HVI. Considering HVI as input variables, the coefficients of determination (R2) of 0.76 and 0.77 for yield and 0.91 and 0.89 for FBIO were obtained using DNN and EB, respectively. In this study, we also used hybrid DNN-SPEA2 to estimate the optimum HVI values in soybeans with maximized yield and FBIO productions. In addition, to identify the most informative HVI in predicting yield and FBIO, the feature recursive elimination wrapper method was used and the top ranking HVI were determined to be associated with red, 670 nm and near-infrared, 800 nm, regions. Overall, this study introduced hybrid DNN-SPEA2 as a robust mathematical tool for optimizing and using informative HVI for estimating soybean seed yield and FBIO at early growth stages, which can be employed by soybean breeders for discriminating superior genotypes in large breeding populations.
KW  - high-throughput phenotyping
KW  - machine learning
KW  - multi-objective optimization algorithm
KW  - radial basis function
KW  - random forest
KW  - support vector regression
KW  - SPEA2
DO  - 10.3390/rs13132555
TY  - EJOU
AU  - Mbiydzenyuy, Gideon
AU  - Nowaczyk, Sławomir
AU  - Knutsson, Håkan
AU  - Vanhoudt, Dirk
AU  - Brage, Jens
AU  - Calikus, Ece
TI  - Opportunities for Machine Learning in District Heating
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 13
SN  - 2076-3417

AB  - The district heating (DH) industry is facing an important transformation towards more efficient networks that utilise significantly lower water temperatures to distribute the heat. This change requires taking advantage of new technologies, and Machine Learning (ML) is a popular direction. In the last decade, we have witnessed an extreme growth in the number of published research papers that focus on applying ML techniques to the DH domain. However, based on our experience in the field, and an extensive review of the state-of-the-art, we perceive a mismatch between the most popular research directions, such as forecasting, and the challenges faced by the DH industry. In this work, we present our findings, explain and demonstrate the key gaps between the two communities and suggest a road-map ahead towards increasing the impact of ML research in the DH industry.
KW  - Machine Learning
KW  - district heating
KW  - review
KW  - road-map
KW  - research opportunities
DO  - 10.3390/app11136112
TY  - EJOU
AU  - Ackerson, Joseph M.
AU  - Dave, Rushit
AU  - Seliya, Naeem
TI  - Applications of Recurrent Neural Network for Biometric Authentication &amp; Anomaly Detection
T2  - Information

PY  - 2021
VL  - 12
IS  - 7
SN  - 2078-2489

AB  - Recurrent Neural Networks are powerful machine learning frameworks that allow for data to be saved and referenced in a temporal sequence. This opens many new possibilities in fields such as handwriting analysis and speech recognition. This paper seeks to explore current research being conducted on RNNs in four very important areas, being biometric authentication, expression recognition, anomaly detection, and applications to aircraft. This paper reviews the methodologies, purpose, results, and the benefits and drawbacks of each proposed method below. These various methodologies all focus on how they can leverage distinct RNN architectures such as the popular Long Short-Term Memory (LSTM) RNN or a Deep-Residual RNN. This paper also examines which frameworks work best in certain situations, and the advantages and disadvantages of each proposed model.
KW  - recurrent neural network
KW  - biometric authentication
KW  - expression recognition
KW  - anomaly detection
KW  - smartphone authentication
KW  - mouse-based authentication
KW  - aircraft trajectory prediction
DO  - 10.3390/info12070272
TY  - EJOU
AU  - Pourroostaei Ardakani, Saeid
AU  - Cheshmehzangi, Ali
TI  - Reinforcement Learning-Enabled UAV Itinerary Planning for Remote Sensing Applications in Smart Farming
T2  - Telecom

PY  - 2021
VL  - 2
IS  - 3
SN  - 2673-4001

AB  - UAV path planning for remote sensing aims to find the best-fitted routes to complete a data collection mission. UAVs plan the routes and move through them to remotely collect environmental data from particular target zones by using sensory devices such as cameras. Route planning may utilize machine learning techniques to autonomously find/select cost-effective and/or best-fitted routes and achieve optimized results including: minimized data collection delay, reduced UAV power consumption, decreased flight traversed distance and maximized number of collected data samples. This paper utilizes a reinforcement learning technique (location and energy-aware Q-learning) to plan UAV routes for remote sensing in smart farms. Through this, the UAV avoids heuristically or blindly moving throughout a farm, but this takes the benefits of environment exploration–exploitation to explore the farm and find the shortest and most cost-effective paths into target locations with interesting data samples to collect. According to the simulation results, utilizing the Q-learning technique increases data collection robustness and reduces UAV resource consumption (e.g., power), traversed paths, and remote sensing latency as compared to two well-known benchmarks, IEMF and TBID, especially if the target locations are dense and crowded in a farm.
KW  - UAV
KW  - reinforcement learning
KW  - Q-learning
KW  - path planning
KW  - remote sensing
DO  - 10.3390/telecom2030017
TY  - EJOU
AU  - Swinney, Carolyn J.
AU  - Woods, John C.
TI  - The Effect of Real-World Interference on CNN Feature Extraction and Machine Learning Classification of Unmanned Aerial Systems
T2  - Aerospace

PY  - 2021
VL  - 8
IS  - 7
SN  - 2226-4310

AB  - Small unmanned aerial systems (UASs) present many potential solutions and enhancements to industry today but equally pose a significant security challenge. We only need to look at the levels of disruption caused by UASs at airports in recent years. The accuracy of UAS detection and classification systems based on radio frequency (RF) signals can be hindered by other interfering signals present in the same frequency band, such as Bluetooth and Wi-Fi devices. In this paper, we evaluate the effect of real-world interference from Bluetooth and Wi-Fi signals concurrently on convolutional neural network (CNN) feature extraction and machine learning classification of UASs. We assess multiple UASs that operate using different transmission systems: Wi-Fi, Lightbridge 2.0, OcuSync 1.0, OcuSync 2.0 and the recently released OcuSync 3.0. We consider 7 popular UASs, evaluating 2 class UAS detection, 8 class UAS type classification and 21 class UAS flight mode classification. Our results show that the process of CNN feature extraction using transfer learning and machine learning classification is fairly robust in the presence of real-world interference. We also show that UASs that are operating using the same transmission system can be distinguished. In the presence of interference from both Bluetooth and Wi-Fi signals, our results show 100% accuracy for UAV detection (2 classes), 98.1% (+/−0.4%) for UAV type classification (8 classes) and 95.4% (+/−0.3%) for UAV flight mode classification (21 classes).
KW  - unmanned aerial vehicles
KW  - unmanned aerial systems
KW  - interference
KW  - UAS detection
KW  - RF spectrum analysis
KW  - machine learning classification
KW  - deep learning
KW  - convolutional neural network
KW  - transfer learning
KW  - signal analysis
DO  - 10.3390/aerospace8070179
TY  - EJOU
AU  - Grigore, Lucian Ș.
AU  - Ștefan, Amado
AU  - Oncioiu, Ionica
AU  - Molder, Cristian
AU  - Gorgoteanu, Damian
AU  - Constantin, Daniel
AU  - Bălașa, Răzvan-Ionuț
TI  - Aspects Regarding of a UGV Fire Fighting Thermal Shield
T2  - Engineering Proceedings

PY  - 2021
VL  - 6
IS  - 1
SN  - 2673-4591

AB  - This article presents aspects related to the protection (with a double shield made of stainless steel) of a robot for emergency situations against the effect of flames due to a fire. The ground robot is semi-autonomous/autonomous, with a wheeled propeller (6 × 6). The robot, designed and built at the TRL 2 level, is intended for fire investigation, monitoring, and intervention (and, in particular, for petrochemical plants). The role of the shield is to protect the equipment that is part of the robot including its controllers, sensors, communications, power supply, etc. The need to mount a thermal protection shield on the intervention robot was given by the fact that fires at petrochemical plants generate very large thermal fields and gradients which are responsible for creating blind spots. These blind spots do not allow intervention crews to see what is happening in that area. These blind spots are characterized by very high temperatures. The dynamics of these fires can be unpredictable. Therefore, to analyze the performance of the heat shield in this study we perform a numerical-experimental analysis.
KW  - robot
KW  - thermal
KW  - shield
KW  - sensors
KW  - firefighting
KW  - emergency
DO  - 10.3390/I3S2021Dresden-10082

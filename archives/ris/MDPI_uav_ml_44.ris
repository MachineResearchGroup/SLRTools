TY  - EJOU
AU  - Islam, Nahina
AU  - Rashid, Md M.
AU  - Wibowo, Santoso
AU  - Xu, Cheng-Yuan
AU  - Morshed, Ahsan
AU  - Wasimi, Saleh A.
AU  - Moore, Steven
AU  - Rahman, Sk M.
TI  - Early Weed Detection Using Image Processing and Machine Learning Techniques in an Australian Chilli Farm
T2  - Agriculture

PY  - 2021
VL  - 11
IS  - 5
SN  - 2077-0472

AB  - This paper explores the potential of machine learning algorithms for weed and crop classification from UAV images. The identification of weeds in crops is a challenging task that has been addressed through orthomosaicing of images, feature extraction and labelling of images to train machine learning algorithms. In this paper, the performances of several machine learning algorithms, random forest (RF), support vector machine (SVM) and k-nearest neighbours (KNN), are analysed to detect weeds using UAV images collected from a chilli crop field located in Australia. The evaluation metrics used in the comparison of performance were accuracy, precision, recall, false positive rate and kappa coefficient. MATLAB is used for simulating the machine learning algorithms; and the achieved weed detection accuracies are 96% using RF, 94% using SVM and 63% using KNN. Based on this study, RF and SVM algorithms are efficient and practical to use, and can be implemented easily for detecting weed from UAV images.
KW  - weed detection
KW  - smart farming
KW  - machine learning
KW  - remote sensing
KW  - image processing
DO  - 10.3390/agriculture11050387
ER  -
TY  - EJOU
AU  - Avola, Danilo
AU  - Cinque, Luigi
AU  - Diko, Anxhelo
AU  - Fagioli, Alessio
AU  - Foresti, Gian L.
AU  - Mecca, Alessio
AU  - Pannone, Daniele
AU  - Piciarelli, Claudio
TI  - MS-Faster R-CNN: Multi-Stream Backbone for Improved Faster R-CNN Object Detection and Aerial Tracking from UAV Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - Tracking objects across multiple video frames is a challenging task due to several difficult issues such as occlusions, background clutter, lighting as well as object and camera view-point variations, which directly affect the object detection. These aspects are even more emphasized when analyzing unmanned aerial vehicles (UAV) based images, where the vehicle movement can also impact the image quality. A common strategy employed to address these issues is to analyze the input images at different scales to obtain as much information as possible to correctly detect and track the objects across video sequences. Following this rationale, in this paper, we introduce a simple yet effective novel multi-stream (MS) architecture, where different kernel sizes are applied to each stream to simulate a multi-scale image analysis. The proposed architecture is then used as backbone for the well-known Faster-R-CNN pipeline, defining a MS-Faster R-CNN object detector that consistently detects objects in video sequences. Subsequently, this detector is jointly used with the Simple Online and Real-time Tracking with a Deep Association Metric (Deep SORT) algorithm to achieve real-time tracking capabilities on UAV images. To assess the presented architecture, extensive experiments were performed on the UMCD, UAVDT, UAV20L, and UAV123 datasets. The presented pipeline achieved state-of-the-art performance, confirming that the proposed multi-stream method can correctly emulate the robust multi-scale image analysis paradigm.
KW  - UAV
KW  - object detection
KW  - tracking
KW  - deep learning
KW  - aerial images
DO  - 10.3390/rs13091670
ER  -
TY  - EJOU
AU  - Song, Bonggeun
AU  - Park, Kyunghun
TI  - Comparison of Outdoor Compost Pile Detection Using Unmanned Aerial Vehicle Images and Various Machine Learning Techniques
T2  - Drones

PY  - 2021
VL  - 5
IS  - 2
SN  - 2504-446X

AB  - Since outdoor compost piles (OCPs) contain large amounts of nitrogen and phosphorus, they act as a major pollutant that deteriorates water quality, such as eutrophication and green algae, when the OCPs enter the river during rainfall. In South Korea, OCPs are frequently used, but there is a limitation that a lot of manpower and budget are consumed to investigate the current situation, so it is necessary to efficiently investigate the OCPs. This study compared the accuracy of various machine learning techniques for the efficient detection and management of outdoor compost piles (OCPs), a non-point pollution source in agricultural areas in South Korea, using unmanned aerial vehicle (UAV) images. RGB, multispectral, and thermal infrared UAV images were taken in August and October 2019. Additionally, vegetation indices (NDVI, NDRE, ENDVI, and GNDVI) and surface temperature were also considered. Four machine learning techniques, including support vector machine (SVM), decision tree (DT), random forest (RF), and k-NN, were implemented, and the machine learning technique with the highest accuracy was identified by adjusting several variables. The accuracy of all machine learning techniques was very high, reaching values of up to 0.96. Particularly, the accuracy of the RF method with the number of estimators set to 10 was highest, reaching 0.989 in August and 0.987 in October. The proposed method allows for the prediction of OCP location and area over large regions, thereby foregoing the need for OCP field measurements. Therefore, our findings provide highly useful data for the improvement of OCP management strategies and water quality.
KW  - non-point pollutant
KW  - random forest
KW  - SVM
KW  - decision tree
KW  - k-NN
KW  - python
DO  - 10.3390/drones5020031
ER  -
TY  - EJOU
AU  - Elsayed, Salah
AU  - El-Hendawy, Salah
AU  - Khadr, Mosaad
AU  - Elsherbiny, Osama
AU  - Al-Suhaibani, Nasser
AU  - Alotaibi, Majed
AU  - Tahir, Muhammad U.
AU  - Darwish, Waleed
TI  - Combining Thermal and RGB Imaging Indices with Multivariate and Data-Driven Modeling to Estimate the Growth, Water Status, and Yield of Potato under Different Drip Irrigation Regimes
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - Advances in proximal hyperspectral sensing tools, chemometric techniques, and data-driven modeling have enhanced precision irrigation management by facilitating the monitoring of several plant traits. This study investigated the performance of remote sensing indices derived from thermal and red-green-blue (RGB) images combined with stepwise multiple linear regression (SMLR) and an integrated adaptive neuro-fuzzy inference system with a genetic algorithm (ANFIS-GA) for monitoring the biomass fresh weight (BFW), biomass dry weight (BDW), biomass water content (BWC), and total tuber yield (TTY) of two potato varieties under 100%, 75%, and 50% of the estimated crop evapotranspiration (ETc). Results showed that the plant traits and indices varied significantly between the three irrigation regimes. Furthermore, all of the indices exhibited strong relationships with BFW, CWC, and TTY (R2 = 0.80–0.92) and moderate to weak relationships with BDW (R2 = 0.25–0.65) when considered for each variety across the irrigation regimes, for each season across the varieties and irrigation regimes, and across all data combined, but none of the indices successfully assessed any of the plant traits when considered for each irrigation regime across the two varieties. The SMLR and ANFIS-GA models gave the best predictions for the four plant traits in the calibration and testing stages, with the exception of the SMLR testing model for BDW. Thus, the use of thermal and RGB imaging indices with ANFIS-GA models could be a practical tool for managing the growth and production of potato crops under deficit irrigation regimes.
KW  - ANFIS
KW  - deficit irrigation
KW  - genetic algorithm
KW  - irrigation management
KW  - RGB digital camera
KW  - stepwise multiple linear regression
KW  - thermal camera
DO  - 10.3390/rs13091679
ER  -
TY  - EJOU
AU  - Khan, Nawab
AU  - Ray, Ram L.
AU  - Sargani, Ghulam R.
AU  - Ihtisham, Muhammad
AU  - Khayyam, Muhammad
AU  - Ismail, Sohaib
TI  - Current Progress and Future Prospects of Agriculture Technology: Gateway to Sustainable Agriculture
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 9
SN  - 2071-1050

AB  - The agricultural industry is getting more data-centric and requires precise, more advanced data and technologies than before, despite being familiar with agricultural processes. The agriculture industry is being advanced by various information and advanced communication technologies, such as the Internet of Things (IoT). The rapid emergence of these advanced technologies has restructured almost all other industries, as well as advanced agriculture, which has shifted the industry from a statistical approach to a quantitative one. This radical change has shaken existing farming techniques and produced the latest prospects in a series of challenges. This comprehensive review article enlightens the potential of the IoT in the advancement of agriculture and the challenges faced when combining these advanced technologies with conventional agricultural systems. A brief analysis of these advanced technologies with sensors is presented in advanced agricultural applications. Numerous sensors that can be implemented for specific agricultural practices require best management practices (e.g., land preparation, irrigation systems, insect, and disease management). This review includes the integration of all suitable techniques, from sowing to harvesting, packaging, transportation, and advanced technologies available for farmers throughout the cropping system. Besides, this review article highlights the utilization of other tools such as unmanned aerial vehicles (UAVs) for crop monitoring and other beneficiary measures, such as optimizing crop yields. In addition, advanced programs based on the IoT are also discussed. Finally, based on our comprehensive review, we identified advanced prospects regarding the IoT, which are essential tools for sustainable agriculture.
KW  - IoT
KW  - agriculture advancement
KW  - UAVs
KW  - sustainable agriculture
DO  - 10.3390/su13094883
ER  -
TY  - EJOU
AU  - Gano, Boubacar
AU  - Dembele, Joseph Sékou B.
AU  - Ndour, Adama
AU  - Luquet, Delphine
AU  - Beurier, Gregory
AU  - Diouf, Diaga
AU  - Audebert, Alain
TI  - Using UAV Borne, Multi-Spectral Imaging for the Field Phenotyping of Shoot Biomass, Leaf Area Index and Height of West African Sorghum Varieties under Two Contrasted Water Conditions
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 5
SN  - 2073-4395

AB  - Meeting food demand for the growing population will require an increase to crop production despite climate changes and, more particularly, severe drought episodes. Sorghum is one of the cereals most adapted to drought that feed millions of people around the world. Valorizing its genetic diversity for crop improvement can benefit from extensive phenotyping. The current methods to evaluate plant biomass, leaves area and plants height involve destructive sampling and are not practical in breeding. Phenotyping relying on drone based imagery is a powerful approach in this context. The objective of this study was to develop and validate a high throughput field phenotyping method of sorghum growth traits under contrasted water conditions relying on drone based imagery. Experiments were conducted in Bambey (Senegal) in 2018 and 2019, to test the ability of multi-spectral sensing technologies on-board a UAV platform to calculate various vegetation indices to estimate plants characteristics. In total, ten (10) contrasted varieties of West African sorghum collection were selected and arranged in a randomized complete block design with three (3) replicates and two (2) water treatments (well-watered and drought stress). This study focused on plant biomass, leaf area index (LAI) and the plant height that were measured weekly from emergence to maturity. Drone flights were performed just before each destructive sampling and images were taken by multi-spectral and visible cameras. UAV-derived vegetation indices exhibited their capacity of estimating LAI and biomass in the 2018 calibration data set, in particular: normalized difference vegetative index (NDVI), corrected transformed vegetation index (CTVI), seconded modified soil-adjusted vegetation index (MSAVI2), green normalize difference vegetation index (GNDVI), and simple ratio (SR) (r2 of 0.8 and 0.6 for LAI and biomass, respectively). Developed models were validated with 2019 data, showing a good performance (r2 of 0.92 and 0.91 for LAI and biomass accordingly). Results were also promising regarding plant height estimation (RMSE = 9.88 cm). Regression plots between the image-based estimation and the measured plant height showed a r2 of 0.83. The validation results were similar between water treatments. This study is the first successful application of drone based imagery for phenotyping sorghum growth and development in a West African context characterized by severe drought occurrence. The developed approach could be used as a decision support tool for breeding programs and as a tool to increase the throughput of sorghum genetic diversity characterization for adaptive traits.
KW  - sorghum
KW  - drought tolerance
KW  - West Africa
KW  - phenotyping
KW  - UAV platform
KW  - vegetation indices
KW  - multi-spectral
KW  - RGB cameras
DO  - 10.3390/agronomy11050850
ER  -
TY  - EJOU
AU  - Allouch, Azza
AU  - Cheikhrouhou, Omar
AU  - Koubâa, Anis
AU  - Toumi, Khalifa
AU  - Khalgui, Mohamed
AU  - Nguyen Gia, Tuan
TI  - UTM-Chain: Blockchain-Based Secure Unmanned Traffic Management for Internet of Drones
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 9
SN  - 1424-8220

AB  - Unmanned aerial systems (UAVs) are dramatically evolving and promoting several civil applications. However, they are still prone to many security issues that threaten public safety. Security becomes even more challenging when they are connected to the Internet as their data stream is exposed to attacks. Unmanned traffic management (UTM) represents one of the most important topics for small unmanned aerial systems for beyond-line-of-sight operations in controlled low-altitude airspace. However, without securing the flight path exchanges between drones and ground stations or control centers, serious security threats may lead to disastrous situations. For example, a predefined flight path could be easily altered to make the drone perform illegal operations. Motivated by these facts, this paper discusses the security issues for UTM’s components and addresses the security requirements for such systems. Moreover, we propose UTM-Chain, a lightweight blockchain-based security solution using hyperledger fabric for UTM of low-altitude UAVs which fits the computational and storage resources limitations of UAVs. Moreover, UTM-Chain provides secure and unalterable traffic data between the UAVs and their ground control stations. The performance of the proposed system related to transaction latency and resource utilization is analyzed by using cAdvisor. Finally, the analysis of security aspects demonstrates that the proposed UTM-Chain scheme is feasible and extensible for the secure sharing of UAV data.
KW  - Internet-of-Drones
KW  - IoD
KW  - unmanned aerial systems
KW  - UAV
KW  - unmanned traffic management
KW  - hyperledger
KW  - ground control station
DO  - 10.3390/s21093049
ER  -
TY  - EJOU
AU  - Wang, Zhaojun
AU  - Wang, Jiangning
AU  - Lin, Congtian
AU  - Han, Yan
AU  - Wang, Zhaosheng
AU  - Ji, Liqiang
TI  - Identifying Habitat Elements from Bird Images Using Deep Convolutional Neural Networks
T2  - Animals

PY  - 2021
VL  - 11
IS  - 5
SN  - 2076-2615

AB  - With the rapid development of digital technology, bird images have become an important part of ornithology research data. However, due to the rapid growth of bird image data, it has become a major challenge to effectively process such a large amount of data. In recent years, deep convolutional neural networks (DCNNs) have shown great potential and effectiveness in a variety of tasks regarding the automatic processing of bird images. However, no research has been conducted on the recognition of habitat elements in bird images, which is of great help when extracting habitat information from bird images. Here, we demonstrate the recognition of habitat elements using four DCNN models trained end-to-end directly based on images. To carry out this research, an image database called Habitat Elements of Bird Images (HEOBs-10) and composed of 10 categories of habitat elements was built, making future benchmarks and evaluations possible. Experiments showed that good results can be obtained by all the tested models. ResNet-152-based models yielded the best test accuracy rate (95.52%); the AlexNet-based model yielded the lowest test accuracy rate (89.48%). We conclude that DCNNs could be efficient and useful for automatically identifying habitat elements from bird images, and we believe that the practical application of this technology will be helpful for studying the relationships between birds and habitat elements.
KW  - bird images
KW  - deep convolutional neural networks
KW  - habitat elements
DO  - 10.3390/ani11051263
ER  -
TY  - EJOU
AU  - Jenal, Alexander
AU  - Hüging, Hubert
AU  - Ahrends, Hella E.
AU  - Bolten, Andreas
AU  - Bongartz, Jens
AU  - Bareth, Georg
TI  - Investigating the Potential of a Newly Developed UAV-Mounted VNIR/SWIR Imaging System for Monitoring Crop Traits—A Case Study for Winter Wheat
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - UAV-based multispectral multi-camera systems are widely used in scientific research for non-destructive crop traits estimation to optimize agricultural management decisions. These systems typically provide data from the visible and near-infrared (VNIR) domain. However, several key absorption features related to biomass and nitrogen (N) are located in the short-wave infrared (SWIR) domain. Therefore, this study investigates a novel multi-camera system prototype that addresses this spectral gap with a sensitivity from 600 to 1700 nm by implementing dedicated bandpass filter combinations to derive application-specific vegetation indices (VIs). In this study, two VIs, GnyLi and NRI, were applied using data obtained on a single observation date at a winter wheat field experiment located in Germany. Ground truth data were destructively sampled for the entire growing season. Likewise, crop heights were derived from UAV-based RGB image data using an improved approach developed within this study. Based on these variables, regression models were derived to estimate fresh and dry biomass, crop moisture, N concentration, and N uptake. The relationships between the NIR/SWIR-based VIs and the estimated crop traits were successfully evaluated (R2: 0.57 to 0.66). Both VIs were further validated against the sampled ground truth data (R2: 0.75 to 0.84). These results indicate the imaging system’s potential for monitoring crop traits in agricultural applications, but further multitemporal validations are needed.
KW  - unmanned aerial vehicle (UAV)
KW  - near-infrared (NIR)
KW  - short-wave infrared (SWIR)
KW  - biomass
KW  - nitrogen concentration
KW  - nitrogen uptake
KW  - crop moisture
KW  - crop height
KW  - winter wheat
KW  - precision agriculture
DO  - 10.3390/rs13091697
ER  -
TY  - EJOU
AU  - de Camargo, Tibor
AU  - Schirrmann, Michael
AU  - Landwehr, Niels
AU  - Dammer, Karl-Heinz
AU  - Pflanz, Michael
TI  - Optimized Deep Learning Model as a Basis for Fast UAV Mapping of Weed Species in Winter Wheat Crops
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - Weed maps should be available quickly, reliably, and with high detail to be useful for site-specific management in crop protection and to promote more sustainable agriculture by reducing pesticide use. Here, the optimization of a deep residual convolutional neural network (ResNet-18) for the classification of weed and crop plants in UAV imagery is proposed. The target was to reach sufficient performance on an embedded system by maintaining the same features of the ResNet-18 model as a basis for fast UAV mapping. This would enable online recognition and subsequent mapping of weeds during UAV flying operation. Optimization was achieved mainly by avoiding redundant computations that arise when a classification model is applied on overlapping tiles in a larger input image. The model was trained and tested with imagery obtained from a UAV flight campaign at low altitude over a winter wheat field, and classification was performed on species level with the weed species Matricaria chamomilla L., Papaver rhoeas L., Veronica hederifolia L., and Viola arvensis ssp. arvensis observed in that field. The ResNet-18 model with the optimized image-level prediction pipeline reached a performance of 2.2 frames per second with an NVIDIA Jetson AGX Xavier on the full resolution UAV image, which would amount to about 1.78 ha h−1 area output for continuous field mapping. The overall accuracy for determining crop, soil, and weed species was 94%. There were some limitations in the detection of species unknown to the model. When shifting from 16-bit to 32-bit model precision, no improvement in classification accuracy was observed, but a strong decline in speed performance, especially when a higher number of filters was used in the ResNet-18 model. Future work should be directed towards the integration of the mapping process on UAV platforms, guiding UAVs autonomously for mapping purpose, and ensuring the transferability of the models to other crop fields.
KW  - ResNet
KW  - deep residual networks
KW  - UAV imagery
KW  - embedded systems
KW  - crop monitoring
KW  - image classification
KW  - site-specific weed management
KW  - real-time mapping
DO  - 10.3390/rs13091704
ER  -
TY  - EJOU
AU  - Xu, Dandan
AU  - Wang, Haobin
AU  - Xu, Weixin
AU  - Luan, Zhaoqing
AU  - Xu, Xia
TI  - LiDAR Applications to Estimate Forest Biomass at Individual Tree Scale: Opportunities, Challenges and Future Perspectives
T2  - Forests

PY  - 2021
VL  - 12
IS  - 5
SN  - 1999-4907

AB  - Accurate forest biomass estimation at the individual tree scale is the foundation of timber industry and forest management. It plays an important role in explaining ecological issues and small-scale processes. Remotely sensed images, across a range of spatial and temporal resolutions, with their advantages of non-destructive monitoring, are widely applied in forest biomass monitoring at global, ecoregion or community scales. However, the development of remote sensing applications for forest biomass at the individual tree scale has been relatively slow due to the constraints of spatial resolution and evaluation accuracy of remotely sensed data. With the improvements in platforms and spatial resolutions, as well as the development of remote sensing techniques, the potential for forest biomass estimation at the single tree level has been demonstrated. However, a comprehensive review of remote sensing of forest biomass scaled at individual trees has not been done. This review highlights the theoretical bases, challenges and future perspectives for Light Detection and Ranging (LiDAR) applications of individual trees scaled to whole forests. We summarize research on estimating individual tree volume and aboveground biomass (AGB) using Terrestrial Laser Scanning (TLS), Airborne Laser Scanning (ALS), Unmanned Aerial Vehicle Laser Scanning (UAV-LS) and Mobile Laser Scanning (MLS, including Vehicle-borne Laser Scanning (VLS) and Backpack Laser Scanning (BLS)) data.
KW  - forest aboveground biomass
KW  - LiDAR
KW  - individual tree scale
KW  - UAV-LS
KW  - Backpack Laser Scanning
DO  - 10.3390/f12050550
ER  -
TY  - EJOU
AU  - Kuzmin, Anton
AU  - Korhonen, Lauri
AU  - Kivinen, Sonja
AU  - Hurskainen, Pekka
AU  - Korpelainen, Pasi
AU  - Tanhuanpää, Topi
AU  - Maltamo, Matti
AU  - Vihervaara, Petteri
AU  - Kumpula, Timo
TI  - Detection of European Aspen (Populus tremula L.) Based on an Unmanned Aerial Vehicle Approach in Boreal Forests
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - European aspen (Populus tremula L.) is a keystone species for biodiversity of boreal forests. Large-diameter aspens maintain the diversity of hundreds of species, many of which are threatened in Fennoscandia. Due to a low economic value and relatively sparse and scattered occurrence of aspen in boreal forests, there is a lack of information of the spatial and temporal distribution of aspen, which hampers efficient planning and implementation of sustainable forest management practices and conservation efforts. Our objective was to assess identification of European aspen at the individual tree level in a southern boreal forest using high-resolution photogrammetric point cloud (PPC) and multispectral (MSP) orthomosaics acquired with an unmanned aerial vehicle (UAV). The structure-from-motion approach was applied to generate RGB imagery-based PPC to be used for individual tree-crown delineation. Multispectral data were collected using two UAV cameras: Parrot Sequoia and MicaSense RedEdge-M. Tree-crown outlines were obtained from watershed segmentation of PPC data and intersected with multispectral mosaics to extract and calculate spectral metrics for individual trees. We assessed the role of spectral data features extracted from PPC and multispectral mosaics and a combination of it, using a machine learning classifier—Support Vector Machine (SVM) to perform two different classifications: discrimination of aspen from the other species combined into one class and classification of all four species (aspen, birch, pine, spruce) simultaneously. In the first scenario, the highest classification accuracy of 84% (F1-score) for aspen and overall accuracy of 90.1% was achieved using only RGB features from PPC, whereas in the second scenario, the highest classification accuracy of 86 % (F1-score) for aspen and overall accuracy of 83.3% was achieved using the combination of RGB and MSP features. The proposed method provides a new possibility for the rapid assessment of aspen occurrence to enable more efficient forest management as well as contribute to biodiversity monitoring and conservation efforts in boreal forests.
KW  - tree species classification
KW  - European aspen
KW  - UAV
KW  - biodiversity
KW  - deciduous trees
KW  - machine learning
KW  - multispectral data
KW  - boreal forest
DO  - 10.3390/rs13091723
ER  -
TY  - EJOU
AU  - Chen, Ang
AU  - Yang, Xiuchun
AU  - Xu, Bin
AU  - Jin, Yunxiang
AU  - Guo, Jian
AU  - Xing, Xiaoyu
AU  - Yang, Dong
AU  - Wang, Ping
AU  - Zhu, Libo
TI  - Monitoring the Spatiotemporal Dynamics of Aeolian Desertification Using Google Earth Engine
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - Northern China has been long threatened by aeolian desertification. In recent years, all levels of the Chinese government have performed a series of ecological protection and sand control projects. To grasp the implementation effects of these projects and adjust policies in time, it is necessary to understand the process of aeolian desertification quickly and accurately. Remote sensing technologies play an irreplaceable role in aeolian desertification monitoring. In this study, the Zhenglan Banner, which is in the hinterland of the Hunshandake Sandy Land, was considered as the research area. Based on unmanned aerial vehicle (UAV) images, ground survey data, and Landsat images called in Google Earth Engine (GEE), the aeolian desertified land (ADL) in 2000, 2004, 2010, 2015, and 2019 was extracted using spectral mixture analysis. A desertification index (DI) was constructed to evaluate the spatial and temporal dynamics of the ADL in the Zhenglan Banner. Finally, a residual analysis explored the driving forces of aeolian desertification. The results showed that (1) the ADL area in the Zhenglan Banner has been trending downwards over the past 20 years but rebounded from 2004 to 2010; (2) over the past 20 years, the area of slightly, moderately, and severely desertified land has decreased at annual rates of 0.4%, 2.7%, and 3.4%, respectively; (3) human activities had significantly positive and negative impacts on the aeolian desertification trend for 20.0% and 21.0% of the study area, respectively, but not for the rest. This paper explored new techniques for rapid aeolian desertification monitoring and is of great significance for controlling and managing aeolian desertification in this region.
KW  - aeolian desertification
KW  - Google Earth Engine (GEE)
KW  - unmanned aerial vehicle (UAV)
KW  - human activity
KW  - climate change
DO  - 10.3390/rs13091730
ER  -
TY  - EJOU
AU  - Hobley, Brandon
AU  - Arosio, Riccardo
AU  - French, Geoffrey
AU  - Bremner, Julie
AU  - Dolphin, Tony
AU  - Mackiewicz, Michal
TI  - Semi-Supervised Segmentation for Coastal Monitoring Seagrass Using RPA Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - Intertidal seagrass plays a vital role in estimating the overall health and dynamics of coastal environments due to its interaction with tidal changes. However, most seagrass habitats around the globe have been in steady decline due to human impacts, disturbing the already delicate balance in the environmental conditions that sustain seagrass. Miniaturization of multi-spectral sensors has facilitated very high resolution mapping of seagrass meadows, which significantly improves the potential for ecologists to monitor changes. In this study, two analytical approaches used for classifying intertidal seagrass habitats are compared—Object-based Image Analysis (OBIA) and Fully Convolutional Neural Networks (FCNNs). Both methods produce pixel-wise classifications in order to create segmented maps. FCNNs are an emerging set of algorithms within Deep Learning. Conversely, OBIA has been a prominent solution within this field, with many studies leveraging in-situ data and multiresolution segmentation to create habitat maps. This work demonstrates the utility of FCNNs in a semi-supervised setting to map seagrass and other coastal features from an optical drone survey conducted at Budle Bay, Northumberland, England. Semi-supervision is also an emerging field within Deep Learning that has practical benefits of achieving state of the art results using only subsets of labelled data. This is especially beneficial for remote sensing applications where in-situ data is an expensive commodity. For our results, we show that FCNNs have comparable performance with the standard OBIA method used by ecologists.
KW  - deep learning
KW  - computer vision
KW  - remote sensing
KW  - supervised learning
KW  - semi-supervised learning
KW  - segmentation
KW  - seagrass mapping
DO  - 10.3390/rs13091741
ER  -
TY  - EJOU
AU  - Abdelbaki, Asmaa
AU  - Schlerf, Martin
AU  - Retzlaff, Rebecca
AU  - Machwitz, Miriam
AU  - Verrelst, Jochem
AU  - Udelhoven, Thomas
TI  - Comparison of Crop Trait Retrieval Strategies Using UAV-Based VNIR Hyperspectral Imaging
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - Hyperspectral cameras onboard unmanned aerial vehicles (UAVs) have recently emerged for monitoring crop traits at the sub-field scale. Different physical, statistical, and hybrid methods for crop trait retrieval have been developed. However, spectra collected from UAVs can be confounded by various issues, including illumination variation throughout the crop growing season, the effect of which on the retrieval performance is not well understood at present. In this study, four retrieval methods are compared, in terms of retrieving the leaf area index (LAI), fractional vegetation cover (fCover), and canopy chlorophyll content (CCC) of potato plants over an agricultural field for six dates during the growing season. We analyzed: (1) The standard look-up table method (LUTstd), (2) an improved (regularized) LUT method that involves variable correlation (LUTreg), (3) hybrid methods, and (4) random forest regression without (RF) and with (RFexp) the exposure time as an additional explanatory variable. The Soil–Leaf–Canopy (SLC) model was used in association with the LUT-based inversion and hybrid methods, while the statistical modelling methods (RF and RFexp) relied entirely on in situ data. The results revealed that RFexp was the best-performing method, yielding the highest accuracies, in terms of the normalized root mean square error (NRMSE), for LAI (5.36%), fCover (5.87%), and CCC (15.01%). RFexp was able to reduce the effects of illumination variability and cloud shadows. LUTreg outperformed the other two retrieval methods (hybrid methods and LUTstd), with an NRMSE of 9.18% for LAI, 10.46% for fCover, and 12.16% for CCC. Conversely, LUTreg led to lower accuracies than those derived from RF for LAI (5.51%) and for fCover (6.23%), but not for CCC (16.21%). Therefore, the machine learning approaches—in particular, RF—appear to be the most promising retrieval methods for application to UAV-based hyperspectral data.
KW  - LUT-based inversion
KW  - hybrid method
KW  - statistical method
KW  - leaf area index
KW  - fractional vegetation cover
KW  - canopy chlorophyll content
DO  - 10.3390/rs13091748
ER  -
TY  - EJOU
AU  - Varela, Sebastian
AU  - Pederson, Taylor
AU  - Bernacchi, Carl J.
AU  - Leakey, Andrew D. B.
TI  - Understanding Growth Dynamics and Yield Prediction of Sorghum Using High Temporal Resolution UAV Imagery Time Series and Machine Learning
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - Unmanned aerial vehicles (UAV) carrying multispectral cameras are increasingly being used for high-throughput phenotyping (HTP) of above-ground traits of crops to study genetic diversity, resource use efficiency and responses to abiotic or biotic stresses. There is significant unexplored potential for repeated data collection through a field season to reveal information on the rates of growth and provide predictions of the final yield. Generating such information early in the season would create opportunities for more efficient in-depth phenotyping and germplasm selection. This study tested the use of high-resolution time-series imagery (5 or 10 sampling dates) to understand the relationships between growth dynamics, temporal resolution and end-of-season above-ground biomass (AGB) in 869 diverse accessions of highly productive (mean AGB = 23.4 Mg/Ha), photoperiod sensitive sorghum. Canopy surface height (CSM), ground cover (GC), and five common spectral indices were considered as features of the crop phenotype. Spline curve fitting was used to integrate data from single flights into continuous time courses. Random Forest was used to predict end-of-season AGB from aerial imagery, and to identify the most informative variables driving predictions. Improved prediction of end-of-season AGB (RMSE reduction of 0.24 Mg/Ha) was achieved earlier in the growing season (10 to 20 days) by leveraging early- and mid-season measurement of the rate of change of geometric and spectral features. Early in the season, dynamic traits describing the rates of change of CSM and GC predicted end-of-season AGB best. Late in the season, CSM on a given date was the most influential predictor of end-of-season AGB. The power to predict end-of-season AGB was greatest at 50 days after planting, accounting for 63% of variance across this very diverse germplasm collection with modest error (RMSE 1.8 Mg/ha). End-of-season AGB could be predicted equally well when spline fitting was performed on data collected from five flights versus 10 flights over the growing season. This demonstrates a more valuable and efficient approach to using UAVs for HTP, while also proposing strategies to add further value.
KW  - unmanned aerial vehicles
KW  - high throughput phenotyping
KW  - machine learning
KW  - bioenergy crops
DO  - 10.3390/rs13091763
ER  -
TY  - EJOU
AU  - Wang, Li
AU  - Chen, Shuisen
AU  - Peng, Zhiping
AU  - Huang, Jichuan
AU  - Wang, Chongyang
AU  - Jiang, Hao
AU  - Zheng, Qiong
AU  - Li, Dan
TI  - Phenology Effects on Physically Based Estimation of Paddy Rice Canopy Traits from UAV Hyperspectral Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - Radiation transform models such as PROSAIL are widely used for crop canopy reflectance simulation and biophysical parameter inversion. The PROSAIL model basically assumes that the canopy is turbid homogenous media with a bare soil background. However, the canopy structure changes when crop growth stages develop, which is more or less a departure from this assumption. In addition, a paddy rice field is inundated most of the time with flooded soil background. In this study, field-scale paddy rice leaf area index (LAI), leaf cholorphyll content (LCC), and canopy chlorophyll content (CCC) were retrieved from unmanned-aerial-vehicle-based hyperspectral images by the PROSAIL radiation transform model using a lookup table (LUT) strategy, with a special focus on the effects of growth-stage development and soil-background signature selection. Results show that involving flooded soil reflectance as background reflectance for PROSAIL could improve estimation accuracy. When using a LUT with the flooded soil reflectance signature (LUTflooded) the coefficients of determination (R2) between observed and estimation variables are 0.70, 0.11, and 0.79 for LAI, LCC, and CCC, respectively, for the entire growing season (from tillering to heading growth stages), and the corresponding mean absolute errors (MAEs) are 21.87%, 16.27%, and 12.52%. For LAI and LCC, high model bias mainly occurred in tillering growth stages. There is an obvious overestimation of LAI and underestimation of LCC for in the tillering growth stage. The estimation accuracy of CCC is relatively consistent from tillering to heading growth stages.
KW  - paddy rice
KW  - growth stages
KW  - phenology
KW  - soil background
KW  - radiative transfer models
KW  - PROSAIL
KW  - lookup tables
KW  - hyperspectral
DO  - 10.3390/rs13091792
ER  -
TY  - EJOU
AU  - Feroz, Sainab
AU  - Abu Dabous, Saleh
TI  - UAV-Based Remote Sensing Applications for Bridge Condition Assessment
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - Deterioration of bridge infrastructure is a serious concern to transport and government agencies as it declines serviceability and reliability of bridges and jeopardizes public safety. Maintenance and rehabilitation needs of bridge infrastructure are periodically monitored and assessed, typically every two years. Existing inspection techniques, such as visual inspection, are time-consuming, subjective, and often incomplete. Non-destructive testing (NDT) using Unmanned Aerial Vehicles (UAVs) have been gaining momentum for bridge monitoring in the recent years, particularly due to enhanced accessibility and cost efficiency, deterrence of traffic closure, and improved safety during inspection. The primary objective of this study is to conduct a comprehensive review of the application of UAVs in bridge condition monitoring, used in conjunction with remote sensing technologies. Remote sensing technologies such as visual imagery, infrared thermography, LiDAR, and other sensors, integrated with UAVs for data acquisition are analyzed in depth. This study compiled sixty-five journal and conference papers published in the last two decades scrutinizing NDT-based UAV systems. In addition to comparison of stand-alone and integrated NDT-UAV methods, the facilitation of bridge inspection using UAVs is thoroughly discussed in the present article in terms of ease of use, accuracy, cost-efficiency, employed data collection tools, and simulation platforms. Additionally, challenges and future perspectives of the reviewed UAV-NDT technologies are highlighted.
KW  - unmanned aerial vehicles
KW  - drones
KW  - condition monitoring
KW  - remote sensing
KW  - non-destructive testing
KW  - remotely piloted aircraft
DO  - 10.3390/rs13091809
ER  -
TY  - EJOU
AU  - Muharam, Farrah M.
AU  - Nurulhuda, Khairudin
AU  - Zulkafli, Zed
AU  - Tarmizi, Mohamad A.
AU  - Abdullah, Asniyani N.
AU  - Che Hashim, Muhamad F.
AU  - Mohd Zad, Siti N.
AU  - Radhwane, Derraz
AU  - Ismail, Mohd R.
TI  - UAV- and Random-Forest-AdaBoost (RFA)-Based Estimation of Rice Plant Traits
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 5
SN  - 2073-4395

AB  - Rapid, accurate and inexpensive methods are required to analyze plant traits throughout all crop growth stages for plant phenotyping. Few studies have comprehensively evaluated plant traits from multispectral cameras onboard UAV platforms. Additionally, machine learning algorithms tend to over- or underfit data and limited attention has been paid to optimizing their performance through an ensemble learning approach. This study aims to (1) comprehensively evaluate twelve rice plant traits estimated from aerial unmanned vehicle (UAV)-based multispectral images and (2) introduce Random Forest AdaBoost (RFA) algorithms as an optimization approach for estimating plant traits. The approach was tested based on a farmer’s field in Terengganu, Malaysia, for the off-season from February to June 2018, involving five rice cultivars and three nitrogen (N) rates. Four bands, thirteen indices and Random Forest-AdaBoost (RFA) regression models were evaluated against the twelve plant traits according to the growth stages. Among the plant traits, plant height, green leaf and storage organ biomass, and foliar nitrogen (N) content were estimated well, with a coefficient of determination (R2) above 0.80. In comparing the bands and indices, red, Normalized Difference Vegetation Index (NDVI), Ratio Vegetation Index (RVI), Red-Edge Wide Dynamic Range Vegetation Index (REWDRVI) and Red-Edge Soil Adjusted Vegetation Index (RESAVI) were remarkable in estimating all plant traits at tillering, booting and milking stages with R2 values ranging from 0.80–0.99 and root mean square error (RMSE) values ranging from 0.04–0.22. Milking was found to be the best growth stage to conduct estimations of plant traits. In summary, our findings demonstrate that an ensemble learning approach can improve the accuracy as well as reduce under/overfitting in plant phenotyping algorithms.
KW  - rice
KW  - phenotyping
KW  - multispectral images
KW  - machine learning
KW  - boosting algorithm
DO  - 10.3390/agronomy11050915
ER  -
TY  - EJOU
AU  - Chen, Shuo
AU  - Zhang, Kefei
AU  - Zhao, Yindi
AU  - Sun, Yaqin
AU  - Ban, Wei
AU  - Chen, Yu
AU  - Zhuang, Huifu
AU  - Zhang, Xuewei
AU  - Liu, Jinxiang
AU  - Yang, Tao
TI  - An Approach for Rice Bacterial Leaf Streak Disease Segmentation and Disease Severity Estimation
T2  - Agriculture

PY  - 2021
VL  - 11
IS  - 5
SN  - 2077-0472

AB  - Rice bacterial leaf streak (BLS) is a serious disease in rice leaves and can seriously affect the quality and quantity of rice growth. Automatic estimation of disease severity is a crucial requirement in agricultural production. To address this, a new method (termed BLSNet) was proposed for rice and BLS leaf lesion recognition and segmentation based on a UNet network in semantic segmentation. An attention mechanism and multi-scale extraction integration were used in BLSNet to improve the accuracy of lesion segmentation. We compared the performance of the proposed network with that of DeepLabv3+ and UNet as benchmark models used in semantic segmentation. It was found that the proposed BLSNet model demonstrated higher segmentation and class accuracy. A preliminary investigation of BLS disease severity estimation was carried out based on our BLS segmentation results, and it was found that the proposed BLSNet method has strong potential to be a reliable automatic estimator of BLS disease severity.
KW  - rice bacterial leaf streak
KW  - leaf disease recognition
KW  - lesion segmentation
KW  - semantic segmentation
KW  - deep learning
KW  - convolutional neural network
KW  - disease severity estimation
DO  - 10.3390/agriculture11050420
ER  -
TY  - EJOU
AU  - Benmokhtar, Salma
AU  - Robin, Marc
AU  - Maanan, Mohamed
AU  - Bazairi, Hocein
TI  - Mapping and Quantification of the Dwarf Eelgrass Zostera noltei Using a Random Forest Algorithm on a SPOT 7 Satellite Image
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 5
SN  - 2220-9964

AB  - The dwarf eelgrass Zostera noltei Hornemann (Z. noltei) is the most dominant seagrass in semi-enclosed coastal systems of the Atlantic coast of Morocco. The species is experiencing a worldwide decline and monitoring the extent of its meadows would be a useful approach to estimate the impacts of natural and anthropogenic stressors. Here, we aimed to map the Z. noltei meadows in the Merja Zerga coastal lagoon (Atlantic coast of Morocco) using remote sensing. We used a random forest algorithm combined with field data to classify a SPOT 7 satellite image. Despite the difficulties related to the non-synchronization of the satellite images with the high tide coefficient, our results revealed, with an accuracy of 95%, that dwarf eelgrass beds can be discriminated successfully from other habitats in the lagoon. The estimated area was 160.76 ha when considering mixed beds (Z. noltei-associated macroalgae). The use of SPOT 7 satellite images seems to be satisfactory for long-term monitoring of Z. noltei meadows in the Merja Zerga lagoon and for biomass estimation using an NDVI–biomass quantitative relationship. Nevertheless, using this method of biomass estimation for dwarf eelgrass meadows could be unsuccessful when it comes to areas where the NDVI is saturated due to the stacking of many layers.
KW  - seagrass
KW  - remote sensing
KW  - random forest
KW  - vegetation indices
KW  - machine learning classification
DO  - 10.3390/ijgi10050313
ER  -
TY  - EJOU
AU  - Mahmud, Md S.
AU  - Zahid, Azlan
AU  - He, Long
AU  - Martin, Phillip
TI  - Opportunities and Possibilities of Developing an Advanced Precision Spraying System for Tree Fruits
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 9
SN  - 1424-8220

AB  - Reducing risk from pesticide applications has been gaining serious attention in the last few decades due to the significant damage to human health, environment, and ecosystems. Pesticide applications are an essential part of current agriculture, enhancing cultivated crop productivity and quality and preventing losses of up to 45% of the world food supply. However, inappropriate and excessive use of pesticides is a major rising concern. Precision spraying addresses these concerns by precisely and efficiently applying pesticides to the target area and substantially reducing pesticide usage while maintaining efficacy at preventing crop losses. This review provides a systematic summary of current technologies used for precision spraying in tree fruits and highlights their potential, briefly discusses factors affecting spraying parameters, and concludes with possible solutions to reduce excessive agrochemical uses. We conclude there is a critical need for appropriate sensing techniques that can accurately detect the target. In addition, air jet velocity, travel speed, wind speed and direction, droplet size, and canopy characteristics need to be considered for successful droplet deposition by the spraying system. Assessment of terrain is important when field elevation has significant variability. Control of airflow during spraying is another important parameter that needs to be considered. Incorporation of these variables in precision spraying systems will optimize spray decisions and help reduce excessive agrochemical applications.
KW  - crop protection
KW  - canopy detection
KW  - canopy density
KW  - canopy volume
KW  - deep learning
KW  - machine vision
KW  - sensing
DO  - 10.3390/s21093262
ER  -
TY  - EJOU
AU  - Chormański, Jarosław
AU  - Nowicka, Barbara
AU  - Wieckowski, Aleksander
AU  - Ciupak, Maurycy
AU  - Jóźwiak, Jacek
AU  - Figura, Tadeusz
TI  - Coupling of Dual Channel Waveform ALS and Sonar for Investigation of Lake Bottoms and Shore Zones
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - In this work, we proposed to include remote sensing techniques as a part of the methodology for natural lake bottom mapping, with a focus on the littoral zone. Due to the inaccessibility of this zone caused by dense vegetation, measurements of the lake bottom and the coastline are also difficult to perform using traditional methods. The authors of this paper present, discuss and verify the applicability of remote sensing active sensors as a tool for measurements in the shore zone of a lake. The single-beam Lowrance HDS-7 ComboGPS echosounder with an 83/200 kHz transducer and a two-beam LiDAR RIEGL VQ-1560i-DW scanner have been used for reservoir bottom measurements of two neighboring lakes, which differ in terms of water transparency. The research has found a strong correlation between both sonar and LiDAR for mapping the bottom depth in a range up to 1.6 m, and allowed LiDAR mapping of approximately 20% of the highly transparent lake, but it has not been found to be useful in water with low transparency. In the light of the conducted research, both devices, sonar and LiDAR, have potential for complementary use by fusing both methods: the sonar for mapping of the sublittoral and the pelagic zone, and the LiDAR for mapping of the littoral zone, overcoming limitation related to vegetation in the lake shore zone.
KW  - bathymetry
KW  - dual channel LiDAR
KW  - Green-ALS
KW  - sonar
KW  - lake shoreline
KW  - shore zone
KW  - eutrophication
DO  - 10.3390/rs13091833
ER  -
TY  - EJOU
AU  - Guffogg, Jenna A.
AU  - Soto-Berelov, Mariela
AU  - Jones, Simon D.
AU  - Bellman, Chris J.
AU  - Lavers, Jennifer L.
AU  - Skidmore, Andrew K.
TI  - Towards the Spectral Mapping of Plastic Debris on Beaches
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - Floating and washed ashore marine plastic debris (MPD) is a growing environmental challenge. It has become evident that secluded locations including the Arctic, Antarctic, and remote islands are being impacted by plastic pollution generated thousands of kilometers away. Optical remote sensing of MPD is an emerging field that can aid in monitoring remote environments where in-person observation and data collection is not always feasible. Here we evaluate MPD spectral features in the visible to shortwave infrared regions for detecting varying quantities of MPD that have accumulated on beaches using a spectroradiometer. Measurements were taken from a range of in situ MPD accumulations ranging from 0.08% to 7.94% surface coverage. Our results suggest that spectral absorption features at 1215 nm and 1732 nm are useful for detecting varying abundance levels of MPD in a complex natural environment, however other absorption features at 931 nm, 1045 nm and 2046 nm could not detect in situ MPD. The reflectance of some in situ MPD accumulations was statistically different from samples that only contained organic debris and sand between 1.56% and 7.94% surface cover; however other samples with similar surface cover did not have reflectance that was statistically different from samples containing no MPD. Despite MPD being detectable against a background of sand and organic beach debris, a clear relationship between the surface cover of MPD and the strength of key absorption features could not be established. Additional research is needed to advance our understanding of the factors, such as type of MPD assemblage, that contribute to the bulk reflectance of MPD contaminated landscapes.
KW  - Cocos (Keeling) Islands
KW  - plastic debris
KW  - proximal remote sensing
KW  - macroplastics
KW  - spectral absorption features
KW  - shortwave infrared
KW  - spectroscopy
KW  - hyperspectral
DO  - 10.3390/rs13091850
ER  -
TY  - EJOU
AU  - Jin, Xing
AU  - Tang, Ping
AU  - Zhang, Zheng
TI  - Sequence Image Datasets Construction via Deep Convolution Networks
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - Remote-sensing time-series datasets are significant for global change research and a better understanding of the Earth. However, remote-sensing acquisitions often provide sparse time series due to sensor resolution limitations and environmental factors such as cloud noise for optical data. Image transformation is the method that is often used to deal with this issue. This paper considers the deep convolution networks to learn the complex mapping between sequence images, called adaptive filter generation network (AdaFG), convolution long short-term memory network (CLSTM), and cycle-consistent generative adversarial network (CyGAN) for construction of sequence image datasets. AdaFG network uses a separable 1D convolution kernel instead of 2D kernels to capture the spatial characteristics of input sequence images and then is trained end-to-end using sequence images. CLSTM network can map between different images using the state information of multiple time-series images. CyGAN network can map an image from a source domain to a target domain without additional information. Our experiments, which were performed with unmanned aerial vehicle (UAV) and Landsat-8 datasets, show that the deep convolution networks are effective to produce high-quality time-series image datasets, and the data-driven deep convolution networks can better simulate complex and diverse nonlinear data information.
KW  - sequence image datasets
KW  - adaptive filter generation network
KW  - convolution long short-term memory network
KW  - cycle-consistent generative adversarial network
KW  - UAV dataset
KW  - Landsat-8 dataset
DO  - 10.3390/rs13091853
ER  -
TY  - EJOU
AU  - Cheng, Zhenzhen
AU  - Qi, Lijun
AU  - Cheng, Yifan
TI  - Cherry Tree Crown Extraction from Natural Orchard Images with Complex Backgrounds
T2  - Agriculture

PY  - 2021
VL  - 11
IS  - 5
SN  - 2077-0472

AB  - Highly effective pesticide applications require a continual adjustment of the pesticide spray flow rate that attends to different canopy characterizations. Real-time image processing with rapid target detection and data-processing technologies is vital for precision pesticide application. However, the extant studies do not provide an efficient and reliable method of extracting individual trees with irregular tree-crown shapes and complicated backgrounds. This paper on our study proposes a Mahalanobis distance and conditional random field (CRF)-based segmentation model to extract cherry trees accurately in a natural orchard environment. This study computed Mahalanobis distance from the image’s color, brightness and location features to acquire an initial classification of the canopy and background. A CRF was then created by using the Mahalanobis distance calculations as unary potential energy and the Gaussian kernel function based on the image color and pixels distance as binary potential energy. Finally, the study completed image segmentation using mean-field approximation. The results show that the proposed method displays a higher accuracy rate than the traditional algorithms K-means and GrabCut algorithms and lower labeling and training costs than the deep learning algorithm DeepLabv3+, with 92.1%, 94.5% and 93.3% of the average P, R and F1-score, respectively. Moreover, experiments on datasets with different overlap conditions and image acquisition times, as well as in different years and seasons, show that this method performs well under complex background conditions, with an average F1-score higher than 87.7%.
KW  - agricultural computer vision
KW  - tree-crown segmentation
KW  - complex scene
KW  - natural orchard environment
DO  - 10.3390/agriculture11050431
ER  -
TY  - EJOU
AU  - Bashir, Syed M.
AU  - Wang, Yi
TI  - Small Object Detection in Remote Sensing Images with Residual Feature Aggregation-Based Super-Resolution and Object Detector Network
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - This paper deals with detecting small objects in remote sensing images from satellites or any aerial vehicle by utilizing the concept of image super-resolution for image resolution enhancement using a deep-learning-based detection method. This paper provides a rationale for image super-resolution for small objects by improving the current super-resolution (SR) framework by incorporating a cyclic generative adversarial network (GAN) and residual feature aggregation (RFA) to improve detection performance. The novelty of the method is threefold: first, a framework is proposed, independent of the final object detector used in research, i.e., YOLOv3 could be replaced with Faster R-CNN or any object detector to perform object detection; second, a residual feature aggregation network was used in the generator, which significantly improved the detection performance as the RFA network detected complex features; and third, the whole network was transformed into a cyclic GAN. The image super-resolution cyclic GAN with RFA and YOLO as the detection network is termed as SRCGAN-RFA-YOLO, which is compared with the detection accuracies of other methods. Rigorous experiments on both satellite images and aerial images (ISPRS Potsdam, VAID, and Draper Satellite Image Chronology datasets) were performed, and the results showed that the detection performance increased by using super-resolution methods for spatial resolution enhancement; for an IoU of 0.10, AP of 0.7867 was achieved for a scale factor of 16.
KW  - object detection in satellite images
KW  - image classification
KW  - vehicle detection
KW  - remote sensing
KW  - deep learning
KW  - generative adversarial networks
KW  - residual feature aggregation (RFA)
DO  - 10.3390/rs13091854
ER  -
TY  - EJOU
AU  - Aabid, Abdul
AU  - Parveez, Bisma
AU  - Raheman, Md A.
AU  - Ibrahim, Yasser E.
AU  - Anjum, Asraar
AU  - Hrairi, Meftah
AU  - Parveen, Nagma
AU  - Mohammed Zayan, Jalal
TI  - A Review of Piezoelectric Material-Based Structural Control and Health Monitoring Techniques for Engineering Structures: Challenges and Opportunities
T2  - Actuators

PY  - 2021
VL  - 10
IS  - 5
SN  - 2076-0825

AB  - With the breadth of applications and analysis performed over the last few decades, it would not be an exaggeration to call piezoelectric materials “the top of the crop” of smart materials. Piezoelectric materials have emerged as the most researched materials for practical applications among the numerous smart materials. They owe it to a few main reasons, including low cost, high bandwidth of service, availability in a variety of formats, and ease of handling and execution. Several authors have used piezoelectric materials as sensors and actuators to effectively control structural vibrations, noise, and active control, as well as for structural health monitoring, over the last three decades. These studies cover a wide range of engineering disciplines, from vast space systems to aerospace, automotive, civil, and biomedical engineering. Therefore, in this review, a study has been reported on piezoelectric materials and their advantages in engineering fields with fundamental modeling and applications. Next, the new approaches and hypotheses suggested by different scholars are also explored for control/repair methods and the structural health monitoring of engineering structures. Lastly, the challenges and opportunities has been discussed based on the exhaustive literature studies for future work. As a result, this review can serve as a guideline for the researchers who want to use piezoelectric materials for engineering structures.
KW  - piezoelectric material
KW  - vibration control
KW  - noise control
KW  - active control
KW  - damage structure
KW  - SHM
DO  - 10.3390/act10050101
ER  -
TY  - EJOU
AU  - Ballesteros, Rocío
AU  - Moreno, Miguel A.
AU  - Barroso, Fellype
AU  - González-Gómez, Laura
AU  - Ortega, José F.
TI  - Assessment of Maize Growth and Development with High- and Medium-Resolution Remote Sensing Products
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 5
SN  - 2073-4395

AB  - The availability of a great amount of remote sensing data for precision agriculture purposes has set the question of which resolution and indices, derived from satellites or unmanned aerial vehicles (UAVs), offer the most accurate results to characterize vegetation. This study focused on assessing, comparing, and discussing the performances and limitations of satellite and UAV-based imagery in terms of canopy development, i.e., the leaf area index (LAI), and yield, i.e., the dry aboveground biomass (DAGB), for maize. Three commercial maize fields were studied over four seasons to obtain the LAI and DAGB. The normalized difference vegetation index (NDVI) and visible atmospherically resistant index (VARI) from satellite platforms (Landsat 5TM, 7 ETM+, 8OLI, and Sentinel 2A MSI) and the VARI and green canopy cover (GCC) from UAV imagery were compared. The remote sensing predictors in addition to the growing degree days (GDD) were assessed to estimate the LAI and DAGB using multilinear regression models (MRMs). For LAI estimation, better adjustments were obtained when predictors from the UAV platform were considered. The DAGB estimation revealed similar adjustments for both platforms, although the Landsat imagery offered slightly better adjustments. The results obtained in this study demonstrate the advantage of remote sensing platforms as a useful tool to estimate essential agronomic features.
KW  - remote sensing
KW  - satellite imagery
KW  - unmanned aerial vehicle (UAV) imagery
KW  - leaf area index (LAI)
KW  - biomass
KW  - maize
DO  - 10.3390/agronomy11050940
ER  -
TY  - EJOU
AU  - Ioannou, Konstantinos
AU  - Myronidis, Dimitrios
TI  - Automatic Detection of Photovoltaic Farms Using Satellite Imagery and Convolutional Neural Networks
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 9
SN  - 2071-1050

AB  - The number of solar photovoltaic (PV) arrays in Greece has increased rapidly during the recent years. As a result, there is an increasing need for high quality updated information regarding the status of PV farms. This information includes the number of PV farms, power capacity and the energy generated. However, access to this data is obsolete, mainly due to the fact that there is a difficulty tracking PV investment status (from licensing to investment completion and energy production). This article presents a novel approach, which uses free access high resolution satellite imagery and a deep learning algorithm (a convolutional neural network—CNN) for the automatic detection of PV farms. Furthermore, in an effort to create an algorithm capable of generalizing better, all the current locations with installed PV farms (data provided from the Greek Energy Regulator Authority) in the Greek Territory (131,957 km2) were used. According to our knowledge this is the first time such an algorithm is used in order to determine the existence of PV farms and the results showed satisfying accuracy.
KW  - PV farms
KW  - deep learning
KW  - satellite imagery
KW  - CNN
KW  - automatic detection
DO  - 10.3390/su13095323
ER  -
TY  - EJOU
AU  - Jin, Hongxiao
AU  - Köppl, Christian J.
AU  - Fischer, Benjamin M. C.
AU  - Rojas-Conejo, Johanna
AU  - Johnson, Mark S.
AU  - Morillas, Laura
AU  - Lyon, Steve W.
AU  - Durán-Quesada, Ana M.
AU  - Suárez-Serrano, Andrea
AU  - Manzoni, Stefano
AU  - Garcia, Monica
TI  - Drone-Based Hyperspectral and Thermal Imagery for Quantifying Upland Rice Productivity and Water Use Efficiency after Biochar Application
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 10
SN  - 2072-4292

AB  - Miniature hyperspectral and thermal cameras onboard lightweight unmanned aerial vehicles (UAV) bring new opportunities for monitoring land surface variables at unprecedented fine spatial resolution with acceptable accuracy. This research applies hyperspectral and thermal imagery from a drone to quantify upland rice productivity and water use efficiency (WUE) after biochar application in Costa Rica. The field flights were conducted over two experimental groups with bamboo biochar (BC1) and sugarcane biochar (BC2) amendments and one control (C) group without biochar application. Rice canopy biophysical variables were estimated by inverting a canopy radiative transfer model on hyperspectral reflectance. Variations in gross primary productivity (GPP) and WUE across treatments were estimated using light-use efficiency and WUE models respectively from the normalized difference vegetation index (NDVI), canopy chlorophyll content (CCC), and evapotranspiration rate. We found that GPP was increased by 41.9 ± 3.4% in BC1 and 17.5 ± 3.4% in BC2 versus C, which may be explained by higher soil moisture after biochar application, and consequently significantly higher WUEs by 40.8 ± 3.5% in BC1 and 13.4 ± 3.5% in BC2 compared to C. This study demonstrated the use of hyperspectral and thermal imagery from a drone to quantify biochar effects on dry cropland by integrating ground measurements and physical models.
KW  - unmanned aerial vehicle (UAV)
KW  - hyperspectral and thermal imagery
KW  - gross primary productivity (GPP)
KW  - water use efficiency (WUE)
KW  - biochar
KW  - upland rice
DO  - 10.3390/rs13101866
ER  -
TY  - EJOU
AU  - Lama, Giuseppe F.
AU  - Crimaldi, Mariano
AU  - Pasquino, Vittorio
AU  - Padulano, Roberta
AU  - Chirico, Giovanni B.
TI  - Bulk Drag Predictions of Riparian Arundo donax Stands through UAV-Acquired Multispectral Images
T2  - Water

PY  - 2021
VL  - 13
IS  - 10
SN  - 2073-4441

AB  - Estimating the main hydrodynamic features of real vegetated water bodies is crucial to assure a balance between their hydraulic conveyance and environmental quality. Riparian vegetation stands have a high impact on vegetated channels. The present work has the aim to integrate riparian vegetation’s reflectance indices and hydrodynamics of real vegetated water flows to assess the impact of riparian vegetation morphometry on bulk drag coefficients distribution along an abandoned vegetated drainage channel fully covered by 9–10 m high Arundo donax (commonly known as giant reed) stands, starting from flow average velocities measurements at 30 cross-sections identified along the channel. A map of riparian vegetation cover was obtained through digital processing of Unnamed Aerial Vehicle (UAV)-acquired multispectral images, which represent a fast way to observe riparian plants’ traits in hardly accessible areas such as vegetated water bodies in natural conditions. In this study, the portion of riparian plants effectively interacting with flow was expressed in terms of ground-based Leaf Area Index measurements (LAI), which easily related to UAV-based Normalized Difference Vegetation Index (NDVI). The comparative analysis between Arundo donax stands NDVI and LAI map enabled the analysis of the impact of UAV-acquired multispectral imagery on bulk drag predictions along the vegetated drainage channel.
KW  - ecohydraulics
KW  - bulk drag coefficients
KW  - vegetated flows
KW  - Arundo donax stands
KW  - multispectral images
KW  - UAV
DO  - 10.3390/w13101333
ER  -
TY  - EJOU
AU  - Mattivi, Pietro
AU  - Pappalardo, Salvatore E.
AU  - Nikolić, Nebojša
AU  - Mandolesi, Luca
AU  - Persichetti, Antonio
AU  - De Marchi, Massimo
AU  - Masin, Roberta
TI  - Can Commercial Low-Cost Drones and Open-Source GIS Technologies Be Suitable for Semi-Automatic Weed Mapping for Smart Farming? A Case Study in NE Italy
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 10
SN  - 2072-4292

AB  - Weed management is a crucial issue in agriculture, resulting in environmental in-field and off-field impacts. Within Agriculture 4.0, adoption of UASs combined with spatially explicit approaches may drastically reduce doses of herbicides, increasing sustainability in weed management. However, Agriculture 4.0 technologies are barely adopted in small-medium size farms. Recently, small and low-cost UASs, together with open-source software packages, may represent a low-cost spatially explicit system to map weed distribution in crop fields. The general aim is to map weed distribution by a low-cost UASs and a replicable workflow, completely based on open GIS software and algorithms: OpenDroneMap, QGIS, SAGA and OpenCV classification algorithms. Specific objectives are: (i) testing a low-cost UAS for weed mapping; (ii) assessing open-source packages for semi-automatic weed classification; (iii) performing a sustainable management scenario by prescription maps. Results showed high performances along the whole process: in orthomosaic generation at very high spatial resolution (0.01 m/pixel), in testing weed detection (Matthews Correlation Coefficient: 0.67–0.74), and in the production of prescription maps, reducing herbicide treatment to only 3.47% of the entire field. This study reveals the feasibility of low-cost UASs combined with open-source software, enabling a spatially explicit approach for weed management in small-medium size farmlands.
KW  - site-specific weed management
KW  - precision farming
KW  - OpenDroneMap
KW  - open photogrammetry
KW  - open-source mapping
DO  - 10.3390/rs13101869
ER  -
TY  - EJOU
AU  - Duarte, Lia
AU  - Teodoro, Ana C.
AU  - Sousa, Joaquim J.
AU  - Pádua, Luís
TI  - QVigourMap: A GIS Open Source Application for the Creation of Canopy Vigour Maps
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 5
SN  - 2073-4395

AB  - In a precision agriculture context, the amount of geospatial data available can be difficult to interpret in order to understand the crop variability within a given terrain parcel, raising the need for specific tools for data processing and analysis. This is the case for data acquired from Unmanned Aerial Vehicles (UAV), in which the high spatial resolution along with data from several spectral wavelengths makes data interpretation a complex process regarding vegetation monitoring. Vegetation Indices (VIs) are usually computed, helping in the vegetation monitoring process. However, a crop plot is generally composed of several non-crop elements, which can bias the data analysis and interpretation. By discarding non-crop data, it is possible to compute the vigour distribution for a specific crop within the area under analysis. This article presents QVigourMaps, a new open source application developed to generate useful outputs for precision agriculture purposes. The application was developed in the form of a QGIS plugin, allowing the creation of vigour maps, vegetation distribution maps and prescription maps based on the combination of different VIs and height information. Multi-temporal data from a vineyard plot and a maize field were used as case studies in order to demonstrate the potential and effectiveness of the QVigourMaps tool. The presented application can contribute to making the right management decisions by providing indicators of crop variability, and the outcomes can be used in the field to apply site-specific treatments according to the levels of vigour.
KW  - precision agriculture
KW  - multispectral imagery
KW  - variable rate
KW  - precision viticulture
KW  - GIS
DO  - 10.3390/agronomy11050952
ER  -
TY  - EJOU
AU  - Quan, Longzhe
AU  - Wu, Bing
AU  - Mao, Shouren
AU  - Yang, Chunjie
AU  - Li, Hengda
TI  - An Instance Segmentation-Based Method to Obtain the Leaf Age and Plant Centre of Weeds in Complex Field Environments
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 10
SN  - 1424-8220

AB  - Leaf age and plant centre are important phenotypic information of weeds, and accurate identification of them plays an important role in understanding the morphological structure of weeds, guiding precise targeted spraying and reducing the use of herbicides. In this work, a weed segmentation method based on BlendMask is proposed to obtain the phenotypic information of weeds under complex field conditions. This study collected images from different angles (front, side, and top views) of three kinds of weeds (Solanum nigrum, barnyard grass (Echinochloa crus-galli), and Abutilon theophrasti Medicus) in a maize field. Two datasets (with and without data enhancement) and two backbone networks (ResNet50 and ResNet101) were replaced to improve model performance. Finally, seven evaluation indicators are used to evaluate the segmentation results of the model under different angles. The results indicated that data enhancement and ResNet101 as the backbone network could enhance the model performance. The F1 value of the plant centre is 0.9330, and the recognition accuracy of leaf age can reach 0.957. The mIOU value of the top view is 0.642. Therefore, deep learning methods can effectively identify weed leaf age and plant centre, which is of great significance for variable spraying.
KW  - weeds
KW  - phenotype
KW  - deep learning
KW  - image segmentation
DO  - 10.3390/s21103389
ER  -
TY  - EJOU
AU  - Li, Jing
AU  - Liu, Yong
AU  - Zhang, Yindan
AU  - Zhang, Yang
TI  - Cascaded Attention DenseUNet (CADUNet) for Road Extraction from Very-High-Resolution Images
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 5
SN  - 2220-9964

AB  - The use of very-high-resolution images to extract urban, suburban and rural roads has important application value. However, it is still a problem to effectively extract the road area occluded by roadside tree canopy or high-rise buildings to maintain the integrity of the extracted road area, the smoothness of the sideline and the connectivity of the road network. This paper proposes an innovative Cascaded Attention DenseUNet (CADUNet) semantic segmentation model by embedding two attention modules, such as global attention and core attention modules, in the DenseUNet framework. First, a set of cascaded global attention modules are introduced to obtain the contextual information of the road; secondly, a set of cascaded core attention modules are embedded to ensure that the road information is transmitted to the greatest extent among the dense blocks in the network, and further assist the global attention module in acquiring multi-scale road information, thereby improving the connectivity of the road network while restoring the integrity of the road area shaded by the tree canopy and high-rise buildings. Based on binary cross entropy, an adaptive loss function is proposed for network parameter tuning. Experiments on the Massachusetts road dataset and the DeepGlobe-CVPR 2018 road dataset show that this semantic segmentation model can effectively extract the road area shaded by tree canopy and improve the connectivity of the road network.
KW  - deep learning
KW  - road
KW  - DenseUNet
KW  - attention module
KW  - semantic segmentation
KW  - remote sensing
DO  - 10.3390/ijgi10050329
ER  -
TY  - EJOU
AU  - Liu, Boda
AU  - Yang, Bin
AU  - Xiao, Jianzhuang
AU  - Zhu, Dayu
AU  - Zhang, Binghan
AU  - Wang, Zhichen
AU  - Dong, Miaosi
TI  - Review of Optimization Dynamically Applied in the Construction and the Application Potential of ICT
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 10
SN  - 2071-1050

AB  - Currently, construction projects are getting more complex, applying more information and communication technologies (ICT), while few studies use real-time data to dynamically optimize construction. The purpose of this article is to study the current development status of the optimization applied dynamically in the construction phase and their potential for applying real data collected by ICT. This article reviews 72 relevant optimization methods and identified some of the ICT research studies that can provide them with dynamic data. The dynamic triggering mode of each research is first analyzed, then its dynamic way, dynamic data, data resource, optimization object, and method are identified and formulated. The results reveal the great value of dynamic optimization in dealing with the complicated and uncertain contextual conditions in construction. Different dynamic triggering modes have different affinities with real data. Then, through the analysis of ICT articles, the huge potential of these dynamic optimization methods in applying real data is shown. This paper points out the most practical dynamic mode for engineers or managers to continuously apply optimization methods to solve dynamic problems in construction, and put forward scientific questions for related researchers: How does one combine ICT with the event dynamics or uncertain parameters? Based on this, the research gap of this area is identified a conceptual solution is proposed.
KW  - optimization
KW  - construction
KW  - information and communication technology (ICT)
KW  - scheduling
KW  - construction planning
KW  - building information modelling (BIM)
DO  - 10.3390/su13105478
ER  -
TY  - EJOU
AU  - Ostrowski, Bartłomiej
AU  - Pióro, Michał
AU  - Tomaszewski, Artur
TI  - Multicast Traffic Throughput Maximization through Joint Dynamic Modulation and Coding Schemes Assignment, and Transmission Power Control in Wireless Sensor Networks
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 10
SN  - 1424-8220

AB  - The paper concerns multicast packet traffic throughput maximization in multi-hop wireless sensor networks with time division multiple access to radio channel. We assume that the modulation and coding schemes (MCSs) that are used by the (broadcasting) nodes as well as the transmission power of the nodes are adjustable. This leads to the main research question studied in this paper: to what extent traffic throughput can be increased by proper MCSs assignment and transmission power control (TPC) at the nodes? To answer this question, we introduce mixed-integer programming formulations for joint MCSs assignment and TPC optimization, together with a solution algorithm. Finally, we present a numerical study illustrating the considerations of the paper. The numerical results show a significant gain being achieved by proper MCSs assignment, which is further increased by applying TPC.
KW  - wireless sensor networks
KW  - multicast traffic
KW  - throughput maximization
KW  - transmission scheduling
KW  - TDMA
KW  - transmission power control
KW  - IoT
KW  - MCS
KW  - mixed-integer programming
DO  - 10.3390/s21103411
ER  -
TY  - EJOU
AU  - Jo, Yongwon
AU  - Lee, Soobin
AU  - Lee, Youngjae
AU  - Kahng, Hyungu
AU  - Park, Seonghun
AU  - Bae, Seounghun
AU  - Kim, Minkwan
AU  - Han, Sungwon
AU  - Kim, Seoungbum
TI  - Semantic Segmentation of Cabbage in the South Korea Highlands with Images by Unmanned Aerial Vehicles
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 10
SN  - 2076-3417

AB  - Identifying agricultural fields that grow cabbage in the highlands of South Korea is critical for accurate crop yield estimation. Only grown for a limited time during the summer, highland cabbage accounts for a significant proportion of South Korea’s annual cabbage production. Thus, it has a profound effect on the formation of cabbage prices. Traditionally, labor-extensive and time-consuming field surveys are manually carried out to derive agricultural field maps of the highlands. Recently, high-resolution overhead images of the highlands have become readily available with the rapid development of unmanned aerial vehicles (UAV) and remote sensing technology. In addition, deep learning-based semantic segmentation models have quickly advanced by recent improvements in algorithms and computational resources. In this study, we propose a semantic segmentation framework based on state-of-the-art deep learning techniques to automate the process of identifying cabbage cultivation fields. We operated UAVs and collected 2010 multispectral images under different spatiotemporal conditions to measure how well semantic segmentation models generalize. Next, we manually labeled these images at a pixel-level to obtain ground truth labels for training. Our results demonstrate that our framework performs well in detecting cabbage fields not only in areas included in the training data but also in unseen areas not included in the training data. Moreover, we analyzed the effects of infrared wavelengths on the performance of identifying cabbage fields. Based on the results of our framework, we expect agricultural officials to reduce time and manpower when identifying information about highlands cabbage fields by replacing field surveys.
KW  - land-cover classification
KW  - semantic segmentation
KW  - unmanned aerial vehicles
DO  - 10.3390/app11104493
ER  -
TY  - EJOU
AU  - Saha, Subrata
AU  - Vasegaard, Alex E.
AU  - Nielsen, Izabela
AU  - Hapka, Aneta
AU  - Budzisz, Henryk
TI  - UAVs Path Planning under a Bi-Objective Optimization Framework for Smart Cities
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 10
SN  - 2079-9292

AB  - Unmanned aerial vehicles (UAVs) have been used extensively for search and rescue operations, surveillance, disaster monitoring, attacking terrorists, etc. due to their growing advantages of low-cost, high maneuverability, and easy deployability. This study proposes a mixed-integer programming model under a multi-objective optimization framework to design trajectories that enable a set of UAVs to execute surveillance tasks. The first objective maximizes the cumulative probability of target detection to aim for mission planning success. The second objective ensures minimization of cumulative path length to provide a higher resource utilization goal. A two-step variable neighborhood search (VNS) algorithm is offered, which addresses the combinatorial optimization issue for determining the near-optimal sequence for cell visiting to reach the target. Numerical experiments and simulation results are evaluated in numerous benchmark instances. Results demonstrate that the proposed approach can favorably support practical deployability purposes.
KW  - unmanned aerial vehicles (UAVs)
KW  - multi-objective optimization
KW  - integer programming
KW  - GLPK
KW  - variable neighborhood search
KW  - search and rescue
DO  - 10.3390/electronics10101193
ER  -
TY  - EJOU
AU  - Chen, Fang
AU  - Wang, Ning
AU  - Yu, Bo
AU  - Qin, Yuchu
AU  - Wang, Lei
TI  - A Strategy of Parallel Seed-Based Image Segmentation Algorithms for Handling Massive Image Tiles over the Spark Platform
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 10
SN  - 2072-4292

AB  - The volume of remote sensing images continues to grow as image sources become more diversified and with increasing spatial and spectral resolution. The handling of such large-volume datasets, which exceed available CPU memory, in a timely and efficient manner is becoming a challenge for single machines. The distributed cluster provides an effective solution with strong calculation power. There has been an increasing number of big data technologies that have been adopted to deal with large images using mature parallel technology. However, since most commercial big data platforms are not specifically developed for the remote sensing field, two main issues exist in processing large images with big data platforms using a distributed cluster. On the one hand, the quantities and categories of official algorithms used to process remote sensing images in big data platforms are limited compared to large amounts of sequential algorithms. On the other hand, the sequential algorithms employed directly to process large images in parallel over a distributed cluster may lead to incomplete objects in the tile edges and the generation of large communication volumes at the shuffle stage. It is, therefore, necessary to explore the distributed strategy and adapt the sequential algorithms over the distributed cluster. In this research, we employed two seed-based image segmentation algorithms to construct a distributed strategy based on the Spark platform. The proposed strategy focuses on modifying the incomplete objects by processing border areas and reducing the communication volume to a reasonable size by limiting the auxiliary bands and the buffer size to a small range during the shuffle stage. We calculated the F-measure and execution time to evaluate the accuracy and execution efficiency. The statistical data reveal that both segmentation algorithms maintained high accuracy, as achieved in the reference image segmented in the sequential way. Moreover, generally the strategy took less execution time compared to significantly larger auxiliary bands and buffer sizes. The proposed strategy can modify incomplete objects, with execution time being twice as fast as the strategies that do not employ communication volume reduction in the distributed cluster.
KW  - segmentation algorithm
KW  - distributed computation
KW  - image processing
KW  - spark platform
KW  - digital disaster reduction
DO  - 10.3390/rs13101969
ER  -
TY  - EJOU
AU  - Wang, Lin
AU  - Zhou, Yuzhen
AU  - Hu, Qiao
AU  - Tang, Zhenghong
AU  - Ge, Yufeng
AU  - Smith, Adam
AU  - Awada, Tala
AU  - Shi, Yeyin
TI  - Early Detection of Encroaching Woody Juniperus virginiana and Its Classification in Multi-Species Forest Using UAS Imagery and Semantic Segmentation Algorithms
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 10
SN  - 2072-4292

AB  - Woody plant encroachment into grasslands ecosystems causes significantly ecological destruction and economic losses. Effective and efficient management largely benefits from accurate and timely detection of encroaching species at an early development stage. Recent advances in unmanned aircraft systems (UAS) enabled easier access to ultra-high spatial resolution images at a centimeter level, together with the latest machine learning based image segmentation algorithms, making it possible to detect small-sized individuals of target species at early development stage and identify them when mixed with other species. However, few studies have investigated the optimal practical spatial resolution of early encroaching species detection. Hence, we investigated the performance of four popular semantic segmentation algorithms (decision tree, DT; random forest, RF; AlexNet; and ResNet) on a multi-species forest classification case with UAS-collected RGB images in original and down-sampled coarser spatial resolutions. The objective of this study was to explore the optimal segmentation algorithm and spatial resolution for eastern redcedar (Juniperus virginiana, ERC) early detection and its classification within a multi-species forest context. To be specific, firstly, we implemented and compared the performance of the four semantic segmentation algorithms with images in the original spatial resolution (0.694 cm). The highest overall accuracy was 0.918 achieved by ResNet with a mean interaction over union at 85.0%. Secondly, we evaluated the performance of ResNet algorithm with images in down-sampled spatial resolutions (1 cm to 5 cm with 0.5 cm interval). When applied on the down-sampled images, ERC segmentation performance decreased with decreasing spatial resolution, especially for those images coarser than 3 cm spatial resolution. The UAS together with the state-of-the-art semantic segmentation algorithms provides a promising tool for early-stage detection and localization of ERC and the development of effective management strategies for mixed-species forest management.
KW  - forest classification
KW  - aggressive native species
KW  - invasive species
KW  - biodiversity
KW  - remote sensing
KW  - UAV
KW  - machine learning
KW  - deep learning
DO  - 10.3390/rs13101975
ER  -
TY  - EJOU
AU  - Hamdi, Slim
AU  - Bouindour, Samir
AU  - Snoussi, Hichem
AU  - Wang, Tian
AU  - Abid, Mohamed
TI  - End-to-End Deep One-Class Learning for Anomaly Detection in UAV Video Stream
T2  - Journal of Imaging

PY  - 2021
VL  - 7
IS  - 5
SN  - 2313-433X

AB  - In recent years, the use of drones for surveillance tasks has been on the rise worldwide. However, in the context of anomaly detection, only normal events are available for the learning process. Therefore, the implementation of a generative learning method in an unsupervised mode to solve this problem becomes fundamental. In this context, we propose a new end-to-end architecture capable of generating optical flow images from original UAV images and extracting compact spatio-temporal characteristics for anomaly detection purposes. It is designed with a custom loss function as a sum of three terms, the reconstruction loss (Rl), the generation loss (Gl) and the compactness loss (Cl) to ensure an efficient classification of the “deep-one” class. In addition, we propose to minimize the effect of UAV motion in video processing by applying background subtraction on optical flow images. We tested our method on very complex datasets called the mini-drone video dataset, and obtained results surpassing existing techniques’ performances with an AUC of 85.3.
KW  - anomaly detection
KW  - UAV videos
KW  - deep one-class
DO  - 10.3390/jimaging7050090
ER  -
TY  - EJOU
AU  - Liu, Chuanyang
AU  - Wu, Yiquan
AU  - Liu, Jingjing
AU  - Sun, Zuo
AU  - Xu, Huajie
TI  - Insulator Faults Detection in Aerial Images from High-Voltage Transmission Lines Based on Deep Learning Model
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 10
SN  - 2076-3417

AB  - Insulator fault detection is one of the essential tasks for high-voltage transmission lines’ intelligent inspection. In this study, a modified model based on You Only Look Once (YOLO) is proposed for detecting insulator faults in aerial images with a complex background. Firstly, aerial images with one fault or multiple faults are collected in diverse scenes, and then a novel dataset is established. Secondly, to increase feature reuse and propagation in the low-resolution feature layers, a Cross Stage Partial Dense YOLO (CSPD-YOLO) model is proposed based on YOLO-v3 and the Cross Stage Partial Network. The feature pyramid network and improved loss function are adopted to the CSPD-YOLO model, improving the accuracy of insulator fault detection. Finally, the proposed CSPD-YOLO model and compared models are trained and tested on the established dataset. The average precision of CSPD-YOLO model is 4.9% and 1.8% higher than that of YOLO-v3 and YOLO-v4, and the running time of CSPD-YOLO (0.011 s) model is slightly longer than that of YOLO-v3 (0.01 s) and YOLO-v4 (0.01 s). Compared with the excellent object detection models YOLO-v3 and YOLO-v4, the experimental results and analysis demonstrate that the proposed CSPD-YOLO model performs better in insulator fault detection from high-voltage transmission lines with a complex background.
KW  - fault detection
KW  - aerial image
KW  - complex background
KW  - deep learning
KW  - image processing
KW  - intelligent inspection
DO  - 10.3390/app11104647
ER  -
TY  - EJOU
AU  - Palma, Adriano
AU  - Chu, Chen-Yeon
AU  - Petracchini, Francesco
AU  - Yeh, Mei-Ling
AU  - Wu, Cheng-Ting
AU  - Lai, Yu-Chen
TI  - A Modeling Application for GHG Fluxes Estimates in Betel Nuts Plantations in Taiwan
T2  - Processes

PY  - 2021
VL  - 9
IS  - 5
SN  - 2227-9717

AB  - Perennial woody crops could have a positive impact on carbon balance, absorbing carbon during growing season and storing it for several years, whereas annual crops do not have this particular effect. Usually, techniques for GHG (greenhouse gases) flux measurements have limited spatial representativeness, with some difficulties to extend leaf measurements to field scale. Models, especially if supported by remote sensing data, allow for upscaling the monitoring of these fluxes. The aim of this work was to evaluate the carbon fluxes (gross primary production, GPP; net ecosystem production, NEP) of the betel nut cultivars in Taiwan by a vegetation photosynthesis model (VPM). The model permitted estimating seasonal dynamics of GPP in a moist tropical evergreen forest. These plantations are very common in Taiwan and their role could be significant in environmental and development policies even though, until now, the consumption of the fruit of this tree is at the center of controversy due to their use and effects on the population. To obtain estimates of carbon fluxes on a large area that would appreciate its spatial variability, a model based on physiological processes was used. This model incorporated a series of procedures and monthly mean meteorological data, light use efficiency, and satellite enhanced vegetation index (EVI) were used as inputs. An additional purpose of this work was to compare the carbon uptake of different cultivars in Taiwan and Italy. Using a different model, always based on light use efficiency, a similar project was carried on Italian vineyards, with other climate conditions and different agricultural practices.
KW  - GHG flux measurements
KW  - betel nuts
KW  - enhanced vegetation index
KW  - carbon cycle
DO  - 10.3390/pr9050895
ER  -
TY  - EJOU
AU  - Tullu, Abera
AU  - Endale, Bedada
AU  - Wondosen, Assefinew
AU  - Hwang, Ho-Yon
TI  - Machine Learning Approach to Real-Time 3D Path Planning for Autonomous Navigation of Unmanned Aerial Vehicle
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 10
SN  - 2076-3417

AB  - The need for civilian use of Unmanned Aerial Vehicles (UAVs) has drastically increased in recent years. Their potential applications for civilian use include door-to-door package delivery, law enforcement, first aid, and emergency services in urban areas, which put the UAVs into obstacle collision risk. Therefore, UAVs are required to be equipped with sensors so as to acquire Artificial Intelligence (AI) to avoid potential risks during mission execution. The AI comes with intensive training of an on-board machine that is responsible to autonomously navigate the UAV. The training enables the UAV to develop humanoid perception of the environment it is to be navigating in. During the mission, this perception detects and localizes objects in the environment. It is based on this AI that this work proposes a real-time three-dimensional (3D) path planner that maneuvers the UAV towards destination through obstacle-free path. The proposed path planner has a heuristic sense of A⋆ algorithm, but requires no frontier nodes to be stored in a memory unlike A⋆. The planner relies on relative locations of detected objects (obstacles) and determines collision-free paths. This path planner is light-weight and hence a fast guidance method for real-time purposes. Its performance efficiency is proved through rigorous Software-In-The-Loop (SITL) simulations in constrained-environment and preliminary real flight tests.
KW  - vision-based navigation
KW  - cluttered environment
KW  - three-dimensional path planner
KW  - obstacle avoidance
KW  - machine learning
DO  - 10.3390/app11104706
ER  -
TY  - EJOU
AU  - Mores, Antonia
AU  - Borrelli, Grazia M.
AU  - Laidò, Giovanni
AU  - Petruzzino, Giuseppe
AU  - Pecchioni, Nicola
AU  - Amoroso, Luca G.
AU  - Desiderio, Francesca
AU  - Mazzucotelli, Elisabetta
AU  - Mastrangelo, Anna M.
AU  - Marone, Daniela
TI  - Genomic Approaches to Identify Molecular Bases of Crop Resistance to Diseases and to Develop Future Breeding Strategies
T2  - International Journal of Molecular Sciences

PY  - 2021
VL  - 22
IS  - 11
SN  - 1422-0067

AB  - Plant diseases are responsible for substantial crop losses each year and affect food security and agricultural sustainability. The improvement of crop resistance to pathogens through breeding represents an environmentally sound method for managing disease and minimizing these losses. The challenge is to breed varieties with a stable and broad-spectrum resistance. Different approaches, from markers to recent genomic and ‘post-genomic era’ technologies, will be reviewed in order to contribute to a better understanding of the complexity of host–pathogen interactions and genes, including those with small phenotypic effects and mechanisms that underlie resistance. An efficient combination of these approaches is herein proposed as the basis to develop a successful breeding strategy to obtain resistant crop varieties that yield higher in increasing disease scenarios.
KW  - crop
KW  - disease resistance
KW  - genes
KW  - marker-assisted selection
KW  - meta-analysis
KW  - genomic selection
KW  - effectoromics
KW  - new breeding technologies
DO  - 10.3390/ijms22115423
ER  -
TY  - EJOU
AU  - Behera, Mukunda D.
AU  - Barnwal, Surbhi
AU  - Paramanik, Somnath
AU  - Das, Pulakesh
AU  - Bhattyacharya, Bimal K.
AU  - Jagadish, Buddolla
AU  - Roy, Parth S.
AU  - Ghosh, Sujit M.
AU  - Behera, Soumit K.
TI  - Species-Level Classification and Mapping of a Mangrove Forest Using Random Forest—Utilisation of AVIRIS-NG and Sentinel Data
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 11
SN  - 2072-4292

AB  - Although studies on species-level classification and mapping using multisource data and machine learning approaches are plenty, the use of data with ideal placement of central wavelength and bandwidth at appropriate spatial resolution, for the classification of mangrove species is underreported. The species composition of a mangrove forest has been estimated utilising the red-edge spectral bands and chlorophyll absorption information from AVIRIS-NG and Sentinel-2 data. In this study, three dominant species, Heritiera fomes, Excoecaria agallocha and Avicennia officinalis, have been classified using the random forest (RF) model for a mangrove forest in Bhitarkanika Wildlife Sanctuary, India. Various combinations of reflectance/backscatter bands and vegetation indices derived from Sentinel-2, AVIRIS-NG, and Sentinel-1 were used for species-level discrimination and mapping. The RF model showed maximum accuracy using Sentinel-2, followed by the AVIRIS-NG, in discriminating three dominant species and two mixed compositions. This study indicates the potential of Sentinel-2 data for discriminating various mangrove species owing to the appropriate placement of central wavelength and bandwidth in Sentinel-2 at ≥10 m spatial resolution. The variable importance plots proved that species-level classification could be attempted using red edge and chlorophyll absorption information. This study has wider applicability in other mangrove forests around the world.
KW  - AVIRIS-NG
KW  - red edge
KW  - Bhitarkanika Wildlife Sanctuary
KW  - random forest
KW  - species-level classification
DO  - 10.3390/rs13112027
ER  -
TY  - EJOU
AU  - Wu, Zhangnan
AU  - Chen, Yajun
AU  - Zhao, Bo
AU  - Kang, Xiaobing
AU  - Ding, Yuanyuan
TI  - Review of Weed Detection Methods Based on Computer Vision
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 11
SN  - 1424-8220

AB  - Weeds are one of the most important factors affecting agricultural production. The waste and pollution of farmland ecological environment caused by full-coverage chemical herbicide spraying are becoming increasingly evident. With the continuous improvement in the agricultural production level, accurately distinguishing crops from weeds and achieving precise spraying only for weeds are important. However, precise spraying depends on accurately identifying and locating weeds and crops. In recent years, some scholars have used various computer vision methods to achieve this purpose. This review elaborates the two aspects of using traditional image-processing methods and deep learning-based methods to solve weed detection problems. It provides an overview of various methods for weed detection in recent years, analyzes the advantages and disadvantages of existing methods, and introduces several related plant leaves, weed datasets, and weeding machinery. Lastly, the problems and difficulties of the existing weed detection methods are analyzed, and the development trend of future research is prospected.
KW  - weed detection
KW  - computer vision
KW  - image processing
KW  - deep learning
KW  - machine learning
DO  - 10.3390/s21113647
ER  -
TY  - EJOU
AU  - Almalki, Faris A.
AU  - Soufiene, Ben O.
AU  - Alsamhi, Saeed H.
AU  - Sakli, Hedi
TI  - A Low-Cost Platform for Environmental Smart Farming Monitoring System Based on IoT and UAVs
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 11
SN  - 2071-1050

AB  - When integrating the Internet of Things (IoT) with Unmanned Aerial Vehicles (UAVs) occurred, tens of applications including smart agriculture have emerged to offer innovative solutions to modernize the farming sector. This paper aims to present a low-cost platform for comprehensive environmental parameter monitoring using flying IoT. This platform is deployed and tested in a real scenario on a farm in Medenine, Tunisia, in the period of March 2020 to March 2021. The experimental work fulfills the requirements of automated and real-time monitoring of the environmental parameters using both under- and aboveground sensors. These IoT sensors are on a farm collecting vast amounts of environmental data, where it is sent to ground gateways every 1 h, after which the obtained data is collected and transmitted by a drone to the cloud for storage and analysis every 12 h. This low-cost platform can help farmers, governmental, or manufacturers to predict environmental data over the geographically large farm field, which leads to enhancement in crop productivity and farm management in a cost-effective, and timely manner. Obtained experimental results infer that automated and human-made sets of actions can be applied and/or suggested, due to the innovative integration between IoT sensors with the drone. These smart actions help in precision agriculture, which, in turn, intensely boost crop productivity, saving natural resources.
KW  - Internet of Things
KW  - Unmanned Aerial Vehicles
KW  - smart farming
KW  - environmental parameters
KW  - LoRa
DO  - 10.3390/su13115908
ER  -
TY  - EJOU
AU  - Teodoro, Ana
AU  - Santos, Patrícia
AU  - Espinha Marques, Jorge
AU  - Ribeiro, Joana
AU  - Mansilha, Catarina
AU  - Melo, Armindo
AU  - Duarte, Lia
AU  - Rodrigues de Almeida, Cátia
AU  - Flores, Deolinda
TI  - An Integrated Multi-Approach to Environmental Monitoring of a Self-Burning Coal Waste Pile: The São Pedro da Cova Mine (Porto, Portugal) Study Case
T2  - Environments

PY  - 2021
VL  - 8
IS  - 6
SN  - 2076-3298

AB  - The São Pedro da Cova waste pile (Porto, Portugal) is composed of coal mining residues that have been self-burning since 2005 and is located close to an inhabited area and social infrastructures, further adding to effects on the environment and human health. Therefore, there is a great interest in the environmental monitoring of this waste pile. This work describes an integrative multi-approach that allows the environmental monitoring of several parameters of the waste pile, applying several technologies. The temperature measurements were obtained by a thermal infrared (TIR) sensor on board an unmanned aerial vehicle (UAV) and supplemented with field measurements. In order to evaluate the altimetric variations, for each flight, a digital elevation model (DEM) was generated considering a multispectral sensor also on board the UAV. The hydrogeochemical characterization was performed through the analysis of groundwater and surface water samples, with and without the influence of mine drainage. The soil monitoring included the analysis of waste material as well as the surface soil in the surrounding area of the waste pile. All the data were analyzed and integrated in a geographical information system (GIS) open-source application. The adopted multi-approach methodology, given its intrinsic interdisciplinary character, has proven to be an effective way of encompassing the complexity of this type of environmental problem.
KW  - temperature
KW  - soils
KW  - water quality
KW  - geographical information system
KW  - unmanned aerial vehicles
KW  - land use land cover
DO  - 10.3390/environments8060048
ER  -
TY  - EJOU
AU  - Fetai, Bujar
AU  - Račič, Matej
AU  - Lisec, Anka
TI  - Deep Learning for Detection of Visible Land Boundaries from UAV Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 11
SN  - 2072-4292

AB  - Current efforts aim to accelerate cadastral mapping through innovative and automated approaches and can be used to both create and update cadastral maps. This research aims to automate the detection of visible land boundaries from unmanned aerial vehicle (UAV) imagery using deep learning. In addition, we wanted to evaluate the advantages and disadvantages of programming-based deep learning compared to commercial software-based deep learning. For the first case, we used the convolutional neural network U-Net, implemented in Keras, written in Python using the TensorFlow library. For commercial software-based deep learning, we used ENVINet5. UAV imageries from different areas were used to train the U-Net model, which was performed in Google Collaboratory and tested in the study area in Odranci, Slovenia. The results were compared with the results of ENVINet5 using the same datasets. The results showed that both models achieved an overall accuracy of over 95%. The high accuracy is due to the problem of unbalanced classes, which is usually present in boundary detection tasks. U-Net provided a recall of 0.35 and a precision of 0.68 when the threshold was set to 0.5. A threshold can be viewed as a tool for filtering predicted boundary maps and balancing recall and precision. For equitable comparison with ENVINet5, the threshold was increased. U-Net provided more balanced results, a recall of 0.65 and a precision of 0.41, compared to ENVINet5 recall of 0.84 and a precision of 0.35. Programming-based deep learning provides a more flexible yet complex approach to boundary mapping than software-based, which is rigid and does not require programming. The predicted visible land boundaries can be used both to speed up the creation of cadastral maps and to automate the revision of existing cadastral maps and define areas where updates are needed. The predicted boundaries cannot be considered final at this stage but can be used as preliminary cadastral boundaries.
KW  - land
KW  - cadastral mapping
KW  - visible boundary
KW  - UAV
KW  - deep learning
DO  - 10.3390/rs13112077
ER  -
TY  - EJOU
AU  - Dronova, Iryna
AU  - Kislik, Chippie
AU  - Dinh, Zack
AU  - Kelly, Maggi
TI  - A Review of Unoccupied Aerial Vehicle Use in Wetland Applications: Emerging Opportunities in Approach, Technology, and Data
T2  - Drones

PY  - 2021
VL  - 5
IS  - 2
SN  - 2504-446X

AB  - Recent developments in technology and data processing for Unoccupied Aerial Vehicles (UAVs) have revolutionized the scope of ecosystem monitoring, providing novel pathways to fill the critical gap between limited-scope field surveys and limited-customization satellite and piloted aerial platforms. These advances are especially ground-breaking for supporting management, restoration, and conservation of landscapes with limited field access and vulnerable ecological systems, particularly wetlands. This study presents a scoping review of the current status and emerging opportunities in wetland UAV applications, with particular emphasis on ecosystem management goals and remaining research, technology, and data needs to even better support these goals in the future. Using 122 case studies from 29 countries, we discuss which wetland monitoring and management objectives are most served by this rapidly developing technology, and what workflows were employed to analyze these data. This review showcases many ways in which UAVs may help reduce or replace logistically demanding field surveys and can help improve the efficiency of UAV-based workflows to support longer-term monitoring in the face of wetland environmental challenges and management constraints. We also highlight several emerging trends in applications, technology, and data and offer insights into future needs.
KW  - wetland
KW  - unoccupied aerial vehicle
KW  - UAV
KW  - UAS
KW  - drone
KW  - management
KW  - conservation
KW  - restoration
KW  - monitoring
KW  - high spatial resolution
DO  - 10.3390/drones5020045
ER  -
TY  - EJOU
AU  - Ahmed, Shibbir
AU  - Qiu, Baijing
AU  - Ahmad, Fiaz
AU  - Kong, Chun-Wei
AU  - Xin, Huang
TI  - A State-of-the-Art Analysis of Obstacle Avoidance Methods from the Perspective of an Agricultural Sprayer UAV’s Operation Scenario
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 6
SN  - 2073-4395

AB  - Over the last decade, Unmanned Aerial Vehicles (UAVs), also known as drones, have been broadly utilized in various agricultural fields, such as crop management, crop monitoring, seed sowing, and pesticide spraying. Nonetheless, autonomy is still a crucial limitation faced by the Internet of Things (IoT) UAV systems, especially when used as sprayer UAVs, where data needs to be captured and preprocessed for robust real-time obstacle detection and collision avoidance. Moreover, because of the objective and operational difference between general UAVs and sprayer UAVs, not every obstacle detection and collision avoidance method will be sufficient for sprayer UAVs. In this regard, this article seeks to review the most relevant developments on all correlated branches of the obstacle avoidance scenarios for agricultural sprayer UAVs, including a UAV sprayer’s structural details. Furthermore, the most relevant open challenges for current UAV sprayer solutions are enumerated, thus paving the way for future researchers to define a roadmap for devising new-generation, affordable autonomous sprayer UAV solutions. Agricultural UAV sprayers require data-intensive algorithms for the processing of the images acquired, and expertise in the field of autonomous flight is usually needed. The present study concludes that UAV sprayers are still facing obstacle detection challenges due to their dynamic operating and loading conditions.
KW  - agricultural sprayer UAVs
KW  - Internet of Things
KW  - obstacles on farmland
KW  - operation pattern
KW  - obstacle detection
KW  - collision avoidance
KW  - path planning
KW  - spray coverage
DO  - 10.3390/agronomy11061069
ER  -
TY  - EJOU
AU  - De Marchi, Mirco
AU  - Lumpp, Francesco
AU  - Martini, Enrico
AU  - Boldo, Michele
AU  - Aldegheri, Stefano
AU  - Bombieri, Nicola
TI  - Efficient ROS-Compliant CPU-iGPU Communication on Embedded Platforms
T2  - Journal of Low Power Electronics and Applications

PY  - 2021
VL  - 11
IS  - 2
SN  - 2079-9268

AB  - Many modern programmable embedded devices contain CPUs and a GPU that share the same system memory on a single die. Such a unified memory architecture (UMA) allows programmers to implement different communication models between CPU and the integrated GPU (iGPU). Although the simpler model guarantees implicit synchronization at the cost of performance, the more advanced model allows, through the zero-copy paradigm, the explicit data copying between CPU and iGPU to be eliminated with the benefit of significantly improving performance and energy savings. On the other hand, the robot operating system (ROS) has become a de-facto reference standard for developing robotic applications. It allows for application re-use and the easy integration of software blocks in complex cyber-physical systems. Although ROS compliance is strongly required for SW portability and reuse, it can lead to performance loss and elude the benefits of the zero-copy communication. In this article we present efficient techniques to implement CPU–iGPU communication by guaranteeing compliance to the ROS standard. We show how key features of each communication model are maintained and the corresponding overhead involved by the ROS compliancy.
KW  - CPU–iGPU communication
KW  - ROS
KW  - cyber-physical systems
KW  - CUDA
DO  - 10.3390/jlpea11020024
ER  -
TY  - EJOU
AU  - Quemada, Carlos
AU  - Pérez-Escudero, José M.
AU  - Gonzalo, Ramón
AU  - Ederra, Iñigo
AU  - Santesteban, Luis G.
AU  - Torres, Nazareth
AU  - Iriarte, Juan C.
TI  - Remote Sensing for Plant Water Content Monitoring: A Review
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 11
SN  - 2072-4292

AB  - This paper reviews the different remote sensing techniques found in the literature to monitor plant water status, allowing farmers to control the irrigation management and to avoid unnecessary periods of water shortage and a needless waste of valuable water. The scope of this paper covers a broad range of 77 references published between the years 1981 and 2021 and collected from different search web sites, especially Scopus. Among them, 74 references are research papers and the remaining three are review papers. The different collected approaches have been categorized according to the part of the plant subjected to measurement, that is, soil (12.2%), canopy (33.8%), leaves (35.1%) or trunk (18.9%). In addition to a brief summary of each study, the main monitoring technologies have been analyzed in this review. Concerning the presentation of the data, different results have been obtained. According to the year of publication, the number of published papers has increased exponentially over time, mainly due to the technological development over the last decades. The most common sensor is the radiometer, which is employed in 15 papers (20.3%), followed by continuous-wave (CW) spectroscopy (12.2%), camera (10.8%) and THz time-domain spectroscopy (TDS) (10.8%). Excluding two studies, the minimum coefficient of determination (R2) obtained in the references of this review is 0.64. This indicates the high degree of correlation between the estimated and measured data for the different technologies and monitoring methods. The five most frequent water indicators of this study are: normalized difference vegetation index (NDVI) (12.2%), backscattering coefficients (10.8%), spectral reflectance (8.1%), reflection coefficient (8.1%) and dielectric constant (8.1%).
KW  - backscattering coefficients
KW  - canopy water content
KW  - continuous-wave spectroscopy
KW  - leaf water content
KW  - NDVI
KW  - plant water content
KW  - radiometer
KW  - remote sensing
KW  - soil water content
KW  - xylem water content
DO  - 10.3390/rs13112088
ER  -
TY  - EJOU
AU  - Fu, Chen-Hua
AU  - Tsao, Ming-Wen
AU  - Chi, Li-Pin
AU  - Zhuang, Zheng-Yun
TI  - On the Dominant Factors of Civilian-Use Drones: A Thorough Study and Analysis of Cross-Group Opinions Using a Triple Helix Model (THM) with the Analytic Hierarchy Process (AHP)
T2  - Drones

PY  - 2021
VL  - 5
IS  - 2
SN  - 2504-446X

AB  - This study explores the experts’ opinions during the consultation stage before law-making for civilian drones. A thorough literature study is first undertaken to have the set of influencing factors that should be suitable for the investigation from the perspective of designing and selecting civilian drones. Several rounds of surveys using the Delphi method, followed by an analytic hierarchy process (AHP), are performed to conform to the organized tree structure of constructs and factors and to obtain the knowledge about the opinions of the expert groups, with the expert sample being intentionally partitioned into three opinion groups at the beginning: academia (A), industry (I), and research institutes (R). Doing so facilitates a “mind-mining” process using the triple helix model (THM), while the opinions across the groups can also be visualized and compared. This exploits a new set of knowledge for the design and selection of civilian drones on a scientific yet empirical basis, and the observed differences and similarities among the groups may benefit their future negotiations to propose the drafts for regulating the design, manufacturing, and uses of civilian drones. As several significant implications and insights are also drawn and gained from the abovementioned results eventually, some possible research directions are worthwhile. The proposed hybrid methodological flow is another novelty.
KW  - drones
KW  - civilian use
KW  - factors
KW  - design and selection
KW  - law-making
KW  - mind-mining
KW  - expert groups
KW  - literature study
KW  - triple helix model (THM)
KW  - analytic hierarchy process (AHP)
DO  - 10.3390/drones5020046
ER  -
TY  - EJOU
AU  - Reis, João
AU  - Cohen, Yuval
AU  - Melão, Nuno
AU  - Costa, Joana
AU  - Jorge, Diana
TI  - High-Tech Defense Industries: Developing Autonomous Intelligent Systems
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 11
SN  - 2076-3417

AB  - After the Cold War, the defense industries found themselves at a crossroads. However, it seems that they are gaining new momentum, as new technologies such as robotics and artificial intelligence are enabling the development of autonomous, highly innovative and disruptive intelligent systems. Despite this new impetus, there are still doubts about where to invest limited financial resources to boost high-tech defense industries. In order to shed some light on the topic, we decided to conduct a systematic literature review by using the PRISMA protocol and content analysis. The results indicate that autonomous intelligent systems are being developed by the defense industry and categorized into three different modes—fully autonomous operations, partially autonomous operations, and smart autonomous decision-making. In addition, it is also important to note that, at a strategic level of war, there is limited room for automation given the need for human intervention. However, at the tactical level of war, there is a high probability of growth in industrial defense, since, at this level, structured decisions and complex analytical-cognitive tasks are carried out. In the light of carrying out those decisions and tasks, robotics and artificial intelligence can make a contribution far superior to that of human beings.
KW  - artificial intelligence
KW  - defense industry
KW  - high technology
KW  - intelligent systems
KW  - level of war
KW  - robotics
DO  - 10.3390/app11114920
ER  -
TY  - EJOU
AU  - Greifeneder, Felix
AU  - Notarnicola, Claudia
AU  - Wagner, Wolfgang
TI  - A Machine Learning-Based Approach for Surface Soil Moisture Estimations with Google Earth Engine
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 11
SN  - 2072-4292

AB  - Due to its relation to the Earth’s climate and weather and phenomena like drought, flooding, or landslides, knowledge of the soil moisture content is valuable to many scientific and professional users. Remote-sensing offers the unique possibility for continuous measurements of this variable. Especially for agriculture, there is a strong demand for high spatial resolution mapping. However, operationally available soil moisture products exist with medium to coarse spatial resolution only (≥1 km). This study introduces a machine learning (ML)—based approach for the high spatial resolution (50 m) mapping of soil moisture based on the integration of Landsat-8 optical and thermal images, Copernicus Sentinel-1 C-Band SAR images, and modelled data, executable in the Google Earth Engine. The novelty of this approach lies in applying an entirely data-driven ML concept for global estimation of the surface soil moisture content. Globally distributed in situ data from the International Soil Moisture Network acted as an input for model training. Based on the independent validation dataset, the resulting overall estimation accuracy, in terms of Root-Mean-Squared-Error and R², was 0.04 m3·m−3 and 0.81, respectively. Beyond the retrieval model itself, this article introduces a framework for collecting training data and a stand-alone Python package for soil moisture mapping. The Google Earth Engine Python API facilitates the execution of data collection and retrieval which is entirely cloud-based. For soil moisture retrieval, it eliminates the requirement to download or preprocess any input datasets.
KW  - soil moisture
KW  - Sentinel-1 SAR
KW  - Landsat-8 optical/thermal data
KW  - machine learning
KW  - cloud-based approach
KW  - Google Earth Engine
DO  - 10.3390/rs13112099
ER  -
TY  - EJOU
AU  - Shi, Yan
AU  - Gao, Jay
AU  - Li, Xilai
AU  - Li, Jiexia
AU  - dela Torre, Daniel Marc G.
AU  - Brierley, Gary J.
TI  - Improved Estimation of Aboveground Biomass of Disturbed Grassland through Including Bare Ground and Grazing Intensity
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 11
SN  - 2072-4292

AB  - Accurate approaches to aboveground biomass (AGB) estimation are required to support appraisal of the effectiveness of land use measures, which seek to protect grazing-adapted grasslands atop the Qinghai-Tibet Plateau (QTP). This methodological study assesses the effectiveness of one commonly used visible band vegetation index, Red Green Blue Vegetation Index (RGBVI), obtained from unmanned aerial vehicle (UAV), in estimating AGB timely and accurately at the local scale, seeking to improve the estimation accuracy by taking into account in situ collected information on disturbed grassland. Particular emphasis is placed upon the mapping and quantification of areas disturbed by grazing (simulated via mowing) and plateau pika (Ochotona curzoniae) that have led to the emergence of bare ground. The initial model involving only RGBVI performed poorly in AGB estimation by underestimating high AGB by around 10% and overestimating low AGB by about 10%. The estimation model was modified by the mowing intensity ratio and bare ground metrics. The former almost doubled the estimation accuracy from R2 = 0.44 to 0.81. However, this modification caused the bare ground AGB to be overestimated by about 38 and 19 g m−2 for 2018 and 2019, respectively. Although further modification of the model by bare ground metrics improved the accuracy slightly to 0.88, it markedly reduced the overestimation of low AGB values. It is recommended that grazing intensity be incorporated into the micro-scale estimation of AGB, together with the bare ground modification metrics, especially for severely disturbed meadows with a sizable portion of bare ground.
KW  - UAV images
KW  - AGB estimation accuracy
KW  - visible band VI
KW  - meadow disturbances
KW  - mowing intensity
KW  - Qinghai-Tibet Plateau
DO  - 10.3390/rs13112105
ER  -
TY  - EJOU
AU  - Choudhury, MD A.
AU  - Marcheggiani, Ernesto
AU  - Galli, Andrea
AU  - Modica, Giuseppe
AU  - Somers, Ben
TI  - Mapping the Urban Atmospheric Carbon Stock by LiDAR and WorldView-3 Data
T2  - Forests

PY  - 2021
VL  - 12
IS  - 6
SN  - 1999-4907

AB  - Currently, the worsening impacts of urbanizations have been impelled to the importance of monitoring and management of existing urban trees, securing sustainable use of the available green spaces. Urban tree species identification and evaluation of their roles in atmospheric Carbon Stock (CS) are still among the prime concerns for city planners regarding initiating a convenient and easily adaptive urban green planning and management system. A detailed methodology on the urban tree carbon stock calibration and mapping was conducted in the urban area of Brussels, Belgium. A comparative analysis of the mapping outcomes was assessed to define the convenience and efficiency of two different remote sensing data sources, Light Detection and Ranging (LiDAR) and WorldView-3 (WV-3), in a unique urban area. The mapping results were validated against field estimated carbon stocks. At the initial stage, dominant tree species were identified and classified using the high-resolution WorldView3 image, leading to the final carbon stock mapping based on the dominant species. An object-based image analysis approach was employed to attain an overall accuracy (OA) of 71% during the classification of the dominant species. The field estimations of carbon stock for each plot were done utilizing an allometric model based on the field tree dendrometric data. Later based on the correlation among the field data and the variables (i.e., Normalized Difference Vegetation Index, NDVI and Crown Height Model, CHM) extracted from the available remote sensing data, the carbon stock mapping and validation had been done in a GIS environment. The calibrated NDVI and CHM had been used to compute possible carbon stock in either case of the WV-3 image and LiDAR data, respectively. A comparative discussion has been introduced to bring out the issues, especially for the developing countries, where WV-3 data could be a better solution over the hardly available LiDAR data. This study could assist city planners in understanding and deciding the applicability of remote sensing data sources based on their availability and the level of expediency, ensuring a sustainable urban green management system.
KW  - urban trees
KW  - Geospatial Object-Based Image Analysis (GEOBIA)
KW  - Carbon Stock (CS) mapping
KW  - allometric model
KW  - WorldView-3 (WV-3) imagery
KW  - aerial Light Detection and Ranging (LiDAR) data
DO  - 10.3390/f12060692
ER  -
TY  - EJOU
AU  - Golub Medvešek, Ivana
AU  - Vujović, Igor
AU  - Šoda, Joško
AU  - Krčum, Maja
TI  - A Novel Method on Hydrographic Survey Technology Selection Based on the Decision Tree Supervised Learning
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 11
SN  - 2076-3417

AB  - Hydrographic survey or seabed mapping plays an important role in achieving better maritime safety, especially in coastal waters. Due to advances in survey technologies, it becomes important to choose well-suited technology for a specific area. Moreover, various technologies have various ranges of equipment and manufacturers, as well as characteristics. Therefore, in this paper, a novel method of a hydrographic survey, i.e., identifying the appropriate technology, has been developed. The method is based on a reduced elimination matrix, decision tree supervised learning, and multicriteria decision methods. The available technologies were: remotely operated underwater vehicle (ROV), unmanned aerial vehicle (UAV), light detection and ranging (LIDAR), autonomous underwater vehicle (AUV), satellite-derived bathymetry (SDB), and multibeam echosounder (MBES), and they are applied as a case study of Kaštela Bay. Results show, considering the specifics of the survey area, that UAV is the best-suited technology to be used for a hydrographic survey. However, some other technologies, such as SDB come close and can be considered an alternative for hydrographic surveys.
KW  - supervised learning
KW  - decision tree
KW  - hydrographic survey
KW  - weighted sum model
DO  - 10.3390/app11114966
ER  -
TY  - EJOU
AU  - Aeberli, Aaron
AU  - Johansen, Kasper
AU  - Robson, Andrew
AU  - Lamb, David W.
AU  - Phinn, Stuart
TI  - Detection of Banana Plants Using Multi-Temporal Multispectral UAV Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 11
SN  - 2072-4292

AB  - Unoccupied aerial vehicles (UAVs) have become increasingly commonplace in aiding planning and management decisions in agricultural and horticultural crop production. The ability of UAV-based sensing technologies to provide high spatial (&lt;1 m) and temporal (on-demand) resolution data facilitates monitoring of individual plants over time and can provide essential information about health, yield, and growth in a timely and quantifiable manner. Such applications would be beneficial for cropped banana plants due to their distinctive growth characteristics. Limited studies have employed UAV data for mapping banana crops and to our knowledge only one other investigation features multi-temporal detection of banana crowns. The purpose of this study was to determine the suitability of multiple-date UAV-captured multi-spectral data for the automated detection of individual plants using convolutional neural network (CNN), template matching (TM), and local maximum filter (LMF) methods in a geographic object-based image analysis (GEOBIA) software framework coupled with basic classification refinement. The results indicate that CNN returns the highest plant detection accuracies, with the developed rule set and model providing greater transferability between dates (F-score ranging between 0.93 and 0.85) than TM (0.86–0.74) and LMF (0.86–0.73) approaches. The findings provide a foundation for UAV-based individual banana plant counting and crop monitoring, which may be used for precision agricultural applications to monitor health, estimate yield, and to inform on fertilizer, pesticide, and other input requirements for optimized farm management.
KW  - unoccupied aerial vehicle
KW  - UAV
KW  - banana plant
KW  - geographic object-based image analysis
KW  - convolutional neural network
KW  - CNN
KW  - template matching
KW  - local maximum filter
DO  - 10.3390/rs13112123
ER  -
TY  - EJOU
AU  - de Castro, Ana I.
AU  - Shi, Yeyin
AU  - Maja, Joe M.
AU  - Peña, Jose M.
TI  - UAVs for Vegetation Monitoring: Overview and Recent Scientific Contributions
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 11
SN  - 2072-4292

AB  - This paper reviewed a set of twenty-one original and innovative papers included in a special issue on UAVs for vegetation monitoring, which proposed new methods and techniques applied to diverse agricultural and forestry scenarios. Three general categories were considered: (1) sensors and vegetation indices used, (2) technological goals pursued, and (3) agroforestry applications. Some investigations focused on issues related to UAV flight operations, spatial resolution requirements, and computation and data analytics, while others studied the ability of UAVs for characterizing relevant vegetation features (mainly canopy cover and crop height) or for detecting different plant/crop stressors, such as nutrient content/deficiencies, water needs, weeds, and diseases. The general goal was proposing UAV-based technological solutions for a better use of agricultural and forestry resources and more efficient production with relevant economic and environmental benefits.
KW  - drone
KW  - RGB
KW  - multispectral
KW  - hyperspectral
KW  - thermal
KW  - machine learning
KW  - water stress
KW  - nutrient deficiency
KW  - weed detection
KW  - disease diagnosis
KW  - plant trails
DO  - 10.3390/rs13112139
ER  -
TY  - EJOU
AU  - Adak, Alper
AU  - Murray, Seth C.
AU  - Božinović, Sofija
AU  - Lindsey, Regan
AU  - Nakasagga, Shakirah
AU  - Chatterjee, Sumantra
AU  - Anderson, Steven L.
AU  - Wilde, Scott
TI  - Temporal Vegetation Indices and Plant Height from Remotely Sensed Imagery Can Predict Grain Yield and Flowering Time Breeding Value in Maize via Machine Learning Regression
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 11
SN  - 2072-4292

AB  - Unoccupied aerial system (UAS; i.e., drone equipped with sensors) field-based high-throughput phenotyping (HTP) platforms are used to collect high quality images of plant nurseries to screen genetic materials (e.g., hybrids and inbreds) throughout plant growth at relatively low cost. In this study, a set of 100 advanced breeding maize (Zea mays L.) hybrids were planted at optimal (OHOT trial) and delayed planting dates (DHOT trial). Twelve UAS surveys were conducted over the trials throughout the growing season. Fifteen vegetative indices (VIs) and the 99th percentile canopy height measurement (CHMs) were extracted from processed UAS imagery (orthomosaics and point clouds) which were used to predict plot-level grain yield, days to anthesis (DTA), and silking (DTS). A novel statistical approach utilizing a nested design was fit to predict temporal best linear unbiased predictors (TBLUP) for the combined temporal UAS data. Our results demonstrated machine learning-based regressions (ridge, lasso, and elastic net) had from 4- to 9-fold increases in the prediction accuracies and from 13- to 73-fold reductions in root mean squared error (RMSE) compared to classical linear regression in prediction of grain yield or flowering time. Ridge regression performed best in predicting grain yield (prediction accuracy = ~0.6), while lasso and elastic net regressions performed best in predicting DTA and DTS (prediction accuracy = ~0.8) consistently in both trials. We demonstrated that predictor variable importance descended towards the terminal stages of growth, signifying the importance of phenotype collection beyond classical terminal growth stages. This study is among the first to demonstrate an ability to predict yield in elite hybrid maize breeding trials using temporal UAS image-based phenotypes and supports the potential benefit of phenomic selection approaches in estimating breeding values before harvest.
KW  - high throughput phenotyping
KW  - unoccupied aerial system
KW  - temporal vegetation indices
KW  - nested design
KW  - machine learning regression
KW  - phenomic prediction and selection
DO  - 10.3390/rs13112141
ER  -
TY  - EJOU
AU  - Zhang, Peng
AU  - Hu, Shougeng
AU  - Li, Weidong
AU  - Zhang, Chuanrong
AU  - Cheng, Peikun
TI  - Improving Parcel-Level Mapping of Smallholder Crops from VHSR Imagery: An Ensemble Machine-Learning-Based Framework
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 11
SN  - 2072-4292

AB  - Explicit spatial information about crop types on smallholder farms is important for the development of local precision agriculture. However, due to highly fragmented and heterogeneous cropland landscapes, fine-scale mapping of smallholder crops, based on low- and medium-resolution satellite images and relying on a single machine learning (ML) classifier, generally fails to achieve satisfactory performance. This paper develops an ensemble ML-based framework to improve the accuracy of parcel-level smallholder crop mapping from very high spatial resolution (VHSR) images. A typical smallholder agricultural area in central China covered by WorldView-2 images is selected to demonstrate our approach. This approach involves the task of distinguishing eight crop-level agricultural land use types. To this end, six widely used individual ML classifiers are evaluated. We further improved their performance by independently implementing bagging and stacking ensemble learning (EL) techniques. The results show that the bagging models improved the performance of unstable classifiers, but these improvements are limited. In contrast, the stacking models perform better, and the Stacking #2 model (overall accuracy = 83.91%, kappa = 0.812), which integrates the three best-performing individual classifiers, performs the best of all of the built models and improves the classwise accuracy of almost all of the land use types. Since classification performance can be significantly improved without adding costly data collection, stacking-ensemble mapping approaches are valuable for the spatial management of complex agricultural areas. We also demonstrate that using geometric and textural features extracted from VHSR images can improve the accuracy of parcel-level smallholder crop mapping. The proposed framework shows the great potential of combining EL technology with VHSR imagery for accurate mapping of smallholder crops, which could facilitate the development of parcel-level crop identification systems in countries dominated by smallholder agriculture.
KW  - crop classification
KW  - smallholder farms
KW  - land parcel
KW  - geographic object-based image analysis (GEOBIA)
KW  - machine learning
KW  - stacking
KW  - bagging
KW  - WorldView-2
DO  - 10.3390/rs13112146
ER  -
TY  - EJOU
AU  - Bai, Hao
AU  - Bai, Tingzhu
AU  - Li, Wei
AU  - Liu, Xun
TI  - A Building Segmentation Network Based on Improved Spatial Pyramid in Remote Sensing Images
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 11
SN  - 2076-3417

AB  - Building segmentation is widely used in urban planning, disaster prevention, human flow monitoring and environmental monitoring. However, due to the complex landscapes and highdensity settlements, automatically characterizing building in the urban village or cities using remote sensing images is very challenging. Inspired by the rencent deep learning methods, this paper proposed a novel end-to-end building segmentation network for segmenting buildings from remote sensing images. The network includes two branches: one branch uses Widely Adaptive Spatial Pyramid (WASP) structure to extract multi-scale features, and the other branch uses a deep residual network combined with a sub-pixel up-sampling structure to enhance the detail of building boundaries. We compared our proposed method with three state-of-the-art networks: DeepLabv3+, ENet, ESPNet. Experiments were performed using the publicly available Inria Aerial Image Labelling dataset (Inria aerial dataset) and the Satellite dataset II(East Asia). The results showed that our method outperformed the other networks in the experiments, with Pixel Accuracy reaching 0.8421 and 0.8738, respectively and with mIoU reaching 0.9034 and 0.8936 respectively. Compared with the basic network, it has increased by about 25% or more. It can not only extract building footprints, but also especially small building objects.
KW  - CNN
KW  - semantic segmentation
KW  - super resolution
KW  - remote sensing
KW  - spatial pyramid
KW  - ResNet
DO  - 10.3390/app11115069
ER  -
TY  - EJOU
AU  - Miranda, Alejandro
AU  - Catalán, Germán
AU  - Altamirano, Adison
AU  - Zamorano-Elgueta, Carlos
AU  - Cavieres, Manuel
AU  - Guerra, Javier
AU  - Mola-Yudego, Blas
TI  - How Much Can We See from a UAV-Mounted Regular Camera? Remote Sensing-Based Estimation of Forest Attributes in South American Native Forests
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 11
SN  - 2072-4292

AB  - Data collection from large areas of native forests poses a challenge. The present study aims at assessing the use of UAV for forest inventory on native forests in Southern Chile, and seeks to retrieve both stand and tree level attributes from forest canopy data. Data were collected from 14 plots (45 × 45 m) established at four locations representing unmanaged Chilean temperate forests: seven plots on secondary forests and seven plots on old-growth forests, including a total of 17 different native species. The imagery was captured using a fixed-wing airframe equipped with a regular RGB camera. We used the structure from motion and digital aerial photogrammetry techniques for data processing and combined machine learning methods based on boosted regression trees and mixed models. In total, 2136 trees were measured on the ground, from which 858 trees were visualized from the UAV imagery of the canopy, ranging from 26% to 88% of the measured trees in the field (mean = 45.7%, SD = 17.3), which represented between 70.6% and 96% of the total basal area of the plots (mean = 80.28%, SD = 7.7). Individual-tree diameter models based on remote sensing data were constructed with R2 = 0.85 and R2 = 0.66 based on BRT and mixed models, respectively. We found a strong relationship between canopy and ground data; however, we suggest that the best alternative was combining the use of both field-based and remotely sensed methods to achieve high accuracy estimations, particularly in complex structure forests (e.g., old-growth forests). Field inventories and UAV surveys provide accurate information at local scales and allow validation of large-scale applications of satellite imagery. Finally, in the future, increasing the accuracy of aerial surveys and monitoring is necessary to advance the development of local and regional allometric crown and DBH equations at the species level.
KW  - forest inventory
KW  - aerial survey
KW  - drone
KW  - structure from motion
DO  - 10.3390/rs13112151
ER  -
TY  - EJOU
AU  - Nakata, Yasutaka
AU  - Hayamizu, Masato
AU  - Ishiyama, Nobuo
AU  - Torita, Hiroyuki
TI  - Observation of Diurnal Ground Surface Changes Due to Freeze-Thaw Action by Real-Time Kinematic Unmanned Aerial Vehicle
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 11
SN  - 2072-4292

AB  - Ground surface changes caused by freeze-thaw action affect agriculture and forestry, as well as artificial structures such as roads. In this study, an area is examined in which reforestation is urgently needed but the growth of naturally restored seedlings and planted trees is impaired by freeze-thaw action. Thus, a method of measuring freeze-thaw induced ground surface changes and mitigating their negative impacts is needed. Real-time kinematic unmanned aerial vehicle and structure-from-motion multiview stereophotogrammetry are used on slope-failure sites in forest areas to observe the ground surface changes caused by freeze-thaw action over a wide area, in a nondestructive manner. The slope characteristics influencing the ground-surface changes were examined, and it was confirmed that it is possible to observe minute topographical changes of less than ±5 cm resulting from freeze-thaw action. Statistical models show that the amount of freeze-thaw action is mostly linked to the cumulative solar radiation, daily ground-surface temperature range, and topographic-wetness index, which influence the microscale dynamics of the ground surface. The proposed method will be useful for future quantitative assessments of ground-surface conditions. Further, efficient reforestation could be implemented by considering the effects of the factors identified on the amount of freeze-thaw action.
KW  - RTK-UAV
KW  - freeze-thaw action
KW  - landslide
KW  - thermal imagery
KW  - generalized linear model
DO  - 10.3390/rs13112167
ER  -
TY  - EJOU
AU  - Lee, Seunghyeon
AU  - Song, Youngkeun
AU  - Kil, Sung-Ho
TI  - Feasibility Analyses of Real-Time Detection of Wildlife Using UAV-Derived Thermal and RGB Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 11
SN  - 2072-4292

AB  - Wildlife monitoring is carried out for diverse reasons, and monitoring methods have gradually advanced through technological development. Direct field investigations have been replaced by remote monitoring methods, and unmanned aerial vehicles (UAVs) have recently become the most important tool for wildlife monitoring. Many previous studies on detecting wild animals have used RGB images acquired from UAVs, with most of the analyses depending on machine learning–deep learning (ML–DL) methods. These methods provide relatively accurate results, and when thermal sensors are used as a supplement, even more accurate detection results can be obtained through complementation with RGB images. However, because most previous analyses were based on ML–DL methods, a lot of time was required to generate training data and train detection models. This drawback makes ML–DL methods unsuitable for real-time detection in the field. To compensate for the disadvantages of the previous methods, this paper proposes a real-time animal detection method that generates a total of six applicable input images depending on the context and uses them for detection. The proposed method is based on the Sobel edge algorithm, which is simple but can detect edges quickly based on change values. The method can detect animals in a single image without training data. The fastest detection time per image was 0.033 s, and all frames of a thermal video could be analyzed. Furthermore, because of the synchronization of the properties of the thermal and RGB images, the performance of the method was above average in comparison with previous studies. With target images acquired at heights below 100 m, the maximum detection precision and detection recall of the most accurate input image were 0.804 and 0.699, respectively. However, the low resolution of the thermal sensor and its shooting height limitation were hindrances to wildlife detection. The aim of future research will be to develop a detection method that can improve these shortcomings.
KW  - thermal sensing
KW  - unmanned aerial vehicle
KW  - object-based animal detection
KW  - instant and automated detection
KW  - mixed image analysis
KW  - wildlife monitoring
KW  - multiple height shooting
DO  - 10.3390/rs13112169
ER  -
TY  - EJOU
AU  - Yang, Zhiqi
AU  - Dong, Jinwei
AU  - Kou, Weili
AU  - Qin, Yuanwei
AU  - Xiao, Xiangming
TI  - Mapping Panax Notoginseng Plantations by Using an Integrated Pixel- and Object-Based (IPOB) Approach and ZY-3 Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 11
SN  - 2072-4292

AB  - Plantations of Panax notoginseng (PN), traditional herbal medicine for the prevention and treatment of vascular diseases, are expanding rapidly in China, especially in the Yunnan province of China, due to its increasing demands and prices and causing dramatic environmental concerns. However, existing information on its planting area and spatial distribution are limited. Here, we mapped the PN planting area by using a new integrated pixel- and object-based (IPOB) approach, the Random Forest (RF) classifier, and the high-resolution ZiYuan-3 (ZY-3) imagery. We improved the procedures of classification in three aspects: (1) a new spectral index—Normalized Difference PN Index (NDPI)—was proposed, (2) the efficiency and scale of segmentation were optimized by using the Bi-level Scale-sets Model (BSM), and (3) feature variables were selected through an iteration analysis from 99 feature variables (spectral, textural, geometric, and geographic). Compared with the pixel- and the object-based methods, the IPOB has the highest F1 score of 0.98 and also has high robustness in terms of user and producer accuracies (97% and 99%, respectively), following by the object-based method (F1 = 0.94) and the pixel-based method (F1 = 0.93). The high accuracy was expected since the target class has very distinctive spectral and textural characteristics. Although all three approaches showed reasonably high accuracies due to the application of the NDPI and optimized procedures, the result showed the outperformance of the proposed IPOB approach. The framework established in this study expects to apply for regional or national PN surveys extensively. The information on the area and spatial distribution of PN can guide the government on policy making for the planting and exporting of traditional Chinese medicine resources.
KW  - Random Forest
KW  - integrated pixel- and object-based (IPOB) approach
KW  - feature selection
KW  - segmentation
KW  - Panax notoginseng
DO  - 10.3390/rs13112184
ER  -
TY  - EJOU
AU  - Lulić, Luka
AU  - Ožić, Karlo
AU  - Kišiček, Tomislav
AU  - Hafner, Ivan
AU  - Stepinac, Mislav
TI  - Post-Earthquake Damage Assessment—Case Study of the Educational Building after the Zagreb Earthquake
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 11
SN  - 2071-1050

AB  - In the wake of recent strong earthquakes in Croatia, there is a need for a detailed and more comprehensive post-earthquake damage assessment. Given that masonry structures are highly vulnerable to horizontal actions caused by earthquakes and a majority of the Croatian building stock is made of masonry, this field is particularly important for Croatia. In this paper, a complete assessment of an educational building in Zagreb Lower Town is reported. An extensive program of visual inspection and geometrical surveys has been planned and performed. Additionally, an in situ shear strength test is presented. After extensive fieldwork, collected data and results were input in 3Muri software for structural modeling. Moreover, a non-linear static (pushover) analysis was performed to individuate the possible failure mechanisms and to compare real-life damage to software results.
KW  - assessment
KW  - earthquake
KW  - Zagreb
KW  - case study
KW  - cultural heritage
DO  - 10.3390/su13116353
ER  -
TY  - EJOU
AU  - Rocha, Miguel
AU  - Oliveira, Anabela
AU  - Freire, Paula
AU  - Fortunato, André B.
AU  - Nahon, Alphonse
AU  - Barros, José L.
AU  - Azevedo, Alberto
AU  - Oliveira, Filipa S. B. F.
AU  - Rogeiro, João
AU  - Jesus, Gonçalo
AU  - Martins, Ricardo J.
AU  - Santos, Pedro P.
AU  - Tavares, Alexandre O.
AU  - Oliveira, João
TI  - Multi-Hazard WebGIS Platform for Coastal Regions
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 11
SN  - 2076-3417

AB  - The combined action of waves, surges and tides can cause flooding, erosion and dune and structure overtopping in many coastal regions. Addressing emergency and risk management in these areas require a combination of targeted campaigns and real-time data that measure all phenomena at stake and can be used to develop comprehensive monitoring platforms. These monitoring platforms can support the development of prediction tools that address all hazards in an integrated way. Herein, we present a methodology focused on multi-hazard coastal alert and risk, and its implementation in a tailored WebGIS platform. The MOSAIC platform offers a one-stop-shop capacity to access in-situ and remote sensing data, and hydrodynamic and morphodynamic predictions, supported by numerical models: SCHISM and XBeach. Information is structured on a local observatory scale, with regional forcings available for the correct interpretation of local hazards effects. This implementation can be further applied and extended to other coastal zones. The MOSAIC platform also provides access to a detailed database of past hazardous events, organized along several risk indicators, for the western coast of Portugal. The combination of features in the platform provides a unique repository of hazard information to support end-users for both emergency and long term risk planning actions.
KW  - web platform
KW  - flood and erosion risk management
KW  - hydro-morphodynamic modeling
KW  - remote sensing
KW  - forecast systems
KW  - GIS
KW  - observatories
DO  - 10.3390/app11115253
ER  -
TY  - EJOU
AU  - Elmetwalli, Adel H.
AU  - Tyler, Andrew N.
AU  - Moghanm, Farahat S.
AU  - Alamri, Saad A.M.
AU  - Eid, Ebrahem M.
AU  - Elsayed, Salah
TI  - Integration of Radiometric Ground-Based Data and High-Resolution QuickBird Imagery with Multivariate Modeling to Estimate Maize Traits in the Nile Delta of Egypt
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 11
SN  - 1424-8220

AB  - In site-specific management, rapid and accurate identification of crop stress at a large scale is critical. Radiometric ground-based data and satellite imaging with advanced spatial and spectral resolution allow for a deeper understanding of crop stress and the level of stress in a given area. This research aimed to assess the potential of radiometric ground-based data and high-resolution QuickBird satellite imagery to determine the leaf area index (LAI), biomass fresh weight (BFW) and chlorophyll meter (Chlm) of maize across well-irrigated, water stress and salinity stress areas in the Nile Delta of Egypt. Partial least squares regression (PLSR) and multiple linear regression (MLR) were evaluated to estimate the three measured traits based on vegetation spectral indices (vegetation-SRIs) derived from these methods and their combination. Maize field visits were conducted during the summer seasons from 28 to 30 July 2007 to collect ground reference data concurrent with the acquisition of radiometric ground-based measurements and QuickBird satellite imagery. The results showed that the majority of vegetation-SRIs extracted from radiometric ground-based data and high-resolution satellite images were more effective in estimating LAI, BFW, and Chlm. In general, the vegetation-SRIs of radiometric ground-based data showed higher R2 with measured traits compared to the vegetation-SRIs extracted from high-resolution satellite imagery. The coefficient of determination (R2) of the significant relationships between vegetation-SRIs of both methods and three measured traits varied from 0.64 to 0.89. For example, with QuickBird high-resolution satellite images, the relationships of the green normalized difference vegetation index (GNDVI) with LAI and BFW showed the highest R2 of 0.80 and 0.84, respectively. Overall, the ground-based vegetation-SRIs and the satellite-based indices were found to be in good agreement to assess the measured traits of maize. Both the calibration (Cal.) and validation (Val.) models of PLSR and MLR showed the highest performance in predicting the three measured traits based on the combination of vegetation-SRIs from radiometric ground-based data and high-resolution QuickBird satellite imagery. For example, validation (Val.) models of PLSR and MLR showed the highest performance in predicting the measured traits based on the combination of vegetation-SRIs from radiometric ground-based data and high-resolution QuickBird satellite imagery with R2 (0.91) of both methods for LAI, R2 (0.91–0.93) for BFW respectively, and R2 (0.82) of both methods for Chlm. The models of PLSR and MLR showed approximately the same performance in predicting the three measured traits and no clear difference was found between them and their combinations. In conclusion, the results obtained from this study showed that radiometric ground-based measurements and high spectral resolution remote-sensing imagery have the potential to offer necessary crop monitoring information across well-irrigated, water stress and salinity stress in regions suffering lack of freshwater resources.
KW  - maize
KW  - QuickBird imagery
KW  - spectral indices
KW  - water stress
KW  - salinity stress
KW  - PLSR and MLR
DO  - 10.3390/s21113915
ER  -
TY  - EJOU
AU  - Manzoor, Bilal
AU  - Othman, Idris
AU  - Pomares, Juan C.
TI  - Digital Technologies in the Architecture, Engineering and Construction (AEC) Industry—A Bibliometric—Qualitative Literature Review of Research Activities
T2  - International Journal of Environmental Research and Public Health

PY  - 2021
VL  - 18
IS  - 11
SN  - 1660-4601

AB  - Digital technologies (DTs) are proven helpful in the Architecture, Engineering and Construction (AEC) industry due to their varied benefits to project stakeholders, such as enhanced visualization, better data sharing, reduction in building waste, increased productivity, sustainable performance and safety improvement. Therefore, researchers have conducted various studies on DTs in the AEC industry over the year; however, this study explores the state-of-the-art research on DTs in the AEC industry by means of a bibliometric-qualitative review method. This research would uncover new knowledge gaps and practical needs in the domain of DTs in the AEC industry. In addition, bibliometric analysis was carried out by utilizing academic publications from Scopus (i.e., 11,047 publications for the AEC industry, 1956 for DTs and 1778 for DTs in the AEC industry). Furthermore, a qualitative review was further conducted on 200 screened selected research publications in the domain of DTs. This study brings attention to the body of knowledge by envisioning trends and patterns by defining key research interests, journals, countries, new advancements, challenges, negative attitudes and future directions towards DTs in the AEC industry. However, this study is the first in its vital importance and uniqueness by providing a broad updated review of DTs in the AEC literature. Furthermore, this research laid a foundation for future researchers, policy makers and practitioners to explore the limitations in future research.
KW  - digital technologies
KW  - bibliometric analysis
KW  - systematic review
KW  - building information modeling (BIM)
KW  - safety
KW  - accidents
DO  - 10.3390/ijerph18116135
ER  -
TY  - EJOU
AU  - Yang, Xiaoyu
AU  - Bao, Nisha
AU  - Li, Wenwen
AU  - Liu, Shanjun
AU  - Fu, Yanhua
AU  - Mao, Yachun
TI  - Soil Nutrient Estimation and Mapping in Farmland Based on UAV Imaging Spectrometry
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 11
SN  - 1424-8220

AB  - Soil nutrient is one of the most important properties for improving farmland quality and product. Imaging spectrometry has the potential for rapid acquisition and real-time monitoring of soil characteristics. This study aims to explore the preprocessing and modeling methods of hyperspectral images obtained from an unmanned aerial vehicle (UAV) platform for estimating the soil organic matter (SOM) and soil total nitrogen (STN) in farmland. The results showed that: (1) Multiplicative Scattering Correction (MSC) performed better in reducing image scattering noise than Standard Normal Variate (SNV) transformation or spectral derivatives, and it yielded a result with higher correlation and lower signal-to-noise ratio; (2) The proposed feature selection method combining Successive Projections Algorithm (SPA) and Competitive Adaptive Reweighted Sampling algorithm (CARS), could provide selective preference for hyperspectral bands. Exploiting this method, 24 and 22 feature bands were selected for SOM and STN estimation, respectively; (3) The particle swarm optimization (PSO) algorithm was employed to obtain optimized input weights and bias values of the extreme learning machine (ELM) model for more accurate prediction of SOM and STN. The improved PSO-ELM model based on the selected preference bands achieved higher prediction accuracy (R2 of 0.73 and RPD of 1.91 for SOM, R2 of 0.63, and RPD of 1.53 for STN) than support vector machine (SVM), partial least squares regression (PLSR), and the ELM model. This study provides an important guideline for monitoring soil nutrient for precision agriculture with imaging spectrometry.
KW  - unmanned aerial vehicle
KW  - hyperspectral image
KW  - extreme learning machine
KW  - soil nutrient estimation
KW  - feature selection
DO  - 10.3390/s21113919
ER  -
TY  - EJOU
AU  - Aduvukha, Grace R.
AU  - Abdel-Rahman, Elfatih M.
AU  - Sichangi, Arthur W.
AU  - Makokha, Godfrey O.
AU  - Landmann, Tobias
AU  - Mudereri, Bester T.
AU  - Tonnang, Henri E. Z.
AU  - Dubois, Thomas
TI  - Cropping Pattern Mapping in an Agro-Natural Heterogeneous Landscape Using Sentinel-2 and Sentinel-1 Satellite Datasets
T2  - Agriculture

PY  - 2021
VL  - 11
IS  - 6
SN  - 2077-0472

AB  - The quantity of land covered by various crops in a specific time span, referred to as a cropping pattern, dictates the level of agricultural production. However, retrieval of this information at a landscape scale can be challenging, especially when high spatial resolution imagery is not available. This study hypothesized that utilizing the unique advantages of multi-date and medium spatial resolution freely available Sentinel-2 (S2) reflectance bands (S2 bands), their vegetation indices (VIs) and vegetation phenology (VP) derivatives, and Sentinel-1 (S1) backscatter data would improve cropping pattern mapping in heterogeneous landscapes using robust machine learning algorithms, i.e., the guided regularized random forest (GRRF) for variable selection and the random forest (RF) for classification. This study’s objective was to map cropping patterns within three sub-counties in Murang’a County, a typical African smallholder heterogeneous farming area, in Kenya. Specifically, the performance of eight classification scenarios for mapping cropping patterns was compared, namely: (i) only S2 bands; (ii) S2 bands and VIs; (iii) S2 bands and VP; (iv) S2 bands and S1; (v) S2 bands, VIs, and S1; (vi) S2 bands, VP, and S1; (vii) S2 bands, VIs, and VP; and (viii) S2 bands, VIs, VP, and S1. Reference data of the dominant cropping patterns and non-croplands were collected. The GRRF algorithm was used to select the optimum variables in each scenario, and the RF was used to perform the classification for each scenario. The highest overall accuracy was 94.33% with Kappa of 0.93, attained using the GRRF-selected variables of scenario (v) S2, VIs, and S1. Furthermore, McNemar’s test of significance did not show significant differences (p ≤ 0.05) among the tested scenarios. This study demonstrated the strength of GRRF in selecting the most important variables and the synergetic advantage of S2 and S1 derivatives to accurately map cropping patterns in small-scale farming-dominated landscapes. Consequently, the cropping pattern mapping approach can be used in other sites of relatively similar agro-ecological conditions. Additionally, these results can be used to understand the sustainability of food systems and to model the abundance and spread of crop insect pests, diseases, and pollinators.
KW  - agricultural productivity
KW  - cropping pattern
KW  - Kenya
KW  - multi-data analysis
DO  - 10.3390/agriculture11060530
ER  -
TY  - EJOU
AU  - Hara, Patryk
AU  - Piekutowska, Magdalena
AU  - Niedbała, Gniewko
TI  - Selection of Independent Variables for Crop Yield Prediction Using Artificial Neural Network Models with Remote Sensing Data
T2  - Land

PY  - 2021
VL  - 10
IS  - 6
SN  - 2073-445X

AB  - Knowing the expected crop yield in the current growing season provides valuable information for farmers, policy makers, and food processing plants. One of the main benefits of using reliable forecasting tools is generating more income from grown crops. Information on the amount of crop yielding before harvesting helps to guide the adoption of an appropriate strategy for managing agricultural products. The difficulty in creating forecasting models is related to the appropriate selection of independent variables. Their proper selection requires a perfect knowledge of the research object. The following article presents and discusses the most commonly used independent variables in agricultural crop yield prediction modeling based on artificial neural networks (ANNs). Particular attention is paid to environmental variables, such as climatic data, air temperature, total precipitation, insolation, and soil parameters. The possibility of using plant productivity indices and vegetation indices, which are valuable predictors obtained due to the application of remote sensing techniques, are analyzed in detail. The paper emphasizes that the increasingly common use of remote sensing and photogrammetric tools enables the development of precision agriculture. In addition, some limitations in the application of certain input variables are specified, as well as further possibilities for the development of non-linear modeling, using artificial neural networks as a tool supporting the practical use of and improvement in precision farming techniques.
KW  - crop yield prediction
KW  - independent variables
KW  - ANN
KW  - remote sensing
DO  - 10.3390/land10060609
ER  -
TY  - EJOU
AU  - Ruf, Boitumelo
AU  - Mohrs, Jonas
AU  - Weinmann, Martin
AU  - Hinz, Stefan
AU  - Beyerer, Jürgen
TI  - ReS2tAC—UAV-Borne Real-Time SGM Stereo Optimized for Embedded ARM and CUDA Devices
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 11
SN  - 1424-8220

AB  - With the emergence of low-cost robotic systems, such as unmanned aerial vehicle, the importance of embedded high-performance image processing has increased. For a long time, FPGAs were the only processing hardware that were capable of high-performance computing, while at the same time preserving a low power consumption, essential for embedded systems. However, the recently increasing availability of embedded GPU-based systems, such as the NVIDIA Jetson series, comprised of an ARM CPU and a NVIDIA Tegra GPU, allows for massively parallel embedded computing on graphics hardware. With this in mind, we propose an approach for real-time embedded stereo processing on ARM and CUDA-enabled devices, which is based on the popular and widely used Semi-Global Matching algorithm. In this, we propose an optimization of the algorithm for embedded CUDA GPUs, by using massively parallel computing, as well as using the NEON intrinsics to optimize the algorithm for vectorized SIMD processing on embedded ARM CPUs. We have evaluated our approach with different configurations on two public stereo benchmark datasets to demonstrate that they can reach an error rate as low as 3.3%. Furthermore, our experiments show that the fastest configuration of our approach reaches up to 46 FPS on VGA image resolution. Finally, in a use-case specific qualitative evaluation, we have evaluated the power consumption of our approach and deployed it on the DJI Manifold 2-G attached to a DJI Matrix 210v2 RTK unmanned aerial vehicle (UAV), demonstrating its suitability for real-time stereo processing onboard a UAV.
KW  - embedded stereo vision
KW  - real-time stereo processing
KW  - disparity estimation
KW  - semi-global matching
KW  - GPGPU
KW  - SIMD
KW  - UAV
DO  - 10.3390/s21113938
ER  -
TY  - EJOU
AU  - Al-amri, Redhwan
AU  - Murugesan, Raja K.
AU  - Man, Mustafa
AU  - Abdulateef, Alaa F.
AU  - Al-Sharafi, Mohammed A.
AU  - Alkahtani, Ammar A.
TI  - A Review of Machine Learning and Deep Learning Techniques for Anomaly Detection in IoT Data
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 12
SN  - 2076-3417

AB  - Anomaly detection has gained considerable attention in the past couple of years. Emerging technologies, such as the Internet of Things (IoT), are known to be among the most critical sources of data streams that produce massive amounts of data continuously from numerous applications. Examining these collected data to detect suspicious events can reduce functional threats and avoid unseen issues that cause downtime in the applications. Due to the dynamic nature of the data stream characteristics, many unresolved problems persist. In the existing literature, methods have been designed and developed to evaluate certain anomalous behaviors in IoT data stream sources. However, there is a lack of comprehensive studies that discuss all the aspects of IoT data processing. Thus, this paper attempts to fill this gap by providing a complete image of various state-of-the-art techniques on the major problems and core challenges in IoT data. The nature of data, anomaly types, learning mode, window model, datasets, and evaluation criteria are also presented. Research challenges related to data evolving, feature-evolving, windowing, ensemble approaches, nature of input data, data complexity and noise, parameters selection, data visualizations, heterogeneity of data, accuracy, and large-scale and high-dimensional data are investigated. Finally, the challenges that require substantial research efforts and future directions are summarized.
KW  - anomaly detection
KW  - data stream
KW  - deep learning
KW  - Internet of Things
KW  - machine learning
DO  - 10.3390/app11125320
ER  -
TY  - EJOU
AU  - Ma, Xiaohang
AU  - Wu, Yongze
AU  - Shen, Jingfang
AU  - Duan, Lingfeng
AU  - Liu, Ying
TI  - ML-LME: A Plant Growth Situation Analysis Model Using the Hierarchical Effect of Fractal Dimension
T2  - Mathematics

PY  - 2021
VL  - 9
IS  - 12
SN  - 2227-7390

AB  - Rice plays an essential role in agricultural production as the most significant food crop. Automated supervision in the process of crop growth is the future development direction of agriculture, and it is also a problem that needs to be solved urgently. Productive cultivation, production and research of crops are attributed to increased automation of supervision in the growth. In this article, for the first time, we propose the concept of rice fractal dimension heterogeneity and define it as rice varieties with different fractal dimension values having various correlations between their traits. To make a comprehensive prediction of the rice growth, Machine Learning and Linear Mixed Effect (ML-LME) model is proposed to model and analyze this heterogeneity, which is based on the existing automatic measurement system RAP and introduces statistical characteristics of fractal dimensions as novel features. Machine learning algorithms are applied to distinguish the rice growth stages with a high degree of accuracy and to excavate the heterogeneity of rice fractal dimensions with statistical meaning. According to the information of growth stage and fractal dimension heterogeneity, a precise prediction of key rice phenotype traits can be received by ML-LME using a Linear Mixed Effect model. In this process, the value of the fractal dimension is divided into groups and then rices of different levels are respectively fitted to improve the accuracy of the subsequent prediction, that is, the heterogeneity of the fractal dimension. Afterwards, we apply the model to analyze the rice pot image. The research results show that the ML-LME model, which possesses the hierarchical effect of fractal dimension, performs more excellently in predicting the growth situation of plants than the traditional regression model does. Further comparison confirmed that the model we proposed is the first to consider the hierarchy structure of plant fractal dimension, and that consideration obviously strengthens the model on the ability of variation interpretation and prediction precision.
KW  - fractal theory
KW  - machine learning
KW  - linear mixed effect model
KW  - rice phenotype heterogeneity
DO  - 10.3390/math9121322
ER  -
TY  - EJOU
AU  - de Oliveira, Gabriel S.
AU  - Marcato Junior, José
AU  - Polidoro, Caio
AU  - Osco, Lucas P.
AU  - Siqueira, Henrique
AU  - Rodrigues, Lucas
AU  - Jank, Liana
AU  - Barrios, Sanzio
AU  - Valle, Cacilda
AU  - Simeão, Rosângela
AU  - Carromeu, Camilo
AU  - Silveira, Eloise
AU  -  André de Castro Jorge, Lúcio
AU  - Gonçalves, Wesley
AU  - Santos, Mateus
AU  - Matsubara, Edson
TI  - Convolutional Neural Networks to Estimate Dry Matter Yield in a Guineagrass Breeding Program Using UAV Remote Sensing
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 12
SN  - 1424-8220

AB  - Forage dry matter is the main source of nutrients in the diet of ruminant animals. Thus, this trait is evaluated in most forage breeding programs with the objective of increasing the yield. Novel solutions combining unmanned aerial vehicles (UAVs) and computer vision are crucial to increase the efficiency of forage breeding programs, to support high-throughput phenotyping (HTP), aiming to estimate parameters correlated to important traits. The main goal of this study was to propose a convolutional neural network (CNN) approach using UAV-RGB imagery to estimate dry matter yield traits in a guineagrass breeding program. For this, an experiment composed of 330 plots of full-sib families and checks conducted at Embrapa Beef Cattle, Brazil, was used. The image dataset was composed of images obtained with an RGB sensor embedded in a Phantom 4 PRO. The traits leaf dry matter yield (LDMY) and total dry matter yield (TDMY) were obtained by conventional agronomic methodology and considered as the ground-truth data. Different CNN architectures were analyzed, such as AlexNet, ResNeXt50, DarkNet53, and two networks proposed recently for related tasks named MaCNN and LF-CNN. Pretrained AlexNet and ResNeXt50 architectures were also studied. Ten-fold cross-validation was used for training and testing the model. Estimates of DMY traits by each CNN architecture were considered as new HTP traits to compare with real traits. Pearson correlation coefficient r between real and HTP traits ranged from 0.62 to 0.79 for LDMY and from 0.60 to 0.76 for TDMY; root square mean error (RSME) ranged from 286.24 to 366.93 kg·ha−1 for LDMY and from 413.07 to 506.56 kg·ha−1 for TDMY. All the CNNs generated heritable HTP traits, except LF-CNN for LDMY and AlexNet for TDMY. Genetic correlations between real and HTP traits were high but varied according to the CNN architecture. HTP trait from ResNeXt50 pretrained achieved the best results for indirect selection regardless of the dry matter trait. This demonstrates that CNNs with remote sensing data are highly promising for HTP for dry matter yield traits in forage breeding programs.
KW  - deep learning
KW  - forage dry matter yield
KW  - high-throughput phenotyping
KW  - Brazilian pasture
DO  - 10.3390/s21123971
ER  -
TY  - EJOU
AU  - Sangjan, Worasit
AU  - Carter, Arron H.
AU  - Pumphrey, Michael O.
AU  - Jitkov, Vadim
AU  - Sankaran, Sindhuja
TI  - Development of a Raspberry Pi-Based Sensor System for Automated In-Field Monitoring to Support Crop Breeding Programs
T2  - Inventions

PY  - 2021
VL  - 6
IS  - 2
SN  - 2411-5134

AB  - Sensor applications for plant phenotyping can advance and strengthen crop breeding programs. One of the powerful sensing options is the automated sensor system, which can be customized and applied for plant science research. The system can provide high spatial and temporal resolution data to delineate crop interaction with weather changes in a diverse environment. Such a system can be integrated with the internet to enable the internet of things (IoT)-based sensor system development for real-time crop monitoring and management. In this study, the Raspberry Pi-based sensor (imaging) system was fabricated and integrated with a microclimate sensor to evaluate crop growth in a spring wheat breeding trial for automated phenotyping applications. Such an in-field sensor system will increase the reproducibility of measurements and improve the selection efficiency by investigating dynamic crop responses as well as identifying key growth stages (e.g., heading), assisting in the development of high-performing crop varieties. In the low-cost system developed here-in, a Raspberry Pi computer and multiple cameras (RGB and multispectral) were the main components. The system was programmed to automatically capture and manage the crop image data at user-defined time points throughout the season. The acquired images were suitable for extracting quantifiable plant traits, and the images were automatically processed through a Python script (an open-source programming language) to extract vegetation indices, representing crop growth and overall health. Ongoing efforts are conducted towards integrating the sensor system for real-time data monitoring via the internet that will allow plant breeders to monitor multiple trials for timely crop management and decision making.
KW  - sensor
KW  - high-throughput phenotyping
KW  - internet of things
KW  - Raspberry Pi
DO  - 10.3390/inventions6020042
ER  -
TY  - EJOU
AU  - Chen, Hualong
AU  - Wen, Yuanqiao
AU  - Zhu, Man
AU  - Huang, Yamin
AU  - Xiao, Changshi
AU  - Wei, Tao
AU  - Hahn, Axel
TI  - From Automation System to Autonomous System: An Architecture Perspective
T2  - Journal of Marine Science and Engineering

PY  - 2021
VL  - 9
IS  - 6
SN  - 2077-1312

AB  - Autonomy is the core capability of future systems, and architecture design is one of the critical issues in system development and implementation. To discuss the architecture of autonomous systems in the future, this paper reviews the developing progress of architectures from automation systems to autonomous systems. Firstly, the autonomy and autonomous systems in different fields are summarized. The article classifies and summarizes the architecture of typical automated systems and infer three suggestions for building an autonomous system architecture: extensibility, evolvability, and collaborability. Accordingly, this paper builds an autonomous waterborne transportation system, and the architecture is composed of the object layer, cyberspace layer, cognition layer, and application layer, the proposed suggestions made in the construction of the architecture are reflected in the inter-relationships at all layers. Through the cooperation of four layers, the autonomous waterborne transportation system can autonomously complete the system functions, such as system control and transportation service. In the end, the characteristics of autonomous systems are concluded, from which the future primary research directions and the challenges of autonomous systems are provided.
KW  - autonomous systems
KW  - autonomy
KW  - architecture
KW  - automation system
KW  - waterway transportation system
DO  - 10.3390/jmse9060645
ER  -
TY  - EJOU
AU  - Zheng, Ke
AU  - Jia, Guozhu
AU  - Yang, Linchao
AU  - Wang, Jiaqing
TI  - A Compound Fault Labeling and Diagnosis Method Based on Flight Data and BIT Record of UAV
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 12
SN  - 2076-3417

AB  - In the process of Unmanned Aerial Vehicle (UAV) flight testing, plenty of compound faults exist, which could be composed of concurrent single faults or over-limit states alarmed by Built-In-Test (BIT) equipment. At present, there still lacks a suitable automatic labeling approach for UAV flight data, effectively utilizing the information of the BIT record. The performance of the originally employed flight data-driven fault diagnosis models based on machine learning needs to be improved as well. A compound fault labeling and diagnosis method based on actual flight data and the BIT record of the UAV during flight test phase is proposed, through labeling the flight data with compound fault modes corresponding to concurrent single faults recorded by the BIT system, and upgrading the original diagnosis model based on Gradient Boosting Decision Tree (GBDT) and Fully Convolutional Network (FCNN), to eXtreme Gradient Boosting (XGBoost), Light Gradient Boosting Machine (LightGBM) and modified Convolutional Neural Network (CNN). The experimental results based on actual test flight data show that the proposed method could effectively label the flight data and obtain a significant improvement in diagnostic performance, appearing to be practical in the UAV test flight process.
KW  - fault diagnosis
KW  - data labeling
KW  - UAV
KW  - flight data and BIT record
KW  - machine learning
DO  - 10.3390/app11125410
ER  -
TY  - EJOU
AU  - Sun, Fengjie
AU  - Wang, Xianchang
AU  - Zhang, Rui
TI  - Improved Q-Learning Algorithm Based on Approximate State Matching in Agricultural Plant Protection Environment
T2  - Entropy

PY  - 2021
VL  - 23
IS  - 6
SN  - 1099-4300

AB  - An Unmanned Aerial Vehicle (UAV) can greatly reduce manpower in the agricultural plant protection such as watering, sowing, and pesticide spraying. It is essential to develop a Decision-making Support System (DSS) for UAVs to help them choose the correct action in states according to the policy. In an unknown environment, the method of formulating rules for UAVs to help them choose actions is not applicable, and it is a feasible solution to obtain the optimal policy through reinforcement learning. However, experiments show that the existing reinforcement learning algorithms cannot get the optimal policy for a UAV in the agricultural plant protection environment. In this work we propose an improved Q-learning algorithm based on similar state matching, and we prove theoretically that there has a greater probability for UAV choosing the optimal action according to the policy learned by the algorithm we proposed than the classic Q-learning algorithm in the agricultural plant protection environment. This proposed algorithm is implemented and tested on datasets that are evenly distributed based on real UAV parameters and real farm information. The performance evaluation of the algorithm is discussed in detail. Experimental results show that the algorithm we proposed can efficiently learn the optimal policy for UAVs in the agricultural plant protection environment.
KW  - decision-making support system
KW  - reinforcement learning
KW  - Q-learning
DO  - 10.3390/e23060737
ER  -
TY  - EJOU
AU  - Brandoli, Bruno
AU  - de Geus, André R.
AU  - Souza, Jefferson R.
AU  - Spadon, Gabriel
AU  - Soares, Amilcar
AU  - Rodrigues, Jose F.
AU  - Komorowski, Jerzy
AU  - Matwin, Stan
TI  - Aircraft Fuselage Corrosion Detection Using Artificial Intelligence
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 12
SN  - 1424-8220

AB  - Corrosion identification and repair is a vital task in aircraft maintenance to ensure continued structural integrity. Regarding fuselage lap joints, typically, visual inspections are followed by non-destructive methodologies, which are time-consuming. The visual inspection of large areas suffers not only from subjectivity but also from the variable probability of corrosion detection, which is aggravated by the multiple layers used in fuselage construction. In this paper, we propose a methodology for automatic image-based corrosion detection of aircraft structures using deep neural networks. For machine learning, we use a dataset that consists of D-Sight Aircraft Inspection System (DAIS) images from different lap joints of Boeing and Airbus aircrafts. We also employ transfer learning to overcome the shortage of aircraft corrosion images. With precision of over 93%, we demonstrate that our approach detects corrosion with a precision comparable to that of trained operators, aiding to reduce the uncertainties related to operator fatigue or inadequate training. Our results indicate that our methodology can support specialists and engineers in corrosion monitoring in the aerospace industry, potentially contributing to the automation of condition-based maintenance protocols.
KW  - aircraft corrosion inspection
KW  - automatic corrosion detection
KW  - material fatigue
KW  - corrosion science
KW  - rust detection
KW  - aviation maintenance
KW  - deep learning
DO  - 10.3390/s21124026
ER  -
TY  - EJOU
AU  - Martínez, Jimmy
AU  - Riba, Jordi-Roger
AU  - Moreno-Eguilaz, Manuel
TI  - State of Health Prediction of Power Connectors by Analyzing the Degradation Trajectory of the Electrical Resistance
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 12
SN  - 2079-9292

AB  - Estimating the remaining useful life (RUL) or the state of health (SoH) of electrical components such as power connectors is still a challenging and complex task. Power connectors play a critical role in medium- and high-voltage power networks, their failure leading to important consequences such as power outages, unscheduled downtimes, safety hazards or important economic losses. Online condition monitoring strategies allow developing improved predictive maintenance plans. Due to the development of low-cost sensors and electronic communication systems compatible with Internet of Things (IoT) applications, several methods for online and offline SoH determination of diverse power devices are emerging. This paper presents, analyzes and compares the performance of three simple and effective methods for online determination of the SoH of power connectors with low computational requirements. The proposed approaches are based on monitoring the evolution of the connectors’ electrical resistance, which defines the degradation trajectory because the electrical resistance is a reliable indicator or signature of the SoH of the connectors. The methods analyzed in this paper are validated by means of experimental ageing tests emulating real degradation conditions. Laboratory results prove the suitability and feasibility of the proposed approach, which could be applied to other power products and apparatus.
KW  - electrical connectors
KW  - state of health
KW  - condition monitoring
KW  - parameter identification
KW  - predictive maintenance
DO  - 10.3390/electronics10121409
ER  -
TY  - EJOU
AU  - Zhang, Wentao
AU  - Liu, Yucheng
AU  - Zhang, Shaohui
AU  - Long, Tuzhi
AU  - Liang, Jinglun
TI  - Error Fusion of Hybrid Neural Networks for Mechanical Condition Dynamic Prediction
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 12
SN  - 1424-8220

AB  - It is important for equipment to operate safely and reliably so that the working state of mechanical parts pushes forward an immense influence. Therefore, in order to enhance the dependability and security of mechanical equipment, to accurately predict the changing trend of mechanical components in advance plays a significant role. This paper introduces a novel condition prediction method, named error fusion of hybrid neural networks (EFHNN), by combining the error fusion of multiple sparse auto-encoders with convolutional neural networks for predicting the mechanical condition. First, to improve prediction accuracy, we can use the error fusion of multiple sparse auto-encoders to collect multi-feature information, and obtain a trend curve representing machine condition as well as a threshold line that can indicate the beginning of mechanical failure by computing the square prediction error (SPE). Then, convolutional neural networks predict the state of the machine according to the original data when the SPE value exceeds the threshold line. It can be seen from this result that the EFHNN method in the prediction of mechanical fault time series is available and superior.
KW  - mechanical equipment
KW  - error fusion of multiple SAEs (EFMSAE)
KW  - convolutional neural networks (CNN)
KW  - prediction
DO  - 10.3390/s21124043
ER  -
TY  - EJOU
AU  - Saad, Mohamad H.
AU  - Hamdan, Nurul M.
AU  - Sarker, Mahidur R.
TI  - State of the Art of Urban Smart Vertical Farming Automation System: Advanced Topologies, Issues and Recommendations
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 12
SN  - 2079-9292

AB  - The global economy is now under threat due to the ongoing domestic and international lockdown for COVID-19. Many have already lost their jobs, and businesses have been unstable in the Corona era. Apart from educational institutions, banks, privately owned institutions, and agriculture, there are signs of economic recession in almost all sectors. The roles of modern technology, the Internet of things, and artificial intelligence are undeniable in helping the world achieve economic prosperity in the post-COVID-19 economic downturn. Food production must increase by 60% by 2050 to meet global food security demands in the face of uncertainty such as the COVID-19 pandemic and a growing population. Given COVID 19’s intensity and isolation, improving food production and distribution systems is critical to combating hunger and addressing the double burden of malnutrition. As the world’s population is growing day by day, according to an estimation world’s population reaches 9.6 billion by 2050, so there is a growing need to modify the agriculture methods, technologies so that maximum crops can be attained and human effort can be reduced. The urban smart vertical farming (USVF) is a solution to secure food production, which can be introduced at any adaptive reuse, retrofit, or new buildings in vertical manners. This paper aims to provide a comprehensive review of the concept of USVF using various techniques to enhance productivity as well as its types, topologies, technologies, control systems, social acceptance, and benefits. This review has focused on numerous issues, challenges, and recommendations in the development of the system, vertical farming management, and modern technologies approach.
KW  - automation
KW  - smart vertical farming
KW  - sensors
KW  - Internet of Things
KW  - urban farming
DO  - 10.3390/electronics10121422
ER  -
TY  - EJOU
AU  - Kim, Jingyeom
AU  - Lee, Joohyung
AU  - Kim, Taeyeon
TI  - AdaMM: Adaptive Object Movement and Motion Tracking in Hierarchical Edge Computing System
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 12
SN  - 1424-8220

AB  - This paper presents a novel adaptive object movement and motion tracking (AdaMM) framework in a hierarchical edge computing system for achieving GPU memory footprint reduction of deep learning (DL)-based video surveillance services. DL-based object movement and motion tracking requires a significant amount of resources, such as (1) GPU processing power for the inference phase and (2) GPU memory for model loading. Despite the absence of an object in the video, if the DL model is loaded, the GPU memory must be kept allocated for the loaded model. Moreover, in several cases, video surveillance tries to capture events that rarely occur (e.g., abnormal object behaviors); therefore, such standby GPU memory might be easily wasted. To alleviate this problem, the proposed AdaMM framework categorizes the tasks used for the object movement and motion tracking procedure in an increasing order of the required processing and memory resources as task (1) frame difference calculation, task (2) object detection, and task (3) object motion and movement tracking. The proposed framework aims to adaptively release the unnecessary standby object motion and movement tracking model to save GPU memory by utilizing light tasks, such as frame difference calculation and object detection in a hierarchical manner. Consequently, object movement and motion tracking are adaptively triggered if the object is detected within the specified threshold time; otherwise, the GPU memory for the model of task (3) can be released. Moreover, object detection is also adaptively performed if the frame difference over time is greater than the specified threshold. We implemented the proposed AdaMM framework using commercial edge devices by considering a three-tier system, such as the 1st edge node for both tasks (1) and (2), the 2nd edge node for task (3), and the cloud for sending a push alarm. A measurement-based experiment reveals that the proposed framework achieves a maximum GPU memory reduction of 76.8% compared to the baseline system, while requiring a 2680 ms delay for loading the model for object movement and motion tracking.
KW  - EdgeAI
KW  - hierarchical edge computing
KW  - deep learning
KW  - object detection and tracking
KW  - software implementation
DO  - 10.3390/s21124089
ER  -
TY  - EJOU
AU  - Tasseron, Paolo
AU  - van Emmerik, Tim
AU  - Peller, Joseph
AU  - Schreyers, Louise
AU  - Biermann, Lauren
TI  - Advancing Floating Macroplastic Detection from Space Using Experimental Hyperspectral Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 12
SN  - 2072-4292

AB  - Airborne and spaceborne remote sensing (RS) collecting hyperspectral imagery provides unprecedented opportunities for the detection and monitoring of floating riverine and marine plastic debris. However, a major challenge in the application of RS techniques is the lack of a fundamental understanding of spectral signatures of water-borne plastic debris. Recent work has emphasised the case for open-access hyperspectral reflectance reference libraries of commonly used polymer items. In this paper, we present and analyse a high-resolution hyperspectral image database of a unique mix of 40 virgin macroplastic items and vegetation. Our double camera setup covered the visible to shortwave infrared (VIS-SWIR) range from 400 to 1700 nm in a darkroom experiment with controlled illumination. The cameras scanned the samples floating in water and captured high-resolution images in 336 spectral bands. Using the resulting reflectance spectra of 1.89 million pixels in linear discriminant analyses (LDA), we determined the importance of each spectral band for discriminating between water and mixed floating debris, and vegetation and plastics. The absorption peaks of plastics (1215 nm, 1410 nm) and vegetation (710 nm, 1450 nm) are associated with high LDA weights. We then compared Sentinel-2 and Worldview-3 satellite bands with these outcomes and identified 12 satellite bands to overlap with important wavelengths for discrimination between the classes. Lastly, the Normalised Vegetation Difference Index (NDVI) and Floating Debris Index (FDI) were calculated to determine why they work, and how they could potentially be improved. These findings could be used to enhance existing efforts in monitoring macroplastic pollution, as well as form a baseline for the design of future multispectral RS systems.
KW  - remote sensing
KW  - Sentinel-2
KW  - earth observation
KW  - plastic monitoring
KW  - spectral reflectance
DO  - 10.3390/rs13122335
ER  -
TY  - EJOU
AU  - Yang, Haibo
AU  - Li, Fei
AU  - Wang, Wei
AU  - Yu, Kang
TI  - Estimating Above-Ground Biomass of Potato Using Random Forest and Optimized Hyperspectral Indices
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 12
SN  - 2072-4292

AB  - Spectral indices rarely show consistency in estimating crop traits across growth stages; thus, it is critical to simultaneously evaluate a group of spectral variables and select the most informative spectral indices for retrieving crop traits. The objective of this study was to explore the optimal spectral predictors for above-ground biomass (AGB) by applying Random Forest (RF) on three types of spectral predictors: the full spectrum, published spectral indices (Pub-SIs), and optimized spectral indices (Opt-SIs). Canopy hyperspectral reflectance of potato plants, treated with seven nitrogen (N) rates, was obtained during the tuber formation and tuber bulking from 2015 to 2016. Twelve Pub-SIs were selected, and their spectral bands were optimized using band optimization algorithms. Results showed that the Opt-SIs were the best input variables of RF models. Compared to the best empirical model based on Opt-SIs, the Opt-SIs based RF model improved the prediction of AGB, with R2 increased by 6%, 10%, and 16% at the tuber formation, tuber bulking, and for across the two growth stages, respectively. The Opt-SIs can significantly reduce the number of input variables. The optimized Blue nitrogen index (Opt-BNI) and Modified red-edge normalized difference vegetation index (Opt-mND705) combined with an RF model showed the best performance in estimating potato AGB at the tuber formation stage (R2 = 0.88). In the tuber bulking stage, only using optimized Nitrogen planar domain index (Opt-NPDI) as the input variable of the RF model produced satisfactory accuracy in training and testing datasets, with the R2, RMSE, and RE being 0.92, 208.6 kg/ha, and 10.3%, respectively. The Opt-BNI and Double-peak nitrogen index (Opt-NDDA) coupling with an RF model explained 86% of the variations in potato AGB, with the lowest RMSE (262.9 kg/ha) and RE (14.8%) across two growth stages. This study shows that combining the Opt-SIs and RF can greatly enhance the prediction accuracy for crop AGB while significantly reduces collinearity and redundancies of spectral data.
KW  - potato crops
KW  - biomass estimation
KW  - machine learning
KW  - vegetation indices
DO  - 10.3390/rs13122339
ER  -
TY  - EJOU
AU  - Ruan, Yuling
AU  - Zou, Yanhong
AU  - Chen, Minghui
AU  - Shen, Jingya
TI  - Monitoring the Spatiotemporal Trajectory of Urban Area Hotspots Using the SVM Regression Method Based on NPP-VIIRS Imagery
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 6
SN  - 2220-9964

AB  - Urban area hotspots are considered to be an ideal proxy for spatial heterogeneity of human activity, which is vulnerable to urban expansion. Nighttime light (NTL) images have been extensively employed in monitoring current urbanization dynamics. However, the existing studies related to NTL images mainly concern detection of urban areas, leaving inner spatial differences in urban NTL luminosity poorly explored. In this study, we propose an innovative approach to explore the spatiotemporal trajectory of urban area hotspots using monthly Visible Infrared Imaging Radiometer Suite (VIIRS) NTL images. Firstly, multi-temporal VIIRS NTL intensity was decomposed by time-series analysis to obtain annual stable components after data preprocessing. Secondly, the support vector machine (SVM) regression model was utilized to identify urban area hotspots. In order to ensure the model accuracy, the grid search and cross-validation method was integrated to achieve the optimized model parameters. Finally, we analyzed the spatiotemporal migration trajectory of urban area hotspots by the center of gravity method (i.e., shift distance and angle of urban area hotspot centroid). The results indicate that our method successfully captured urban area hotspots with a regression coefficient over 0.8. Meanwhile, the findings give an intuitive understanding of coupling interaction between urban area hotspots and socioeconomic indicators. This study provides important insights for further decision-making regarding sustainable urban planning.
KW  - urban area hotspot
KW  - nighttime light imagery
KW  - SVM regression
KW  - VIIRS
KW  - urbanization
DO  - 10.3390/ijgi10060415
ER  -
TY  - EJOU
AU  - Geng, Liying
AU  - Che, Tao
AU  - Ma, Mingguo
AU  - Tan, Junlei
AU  - Wang, Haibo
TI  - Corn Biomass Estimation by Integrating Remote Sensing and Long-Term Observation Data Based on Machine Learning Techniques
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 12
SN  - 2072-4292

AB  - The accurate and timely estimation of regional crop biomass at different growth stages is of great importance in guiding crop management decision making. The recent availability of long time series of remote sensing data offers opportunities for crop monitoring. In this paper, four machine learning models, namely random forest (RF), support vector machine (SVM), artificial neural network (ANN), and extreme gradient boosting (XGBoost) were adopted to estimate the seasonal corn biomass based on field observation data and moderate resolution imaging spectroradiometer (MODIS) reflectance data from 2012 to 2019 in the middle reaches of the Heihe River basin, China. Nine variables were selected with the forward feature selection approach from among twenty-seven variables potentially influencing corn biomass: soil-adjusted total vegetation index (SATVI), green ratio vegetation index (GRVI), Nadir_B7 (2105–2155 nm), Nadir_B6 (1628–1652 nm), land surface water index (LSWI), normalized difference vegetation index (NDVI), Nadir_B4 (545–565 nm), and Nadir_B3 (459–479 nm). The results indicated that the corn biomass was suitably estimated (the coefficient of determination (R2) was between 0.72 and 0.78) with the four machine learning models. The XGBoost model performed better than the other three models (R2 = 0.78, root mean squared error (RMSE) = 2.86 t/ha and mean absolute error (MAE) = 1.86 t/ha). Moreover, the RF model was an effective method (R2 = 0.77, RMSE = 2.91 t/ha and MAE = 1.91 t/ha), with a performance comparable to that of the XGBoost model. This study provides a reference for estimating crop biomass from MOD43A4 datasets. In addition, the research demonstrates the potential of machine learning techniques to achieve a relatively accurate estimation of daily corn biomass at a large scale.
KW  - corn
KW  - biomass
KW  - field data
KW  - MODIS
KW  - machine learning models
DO  - 10.3390/rs13122352
ER  -
TY  - EJOU
AU  - Lucanus, Oliver
AU  - Kalacska, Margaret
AU  - Arroyo-Mora, J. P.
AU  - Sousa, Leandro
AU  - Carvalho, Lucélia N.
TI  - Before and After: A Multiscale Remote Sensing Assessment of the Sinop Dam, Mato Grosso, Brazil
T2  - Earth

PY  - 2021
VL  - 2
IS  - 2
SN  - 2673-4834

AB  - Hydroelectric dams are a major threat to rivers in the Amazon. They are known to decrease river connectivity, alter aquatic habitats, and emit greenhouse gases such as carbon dioxide and methane. Multiscale remotely sensed data can be used to assess and monitor hydroelectric dams over time. We analyzed the Sinop dam on the Teles Pires river from high spatial resolution satellite imagery to determine the extent of land cover inundated by its reservoir, and subsequent methane emissions from TROPOMI S-5P data. For two case study areas, we generated 3D reconstructions of important endemic fish habitats from unmanned aerial vehicle photographs. We found the reservoir flooded 189 km2 (low water) to 215 km2 (high water) beyond the extent of the Teles Pires river, with 13–30 m tall forest (131.4 Mg/ha average AGB) the predominant flooded class. We further found the reservoir to be a source of methane enhancement in the region. The 3D model showed the shallow habitat had high complexity important for ichthyofauna diversity. The distinctive habitats of rheophile fishes, and of the unique species assemblage found in the tributaries have been permanently modified following inundation. Lastly, we illustrate immersive visualization options for both the satellite imagery and 3D products.
KW  - conservation
KW  - Cubesat
KW  - satellite
KW  - UAV
KW  - PlanetScope
KW  - LiDAR
KW  - SfM photogrammetry
KW  - fish
KW  - freshwater
KW  - TROPOMI
KW  - GLAS
KW  - virtual reality
KW  - VR
DO  - 10.3390/earth2020018
ER  -
TY  - EJOU
AU  - Zeng, Linglin
AU  - Hu, Yuchao
AU  - Wang, Rui
AU  - Zhang, Xiang
AU  - Peng, Guozhang
AU  - Huang, Zhenyu
AU  - Zhou, Guoqing
AU  - Xiang, Daxiang
AU  - Meng, Ran
AU  - Wu, Weixiong
AU  - Hu, Shun
TI  - 8-Day and Daily Maximum and Minimum Air Temperature Estimation via Machine Learning Method on a Climate Zone to Global Scale
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 12
SN  - 2072-4292

AB  - Air temperature (Ta) is a required input in a wide range of applications, e.g., agriculture. Land Surface Temperature (LST) products from Moderate Resolution Imaging Spectroradiometer (MODIS) are widely used to estimate Ta. Previous studies of these products in Ta estimation, however, were generally applied in small areas and with a small number of meteorological stations. This study designed both temporal and spatial experiments to estimate 8-day and daily maximum and minimum Ta (Tmax and Tmin) on three spatial scales: climate zone, continental and global scales from 2009 to 2018, using the Random Forest (RF) method based on MODIS LST products and other auxiliary data. Factors contributing to the relation between LST and Ta were determined based on physical models and equations. Temporal and spatial experiments were defined by the rules of dividing the training and validation datasets for the RF method, in which the stations selected in the training dataset were all included or not in the validation dataset. The RF model was first trained and validated on each spatial scale, respectively. On a global scale, model accuracy with a determination coefficient (R2) &gt; 0.96 and root mean square error (RMSE) &lt; 1.96 °C and R2 &gt; 0.95 and RMSE &lt; 2.55 °C was achieved for 8-day and daily Ta estimations, respectively, in both temporal and spatial experiments. Then the model was trained and cross-validated on each spatial scale. The results showed that the data size and station distribution of the study area were the main factors influencing the model performance at different spatial scales. Finally, the spatial patterns of the model performance and variable importance were analyzed. Both daytime and nighttime LST had a significant contribution in the 8-day Tmax estimation on all the three spatial scales; while their contribution in daily Tmax estimation varied over different continents or climate zones. This study was expected to improve our understanding of Ta estimation in terms of accuracy variations and influencing variables on different spatial and temporal scales. The future work mainly includes identifying underlying mechanisms of estimation errors and the uncertainty sources of Ta estimation from a local to a global scale.
KW  - MODIS
KW  - air temperature estimation
KW  - remote sensing
KW  - land surface temperature
KW  - nighttime LST
DO  - 10.3390/rs13122355
ER  -
TY  - EJOU
AU  - Planke, Lars J.
AU  - Gardi, Alessandro
AU  - Sabatini, Roberto
AU  - Kistan, Trevor
AU  - Ezer, Neta
TI  - Online Multimodal Inference of Mental Workload for Cognitive Human Machine Systems
T2  - Computers

PY  - 2021
VL  - 10
IS  - 6
SN  - 2073-431X

AB  - With increasingly higher levels of automation in aerospace decision support systems, it is imperative that the human operator maintains the required level of situational awareness in different operational conditions and a central role in the decision-making process. While current aerospace systems and interfaces are limited in their adaptability, a Cognitive Human Machine System (CHMS) aims to perform dynamic, real-time system adaptation by estimating the cognitive states of the human operator. Nevertheless, to reliably drive system adaptation of current and emerging aerospace systems, there is a need to accurately and repeatably estimate cognitive states, particularly for Mental Workload (MWL), in real-time. As part of this study, two sessions were performed during a Multi-Attribute Task Battery (MATB) scenario, including a session for offline calibration and validation and a session for online validation of eleven multimodal inference models of MWL. The multimodal inference model implemented included an Adaptive Neuro Fuzzy Inference System (ANFIS), which was used in different configurations to fuse data from an Electroencephalogram (EEG) model’s output, four eye activity features and a control input feature. The online validation of the ANFIS models produced good results, while the best performing model (containing all four eye activity features and the control input feature) showed an average Mean Absolute Error (MAE) = 0.67 ± 0.18 and Correlation Coefficient (CC) = 0.71 ± 0.15. The remaining six ANFIS models included data from the EEG model’s output, which had an offset discrepancy. This resulted in an equivalent offset for the online multimodal fusion. Nonetheless, the efficacy of these ANFIS models could be confirmed by the pairwise correlation with the task level, where one model demonstrated a CC = 0.77 ± 0.06, which was the highest among all of the ANFIS models tested. Hence, this study demonstrates the suitability for online multimodal fusion of features extracted from EEG signals, eye activity and control inputs to produce an accurate and repeatable inference of MWL.
KW  - mental workload
KW  - EEG
KW  - eye tracking
KW  - control inputs
KW  - closed loop system adaptation
KW  - adaptive automation
KW  - multimodal data fusion
KW  - machine learning
KW  - ANFIS
DO  - 10.3390/computers10060081
ER  -
TY  - EJOU
AU  - Linaza, Maria T.
AU  - Posada, Jorge
AU  - Bund, Jürgen
AU  - Eisert, Peter
AU  - Quartulli, Marco
AU  - Döllner, Jürgen
AU  - Pagani, Alain
AU  - G. Olaizola, Igor
AU  - Barriguinha, Andre
AU  - Moysiadis, Theocharis
AU  - Lucat, Laurent
TI  - Data-Driven Artificial Intelligence Applications for Sustainable Precision Agriculture
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 6
SN  - 2073-4395

AB  - One of the main challenges for the implementation of artificial intelligence (AI) in agriculture includes the low replicability and the corresponding difficulty in systematic data gathering, as no two fields are exactly alike. Therefore, the comparison of several pilot experiments in different fields, weather conditions and farming techniques enhances the collective knowledge. Thus, this work provides a summary of the most recent research activities in the form of research projects implemented and validated by the authors in several European countries, with the objective of presenting the already achieved results, the current investigations and the still open technical challenges. As an overall conclusion, it can be mentioned that even though in their primary stages in some cases, AI technologies improve decision support at farm level, monitoring conditions and optimizing production to allow farmers to apply the optimal number of inputs for each crop, thereby boosting yields and reducing water use and greenhouse gas emissions. Future extensions of this work will include new concepts based on autonomous and intelligent robots for plant and soil sample retrieval, and effective livestock management.
KW  - agriculture
KW  - artificial intelligence
KW  - data analysis
KW  - computer vision
KW  - robotics
DO  - 10.3390/agronomy11061227
ER  -
TY  - EJOU
AU  - Lee, Thomas
AU  - Mckeever, Susan
AU  - Courtney, Jane
TI  - Flying Free: A Research Overview of Deep Learning in Drone Navigation Autonomy
T2  - Drones

PY  - 2021
VL  - 5
IS  - 2
SN  - 2504-446X

AB  - With the rise of Deep Learning approaches in computer vision applications, significant strides have been made towards vehicular autonomy. Research activity in autonomous drone navigation has increased rapidly in the past five years, and drones are moving fast towards the ultimate goal of near-complete autonomy. However, while much work in the area focuses on specific tasks in drone navigation, the contribution to the overall goal of autonomy is often not assessed, and a comprehensive overview is needed. In this work, a taxonomy of drone navigation autonomy is established by mapping the definitions of vehicular autonomy levels, as defined by the Society of Automotive Engineers, to specific drone tasks in order to create a clear definition of autonomy when applied to drones. A top–down examination of research work in the area is conducted, focusing on drone navigation tasks, in order to understand the extent of research activity in each area. Autonomy levels are cross-checked against the drone navigation tasks addressed in each work to provide a framework for understanding the trajectory of current research. This work serves as a guide to research in drone autonomy with a particular focus on Deep Learning-based solutions, indicating key works and areas of opportunity for development of this area in the future.
KW  - artificial intelligence
KW  - deep learning
KW  - neural networks
KW  - artificial neural networks
KW  - multi-layer neural network
KW  - neural network hardware
KW  - autonomous systems
KW  - internet of things
KW  - machine vision
KW  - unmanned autonomous vehicles
KW  - unmanned aerial vehicles
DO  - 10.3390/drones5020052
ER  -
TY  - EJOU
AU  - Marin, Ivana
AU  - Mladenović, Saša
AU  - Gotovac, Sven
AU  - Zaharija, Goran
TI  - Deep-Feature-Based Approach to Marine Debris Classification
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 12
SN  - 2076-3417

AB  - The global community has recognized an increasing amount of pollutants entering oceans and other water bodies as a severe environmental, economic, and social issue. In addition to prevention, one of the key measures in addressing marine pollution is the cleanup of debris already present in marine environments. Deployment of machine learning (ML) and deep learning (DL) techniques can automate marine waste removal, making the cleanup process more efficient. This study examines the performance of six well-known deep convolutional neural networks (CNNs), namely VGG19, InceptionV3, ResNet50, Inception-ResNetV2, DenseNet121, and MobileNetV2, utilized as feature extractors according to three different extraction schemes for the identification and classification of underwater marine debris. We compare the performance of a neural network (NN) classifier trained on top of deep CNN feature extractors when the feature extractor is (1) fixed; (2) fine-tuned on the given task; (3) fixed during the first phase of training and fine-tuned afterward. In general, fine-tuning resulted in better-performing models but is much more computationally expensive. The overall best NN performance showed the fine-tuned Inception-ResNetV2 feature extractor with an accuracy of 91.40% and F1-score 92.08%, followed by fine-tuned InceptionV3 extractor. Furthermore, we analyze conventional ML classifiers’ performance when trained on features extracted with deep CNNs. Finally, we show that replacing NN with a conventional ML classifier, such as support vector machine (SVM) or logistic regression (LR), can further enhance the classification performance on new data.
KW  - deep learning
KW  - marine litter classification
KW  - feature vectors
KW  - transfer learning
KW  - computer vision
DO  - 10.3390/app11125644
ER  -
TY  - EJOU
AU  - Barbosa, Brenon D.
AU  - Araújo e Silva Ferraz, Gabriel
AU  - Mendes dos Santos, Luana
AU  - Santana, Lucas S.
AU  - Bedin Marin, Diego
AU  - Rossi, Giuseppe
AU  - Conti, Leonardo
TI  - Application of RGB Images Obtained by UAV in Coffee Farming
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 12
SN  - 2072-4292

AB  - The objective of this study was to evaluate the potential of the practical application of unmanned aerial vehicles and RGB vegetation indices (VIs) in the monitoring of a coffee crop. The study was conducted in an experimental coffee field over a 12-month period. An RGB digital camera coupled to a UAV was used. Nine VIs were evaluated in this study. These VIs were subjected to a Pearson correlation analysis with the leaf area index (LAI), and subsequently, the VIs with higher R2 values were selected. The LAI was estimated by plant height and crown diameter values obtained by imaging, which were correlated with these values measured in the field. Among the VIs evaluated, MPRI (0.31) and GLI (0.41) presented greater correlation with LAI; however, the correlation was weak. Thematic maps of VIs in the evaluated period showed variability present in the crop. The evolution of weeds in the planting rows was noticeable with both VIs, which can help managers to make the decision to start crop management, thus saving resources. The results show that the use of low-cost UAVs and RGB cameras has potential for monitoring the coffee production cycle, providing producers with information in a more accurate, quick and simple way.
KW  - coffee
KW  - precision agriculture
KW  - unmanned aerial vehicle–UAV
KW  - drone
DO  - 10.3390/rs13122397
ER  -
TY  - EJOU
AU  - Teillet, Claire
AU  - Pillot, Benjamin
AU  - Catry, Thibault
AU  - Demagistri, Laurent
AU  - Lyszczarz, Dominique
AU  - Lang, Marc
AU  - Couteron, Pierre
AU  - Barbier, Nicolas
AU  - Adou Kouassi, Arsène
AU  - Gunther, Quentin
AU  - Dessay, Nadine
TI  - Fast Unsupervised Multi-Scale Characterization of Urban Landscapes Based on Earth Observation Data
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 12
SN  - 2072-4292

AB  - Most remote sensing studies of urban areas focus on a single scale, using supervised methodologies and very few analyses focus on the “neighborhood” scale. The lack of multi-scale analysis, together with the scarcity of training and validation datasets in many countries lead us to propose a single fast unsupervised method for the characterization of urban areas. With the FOTOTEX algorithm, this paper introduces a texture-based method to characterize urban areas at three nested scales: macro-scale (urban footprint), meso-scale (“neighbourhoods”) and micro-scale (objects). FOTOTEX combines a Fast Fourier Transform and a Principal Component Analysis to convert texture into frequency signal. Several parameters were tested over Sentinel-2 and Pleiades imagery on Bouake and Brasilia. Results showed that a single Sentinel-2 image better assesses the urban footprint than the global products. Pleiades images allowed discriminating neighbourhoods and urban objects using texture, which is correlated with metrics such as building density, built-up and vegetation proportions. The best configurations for each scale of analysis were determined and recommendations provided to users. The open FOTOTEX algorithm demonstrated a strong potential to characterize the three nested scales of urban areas, especially when training and validation data are scarce, and computing resources limited.
KW  - remote sensing
KW  - multi-scale
KW  - unsupervised
KW  - urban landscapes
KW  - texture
DO  - 10.3390/rs13122398
ER  -
TY  - EJOU
AU  - Perich, Gregor
AU  - Aasen, Helge
AU  - Verrelst, Jochem
AU  - Argento, Francesco
AU  - Walter, Achim
AU  - Liebisch, Frank
TI  - Crop Nitrogen Retrieval Methods for Simulated Sentinel-2 Data Using In-Field Spectrometer Data
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 12
SN  - 2072-4292

AB  - Nitrogen (N) is one of the key nutrients supplied in agricultural production worldwide. Over-fertilization can have negative influences on the field and the regional level (e.g., agro-ecosystems). Remote sensing of the plant N of field crops presents a valuable tool for the monitoring of N flows in agro-ecosystems. Available data for validation of satellite-based remote sensing of N is scarce. Therefore, in this study, field spectrometer measurements were used to simulate data of the Sentinel-2 (S2) satellites developed for vegetation monitoring by the ESA. The prediction performance of normalized ratio indices (NRIs), random forest regression (RFR) and Gaussian processes regression (GPR) for plant-N-related traits was assessed on a diverse real-world dataset including multiple crops, field sites and years. The plant N traits included the mass-based N measure, N concentration in the biomass (Nconc), and an area-based N measure approximating the plant N uptake (NUP). Spectral indices such as normalized ratio indices (NRIs) performed well, but the RFR and GPR methods outperformed the NRIs. Key spectral bands for each trait were identified using the RFR variable importance measure and the Gaussian processes regression band analysis tool (GPR-BAT), highlighting the importance of the short-wave infrared (SWIR) region for estimation of plant Nconc—and to a lesser extent the NUP. The red edge (RE) region was also important. The GPR-BAT showed that five bands were sufficient for plant N trait and leaf area index (LAI) estimation and that a surplus of bands effectively reduced prediction performance. A global sensitivity analysis (GSA) was performed on all traits simultaneously, showing the dominance of the LAI in the mixed remote sensing signal. To delineate the plant-N-related traits from this signal, regional and/or national data collection campaigns producing large crop spectral libraries (CSL) are needed. An improved database will likely enable the mapping of N at the agro-ecosystem level or for use in precision farming by farmers in the future.
KW  - nitrogen
KW  - chlorophyll
KW  - leaf area index
KW  - agro-ecosystem monitoring
KW  - spectral indices
KW  - random forest
KW  - gaussian processes regression
KW  - ARTMO toolbox
DO  - 10.3390/rs13122404
ER  -
TY  - EJOU
AU  - Tian, Luo
AU  - Qu, Yonghua
AU  - Qi, Jianbo
TI  - Estimation of Forest LAI Using Discrete Airborne LiDAR: A Review
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 12
SN  - 2072-4292

AB  - The leaf area index (LAI) is an essential input parameter for quantitatively studying the energy and mass balance in soil-vegetation-atmosphere transfer systems. As an active remote sensing technology, light detection and ranging (LiDAR) provides a new method to describe forest canopy LAI. This paper reviewed the primary LAI retrieval methods using point cloud data (PCD) obtained by discrete airborne LiDAR scanner (DALS), its validation scheme, and its limitations. There are two types of LAI retrieval methods based on DALS PCD, i.e., the empirical regression and the gap fraction (GF) model. In the empirical model, tree height-related variables, LiDAR penetration indexes (LPIs), and canopy cover are the most widely used proxy variables. The height-related proxies are used most frequently; however, the LPIs proved the most efficient proxy. The GF model based on the Beer-Lambert law has been proven useful to estimate LAI; however, the suitability of LPIs is site-, tree species-, and LiDAR system-dependent. In the local validation in previous studies, poor scalability of both empirical and GF models in time, space, and across different DALS systems was observed, which means that field measurements are still needed to calibrate both types of models. The method to correct the impact from the clumping effect and woody material using DALS PCD and the saturation effect for both empirical and GF models still needs further exploration. Of most importance, further work is desired to emphasize assessing the transferability of published methods to new geographic contexts, different DALS sensors, and survey characteristics, based on figuring out the influence of each factor on the LAI retrieval process using DALS PCD. In addition, from a methodological perspective, taking advantage of DALS PCD in characterizing the 3D structure of the canopy, making full use of the ability of machine learning methods in the fusion of multisource data, developing a spatiotemporal scalable model of canopy structure parameters including LAI, and using multisource and heterogeneous data are promising areas of research.
KW  - leaf area index (LAI)
KW  - airborne laser scanner (ALS)
KW  - discrete airborne LiDAR scanner (DALS)
KW  - LiDAR
KW  - LiDAR penetration index (LPI)
DO  - 10.3390/rs13122408
ER  -
TY  - EJOU
AU  - Sharafat, Abubakar
AU  - Khan, Muhammad S.
AU  - Latif, Kamran
AU  - Tanoli, Waqas A.
AU  - Park, Wonyoung
AU  - Seo, Jongwon
TI  - BIM-GIS-Based Integrated Framework for Underground Utility Management System for Earthwork Operations
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 12
SN  - 2076-3417

AB  - Underground utilities are important assets that provide basic services for society’s daily life. They are generally very complex and remain unnoticed until they fail due to any particular reason. The stakeholders involved in the design, construction, and maintenance of utility infrastructure face many problems due to the traditional underground utility management system, resulting in injuries, loss of life, disruptions, project delays, and financial loss. The problem with the traditional system is that it uses 2D drawings and keeps unreliable information or a lack of updated information, which makes it an inefficient utility management system. With the advancement in construction information technology, we can address this effectively by integrating BIM and GIS. In this paper, a novel integrated BIM-GIS framework for underground utility management systems was developed on the basis of IFC to CityGML mapping. It provides an effective underground utility management system that facilitates designers in optimization of the design, assists in the excavator’s operator by providing real-time three-dimensional spatial information during the construction process, and acts as an as-built information database for utility facility management. For validation, a real-time project case study indicated that the proposed system can effectively provide comprehensive underground utility information at different project stages.
KW  - BIM
KW  - GIS
KW  - underground utility management
KW  - machine guidance system
KW  - advanced construction technologies
KW  - construction management
DO  - 10.3390/app11125721
ER  -
TY  - EJOU
AU  - Shah, Junaid
AU  - Wang, Xiukang
AU  - Khan, Sami U.
AU  - Khan, Sajjad
AU  - Gurmani, Zulfiqar A.
AU  - Fiaz, Sajid
AU  - Qayyum, Abdul
TI  - Optical-Sensor-Based Nitrogen Management in Oat for Yield Enhancement
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 12
SN  - 2071-1050

AB  - The deficiency of nitrogen (N) in soil restricts agricultural productivity and its overdosage pollutes the atmosphere. Nitrogen is a vital component of protein, chlorophyll and various physiological processes. When it is applied at a recommended dose, it may be lost through fixation, leaching, volatilization and denitrification, etc. Therefore, there is a dire need to harmonize the supply of nitrogen according to crop and soil requirements. Under this situation, precision nitrogen management is one of the best options. GreenSeekerTM is an integrated optical sensor with a variable application rate and mapping system that measures crops’ nitrogen requirements. To ascertain the abovementioned facts, a research study was conducted at the National Agriculture Research Center, Islamabad, Pakistan, to examine the response of fodder oat to nitrogen management (N0 = control, N1 = 80 kg ha−1 basal dose, N2 = 40 + 40 kg ha−1 split doses, N3 = 40 kg ha−1 with one-time management with GreenSeekerTM and N4 = 20 kg ha−1 with two-time management with GreenSeekerTM) and seed rate (S1 = 80, S2 = 100, S3 = 120 and S4 = 140 kg ha−1). Data were recorded on the agronomic and physiological aspects of the crop and economic analysis was performed for GreenSeekerTM-based N application against the conventional recommended dose of nitrogen application. Mean values showed that greater number of tillers plant−1 (6), fresh weight (16572 kg) and photosynthetic rate (11.64 mmol m−2 s−1) were noted in the treatment N4 (20 kg ha−1 and two-time management with GreenSeekerTM). Greater plant height (70.8 cm) and leaf area (64.14 cm2) were recorded in treatment N2 (40 + 40 kg ha−1 split doses) as compared to the control. The effects of nitrogen on fodder oat were forecasted through NDVI. The results suggested that nitrogen treatment N4 (18 kg ha−1) managed by GreenSeeker in the PARC Oat cultivar produced the maximum NDVI value (0.68) at the booting stage among all treatments. The correlation of NDVI at the tillering and booting stages with green fodder yield was positive (R2 = 0.80). Therefore, the tillering and booting stages can be good depictive stages at early and later growth stages of fodder oat under the agro-climatic conditions of Islamabad, Pakistan. Based on the results, it is recommended to apply an initial dose of 20 kg ha−1 nitrogen along with two-time management with GreenSeekerTM for obtaining more green fodder yield in fodder oat. In Crux, with N1, a total of 80 kg ha−1 nitrogen was applied to achieve an estimated net profitability of USD 582.13. With N4, a total 58 kg ha−1 nitrogen was used to achieve a net profitability of USD 836.16; therefore, this treatment was found to be environmentally safe as compared to N1 (80 kg ha−1).
KW  - oat
KW  - nitrogen management
KW  - GreenSeekerTM
KW  - seed rate
KW  - fodder yield
DO  - 10.3390/su13126955
ER  -
TY  - EJOU
AU  - Chen, Fang
TI  - Comparing Methods for Segmenting Supra-Glacial Lakes and Surface Features in the Mount Everest Region of the Himalayas Using Chinese GaoFen-3 SAR Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - Glaciers and numerous glacial lakes that are produced by glacier melting are key indicators of climate change. Often overlooked, supra-glacial lakes develop in the melting area in the low-lying part of a glacier and appear to be highly variable in their size, shape, and location. The lifespan of these lakes is thought to be quite transient, since the lakes may be completely filled by water and burst out within several weeks. Changes in supra-glacial lake outlines and other surface features such as supra-glacial rivers and crevasses on the glaciers are useful indicators for the direct monitoring of glacier changes. Synthetic aperture radar (SAR) is not affected by weather and climate, and is an effective tool for study of glaciated areas. The development of the Chinese GaoFen-3 (GF-3) SAR, which has high spatial and temporal resolution and high-precision observation performance, has made it possible to obtain dynamic information about glaciers in more detail. In this paper, the classical Canny operator, the variational B-spline level-set method, and U-Net-based deep-learning model were applied and compared to extract glacial lake outlines and other surface features using different modes and Chinese GF-3 SAR imagery in the Mount Everest Region of the Himalayas. Particularly, the U-Net-based deep-learning method, which was independent of auxiliary data and had a high degree of automation, was used for the first time in this context. The experimental results showed that the U-Net-based deep-learning model worked best in the segmentation of supra-glacial lakes in terms of accuracy (Precision = 98.45% and Recall = 95.82%) and segmentation efficiency, and was good at detecting small, elongated, and ice-covered supra-glacial lakes. We also found that it was useful for accurately identifying the location of supra-glacial streams and ice crevasses on glaciers, and quantifying their width. Finally, based on the time series of the mapping results, the spatial characteristics and temporal evolution of these features over the glaciers were comprehensively analyzed. Overall, this study presents a novel approach to improve the detection accuracy of glacier elements that could be leveraged for dynamic monitoring in future research.
KW  - GF-3
KW  - supra-glacial lakes
KW  - supra-glacial streams
KW  - ice crevasses
KW  - segmentation
KW  - digital disaster reduction
DO  - 10.3390/rs13132429
ER  -
TY  - EJOU
AU  - Calamita, Federico
AU  - Imran, Hafiz A.
AU  - Vescovo, Loris
AU  - Mekhalfi, Mohamed L.
AU  - La Porta, Nicola
TI  - Early Identification of Root Rot Disease by Using Hyperspectral Reflectance: The Case of Pathosystem Grapevine/Armillaria
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - Armillaria genus represents one of the most common causes of chronic root rot disease in woody plants. Prompt recognition of diseased plants is crucial to control the pathogen. However, the current disease detection methods are limited at a field scale. Therefore, an alternative approach is needed. In this study, we investigated the potential of hyperspectral techniques to identify fungi-infected vs. healthy plants of Vitis vinifera. We used the hyperspectral imaging sensor Specim-IQ to acquire leaves’ reflectance data of the Teroldego Rotaliano grapevine cultivar. We analyzed three different groups of plants: healthy, asymptomatic, and diseased. Highly significant differences were found in the near-infrared (NIR) spectral region with a decreasing pattern from healthy to diseased plants attributable to the leaf mesophyll changes. Asymptomatic plants emerged from the other groups due to a lower reflectance in the red edge spectrum (around 705 nm), ascribable to an accumulation of secondary metabolites involved in plant defense strategies. Further significant differences were observed in the wavelengths close to 550 nm in diseased vs. asymptomatic plants. We evaluated several machine learning paradigms to differentiate the plant groups. The Naïve Bayes (NB) algorithm, combined with the most discriminant variables among vegetation indices and spectral narrow bands, provided the best results with an overall accuracy of 90% and 75% in healthy vs. diseased and healthy vs. asymptomatic plants, respectively. To our knowledge, this study represents the first report on the possibility of using hyperspectral data for root rot disease diagnosis in woody plants. Although further validation studies are required, it appears that the spectral reflectance technique, possibly implemented on unmanned aerial vehicles (UAVs), could be a promising tool for a cost-effective, non-invasive method of Armillaria disease diagnosis and mapping in-field, contributing to a significant step forward in precision viticulture.
KW  - agriculture 4.0
KW  - chlorophyll
KW  - early diagnosis
KW  - fungal tree pathogens
KW  - mycology
KW  - plant disease
KW  - plant pathology
KW  - smart viticulture
KW  - vegetation indices
KW  - wine grapes
DO  - 10.3390/rs13132436
ER  -
TY  - EJOU
AU  - Lan, Tingting
AU  - Qin, Danyang
AU  - Sun, Guanyu
TI  - Joint Optimization on Trajectory, Cache Placement, and Transmission Power for Minimum Mission Time in UAV-Aided Wireless Networks
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 7
SN  - 2220-9964

AB  - In recent years, due to the strong mobility, easy deployment, and low cost of unmanned aerial vehicles (UAV), great interest has arisen in utilizing UAVs to assist in wireless communication, especially for on-demand deployment in emergency situations and temporary events. However, UAVs can only provide users with data transmission services through wireless backhaul links established with a ground base station, and the limited capacity of the wireless backhaul link would limit the transmission speed of UAVs. Therefore, this paper designed a UAV-assisted wireless communication system that used cache technology and realized the transmission of multi-user data by using the mobility of UAVs and wireless cache technology. Considering the limited storage space and energy of UAVs, the joint optimization problem of the UAV’s trajectory, cache placement, and transmission power was established to minimize the mission time of the UAV. Since this problem was a non-convex problem, it was decomposed into three sub-problems: trajectory optimization, cache placement optimization, and power allocation optimization. An iterative algorithm based on the successive convex approximation and alternate optimization techniques was proposed to solve these three optimization problems. Finally, in the power allocation optimization, the proposed algorithm was improved by changing the optimization objective function. Numerical results showed that the algorithm had good performance and could effectively reduce the task completion time of the UAV.
KW  - UAV
KW  - trajectory
KW  - cache placement
KW  - transmission power
DO  - 10.3390/ijgi10070426
ER  -
TY  - EJOU
AU  - Al-Dhaqm, Arafat
AU  - Ikuesan, Richard A.
AU  - Kebande, Victor R.
AU  - Razak, Shukor
AU  - Ghabban, Fahad M.
TI  - Research Challenges and Opportunities in Drone Forensics Models
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 13
SN  - 2079-9292

AB  - The emergence of unmanned aerial vehicles (also referred to as drones) has transformed the digital landscape of surveillance and supply chain logistics, especially in terrains where such was previously deemed unattainable. Moreover, the adoption of drones has further led to the proliferation of diverse drone types and drone-related criminality, which has introduced a myriad of security and forensics-related concerns. As a step towards understanding the state-of-the-art research into these challenges and potential approaches to mitigation, this study provides a detailed review of existing digital forensic models using the Design Science Research method. The outcome of this study generated in-depth knowledge of the research challenges and opportunities through which an effective investigation can be carried out on drone-related incidents. Furthermore, a potential generic investigation model has been proposed. The findings presented in this study are essentially relevant to forensic researchers and practitioners towards a guided methodology for drone-related event investigation. Ultimately, it is important to mention that this study presents a background for the development of international standardization for drone forensics.
KW  - drone forensics
KW  - unmanned aerial vehicles (UAV)
KW  - digital forensics
DO  - 10.3390/electronics10131519
ER  -
TY  - EJOU
AU  - Ahvar, Ehsan
AU  - Ahvar, Shohreh
AU  - Raza, Syed M.
AU  - Manuel Sanchez Vilchez, Jose
AU  - Lee, Gyu M.
TI  - Next Generation of SDN in Cloud-Fog for 5G and Beyond-Enabled Applications: Opportunities and Challenges
T2  - Network

PY  - 2021
VL  - 1
IS  - 1
SN  - 2673-8732

AB  - In recent years, the number of objects connected to the internet have significantly increased. Increasing the number of connected devices to the internet is transforming today’s Internet of Things (IoT) into massive IoT of the future. It is predicted that, in a few years, a high communication and computation capacity will be required to meet the demands of massive IoT devices and applications requiring data sharing and processing. 5G and beyond mobile networks are expected to fulfill a part of these requirements by providing a data rate of up to terabits per second. It will be a key enabler to support massive IoT and emerging mission critical applications with strict delay constraints. On the other hand, the next generation of software-defined networking (SDN) with emerging cloudrelated technologies (e.g., fog and edge computing) can play an important role in supporting and implementing the above-mentioned applications. This paper sets out the potential opportunities and important challenges that must be addressed in considering options for using SDN in hybrid cloud-fog systems to support 5G and beyond-enabled applications.
KW  - SDN
KW  - cloud computing
KW  - 5G
KW  - 6G
KW  - fog computing
KW  - challenge
KW  - massive IoT
DO  - 10.3390/network1010004
ER  -
TY  - EJOU
AU  - Martos, Vanesa
AU  - Ahmad, Ali
AU  - Cartujo, Pedro
AU  - Ordoñez, Javier
TI  - Ensuring Agricultural Sustainability through Remote Sensing in the Era of Agriculture 5.0
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 13
SN  - 2076-3417

AB  - Timely and reliable information about crop management, production, and yield is considered of great utility by stakeholders (e.g., national and international authorities, farmers, commercial units, etc.) to ensure food safety and security. By 2050, according to Food and Agriculture Organization (FAO) estimates, around 70% more production of agricultural products will be needed to fulfil the demands of the world population. Likewise, to meet the Sustainable Development Goals (SDGs), especially the second goal of “zero hunger”, potential technologies like remote sensing (RS) need to be efficiently integrated into agriculture. The application of RS is indispensable today for a highly productive and sustainable agriculture. Therefore, the present study draws a general overview of RS technology with a special focus on the principal platforms of this technology, i.e., satellites and remotely piloted aircrafts (RPAs), and the sensors used, in relation to the 5th industrial revolution. Nevertheless, since 1957, RS technology has found applications, through the use of satellite imagery, in agriculture, which was later enriched by the incorporation of remotely piloted aircrafts (RPAs), which is further pushing the boundaries of proficiency through the upgrading of sensors capable of higher spectral, spatial, and temporal resolutions. More prominently, wireless sensor technologies (WST) have streamlined real time information acquisition and programming for respective measures. Improved algorithms and sensors can, not only add significant value to crop data acquisition, but can also devise simulations on yield, harvesting and irrigation periods, metrological data, etc., by making use of cloud computing. The RS technology generates huge sets of data that necessitate the incorporation of artificial intelligence (AI) and big data to extract useful products, thereby augmenting the adeptness and efficiency of agriculture to ensure its sustainability. These technologies have made the orientation of current research towards the estimation of plant physiological traits rather than the structural parameters possible. Futuristic approaches for benefiting from these cutting-edge technologies are discussed in this study. This study can be helpful for researchers, academics, and young students aspiring to play a role in the achievement of sustainable agriculture.
KW  - agriculture 5.0
KW  - drones
KW  - remotely piloted aircrafts (RPAs)
KW  - precision agriculture
KW  - remote sensing
KW  - Internet of Things (IoT)
KW  - digital agriculture
KW  - sustainable development goals
KW  - sensors
KW  - agricultural robots
DO  - 10.3390/app11135911
ER  -
TY  - EJOU
AU  - Meng, Baoping
AU  - Yang, Zhigui
AU  - Yu, Hongyan
AU  - Qin, Yu
AU  - Sun, Yi
AU  - Zhang, Jianguo
AU  - Chen, Jianjun
AU  - Wang, Zhiwei
AU  - Zhang, Wei
AU  - Li, Meng
AU  - Lv, Yanyan
AU  - Yi, Shuhua
TI  - Mapping of Kobresia pygmaea Community Based on Umanned Aerial Vehicle Technology and Gaofen Remote Sensing Data in Alpine Meadow Grassland: A Case Study in Eastern of Qinghai–Tibetan Plateau
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - The Kobresia pygmaea (KP) community is a key succession stage of alpine meadow degradation on the Qinghai–Tibet Plateau (QTP). However, most of the grassland classification and mapping studies have been performed at the grassland type level. The spatial distribution and impact factors of KP on the QTP are still unclear. In this study, field measurements of the grassland vegetation community in the eastern part of the QTP (Counties of Zeku, Henan and Maqu) from 2015 to 2019 were acquired using unmanned aerial vehicle (UAV) technology. The machine learning algorithms for grassland vegetation community classification were constructed by combining Gaofen satellite images and topographic indices. Then, the spatial distribution of KP community was mapped. The results showed that: (1) For all field observed sites, the alpine meadow vegetation communities demonstrated a considerable spatial heterogeneity. The traditional classification methods can hardly distinguish those communities due to the high similarity of their spectral characteristics. (2) The random forest method based on the combination of satellite vegetation indices, texture feature and topographic indices exhibited the best performance in three counties, with overall accuracy and Kappa coefficient ranged from 74.06% to 83.92% and 0.65 to 0.80, respectively. (3) As a whole, the area of KP community reached 1434.07 km2, and accounted for 7.20% of the study area. We concluded that the combination of satellite remote sensing, UAV surveying and machine learning can be used for KP classification and mapping at community level.
KW  - Kobresia pygmaea community
KW  - unmanned aerial vehicle
KW  - Gaofen satellite
KW  - spatial distribution
DO  - 10.3390/rs13132483
ER  -
TY  - EJOU
AU  - Ouhami, Maryam
AU  - Hafiane, Adel
AU  - Es-Saady, Youssef
AU  - El Hajji, Mohamed
AU  - Canals, Raphael
TI  - Computer Vision, IoT and Data Fusion for Crop Disease Detection Using Machine Learning: A Survey and Ongoing Research
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - Crop diseases constitute a serious issue in agriculture, affecting both quality and quantity of agriculture production. Disease control has been a research object in many scientific and technologic domains. Technological advances in sensors, data storage, computing resources and artificial intelligence have shown enormous potential to control diseases effectively. A growing body of literature recognizes the importance of using data from different types of sensors and machine learning approaches to build models for detection, prediction, analysis, assessment, etc. However, the increasing number and diversity of research studies requires a literature review for further developments and contributions in this area. This paper reviews state-of-the-art machine learning methods that use different data sources, applied to plant disease detection. It lists traditional and deep learning methods associated with the main data acquisition modalities, namely IoT, ground imaging, unmanned aerial vehicle imaging and satellite imaging. In addition, this study examines the role of data fusion for ongoing research in the context of disease detection. It highlights the advantage of intelligent data fusion techniques, from heterogeneous data sources, to improve plant health status prediction and presents the main challenges facing this field. The study concludes with a discussion of several current issues and research trends.
KW  - plant disease
KW  - machine learning
KW  - remote sensing
KW  - intelligent sensors
KW  - data fusion
DO  - 10.3390/rs13132486
ER  -
TY  - EJOU
AU  - Fu, Wei
AU  - Yu, Shuang
AU  - Wang, Xin
TI  - A Novel Method to Determine Basic Probability Assignment Based on Adaboost and Its Application in Classification
T2  - Entropy

PY  - 2021
VL  - 23
IS  - 7
SN  - 1099-4300

AB  - In the framework of evidence theory, one of the open and crucial issues is how to determine the basic probability assignment (BPA), which is directly related to whether the decision result is correct. This paper proposes a novel method for obtaining BPA based on Adaboost. The method uses training data to generate multiple strong classifiers for each attribute model, which is used to determine the BPA of the singleton proposition since the weights of classification provide necessary information for fundamental hypotheses. The BPA of the composite proposition is quantified by calculating the area ratio of the singleton proposition’s intersection region. The recursive formula of the area ratio of the intersection region is proposed, which is very useful for computer calculation. Finally, BPAs are combined by Dempster’s rule of combination. Using the proposed method to classify the Iris dataset, the experiment concludes that the total recognition rate is 96.53% and the classification accuracy is 90% when the training percentage is 10%. For the other datasets, the experiment results also show that the proposed method is reasonable and effective, and the proposed method performs well in the case of insufficient samples.
KW  - Dempster-Shafer evidence theory
KW  - basic probability assignment
KW  - Adaboost
KW  - multiple strong classifiers
KW  - area ratio of the intersection region
DO  - 10.3390/e23070812
ER  -
TY  - EJOU
AU  - Nabwire, Shona
AU  - Suh, Hyun-Kwon
AU  - Kim, Moon S.
AU  - Baek, Insuck
AU  - Cho, Byoung-Kwan
TI  - Review: Application of Artificial Intelligence in Phenomics
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 13
SN  - 1424-8220

AB  - Plant phenomics has been rapidly advancing over the past few years. This advancement is attributed to the increased innovation and availability of new technologies which can enable the high-throughput phenotyping of complex plant traits. The application of artificial intelligence in various domains of science has also grown exponentially in recent years. Notably, the computer vision, machine learning, and deep learning aspects of artificial intelligence have been successfully integrated into non-invasive imaging techniques. This integration is gradually improving the efficiency of data collection and analysis through the application of machine and deep learning for robust image analysis. In addition, artificial intelligence has fostered the development of software and tools applied in field phenotyping for data collection and management. These include open-source devices and tools which are enabling community driven research and data-sharing, thereby availing the large amounts of data required for the accurate study of phenotypes. This paper reviews more than one hundred current state-of-the-art papers concerning AI-applied plant phenotyping published between 2010 and 2020. It provides an overview of current phenotyping technologies and the ongoing integration of artificial intelligence into plant phenotyping. Lastly, the limitations of the current approaches/methods and future directions are discussed.
KW  - artificial intelligence
KW  - deep learning
KW  - plant phenomics
KW  - field phenotyping
KW  - high throughput phenotyping
KW  - image-based phenotyping
DO  - 10.3390/s21134363
ER  -
TY  - EJOU
AU  - Shrestha, Rakesh
AU  - Omidkar, Atefeh
AU  - Roudi, Sajjad A.
AU  - Abbas, Robert
AU  - Kim, Shiho
TI  - Machine-Learning-Enabled Intrusion Detection System for Cellular Connected UAV Networks
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 13
SN  - 2079-9292

AB  - The recent development and adoption of unmanned aerial vehicles (UAVs) is due to its wide variety of applications in public and private sector from parcel delivery to wildlife conservation. The integration of UAVs, 5G, and satellite technologies has prompted telecommunication networks to evolve to provide higher-quality and more stable service to remote areas. However, security concerns with UAVs are growing as UAV nodes are becoming attractive targets for cyberattacks due to enormously growing volumes and poor and weak inbuilt security. In this paper, we propose a UAV- and satellite-based 5G-network security model that can harness machine learning to effectively detect of vulnerabilities and cyberattacks. The solution is divided into two main parts: the model creation for intrusion detection using various machine learning (ML) algorithms and the implementation of ML-based model into terrestrial or satellite gateways. The system identifies various attack types using realistic CSE-CIC IDS-2018 network datasets published by Canadian Establishment for Cybersecurity (CIC). It consists of seven different types of new and contemporary attack types. This paper demonstrates that ML algorithms can be used to classify benign or malicious packets in UAV networks to enhance security. Finally, the tested ML algorithms are compared for effectiveness in terms of accuracy rate, precision, recall, F1-score, and false-negative rate. The decision tree algorithm performed well by obtaining a maximum accuracy rate of 99.99% and a minimum false negative rate of 0% in detecting various attacks as compared to all other types of ML classifiers.
KW  - UAV
KW  - machine learning
KW  - intrusion detection system
KW  - cybersecurity attacks
KW  - software-defined security
DO  - 10.3390/electronics10131549
ER  -
TY  - EJOU
AU  - Pu, Junwei
AU  - Zhao, Xiaoqing
AU  - Dong, Pinliang
AU  - Wang, Qian
AU  - Yue, Qifa
TI  - Extracting Information on Rocky Desertification from Satellite Images: A Comparative Study
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - Rocky desertification occurs in many karst terrains of the world and poses major challenges for regional sustainable development. Remotely sensed data can provide important information on rocky desertification. In this study, three common open-access satellite image datasets (Sentinel-2B, Landsat-8, and Gaofen-6) were used for extracting information on rocky desertification in a typical karst region (Guangnan County, Yunnan) of southwest China, using three machine-learning algorithms implemented in the Python programming language: random forest (RF), bagged decision tree (BDT), and extremely randomized trees (ERT). Comparative analyses of the three data sources and three algorithms show that: (1) The Sentinel-2B image has the best capability for extracting rocky desertification information, with an overall accuracy (OA) of 85.21% using the ERT method. This can be attributed to the higher spatial resolution of the Sentinel-2B image than that of Landsat-8 and Gaofen-6 images and Gaofen-6’s lack of the shortwave infrared (SWIR) bands suitable for mapping carbonate rocks. (2) The ERT method has the best classification results of rocky desertification. Compared with the RF and BDT methods, the ERT method has stronger randomness in modeling and can effectively identify important feature factors for extracting information on rocky desertification. (3) The combination of the Sentinel-2B images and the ERT method provides an effective, efficient, and free approach to information extraction for mapping rocky desertification. The study can provide a useful reference for effective mapping of rocky desertification in similar karst environments of the world, in terms of both satellite image sources and classification algorithms. It also provides important information on the total area and spatial distribution of different levels of rocky desertification in the study area to support decision making by local governments for sustainable development.
KW  - rocky desertification
KW  - open-access satellite image
KW  - information extraction
KW  - machine-learning algorithms
KW  - southwest China
DO  - 10.3390/rs13132497
ER  -
TY  - EJOU
AU  - Salehi Hikouei, Iman
AU  - Kim, S. S.
AU  - Mishra, Deepak R.
TI  - Machine-Learning Classification of Soil Bulk Density in Salt Marsh Environments
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 13
SN  - 1424-8220

AB  - Remotely sensed data from both in situ and satellite platforms in visible, near-infrared, and shortwave infrared (VNIR–SWIR, 400–2500 nm) regions have been widely used to characterize and model soil properties in a direct, cost-effective, and rapid manner at different scales. In this study, we assess the performance of machine-learning algorithms including random forest (RF), extreme gradient boosting machines (XGBoost), and support vector machines (SVM) to model salt marsh soil bulk density using multispectral remote-sensing data from the Landsat-7 Enhanced Thematic Mapper Plus (ETM+) platform. To our knowledge, use of remote-sensing data for estimating salt marsh soil bulk density at the vegetation rooting zone has not been investigated before. Our study reveals that blue (band 1; 450–520 nm) and NIR (band 4; 770–900 nm) bands of Landsat-7 ETM+ ranked as the most important spectral features for bulk density prediction by XGBoost and RF, respectively. According to XGBoost, band 1 and band 4 had relative importance of around 41% and 39%, respectively. We tested two soil bulk density classes in order to differentiate salt marshes in terms of their capability to support vegetation that grows in either low (0.032 to 0.752 g/cm3) or high (0.752 g/cm3 to 1.893 g/cm3) bulk density areas. XGBoost produced a higher classification accuracy (88%) compared to RF (87%) and SVM (86%), although discrepancies in accuracy between these models were small (&lt;2%). XGBoost correctly classified 178 out of 186 soil samples labeled as low bulk density and 37 out of 62 soil samples labeled as high bulk density. We conclude that remote-sensing-based machine-learning models can be a valuable tool for ecologists and engineers to map the soil bulk density in wetlands to select suitable sites for effective restoration and successful re-establishment practices.
KW  - soil characterization
KW  - random forest
KW  - XGBoost
KW  - machine learning
KW  - coastal wetlands
KW  - Landsat-7 (ETM+)
DO  - 10.3390/s21134408
ER  -
TY  - EJOU
AU  - Ukaegbu, Uchechi F.
AU  - Tartibu, Lagouge K.
AU  - Okwu, Modestus O.
AU  - Olayode, Isaac O.
TI  - Development of a Light-Weight Unmanned Aerial Vehicle for Precision Agriculture
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 13
SN  - 1424-8220

AB  - This paper describes the development of a modular unmanned aerial vehicle for the detection and eradication of weeds on farmland. Precision agriculture entails solving the problem of poor agricultural yield due to competition for nutrients by weeds and provides a faster approach to eliminating the problematic weeds using emerging technologies. This research has addressed the aforementioned problem. A quadcopter was built, and components were assembled with light-weight materials. The system consists of the electric motor, electronic speed controller, propellers, frame, lithium polymer (li-po) battery, flight controller, a global positioning system (GPS), and receiver. A sprayer module which consists of a relay, Raspberry Pi 3, spray pump, 12 V DC source, water hose, and the tank was built. It operated in such a way that when a weed is detected based on the deep learning algorithms deployed on the Raspberry Pi, general purpose input/output (GPIO) 17 or GPIO 18 (of the Raspberry Pi) were activated to supply 3.3 V, which turned on a DC relay to spray herbicides accordingly. The sprayer module was mounted on the quadcopter and from the test-running operation conducted, broadleaf and grass weeds were accurately detected and the spraying of herbicides according to the weed type occurred in less than a second.
KW  - unmanned aerial vehicle (UAV)
KW  - deep learning
KW  - Raspberry Pi 3
KW  - industry 4.0
KW  - precision agriculture
DO  - 10.3390/s21134417
ER  -
TY  - EJOU
AU  - Murphy, Darren J.
AU  - Murphy, Michael D.
AU  - O’Brien, Bernadette
AU  - O’Donovan, Michael
TI  - A Review of Precision Technologies for Optimising Pasture Measurement on Irish Grassland
T2  - Agriculture

PY  - 2021
VL  - 11
IS  - 7
SN  - 2077-0472

AB  - The development of precision grass measurement technologies is of vital importance to securing the future sustainability of pasture-based livestock production systems. There is potential to increase grassland production in a sustainable manner by achieving a more precise measurement of pasture quantity and quality. This review presents an overview of the most recent seminal research pertaining to the development of precision grass measurement technologies. One of the main obstacles to precision grass measurement, sward heterogeneity, is discussed along with optimal sampling techniques to address this issue. The limitations of conventional grass measurement techniques are outlined and alternative new terrestrial, proximal, and remote sensing technologies are presented. The possibilities of automating grass measurement and reducing labour costs are hypothesised and the development of holistic online grassland management systems that may facilitate these goals are further outlined.
KW  - pasture-based agriculture
KW  - precision agriculture
KW  - remote sensing
KW  - spectroscopy
KW  - grass measurement
KW  - grassland sampling
DO  - 10.3390/agriculture11070600
ER  -
TY  - EJOU
AU  - Al-Nuaimi, Mohammed
AU  - Wibowo, Sapto
AU  - Qu, Hongyang
AU  - Aitken, Jonathan
AU  - Veres, Sandor
TI  - Hybrid Verification Technique for Decision-Making of Self-Driving Vehicles
T2  - Journal of Sensor and Actuator Networks

PY  - 2021
VL  - 10
IS  - 3
SN  - 2224-2708

AB  - The evolution of driving technology has recently progressed from active safety features and ADAS systems to fully sensor-guided autonomous driving. Bringing such a vehicle to market requires not only simulation and testing but formal verification to account for all possible traffic scenarios. A new verification approach, which combines the use of two well-known model checkers: model checker for multi-agent systems (MCMAS) and probabilistic model checker (PRISM), is presented for this purpose. The overall structure of our autonomous vehicle (AV) system consists of: (1) A perception system of sensors that feeds data into (2) a rational agent (RA) based on a belief–desire–intention (BDI) architecture, which uses a model of the environment and is connected to the RA for verification of decision-making, and (3) a feedback control systems for following a self-planned path. MCMAS is used to check the consistency and stability of the BDI agent logic during design-time. PRISM is used to provide the RA with the probability of success while it decides to take action during run-time operation. This allows the RA to select movements of the highest probability of success from several generated alternatives. This framework has been tested on a new AV software platform built using the robot operating system (ROS) and virtual reality (VR) Gazebo Simulator. It also includes a parking lot scenario to test the feasibility of this approach in a realistic environment. A practical implementation of the AV system was also carried out on the experimental testbed.
KW  - self-driving vehicle
KW  - formal verification
KW  - model checking
KW  - rational agent
KW  - decision-making
KW  - ROS
DO  - 10.3390/jsan10030042
ER  -
TY  - EJOU
AU  - Niu, Zijie
AU  - Deng, Juntao
AU  - Zhang, Xu
AU  - Zhang, Jun
AU  - Pan, Shijia
AU  - Mu, Haotian
TI  - Identifying the Branch of Kiwifruit Based on Unmanned Aerial Vehicle (UAV) Images Using Deep Learning Method
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 13
SN  - 1424-8220

AB  - It is important to obtain accurate information about kiwifruit vines to monitoring their physiological states and undertake precise orchard operations. However, because vines are small and cling to trellises, and have branches laying on the ground, numerous challenges exist in the acquisition of accurate data for kiwifruit vines. In this paper, a kiwifruit canopy distribution prediction model is proposed on the basis of low-altitude unmanned aerial vehicle (UAV) images and deep learning techniques. First, the location of the kiwifruit plants and vine distribution are extracted from high-precision images collected by UAV. The canopy gradient distribution maps with different noise reduction and distribution effects are generated by modifying the threshold and sampling size using the resampling normalization method. The results showed that the accuracies of the vine segmentation using PSPnet, support vector machine, and random forest classification were 71.2%, 85.8%, and 75.26%, respectively. However, the segmentation image obtained using depth semantic segmentation had a higher signal-to-noise ratio and was closer to the real situation. The average intersection over union of the deep semantic segmentation was more than or equal to 80% in distribution maps, whereas, in traditional machine learning, the average intersection was between 20% and 60%. This indicates the proposed model can quickly extract the vine distribution and plant position, and is thus able to perform dynamic monitoring of orchards to provide real-time operation guidance.
KW  - deep learning
KW  - unmanned aerial vehicle
KW  - kiwifruit
KW  - image segmentation
DO  - 10.3390/s21134442
ER  -
TY  - EJOU
AU  - Hyyppä, Juha
AU  - Yu, Xiaowei
AU  - Hakala, Teemu
AU  - Kaartinen, Harri
AU  - Kukko, Antero
AU  - Hyyti, Heikki
AU  - Muhojoki, Jesse
AU  - Hyyppä, Eric
TI  - Under-Canopy UAV Laser Scanning Providing Canopy Height and Stem Volume Accurately
T2  - Forests

PY  - 2021
VL  - 12
IS  - 7
SN  - 1999-4907

AB  - The automation of forest field reference data collection has been an intensive research objective for laser scanning scientists ever since the invention of terrestrial laser scanning more than two decades ago. In this study, we demonstrated that an under-canopy UAV laser scanning system utilizing a rotating laser scanner can alone provide accurate estimates of canopy height and stem volume for the majority of trees in a boreal forest. We mounted a rotating laser scanner based on a Velodyne VLP-16 sensor onboard a manually piloted UAV. The UAV was commanded with the help of a live video feed from the onboard camera. Since the system was based on a rotating laser scanner providing varying view angles, all important elements such as treetops, branches, trunks, and ground could be recorded with laser hits. In an experiment including two different forest structures, namely sparse and obstructed canopy, we showed that our system can measure the heights of individual trees with a bias of −20 cm and a standard error of 40 cm in the sparse forest and with a bias of −65 cm and a standard error of 1 m in the obstructed forest. The accuracy of the obtained tree height estimates was equivalent to airborne above-canopy UAV surveys conducted in similar forest conditions or even at the same sites. The higher underestimation and higher inaccuracy in the obstructed site can be attributed to three trees with a height exceeding 25 m and the reduced point density of these tree tops due to occlusion and the limited ranging capacity of the scanner. Additionally, we used our system to estimate the stem volumes of individual trees with a standard error at the level of 10%. This level of error is equivalent to the error obtained when merging above-canopy UAV laser scanner data with terrestrial point cloud data. The results show that we do not necessarily need a combination of terrestrial point clouds and point clouds collected using above-canopy UAV systems in order to accurately estimate the heights and the volumes of individual trees in reference data collection.
KW  - under-canopy
KW  - UAV
KW  - laser scanning
KW  - lidar
KW  - tree height
KW  - stem curve
KW  - stem volume
KW  - automation of field reference
KW  - forest plot
DO  - 10.3390/f12070856
ER  -
TY  - EJOU
AU  - Shin, Jisun
AU  - Jo, Young-Heon
AU  - Ryu, Joo-Hyung
AU  - Khim, Boo-Keun
AU  - Kim, Soo M.
TI  - High Spatial-Resolution Red Tide Detection in the Southern Coast of Korea Using U-Net from PlanetScope Imagery
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 13
SN  - 1424-8220

AB  - Red tides caused by Margalefidinium polykrikoides occur continuously along the southern coast of Korea, where there are many aquaculture cages, and therefore, prompt monitoring of bloom water is required to prevent considerable damage. Satellite-based ocean-color sensors are widely used for detecting red tide blooms, but their low spatial resolution restricts coastal observations. Contrarily, terrestrial sensors with a high spatial resolution are good candidate sensors, despite the lack of spectral resolution and bands for red tide detection. In this study, we developed a U-Net deep learning model for detecting M. polykrikoides blooms along the southern coast of Korea from PlanetScope imagery with a high spatial resolution of 3 m. The U-Net model was trained with four different datasets that were constructed with randomly or non-randomly chosen patches consisting of different ratios of red tide and non-red tide pixels. The qualitative and quantitative assessments of the conventional red tide index (RTI) and four U-Net models suggest that the U-Net model, which was trained with a dataset of non-randomly chosen patches including non-red tide patches, outperformed RTI in terms of sensitivity, precision, and F-measure level, accounting for an increase of 19.84%, 44.84%, and 28.52%, respectively. The M. polykrikoides map derived from U-Net provides the most reasonable red tide patterns in all water areas. Combining high spatial resolution images and deep learning approaches represents a good solution for the monitoring of red tides over coastal regions.
KW  - Margalefidinium polykrikoides
KW  - PlanetScope
KW  - southern coast of Korea
KW  - convolutional neural network
KW  - U-Net
DO  - 10.3390/s21134447
ER  -
TY  - EJOU
AU  - Guo, Xinyi
AU  - Fu, Bihong
AU  - Du, Jie
AU  - Shi, Pilong
AU  - Chen, Qingyu
AU  - Zhang, Wenyuan
TI  - Applicability of Susceptibility Model for Rock and Loess Earthquake Landslides in the Eastern Tibetan Plateau
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - It is crucial to explore a suitable landslide susceptibility model with an excellent prediction capability for rapid evaluation and disaster relief in seismic regions with different lithological features. In this study, we selected two typical seismic events, the Jiuzhaigou and Minxian earthquakes, which occurred in the Alpine karst and loess regions, respectively. Eight influencing factors and five models were chosen to calculate the susceptibility of landslide, including the information (I) model, certainty factor (CF) model, logistic regression (LR) model, I + LR coupling model, and CF + LR coupling model. Then, the accuracy and the landslide susceptibility distribution of these models were assessed by the area under curve (AUC) and distribution criteria. Finally, the model with high accuracy and good applicability for the rock landslide or loess landslide regions was optimized. Our results showed that the accuracy of the coupling model is higher than that of the single models. Except for the LR model, the landslide susceptibility distribution for the above-mentioned models is consistent with universal cognition. The coupling models are generally better than their single models. Among them, the I + LR model can obtain the best comprehensive results for assessing the distribution and accuracy of both rock and loess landslide susceptibility, which is helpful for disaster relief and policy-making, and it can also provide useful scientific data for post-seismic reconstruction and restoration.
KW  - landslide susceptibility
KW  - coupling model
KW  - Jiuzhaigou earthquake
KW  - Minxian earthquake
KW  - rock landslide
KW  - loess landslide
DO  - 10.3390/rs13132546
ER  -
TY  - EJOU
AU  - Habibi, Luthfan N.
AU  - Watanabe, Tomoya
AU  - Matsui, Tsutomu
AU  - Tanaka, Takashi S. T.
TI  - Machine Learning Techniques to Predict Soybean Plant Density Using UAV and Satellite-Based Remote Sensing
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - The plant density of soybean is a critical factor affecting plant canopy structure and yield. Predicting the spatial variability of plant density would be valuable for improving agronomic practices. The objective of this study was to develop a model for plant density measurement using several data sets with different spatial resolutions, including unmanned aerial vehicle (UAV) imagery, PlanetScope satellite imagery, and climate data. The model establishment process includes (1) performing the high-throughput measurement of actual plant density from UAV imagery with the You Only Look Once version 3 (YOLOv3) object detection algorithm, which was further treated as a response variable of the estimation models in the next step, and (2) developing regression models to estimate plant density in the extended areas using various combinations of predictors derived from PlanetScope imagery and climate data. Our results showed that the YOLOv3 model can accurately measure actual soybean plant density from UAV imagery data with a root mean square error (RMSE) value of 0.96 plants m−2. Furthermore, the two regression models, partial least squares and random forest (RF), successfully expanded the plant density prediction areas with RMSE values ranging from 1.78 to 3.67 plant m−2. Model improvement was conducted using the variable importance feature in RF, which improved prediction accuracy with an RMSE value of 1.72 plant m−2. These results demonstrated that the established model had an acceptable prediction accuracy for estimating plant density. Although the model could not often evaluate the within-field spatial variability of soybean plant density, the predicted values were sufficient for informing the field-specific status.
KW  - PlanetScope
KW  - random forest
KW  - partial least squares regression
KW  - spatial variation
KW  - spectral reflectance
KW  - YOLOv3
DO  - 10.3390/rs13132548
ER  -
TY  - EJOU
AU  - Cheng, Lei
AU  - Tan, Xiyue
AU  - Yao, Dong
AU  - Xu, Wenxia
AU  - Wu, Huaiyu
AU  - Chen, Yang
TI  - A Fishery Water Quality Monitoring and Prediction Evaluation System for Floating UAV Based on Time Series
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 13
SN  - 1424-8220

AB  - In recent years, fishery has developed rapidly. For the vital interests of the majority of fishermen, this paper makes full use of Internet of Things and air–water amphibious UAV technology to provide an integrated system that can meet the requirements of fishery water quality monitoring and prediction evaluation. To monitor target water quality in real time, the water quality monitoring of the system is mainly completed by a six-rotor floating UAV that carries water quality sensors. The GPRS module is then used to realize remote data transmission. The prediction of water quality transmission data is mainly realized by the algorithm of time series comprehensive analysis. The evaluation rules are determined according to the water quality evaluation standards to evaluate the predicted water quality data. Finally, the feasibility of the system is proved through experiments. The results show that the system can effectively evaluate fishery water quality under different weather conditions. The prediction accuracy of the pH, dissolved oxygen content, and ammonia nitrogen content of fishery water quality can reach 99%, 98%, and 99% on sunny days, and reach 92%, 98%, and 91% on rainy days.
KW  - water quality monitoring
KW  - six-rotor floating UAV
KW  - time series analysis
KW  - prediction
KW  - evaluation
DO  - 10.3390/s21134451
ER  -
TY  - EJOU
AU  - Yoosefzadeh-Najafabadi, Mohsen
AU  - Tulpan, Dan
AU  - Eskandari, Milad
TI  - Using Hybrid Artificial Intelligence and Evolutionary Optimization Algorithms for Estimating Soybean Yield and Fresh Biomass Using Hyperspectral Vegetation Indices
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - Recent advanced high-throughput field phenotyping combined with sophisticated big data analysis methods have provided plant breeders with unprecedented tools for a better prediction of important agronomic traits, such as yield and fresh biomass (FBIO), at early growth stages. This study aimed to demonstrate the potential use of 35 selected hyperspectral vegetation indices (HVI), collected at the R5 growth stage, for predicting soybean seed yield and FBIO. Two artificial intelligence algorithms, ensemble-bagging (EB) and deep neural network (DNN), were used to predict soybean seed yield and FBIO using HVI. Considering HVI as input variables, the coefficients of determination (R2) of 0.76 and 0.77 for yield and 0.91 and 0.89 for FBIO were obtained using DNN and EB, respectively. In this study, we also used hybrid DNN-SPEA2 to estimate the optimum HVI values in soybeans with maximized yield and FBIO productions. In addition, to identify the most informative HVI in predicting yield and FBIO, the feature recursive elimination wrapper method was used and the top ranking HVI were determined to be associated with red, 670 nm and near-infrared, 800 nm, regions. Overall, this study introduced hybrid DNN-SPEA2 as a robust mathematical tool for optimizing and using informative HVI for estimating soybean seed yield and FBIO at early growth stages, which can be employed by soybean breeders for discriminating superior genotypes in large breeding populations.
KW  - high-throughput phenotyping
KW  - machine learning
KW  - multi-objective optimization algorithm
KW  - radial basis function
KW  - random forest
KW  - support vector regression
KW  - SPEA2
DO  - 10.3390/rs13132555
ER  -
TY  - EJOU
AU  - Matin, Sahar S.
AU  - Pradhan, Biswajeet
TI  - Earthquake-Induced Building-Damage Mapping Using Explainable AI (XAI)
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 13
SN  - 1424-8220

AB  - Building-damage mapping using remote sensing images plays a critical role in providing quick and accurate information for the first responders after major earthquakes. In recent years, there has been an increasing interest in generating post-earthquake building-damage maps automatically using different artificial intelligence (AI)-based frameworks. These frameworks in this domain are promising, yet not reliable for several reasons, including but not limited to the site-specific design of the methods, the lack of transparency in the AI-model, the lack of quality in the labelled image, and the use of irrelevant descriptor features in building the AI-model. Using explainable AI (XAI) can lead us to gain insight into identifying these limitations and therefore, to modify the training dataset and the model accordingly. This paper proposes the use of SHAP (Shapley additive explanation) to interpret the outputs of a multilayer perceptron (MLP)—a machine learning model—and analyse the impact of each feature descriptor included in the model for building-damage assessment to examine the reliability of the model. In this study, a post-event satellite image from the 2018 Palu earthquake was used. The results show that MLP can classify the collapsed and non-collapsed buildings with an overall accuracy of 84% after removing the redundant features. Further, spectral features are found to be more important than texture features in distinguishing the collapsed and non-collapsed buildings. Finally, we argue that constructing an explainable model would help to understand the model’s decision to classify the buildings as collapsed and non-collapsed and open avenues to build a transferable AI model.
KW  - building-damage mapping
KW  - feature analysis
KW  - explainable AI
KW  - machine learning
KW  - remote sensing
DO  - 10.3390/s21134489
ER  -
TY  - EJOU
AU  - Ghorbanian, Arsalan
AU  - Zaghian, Soheil
AU  - Asiyabi, Reza M.
AU  - Amani, Meisam
AU  - Mohammadzadeh, Ali
AU  - Jamali, Sadegh
TI  - Mangrove Ecosystem Mapping Using Sentinel-1 and Sentinel-2 Satellite Images and Random Forest Algorithm in Google Earth Engine
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - Mangroves are among the most productive ecosystems in existence, with many ecological benefits. Therefore, generating accurate thematic maps from mangrove ecosystems is crucial for protecting, conserving, and reforestation planning for these valuable natural resources. In this paper, Sentinel-1 and Sentinel-2 satellite images were used in synergy to produce a detailed mangrove ecosystem map of the Hara protected area, Qeshm, Iran, at 10 m spatial resolution within the Google Earth Engine (GEE) cloud computing platform. In this regard, 86 Sentinel-1 and 41 Sentinel-2 data, acquired in 2019, were employed to generate seasonal optical and synthetic aperture radar (SAR) features. Afterward, seasonal features were inserted into a pixel-based random forest (RF) classifier, resulting in an accurate mangrove ecosystem map with average overall accuracy (OA) and Kappa coefficient (KC) of 93.23% and 0.92, respectively, wherein all classes (except aerial roots) achieved high producer and user accuracies of over 90%. Furthermore, comprehensive quantitative and qualitative assessments were performed to investigate the robustness of the proposed approach, and the accurate and stable results achieved through cross-validation and consistency checks confirmed its robustness and applicability. It was revealed that seasonal features and the integration of multi-source remote sensing data contributed towards obtaining a more reliable mangrove ecosystem map. The proposed approach relies on a straightforward yet effective workflow for mangrove ecosystem mapping, with a high rate of automation that can be easily implemented for frequent and precise mapping in other parts of the world. Overall, the proposed workflow can further improve the conservation and sustainable management of these valuable natural resources.
KW  - mangrove ecosystem
KW  - random forest (RF)
KW  - Google Earth Engine (GEE)
KW  - Sentinel
KW  - synthetic aperture radar (SAR)
KW  - optical
KW  - aerial roots
DO  - 10.3390/rs13132565
ER  -
TY  - EJOU
AU  - Mbiydzenyuy, Gideon
AU  - Nowaczyk, Sławomir
AU  - Knutsson, Håkan
AU  - Vanhoudt, Dirk
AU  - Brage, Jens
AU  - Calikus, Ece
TI  - Opportunities for Machine Learning in District Heating
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 13
SN  - 2076-3417

AB  - The district heating (DH) industry is facing an important transformation towards more efficient networks that utilise significantly lower water temperatures to distribute the heat. This change requires taking advantage of new technologies, and Machine Learning (ML) is a popular direction. In the last decade, we have witnessed an extreme growth in the number of published research papers that focus on applying ML techniques to the DH domain. However, based on our experience in the field, and an extensive review of the state-of-the-art, we perceive a mismatch between the most popular research directions, such as forecasting, and the challenges faced by the DH industry. In this work, we present our findings, explain and demonstrate the key gaps between the two communities and suggest a road-map ahead towards increasing the impact of ML research in the DH industry.
KW  - Machine Learning
KW  - district heating
KW  - review
KW  - road-map
KW  - research opportunities
DO  - 10.3390/app11136112
ER  -
TY  - EJOU
AU  - Ackerson, Joseph M.
AU  - Dave, Rushit
AU  - Seliya, Naeem
TI  - Applications of Recurrent Neural Network for Biometric Authentication &amp; Anomaly Detection
T2  - Information

PY  - 2021
VL  - 12
IS  - 7
SN  - 2078-2489

AB  - Recurrent Neural Networks are powerful machine learning frameworks that allow for data to be saved and referenced in a temporal sequence. This opens many new possibilities in fields such as handwriting analysis and speech recognition. This paper seeks to explore current research being conducted on RNNs in four very important areas, being biometric authentication, expression recognition, anomaly detection, and applications to aircraft. This paper reviews the methodologies, purpose, results, and the benefits and drawbacks of each proposed method below. These various methodologies all focus on how they can leverage distinct RNN architectures such as the popular Long Short-Term Memory (LSTM) RNN or a Deep-Residual RNN. This paper also examines which frameworks work best in certain situations, and the advantages and disadvantages of each proposed model.
KW  - recurrent neural network
KW  - biometric authentication
KW  - expression recognition
KW  - anomaly detection
KW  - smartphone authentication
KW  - mouse-based authentication
KW  - aircraft trajectory prediction
DO  - 10.3390/info12070272
ER  -
TY  - EJOU
AU  - Pourroostaei Ardakani, Saeid
AU  - Cheshmehzangi, Ali
TI  - Reinforcement Learning-Enabled UAV Itinerary Planning for Remote Sensing Applications in Smart Farming
T2  - Telecom

PY  - 2021
VL  - 2
IS  - 3
SN  - 2673-4001

AB  - UAV path planning for remote sensing aims to find the best-fitted routes to complete a data collection mission. UAVs plan the routes and move through them to remotely collect environmental data from particular target zones by using sensory devices such as cameras. Route planning may utilize machine learning techniques to autonomously find/select cost-effective and/or best-fitted routes and achieve optimized results including: minimized data collection delay, reduced UAV power consumption, decreased flight traversed distance and maximized number of collected data samples. This paper utilizes a reinforcement learning technique (location and energy-aware Q-learning) to plan UAV routes for remote sensing in smart farms. Through this, the UAV avoids heuristically or blindly moving throughout a farm, but this takes the benefits of environment exploration–exploitation to explore the farm and find the shortest and most cost-effective paths into target locations with interesting data samples to collect. According to the simulation results, utilizing the Q-learning technique increases data collection robustness and reduces UAV resource consumption (e.g., power), traversed paths, and remote sensing latency as compared to two well-known benchmarks, IEMF and TBID, especially if the target locations are dense and crowded in a farm.
KW  - UAV
KW  - reinforcement learning
KW  - Q-learning
KW  - path planning
KW  - remote sensing
DO  - 10.3390/telecom2030017
ER  -
TY  - EJOU
AU  - Swinney, Carolyn J.
AU  - Woods, John C.
TI  - The Effect of Real-World Interference on CNN Feature Extraction and Machine Learning Classification of Unmanned Aerial Systems
T2  - Aerospace

PY  - 2021
VL  - 8
IS  - 7
SN  - 2226-4310

AB  - Small unmanned aerial systems (UASs) present many potential solutions and enhancements to industry today but equally pose a significant security challenge. We only need to look at the levels of disruption caused by UASs at airports in recent years. The accuracy of UAS detection and classification systems based on radio frequency (RF) signals can be hindered by other interfering signals present in the same frequency band, such as Bluetooth and Wi-Fi devices. In this paper, we evaluate the effect of real-world interference from Bluetooth and Wi-Fi signals concurrently on convolutional neural network (CNN) feature extraction and machine learning classification of UASs. We assess multiple UASs that operate using different transmission systems: Wi-Fi, Lightbridge 2.0, OcuSync 1.0, OcuSync 2.0 and the recently released OcuSync 3.0. We consider 7 popular UASs, evaluating 2 class UAS detection, 8 class UAS type classification and 21 class UAS flight mode classification. Our results show that the process of CNN feature extraction using transfer learning and machine learning classification is fairly robust in the presence of real-world interference. We also show that UASs that are operating using the same transmission system can be distinguished. In the presence of interference from both Bluetooth and Wi-Fi signals, our results show 100% accuracy for UAV detection (2 classes), 98.1% (+/−0.4%) for UAV type classification (8 classes) and 95.4% (+/−0.3%) for UAV flight mode classification (21 classes).
KW  - unmanned aerial vehicles
KW  - unmanned aerial systems
KW  - interference
KW  - UAS detection
KW  - RF spectrum analysis
KW  - machine learning classification
KW  - deep learning
KW  - convolutional neural network
KW  - transfer learning
KW  - signal analysis
DO  - 10.3390/aerospace8070179
ER  -
TY  - EJOU
AU  - Xie, Xuelin
AU  - Shen, Jingfang
TI  - Waterlogging Resistance Evaluation Index and Photosynthesis Characteristics Selection: Using Machine Learning Methods to Judge Poplar’s Waterlogging Resistance
T2  - Mathematics

PY  - 2021
VL  - 9
IS  - 13
SN  - 2227-7390

AB  - Flood disasters are the major natural disaster that affects the growth of agriculture and forestry crops. Due to rapid growth and strong waterlogging resistance characteristics, many studies have explained the waterlogging resistance mechanism of poplar from different perspectives. However, there is no accurate method to define the evaluation index of waterlogging resistance. In addition, there is also a lack of research on predicting the waterlogging resistance of poplars. Based on the changes of poplar biomass and seedling height, the evaluation index of poplar resistance to waterlogging was well determined, and the characteristics of photosynthesis were used to predict the waterlogging resistance of poplars. First, four methods of hierarchical clustering, lasso, stepwise regression and all-subsets regression were used to extract the photosynthesis characteristics. After that, the support vector regression model of poplar resistance to waterlogging was established by using the characteristic parameters of photosynthesis. Finally, the results show that the SVR model based on Stepwise regression and Lasso method has high precision. On the test set, the coefficient of determination (R2) was 0.8581 and 0.8492, the mean square error (MSE) was 0.0104 and 0.0341, and the mean relative error (MRE) was 9.78% and 9.85%, respectively. Therefore, using the characteristic parameters of photosynthesis to predict the waterlogging resistance of poplars is feasible.
KW  - flood disasters
KW  - waterlogging stress
KW  - waterlogging resistance index
KW  - feature extraction
KW  - SVR model
DO  - 10.3390/math9131542
ER  -
TY  - EJOU
AU  - Kaczorowska, Monika
AU  - Karczmarek, Paweł
AU  - Plechawska-Wójcik, Małgorzata
AU  - Tokovarov, Mikhail
TI  - On the Improvement of Eye Tracking-Based Cognitive Workload Estimation Using Aggregation Functions
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 13
SN  - 1424-8220

AB  - Cognitive workload, being a quantitative measure of mental effort, draws significant interest of researchers, as it allows to monitor the state of mental fatigue. Estimation of cognitive workload becomes especially important for job positions requiring outstanding engagement and responsibility, e.g., air-traffic dispatchers, pilots, car or train drivers. Cognitive workload estimation finds its applications also in the field of education material preparation. It allows to monitor the difficulty degree for specific tasks enabling to adjust the level of education materials to typical abilities of students. In this study, we present the results of research conducted with the goal of examining the influence of various fuzzy or non-fuzzy aggregation functions upon the quality of cognitive workload estimation. Various classic machine learning models were successfully applied to the problem. The results of extensive in-depth experiments with over 2000 aggregation operators shows the applicability of the approach based on the aggregation functions. Moreover, the approach based on aggregation process allows for further improvement of classification results. A wide range of aggregation functions is considered and the results suggest that the combination of classical machine learning models and aggregation methods allows to achieve high quality of cognitive workload level recognition preserving low computational cost.
KW  - aggregation
KW  - generalized Choquet integral
KW  - fuzzy measure
KW  - classical machine learning
KW  - cognitive workload
DO  - 10.3390/s21134542
ER  -
TY  - EJOU
AU  - Mohan, Midhun
AU  - Richardson, Gabriella
AU  - Gopan, Gopika
AU  - Aghai, Matthew M.
AU  - Bajaj, Shaurya
AU  - Galgamuwa, G. A. Pabodha
AU  - Vastaranta, Mikko
AU  - Arachchige, Pavithra S. Pitumpe
AU  - Amorós, Lot
AU  - Corte, Ana P.
AU  - de-Miguel, Sergio
AU  - Leite, Rodrigo V.
AU  - Kganyago, Mahlatse
AU  - Broadbent, Eben N.
AU  - Doaemo, Willie
AU  - Shorab, Mohammed A.
AU  - Cardil, Adrian
TI  - UAV-Supported Forest Regeneration: Current Trends, Challenges and Implications
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - Replanting trees helps with avoiding desertification, reducing the chances of soil erosion and flooding, minimizing the risks of zoonotic disease outbreaks, and providing ecosystem services and livelihood to the indigenous people, in addition to sequestering carbon dioxide for mitigating climate change. Consequently, it is important to explore new methods and technologies that are aiming to upscale and fast-track afforestation and reforestation (A/R) endeavors, given that many of the current tree planting strategies are not cost effective over large landscapes, and suffer from constraints associated with time, energy, manpower, and nursery-based seedling production. UAV (unmanned aerial vehicle)-supported seed sowing (UAVsSS) can promote rapid A/R in a safe, cost-effective, fast and environmentally friendly manner, if performed correctly, even in otherwise unsafe and/or inaccessible terrains, supplementing the overall manual planting efforts globally. In this study, we reviewed the recent literature on UAVsSS, to analyze the current status of the technology. Primary UAVsSS applications were found to be in areas of post-wildfire reforestation, mangrove restoration, forest restoration after degradation, weed eradication, and desert greening. Nonetheless, low survival rates of the seeds, future forest diversity, weather limitations, financial constraints, and seed-firing accuracy concerns were determined as major challenges to operationalization. Based on our literature survey and qualitative analysis, twelve recommendations—ranging from the need for publishing germination results to linking UAVsSS operations with carbon offset markets—are provided for the advancement of UAVsSS applications.
KW  - planting trees with drones
KW  - seed pods
KW  - unmanned aerial system (UAS)
KW  - seed spraying drones
KW  - forestry applications of UAVs
KW  - afforestation and reforestation using UAVs
DO  - 10.3390/rs13132596
ER  -
TY  - EJOU
AU  - Francos, Nicolas
AU  - Romano, Nunzio
AU  - Nasta, Paolo
AU  - Zeng, Yijian
AU  - Szabó, Brigitta
AU  - Manfreda, Salvatore
AU  - Ciraolo, Giuseppe
AU  - Mészáros, János
AU  - Zhuang, Ruodan
AU  - Su, Bob
AU  - Ben-Dor, Eyal
TI  - Mapping Water Infiltration Rate Using Ground and UAV Hyperspectral Data: A Case Study of Alento, Italy
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - Water infiltration rate (WIR) into the soil profile was investigated through a comprehensive study harnessing spectral information of the soil surface. As soil spectroscopy provides invaluable information on soil attributes, and as WIR is a soil surface-dependent property, field spectroscopy may model WIR better than traditional laboratory spectral measurements. This is because sampling for the latter disrupts the soil-surface status. A field soil spectral library (FSSL), consisting of 114 samples with different textures from six different sites over the Mediterranean basin, combined with traditional laboratory spectral measurements, was created. Next, partial least squares regression analysis was conducted on the spectral and WIR data in different soil texture groups, showing better performance of the field spectral observations compared to traditional laboratory spectroscopy. Moreover, several quantitative spectral properties were lost due to the sampling procedure, and separating the samples according to texture gave higher accuracies. Although the visible near-infrared–shortwave infrared (VNIR–SWIR) spectral region provided better accuracy, we resampled the spectral data to the resolution of a Cubert hyperspectral sensor (VNIR). This hyperspectral sensor was then assembled on an unmanned aerial vehicle (UAV) to apply one selected spectral-based model to the UAV data and map the WIR in a semi-vegetated area within the Alento catchment, Italy. Comprehensive spectral and WIR ground-truth measurements were carried out simultaneously with the UAV–Cubert sensor flight. The results were satisfactorily validated on the ground using field samples, followed by a spatial uncertainty analysis, concluding that the UAV with hyperspectral remote sensing can be used to map soil surface-related soil properties.
KW  - water infiltration rate
KW  - hyperspectral remote sensing
KW  - soil spectroscopy
KW  - soil surface
KW  - unmanned aerial vehicle
DO  - 10.3390/rs13132606
ER  -
TY  - EJOU
AU  - Bahrami, Hazhir
AU  - Homayouni, Saeid
AU  - Safari, Abdolreza
AU  - Mirzaei, Sayeh
AU  - Mahdianpari, Masoud
AU  - Reisi-Gahrouei, Omid
TI  - Deep Learning-Based Estimation of Crop Biophysical Parameters Using Multi-Source and Multi-Temporal Remote Sensing Observations
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 7
SN  - 2073-4395

AB  - Remote sensing data are considered as one of the primary data sources for precise agriculture. Several studies have demonstrated the excellent capability of radar and optical imagery for crop mapping and biophysical parameter estimation. This paper aims at modeling the crop biophysical parameters, e.g., Leaf Area Index (LAI) and biomass, using a combination of radar and optical Earth observations. We extracted several radar features from polarimetric Synthetic Aperture Radar (SAR) data and Vegetation Indices (VIs) from optical images to model crops’ LAI and dry biomass. Then, the mutual correlations between these features and Random Forest feature importance were calculated. We considered two scenarios to estimate crop parameters. First, Machine Learning (ML) algorithms, e.g., Support Vector Regression (SVR), Random Forest (RF), Gradient Boosting (GB), and Extreme Gradient Boosting (XGB), were utilized to estimate two crop biophysical parameters. To this end, crops’ dry biomass and LAI were estimated using three input data; (1) SAR polarimetric features; (2) spectral VIs; (3) integrating both SAR and optical features. Second, a deep artificial neural network was created. These input data were fed to the mentioned algorithms and evaluated using the in-situ measurements. These observations of three cash crops, including soybean, corn, and canola, have been collected over Manitoba, Canada, during the Soil Moisture Active Validation Experimental 2012 (SMAPVEX-12) campaign. The results showed that GB and XGB have great potential in parameter estimation and remarkably improved accuracy. Our results also demonstrated a significant improvement in the dry biomass and LAI estimation compared to the previous studies. For LAI, the validation Root Mean Square Error (RMSE) was reported as 0.557 m2/m2 for canola using GB, and 0.298 m2/m2 for corn using GB, 0.233 m2/m2 for soybean using XGB. RMSE was reported for dry biomass as 26.29 g/m2 for canola utilizing SVR, 57.97 g/m2 for corn using RF, and 5.00 g/m2 for soybean using GB. The results revealed that the deep artificial neural network had a better potential to estimate crop parameters than the ML algorithms.
KW  - crop biomass
KW  - Leaf Area Index
KW  - Earth observations
KW  - Synthetic Aperture Radar
KW  - optical images
KW  - machine learning algorithms
KW  - SMAPVEX-12
DO  - 10.3390/agronomy11071363
ER  -
TY  - EJOU
AU  - Wang, Haozhou
AU  - Duan, Yulin
AU  - Shi, Yun
AU  - Kato, Yoichiro
AU  - Ninomiya, Seishi
AU  - Guo, Wei
TI  - EasyIDP: A Python Package for Intermediate Data Processing in UAV-Based Plant Phenotyping
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - Unmanned aerial vehicle (UAV) and structure from motion (SfM) photogrammetry techniques are widely used for field-based, high-throughput plant phenotyping nowadays, but some of the intermediate processes throughout the workflow remain manual. For example, geographic information system (GIS) software is used to manually assess the 2D/3D field reconstruction quality and cropping region of interests (ROIs) from the whole field. In addition, extracting phenotypic traits from raw UAV images is more competitive than directly from the digital orthomosaic (DOM). Currently, no easy-to-use tools are available to implement previous tasks for commonly used commercial SfM software, such as Pix4D and Agisoft Metashape. Hence, an open source software package called easy intermediate data processor (EasyIDP; MIT license) was developed to decrease the workload in intermediate data processing mentioned above. The functions of the proposed package include (1) an ROI cropping module, assisting in reconstruction quality assessment and cropping ROIs from the whole field, and (2) an ROI reversing module, projecting ROIs to relative raw images. The result showed that both cropping and reversing modules work as expected. Moreover, the effects of ROI height selection and reversed ROI position on raw images to reverse calculation were discussed. This tool shows great potential for decreasing workload in data annotation for machine learning applications.
KW  - orthomosaic
KW  - photogrammetry
KW  - phenotyping
KW  - reverse calculation
KW  - Pix4D
KW  - Agisoft Metashape
KW  - Agisoft PhotoScan
DO  - 10.3390/rs13132622
ER  -
TY  - EJOU
AU  - Moura, Marks M.
AU  - de Oliveira, Luiz E.
AU  - Sanquetta, Carlos R.
AU  - Bastos, Alexis
AU  - Mohan, Midhun
AU  - Corte, Ana P.
TI  - Towards Amazon Forest Restoration: Automatic Detection of Species from UAV Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - Precise assessments of forest species’ composition help analyze biodiversity patterns, estimate wood stocks, and improve carbon stock estimates. Therefore, the objective of this work was to evaluate the use of high-resolution images obtained from Unmanned Aerial Vehicle (UAV) for the identification of forest species in areas of forest regeneration in the Amazon. For this purpose, convolutional neural networks (CNN) were trained using the Keras–Tensorflow package with the faster_rcnn_inception_v2_pets model. Samples of six forest species were used to train CNN. From these, attempts were made with the number of thresholds, which is the cutoff value of the function; any value below this output is considered 0, and values above are treated as an output 1; that is, values above the value stipulated in the Threshold are considered as identified species. The results showed that the reduction in the threshold decreases the accuracy of identification, as well as the overlap of the polygons of species identification. However, in comparison with the data collected in the field, it was observed that there exists a high correlation between the trees identified by the CNN and those observed in the plots. The statistical metrics used to validate the classification results showed that CNN are able to identify species with accuracy above 90%. Based on our results, which demonstrate good accuracy and precision in the identification of species, we conclude that convolutional neural networks are an effective tool in classifying objects from UAV images.
KW  - deep learning
KW  - drone
KW  - forest identification
KW  - unmanned aerial vehicles
DO  - 10.3390/rs13132627
ER  -
TY  - EJOU
AU  - Grybas, Heather
AU  - Congalton, Russell G.
TI  - A Comparison of Multi-Temporal RGB and Multispectral UAS Imagery for Tree Species Classification in Heterogeneous New Hampshire Forests
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - Unmanned aerial systems (UASs) have recently become an affordable means to map forests at the species level, but research into the performance of different classification methodologies and sensors is necessary so users can make informed choices that maximize accuracy. This study investigated whether multi-temporal UAS data improved the classified accuracy of 14 species examined the optimal time-window for data collection, and compared the performance of a consumer-grade RGB sensor to that of a multispectral sensor. A time series of UAS data was collected from early spring to mid-summer and a sequence of mono-temporal and multi-temporal classifications were carried out. Kappa comparisons were conducted to ascertain whether the multi-temporal classifications significantly improved accuracy and whether there were significant differences between the RGB and multispectral classifications. The multi-temporal classification approach significantly improved accuracy; however, there was no significant benefit when more than three dates were used. Mid- to late spring imagery produced the highest accuracies, potentially due to high spectral heterogeneity between species and homogeneity within species during this time. The RGB sensor exhibited significantly higher accuracies, probably due to the blue band, which was found to be very important for classification accuracy and lacking in the multispectral sensor employed here.
KW  - remote sensing
KW  - forests
KW  - New Hampshire
KW  - UAS
KW  - multi-temporal
KW  - species level
KW  - OBIA
DO  - 10.3390/rs13132631
ER  -
TY  - EJOU
AU  - Wei, Jiangang
AU  - Chen, Gang
AU  - Huang, Jizhuo
AU  - Xu, Li
AU  - Yang, Yan
AU  - Wang, Jun
AU  - Sadick, Abdul-Manan
TI  - BIM and GIS Applications in Bridge Projects: A Critical Review
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 13
SN  - 2076-3417

AB  - In recent years, interest in BIM and GIS applications in civil engineering has been growing. For bridge engineering, BIM/GIS applications such as simulation, visualization, and secondary development have been used to assist practitioners in managing bridge construction and decision-making, including selection of bridge location maintenance decisions. In situ 3D modelling of existing bridges with detailed images from UAV camera has allowed engineers to conduct remote condition assessments of bridges and decide on required maintenance actions. Several studies have investigated the applications of BIM/GIS technology on bridge projects. However, there has been limited focus on reviewing the outcomes of these studies to identify the limitations of BIM and GIS applications on bridge projects. Therefore, the aim of this study was to review the research on BIM/GIS technology applications in bridge projects over the last decade. Using a systematic review process, a total of 90 publications that met the inclusion criteria were reviewed in this study. The review identified the state-of-the-art methods of BIM and GIS applications, respectively, at the planning and design, construction, and operation and maintenance phases of bridge projects. However, the findings point to segregated application of BIM and GIS at all phases of bridge projects. The findings of this study will contribute to guiding practitioners in selecting appropriate BIM and GIS technologies for different aspects of bridge projects.
KW  - Building Information Modelling (BIM)
KW  - Geographical Information System (GIS)
KW  - Bridge Information Modelling (BrIM)
KW  - bridge
KW  - application
DO  - 10.3390/app11136207
ER  -
TY  - EJOU
AU  - Gautam, Deepak
AU  - Ostendorf, Bertram
AU  - Pagay, Vinay
TI  - Estimation of Grapevine Crop Coefficient Using a Multispectral Camera on an Unmanned Aerial Vehicle
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - Crop water status and irrigation requirements are of great importance to the horticultural industry due to changing climatic conditions leading to high evaporative demands, drought and water scarcity in semi-arid and arid regions worldwide. Irrigation scheduling strategies based on evapotranspiration (ET), such as regulated deficit irrigation, requires the estimation of seasonal crop coefficients (kc). The ET-driven irrigation decisions for grapevines rely on the sampling of several kc values from each irrigation zone. Here, we present an unmanned aerial vehicle (UAV)-based technique to estimate kc at the single vine level in order to capture the spatial variability of water requirements in a commercial vineyard located in South Australia. A UAV carrying a multispectral sensor is used to extract the spectral, as well as the structural, information of Cabernet Sauvignon grapevines. The spectral and structural information, acquired at the various phenological stages of the vine through two seasons, is used to model kc using univariate (simple linear), multivariate (generalised linear and additive) and machine learning (convolution neural network and random forest) model frameworks. The structural information (e.g., canopy top view area) had the strongest correlation with kc throughout the season (p ≤ 0.001; Pearson R = 0.56), while the spectral indices (e.g., normalised indices) turned less-sensitive post véraison—the onset of ripening in grapes. Combining structural and spectral information improved the model’s performance. Among the investigated predictive models, the random forest predicted kc with the highest accuracy (R2: 0.675, root mean square error: 0.062, and mean absolute error: 0.047). This UAV-based approach improves the precision of irrigation by capturing the spatial variability of kc within a vineyard. Combined with an energy balance model, the water needs of a vineyard can be computed on a weekly or sub-weekly basis for precision irrigation. The UAV-based characterisation of kc can further enhance the water management and irrigation zoning by matching the infrastructure with the spatial variability of the irrigation demand.
KW  - UAV
KW  - UAS
KW  - drone
KW  - precision irrigation
KW  - remote sensing
KW  - spatial variability
KW  - random forest
DO  - 10.3390/rs13132639
ER  -
TY  - EJOU
AU  - Wang, Hao
AU  - Ren, Yaxin
AU  - Meng, Zhijun
TI  - A Farm Management Information System for Semi-Supervised Path Planning and Autonomous Vehicle Control
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 13
SN  - 2071-1050

AB  - This paper presents a farm management information system targeting improvements in the ease of use and sustainability of robot farming systems. The system integrates the functionalities of field survey, path planning, monitoring, and controlling agricultural vehicles in real time. Firstly, a Grabcut-based semi-supervised field registration method is proposed for arable field detection from the orthoimage taken by the drone with an RGB camera. It partitions a complex field into simple geometric entities with simple user interaction. The average Mean Intersection over Union is about 0.95 when the field size ranges from 2.74 ha to 5.06 ha. In addition, a desktop software and a web application are developed as the entity of an FMIS. Compared to existing FMISs, this system provides more advanced features in robot farming, while providing simpler user interaction and better results. It allows clients to invoke web services and receive responses independent of programming language and platforms. Moreover, the system is compatible with other services, users, and devices following the open-source access protocol. We have evaluated the system by controlling 5 robot tractors with a 2 Hz communication frequency. The communication protocols will be publicly available to protentional users.
KW  - smart agriculture
KW  - image segmentation
KW  - agricultural robot
KW  - field registration
DO  - 10.3390/su13137497
ER  -
TY  - EJOU
AU  - Cacace, Jonathan
AU  - Orozco-Soto, Santos M.
AU  - Suarez, Alejandro
AU  - Caballero, Alvaro
AU  - Orsag, Matko
AU  - Bogdan, Stjepan
AU  - Vasiljevic, Goran
AU  - Ebeid, Emad
AU  - Rodriguez, Jose A.
AU  - Ollero, Anibal
TI  - Safe Local Aerial Manipulation for the Installation of Devices on Power Lines: AERIAL-CORE First Year Results and Designs
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 13
SN  - 2076-3417

AB  - The power grid is an essential infrastructure in any country, comprising thousands of kilometers of power lines that require periodic inspection and maintenance, carried out nowadays by human operators in risky conditions. To increase safety and reduce time and cost with respect to conventional solutions involving manned helicopters and heavy vehicles, the AERIAL-CORE project proposes the development of aerial robots capable of performing aerial manipulation operations to assist human operators in power lines inspection and maintenance, allowing the installation of devices, such as bird flight diverters or electrical spacers, and the fast delivery and retrieval of tools. This manuscript describes the goals and functionalities to be developed for safe local aerial manipulation, presenting the preliminary designs and experimental results obtained in the first year of the project.
KW  - aerial manipulation
KW  - inspection and maintenance
KW  - power lines
DO  - 10.3390/app11136220
ER  -
TY  - EJOU
AU  - Oliveira, Francisco
AU  - Luís, Miguel
AU  - Sargento, Susana
TI  - Machine Learning for the Dynamic Positioning of UAVs for Extended Connectivity
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 13
SN  - 1424-8220

AB  - Unmanned Aerial Vehicle (UAV) networks are an emerging technology, useful not only for the military, but also for public and civil purposes. Their versatility provides advantages in situations where an existing network cannot support all requirements of its users, either because of an exceptionally big number of users, or because of the failure of one or more ground base stations. Networks of UAVs can reinforce these cellular networks where needed, redirecting the traffic to available ground stations. Using machine learning algorithms to predict overloaded traffic areas, we propose a UAV positioning algorithm responsible for determining suitable positions for the UAVs, with the objective of a more balanced redistribution of traffic, to avoid saturated base stations and decrease the number of users without a connection. The tests performed with real data of user connections through base stations show that, in less restrictive network conditions, the algorithm to dynamically place the UAVs performs significantly better than in more restrictive conditions, reducing significantly the number of users without a connection. We also conclude that the accuracy of the prediction is a very important factor, not only in the reduction of users without a connection, but also on the number of UAVs deployed.
KW  - unmanned aerial vehicle
KW  - UAV positioning
KW  - machine learning
KW  - wireless communications
DO  - 10.3390/s21134618
ER  -
TY  - EJOU
AU  - Munawar, Hafiz S.
AU  - Ullah, Fahim
AU  - Qayyum, Siddra
AU  - Khan, Sara I.
AU  - Mojtahedi, Mohammad
TI  - UAVs in Disaster Management: Application of Integrated Aerial Imagery and Convolutional Neural Network for Flood Detection
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 14
SN  - 2071-1050

AB  - Floods have been a major cause of destruction, instigating fatalities and massive damage to the infrastructure and overall economy of the affected country. Flood-related devastation results in the loss of homes, buildings, and critical infrastructure, leaving no means of communication or travel for the people stuck in such disasters. Thus, it is essential to develop systems that can detect floods in a region to provide timely aid and relief to stranded people, save their livelihoods, homes, and buildings, and protect key city infrastructure. Flood prediction and warning systems have been implemented in developed countries, but the manufacturing cost of such systems is too high for developing countries. Remote sensing, satellite imagery, global positioning system, and geographical information systems are currently used for flood detection to assess the flood-related damages. These techniques use neural networks, machine learning, or deep learning methods. However, unmanned aerial vehicles (UAVs) coupled with convolution neural networks have not been explored in these contexts to instigate a swift disaster management response to minimize damage to infrastructure. Accordingly, this paper uses UAV-based aerial imagery as a flood detection method based on Convolutional Neural Network (CNN) to extract flood-related features from the images of the disaster zone. This method is effective in assessing the damage to local infrastructures in the disaster zones. The study area is based on a flood-prone region of the Indus River in Pakistan, where both pre-and post-disaster images are collected through UAVs. For the training phase, 2150 image patches are created by resizing and cropping the source images. These patches in the training dataset train the CNN model to detect and extract the regions where a flood-related change has occurred. The model is tested against both pre-and post-disaster images to validate it, which has positive flood detection results with an accuracy of 91%. Disaster management organizations can use this model to assess the damages to critical city infrastructure and other assets worldwide to instigate proper disaster responses and minimize the damages. This can help with the smart governance of the cities where all emergent disasters are addressed promptly.
KW  - convolutional neural network (CNN)
KW  - disaster management
KW  - aerial imagery
KW  - flood detection
KW  - unmanned aerial vehicles (UAVs)
DO  - 10.3390/su13147547
ER  -
TY  - EJOU
AU  - Jadoun, Vinay K.
AU  - Sharma, Nipun
AU  - Jha, Piyush
AU  - S., Jayalakshmi N.
AU  - Malik, Hasmat
AU  - Garcia Márquez, Fausto P.
TI  - Optimal Scheduling of Dynamic Pricing Based V2G and G2V Operation in Microgrid Using Improved Elephant Herding Optimization
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 14
SN  - 2071-1050

AB  - The unpredictable nature of the loads and non-linearity of the components of microgrid systems make optimal scheduling more complex. In this paper, a deterministic optimal load-scheduling problem is developed for microgrids operating in both islanding and grid-connected mode under different energy scenarios. Various cases are considered in this research, based on the interaction and dynamic behavior of the microgrid, considering electric vehicles (EVs) in the scenario. The aim of this research is to minimize the overall cost of microgrid operations. The concept of dynamic pricing has also been introduced in order to optimize the energy cost for the consumers. For ensuring the stability of the microgrids, a load variance index has been considered, and the fuzzy-based approach has been used for cost and load variance minimization to reduce the operation cost without compromising the stability of the microgrid. The grid-to-vehicle (G2V) and vehicle-to-grid (V2G) operations of EVs are integrated into the microgrid, which would help in valley filling and peak shaving of the loads during the off-peak and peak hours, respectively. In order to solve the proposed complex combinatorial optimization problem, elephant herding optimization (EHO) is modified and implemented. The performance of the proposed improved EHO (IEHO) is first tested on the latest CEC test functions. The results obtained by IEHO after 100 different trials are compared with the latest published methods and are found to be better based on the average value and the standard deviation for different CEC test functions. In addition, the simulation results obtained by particle swarm optimization (PSO), EHO, and proposed IEHO on a microgrid test system for different scenarios with all cases reveal that the proposed model with a mix of energy resources in the dynamic load dispatch environment bring the maximum benefits of microgrid systems. Furthermore, the results obtained from the simulation verifies that if free trade of power is allowed between the microgrids and the main grid, the process of power generation can be more economical, and further introduction of dynamic pricing into the scenario proves to be even cheaper. The implementation of the G2V and V2G operations of EVs operations in the proposed scenario not only helped in cost minimization but also helped in stabilizing the grid.
KW  - microgrid
KW  - optimal scheduling
KW  - dynamic pricing
KW  - load variance
KW  - electric vehicles
KW  - elephant herding optimization
DO  - 10.3390/su13147551
ER  -
TY  - EJOU
AU  - Jozdani, Shahab
AU  - Chen, Dongmei
AU  - Chen, Wenjun
AU  - Leblanc, Sylvain G.
AU  - Prévost, Christian
AU  - Lovitt, Julie
AU  - He, Liming
AU  - Johnson, Brian A.
TI  - Leveraging Deep Neural Networks to Map Caribou Lichen in High-Resolution Satellite Images Based on a Small-Scale, Noisy UAV-Derived Map
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - Lichen is an important food source for caribou in Canada. Lichen mapping using remote sensing (RS) images could be a challenging task, however, as lichens generally appear in unevenly distributed, small patches, and could resemble surficial features. Moreover, collecting lichen labeled data (reference data) is expensive, which restricts the application of many robust supervised classification models that generally demand a large quantity of labeled data. The goal of this study was to investigate the potential of using a very-high-spatial resolution (1-cm) lichen map of a small sample site (e.g., generated based on a single UAV scene and using field data) to train a subsequent classifier to map caribou lichen over a much larger area (~0.04 km2 vs. ~195 km2) and a lower spatial resolution image (in this case, a 50-cm WorldView-2 image). The limited labeled data from the sample site were also partially noisy due to spatial and temporal mismatching issues. For this, we deployed a recently proposed Teacher-Student semi-supervised learning (SSL) approach (based on U-Net and U-Net++ networks) involving unlabeled data to assist with improving the model performance. Our experiments showed that it was possible to scale-up the UAV-derived lichen map to the WorldView-2 scale with reasonable accuracy (overall accuracy of 85.28% and F1-socre of 84.38%) without collecting any samples directly in the WorldView-2 scene. We also found that our noisy labels were partially beneficial to the SSL robustness because they improved the false positive rate compared to the use of a cleaner training set directly collected within the same area in the WorldView-2 image. As a result, this research opens new insights into how current very high-resolution, small-scale caribou lichen maps can be used for generating more accurate large-scale caribou lichen maps from high-resolution satellite imagery.
KW  - remote sensing
KW  - lichen mapping
KW  - deep learning
KW  - semi-supervised learning
KW  - teacher-student learning
KW  - WorldView-2
KW  - unmanned aerial vehicle
DO  - 10.3390/rs13142658
ER  -
TY  - EJOU
AU  - Mirzazade, Ali
AU  - Popescu, Cosmin
AU  - Blanksvärd, Thomas
AU  - Täljsten, Björn
TI  - Workflow for Off-Site Bridge Inspection Using Automatic Damage Detection-Case Study of the Pahtajokk Bridge
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - For the inspection of structures, particularly bridges, it is becoming common to replace humans with autonomous systems that use unmanned aerial vehicles (UAV). In this paper, a framework for autonomous bridge inspection using a UAV is proposed with a four-step workflow: (a) data acquisition with an efficient UAV flight path, (b) computer vision comprising training, testing and validation of convolutional neural networks (ConvNets), (c) point cloud generation using intelligent hierarchical dense structure from motion (DSfM), and (d) damage quantification. This workflow starts with planning the most efficient flight path that allows for capturing of the minimum number of images required to achieve the maximum accuracy for the desired defect size, then followed by bridge and damage recognition. Three types of autonomous detection are used: masking the background of the images, detecting areas of potential damage, and pixel-wise damage segmentation. Detection of bridge components by masking extraneous parts of the image, such as vegetation, sky, roads or rivers, can improve the 3D reconstruction in the feature detection and matching stages. In addition, detecting damaged areas involves the UAV capturing close-range images of these critical regions, and damage segmentation facilitates damage quantification using 2D images. By application of DSfM, a denser and more accurate point cloud can be generated for these detected areas, and aligned to the overall point cloud to create a digital model of the bridge. Then, this generated point cloud is evaluated in terms of outlier noise, and surface deviation. Finally, damage that has been detected is quantified and verified, based on the point cloud generated using the Terrestrial Laser Scanning (TLS) method. The results indicate this workflow for autonomous bridge inspection has potential.
KW  - bridge inspection
KW  - computer vision
KW  - intelligent hierarchical DSfM
KW  - bridge 3D modeling
KW  - damage detection
KW  - damage segmentation
KW  - damage assessment
KW  - unmanned inspections
KW  - UAV
DO  - 10.3390/rs13142665
ER  -
TY  - EJOU
AU  - Łabędź, Piotr
AU  - Skabek, Krzysztof
AU  - Ozimek, Paweł
AU  - Nytko, Mateusz
TI  - Histogram Adjustment of Images for Improving Photogrammetric Reconstruction
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 14
SN  - 1424-8220

AB  - The accuracy of photogrammetric reconstruction depends largely on the acquisition conditions and on the quality of input photographs. This paper proposes methods of improving raster images that increase photogrammetric reconstruction accuracy. These methods are based on modifying color image histograms. Special emphasis was placed on the selection of channels of the RGB and CIE L*a*b* color models for further improvement of the reconstruction process. A methodology was proposed for assessing the quality of reconstruction based on premade reference models using positional statistics. The analysis of the influence of image enhancement on reconstruction was carried out for various types of objects. The proposed methods can significantly improve the quality of reconstruction. The superiority of methods based on the luminance channel of the L*a*b* model was demonstrated. Our studies indicated high efficiency of the histogram equalization method (HE), although these results were not highly distinctive for all performed tests.
KW  - photogrammetry
KW  - preprocessing
KW  - enhancement
KW  - point cloud
KW  - 3D reconstruction
KW  - image processing
KW  - image histogram
DO  - 10.3390/s21144654
ER  -
TY  - EJOU
AU  - Ge, Haixiao
AU  - Ma, Fei
AU  - Li, Zhenwang
AU  - Tan, Zhengzheng
AU  - Du, Changwen
TI  - Improved Accuracy of Phenological Detection in Rice Breeding by Using Ensemble Models of Machine Learning Based on UAV-RGB Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - Accurate and timely detection of phenology at plot scale in rice breeding trails is crucial for understanding the heterogeneity of varieties and guiding field management. Traditionally, remote sensing studies of phenology detection have heavily relied on the time-series vegetation index (VI) data. However, the methodology based on time-series VI data was often limited by the temporal resolution. In this study, three types of ensemble models including hard voting (majority voting), soft voting (weighted majority voting) and model stacking, were proposed to identify the principal phenological stages of rice based on unmanned aerial vehicle (UAV) RGB imagery. These ensemble models combined RGB-VIs, color space (e.g., RGB and HSV) and textures derived from UAV-RGB imagery, and five machine learning algorithms (random forest; k-nearest neighbors; Gaussian naïve Bayes; support vector machine and logistic regression) as base models to estimate phenological stages in rice breeding. The phenological estimation models were trained on the dataset of late-maturity cultivars and tested independently on the dataset of early-medium-maturity cultivars. The results indicated that all ensemble models outperform individual machine learning models in all datasets. The soft voting strategy provided the best performance for identifying phenology with the overall accuracy of 90% and 93%, and the mean F1-scores of 0.79 and 0.81, respectively, in calibration and validation datasets, which meant that the overall accuracy and mean F1-scores improved by 5% and 7%, respectively, in comparison with those of the best individual model (GNB), tested in this study. Therefore, the ensemble models demonstrated great potential in improving the accuracy of phenology detection in rice breeding.
KW  - UAV
KW  - machine learning
KW  - ensemble models
KW  - phenology
KW  - breeding
DO  - 10.3390/rs13142678
ER  -
TY  - EJOU
AU  - Herzig, Paul
AU  - Borrmann, Peter
AU  - Knauer, Uwe
AU  - Klück, Hans-Christian
AU  - Kilias, David
AU  - Seiffert, Udo
AU  - Pillen, Klaus
AU  - Maurer, Andreas
TI  - Evaluation of RGB and Multispectral Unmanned Aerial Vehicle (UAV) Imagery for High-Throughput Phenotyping and Yield Prediction in Barley Breeding
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - With advances in plant genomics, plant phenotyping has become a new bottleneck in plant breeding and the need for reliable high-throughput plant phenotyping techniques has emerged. In the face of future climatic challenges, it does not seem appropriate to continue to solely select for grain yield and a few agronomically important traits. Therefore, new sensor-based high-throughput phenotyping has been increasingly used in plant breeding research, with the potential to provide non-destructive, objective and continuous plant characterization that reveals the formation of the final grain yield and provides insights into the physiology of the plant during the growth phase. In this context, we present the comparison of two sensor systems, Red-Green-Blue (RGB) and multispectral cameras, attached to unmanned aerial vehicles (UAV), and investigate their suitability for yield prediction using different modelling approaches in a segregating barley introgression population at three environments with weekly data collection during the entire vegetation period. In addition to vegetation indices, morphological traits such as canopy height, vegetation cover and growth dynamics traits were used for yield prediction. Repeatability analyses and genotype association studies of sensor-based traits were compared with reference values from ground-based phenotyping to test the use of conventional and new traits for barley breeding. The relative height estimation of the canopy by UAV achieved high precision (up to r = 0.93) and repeatability (up to R2 = 0.98). In addition, we found a great overlap of detected significant genotypes between the reference heights and sensor-based heights. The yield prediction accuracy of both sensor systems was at the same level and reached a maximum prediction accuracy of r2 = 0.82 with a continuous increase in precision throughout the entire vegetation period. Due to the lower costs and the consumer-friendly handling of image acquisition and processing, the RGB imagery seems to be more suitable for yield prediction in this study.
KW  - barley (Hordeum vulgare ssp. vulgare)
KW  - remote sensing
KW  - unmanned aerial vehicle (UAV)
KW  - multi-spectral imagery
KW  - RGB imagery
KW  - crop height modelling
KW  - vegetation cover modelling
KW  - growth dynamics
KW  - yield prediction
KW  - genotype association study
DO  - 10.3390/rs13142670
ER  -
TY  - EJOU
AU  - Liu, Zhi
AU  - Yang, Shuyuan
AU  - Feng, Zhixi
AU  - Gao, Quanwei
AU  - Wang, Min
TI  - Fast SAR Autofocus Based on Ensemble Convolutional Extreme Learning Machine
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - Inaccurate Synthetic Aperture Radar (SAR) navigation information will lead to unknown phase errors in SAR data. Uncompensated phase errors can blur the SAR images. Autofocus is a technique that can automatically estimate phase errors from data. However, existing autofocus algorithms either have poor focusing quality or a slow focusing speed. In this paper, an ensemble learning-based autofocus method is proposed. Convolutional Extreme Learning Machine (CELM) is constructed and utilized to estimate the phase error. However, the performance of a single CELM is poor. To overcome this, a novel, metric-based combination strategy is proposed, combining multiple CELMs to further improve the estimation accuracy. The proposed model is trained with the classical bagging-based ensemble learning method. The training and testing process is non-iterative and fast. Experimental results conducted on real SAR data show that the proposed method has a good trade-off between focusing quality and speed.
KW  - synthetic aperture radar
KW  - autofocus
KW  - ensemble learning
KW  - extreme learning machine
KW  - convolutional neural network
DO  - 10.3390/rs13142683
ER  -
TY  - EJOU
AU  - Mhango, Joseph K.
AU  - Harris, Edwin W.
AU  - Green, Richard
AU  - Monaghan, James M.
TI  - Mapping Potato Plant Density Variation Using Aerial Imagery and Deep Learning Techniques for Precision Agriculture
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - In potato (Solanum tuberosum) production, the number of tubers harvested and their sizes are related to the plant population. Field maps of the spatial variation in plant density can therefore provide a decision support tool for spatially variable harvest timing to optimize tuber sizes by allowing densely populated management zones more tuber-bulking time. Computer vision has been proposed to enumerate plant numbers using images from unmanned aerial vehicles (UAV) but inaccurate predictions in images of merged canopies remains a challenge. Some research has been done on individual potato plant bounding box prediction but there is currently no information on the spatial structure of plant density that these models may reveal and its relationship with potato yield quality attributes. In this study, the Faster Region-based Convolutional Neural Network (FRCNN) framework was used to produce a plant detection model and estimate plant densities across a UAV orthomosaic. Using aerial images of 2 mm ground sampling distance (GSD) collected from potatoes at 40 days after planting, the FRCNN model was trained to an average precision (aP) of 0.78 on unseen testing data. The model was then used to generate predictions on quadrants imposed on orthorectified rasters captured at 14 and 18 days after emergence. After spatially interpolating the plant densities, the resultant surfaces were highly correlated to manually-determined plant density (R2 = 0.80). Further correlations were observed with tuber number (r = 0.54 at Butter Hill; r = 0.53 at Horse Foxhole), marketable tuber weight per plant (r = −0.57 at Buttery Hill; r = −0.56 at Horse Foxhole) and the normalized difference vegetation index (r = 0.61). These results show that accurate two-dimensional maps of plant density can be constructed from UAV imagery with high correlation to important yield components, despite the loss of accuracy of FRCNN models in partially merged canopies.
KW  - potatoes
KW  - UAV
KW  - deep learning
KW  - satellite
KW  - precision agriculture
DO  - 10.3390/rs13142705
ER  -
TY  - EJOU
AU  - Huang, Shenjin
AU  - Han, Wenting
AU  - Chen, Haipeng
AU  - Li, Guang
AU  - Tang, Jiandong
TI  - Recognizing Zucchinis Intercropped with Sunflowers in UAV Visible Images Using an Improved Method Based on OCRNet
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - An improved semantic segmentation method based on object contextual representations network (OCRNet) is proposed to accurately identify zucchinis intercropped with sunflowers from unmanned aerial vehicle (UAV) visible images taken over Hetao Irrigation District, Inner Mongolia, China. The proposed method improves on the performance of OCRNet in two respects. First, based on the object region context extraction structure of the OCRNet, a branch that uses the channel attention module was added in parallel to rationally use channel feature maps with different weights and reduce the noise of invalid channel features. Secondly, Lovász-Softmax loss was introduced to improve the accuracy of the object region representation in the OCRNet and optimize the final segmentation result at the object level. We compared the proposed method with extant advanced semantic segmentation methods (PSPNet, DeepLabV3+, DNLNet, and OCRNet) in two test areas to test its effectiveness. The results showed that the proposed method achieved the best semantic segmentation effect in the two test areas. More specifically, our method performed better in processing image details, segmenting field edges, and identifying intercropping fields. The proposed method has significant advantages for crop classification and intercropping recognition based on UAV visible images, and these advantages are more substantive in object-level evaluation metrics (mIoU and intercropping IoU).
KW  - intercropping identification
KW  - UAV remote sensing
KW  - semantic segmentation
KW  - OCRNet
DO  - 10.3390/rs13142706
ER  -
TY  - EJOU
AU  - Bui, Quang-Thanh
AU  - Chou, Tien-Yin
AU  - Hoang, Thanh-Van
AU  - Fang, Yao-Min
AU  - Mu, Ching-Yun
AU  - Huang, Pi-Hui
AU  - Pham, Vu-Dong
AU  - Nguyen, Quoc-Huy
AU  - Anh, Do T.
AU  - Pham, Van-Manh
AU  - Meadows, Michael E.
TI  - Gradient Boosting Machine and Object-Based CNN for Land Cover Classification
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - In regular convolutional neural networks (CNN), fully-connected layers act as classifiers to estimate the probabilities for each instance in classification tasks. The accuracy of CNNs can be improved by replacing fully connected layers with gradient boosting algorithms. In this regard, this study investigates three robust classifiers, namely XGBoost, LightGBM, and Catboost, in combination with a CNN for a land cover study in Hanoi, Vietnam. The experiments were implemented using SPOT7 imagery through (1) image segmentation and extraction of features, including spectral information and spatial metrics, (2) normalization of attribute values and generation of graphs, and (3) using graphs as the input dataset to the investigated models for classifying six land cover classes, namely House, Bare land, Vegetation, Water, Impervious Surface, and Shadow. The results show that CNN-based XGBoost (Overall accuracy = 0.8905), LightGBM (0.8956), and CatBoost (0.8956) outperform the other methods used for comparison. It can be seen that the combination of object-based image analysis and CNN-based gradient boosting algorithms significantly improves classification accuracies and can be considered as alternative methods for land cover analysis.
KW  - object-based image analysis
KW  - gradient boosting
KW  - convolutional neural network
KW  - land cover
DO  - 10.3390/rs13142709
ER  -
TY  - EJOU
AU  - Li, Guang
AU  - Han, Wenting
AU  - Huang, Shenjin
AU  - Ma, Weitong
AU  - Ma, Qian
AU  - Cui, Xin
TI  - Extraction of Sunflower Lodging Information Based on UAV Multi-Spectral Remote Sensing and Deep Learning
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - The rapid and accurate identification of sunflower lodging is important for the assessment of damage to sunflower crops. To develop a fast and accurate method of extraction of information on sunflower lodging, this study improves the inputs to SegNet and U-Net to render them suitable for multi-band image processing. Random forest and two improved deep learning methods are combined with RGB, RGB + NIR, RGB + red-edge, and RGB + NIR + red-edge bands of multi-spectral images captured by a UAV (unmanned aerial vehicle) to construct 12 models to extract information on sunflower lodging. These models are then combined with the method used to ignore edge-related information to predict sunflower lodging. The results of experiments show that the deep learning methods were superior to the random forest method in terms of the obtained lodging information and accuracy. The predictive accuracy of the model constructed by using a combination of SegNet and RGB + NIR had the highest overall accuracy of 88.23%. Adding NIR to RGB improved the accuracy of extraction of the lodging information whereas adding red-edge reduced it. An overlay analysis of the results for the lodging area shows that the extraction error was mainly caused by the failure of the model to recognize lodging in mixed areas and low-coverage areas. The predictive accuracy of information on sunflower lodging when edge-related information was ignored was about 2% higher than that obtained by using the direct splicing method.
KW  - sunflower lodging
KW  - deep learning
KW  - multispectral remote sensing
KW  - UAV (unmanned aerial vehicle)
DO  - 10.3390/rs13142721
ER  -
TY  - EJOU
AU  - Abdollahi, Abolfazl
AU  - Pradhan, Biswajeet
TI  - Urban Vegetation Mapping from Aerial Imagery Using Explainable AI (XAI)
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 14
SN  - 1424-8220

AB  - Urban vegetation mapping is critical in many applications, i.e., preserving biodiversity, maintaining ecological balance, and minimizing the urban heat island effect. It is still challenging to extract accurate vegetation covers from aerial imagery using traditional classification approaches, because urban vegetation categories have complex spatial structures and similar spectral properties. Deep neural networks (DNNs) have shown a significant improvement in remote sensing image classification outcomes during the last few years. These methods are promising in this domain, yet unreliable for various reasons, such as the use of irrelevant descriptor features in the building of the models and lack of quality in the labeled image. Explainable AI (XAI) can help us gain insight into these limits and, as a result, adjust the training dataset and model as needed. Thus, in this work, we explain how an explanation model called Shapley additive explanations (SHAP) can be utilized for interpreting the output of the DNN model that is designed for classifying vegetation covers. We want to not only produce high-quality vegetation maps, but also rank the input parameters and select appropriate features for classification. Therefore, we test our method on vegetation mapping from aerial imagery based on spectral and textural features. Texture features can help overcome the limitations of poor spectral resolution in aerial imagery for vegetation mapping. The model was capable of obtaining an overall accuracy (OA) of 94.44% for vegetation cover mapping. The conclusions derived from SHAP plots demonstrate the high contribution of features, such as Hue, Brightness, GLCM_Dissimilarity, GLCM_Homogeneity, and GLCM_Mean to the output of the proposed model for vegetation mapping. Therefore, the study indicates that existing vegetation mapping strategies based only on spectral characteristics are insufficient to appropriately classify vegetation covers.
KW  - XAI
KW  - deep neural network
KW  - remote sensing
KW  - SHAP
KW  - vegetation mapping
DO  - 10.3390/s21144738
ER  -
TY  - EJOU
AU  - Zhang, Liang
AU  - Mou, Junmin
AU  - Chen, Pengfei
AU  - Li, Mengxia
TI  - Path Planning for Autonomous Ships: A Hybrid Approach Based on Improved APF and Modified VO Methods
T2  - Journal of Marine Science and Engineering

PY  - 2021
VL  - 9
IS  - 7
SN  - 2077-1312

AB  - In this research, a hybrid approach for path planning of autonomous ships that generates both global and local paths, respectively, is proposed. The global path is obtained via an improved artificial potential field (APF) method, which makes up for the shortcoming that the typical APF method easily falls into a local minimum. A modified velocity obstacle (VO) method that incorporates the closest point of approach (CPA) model and the International Regulations for Preventing Collisions at Sea (COLREGS), based on the typical VO method, can be used to get the local path. The contribution of this research is two-fold: (1) improvement of the typical APF and VO methods, making up for previous shortcomings, and integrated COLREGS rules and good seamanship, making the paths obtained more in line with navigation practice; (2) the research included global and local path planning, considering both the safety and maneuverability of the ship in the process of avoiding collision, and studied the whole process of avoiding collision in a relatively entirely way. A case study was then conducted to test the proposed approach in different situations. The results indicate that the proposed approach can find both global and local paths to avoid the target ship.
KW  - path planning
KW  - autonomous ship
KW  - velocity obstacles method
KW  - artificial potential field method
DO  - 10.3390/jmse9070761
ER  -
TY  - EJOU
AU  - Wengert, Matthias
AU  - Piepho, Hans-Peter
AU  - Astor, Thomas
AU  - Graß, Rüdiger
AU  - Wijesingha, Jayan
AU  - Wachendorf, Michael
TI  - Assessing Spatial Variability of Barley Whole Crop Biomass Yield and Leaf Area Index in Silvoarable Agroforestry Systems Using UAV-Borne Remote Sensing
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - Agroforestry systems (AFS) can provide positive ecosystem services while at the same time stabilizing yields under increasingly common drought conditions. The effect of distance to trees in alley cropping AFS on yield-related crop parameters has predominantly been studied using point data from transects. Unmanned aerial vehicles (UAVs) offer a novel possibility to map plant traits with high spatial resolution and coverage. In the present study, UAV-borne red, green, blue (RGB) and multispectral imagery was utilized for the prediction of whole crop dry biomass yield (DM) and leaf area index (LAI) of barley at three different conventionally managed silvoarable alley cropping agroforestry sites located in Germany. DM and LAI were modelled using random forest regression models with good accuracies (DM: R² 0.62, nRMSEp 14.9%, LAI: R² 0.92, nRMSEp 7.1%). Important variables for prediction included normalized reflectance, vegetation indices, texture and plant height. Maps were produced from model predictions for spatial analysis, showing significant effects of distance to trees on DM and LAI. Spatial patterns differed greatly between the sampled sites and suggested management and soil effects overriding tree effects across large portions of 96 m wide crop alleys, thus questioning alleged impacts of AFS tree rows on yield distribution in intensively managed barley populations. Models based on UAV-borne imagery proved to be a valuable novel tool for prediction of DM and LAI at high accuracies, revealing spatial variability in AFS with high spatial resolution and coverage.
KW  - UAV
KW  - agroforestry
KW  - multispectral
KW  - barley
KW  - alley cropping
KW  - predictive modelling
KW  - SFM
DO  - 10.3390/rs13142751
ER  -
TY  - EJOU
AU  - Anderson, Nicholas T.
AU  - Walsh, Kerry B.
AU  - Wulfsohn, Dvoralai
TI  - Technologies for Forecasting Tree Fruit Load and Harvest Timing—From Ground, Sky and Time
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 7
SN  - 2073-4395

AB  - The management and marketing of fruit requires data on expected numbers, size, quality and timing. Current practice estimates orchard fruit load based on the qualitative assessment of fruit number per tree and historical orchard yield, or manually counting a subsample of trees. This review considers technological aids assisting these estimates, in terms of: (i) improving sampling strategies by the number of units to be counted and their selection; (ii) machine vision for the direct measurement of fruit number and size on the canopy; (iii) aerial or satellite imagery for the acquisition of information on tree structural parameters and spectral indices, with the indirect assessment of fruit load; (iv) models extrapolating historical yield data with knowledge of tree management and climate parameters, and (v) technologies relevant to the estimation of harvest timing such as heat units and the proximal sensing of fruit maturity attributes. Machine vision is currently dominating research outputs on fruit load estimation, while the improvement of sampling strategies has potential for a widespread impact. Techniques based on tree parameters and modeling offer scalability, but tree crops are complicated (perennialism). The use of machine vision for flowering estimates, fruit sizing, external quality evaluation is also considered. The potential synergies between technologies are highlighted.
KW  - yield
KW  - estimation
KW  - machine vision
KW  - remote sensing
KW  - correlative
KW  - models
KW  - fruit
KW  - tree
KW  - review
DO  - 10.3390/agronomy11071409
ER  -
TY  - EJOU
AU  - Lai, Zhengchao
AU  - Liu, Fei
AU  - Guo, Shangwei
AU  - Meng, Xiantong
AU  - Han, Shaokun
AU  - Li, Wenhao
TI  - Onboard Real-Time Dense Reconstruction in Large Terrain Scene Using Embedded UAV Platform
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - Using unmanned aerial vehicles (UAVs) for remote sensing has the advantages of high flexibility, convenient operation, low cost, and wide application range. It fills the need for rapid acquisition of high-resolution aerial images in modern photogrammetry applications. Due to the insufficient parallaxes and the computation-intensive process, dense real-time reconstruction for large terrain scenes is a considerable challenge. To address these problems, we proposed a novel SLAM-based MVS (Multi-View-Stereo) approach, which can incrementally generate a dense 3D (three-dimensional) model of the terrain by using the continuous image stream during the flight. The pipeline of the proposed methodology starts with pose estimation based on SLAM algorithm. The tracked frames were then selected by a novel scene-adaptive keyframe selection method to construct a sliding window frame-set. This was followed by depth estimation using a flexible search domain approach, which can improve accuracy without increasing the iterate time or memory consumption. The whole system proposed in this study was implemented on the embedded GPU based on an UAV platform. We proposed a highly parallel and memory-efficient CUDA-based depth computing architecture, enabling the system to achieve good real-time performance. The evaluation experiments were carried out in both simulation and real-world environments. A virtual large terrain scene was built using the Gazebo simulator. The simulated UAV equipped with an RGB-D camera was used to obtain synthetic evaluation datasets, which were divided by flight altitudes (800-, 1000-, 1200 m) and terrain height difference (100-, 200-, 300 m). In addition, the system has been extensively tested on various types of real scenes. Comparison with commercial 3D reconstruction software is carried out to evaluate the precision in real-world data. According to the results on the synthetic datasets, over 93.462% of the estimation with absolute error distance of less then 0.9%. In the real-world dataset captured at 800 m flight height, more than 81.27% of our estimated point cloud are less then 5 m difference with the results of Photoscan. All evaluation experiments show that the proposed approach outperforms the state-of-the-art ones in terms of accuracy and efficiency.
KW  - UAV
KW  - SLAM
KW  - MVS
KW  - real-time 3D reconstruction
KW  - embedded GPU
KW  - CUDA
KW  - Gazebo simulator
DO  - 10.3390/rs13142778
ER  -
TY  - EJOU
AU  - Munawar, Hafiz S.
AU  - Hammad, Ahmed W. A.
AU  - Waller, S. T.
AU  - Thaheem, Muhammad J.
AU  - Shrestha, Asheem
TI  - An Integrated Approach for Post-Disaster Flood Management Via the Use of Cutting-Edge Technologies and UAVs: A Review
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 14
SN  - 2071-1050

AB  - Rapid advances that improve flood management have facilitated the disaster response by providing first aid services, finding safe routes, maintaining communication and developing flood maps. Different technologies such as image processing, satellite imagery, synthetic imagery and integrated approaches have been extensively analysed in the literature for disaster operations. There is a need to review cutting-edge technologies for flood management. This paper presents a review of the latest advancements in the flood management domain based on image processing, artificial intelligence and integrated approaches with a focus on post-disaster. It answers the following research questions: (1) What are the latest developments in image processing for flood management in a post-disaster scenario? (2) What are the latest techniques for flood management based on artificial intelligence in a post-disaster scenario? (3) What are the existing gaps in the selected technologies for post-disaster? (4) How can the authorities improve the existing post-disaster management operation with cutting-edge technologies? A novel framework has been proposed to optimise flood management with the application of a holistic approach.
KW  - natural disaster
KW  - early warning system
KW  - artificial intelligence
KW  - image processing
DO  - 10.3390/su13147925
ER  -
TY  - EJOU
AU  - Li, Jingbo
AU  - Li, Changchun
AU  - Fei, Shuaipeng
AU  - Ma, Chunyan
AU  - Chen, Weinan
AU  - Ding, Fan
AU  - Wang, Yilin
AU  - Li, Yacong
AU  - Shi, Jinjin
AU  - Xiao, Zhen
TI  - Wheat Ear Recognition Based on RetinaNet and Transfer Learning
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 14
SN  - 1424-8220

AB  - The number of wheat ears is an essential indicator for wheat production and yield estimation, but accurately obtaining wheat ears requires expensive manual cost and labor time. Meanwhile, the characteristics of wheat ears provide less information, and the color is consistent with the background, which can be challenging to obtain the number of wheat ears required. In this paper, the performance of Faster regions with convolutional neural networks (Faster R-CNN) and RetinaNet to predict the number of wheat ears for wheat at different growth stages under different conditions is investigated. The results show that using the Global WHEAT dataset for recognition, the RetinaNet method, and the Faster R-CNN method achieve an average accuracy of 0.82 and 0.72, with the RetinaNet method obtaining the highest recognition accuracy. Secondly, using the collected image data for recognition, the R2 of RetinaNet and Faster R-CNN after transfer learning is 0.9722 and 0.8702, respectively, indicating that the recognition accuracy of the RetinaNet method is higher on different data sets. We also tested wheat ears at both the filling and maturity stages; our proposed method has proven to be very robust (the R2 is above 90). This study provides technical support and a reference for automatic wheat ear recognition and yield estimation.
KW  - RetinaNet
KW  - deep learning
KW  - transfer learning
KW  - wheat ears
KW  - Global WHEAT
DO  - 10.3390/s21144845
ER  -
TY  - EJOU
AU  - Messina, Gaetano
AU  - Praticò, Salvatore
AU  - Badagliacca, Giuseppe
AU  - Di Fazio, Salvatore
AU  - Monti, Michele
AU  - Modica, Giuseppe
TI  - Monitoring Onion Crop “Cipolla Rossa di Tropea Calabria IGP” Growth and Yield Response to Varying Nitrogen Fertilizer Application Rates Using UAV Imagery
T2  - Drones

PY  - 2021
VL  - 5
IS  - 3
SN  - 2504-446X

AB  - Remote sensing (RS) platforms such as unmanned aerial vehicles (UAVs) represent an essential source of information in precision agriculture (PA) as they are able to provide images on a daily basis and at a very high resolution. In this framework, this study aims to identify the optimal level of nitrogen (N)-based nutrients for improved productivity in an onion field of “Cipolla Rossa di Tropea” (Tropea red onion). Following an experiment that involved the arrangement of nine plots in the onion field in a randomized complete block design (RCBD), with three replications, three different levels of N fertilization were compared: N150 (150 kg N ha−1), N180 (180 kg N ha−1), and e N210 (210 kg N ha−1). The crop cycle was monitored using multispectral (MS) UAV imagery, producing vigor maps and taking into account the yield of data. The soil-adjusted vegetation index (SAVI) was used to monitor the vigor of the crop. In addition, the coverage’s class onion was spatially identified using geographical object-based image classification (GEOBIA), observing differences in SAVI values obtained in plots subjected to differentiated N fertilizer treatment. The information retrieved from the analysis of soil properties (electrical conductivity, ammonium and nitrate nitrogen), yield performance and mean SAVI index data from each field plot showed significant relationships between the different indicators investigated. A higher onion yield was evident in plot N180, in which SAVI values were higher based on the production data.
KW  - Tropea red onion
KW  - multispectral (MS) imagery
KW  - multiresolution segmentation
KW  - precision agriculture (PA)
KW  - soil-adjusted vegetation index (SAVI)
KW  - geographic object-based image analysis (GEOBIA)
DO  - 10.3390/drones5030061
ER  -
TY  - EJOU
AU  - Jiang, Fugen
AU  - Chen, Chuanshi
AU  - Li, Chengjie
AU  - Kutia, Mykola
AU  - Sun, Hua
TI  - A Novel Spatial Simulation Method for Mapping the Urban Forest Carbon Density in Southern China by the Google Earth Engine
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - Urban forest is an important component of terrestrial ecosystems and is highly related to global climate change. However, because of complex city landscapes, deriving the spatial distribution of urban forest carbon density and conducting accuracy assessments are difficult. This study proposes a novel spatial simulation method, optimized geographically weighted logarithm regression (OGWLR), using Landsat 8 data acquired by the Google Earth Engine (GEE) and field survey data to map the forest carbon density of Shenzhen city in southern China. To verify the effectiveness of the novel method, multiple linear regression (MLR), k-nearest neighbors (kNN), random forest (RF) and geographically weighted regression (GWR) models were established for comparison. The results showed that OGWLR achieved the highest coefficient of determination (R2 = 0.54) and the lowest root mean square error (RMSE = 13.28 Mg/ha) among all estimation models. In addition, OGWLR achieved a more consistent spatial distribution of carbon density with the actual situation. The carbon density of the forests in the study area was large in the central and western regions and coastal areas and small in the building and road areas. Therefore, this method can provide a new reference for urban forest carbon density estimation and mapping.
KW  - forest carbon density
KW  - Landsat 8
KW  - GEE
KW  - geographically weighted regression
DO  - 10.3390/rs13142792
ER  -
TY  - EJOU
AU  - Ran, Shuhao
AU  - Gao, Xianjun
AU  - Yang, Yuanwei
AU  - Li, Shaohua
AU  - Zhang, Guangbin
AU  - Wang, Ping
TI  - Building Multi-Feature Fusion Refined Network for Building Extraction from High-Resolution Remote Sensing Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - Deep learning approaches have been widely used in building automatic extraction tasks and have made great progress in recent years. However, the missing detection and wrong detection causing by spectrum confusion is still a great challenge. The existing fully convolutional networks (FCNs) cannot effectively distinguish whether the feature differences are from one building or the building and its adjacent non-building objects. In order to overcome the limitations, a building multi-feature fusion refined network (BMFR-Net) was presented in this paper to extract buildings accurately and completely. BMFR-Net is based on an encoding and decoding structure, mainly consisting of two parts: the continuous atrous convolution pyramid (CACP) module and the multiscale output fusion constraint (MOFC) structure. The CACP module is positioned at the end of the contracting path and it effectively minimizes the loss of effective information in multiscale feature extraction and fusion by using parallel continuous small-scale atrous convolution. To improve the ability to aggregate semantic information from the context, the MOFC structure performs predictive output at each stage of the expanding path and integrates the results into the network. Furthermore, the multilevel joint weighted loss function effectively updates parameters well away from the output layer, enhancing the learning capacity of the network for low-level abstract features. The experimental results demonstrate that the proposed BMFR-Net outperforms the other five state-of-the-art approaches in both visual interpretation and quantitative evaluation.
KW  - high-resolution remote sensing images
KW  - building extraction
KW  - multiscale features
KW  - aggregate semantic information
KW  - feature pyramid
DO  - 10.3390/rs13142794
ER  -
TY  - EJOU
AU  - Vandendaele, Bastien
AU  - Fournier, Richard A.
AU  - Vepakomma, Udayalakshmi
AU  - Pelletier, Gaetan
AU  - Lejeune, Philippe
AU  - Martin-Ducup, Olivier
TI  - Estimation of Northern Hardwood Forest Inventory Attributes Using UAV Laser Scanning (ULS): Transferability of Laser Scanning Methods and Comparison of Automated Approaches at the Tree- and Stand-Level
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - UAV laser scanning (ULS) has the potential to support forest operations since it provides high-density data with flexible operational conditions. This study examined the use of ULS systems to estimate several tree attributes from an uneven-aged northern hardwood stand. We investigated: (1) the transferability of raster-based and bottom-up point cloud-based individual tree detection (ITD) algorithms to ULS data; and (2) automated approaches to the retrieval of tree-level (i.e., height, crown diameter (CD), DBH) and stand-level (i.e., tree count, basal area (BA), DBH-distribution) forest inventory attributes. These objectives were studied under leaf-on and leaf-off canopy conditions. Results achieved from ULS data were cross-compared with ALS and TLS to better understand the potential and challenges faced by different laser scanning systems and methodological approaches in hardwood forest environments. The best results that characterized individual trees from ULS data were achieved under leaf-off conditions using a point cloud-based bottom-up ITD. The latter outperformed the raster-based ITD, improving the accuracy of tree detection (from 50% to 71%), crown delineation (from R2 = 0.29 to R2 = 0.61), and prediction of tree DBH (from R2 = 0.36 to R2 = 0.67), when compared with values that were estimated from reference TLS data. Major improvements were observed for the detection of trees in the lower canopy layer (from 9% with raster-based ITD to 51% with point cloud-based ITD) and in the intermediate canopy layer (from 24% with raster-based ITD to 59% with point cloud-based ITD). Under leaf-on conditions, LiDAR data from aerial systems include substantial signal occlusion incurred by the upper canopy. Under these conditions, the raster-based ITD was unable to detect low-level canopy trees (from 5% to 15% of trees detected from lower and intermediate canopy layers, respectively), resulting in a tree detection rate of about 40% for both ULS and ALS data. The cylinder-fitting method used to estimate tree DBH under leaf-off conditions did not meet inventory standards when compared to TLS DBH, resulting in RMSE = 7.4 cm, Bias = 3.1 cm, and R2 = 0.75. Yet, it yielded more accurate estimates of the BA (+3.5%) and DBH-distribution of the stand than did allometric models −12.9%), when compared with in situ field measurements. Results suggest that the use of bottom-up ITD on high-density ULS data from leaf-off hardwood forest leads to promising results when estimating trees and stand attributes, which opens up new possibilities for supporting forest inventories and operations.
KW  - UAV laser scanning (ULS)
KW  - hardwood
KW  - uneven-aged forest
KW  - individual tree detection and delineation (ITD)
KW  - forest inventory
KW  - diameter at breast height (DBH)
KW  - airborne laser scanning (ALS)
KW  - terrestrial laser scanning (TLS)
KW  - open-source analytic tools
DO  - 10.3390/rs13142796
ER  -
TY  - EJOU
AU  - Jing, Chenchen
AU  - Zhu, Yanyan
AU  - Wang, Jie
AU  - Wang, Feifan
AU  - Lu, Jiping
AU  - Liu, Changmeng
TI  - Investigation on Morphology and Mechanical Properties of Rod Units in Lattice Structures Fabricated by Selective Laser Melting
T2  - Materials

PY  - 2021
VL  - 14
IS  - 14
SN  - 1996-1944

AB  - Selective laser melting (SLM) fabrication of lattice structures has attracted considerable interest due to its many immanent advantages, such as high specific strength. A wide variety of lattice structures have been designed and fabricated. However, as a vital prerequisite for design optimization, a clear relation between the process constraint of SLM and the apparent properties of the fabricated lattice structure has received much less attention. Therefore, this work systematically investigates the characterization and preformation of rod units, which are the basic components of lattice structures, so as to evaluate the SLM manufacturability of lattice structures. A series of rod units with different inclination angles and diameters were fabricated by SLM. Their morphology and mechanical properties were measured by scanning electron microscope observation and a tensile test, respectively. The inclination angle was found to have significant effects on profile error and little effect on mechanical properties. The higher the inclination angle, the larger the profile error. The characteristic diameter had no significant correlation with profile errors and mechanical properties. Based on systematic studies, a formula is proposed to evaluate the cross-sectional area of the fabricated rod units and further estimate their load capacity. This has important implications for optimizing the design of lattice structures fabricated by SLM.
KW  - lattice structures
KW  - selective laser melting
KW  - Ti-6Al-4V
KW  - morphology
KW  - mechanical properties
DO  - 10.3390/ma14143994
ER  -
TY  - EJOU
AU  - Vásquez, Felipe
AU  - Cravero, Ania
AU  - Castro, Manuel
AU  - Acevedo, Patricio
TI  - Decision Support System Development of Wildland Fire: A Systematic Mapping
T2  - Forests

PY  - 2021
VL  - 12
IS  - 7
SN  - 1999-4907

AB  - Wildland fires have been a rising problem on the worldwide level, generating ecological and economic losses. Specifically, between wildland fire types, uncontrolled fires are critical due to the potential damage to the ecosystem and their effects on the soil, and, in the last decade, different technologies have been applied to fight them. Selecting a specific technology and Decision Support Systems (DSS) is fundamental, since the results and validity of this could drastically oscillate according to the different environmental and geographic factors of the terrain to be studied. Given the above, a systematic mapping was realized, with the purpose of recognizing the most-used DSS and context where they have been applied. One hundred and eighty-three studies were found that used different types of DSS to solve problems of detection, prediction, prevention, monitoring, simulation, administration, and access to routes. The concepts key to the type of solution are related to the use or development of systems or Information and Communication Technologies (ICT) in the computer science area. Although the use of BA and Big Data has increased in recent years, there are still many challenges to face, such as staff training, the friendly environment of DSS, and real-time decision-making.
KW  - wildland fire
KW  - forest fire
KW  - decision support systems
KW  - systematic mapping
DO  - 10.3390/f12070943
ER  -
TY  - EJOU
AU  - Lin, Zhe
AU  - Guo, Wenxuan
TI  - Cotton Stand Counting from Unmanned Aerial System Imagery Using MobileNet and CenterNet Deep Learning Models
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - An accurate stand count is a prerequisite to determining the emergence rate, assessing seedling vigor, and facilitating site-specific management for optimal crop production. Traditional manual counting methods in stand assessment are labor intensive and time consuming for large-scale breeding programs or production field operations. This study aimed to apply two deep learning models, the MobileNet and CenterNet, to detect and count cotton plants at the seedling stage with unmanned aerial system (UAS) images. These models were trained with two datasets containing 400 and 900 images with variations in plant size and soil background brightness. The performance of these models was assessed with two testing datasets of different dimensions, testing dataset 1 with 300 by 400 pixels and testing dataset 2 with 250 by 1200 pixels. The model validation results showed that the mean average precision (mAP) and average recall (AR) were 79% and 73% for the CenterNet model, and 86% and 72% for the MobileNet model with 900 training images. The accuracy of cotton plant detection and counting was higher with testing dataset 1 for both CenterNet and MobileNet models. The results showed that the CenterNet model had a better overall performance for cotton plant detection and counting with 900 training images. The results also indicated that more training images are required when applying object detection models on images with different dimensions from training datasets. The mean absolute percentage error (MAPE), coefficient of determination (R2), and the root mean squared error (RMSE) values of the cotton plant counting were 0.07%, 0.98 and 0.37, respectively, with testing dataset 1 for the CenterNet model with 900 training images. Both MobileNet and CenterNet models have the potential to accurately and timely detect and count cotton plants based on high-resolution UAS images at the seedling stage. This study provides valuable information for selecting the right deep learning tools and the appropriate number of training images for object detection projects in agricultural applications.
KW  - cotton stand count
KW  - unmanned aerial systems
KW  - deep learning
KW  - remote sensing
KW  - MobileNet
KW  - CenterNet
KW  - Python
KW  - Tensorflow
DO  - 10.3390/rs13142822
ER  -
TY  - EJOU
AU  - Tanwar, Monika
AU  - Park, Hyunseok
AU  - Raghavan, Nagarajan
TI  - Multistate Diagnosis and Prognosis of Lubricating Oil Degradation Using Sticky Hierarchical Dirichlet Process–Hidden Markov Model Framework
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 14
SN  - 2076-3417

AB  - In this study, we present a state-based diagnostic and prognostic methodology for lubricating oil degradation based on a nonparametric Bayesian approach, i.e., sticky hierarchical Dirichlet process–hidden Markov model (HDP-HMM). An accurate health state-space assessment for diagnostics and prognostics has always been unobservable and hypothetical in the past. The lubrication condition monitoring (LCM) data is generally segregated as “healthy or unhealthy”, representing a binary state-based perspective to the problem. This two-state performance-based formulation poses limitations to the precision and accuracy of the diagnosis and prognosis for real data wherein there may be multiple states of discrete performance that are characteristic of the system functionality. In particular, the reversible and nonlinear time-series trends of degradation data increase the complexity of state-based modeling. We propose a multistate diagnostic and prognostic framework for LCM data in the wear-out phase (i.e., the unhealthy portion of degradation data), accounting for irregular oil replenishment and oil change effects (i.e., nonlinearity in the degradation signal). The LCM data is simulated for an elementary mechanical system with four components. The sticky HDP sets the prior for the HMM parameters. The unsupervised learning over infinite observations and emission reveals four discrete health states and helps estimate the associated state transition probabilities. The inferred state sequence provides information relating to the state dynamics, which provides further guidance to maintenance decision making. The decision making is further backed by prognostics based on the conditional reliability function and mean residual life estimation.
KW  - sticky HDP-HMM
KW  - Dirichlet process
KW  - health state estimation
KW  - hidden Markov model
KW  - diagnostics
KW  - prognostics
KW  - lubricating oil
DO  - 10.3390/app11146603
ER  -
TY  - EJOU
AU  - Hu, Pengcheng
AU  - Chapman, Scott C.
AU  - Jin, Huidong
AU  - Guo, Yan
AU  - Zheng, Bangyou
TI  - Comparison of Modelling Strategies to Estimate Phenotypic Values from an Unmanned Aerial Vehicle with Spectral and Temporal Vegetation Indexes
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - Aboveground dry weight (AGDW) and leaf area index (LAI) are indicators of crop growth status and grain yield as affected by interactions of genotype, environment, and management. Unmanned aerial vehicle (UAV) based remote sensing provides cost-effective and non-destructive methods for the high-throughput phenotyping of crop traits (e.g., AGDW and LAI) through the integration of UAV-derived vegetation indexes (VIs) with statistical models. However, the effects of different modelling strategies that use different dataset compositions of explanatory variables (i.e., combinations of sources and temporal combinations of the VI datasets) on estimates of AGDW and LAI have rarely been evaluated. In this study, we evaluated the effects of three sources of VIs (visible, spectral, and combined) and three types of temporal combinations of the VI datasets (mono-, multi-, and full-temporal) on estimates of AGDW and LAI. The VIs were derived from visible (RGB) and multi-spectral imageries, which were acquired by a UAV-based platform over a wheat trial at five sampling dates before flowering. Partial least squares regression models were built with different modelling strategies to estimate AGDW and LAI at each prediction date. The results showed that models built with the three sources of mono-temporal VIs obtained similar performances for estimating AGDW (RRMSE = 11.86% to 15.80% for visible, 10.25% to 16.70% for spectral, and 10.25% to 16.70% for combined VIs) and LAI (RRMSE = 13.30% to 22.56% for visible, 12.04% to 22.85% for spectral, and 13.45% to 22.85% for combined VIs) across prediction dates. Mono-temporal models built with visible VIs outperformed the other two sources of VIs in general. Models built with mono-temporal VIs generally obtained better estimates than models with multi- and full-temporal VIs. The results suggested that the use of UAV-derived visible VIs can be an alternative to multi-spectral VIs for high-throughput and in-season estimates of AGDW and LAI. The combination of modelling strategies that used mono-temporal datasets and a self-calibration method demonstrated the potential for in-season estimates of AGDW and LAI (RRMSE normally less than 15%) in breeding or agronomy trials.
KW  - aboveground dry weight
KW  - leaf area index
KW  - high-throughput phenotyping
KW  - remote sensing
DO  - 10.3390/rs13142827
ER  -
TY  - EJOU
AU  - Fernández-Novales, Juan
AU  - Saiz-Rubio, Verónica
AU  - Barrio, Ignacio
AU  - Rovira-Más, Francisco
AU  - Cuenca-Cuenca, Andrés
AU  - Santos Alves, Fernando
AU  - Valente, Joana
AU  - Tardaguila, Javier
AU  - Diago, María P.
TI  - Monitoring and Mapping Vineyard Water Status Using Non-Invasive Technologies by a Ground Robot
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - There is a growing need to provide support and applicable tools to farmers and the agro-industry in order to move from their traditional water status monitoring and high-water-demand cropping and irrigation practices to modern, more precise, reduced-demand systems and technologies. In precision viticulture, very few approaches with ground robots have served as moving platforms for carrying non-invasive sensors to deliver field maps that help growers in decision making. The goal of this work is to demonstrate the capability of the VineScout (developed in the context of a H2020 EU project), a ground robot designed to assess and map vineyard water status using thermal infrared radiometry in commercial vineyards. The trials were carried out in Douro Superior (Portugal) under different irrigation treatments during seasons 2019 and 2020. Grapevines of Vitis vinifera L. Touriga Nacional were monitored at different timings of the day using leaf water potential (Ψl) as reference indicators of plant water status. Grapevines’ canopy temperature (Tc) values, recorded with an infrared radiometer, as well as data acquired with an environmental sensor (Tair, RH, and AP) and NDVI measurements collected with a multispectral sensor were automatically saved in the computer of the autonomous robot to assess and map the spatial variability of a commercial vineyard water status. Calibration and prediction models were performed using Partial Least Squares (PLS) regression. The best prediction models for grapevine water status yielded a determination coefficient of cross-validation (r2cv) of 0.57 in the morning time and a r2cv of 0.42 in the midday. The root mean square error of cross-validation (RMSEcv) was 0.191 MPa and 0.139 MPa at morning and midday, respectively. Spatial–temporal variation maps were developed at two different times of the day to illustrate the capability to monitor the grapevine water status in order to reduce the consumption of water, implementing appropriate irrigation strategies and increase the efficiency in the real time vineyard management. The promising outcomes gathered with the VineScout using different sensors based on thermography, multispectral imaging and environmental data disclose the need for further studies considering new variables related with the plant water status, and more grapevine cultivars, seasons and locations to improve the accuracy, robustness and reliability of the predictive models, in the context of precision and sustainable viticulture.
KW  - agricultural robotics
KW  - non-invasive proximal sensing
KW  - water stress
KW  - chemometrics
KW  - precision viticulture
DO  - 10.3390/rs13142830
ER  -
TY  - EJOU
AU  - Che’Ya, Nik N.
AU  - Dunwoody, Ernest
AU  - Gupta, Madan
TI  - Assessment of Weed Classification Using Hyperspectral Reflectance and Optimal Multispectral UAV Imagery
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 7
SN  - 2073-4395

AB  - Weeds compete with crops and are hard to differentiate and identify due to their similarities in color, shape, and size. In this study, the weed species present in sorghum (sorghum bicolor (L.) Moench) fields, such as amaranth (Amaranthus macrocarpus), pigweed (Portulaca oleracea), mallow weed (Malva sp.), nutgrass (Cyperus rotundus), liver seed grass (Urochoa panicoides), and Bellive (Ipomea plebeian), were discriminated using hyperspectral data and were detected and analyzed using multispectral images. Discriminant analysis (DA) was used to identify the most significant spectral bands in order to discriminate weeds from sorghum using hyperspectral data. The results demonstrated good separation accuracy for Amaranthus macrocarpus, Urochoa panicoides, Malva sp., Cyperus rotundus, and Sorghum bicolor (L.) Moench at 440, 560, 680, 710, 720, and 850 nm. Later, the multispectral images of these six bands were collected to detect weeds in the sorghum crop fields using object-based image analysis (OBIA). The results showed that the differences between sorghum and weed species were detectable using the six selected bands, with data collected using an unmanned aerial vehicle. Here, the highest spatial resolution had the highest accuracy for weed detection. It was concluded that each weed was successfully discriminated using hyperspectral data and was detectable using multispectral data with higher spatial resolution.
KW  - weed classification
KW  - hyperspectral reflectance
KW  - discriminant analysis
KW  - weed species
KW  - weed mapping
KW  - site-specific weed management
DO  - 10.3390/agronomy11071435
ER  -
TY  - EJOU
AU  - Hallee, Mitchell J.
AU  - Napolitano, Rebecca K.
AU  - Reinhart, Wesley F.
AU  - Glisic, Branko
TI  - Crack Detection in Images of Masonry Using CNNs
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 14
SN  - 1424-8220

AB  - While there is a significant body of research on crack detection by computer vision methods in concrete and asphalt, less attention has been given to masonry. We train a convolutional neural network (CNN) on images of brick walls built in a laboratory environment and test its ability to detect cracks in images of brick-and-mortar structures both in the laboratory and on real-world images taken from the internet. We also compare the performance of the CNN to a variety of simpler classifiers operating on handcrafted features. We find that the CNN performed better on the domain adaptation from laboratory to real-world images than these simple models. However, we also find that performance is significantly better in performing the reverse domain adaptation task, where the simple classifiers are trained on real-world images and tested on the laboratory images. This work demonstrates the ability to detect cracks in images of masonry using a variety of machine learning methods and provides guidance for improving the reliability of such models when performing domain adaptation for crack detection in masonry.
KW  - computer vision
KW  - crack detection
KW  - structural health monitoring
KW  - masonry
KW  - machine learning
KW  - convolutional neural network
DO  - 10.3390/s21144929
ER  -
TY  - EJOU
AU  - Wei, Baoquan
AU  - Zuo, Yong
AU  - Liu, Yande
AU  - Luo, Wei
AU  - Wen, Kaiyun
AU  - Deng, Fangming
TI  - Novel MOA Fault Detection Technology Based on Small Sample Infrared Image
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 15
SN  - 2079-9292

AB  - This paper proposes a novel metal oxide arrester (MOA) fault detection technology based on a small sample infrared image. The research is carried out from the detection process and data enhancement. A lightweight MOA identification and location algorithm is designed at the edge, which can not only reduce the amount of data uploaded, but also reduce the search space of cloud algorithm. In order to improve the accuracy and generalization ability of the defect detection model under the condition of small samples, a multi-model fusion detection algorithm is proposed. Different features of the image are extracted by multiple convolutional neural networks, and then multiple classifiers are trained. Finally, the weighted voting strategy is used for fault diagnosis. In addition, the extended model of fault samples is constructed by transfer learning and deep convolutional generative adversarial networks (DCGAN) to solve the problem of unbalanced training data sets. The experimental results show that the proposed method can realize the accurate location of arrester under the condition of small samples, and after the data expansion, the recognition rate of arrester anomalies can be improved from 83% to 85%, showing high effectiveness and reliability.
KW  - metal oxide arrester
KW  - deep learning
KW  - edge computing
KW  - condition monitoring
DO  - 10.3390/electronics10151748
ER  -
TY  - EJOU
AU  - Civico, Riccardo
AU  - Ricci, Tullio
AU  - Scarlato, Piergiorgio
AU  - Andronico, Daniele
AU  - Cantarero, Massimo
AU  - Carr, Brett B.
AU  - De Beni, Emanuela
AU  - Del Bello, Elisabetta
AU  - Johnson, Jeffrey B.
AU  - Kueppers, Ulrich
AU  - Pizzimenti, Luca
AU  - Schmid, Markus
AU  - Strehlow, Karen
AU  - Taddeucci, Jacopo
TI  - Unoccupied Aircraft Systems (UASs) Reveal the Morphological Changes at Stromboli Volcano (Italy) before, between, and after the 3 July and 28 August 2019 Paroxysmal Eruptions
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 15
SN  - 2072-4292

AB  - In July and August 2019, two paroxysmal eruptions dramatically changed the morphology of the crater terrace that hosts the active vents of Stromboli volcano (Italy). Here, we document these morphological changes, by using 2259 UAS-derived photographs from eight surveys and Structure-from-Motion (SfM) photogrammetric techniques, resulting in 3D point clouds, orthomosaics, and digital surface models (DSMs) with resolution ranging from 8.1 to 12.4 cm/pixel. We focus on the morphological evolution of volcanic features and volume changes in the crater terrace and the upper part of the underlying slope (Sciara del Fuoco). We identify both crater terrace and lava field variations, with vents shifting up to 47 m and the accumulation of tephra deposits. The maximum elevation changes related to the two paroxysmal eruptions (in between May and September 2019) range from +41.4 to −26.4 m at the lava field and N crater area, respectively. Throughout September 2018–June 2020, the total volume change in the surveyed area was +447,335 m3. Despite Stromboli being one of the best-studied volcanoes worldwide, the UAS-based photogrammetry products of this study provide unprecedented high spatiotemporal resolution observations of its entire summit area, in a period when volcanic activity made the classic field inspections and helicopter overflights too risky. Routinely applied UAS operations represent an effective and evolving tool for volcanic hazard assessment and to support decision-makers involved in volcanic surveillance and civil protection operations.
KW  - Stromboli
KW  - 2019 paroxysmal eruptions
KW  - UAS
KW  - Structure-from-Motion
KW  - photogrammetry
DO  - 10.3390/rs13152870
ER  -
TY  - EJOU
AU  - Ammar, Adel
AU  - Koubaa, Anis
AU  - Benjdira, Bilel
TI  - Deep-Learning-Based Automated Palm Tree Counting and Geolocation in Large Farms from Aerial Geotagged Images
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 8
SN  - 2073-4395

AB  - In this paper, we propose an original deep learning framework for the automated counting and geolocation of palm trees from aerial images using convolutional neural networks. For this purpose, we collected aerial images from two different regions in Saudi Arabia, using two DJI drones, and we built a dataset of around 11,000 instances of palm trees. Then, we applied several recent convolutional neural network models (Faster R-CNN, YOLOv3, YOLOv4, and EfficientDet) to detect palms and other trees, and we conducted a complete comparative evaluation in terms of average precision and inference speed. YOLOv4 and EfficientDet-D5 yielded the best trade-off between accuracy and speed (up to 99% mean average precision and 7.4 FPS). Furthermore, using the geotagged metadata of aerial images, we used photogrammetry concepts and distance corrections to automatically detect the geographical location of detected palm trees. This geolocation technique was tested on two different types of drones (DJI Mavic Pro and Phantom 4 pro) and was assessed to provide an average geolocation accuracy that attains 1.6 m. This GPS tagging allows us to uniquely identify palm trees and count their number from a series of drone images, while correctly dealing with the issue of image overlapping. Moreover, this innovative combination between deep learning object detection and geolocalization can be generalized to any other objects in UAV images.
KW  - unmanned aerial vehicles
KW  - convolutional neural networks
KW  - Faster R-CNN
KW  - You Only Look Once (YOLO)
DO  - 10.3390/agronomy11081458
ER  -
TY  - EJOU
AU  - Isheyskiy, Valentin
AU  - Martinyskin, Evgeny
AU  - Smirnov, Sergey
AU  - Vasilyev, Anton
AU  - Knyazev, Kirill
AU  - Fatyanov, Timur
TI  - Specifics of MWD Data Collection and Verification during Formation of Training Datasets
T2  - Minerals

PY  - 2021
VL  - 11
IS  - 8
SN  - 2075-163X

AB  - This paper presents a structured analysis in the area of measurement while drilling (MWD) data processing and verification methods, as well as describes the main nuances and certain specifics of “clean” data selection in order to build a “parent” training database for subsequent use in machine learning algorithms. The main purpose of the authors is to create a trainable machine learning algorithm, which, based on the available “clean” input data associated with specific conditions, could correlate, process and select parameters obtained from the drilling rig and use them for further estimation of various rock characteristics, prediction of optimal drilling and blasting parameters, and blasting results. The paper is a continuation of a series of publications devoted to the prospects of using MWD technology for the quality management of drilling and blasting operations at mining enterprises.
KW  - measurement while drilling
KW  - drilling monitoring
KW  - drilling parameters
KW  - rock properties
KW  - blasting
KW  - data verification
DO  - 10.3390/min11080798
ER  -
TY  - EJOU
AU  - Li, Mei
AU  - Li, Zengyuan
AU  - Liu, Qingwang
AU  - Chen, Erxue
TI  - Comparison of Coniferous Plantation Heights Using Unmanned Aerial Vehicle (UAV) Laser Scanning and Stereo Photogrammetry
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 15
SN  - 2072-4292

AB  - Plantation forests play a critical role in forest products and ecosystems. Unmanned aerial vehicle (UAV) remote sensing has become a promising technology in forest related applications. The stand heights will reflect the growth and competition of individual trees in plantation. UAV laser scanning (ULS) and UAV stereo photogrammetry (USP) can both be used to estimate stand heights using different algorithms. Thus, this study aimed to deeply explore the variations of four kinds of stand heights including mean height, Lorey’s height, dominated height, and median height of coniferous plantations using different models based on ULS and USP data. In addition, the impacts of thinned point density of 30 pts to 10 pts, 5 pts, 1 pts, and 0.8 pts/m2 were also analyzed. Forest stand heights were estimated from ULS and USP data metrics by linear regression and the prediction accuracy was assessed by 10-fold cross validation. The results showed that the prediction accuracy of the stand heights using metrics from USP was basically as good as that of ULS. Lorey’s height had the highest prediction accuracy, followed by dominated height, mean height, and median height. The correlation between height percentiles metrics from ULS and USP increased with the increased height. Different stand heights had their corresponding best height percentiles as variables based on stand height characteristics. Furthermore, canopy height model (CHM)-based metrics performed slightly better than normalized point cloud (NPC)-based metrics. The USP was not able to extract exact terrain information in a continuous coniferous plantation for forest canopy cover (CC) over 0.49. The combination of USP and terrain from ULS can be used to estimate forest stand heights with high accuracy. In addition, the estimation accuracy of each forest stand height was slightly affected by point density, which can also be ignored.
KW  - forest stand height
KW  - UAV laser scanning
KW  - UAV stereo photogrammetry
KW  - point clouds density
KW  - CHM
KW  - metrics
DO  - 10.3390/rs13152885
ER  -
TY  - EJOU
AU  - Walambe, Rahee
AU  - Marathe, Aboli
AU  - Kotecha, Ketan
TI  - Multiscale Object Detection from Drone Imagery Using Ensemble Transfer Learning
T2  - Drones

PY  - 2021
VL  - 5
IS  - 3
SN  - 2504-446X

AB  - Object detection in uncrewed aerial vehicle (UAV) images has been a longstanding challenge in the field of computer vision. Specifically, object detection in drone images is a complex task due to objects of various scales such as humans, buildings, water bodies, and hills. In this paper, we present an implementation of ensemble transfer learning to enhance the performance of the base models for multiscale object detection in drone imagery. Combined with a test-time augmentation pipeline, the algorithm combines different models and applies voting strategies to detect objects of various scales in UAV images. The data augmentation also presents a solution to the deficiency of drone image datasets. We experimented with two specific datasets in the open domain: the VisDrone dataset and the AU-AIR Dataset. Our approach is more practical and efficient due to the use of transfer learning and two-level voting strategy ensemble instead of training custom models on entire datasets. The experimentation shows significant improvement in the mAP for both VisDrone and AU-AIR datasets by employing the ensemble transfer learning method. Furthermore, the utilization of voting strategies further increases the 3reliability of the ensemble as the end-user can select and trace the effects of the mechanism for bounding box predictions.
KW  - drone imagery
KW  - 2D object detection
KW  - ensemble techniques
KW  - voting strategies
DO  - 10.3390/drones5030066
ER  -
TY  - EJOU
AU  - El Serafy, Ghada Y.H.
AU  - Schaeffer, Blake A.
AU  - Neely, Merrie-Beth
AU  - Spinosa, Anna
AU  - Odermatt, Daniel
AU  - Weathers, Kathleen C.
AU  - Baracchini, Theo
AU  - Bouffard, Damien
AU  - Carvalho, Laurence
AU  - Conmy, Robyn N.
AU  - Keukelaere, Liesbeth D.
AU  - Hunter, Peter D.
AU  - Jamet, Cédric
AU  - Joehnk, Klaus D.
AU  - Johnston, John M.
AU  - Knudby, Anders
AU  - Minaudo, Camille
AU  - Pahlevan, Nima
AU  - Reusen, Ils
AU  - Rose, Kevin C.
AU  - Schalles, John
AU  - Tzortziou, Maria
TI  - Integrating Inland and Coastal Water Quality Data for Actionable Knowledge
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 15
SN  - 2072-4292

AB  - Water quality measures for inland and coastal waters are available as discrete samples from professional and volunteer water quality monitoring programs and higher-frequency, near-continuous data from automated in situ sensors. Water quality parameters also are estimated from model outputs and remote sensing. The integration of these data, via data assimilation, can result in a more holistic characterization of these highly dynamic ecosystems, and consequently improve water resource management. It is becoming common to see combinations of these data applied to answer relevant scientific questions. Yet, methods for scaling water quality data across regions and beyond, to provide actionable knowledge for stakeholders, have emerged only recently, particularly with the availability of satellite data now providing global coverage at high spatial resolution. In this paper, data sources and existing data integration frameworks are reviewed to give an overview of the present status and identify the gaps in existing frameworks. We propose an integration framework to provide information to user communities through the the Group on Earth Observations (GEO) AquaWatch Initiative. This aims to develop and build the global capacity and utility of water quality data, products, and information to support equitable and inclusive access for water resource management, policy and decision making.
KW  - water quality
KW  - remote sensing
KW  - lake
KW  - estuary
KW  - coastal
KW  - sensors
KW  - management
KW  - interoperability
KW  - integration
DO  - 10.3390/rs13152899
ER  -
TY  - EJOU
AU  - Wang, Jingrui
AU  - Wang, Shuqing
AU  - Zou, Dongxiao
AU  - Chen, Huimin
AU  - Zhong, Run
AU  - Li, Hanliang
AU  - Zhou, Wei
AU  - Yan, Kai
TI  - Social Network and Bibliometric Analysis of Unmanned Aerial Vehicle Remote Sensing Applications from 2010 to 2021
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 15
SN  - 2072-4292

AB  - Unmanned Aerial Vehicle (UAV) Remote sensing (RS) has unique advantages over traditional satellite RS, including convenience, high resolution, affordability and fast acquisition speed, making it widely used in many fields. To provide an overview of the development of UAV RS applications during the past decade, we screened related publications from the Web of Science core database from 2010 to 2021, built co-author networks, a discipline interaction network, a keywords timeline view, a co-citation cluster, and detected burst citations using bibliometrics and social network analysis. Our results show that: (1) The number of UAV RS publications had an increasing trend, with explosive growth in the past five years. The number of papers published by China and the United States (US) is far ahead in this field; (2) The US has currently the greatest influence in this field through the largest number of international cooperations. Cooperation is mainly concentrated in countries and institutions with a large number of publications but is not widely distributed. (3) The application of UAV RS involves multiple interdisciplinary subjects, among which “Environmental Science and Ecology” ranks first; (4) Future research trends of UAV RS are expected to be related to artificial intelligence (e.g., artificial neural networks-based research). This paper provides a scientific basis and guidance for future developments of UAV RS applications, which can help the research community to better grasp the developments of this field.
KW  - Unmanned Aerial Vehicle (UAV)
KW  - Remote Sensing (RS)
KW  - Bibliometric
KW  - Scientometric
KW  - visualization
DO  - 10.3390/rs13152912
ER  -
TY  - EJOU
AU  - Wei, Lifei
AU  - Wang, Kun
AU  - Lu, Qikai
AU  - Liang, Yajing
AU  - Li, Haibo
AU  - Wang, Zhengxiang
AU  - Wang, Run
AU  - Cao, Liqin
TI  - Crops Fine Classification in Airborne Hyperspectral Imagery Based on Multi-Feature Fusion and Deep Learning
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 15
SN  - 2072-4292

AB  - Hyperspectral imagery has been widely used in precision agriculture due to its rich spectral characteristics. With the rapid development of remote sensing technology, the airborne hyperspectral imagery shows detailed spatial information and temporal flexibility, which open a new way to accurate agricultural monitoring. To extract crop types from the airborne hyperspectral images, we propose a fine classification method based on multi-feature fusion and deep learning. In this research, the morphological profiles, GLCM texture and endmember abundance features are leveraged to exploit the spatial information of the hyperspectral imagery. Then, the multiple spatial information is fused with the original spectral information to generate classification result by using the deep neural network with conditional random field (DNN+CRF) model. Specifically, the deep neural network (DNN) is a deep recognition model which can extract depth features and mine the potential information of data. As a discriminant model, conditional random field (CRF) considers both spatial and contextual information to reduce the misclassification noises while keeping the object boundaries. Moreover, three multiple feature fusion approaches, namely feature stacking, decision fusion and probability fusion, are taken into account. In the experiments, two airborne hyperspectral remote sensing datasets (Honghu dataset and Xiong’an dataset) are used. The experimental results show that the classification performance of the proposed method is satisfactory, where the salt and pepper noise is decreased, and the boundary of the ground object is preserved.
KW  - hyperspectral imagery
KW  - crops fine classification
KW  - multi-feature fusion
KW  - deep neural network
KW  - conditional random field
DO  - 10.3390/rs13152917
ER  -
TY  - EJOU
AU  - Banerjee, Bikram P.
AU  - Sharma, Vikas
AU  - Spangenberg, German
AU  - Kant, Surya
TI  - Machine Learning Regression Analysis for Estimation of Crop Emergence Using Multispectral UAV Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 15
SN  - 2072-4292

AB  - Optimal crop emergence is an important trait in crop breeding for genotypic screening and for achieving potential growth and yield. Emergence is conventionally quantified manually by counting the sub-sections of field plots or scoring; these are less reliable, laborious and inefficient. Remote sensing technology is being increasingly used for high-throughput estimation of agronomic traits in field crops. This study developed a method for estimating wheat seedlings using multispectral images captured from an unmanned aerial vehicle. A machine learning regression (MLR) analysis was used by combining spectral and morphological information extracted from the multispectral images. The approach was tested on diverse wheat genotypes varying in seedling emergence. In this study, three supervised MLR models including regression trees, support vector regression and Gaussian process regression (GPR) were evaluated for estimating wheat seedling emergence. The GPR model was the most effective compared to the other methods, with R2 = 0.86, RMSE = 4.07 and MAE = 3.21 when correlated to the manual seedling count. In addition, imagery data collected at multiple flight altitudes and different wheat growth stages suggested that 10 m altitude and 20 days after sowing were desirable for optimal spatial resolution and image analysis. The method is deployable on larger field trials and other crops for effective and reliable seedling emergence estimates.
KW  - field trials
KW  - plant count
KW  - plant phenotyping
KW  - wheat
DO  - 10.3390/rs13152918
ER  -
TY  - EJOU
AU  - Huang, Tingting
AU  - Ding, Chenghui
AU  - Li, Weibiao
AU  - Chen, Yilun
TI  - Morphology of Rain Clusters Influencing Rainfall Intensity over Hainan Island
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 15
SN  - 2072-4292

AB  - Continuous observations from geostationary satellites can show the morphology of precipitation cloud systems in quasi-real-time, but there are still large deviations in the inversion of precipitation. We used binary-connected area recognition technology to identify meso-β-scale rain clusters over Hainan Island from 1 June 2000 to 31 December 2018, based on Global Precipitation Measurement (GPM) Integrated Multi-satellitE Retrievals for GPM data. We defined and statistically analyzed the parameters of rain clusters to reveal the typical morphological and precipitation characteristics of rain clusters, and to explore the relationship between the parameters and rainfall intensity of rain clusters. We found that the area and long axis of rain clusters over land were larger than those over the ocean, and that continental rain clusters were usually square in shape. Rain clusters with a larger area and longer axis were concentrated on the northern side of the mountains on Hainan Island and the intensity of rain was larger on the northern and eastern sides of the mountains. The variation of continental rain clusters over time was more dramatic than the variation of oceanic clusters. The area and long axis of rain clusters was larger between 14:00 and 21:00 from April to September and the long axis of the oceanic rain clusters increased in winter. There were clear positive correlations between the area, long axis and shape of the rain clusters and the maximum rain rate. The area and long axis of continental rain clusters had a higher correlation with the rain rate than those of oceanic clusters. The establishment of a relationship between the morphology of rain clusters and precipitation helps us to understand the laws of precipitation and improve the prediction of precipitation in this region.
KW  - Hainan Island
KW  - morphological characteristics
KW  - precipitation characteristics
KW  - sea–land differences
DO  - 10.3390/rs13152920
ER  -
TY  - EJOU
AU  - Zeng, Linglin
AU  - Peng, Guozhang
AU  - Meng, Ran
AU  - Man, Jianguo
AU  - Li, Weibo
AU  - Xu, Binyuan
AU  - Lv, Zhengang
AU  - Sun, Rui
TI  - Wheat Yield Prediction Based on Unmanned Aerial Vehicles-Collected Red–Green–Blue Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 15
SN  - 2072-4292

AB  - Unmanned aerial vehicles-collected (UAVs) digital red–green–blue (RGB) images provided a cost-effective method for precision agriculture applications regarding yield prediction. This study aims to fully explore the potential of UAV-collected RGB images in yield prediction of winter wheat by comparing it to multi-source observations, including thermal, structure, volumetric metrics, and ground-observed leaf area index (LAI) and chlorophyll content under the same level or across different levels of nitrogen fertilization. Color indices are vegetation indices calculated by the vegetation reflectance at visible bands (i.e., red, green, and blue) derived from RGB images. The results showed that some of the color indices collected at the jointing, flowering, and early maturity stages had high correlation (R2 = 0.76–0.93) with wheat grain yield. They gave the highest prediction power (R2 = 0.92–0.93) under four levels of nitrogen fertilization at the flowering stage. In contrast, the other measurements including canopy temperature, volumetric metrics, and ground-observed chlorophyll content showed lower correlation (R2 = 0.52–0.85) to grain yield. In addition, thermal information as well as volumetric metrics generally had little contribution to the improvement of grain yield prediction when combining them with color indices derived from digital images. Especially, LAI had inferior performance to color indices in grain yield prediction within the same level of nitrogen fertilization at the flowering stage (R2 = 0.00–0.40 and R2 = 0.55–0.68), and color indices provided slightly better prediction of yield than LAI at the flowering stage (R2 = 0.93, RMSE = 32.18 g/m2 and R2 = 0.89, RMSE = 39.82 g/m2) under all levels of nitrogen fertilization. This study highlights the capabilities of color indices in wheat yield prediction across genotypes, which also indicates the potential of precision agriculture application using many other flexible, affordable, and easy-to-handle devices such as mobile phones and near surface digital cameras in the future.
KW  - red–green–blue (RGB) imageries
KW  - yield prediction
KW  - nitrogen fertilization
KW  - vegetation index
DO  - 10.3390/rs13152937
ER  -
TY  - EJOU
AU  - Fernández, Claudio I.
AU  - Leblon, Brigitte
AU  - Wang, Jinfei
AU  - Haddadi, Ata
AU  - Wang, Keri
TI  - Detecting Infected Cucumber Plants with Close-Range Multispectral Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 15
SN  - 2072-4292

AB  - This study used close-range multispectral imagery over cucumber plants inside a commercial greenhouse to detect powdery mildew due to Podosphaera xanthii. It was collected using a MicaSense® RedEdge camera at 1.5 m over the top of the plant. Image registration was performed using Speeded-Up Robust Features (SURF) with an affine geometric transformation. The image background was removed using a binary mask created with the aligned NIR band of each image, and the illumination was corrected using Cheng et al.’s algorithm. Different features were computed, including RGB, image reflectance values, and several vegetation indices. For each feature, a fine Gaussian Support Vector Machines algorithm was trained and validated to classify healthy and infected pixels. The data set to train and validate the SVM was composed of 1000 healthy and 1000 infected pixels, split 70–30% into training and validation datasets, respectively. The overall validation accuracy was 89, 73, 82, 51, and 48%, respectively, for blue, green, red, red-edge, and NIR band image. With the RGB images, we obtained an overall validation accuracy of 89%, while the best vegetation index image was the PMVI-2 image which produced an overall accuracy of 81%. Using the five bands together, overall accuracy dropped from 99% in the training to 57% in the validation dataset. While the results of this work are promising, further research should be considered to increase the number of images to achieve better training and validation datasets.
KW  - speeded-up robust features
KW  - SURF features
KW  - support vector machines
KW  - image alignment
KW  - powdery mildew
DO  - 10.3390/rs13152948
ER  -
TY  - EJOU
AU  - Wang, Li
AU  - Chen, Shuisen
AU  - Li, Dan
AU  - Wang, Chongyang
AU  - Jiang, Hao
AU  - Zheng, Qiong
AU  - Peng, Zhiping
TI  - Estimation of Paddy Rice Nitrogen Content and Accumulation Both at Leaf and Plant Levels from UAV Hyperspectral Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 15
SN  - 2072-4292

AB  - Remote sensing-based mapping of crop nitrogen (N) status is beneficial for precision N management over large geographic regions. Both leaf/canopy level nitrogen content and accumulation are valuable for crop nutrient diagnosis. However, previous studies mainly focused on leaf nitrogen content (LNC) estimation. The effects of growth stages on the modeling accuracy have not been widely discussed. This study aimed to estimate different paddy rice N traits—LNC, plant nitrogen content (PNC), leaf nitrogen accumulation (LNA) and plant nitrogen accumulation (PNA)—from unmanned aerial vehicle (UAV)-based hyperspectral images. Additionally, the effects of the growth stage were evaluated. Univariate regression models on vegetation indices (VIs), the traditional multivariate calibration method, partial least squares regression (PLSR) and modern machine learning (ML) methods, including artificial neural network (ANN), random forest (RF), and support vector machine (SVM), were evaluated both over the whole growing season and in each single growth stage (including the tillering, jointing, booting and heading growth stages). The results indicate that the correlation between the four nitrogen traits and the other three biochemical traits—leaf chlorophyll content, canopy chlorophyll content and aboveground biomass—are affected by the growth stage. Within a single growth stage, the performance of selected VIs is relatively constant. For the full-growth-stage models, the performance of the VI-based models is more diverse. For the full-growth-stage models, the transformed chlorophyll absorption in the reflectance index/optimized soil-adjusted vegetation index (TCARI/OSAVI) performs best for LNC, PNC and PNA estimation, while the three band vegetation index (TBVITian) performs best for LNA estimation. There are no obvious patterns regarding which method performs the best of the PLSR, ANN, RF and SVM in either the growth-stage-specific or full-growth-stage models. For the growth-stage-specific models, a lower mean relative error (MRE) and higher R2 can be acquired at the tillering and jointing growth stages. The PLSR and ML methods yield obviously better estimation accuracy for the full-growth-stage models than the VI-based models. For the growth-stage-specific models, the performance of VI-based models seems optimal and cannot be obviously surpassed. These results suggest that building linear regression models on VIs for paddy rice nitrogen traits estimation is still a reasonable choice when only a single growth stage is involved. However, when multiple growth stages are involved or missing the phenology information, using PLSR or ML methods is a better option.
KW  - paddy rice
KW  - growth stages
KW  - phenology
KW  - hyperspectral
KW  - nitrogen
DO  - 10.3390/rs13152956
ER  -
TY  - EJOU
AU  - Ghaffarian, Saman
AU  - Valente, João
AU  - van der Voort, Mariska
AU  - Tekinerdogan, Bedir
TI  - Effect of Attention Mechanism in Deep Learning-Based Remote Sensing Image Processing: A Systematic Literature Review
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 15
SN  - 2072-4292

AB  - Machine learning, particularly deep learning (DL), has become a central and state-of-the-art method for several computer vision applications and remote sensing (RS) image processing. Researchers are continually trying to improve the performance of the DL methods by developing new architectural designs of the networks and/or developing new techniques, such as attention mechanisms. Since the attention mechanism has been proposed, regardless of its type, it has been increasingly used for diverse RS applications to improve the performances of the existing DL methods. However, these methods are scattered over different studies impeding the selection and application of the feasible approaches. This study provides an overview of the developed attention mechanisms and how to integrate them with different deep learning neural network architectures. In addition, it aims to investigate the effect of the attention mechanism on deep learning-based RS image processing. We identified and analyzed the advances in the corresponding attention mechanism-based deep learning (At-DL) methods. A systematic literature review was performed to identify the trends in publications, publishers, improved DL methods, data types used, attention types used, overall accuracies achieved using At-DL methods, and extracted the current research directions, weaknesses, and open problems to provide insights and recommendations for future studies. For this, five main research questions were formulated to extract the required data and information from the literature. Furthermore, we categorized the papers regarding the addressed RS image processing tasks (e.g., image classification, object detection, and change detection) and discussed the results within each group. In total, 270 papers were retrieved, of which 176 papers were selected according to the defined exclusion criteria for further analysis and detailed review. The results reveal that most of the papers reported an increase in overall accuracy when using the attention mechanism within the DL methods for image classification, image segmentation, change detection, and object detection using remote sensing images.
KW  - remote sensing
KW  - image processing
KW  - attention mechanism
KW  - spatial attention
KW  - channel attention
KW  - deep learning
KW  - CNN
DO  - 10.3390/rs13152965
ER  -
TY  - EJOU
AU  - Fraser, Benjamin T.
AU  - Congalton, Russell G.
TI  - Estimating Primary Forest Attributes and Rare Community Characteristics Using Unmanned Aerial Systems (UAS): An Enrichment of Conventional Forest Inventories
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 15
SN  - 2072-4292

AB  - The techniques for conducting forest inventories have been established over centuries of land management and conservation. In recent decades, however, compelling new tools and methodologies in remote sensing, computer vision, and data science have offered innovative pathways for enhancing the effectiveness and comprehension of these sampling designs. Now with the aid of Unmanned Aerial Systems (UAS) and advanced image processing techniques, we have never been closer to mapping forests at field-based inventory scales. Our research, conducted in New Hampshire on complex mixed-species forests, used natural color UAS imagery for estimating individual tree diameters (diameter at breast height (dbh)) as well as stand level estimates of Basal Area per Hectare (BA/ha), Quadratic Mean Diameter (QMD), Trees per Hectare (TPH), and a Stand Density Index (SDI) using digital photogrammetry. To strengthen our understanding of these forests, we also assessed the proficiency of the UAS to map the presence of large trees (i.e., &gt;40 cm in diameter). We assessed the proficiency of UAS digital photogrammetry for identifying large trees in two ways: (1) using the UAS estimated dbh and the 40 cm size threshold and (2) using a random forest supervised classification and a combination of spectral, textural, and geometric features. Our UAS-based estimates of tree diameter reported an average error of 19.7% to 33.7%. At the stand level, BA/ha and QMD were overestimated by 42.18% and 62.09%, respectively, while TPH and SDI were underestimated by 45.58% and 3.34%. When considering only stands larger than 9 ha however, the overestimation of BA/ha at the stand level dropped to 14.629%. The overall classification of large trees, using the random forest supervised classification achieved an overall accuracy of 85%. The efficiency and effectiveness of these methods offer local land managers the opportunity to better understand their forested ecosystems. Future research into individual tree crown detection and delineation, especially for co-dominant or suppressed trees, will further support these efforts.
KW  - Unmanned Aerial Systems (UAS)
KW  - Unmanned Aerial Vehicle (UAV)
KW  - forest inventory
KW  - precision forestry
KW  - large trees
KW  - Structure from Motion (SfM)
KW  - photogrammetry
DO  - 10.3390/rs13152971
ER  -
TY  - EJOU
AU  - Yang, Kaili
AU  - Gong, Yan
AU  - Fang, Shenghui
AU  - Duan, Bo
AU  - Yuan, Ningge
AU  - Peng, Yi
AU  - Wu, Xianting
AU  - Zhu, Renshan
TI  - Combining Spectral and Texture Features of UAV Images for the Remote Estimation of Rice LAI throughout the Entire Growing Season
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 15
SN  - 2072-4292

AB  - Leaf area index (LAI) estimation is very important, and not only for canopy structure analysis and yield prediction. The unmanned aerial vehicle (UAV) serves as a promising solution for LAI estimation due to its great applicability and flexibility. At present, vegetation index (VI) is still the most widely used method in LAI estimation because of its fast speed and simple calculation. However, VI only reflects the spectral information and ignores the texture information of images, so it is difficult to adapt to the unique and complex morphological changes of rice in different growth stages. In this study we put forward a novel method by combining the texture information derived from the local binary pattern and variance features (LBP and VAR) with the spectral information based on VI to improve the estimation accuracy of rice LAI throughout the entire growing season. The multitemporal images of two study areas located in Hainan and Hubei were acquired by a 12-band camera, and the main typical bands for constituting VIs such as green, red, red edge, and near-infrared were selected to analyze their changes in spectrum and texture during the entire growing season. After the mathematical combination of plot-level spectrum and texture values, new indices were constructed to estimate rice LAI. Comparing the corresponding VI, the new indices were all less sensitive to the appearance of panicles and slightly weakened the saturation issue. The coefficient of determination (R2) can be improved for all tested VIs throughout the entire growing season. The results showed that the combination of spectral and texture features exhibited a better predictive ability than VI for estimating rice LAI. This method only utilized the texture and spectral information of the UAV image itself, which is fast, easy to operate, does not need manual intervention, and can be a low-cost method for monitoring crop growth.
KW  - leaf area index (LAI)
KW  - unmanned aerial vehicle (UAV)
KW  - multispectral image
KW  - vegetation index (VI)
KW  - texture
KW  - local binary pattern (LBP)
KW  - rice
DO  - 10.3390/rs13153001
ER  -
TY  - EJOU
AU  - Wang, Yang
AU  - Tian, Yongzhong
AU  - Cao, Yan
TI  - Dam Siting: A Review
T2  - Water

PY  - 2021
VL  - 13
IS  - 15
SN  - 2073-4441

AB  - Dams can effectively regulate the spatial and temporal distribution of water resources, where the rationality of dam siting determines whether the role of dams can be effectively performed. This paper reviews the research literature on dam siting in the past 20 years, discusses the methods used for dam siting, focuses on the factors influencing dam siting, and assesses the impact of different dam functions on siting factors. The results show the following: (1) Existing siting methods can be categorized into three types—namely, GIS/RS-based siting, MCDM- and MCDM-GIS-based siting, and machine learning-based siting. GIS/RS emphasizes the ability to capture and analyze data, MCDM has the advantage of weighing the importance of the relationship between multiple factors, and machine learning methods have a strong ability to learn and process complex data. (2) Site selection factors vary greatly, depending on the function of the dam. For dams with irrigation and water supply as the main purpose, the site selection is more focused on the evaluation of water quality. For dams with power generation as the main purpose, the hydrological factors characterizing the power generation potential are the most important. For dams with flood control as the main purpose, the topography and geological conditions are more important. (3) The integration of different siting methods and the siting of new functional dams in the existing research is not sufficient. Future research should focus on the integration of different methods and disciplines, in order to explore the siting of new types of dams.
KW  - dam siting
KW  - multi-criteria decision-making
KW  - geographic information systems
KW  - machine learning
KW  - siting factors
DO  - 10.3390/w13152080
ER  -
TY  - EJOU
AU  - Wang, Hao
AU  - Lyu, Suxing
AU  - Ren, Yaxin
TI  - Paddy Rice Imagery Dataset for Panicle Segmentation
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 8
SN  - 2073-4395

AB  - Accurate panicle identification is a key step in rice-field phenotyping. Deep learning methods based on high-spatial-resolution images provide a high-throughput and accurate solution of panicle segmentation. Panicle segmentation tasks require costly annotations to train an accurate and robust deep learning model. However, few public datasets are available for rice-panicle phenotyping. We present a semi-supervised deep learning model training process, which greatly assists the annotation and refinement of training datasets. The model learns the panicle features with limited annotations and localizes more positive samples in the datasets, without further interaction. After the dataset refinement, the number of annotations increased by 40.6%. In addition, we trained and tested modern deep learning models to show how the dataset is beneficial to both detection and segmentation tasks. Results of our comparison experiments can inspire others in dataset preparation and model selection.
KW  - image segmentation
KW  - panicle detection
KW  - deep learning
KW  - smart agriculture
KW  - unmanned aerial vehicle platform
DO  - 10.3390/agronomy11081542
ER  -
TY  - EJOU
AU  - Kim, Minsu
AU  - Lee, Chaewon
AU  - Hong, Subin
AU  - Kim, Song L.
AU  - Baek, Jeong-Ho
AU  - Kim, Kyung-Hwan
TI  - High-Throughput Phenotyping Methods for Breeding Drought-Tolerant Crops
T2  - International Journal of Molecular Sciences

PY  - 2021
VL  - 22
IS  - 15
SN  - 1422-0067

AB  - Drought is a main factor limiting crop yields. Modern agricultural technologies such as irrigation systems, ground mulching, and rainwater storage can prevent drought, but these are only temporary solutions. Understanding the physiological, biochemical, and molecular reactions of plants to drought stress is therefore urgent. The recent rapid development of genomics tools has led to an increasing interest in phenomics, i.e., the study of phenotypic plant traits. Among phenomic strategies, high-throughput phenotyping (HTP) is attracting increasing attention as a way to address the bottlenecks of genomic and phenomic studies. HTP provides researchers a non-destructive and non-invasive method yet accurate in analyzing large-scale phenotypic data. This review describes plant responses to drought stress and introduces HTP methods that can detect changes in plant phenotypes in response to drought.
KW  - high-throughput phenotyping
KW  - drought
KW  - phenomics
KW  - breeding
DO  - 10.3390/ijms22158266
ER  -

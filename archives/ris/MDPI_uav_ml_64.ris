TY  - EJOU
AU  - Bote-Curiel, Luis
AU  - Muñoz-Romero, Sergio
AU  - Gerrero-Curieses, Alicia
AU  - Rojo-Álvarez, José L.
TI  - Deep Learning and Big Data in Healthcare: A Double Review for Critical Beginners
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 11
SN  - 2076-3417

AB  - In the last few years, there has been a growing expectation created about the analysis of large amounts of data often available in organizations, which has been both scrutinized by the academic world and successfully exploited by industry. Nowadays, two of the most common terms heard in scientific circles are Big Data and Deep Learning. In this double review, we aim to shed some light on the current state of these different, yet somehow related branches of Data Science, in order to understand the current state and future evolution within the healthcare area. We start by giving a simple description of the technical elements of Big Data technologies, as well as an overview of the elements of Deep Learning techniques, according to their usual description in scientific literature. Then, we pay attention to the application fields that can be said to have delivered relevant real-world success stories, with emphasis on examples from large technology companies and financial institutions, among others. The academic effort that has been put into bringing these technologies to the healthcare sector are then summarized and analyzed from a twofold view as follows: first, the landscape of application examples is globally scrutinized according to the varying nature of medical data, including the data forms in electronic health recordings, medical time signals, and medical images; second, a specific application field is given special attention, in particular the electrocardiographic signal analysis, where a number of works have been published in the last two years. A set of toy application examples are provided with the publicly-available MIMIC dataset, aiming to help the beginners start with some principled, basic, and structured material and available code. Critical discussion is provided for current and forthcoming challenges on the use of both sets of techniques in our future healthcare.
KW  - deep learning
KW  - big data
KW  - statistical learning
KW  - healthcare
KW  - electrocardiogram
KW  - databases
KW  - MIMIC
KW  - review
KW  - machine learning
DO  - 10.3390/app9112331
ER  -
TY  - EJOU
AU  - Ahmed, Sarfraz
AU  - Huda, M. N.
AU  - Rajbhandari, Sujan
AU  - Saha, Chitta
AU  - Elshaw, Mark
AU  - Kanarachos, Stratis
TI  - Pedestrian and Cyclist Detection and Intent Estimation for Autonomous Vehicles: A Survey
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 11
SN  - 2076-3417

AB  - As autonomous vehicles become more common on the roads, their advancement draws on safety concerns for vulnerable road users, such as pedestrians and cyclists. This paper presents a review of recent developments in pedestrian and cyclist detection and intent estimation to increase the safety of autonomous vehicles, for both the driver and other road users. Understanding the intentions of the pedestrian/cyclist enables the self-driving vehicle to take actions to avoid incidents. To make this possible, development of methods/techniques, such as deep learning (DL), for the autonomous vehicle will be explored. For example, the development of pedestrian detection has been significantly advanced using DL approaches, such as; Fast Region-Convolutional Neural Network (R-CNN) , Faster R-CNN and Single Shot Detector (SSD). Although DL has been around for several decades, the hardware to realise the techniques have only recently become viable. Using these DL methods for pedestrian and cyclist detection and applying it for the tracking, motion modelling and pose estimation can allow for a successful and accurate method of intent estimation for the vulnerable road users. Although there has been a growth in research surrounding the study of pedestrian detection using vision-based approaches, further attention should include focus on cyclist detection. To further improve safety for these vulnerable road users (VRUs), approaches such as sensor fusion and intent estimation should be investigated.
KW  - pedestrian detection
KW  - cyclist detection
KW  - deep learning
KW  - CNN
KW  - Fast R-CNN
KW  - Faster R-CNN
KW  - pose estimation
KW  - motion modelling
KW  - tracking
KW  - intent estimation
DO  - 10.3390/app9112335
ER  -
TY  - EJOU
AU  - Jung, Dae-Hyun
AU  - Kim, Hak-Jin
AU  - Kim, Hyoung S.
AU  - Choi, Jaeyoung
AU  - Kim, Jeong D.
AU  - Park, Soo H.
TI  - Fusion of Spectroscopy and Cobalt Electrochemistry Data for Estimating Phosphate Concentration in Hydroponic Solution
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 11
SN  - 1424-8220

AB  - Phosphate is a key element affecting plant growth. Therefore, the accurate determination of phosphate concentration in hydroponic nutrient solutions is essential for providing a balanced set of nutrients to plants within a suitable range. This study aimed to develop a data fusion approach for determining phosphate concentrations in a paprika nutrient solution. As a conventional multivariate analysis approach using spectral data, partial least squares regression (PLSR) and principal components regression (PCR) models were developed using 56 samples for calibration and 24 samples for evaluation. The R2 values of estimation models using PCR and PLSR ranged from 0.44 to 0.64. Furthermore, an estimation model using raw electromotive force (EMF) data from cobalt electrodes gave R2 values of 0.58–0.71. To improve the model performance, a data fusion method was developed to estimate phosphate concentration using near infrared (NIR) spectral and cobalt electrochemical data. Raw EMF data from cobalt electrodes and principle component values from the spectral data were combined. Results of calibration and evaluation tests using an artificial neural network estimation model showed that R2 = 0.90 and 0.89 and root mean square error (RMSE) = 96.70 and 119.50 mg/L, respectively. These values are sufficiently high for application to measuring phosphate concentration in hydroponic solutions.
KW  - phosphate sensing
KW  - Multi-sensor data fusion
KW  - hybrid sensor system
KW  - Feed-forward back-propagation ANN
DO  - 10.3390/s19112596
ER  -
TY  - EJOU
AU  - Wang, Yanyu
AU  - Zhang, Ke
AU  - Tang, Chunlan
AU  - Cao, Qiang
AU  - Tian, Yongchao
AU  - Zhu, Yan
AU  - Cao, Weixing
AU  - Liu, Xiaojun
TI  - Estimation of Rice Growth Parameters Based on Linear Mixed-Effect Model Using Multispectral Images from Fixed-Wing Unmanned Aerial Vehicles
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 11
SN  - 2072-4292

AB  - The accurate estimation of aboveground biomass (AGB) and leaf area index (LAI) is critical to characterize crop growth status and predict grain yield. Unmanned aerial vehicle (UAV) -based remote sensing has attracted significant interest due to its high flexibility and easiness of operation. The mixed effect model introduced in this study can capture secondary factors that cannot be captured by standard empirical relationships. The objective of this study was to explore the potential benefit of using a linear mixed-effect (LME) model and multispectral images from a fixed-wing UAV to estimate both AGB and LAI of rice. Field experiments were conducted over two consecutive years (2017&ndash;2018), that involved different N rates, planting patterns and rice cultivars. Images were collected by a compact multispectral camera mounted on a fixed-wing UAV during key rice growth stages. LME, simple regression (SR), artificial neural networks (ANN) and random forests (RF) models were developed relating growth parameters (AGB and LAI) to spectral information. Cultivar (C), growth stage (S) and planting pattern (P) were selected as candidates of random effects for the LME models due to their significant effects on rice growth. Compared to other regression models (SR, ANN and RF), the LME model improved the AGB estimation accuracy for all stage groups to varying degrees: the R2 increased by 0.14&ndash;0.35 and the RMSE decreased by 0.88&ndash;1.80 t ha&minus;1 for the whole season, the R2 increased by 0.07&ndash;0.15 and the RMSE decreased by 0.31&ndash;0.61 t ha&minus;1 for pre-heading stages and the R2 increased by 0.21&ndash;0.53 and the RMSE decreased by 0.72&ndash;1.52 t ha&minus;1 for post-heading stages. Further analysis suggested that the LME model also successfully predicted within the groups when the number of groups was suitable. More importantly, depending on the availability of C, S, P or combinations thereof, mixed effects could lead to an outperformance of baseline retrieval methods (SR, ANN or RF) due to the inclusion of secondary effects. Satisfactory results were also obtained for the LAI estimation while the superiority of the LME model was not as significant as that for AGB estimation. This study demonstrates that the LME model could accurately estimate rice AGB and LAI and fixed-wing UAVs are promising for the monitoring of the crop growth status over large-scale farmland.
KW  - aboveground biomass
KW  - leaf area index
KW  - vegetation index
KW  - linear mixed-effect model
KW  - UAV multispectral image
KW  - remote sensing
KW  - rice
DO  - 10.3390/rs11111371
ER  -
TY  - EJOU
AU  - Abdulridha, Jaafar
AU  - Batuman, Ozgur
AU  - Ampatzidis, Yiannis
TI  - UAV-Based Remote Sensing Technique to Detect Citrus Canker Disease Utilizing Hyperspectral Imaging and Machine Learning
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 11
SN  - 2072-4292

AB  - A remote sensing technique was developed to detect citrus canker in laboratory conditions and was verified in the grove by utilizing an unmanned aerial vehicle (UAV). In the laboratory, a hyperspectral (400&ndash;1000 nm) imaging system was utilized for the detection of citrus canker in several disease development stages (i.e., asymptomatic, early, and late symptoms) on Sugar Belle leaves and immature (green) fruit by using two classification methods: (i) radial basis function (RBF) and (ii) K nearest neighbor (KNN). The same imaging system mounted on an UAV was used to detect citrus canker on tree canopies in the orchard. The overall classification accuracy of the RBF was higher (94%, 96%, and 100%) than the KNN method (94%, 95%, and 96%) for detecting canker in leaves. Among the 31 studied vegetation indices, the water index (WI) and the Modified Chlorophyll Absorption in Reflectance Index (ARI and TCARI 1) more accurately detected canker in laboratory and in orchard conditions, respectively. Immature fruit was not a reliable tissue for early detection of canker. However, the proposed technique successfully distinguished the late stage canker-infected fruit with 92% classification accuracy. The UAV-based technique achieved 100% classification accuracy for identifying healthy and canker-infected trees.
KW  - citrus
KW  - canker
KW  - disease detection
KW  - hyperspectral imaging
KW  - neural networks
KW  - vegetation indices
DO  - 10.3390/rs11111373
ER  -
TY  - EJOU
AU  - Rostami, Mohammad
AU  - Kolouri, Soheil
AU  - Eaton, Eric
AU  - Kim, Kyungnam
TI  - Deep Transfer Learning for Few-Shot SAR Image Classification
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 11
SN  - 2072-4292

AB  - The reemergence of Deep Neural Networks (DNNs) has lead to high-performance supervised learning algorithms for the Electro-Optical (EO) domain classification and detection problems. This success is because generating huge labeled datasets has become possible using modern crowdsourcing labeling platforms such as Amazon&rsquo;s Mechanical Turk that recruit ordinary people to label data. Unlike the EO domain, labeling the Synthetic Aperture Radar (SAR) domain data can be much more challenging, and for various reasons, using crowdsourcing platforms is not feasible for labeling the SAR domain data. As a result, training deep networks using supervised learning is more challenging in the SAR domain. In the paper, we present a new framework to train a deep neural network for classifying Synthetic Aperture Radar (SAR) images by eliminating the need for a huge labeled dataset. Our idea is based on transferring knowledge from a related EO domain problem, where labeled data are easy to obtain. We transfer knowledge from the EO domain through learning a shared invariant cross-domain embedding space that is also discriminative for classification. To this end, we train two deep encoders that are coupled through their last year to map data points from the EO and the SAR domains to the shared embedding space such that the distance between the distributions of the two domains is minimized in the latent embedding space. We use the Sliced Wasserstein Distance (SWD) to measure and minimize the distance between these two distributions and use a limited number of SAR label data points to match the distributions class-conditionally. As a result of this training procedure, a classifier trained from the embedding space to the label space using mostly the EO data would generalize well on the SAR domain. We provide a theoretical analysis to demonstrate why our approach is effective and validate our algorithm on the problem of ship classification in the SAR domain by comparing against several other competing learning approaches.
KW  - transfer learning
KW  - convolutional neural network
KW  - electro-optical imaging
KW  - Synthetic Aperture Radar (SAR) imaging
KW  - optimal transport metric
DO  - 10.3390/rs11111374
ER  -
TY  - EJOU
AU  - Abeysinghe, Tharindu
AU  - Simic Milas, Anita
AU  - Arend, Kristin
AU  - Hohman, Breann
AU  - Reil, Patrick
AU  - Gregory, Andrew
AU  - Vázquez-Ortega, Angélica
TI  - Mapping Invasive Phragmites australis in the Old Woman Creek Estuary Using UAV Remote Sensing and Machine Learning Classifiers
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 11
SN  - 2072-4292

AB  - Unmanned aerial vehicles (UAV) are increasingly used for spatiotemporal monitoring of invasive plants in coastal wetlands. Early identification of invasive species is necessary in planning, restoring, and managing wetlands. This study assessed the effectiveness of UAV technology to identify invasive Phragmites australis in the Old Woman Creek (OWC) estuary using machine learning (ML) algorithms: Neural network (NN), support vector machine (SVM), and k-nearest neighbor (kNN). The ML algorithms were compared with the parametric maximum likelihood classifier (MLC) using pixel- and object-based methods. Pixel-based NN was identified as the best classifier with an overall accuracy of 94.80% and the lowest error of omission of 1.59%, the outcome desirable for effective eradication of Phragmites. The results were reached combining Sequoia multispectral imagery (green, red, red edge, and near-infrared bands) combined with the canopy height model (CHM) acquired in the mid-growing season and normalized difference vegetation index (NDVI) acquired later in the season. The sensitivity analysis, using various vegetation indices, image texture, CHM, and principal components (PC), demonstrated the impact of various feature layers on the classifiers. The study emphasizes the necessity of a suitable sampling and cross-validation methods, as well as the importance of optimum classification parameters.
KW  - Phragmites australis
KW  - unmanned aerial vehicles
KW  - invasive
KW  - machine learning
KW  - object-based classifiers
DO  - 10.3390/rs11111380
ER  -
TY  - EJOU
AU  - Xu, Jianzhong
AU  - Yan, Fu
AU  - Yun, Kumchol
AU  - Su, Lifei
AU  - Li, Fengshu
AU  - Guan, Jun
TI  - Noninferior Solution Grey Wolf Optimizer with an Independent Local Search Mechanism for Solving Economic Load Dispatch Problems
T2  - Energies

PY  - 2019
VL  - 12
IS  - 12
SN  - 1996-1073

AB  - The economic load dispatch (ELD) problem is a complex optimization problem in power systems. The main task for this optimization problem is to minimize the total fuel cost of generators while also meeting the conditional constraints of valve-point loading effects, prohibited operating zones, and nonsmooth cost functions. In this paper, a novel grey wolf optimization (GWO), abbreviated as NGWO, is proposed to solve the ELD problem by introducing an independent local search strategy and a noninferior solution neighborhood independent local search technique to the original GWO algorithm to achieve the best problem solution. A local search strategy is added to the standard GWO algorithm in the NGWO, which is called GWOI, to search the local neighborhood of the global optimal point in depth and to guarantee a better candidate. In addition, a noninferior solution neighborhood independent local search method is introduced into the GWOI algorithm to find a better solution in the noninferior solution neighborhood and ensure the high probability of jumping out of the local optimum. The feasibility of the proposed NGWO method is verified on five different power systems, and it is compared with other selected methods in terms of the solution quality, convergence rate, and robustness. The compared experimental results indicate that the proposed NGWO method can efficiently solve ELD problems with higher-quality solutions.
KW  - grey wolf optimizer (GWO)
KW  - noninferior solution
KW  - local search mechanism
KW  - economic load dispatch problems (ELD)
KW  - optimization algorithms
DO  - 10.3390/en12122274
ER  -
TY  - EJOU
AU  - Yao, Huang
AU  - Qin, Rongjun
AU  - Chen, Xiaoyu
TI  - Unmanned Aerial Vehicle for Remote Sensing Applications—A Review
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 12
SN  - 2072-4292

AB  - The unmanned aerial vehicle (UAV) sensors and platforms nowadays are being used in almost every application (e.g., agriculture, forestry, and mining) that needs observed information from the top or oblique views. While they intend to be a general remote sensing (RS) tool, the relevant RS data processing and analysis methods are still largely ad-hoc to applications. Although the obvious advantages of UAV data are their high spatial resolution and flexibility in acquisition and sensor integration, there is in general a lack of systematic analysis on how these characteristics alter solutions for typical RS tasks such as land-cover classification, change detection, and thematic mapping. For instance, the ultra-high-resolution data (less than 10 cm of Ground Sampling Distance (GSD)) bring more unwanted classes of objects (e.g., pedestrian and cars) in land-cover classification; the often available 3D data generated from photogrammetric images call for more advanced techniques for geometric and spectral analysis. In this paper, we perform a critical review on RS tasks that involve UAV data and their derived products as their main sources including raw perspective images, digital surface models, and orthophotos. In particular, we focus on solutions that address the &ldquo;new&rdquo; aspects of the UAV data including (1) ultra-high resolution; (2) availability of coherent geometric and spectral data; and (3) capability of simultaneously using multi-sensor data for fusion. Based on these solutions, we provide a brief summary of existing examples of UAV-based RS in agricultural, environmental, urban, and hazards assessment applications, etc., and by discussing their practical potentials, we share our views in their future research directions and draw conclusive remarks.
KW  - UAVs
KW  - remote sensing applications
KW  - data analysis
DO  - 10.3390/rs11121443
ER  -
TY  - EJOU
AU  - Munaye, Yirga Y.
AU  - Lin, Hsin-Piao
AU  - Adege, Abebe B.
AU  - Tarekegn, Getaneh B.
TI  - UAV Positioning for Throughput Maximization Using Deep Learning Approaches
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 12
SN  - 1424-8220

AB  - The use of unmanned aerial vehicles (UAVs) as a communication platform has great practical importance for future wireless networks, especially for on-demand deployment for temporary and emergency conditions. The user throughput estimation in a wireless system depends on the data traffic load and the available capacity to support that load. In UAV-assisted communication, the position of the UAV is one major factor that affects the capacity available to the data flows being served. This study applies multi-layer perceptron (MLP) and long short term memory (LSTM) approaches to determine the position of a UAV that maximizes the overall system performance and user throughput. To analyze and evaluate the system performance, we apply the hybrid of MLP-LSTM for classification regression tasks and K-means algorithms for automatic clustering of classes. The implementation of our work is done through TensorFlow packages. The performance of our proposed system is compared with other approaches to give accurate and novel results for both classification and regression tasks of the user throughput maximization and UAV positioning. According to the results, 98% of the user throughput maximization accuracy is correctly classified. Moreover, the UAV positioning provides accuracy levels of 94.73%, 98.33%, and 99.53% for original datasets (scenario 1), reduced features on the estimated values of user throughput at each grid point (scenario 2), and reduced feature datasets collected on different days and grid points achieved maximum throughput (scenario 3), respectively.
KW  - user throughput
KW  - maximization
KW  - UAV
KW  - positioning
KW  - deep learning (DL)
DO  - 10.3390/s19122775
ER  -
TY  - EJOU
AU  - Vanbrabant, Yasmin
AU  - Tits, Laurent
AU  - Delalieux, Stephanie
AU  - Pauly, Klaas
AU  - Verjans, Wim
AU  - Somers, Ben
TI  - Multitemporal Chlorophyll Mapping in Pome Fruit Orchards from Remotely Piloted Aircraft Systems
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 12
SN  - 2072-4292

AB  - Early and precise spatio-temporal monitoring of tree vitality is key for steering management decisions in pome fruit orchards. Spaceborne remote sensing instruments face a tradeoff between spatial and spectral resolution, while manned aircraft sensor-platform systems are very expensive. In order to address the shortcomings of these platforms, this study investigates the potential of Remotely Piloted Aircraft Systems (RPAS) to facilitate rapid, low cost, and flexible chlorophyll monitoring. Due to the complexity of orchard scenery a robust chlorophyll retrieval model on RPAS level has not yet been developed. In this study, specific focus therefore lies on evaluating the sensitivity of retrieval models to confounding factors. For this study, multispectral and hyperspectral imagery was collected over pome fruit orchards. Sensitivities of both univariate and multivariate retrieval models were demonstrated under different species, phenology, shade, and illumination scenes. Results illustrate that multivariate models have a significantly higher accuracy than univariate models as the former provide accuracies for the canopy chlorophyll content retrieval of R2 = 0.80 and Relative Root Mean Square Error (RRMSE) = 12% for the hyperspectral sensor. Random forest regression on multispectral imagery (R2 &gt; 0.9 for May, June, July, and August, and R2 = 0.5 for October) and hyperspectral imagery (0.6 &lt; R2 &lt; 0.9) led to satisfactory high and consistent accuracies for all months.
KW  - chlorophyll
KW  - fruit orchards
KW  - RPAS
KW  - multivariate
KW  - multispectral remote sensing
KW  - hyperspectral remote sensing
KW  - random forest
DO  - 10.3390/rs11121468
ER  -
TY  - EJOU
AU  - Yang, Zhen
AU  - Yuan, Yongbo
AU  - Zhang, Mingyuan
AU  - Zhao, Xuefeng
AU  - Zhang, Yang
AU  - Tian, Boquan
TI  - Safety Distance Identification for Crane Drivers Based on Mask R-CNN
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 12
SN  - 1424-8220

AB  - Tower cranes are the most commonly used large-scale equipment on construction site. Because workers can&rsquo;t always pay attention to the environment at the top of the head, it is often difficult to avoid accidents when heavy objects fall. Therefore, safety construction accidents such as struck-by often occurs. In order to address crane issue, this research recorded video data by a tower crane camera, labeled the pictures, and operated image recognition with the MASK R-CNN method. Furthermore, The RGB color extraction was performed on the identified mask layer to obtain the pixel coordinates of workers and dangerous zone. At last, we used the pixel and actual distance conversion method to measure the safety distance. The contribution of this research to safety problem area is twofold: On one hand, without affecting the normal behavior of workers, an automatic collection, analysis, and early-warning system was established. On the other hand, the proposed automatic inspection system can help improve the safety operation of tower crane drivers.
KW  - construction management
KW  - construction safety
KW  - cranes
KW  - imaging techniques
KW  - safety distance
DO  - 10.3390/s19122789
ER  -
TY  - EJOU
AU  - Stodola, Petr
AU  - Drozd, Jan
AU  - Nohel, Jan
AU  - Hodický, Jan
AU  - Procházka, Dalibor
TI  - Trajectory Optimization in a Cooperative Aerial Reconnaissance Model
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 12
SN  - 1424-8220

AB  - In recent years, the use of modern technology in military operations has become standard practice. Unmanned systems play an important role in operations such as reconnaissance and surveillance. This article examines a model for planning aerial reconnaissance using a fleet of mutually cooperating unmanned aerial vehicles to increase the effectiveness of the task. The model deploys a number of waypoints such that, when every waypoint is visited by any vehicle in the fleet, the area of interest is fully explored. The deployment of waypoints must meet the conditions arising from the technical parameters of the sensory systems used and tactical requirements of the task at hand. This paper proposes an improvement of the model by optimizing the number and position of waypoints deployed in the area of interest, the effect of which is to improve the trajectories of individual unmanned systems, and thus increase the efficiency of the operation. To achieve this optimization, a modified simulated annealing algorithm is proposed. The improvement of the model is verified by several experiments. Two sets of benchmark problems were designed: (a) benchmark problems for verifying the proposed algorithm for optimizing waypoints, and (b) benchmark problems based on typical reconnaissance scenarios in the real environment to prove the increased effectiveness of the reconnaissance operation. Moreover, an experiment in the SteelBeast simulation system was also conducted.
KW  - cooperative aerial reconnaissance
KW  - unmanned aerial vehicles
KW  - simulated annealing
KW  - optimization of waypoints
KW  - trajectory optimization
KW  - experiments
KW  - simulation
DO  - 10.3390/s19122823
ER  -
TY  - EJOU
AU  - Zhang, Heng
AU  - Eziz, Anwar
AU  - Xiao, Jian
AU  - Tao, Shengli
AU  - Wang, Shaopeng
AU  - Tang, Zhiyao
AU  - Zhu, Jiangling
AU  - Fang, Jingyun
TI  - High-Resolution Vegetation Mapping Using eXtreme Gradient Boosting Based on Extensive Features
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 12
SN  - 2072-4292

AB  - Accurate mapping of vegetation is a premise for conserving, managing, and sustainably using vegetation resources, especially in conditions of intensive human activities and accelerating global changes. However, it is still challenging to produce high-resolution multiclass vegetation map in high accuracy, due to the incapacity of traditional mapping techniques in distinguishing mosaic vegetation classes with subtle differences and the paucity of fieldwork data. This study created a workflow by adopting a promising classifier, extreme gradient boosting (XGBoost), to produce accurate vegetation maps of two strikingly different cases (the Dzungarian Basin in China and New Zealand) based on extensive features and abundant vegetation data. For the Dzungarian Basin, a vegetation map with seven vegetation types, 17 subtypes, and 43 associations was produced with an overall accuracy of 0.907, 0.801, and 0.748, respectively. For New Zealand, a map of 10 habitats and a map of 41 vegetation classes were produced with 0.946, and 0.703 overall accuracy, respectively. The workflow incorporating simplified field survey procedures outperformed conventional field survey and remote sensing based methods in terms of accuracy and efficiency. In addition, it opens a possibility of building large-scale, high-resolution, and timely vegetation monitoring platforms for most terrestrial ecosystems worldwide with the aid of Google Earth Engine and citizen science programs.
KW  - vegetation mapping
KW  - XGBoost
KW  - simplified field survey
KW  - Dzungarian Basin
KW  - New Zealand
DO  - 10.3390/rs11121505
ER  -
TY  - EJOU
AU  - Cardenal, Javier
AU  - Fernández, Tomás
AU  - Pérez-García, José L.
AU  - Gómez-López, José M.
TI  - Measurement of Road Surface Deformation Using Images Captured from UAVs
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 12
SN  - 2072-4292

AB  - This paper presents a methodology for measuring road surface deformation due to terrain instability processes. The methodology is based on ultra-high resolution images acquired from unmanned aerial vehicles (UAVs). Flights are georeferenced by means of Structure from Motion (SfM) techniques. Dense point clouds, obtained using the multiple-view stereo (MVS) approach, are used to generate digital surface models (DSM) and high resolution orthophotographs (0.02 m GSD). The methodology has been applied to an unstable area located in La Guardia (Jaen, Southern Spain), where an active landslide was identified. This landslide affected some roads and accesses to a highway at the landslide foot. The detailed road deformation was monitored between 2012 and 2015 by means of eleven UAV flights of ultrahigh resolution covering an area of about 260 m × 90 m. The accuracy of the analysis has been established in 0.02 ± 0.01 m in XY and 0.04 ± 0.02 m in Z. Large deformations in the order of two meters were registered in the total period analyzed that resulted in maximum average rates of 0.62 m/month in the unstable area. Some boundary conditions were considered because of the low required flying height (&lt;50 m above ground level) in order to achieve a suitable image GSD, the fast landslide dynamic, continuous maintenance works on the affected roads and dramatic seasonal vegetation changes throughout the monitoring period. Finally, we have analyzed the relation of displacements to rainfalls in the area, finding a significant correlation between the two variables, as well as two different reactivation episodes.
KW  - road surface deformation
KW  - UAV images
KW  - SfM-MVS
KW  - monitoring points
DO  - 10.3390/rs11121507
ER  -
TY  - EJOU
AU  - Koch, Tobias
AU  - Körner, Marco
AU  - Fraundorfer, Friedrich
TI  - Automatic and Semantically-Aware 3D UAV Flight Planning for Image-Based 3D Reconstruction
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 13
SN  - 2072-4292

AB  - Small-scaled unmanned aerial vehicles (UAVs) emerge as ideal image acquisition platforms due to their high maneuverability even in complex and tightly built environments. The acquired images can be utilized to generate high-quality 3D models using current multi-view stereo approaches. However, the quality of the resulting 3D model highly depends on the preceding flight plan which still requires human expert knowledge, especially in complex urban and hazardous environments. In terms of safe flight plans, practical considerations often define prohibited and restricted airspaces to be accessed with the vehicle. We propose a 3D UAV path planning framework designed for detailed and complete small-scaled 3D reconstructions considering the semantic properties of the environment allowing for user-specified restrictions on the airspace. The generated trajectories account for the desired model resolution and the demands on a successful photogrammetric reconstruction. We exploit semantics from an initial flight to extract the target object and to define restricted and prohibited airspaces which have to be avoided during the path planning process to ensure a safe and short UAV path, while still aiming to maximize the object reconstruction quality. The path planning problem is formulated as an orienteering problem and solved via discrete optimization exploiting submodularity and photogrammetrical relevant heuristics. An evaluation of our method on a customized synthetic scene and on outdoor experiments suggests the real-world capability of our methodology by providing feasible, short and safe flight plans for the generation of detailed 3D reconstruction models.
KW  - UAV
KW  - trajectory optimization
KW  - path planning
KW  - discrete optimization
KW  - 3D reconstruction
KW  - semantics
KW  - urban mapping
DO  - 10.3390/rs11131550
ER  -
TY  - EJOU
AU  - Zhang, Xin
AU  - Han, Liangxiu
AU  - Dong, Yingying
AU  - Shi, Yue
AU  - Huang, Wenjiang
AU  - Han, Lianghao
AU  - González-Moreno, Pablo
AU  - Ma, Huiqin
AU  - Ye, Huichun
AU  - Sobeih, Tam
TI  - A Deep Learning-Based Approach for Automated Yellow Rust Disease Detection from High-Resolution Hyperspectral UAV Images
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 13
SN  - 2072-4292

AB  - Yellow rust in winter wheat is a widespread and serious fungal disease, resulting in significant yield losses globally. Effective monitoring and accurate detection of yellow rust are crucial to ensure stable and reliable wheat production and food security. The existing standard methods often rely on manual inspection of disease symptoms in a small crop area by agronomists or trained surveyors. This is costly, time consuming and prone to error due to the subjectivity of surveyors. Recent advances in unmanned aerial vehicles (UAVs) mounted with hyperspectral image sensors have the potential to address these issues with low cost and high efficiency. This work proposed a new deep convolutional neural network (DCNN) based approach for automated crop disease detection using very high spatial resolution hyperspectral images captured with UAVs. The proposed model introduced multiple Inception-Resnet layers for feature extraction and was optimized to establish the most suitable depth and width of the network. Benefiting from the ability of convolution layers to handle three-dimensional data, the model used both spatial and spectral information for yellow rust detection. The model was calibrated with hyperspectral imagery collected by UAVs in five different dates across a whole crop cycle over a well-controlled field experiment with healthy and rust infected wheat plots. Its performance was compared across sampling dates and with random forest, a representative of traditional classification methods in which only spectral information was used. It was found that the method has high performance across all the growing cycle, particularly at late stages of the disease spread. The overall accuracy of the proposed model (0.85) was higher than that of the random forest classifier (0.77). These results showed that combining both spectral and spatial information is a suitable approach to improving the accuracy of crop disease detection with high resolution UAV hyperspectral images.
KW  - winter wheat
KW  - yellow rust
KW  - crop disease
KW  - unmanned aerial vehicle
KW  - hyperspectral
KW  - deep learning
KW  - classification
DO  - 10.3390/rs11131554
ER  -
TY  - EJOU
AU  - Yin, Junnan
AU  - Zhu, Dequan
AU  - Liao, Juan
AU  - Zhu, Guangyue
AU  - Wang, Yao
AU  - Zhang, Shun
TI  - Automatic Steering Control Algorithm Based on Compound Fuzzy PID for Rice Transplanter
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 13
SN  - 2076-3417

AB  - In order to realize automatic steering controls of rice transplanters in paddy fields, an automatic steering control algorithm is essential. In this study, combining the fuzzy control with the proportional-integral-derivative (PID) control and the kinematics model, a compound fuzzy PID controller was proposed to adjust the real time data of the PID parameters for the automatic steering control. The Kubota SPU-68C rice transplanter was then modified with the new controller. Next, an automatic steering control experimental with the modified transplanter was carried out under two conditions of linear tracking and headland turning in verifying the automatic steering effect of the transplanter in different steering angle situations. The results showed that the deviation with the new controller and the modified transplanter was acceptable, with maximum deviation in linear tracking of 7.5 cm, the maximum headland turning a deviation of 11.5 cm, and the average a deviation of less than 5 cm. In conclusion, within the allowable deviation range of the field operation of the rice transplanter, the proposed algorithm successfully realized automatic steering controls of the transplanter under different steering angles.
KW  - rice transplanter
KW  - automatic steering
KW  - pure pursuit model
KW  - compound fuzzy PID
DO  - 10.3390/app9132666
ER  -
TY  - EJOU
AU  - Kim, Dongil
AU  - Kang, Seokho
TI  - Effect of Irrelevant Variables on Faulty Wafer Detection in Semiconductor Manufacturing
T2  - Energies

PY  - 2019
VL  - 12
IS  - 13
SN  - 1996-1073

AB  - Machine learning has been applied successfully for faulty wafer detection tasks in semiconductor manufacturing. For the tasks, prediction models are built with prior data to predict the quality of future wafers as a function of their precedent process parameters and measurements. In real-world problems, it is common for the data to have a portion of input variables that are irrelevant to the prediction of an output variable. The inclusion of many irrelevant variables negatively affects the performance of prediction models. Typically, prediction models learned by different learning algorithms exhibit different sensitivities with regard to irrelevant variables. Algorithms with low sensitivities are preferred as a first trial for building prediction models, whereas a variable selection procedure is necessarily considered for highly sensitive algorithms. In this study, we investigate the effect of irrelevant variables on three well-known representative learning algorithms that can be applied to both classification and regression tasks: artificial neural network, decision tree (DT), and k-nearest neighbors (k-NN). We analyze the characteristics of these learning algorithms in the presence of irrelevant variables with different model complexity settings. An empirical analysis is performed using real-world datasets collected from a semiconductor manufacturer to examine how the number of irrelevant variables affects the behavior of prediction models trained with different learning algorithms and model complexity settings. The results indicate that the prediction accuracy of k-NN is highly degraded, whereas DT demonstrates the highest robustness in the presence of many irrelevant variables. In addition, a higher model complexity of learning algorithms leads to a higher sensitivity to irrelevant variables.
KW  - faulty wafer detection
KW  - semiconductor manufacturing
KW  - irrelevant variable
KW  - supervised learning
KW  - prediction model
DO  - 10.3390/en12132530
ER  -
TY  - EJOU
AU  - Zhang, Jianming
AU  - Lu, Chaoquan
AU  - Wang, Jin
AU  - Wang, Lei
AU  - Yue, Xiao-Guang
TI  - Concrete Cracks Detection Based on FCN with Dilated Convolution
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 13
SN  - 2076-3417

AB  - In civil engineering, the stability of concrete is of great significance to safety of people&rsquo;s life and property, so it is necessary to detect concrete damage effectively. In this paper, we treat crack detection on concrete surface as a semantic segmentation task that distinguishes background from crack at the pixel level. Inspired by Fully Convolutional Networks (FCN), we propose a full convolution network based on dilated convolution for concrete crack detection, which consists of an encoder and a decoder. Specifically, we first used the residual network to extract the feature maps of the input image, designed the dilated convolutions with different dilation rates to extract the feature maps of different receptive fields, and fused the extracted features from multiple branches. Then, we exploited the stacked deconvolution to do up-sampling operator in the fused feature maps. Finally, we used the SoftMax function to classify the feature maps at the pixel level. In order to verify the validity of the model, we introduced the commonly used evaluation indicators of semantic segmentation: Pixel Accuracy (PA), Mean Pixel Accuracy (MPA), Mean Intersection over Union (MIoU), and Frequency Weighted Intersection over Union (FWIoU). The experimental results show that the proposed model converges faster and has better generalization performance on the test set by introducing dilated convolutions with different dilation rates and a multi-branch fusion strategy. Our model has a PA of 96.84%, MPA of 92.55%, MIoU of 86.05% and FWIoU of 94.22% on the test set, which is superior to other models.
KW  - FCN
KW  - crack detection
KW  - residual network
KW  - dilated convolution
KW  - semantic segmentation
DO  - 10.3390/app9132686
ER  -
TY  - EJOU
AU  - Lee, SangSik
AU  - Jeong, YiNa
AU  - Son, SuRak
AU  - Lee, ByungKwan
TI  - A Self-Predictable Crop Yield Platform (SCYP) Based On Crop Diseases Using Deep Learning
T2  - Sustainability

PY  - 2019
VL  - 11
IS  - 13
SN  - 2071-1050

AB  - This paper proposes a self-predictable crop yield platform (SCYP) based on crop diseases using deep learning that collects weather information (temperature, humidity, sunshine, precipitation, etc.) and farm status information (harvest date, disease information, crop status, ground temperature, etc.), diagnoses crop diseases by using convolutional neural network (CNN), and predicts crop yield based on factors such as climate change, crop diseases, and others by using artificial neural network (ANN). The SCYP consists of an image preprocessing module (IPM) to determine crop diseases through the Google Vision API and image resizing, a crop disease diagnosis module (CDDM) based on CNN to diagnose the types and extent of crop diseases through photographs, and a crop yield prediction module (CYPM) based on ANN by using information of crop diseases, remaining time until harvest (based on the date), current temperature, humidity and precipitation (amount of snowfall) in the area, sunshine amount, ground temperature, atmospheric pressure, moisture evaporation in the ground, etc. Four experiments were conducted to verify the efficiency of the SCYP. In the CDMM, the accuracy and operation time of each model were measured using three neural network models: CNN, region-CNN(R-CNN), and you only look once (YOLO). In the CYPM, rectified linear unit (ReLU), Sigmoid, and Step activation functions were compared to measure ANN accuracy. The accuracy of CNN was about 3.5% higher than that of R-CNN and about 5.4% higher than that of YOLO. The operation time of CNN was about 37 s less than that of R-CNN and about 72 s less than that of YOLO. The CDDM had slightly less operation time, but in this paper, we prefer accuracy over operation time to diagnose crop diseases efficiently and accurately. When the activation function of the ANN used in the CYPM was ReLU, the accuracy of the ANN was 2% higher than that of Sigmoid and 7% higher than that of Step. The CYPM prediction was about 34% more accurate when using multiple diseases than when not using them. Therefore, the SCYP can predict farm yields more accurately than traditional methods.
KW  - crop disease diagnosis
KW  - yield prediction
KW  - CNN
KW  - ANN
KW  - image preprocessing
DO  - 10.3390/su11133637
ER  -
TY  - EJOU
AU  - Chen, Yang
AU  - Lee, Won S.
AU  - Gan, Hao
AU  - Peres, Natalia
AU  - Fraisse, Clyde
AU  - Zhang, Yanchao
AU  - He, Yong
TI  - Strawberry Yield Prediction Based on a Deep Neural Network Using High-Resolution Aerial Orthoimages
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 13
SN  - 2072-4292

AB  - Strawberry growers in Florida suffer from a lack of efficient and accurate yield forecasts for strawberries, which would allow them to allocate optimal labor and equipment, as well as other resources for harvesting, transportation, and marketing. Accurate estimation of the number of strawberry flowers and their distribution in a strawberry field is, therefore, imperative for predicting the coming strawberry yield. Usually, the number of flowers and their distribution are estimated manually, which is time-consuming, labor-intensive, and subjective. In this paper, we develop an automatic strawberry flower detection system for yield prediction with minimal labor and time costs. The system used a small unmanned aerial vehicle (UAV) (DJI Technology Co., Ltd., Shenzhen, China) equipped with an RGB (red, green, blue) camera to capture near-ground images of two varieties (Sensation and Radiance) at two different heights (2 m and 3 m) and built orthoimages of a 402 m2 strawberry field. The orthoimages were automatically processed using the Pix4D software and split into sequential pieces for deep learning detection. A faster region-based convolutional neural network (R-CNN), a state-of-the-art deep neural network model, was chosen for the detection and counting of the number of flowers, mature strawberries, and immature strawberries. The mean average precision (mAP) was 0.83 for all detected objects at 2 m heights and 0.72 for all detected objects at 3 m heights. We adopted this model to count strawberry flowers in November and December from 2 m aerial images and compared the results with a manual count. The average deep learning counting accuracy was 84.1% with average occlusion of 13.5%. Using this system could provide accurate counts of strawberry flowers, which can be used to forecast future yields and build distribution maps to help farmers observe the growth cycle of strawberry fields.
KW  - strawberry yield prediction
KW  - unmanned aerial vehicle
KW  - orthoimages
KW  - deep neural network
KW  - distribution map
DO  - 10.3390/rs11131584
ER  -
TY  - EJOU
AU  - Fakhrulddin, Saif S.
AU  - Gharghan, Sadik K.
AU  - Al-Naji, Ali
AU  - Chahl, Javaan
TI  - An Advanced First Aid System Based on an Unmanned Aerial Vehicles and a Wireless Body Area Sensor Network for Elderly Persons in Outdoor Environments
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 13
SN  - 1424-8220

AB  - For elderly persons, a fall can cause serious injuries such as a hip fracture or head injury. Here, an advanced first aid system is proposed for monitoring elderly patients with heart conditions that puts them at risk of falling and for providing first aid supplies using an unmanned aerial vehicle. A hybridized fall detection algorithm (FDB-HRT) is proposed based on a combination of acceleration and a heart rate threshold. Five volunteers were invited to evaluate the performance of the heartbeat sensor relative to a benchmark device, and the extracted data was validated using statistical analysis. In addition, the accuracy of fall detections and the recorded locations of fall incidents were validated. The proposed FDB-HRT algorithm was 99.16% and 99.2% accurate with regard to heart rate measurement and fall detection, respectively. In addition, the geolocation error of patient fall incidents based on a GPS module was evaluated by mean absolute error analysis for 17 different locations in three cities in Iraq. Mean absolute error was 1.08 &times; 10&minus;5&deg; and 2.01 &times; 10&minus;5&deg; for latitude and longitude data relative to data from the GPS Benchmark system. In addition, the results revealed that in urban areas, the UAV succeeded in all missions and arrived at the patient&rsquo;s locations before the ambulance, with an average time savings of 105 s. Moreover, a time saving of 31.81% was achieved when using the UAV to transport a first aid kit to the patient compared to an ambulance. As a result, we can conclude that when compared to delivering first aid via ambulance, our design greatly reduces delivery time. The proposed advanced first aid system outperformed previous systems presented in the literature in terms of accuracy of heart rate measurement, fall detection, and information messages and UAV arrival time.
KW  - algorithm
KW  - Arduino microcontroller
KW  - drone
KW  - fall detection
KW  - first aid
KW  - GPS
KW  - GSM
KW  - heart rate
KW  - smartphone
KW  - UAV
KW  - WBSN
DO  - 10.3390/s19132955
ER  -
TY  - EJOU
AU  - Contreras-Cruz, Marco A.
AU  - Ramirez-Paredes, Juan P.
AU  - Hernandez-Belmonte, Uriel H.
AU  - Ayala-Ramirez, Victor
TI  - Vision-Based Novelty Detection Using Deep Features and Evolved Novelty Filters for Specific Robotic Exploration and Inspection Tasks
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 13
SN  - 1424-8220

AB  - One of the essential abilities in animals is to detect novelties within their environment. From the computational point of view, novelty detection consists of finding data that are different in some aspect to the known data. In robotics, researchers have incorporated novelty modules in robots to develop automatic exploration and inspection tasks. The visual sensor is one of the preferred sensors to perform this task. However, there exist problems as illumination changes, occlusion, and scale, among others. Besides, novelty detectors vary their performance depending on the specific application scenario. In this work, we propose a visual novelty detection framework for specific exploration and inspection tasks based on evolved novelty detectors. The system uses deep features to represent the visual information captured by the robots and applies a global optimization technique to design novelty detectors for specific robotics applications. We verified the performance of the proposed system against well-established state-of-the-art methods in a challenging scenario. This scenario was an outdoor environment covering typical problems in computer vision such as illumination changes, occlusion, and geometric transformations. The proposed framework presented high-novelty detection accuracy with competitive or even better results than the baseline methods.
KW  - visual inspection
KW  - one-class classifier
KW  - grow-when-required neural network
KW  - evolving connectionist systems
KW  - automatic design
KW  - bio-inspired techniques
KW  - artificial bee colony
DO  - 10.3390/s19132965
ER  -
TY  - EJOU
AU  - Jalil, Bushra
AU  - Leone, Giuseppe R.
AU  - Martinelli, Massimo
AU  - Moroni, Davide
AU  - Pascali, Maria A.
AU  - Berton, Andrea
TI  - Fault Detection in Power Equipment via an Unmanned Aerial System Using Multi Modal Data
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 13
SN  - 1424-8220

AB  - The power transmission lines are the link between power plants and the points of consumption, through substations. Most importantly, the assessment of damaged aerial power lines and rusted conductors is of extreme importance for public safety; hence, power lines and associated components must be periodically inspected to ensure a continuous supply and to identify any fault and defect. To achieve these objectives, recently, Unmanned Aerial Vehicles (UAVs) have been widely used; in fact, they provide a safe way to bring sensors close to the power transmission lines and their associated components without halting the equipment during the inspection, and reducing operational cost and risk. In this work, a drone, equipped with multi-modal sensors, captures images in the visible and infrared domain and transmits them to the ground station. We used state-of-the-art computer vision methods to highlight expected faults (i.e., hot spots) or damaged components of the electrical infrastructure (i.e., damaged insulators). Infrared imaging, which is invariant to large scale and illumination changes in the real operating environment, supported the identification of faults in power transmission lines; while a neural network is adapted and trained to detect and classify insulators from an optical video stream. We demonstrate our approach on data captured by a drone in Parma, Italy.
KW  - image analysis
KW  - RGB images
KW  - infrared images
KW  - wire detection
KW  - unmanned aerial vehicles
KW  - object detection
KW  - neural networks
DO  - 10.3390/s19133014
ER  -
TY  - EJOU
AU  - Bui, Xuan-Nam
AU  - Lee, Chang W.
AU  - Nguyen, Hoang
AU  - Bui, Hoang-Bac
AU  - Long, Nguyen Q.
AU  - Le, Qui-Thao
AU  - Nguyen, Van-Duc
AU  - Nguyen, Ngoc-Bich
AU  - Moayedi, Hossein
TI  - Estimating PM10 Concentration from Drilling Operations in Open-Pit Mines Using an Assembly of SVR and PSO
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 14
SN  - 2076-3417

AB  - Dust is one of the components causing heavy environmental pollution in open-pit mines, especially PM10. Some pathologies related to the lung, respiratory system, and occupational diseases have been identified due to the effects of PM10 in open-pit mines. Therefore, the prediction and control of PM10 concentration in the production process are necessary for environmental and health protection. In this study, PM10 concentration from drilling operations in the Coc Sau open-pit coal mine (Vietnam) was investigated and considered through a database including 245 datasets collected. A novel hybrid artificial intelligence model was developed based on support vector regression (SVR) and a swarm optimization algorithm (i.e., particle swarm optimization (PSO)), namely PSO-SVR, for estimating PM10 concentration from drilling operations at the mine. Polynomial (P), radial basis function (RBF), and linear (L) kernel functions were considered and applied to the development of the PSO-SVR models in the present study, abbreviated as PSO-SVR-P, PSO-SVR-RBF, and PSO-SVR-L. Also, three benchmark artificial intelligence techniques, such as k-nearest neighbors (KNN), random forest (RF), and classification and regression trees (CART), were applied and developed for estimating PM10 concentration and then compared with the PSO-SVR models. Root-mean-squared error (RMSE) and determination coefficient (R2) were used as the statistical criteria for evaluating the performance of the developed models. The results exhibited that the PSO algorithm had an essential role in the optimization of the hyper-parameters of the SVR models. The PSO-SVR models (i.e., PSO-SVR-L, PSO-SVR-P, and PSO-SVR-RBF) had higher performance levels than the other models (i.e., RF, CART, and KNN) with an RMSE of 0.040, 0.042, and 0.043; and R2 of 0.954, 0.948, and 0.946; for the PSO-SVR-L, PSO-SVR-P, and PSO-SVR-RBF models, respectively. Of these PSO-SVR models, the PSO-SVR-L model was the most dominant model with an RMSE of 0.040 and R2 of 0.954. The remaining three benchmark models (i.e., RF, CART, and KNN) yielded a more unsatisfactory performance with an RMSE of 0.060, 0.052, and 0.067; and R2 of 0.894, 0.924, and 0.867, for the RF, CART, and KNN models, respectively. Furthermore, the findings of this study demonstrated that the density of rock mass, moisture content, and the penetration rate of the drill were essential parameters on the PM10 concentration caused by drilling operations in open-pit mines.
KW  - meta-heuristic algorithm
KW  - PM10 concentration
KW  - drilling operation
KW  - artificial intelligence
KW  - open-pit coal mine
DO  - 10.3390/app9142806
ER  -
TY  - EJOU
AU  - Xin, Junfeng
AU  - Li, Shixin
AU  - Sheng, Jinlu
AU  - Zhang, Yongbo
AU  - Cui, Ying
TI  - Application of Improved Particle Swarm Optimization for Navigation of Unmanned Surface Vehicles
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 14
SN  - 1424-8220

AB  - Multi-sensor fusion for unmanned surface vehicles (USVs) is an important issue for autonomous navigation of USVs. In this paper, an improved particle swarm optimization (PSO) is proposed for real-time autonomous navigation of a USV in real maritime environment. To overcome the conventional PSO&rsquo;s inherent shortcomings, such as easy occurrence of premature convergence and human experience-determined parameters, and to enhance the precision and algorithm robustness of the solution, this work proposes three optimization strategies: linearly descending inertia weight, adaptively controlled acceleration coefficients, and random grouping inversion. Their respective or combinational effects on the effectiveness of path planning are investigated by Monte Carlo simulations for five TSPLIB instances and application tests for the navigation of a self-developed unmanned surface vehicle on the basis of multi-sensor data. Comparative results show that the adaptively controlled acceleration coefficients play a substantial role in reducing the path length and the linearly descending inertia weight help improve the algorithm robustness. Meanwhile, the random grouping inversion optimizes the capacity of local search and maintains the population diversity by stochastically dividing the single swarm into several subgroups. Moreover, the PSO combined with all three strategies shows the best performance with the shortest trajectory and the superior robustness, although retaining solution precision and avoiding being trapped in local optima require more time consumption. The experimental results of our USV demonstrate the effectiveness and efficiency of the proposed method for real-time navigation based on multi-sensor fusion.
KW  - travelling salesman problem
KW  - particle swarm optimization
KW  - parameter setting
KW  - random grouping inversion
KW  - unmanned surface vehicle
KW  - multi-sensor data
DO  - 10.3390/s19143096
ER  -
TY  - EJOU
AU  - Peng, Yahui
AU  - Liu, Xiaochen
AU  - Shen, Chong
AU  - Huang, Haoqian
AU  - Zhao, Donghua
AU  - Cao, Huiliang
AU  - Guo, Xiaoting
TI  - An Improved Optical Flow Algorithm Based on Mask-R-CNN and K-Means for Velocity Calculation
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 14
SN  - 2076-3417

AB  - Aiming at enhancing the accuracy and reliability of velocity calculation in vision navigation, an improved method is proposed in this paper. The method integrates Mask-R-CNN (Mask Region-based Convolutional Neural Network) and K-Means with the pyramid Lucas Kanade algorithm in order to reduce the harmful effect of moving objects on velocity calculation. Firstly, Mask-R-CNN is used to recognize the objects which have motions relative to the ground and covers them with masks to enhance the similarity between pixels and to reduce the impacts of the noisy moving pixels. Then, the pyramid Lucas Kanade algorithm is used to calculate the optical flow value. Finally, the value is clustered by the K-Means algorithm to abandon the outliers, and vehicle velocity is calculated by the processed optical flow. The prominent advantages of the proposed algorithm are (i) decreasing the bad impacts to velocity calculation, due to the objects which have relative motions; (ii) obtaining the correct optical flow sets and velocity calculation outputs with less fluctuation; and (iii) the applicability enhancement of the optical flow algorithm in complex navigation environment. The proposed algorithm is tested by actual experiments. Results with superior precision and reliability show the feasibility and effectiveness of the proposed method for vehicle velocity calculation in vision navigation system.
KW  - velocity calculation
KW  - optical flow
KW  - pyramid LK
KW  - Mask-R-CNN
KW  - clustering algorithm
DO  - 10.3390/app9142808
ER  -
TY  - EJOU
AU  - Zhou, Chengquan
AU  - Ye, Hongbao
AU  - Hu, Jun
AU  - Shi, Xiaoyan
AU  - Hua, Shan
AU  - Yue, Jibo
AU  - Xu, Zhifu
AU  - Yang, Guijun
TI  - Automated Counting of Rice Panicle by Applying Deep Learning Model to Images from Unmanned Aerial Vehicle Platform
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 14
SN  - 1424-8220

AB  - The number of panicles per unit area is a common indicator of rice yield and is of great significance to yield estimation, breeding, and phenotype analysis. Traditional counting methods have various drawbacks, such as long delay times and high subjectivity, and they are easily perturbed by noise. To improve the accuracy of rice detection and counting in the field, we developed and implemented a panicle detection and counting system that is based on improved region-based fully convolutional networks, and we use the system to automate rice-phenotype measurements. The field experiments were conducted in target areas to train and test the system and used a rotor light unmanned aerial vehicle equipped with a high-definition RGB camera to collect images. The trained model achieved a precision of 0.868 on a held-out test set, which demonstrates the feasibility of this approach. The algorithm can deal with the irregular edge of the rice panicle, the significantly different appearance between the different varieties and growing periods, the interference due to color overlapping between panicle and leaves, and the variations in illumination intensity and shading effects in the field. The result is more accurate and efficient recognition of rice-panicles, which facilitates rice breeding. Overall, the approach of training deep learning models on increasingly large and publicly available image datasets presents a clear path toward smartphone-assisted crop disease diagnosis on a global scale.
KW  - rice panicle counting
KW  - UAV platform
KW  - deep learning
KW  - yield estimation
DO  - 10.3390/s19143106
ER  -
TY  - EJOU
AU  - Fu, Yongyong
AU  - Ye, Ziran
AU  - Deng, Jinsong
AU  - Zheng, Xinyu
AU  - Huang, Yibo
AU  - Yang, Wu
AU  - Wang, Yaohua
AU  - Wang, Ke
TI  - Finer Resolution Mapping of Marine Aquaculture Areas Using WorldView-2 Imagery and a Hierarchical Cascade Convolutional Neural Network
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 14
SN  - 2072-4292

AB  - Marine aquaculture plays an important role in seafood supplement, economic development, and coastal ecosystem service provision. The precise delineation of marine aquaculture areas from high spatial resolution (HSR) imagery is vital for the sustainable development and management of coastal marine resources. However, various sizes and detailed structures of marine objects make it difficult for accurate mapping from HSR images by using conventional methods. Therefore, this study attempts to extract marine aquaculture areas by using an automatic labeling method based on the convolutional neural network (CNN), i.e., an end-to-end hierarchical cascade network (HCNet). Specifically, for marine objects of various sizes, we propose to improve the classification performance by utilizing multi-scale contextual information. Technically, based on the output of a CNN encoder, we employ atrous convolutions to capture multi-scale contextual information and aggregate them in a hierarchical cascade way. Meanwhile, for marine objects with detailed structures, we propose to refine the detailed information gradually by using a series of long-span connections with fine resolution features from the shallow layers. In addition, to decrease the semantic gaps between features in different levels, we propose to refine the feature space (i.e., channel and spatial dimensions) using an attention-based module. Experimental results show that our proposed HCNet can effectively identify and distinguish different kinds of marine aquaculture, with 98% of overall accuracy. It also achieves better classification performance compared with object-based support vector machine and state-of-the-art CNN-based methods, such as FCN-32s, U-Net, and DeeplabV2. Our developed method lays a solid foundation for the intelligent monitoring and management of coastal marine resources.
KW  - marine aquaculture areas
KW  - WorldView-2 imagery
KW  - fully convolutional network (FCN)
KW  - land-use and land-cover (LULC) mapping
DO  - 10.3390/rs11141678
ER  -
TY  - EJOU
AU  - Guo, Jia
AU  - Gong, Xiangyang
AU  - Wang, Wendong
AU  - Que, Xirong
AU  - Liu, Jingyu
TI  - SASRT: Semantic-Aware Super-Resolution Transmission for Adaptive Video Streaming over Wireless Multimedia Sensor Networks
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 14
SN  - 1424-8220

AB  - There are few network resources in wireless multimedia sensor networks (WMSNs). Compressing media data can reduce the reliance of user&rsquo;s Quality of Experience (QoE) on network resources. Existing video coding software, such as H.264 and H.265, focuses only on spatial and short-term information redundancy. However, video usually contains redundancy over a long period of time. Therefore, compressing video information redundancy with a long period of time without compromising the user experience and adaptive delivery is a challenge in WMSNs. In this paper, a semantic-aware super-resolution transmission for adaptive video streaming system (SASRT) for WMSNs is presented. In the SASRT, some deep learning algorithms are used to extract video semantic information and enrich the video quality. On the multimedia sensor, different bit-rate semantic information and video data are encoded and uploaded to user. Semantic information can also be identified on the user side, further reducing the amount of data that needs to be transferred. However, identifying semantic information on the user side may increase the computational cost of the user side. On the user side, video quality is enriched with super-resolution technologies. The major challenges faced by SASRT include where the semantic information is identified, how to choose the bit rates of semantic and video information, and how network resources should be allocated to video and semantic information. The optimization problem is formulated as a complexity-constrained nonlinear NP-hard problem. Three adaptive strategies and a heuristic algorithm are proposed to solve the optimization problem. Simulation results demonstrate that SASRT can compress video information redundancy with a long period of time effectively and enrich the user experience with limited network resources while simultaneously improving the utilization of these network resources.
KW  - video streaming optimization
KW  - semantic-aware
KW  - super-resolution
KW  - wireless multimedia sensor networks
DO  - 10.3390/s19143121
ER  -
TY  - EJOU
AU  - Manzo, Mario
TI  - Graph-Based Image Matching for Indoor Localization
T2  - Machine Learning and Knowledge Extraction

PY  - 2019
VL  - 1
IS  - 3
SN  - 2504-4990

AB  - Graphs are a very useful framework for representing information. In general, these data structures are used in different application domains where data of interest are described in terms of local and spatial relations. In this context, the aim is to propose an alternative graph-based image representation. An image is encoded by a Region Adjacency Graph (RAG), based on Multicolored Neighborhood (MCN) clustering. This representation is integrated into a Content-Based Image Retrieval (CBIR) system, designed for the vision-based positioning task. The image matching phase, in the CBIR system, is managed with an approach of attributed graph matching, named the extended-VF algorithm. Evaluated in a context of indoor localization, the proposed system reports remarkable performance.
KW  - content-based image retrieval
KW  - clustering
KW  - attributed graph matching
KW  - image-based localization
DO  - 10.3390/make1030046
ER  -
TY  - EJOU
AU  - Farooq, Adnan
AU  - Jia, Xiuping
AU  - Hu, Jiankun
AU  - Zhou, Jun
TI  - Multi-Resolution Weed Classification via Convolutional Neural Network and Superpixel Based Local Binary Pattern Using Remote Sensing Images
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 14
SN  - 2072-4292

AB  - Automatic weed detection and classification faces the challenges of large intraclass variation and high spectral similarity to other vegetation. With the availability of new high-resolution remote sensing data from various platforms and sensors, it is possible to capture both spectral and spatial characteristics of weed species at multiple scales. Effective multi-resolution feature learning is then desirable to extract distinctive intensity, texture and shape features of each category of weed to enhance the weed separability. We propose a feature extraction method using a Convolutional Neural Network (CNN) and superpixel based Local Binary Pattern (LBP). Both middle and high level spatial features are learned using the CNN. Local texture features from superpixel-based LBP are extracted, and are also used as input to Support Vector Machines (SVM) for weed classification. Experimental results on the hyperspectral and remote sensing datasets verify the effectiveness of the proposed method, and show that it outperforms several feature extraction approaches.
KW  - hyperspectral images
KW  - weed mapping
KW  - multi-resolution
KW  - local binary pattern (LBP)
KW  - convolutional neural network (CNN)
DO  - 10.3390/rs11141692
ER  -
TY  - EJOU
AU  - Mekhalfi, Mohamed L.
AU  - Bejiga, Mesay B.
AU  - Soresina, Davide
AU  - Melgani, Farid
AU  - Demir, Begüm
TI  - Capsule Networks for Object Detection in UAV Imagery
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 14
SN  - 2072-4292

AB  - Recent advances in Convolutional Neural Networks (CNNs) have attracted great attention in remote sensing due to their high capability to model high-level semantic content of Remote Sensing (RS) images. However, CNNs do not explicitly retain the relative position of objects in an image and, thus, the effectiveness of the obtained features is limited in the framework of the complex object detection problems. To address this problem, in this paper we introduce Capsule Networks (CapsNets) for object detection in Unmanned Aerial Vehicle-acquired images. Unlike CNNs, CapsNets extract and exploit the information content about objects&rsquo; relative position across several layers, which enables parsing crowded scenes with overlapping objects. Experimental results obtained on two datasets for car and solar panel detection problems show that CapsNets provide similar object detection accuracies when compared to state-of-the-art deep models with significantly reduced computational time. This is due to the fact that CapsNets emphasize dynamic routine instead of the depth.
KW  - unmanned aerial vehicles
KW  - object detection
KW  - convolutional neural networks
KW  - capsule networks
KW  - dynamic routing
DO  - 10.3390/rs11141694
ER  -
TY  - EJOU
AU  - Cao, Shuang
AU  - Yu, Yongtao
AU  - Guan, Haiyan
AU  - Peng, Daifeng
AU  - Yan, Wanqian
TI  - Affine-Function Transformation-Based Object Matching for Vehicle Detection from Unmanned Aerial Vehicle Imagery
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 14
SN  - 2072-4292

AB  - Vehicle detection from remote sensing images plays a significant role in transportation related applications. However, the scale variations, orientation variations, illumination variations, and partial occlusions of vehicles, as well as the image qualities, bring great challenges for accurate vehicle detection. In this paper, we present an affine-function transformation-based object matching framework for vehicle detection from unmanned aerial vehicle (UAV) images. First, meaningful and non-redundant patches are generated through a superpixel segmentation strategy. Then, the affine-function transformation-based object matching framework is applied to a vehicle template and each of the patches for vehicle existence estimation. Finally, vehicles are detected and located after matching cost thresholding, vehicle location estimation, and multiple response elimination. Quantitative evaluations on two UAV image datasets show that the proposed method achieves an average completeness, correctness, quality, and F1-measure of 0.909, 0.969, 0.883, and 0.938, respectively. Comparative studies also demonstrate that the proposed method achieves compatible performance with the Faster R-CNN and outperforms the other eight existing methods in accurately detecting vehicles of various conditions.
KW  - vehicle detection
KW  - object matching
KW  - superpixel segmentation
KW  - unmanned aerial vehicle
KW  - remote sensing imagery
DO  - 10.3390/rs11141708
ER  -
TY  - EJOU
AU  - Jozdani, Shahab E.
AU  - Johnson, Brian A.
AU  - Chen, Dongmei
TI  - Comparing Deep Neural Networks, Ensemble Classifiers, and Support Vector Machine Algorithms for Object-Based Urban Land Use/Land Cover Classification
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 14
SN  - 2072-4292

AB  - With the advent of high-spatial resolution (HSR) satellite imagery, urban land use/land cover (LULC) mapping has become one of the most popular applications in remote sensing. Due to the importance of context information (e.g., size/shape/texture) for classifying urban LULC features, Geographic Object-Based Image Analysis (GEOBIA) techniques are commonly employed for mapping urban areas. Regardless of adopting a pixel- or object-based framework, the selection of a suitable classifier is of critical importance for urban mapping. The popularity of deep learning (DL) (or deep neural networks (DNNs)) for image classification has recently skyrocketed, but it is still arguable if, or to what extent, DL methods can outperform other state-of-the art ensemble and/or Support Vector Machines (SVM) algorithms in the context of urban LULC classification using GEOBIA. In this study, we carried out an experimental comparison among different architectures of DNNs (i.e., regular deep multilayer perceptron (MLP), regular autoencoder (RAE), sparse, autoencoder (SAE), variational autoencoder (AE), convolutional neural networks (CNN)), common ensemble algorithms (Random Forests (RF), Bagging Trees (BT), Gradient Boosting Trees (GB), and Extreme Gradient Boosting (XGB)), and SVM to investigate their potential for urban mapping using a GEOBIA approach. We tested the classifiers on two RS images (with spatial resolutions of 30 cm and 50 cm). Based on our experiments, we drew three main conclusions: First, we found that the MLP model was the most accurate classifier. Second, unsupervised pretraining with the use of autoencoders led to no improvement in the classification result. In addition, the small difference in the classification accuracies of MLP from those of other models like SVM, GB, and XGB classifiers demonstrated that other state-of-the-art machine learning classifiers are still versatile enough to handle mapping of complex landscapes. Finally, the experiments showed that the integration of CNN and GEOBIA could not lead to more accurate results than the other classifiers applied.
KW  - remote sensing
KW  - high-spatial resolution imagery
KW  - deep learning
KW  - GEOBIA
KW  - land use/cover classification
DO  - 10.3390/rs11141713
ER  -
TY  - EJOU
AU  - Gong, Qingwu
AU  - Tan, Si
AU  - Wang, Yubo
AU  - Liu, Dong
AU  - Qiao, Hui
AU  - Wu, Liuchuang
TI  - Online Operation Risk Assessment of the Wind Power System of the Convolution Neural Network (CNN) Considering Multiple Random Factors
T2  - Processes

PY  - 2019
VL  - 7
IS  - 7
SN  - 2227-9717

AB  - In order to solve the problem of the inaccuracy of the traditional online operation risk assessment model based on a physical mechanism and the inability to adapt to the actual operation of massive online operation monitoring data, this paper proposes an online operation risk assessment of the wind power system of the convolution neural network (CNN) considering multiple random factors. This paper analyzes multiple random factors of the wind power system, including uncertain wind power output, load fluctuations, frequent changes in operation patterns, and the electrical equipment failure rate, and generates the sample data based on multi-random factors. It uses the CNN algorithm network, offline training to obtain the risk assessment model, and online application to obtain the real-time online operation risk state of the wind power system. Finally, the online operation risk assessment model is verified by simulation using the standard network of 39 nodes of 10 machines New England system. The results prove that the risk assessment model presented in this paper is more rapid and suitable for online application.
KW  - online operation risk assessment
KW  - uncertain wind power output
KW  - load fluctuations
KW  - operation pattern
KW  - equipment failure rate
KW  - CNN
DO  - 10.3390/pr7070464
ER  -
TY  - EJOU
AU  - Kim, Whui
AU  - Jung, Woo-Sung
AU  - Choi, Hyun K.
TI  - Lightweight Driver Monitoring System Based on Multi-Task Mobilenets
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 14
SN  - 1424-8220

AB  - Research on driver status recognition has been actively conducted to reduce fatal crashes caused by the driver&rsquo;s distraction and drowsiness. As in many other research areas, deep-learning-based algorithms are showing excellent performance for driver status recognition. However, despite decades of research in the driver status recognition area, the visual image-based driver monitoring system has not been widely used in the automobile industry. This is because the system requires high-performance processors, as well as has a hierarchical structure in which each procedure is affected by an inaccuracy from the previous procedure. To avoid using a hierarchical structure, we propose a method using Mobilenets without the functions of face detection and tracking and show this method is enabled to recognize facial behaviors that indicate the driver&rsquo;s distraction. However, frames per second processed by Mobilenets with a Raspberry pi, one of the single-board computers, is not enough to recognize the driver status. To alleviate this problem, we propose a lightweight driver monitoring system using a resource sharing device in a vehicle (e.g., a driver&rsquo;s mobile phone). The proposed system is based on Multi-Task Mobilenets (MT-Mobilenets), which consists of the Mobilenets&rsquo; base and multi-task classifier. The three Softmax regressions of the multi-task classifier help one Mobilenets base recognize facial behaviors related to the driver status, such as distraction, fatigue, and drowsiness. The proposed system based on MT-Mobilenets improved the accuracy of the driver status recognition with Raspberry Pi by using one additional device.
KW  - lightweight
KW  - driver assistance
KW  - drowsiness
KW  - fatigue
KW  - distraction
KW  - PERCLOS
KW  - ECT
KW  - ECD
KW  - single-board computer
KW  - SBC
KW  - Raspberry pi
DO  - 10.3390/s19143200
ER  -
TY  - EJOU
AU  - Tao, Jiadong
AU  - Yin, Zhong
AU  - Liu, Lei
AU  - Tian, Ying
AU  - Sun, Zhanquan
AU  - Zhang, Jianhua
TI  - Individual-Specific Classification of Mental Workload Levels Via an Ensemble Heterogeneous Extreme Learning Machine for EEG Modeling
T2  - Symmetry

PY  - 2019
VL  - 11
IS  - 7
SN  - 2073-8994

AB  - In a human&ndash;machine cooperation system, assessing the mental workload (MW) of the human operator is quite crucial to maintaining safe operation conditions. Among various MW indicators, electroencephalography (EEG) signals are particularly attractive because of their high temporal resolution and sensitivity to the occupation of working memory. However, the individual difference of the EEG feature distribution may impair the machine-learning based MW classifier. In this paper, we employed a fast-training neural network, extreme learning machine (ELM), as the basis to build an individual-specific classifier ensemble to recognize binary MW. To improve the diversity of the classification committee, heterogeneous member classifiers were adopted by fusing multiple ELMs and Bayesian models. Specifically, a deep network structure was applied in each weak model aiming at finding informative EEG feature representations. The structure of hyper-parameters of the proposed heterogeneous ensemble ELM (HE-ELM) was then identified and then its performance was compared against several competitive MW classifiers. We found that the HE-ELM model was superior for improving the individual-specific accuracy of MW assessments.
KW  - electroencephalography
KW  - mental workload
KW  - extreme learning machine
KW  - ensemble learning
DO  - 10.3390/sym11070944
ER  -
TY  - EJOU
AU  - Iannace, Gino
AU  - Ciaburro, Giuseppe
AU  - Trematerra, Amelia
TI  - Fault Diagnosis for UAV Blades Using Artificial Neural Network
T2  - Robotics

PY  - 2019
VL  - 8
IS  - 3
SN  - 2218-6581

AB  - In recent years, unmanned aerial vehicles (UAVs) have been used in several fields including, for example, archaeology, cargo transport, conservation, healthcare, filmmaking, hobbies and recreational use. UAVs are aircraft characterized by the absence of a human pilot on board. The extensive use of these devices has highlighted maintenance problems with regard to the propellers, which represent the source of propulsion of the aircraft. A defect in the propellers of a drone can cause the aircraft to fall to the ground and its consequent destruction, and it also constitutes a safety problem for objects and people that are in the range of action of the aircraft. In this study, the measurements of the noise emitted by a UAV were used to build a classification model to detect unbalanced blades in a UAV propeller. To simulate the fault condition, two strips of paper tape were applied to the upper surface of a blade. The paper tape created a substantial modification of the aerodynamics of the blade, and this modification characterized the noise produced by the blade in its rotation. Then, a model based on artificial neural network algorithms was built to detect unbalanced blades in a UAV propeller. This model showed high accuracy (0.9763), indicating a high number of correct detections and suggests the adoption of this tool to verify the operating conditions of a UAV. The test must be performed indoors; from the measurements of the noise produced by the UAV it is possible to identify an imbalance in the propeller blade.
KW  - quadcopter UAV
KW  - artificial neural network
KW  - fault diagnosis
KW  - acoustic measurements
KW  - unbalanced propeller
DO  - 10.3390/robotics8030059
ER  -
TY  - EJOU
AU  - Cho, Jaechan
AU  - Jung, Yongchul
AU  - Kim, Dong-Sun
AU  - Lee, Seongjoo
AU  - Jung, Yunho
TI  - Moving Object Detection Based on Optical Flow Estimation and a Gaussian Mixture Model for Advanced Driver Assistance Systems
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 14
SN  - 1424-8220

AB  - Most approaches for moving object detection (MOD) based on computer vision are limited to stationary camera environments. In advanced driver assistance systems (ADAS), however, ego-motion is added to image frames owing to the use of a moving camera. This results in mixed motion in the image frames and makes it difficult to classify target objects and background. In this paper, we propose an efficient MOD algorithm that can cope with moving camera environments. In addition, we present a hardware design and implementation results for the real-time processing of the proposed algorithm. The proposed moving object detector was designed using hardware description language (HDL) and its real-time performance was evaluated using an FPGA based test system. Experimental results demonstrate that our design achieves better detection performance than existing MOD systems. The proposed moving object detector was implemented with 13.2K logic slices, 104 DSP48s, and 163 BRAM and can support real-time processing of 30 fps at an operating frequency of 200 MHz.
KW  - ADAS
KW  - background subtraction
KW  - FPGA
KW  - moving object detection
KW  - optical flow estimation
DO  - 10.3390/s19143217
ER  -
TY  - EJOU
AU  - Jakovljevic, Gordana
AU  - Govedarica, Miro
AU  - Alvarez-Taboada, Flor
AU  - Pajic, Vladimir
TI  - Accuracy Assessment of Deep Learning Based Classification of LiDAR and UAV Points Clouds for DTM Creation and Flood Risk Mapping
T2  - Geosciences

PY  - 2019
VL  - 9
IS  - 7
SN  - 2076-3263

AB  - Digital elevation model (DEM) has been frequently used for the reduction and management of flood risk. Various classification methods have been developed to extract DEM from point clouds. However, the accuracy and computational efficiency need to be improved. The objectives of this study were as follows: (1) to determine the suitability of a new method to produce DEM from unmanned aerial vehicle (UAV) and light detection and ranging (LiDAR) data, using a raw point cloud classification and ground point filtering based on deep learning and neural networks (NN); (2) to test the convenience of rebalancing datasets for point cloud classification; (3) to evaluate the effect of the land cover class on the algorithm performance and the elevation accuracy; and (4) to assess the usability of the LiDAR and UAV structure from motion (SfM) DEM in flood risk mapping. In this paper, a new method of raw point cloud classification and ground point filtering based on deep learning using NN is proposed and tested on LiDAR and UAV data. The NN was trained on approximately 6 million points from which local and global geometric features and intensity data were extracted. Pixel-by-pixel accuracy assessment and visual inspection confirmed that filtering point clouds based on deep learning using NN is an appropriate technique for ground classification and producing DEM, as for the test and validation areas, both ground and non-ground classes achieved high recall (&gt;0.70) and high precision values (&gt;0.85), which showed that the two classes were well handled by the model. The type of method used for balancing the original dataset did not have a significant influence in the algorithm accuracy, and it was suggested not to use any of them unless the distribution of the generated and real data set will remain the same. Furthermore, the comparisons between true data and LiDAR and a UAV structure from motion (UAV SfM) point clouds were analyzed, as well as the derived DEM. The root mean square error (RMSE) and the mean average error (MAE) of the DEM were 0.25 m and 0.05 m, respectively, for LiDAR data, and 0.59 m and &ndash;0.28 m, respectively, for UAV data. For all land cover classes, the UAV DEM overestimated the elevation, whereas the LIDAR DEM underestimated it. The accuracy was not significantly different in the LiDAR DEM for the different vegetation classes, while for the UAV DEM, the RMSE increased with the height of the vegetation class. The comparison of the inundation areas derived from true LiDAR and UAV data for different water levels showed that in all cases, the largest differences were obtained for the lowest water level tested, while they performed best for very high water levels. Overall, the approach presented in this work produced DEM from LiDAR and UAV data with the required accuracy for flood mapping according to European Flood Directive standards. Although LiDAR is the recommended technology for point cloud acquisition, a suitable alternative is also UAV SfM in hilly areas.
KW  - DEM
KW  - NN
KW  - deep learning
KW  - classification
KW  - LIDAR
KW  - UAV
KW  - SfM
KW  - point cloud
DO  - 10.3390/geosciences9070323
ER  -
TY  - EJOU
AU  - Cao, Mingwei
AU  - Jia, Wei
AU  - Lv, Zhihan
AU  - Zheng, Liping
AU  - Liu, Xiaoping
TI  - Superpixel-Based Feature Tracking for Structure from Motion
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 15
SN  - 2076-3417

AB  - Feature tracking in image collections significantly affects the efficiency and accuracy of Structure from Motion (SFM). Insufficient correspondences may result in disconnected structures and incomplete components, while the redundant correspondences containing incorrect ones may yield to folded and superimposed structures. In this paper, we present a Superpixel-based feature tracking method for structure from motion. In the proposed method, we first propose to use a joint approach to detect local keypoints and compute descriptors. Second, the superpixel-based approach is used to generate labels for the input image. Third, we combine the Speed Up Robust Feature and binary test in the generated label regions to produce a set of combined descriptors for the detected keypoints. Fourth, the locality-sensitive hash (LSH)-based k nearest neighboring matching (KNN) is utilized to produce feature correspondences, and then the ratio test approach is used to remove outliers from the previous matching collection. Finally, we conduct comprehensive experiments on several challenging benchmarking datasets including highly ambiguous and duplicated scenes. Experimental results show that the proposed method gets better performances with respect to the state of the art methods.
KW  - feature tracking
KW  - superpixel
KW  - structure from motion
KW  - three-dimensional reconstruction
KW  - local feature
KW  - multi-view stereo
DO  - 10.3390/app9152961
ER  -
TY  - EJOU
AU  - Luo, Cai
AU  - Zhao, Weikang
AU  - Du, Zhenpeng
AU  - Yu, Leijian
TI  - A Neural Network Based Landing Method for an Unmanned Aerial Vehicle with Soft Landing Gears
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 15
SN  - 2076-3417

AB  - This paper presents the design, implementation, and testing of a soft landing gear together with a neural network-based control method for replicating avian landing behavior on non-flat surfaces. With full consideration of unmanned aerial vehicles and landing gear requirements, a quadrotor helicopter, comprised of one flying unit and one landing assistance unit, is employed. Considering the touchdown speed and posture, a novel design of a soft mechanism for non-flat surfaces is proposed, in order to absorb the remaining landing impact. The framework of the control strategy is designed based on a derived dynamic model. A neural network-based backstepping controller is applied to achieve the desired trajectory. The simulation and outdoor testing results attest to the effectiveness and reliability of the proposed control method.
KW  - unmanned aerial vehicle
KW  - neural network
KW  - soft landing gear
DO  - 10.3390/app9152976
ER  -
TY  - EJOU
AU  - Hildmann, Hanno
AU  - Kovacs, Ernö
TI  - Review: Using Unmanned Aerial Vehicles (UAVs) as Mobile Sensing Platforms (MSPs) for Disaster Response, Civil Security and Public Safety
T2  - Drones

PY  - 2019
VL  - 3
IS  - 3
SN  - 2504-446X

AB  - The use of UAVs in areas ranging from agriculture over urban services to entertainment or simply as a hobby has rapidly grown over the last years. Regarding serious/commercial applications, UAVs have been considered in the literature, especially as mobile sensing/actuation platforms (i.e., as a delivery platform for an increasingly wide range of sensors and actuators). With regard to timely, cost-effective and very rich data acquisition, both, NEC Research as well as TNO are pursuing investigations into the use of UAVs and swarms of UAVs for scenarios where high-resolution requirements, prohibiting environments or tight time constraints render traditional approaches ineffective. In this review article, we provide a brief overview of safety and security-focused application areas that we identified as main targets for industrial and commercial projects, especially in the context of intelligent autonomous systems and autonomous/semi-autonomously operating swarms. We discuss a number of challenges related to the deployment of UAVs in general and to their deployment within the identified application areas in particular. As such, this article is meant to serve as a review and overview of the literature and the state-of-the-art, but also to offer an outlook over our possible (near-term) future work and the challenges that we will face there.
KW  - review
KW  - UAV
KW  - drone
KW  - UAV-Swarms
KW  - Intelligent Autonomous Systems
KW  - smart city
KW  - civil security
KW  - public safety
KW  - disaster response
KW  - Mobile Sensing Platform
KW  - applications
KW  - challenges
DO  - 10.3390/drones3030059
ER  -
TY  - EJOU
AU  - Yun, Sungmin
AU  - Kim, Sungho
TI  - TIR-MS: Thermal Infrared Mean-Shift for Robust Pedestrian Head Tracking in Dynamic Target and Background Variations
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 15
SN  - 2076-3417

AB  - Thermal infrared (TIR) pedestrian tracking is one of the major issues in computer vision. Mean-shift is a powerful and versatile non-parametric iterative algorithm for finding local maxima in probability distributions. In existing infrared data, and mean-shift-based tracking is generally based on the brightness feature values. Unfortunately, the brightness is distorted by the target and background variations. This paper proposes a novel pedestrian tracking algorithm, thermal infrared mean-shift (TIR-MS), by introducing radiometric temperature data in mean-shift tracking. The thermal brightness image (eight-bits) was distorted by the automatic contrast enhancement of the scene such as hot objects in the background. On the other hand, the temperature data was unaffected directly by the background change, except for variations by the seasonal effect, which is more stable than the brightness. The experimental results showed that the TIR-MS outperformed the original mean-shift-based brightness when tracking a pedestrian head with successive background variations.
KW  - pedestrian tracking
KW  - infrared
KW  - temperature
KW  - brightness
KW  - background contrast
KW  - radiometry
KW  - mean shift
DO  - 10.3390/app9153015
ER  -
TY  - EJOU
AU  - Salhaoui, Marouane
AU  - Guerrero-González, Antonio
AU  - Arioua, Mounir
AU  - Ortiz, Francisco J.
AU  - El Oualkadi, Ahmed
AU  - Torregrosa, Carlos L.
TI  - Smart Industrial IoT Monitoring and Control System Based on UAV and Cloud Computing Applied to a Concrete Plant
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 15
SN  - 1424-8220

AB  - Unmanned aerial vehicles (UAVs) are now considered one of the best remote sensing techniques for gathering data over large areas. They are now being used in the industry sector as sensing tools for proactively solving or preventing many issues, besides quantifying production and helping to make decisions. UAVs are a highly consistent technological platform for efficient and cost-effective data collection and event monitoring. The industrial Internet of things (IIoT) sends data from systems that monitor and control the physical world to data processing systems that cloud computing has shown to be important tools for meeting processing requirements. In fog computing, the IoT gateway links different objects to the internet. It can operate as a joint interface for different networks and support different communication protocols. A great deal of effort has been put into developing UAVs and multi-UAV systems. This paper introduces a smart IIoT monitoring and control system based on an unmanned aerial vehicle that uses cloud computing services and exploits fog computing as the bridge between IIoT layers. Its novelty lies in the fact that the UAV is automatically integrated into an industrial control system through an IoT gateway platform, while UAV photos are systematically and instantly computed and analyzed in the cloud. Visual supervision of the plant by drones and cloud services is integrated in real-time into the control loop of the industrial control system. As a proof of concept, the platform was used in a case study in an industrial concrete plant. The results obtained clearly illustrate the feasibility of the proposed platform in providing a reliable and efficient system for UAV remote control to improve product quality and reduce waste. For this, we studied the communication latency between the different IIoT layers in different IoT gateways.
KW  - UAVs
KW  - drones
KW  - industry 4.0
KW  - concrete plant
KW  - IoT protocols
KW  - IoT gateway
KW  - image recognition
KW  - cloud computing
KW  - network latency
KW  - end-to-end delay
DO  - 10.3390/s19153316
ER  -
TY  - EJOU
AU  - Ghaychi Afrouz, Setareh
AU  - Razavi, Mohammad R.
AU  - Pourkand, Ashkan
AU  - Mara Dias Wilson, Claudia
TI  - Dynamic Displacement of an Aluminum Frame Using Close Range Photogrammetry
T2  - Buildings

PY  - 2019
VL  - 9
IS  - 8
SN  - 2075-5309

AB  - Dynamic displacement measurement of objects can be challenging due to the limitations of conventional methods and pricey instrumentation of unconventional methods, such as laser scanners. In this research, Close Range Photogrammetry (CRP) is used as an affordable non-contact method to measure 3D dynamic displacements. It is proposed as a reliable alternative to traditional dynamic deformation measurement methods such as displacement sensors or accelerometers. For this purpose, dynamic displacements of a three-dimensional one-story building frame model on a one-dimensional shake table are determined by using the traditional method of attached accelerometer and CRP. The results of the CRP method are compared with the results of the traditional methods as well as numerical models. The results show a good agreement which evidences the reliability of the CRP with regular cameras.
KW  - Close Range Photogrammetry (CRP)
KW  - dynamic displacement
KW  - non-contact measurement
KW  - 3D dynamic instrumentation
DO  - 10.3390/buildings9080176
ER  -
TY  - EJOU
AU  - Fan, Guangpeng
AU  - Chen, Feixiang
AU  - Li, Yan
AU  - Liu, Binbin
AU  - Fan, Xu
TI  - Development and Testing of a New Ground Measurement Tool to Assist in Forest GIS Surveys
T2  - Forests

PY  - 2019
VL  - 10
IS  - 8
SN  - 1999-4907

AB  - In present forest surveys, some problems occur because of the cost and time required when using external tools to acquire tree measurement. Therefore, it is of great importance to develop a new cost-saving and time-saving ground measurement method implemented in a forest geographic information system (GIS) survey. To obtain a better solution, this paper presents the design and implementation of a new ground measurement tool in which mobile devices play a very important role. Based on terrestrial photogrammetry, location-based services (LBS), and computer vision, the tool assists forest GIS surveys in obtaining important forest structure factors such as tree position, diameter at breast height (DBH), tree height, and tree species. This paper selected two plots to verify the accuracy of the ground measurement tool. Experiments show that the root mean square error (RMSE) of the position coordinates of the trees was 0.222 m and 0.229 m, respectively, and the relative root mean square error (rRMSE) was close to 0. The rRMSE of the DBH measurement was 10.17% and 13.38%, and the relative Bias (rBias) of the DBH measurement was &minus;0.88% and &minus;2.41%. The rRMSE of tree height measurement was 6.74% and 6.69%, and the rBias of tree height measurement was &minus;1.69% and &minus;1.27%, which conforms to the forest investigation requirements. In addition, workers usually make visual observations of trees and then combine their personal knowledge or experience to identify tree species, which may lead to the situations when they cannot distinguish tree species due to insufficient knowledge or experience. Based on MobileNets, a lightweight convolutional neural network designed for mobile phone, a model was trained to assist workers in identifying tree species. The dataset was collected from some forest parks in Beijing. The accuracy of the tree species recognition model was 94.02% on a test dataset and 93.21% on a test dataset in the mobile phone. This provides an effective reference for workers to identify tree species and can assist in artificial identification of tree species. Experiments show that this solution using the ground measurement tool saves time and cost for forest resources GIS surveys.
KW  - forest GIS surveys
KW  - terrestrial photogrammetry
KW  - LBS
KW  - MobileNets
KW  - measurement tool
DO  - 10.3390/f10080643
ER  -
TY  - EJOU
AU  - Konecny, Jaromir
AU  - Kromer, Pavel
AU  - Prauzek, Michal
AU  - Musilek, Petr
TI  - Scan Matching by Cross-Correlation and Differential Evolution
T2  - Electronics

PY  - 2019
VL  - 8
IS  - 8
SN  - 2079-9292

AB  - Scan matching is an important task, solved in the context of many high-level problems including pose estimation, indoor localization, simultaneous localization and mapping and others. Methods that are accurate and adaptive and at the same time computationally efficient are required to enable location-based services in autonomous mobile devices. Such devices usually have a wide range of high-resolution sensors but only a limited processing power and constrained energy supply. This work introduces a novel high-level scan matching strategy that uses a combination of two advanced algorithms recently used in this field: cross-correlation and differential evolution. The cross-correlation between two laser range scans is used as an efficient measure of scan alignment and the differential evolution algorithm is used to search for the parameters of a transformation that aligns the scans. The proposed method was experimentally validated and showed good ability to match laser range scans taken shortly after each other and an excellent ability to match laser range scans taken with longer time intervals between them.
KW  - scan matching
KW  - indoor localization
KW  - differential evolution
KW  - cross-correlation
KW  - robotics
DO  - 10.3390/electronics8080856
ER  -
TY  - EJOU
AU  - Iizuka, Kotaro
AU  - Kato, Tsuyoshi
AU  - Silsigia, Sisva
AU  - Soufiningrum, Alifia Y.
AU  - Kozan, Osamu
TI  - Estimating and Examining the Sensitivity of Different Vegetation Indices to Fractions of Vegetation Cover at Different Scaling Grids for Early Stage Acacia Plantation Forests Using a Fixed-Wing UAS
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 15
SN  - 2072-4292

AB  - Understanding the information on land conditions and especially green vegetation cover is important for monitoring ecosystem dynamics. The fraction of vegetation cover (FVC) is a key variable that can be used to observe vegetation cover trends. Conventionally, satellite data are utilized to compute these variables, although computations in regions such as the tropics can limit the amount of available observation information due to frequent cloud coverage. Unmanned aerial systems (UASs) have become increasingly prominent in recent research and can remotely sense using the same methods as satellites but at a lower altitude. UASs are not limited by clouds and have a much higher resolution. This study utilizes a UAS to determine the emerging trends for FVC estimates at an industrial plantation site in Indonesia, which utilizes fast-growing Acacia trees that can rapidly change the land conditions. First, the UAS was utilized to collect high-resolution RGB imagery and multispectral images for the study area. The data were used to develop general land use/land cover (LULC) information for the site. Multispectral data were converted to various vegetation indices, and within the determined resolution grid (5, 10, 30 and 60 m), the fraction of each LULC type was analyzed for its correlation between the different vegetation indices (Vis). Finally, a simple empirical model was developed to estimate the FVC from the UAS data. The results show the correlation between the FVC (acacias) and different Vis ranging from R2 = 0.66&ndash;0.74, 0.76&ndash;0.8, 0.84&ndash;0.89 and 0.93&ndash;0.94 for 5, 10, 30 and 60 m grid resolutions, respectively. This study indicates that UAS-based FVC estimations can be used for observing fast-growing acacia trees at a fine scale resolution, which may assist current restoration programs in Indonesia.
KW  - UAS
KW  - UAV
KW  - vegetation cover
KW  - multispectral
KW  - land cover
KW  - forest
KW  - Acacia
KW  - Indonesia
KW  - tropics
DO  - 10.3390/rs11151816
ER  -
TY  - EJOU
AU  - Cao, Chen
AU  - Chen, Jianping
AU  - Zhang, Wen
AU  - Xu, Peihua
AU  - Zheng, Lianjing
AU  - Zhu, Chun
TI  - Geospatial Analysis of Mass-Wasting Susceptibility of Four Small Catchments in Mountainous Area of Miyun County, Beijing
T2  - International Journal of Environmental Research and Public Health

PY  - 2019
VL  - 16
IS  - 15
SN  - 1660-4601

AB  - Driven by the pull of gravity, mass-wasting comprises all of the sedimentary processes related to remobilization of sediments deposited on slopes, including creep, sliding, slumping, flow, and fall. It is vital to conduct mass-wasting susceptibility mapping, with the aim of providing decision makers with management advice. The current study presents two individual data mining methods&mdash;the frequency ratio (FR) and information value model (IVM) methods&mdash;to map mass-wasting susceptibility in four catchments in Miyun County, Beijing, China. To achieve this goal, nine influence factors and a mass-wasting inventory map were used and produced, respectively. In this study, 71 mass-wasting locations were investigated in the field. Of these hazard locations, 70% of them were randomly selected to build the model, and the remaining 30% of the hazard locations were used for validation. Finally, a receiver operating characteristic (ROC) curve was used to assess the mass-wasting susceptibility maps produced by the above-mentioned models. Results show that the FR had a higher concordance and spatial differentiation, with respective values of 0.902 (area under the success rate) and 0.883 (area under the prediction rate), while the IVM had lower values of 0.865 (area under the success rate) and 0.855 (area under the prediction rate). Both proposed methodologies are useful for general planning and evaluation purposes, and they are shown to be reasonable models. Slopes of 6&ndash;21&deg; were the most common thresholds that controlled occurrence of mass-wasting. Farmland terraces were mainly composed of gravel, mud, and clay, which are more prone to mass-wasting. Mass-wasting susceptibility mapping is feasible and potentially highly valuable. It could provide useful information in support of environmental health policies.
KW  - mass-wasting susceptibility
KW  - catchment management
KW  - frequency ratio
KW  - information value
KW  - farmland terraces
DO  - 10.3390/ijerph16152801
ER  -
TY  - EJOU
AU  - Brinkhoff, James
AU  - Dunn, Brian W.
AU  - Robson, Andrew J.
AU  - Dunn, Tina S.
AU  - Dehaan, Remy L.
TI  - Modeling Mid-Season Rice Nitrogen Uptake Using Multispectral Satellite Data
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 15
SN  - 2072-4292

AB  - Mid-season nitrogen (N) application in rice crops can maximize yield and profitability. This requires accurate and efficient methods of determining rice N uptake in order to prescribe optimal N amounts for topdressing. This study aims to determine the accuracy of using remotely sensed multispectral data from satellites to predict N uptake of rice at the panicle initiation (PI) growth stage, with a view to providing optimum variable-rate N topdressing prescriptions without needing physical sampling. Field experiments over 4 years, 4&ndash;6 N rates, 4 varieties and 2 sites were conducted, with at least 3 replicates of each plot. One WorldView satellite image for each year was acquired, close to the date of PI. Numerous single- and multi-variable models were investigated. Among single-variable models, the square of the NDRE vegetation index was shown to be a good predictor of N uptake (R     2     = 0.75, RMSE = 22.8 kg/ha for data pooled from all years and experiments). For multi-variable models, Lasso regularization was used to ensure an interpretable and compact model was chosen and to avoid over fitting. Combinations of remotely sensed reflectances and spectral indexes as well as variety, climate and management data as input variables for model training achieved R     2    &lt; 0.9 and RMSE &lt; 15 kg/ha for the pooled data set. The ability of remotely sensed data to predict N uptake in new seasons where no physical sample data has yet been obtained was tested. A methodology to extract models that generalize well to new seasons was developed, avoiding model overfitting. Lasso regularization selected four or less input variables, and yielded R     2     of better than 0.67 and RMSE better than 27.4 kg/ha over four test seasons that weren&rsquo;t used to train the models.
KW  - rice
KW  - nitrogen management
KW  - remote sensing
KW  - multispectral imagery
KW  - reflectance index
KW  - multiple variable linear regression
KW  - Lasso model
DO  - 10.3390/rs11151837
ER  -
TY  - EJOU
AU  - Lay, Usman S.
AU  - Pradhan, Biswajeet
AU  - Yusoff, Zainuddin B.
AU  - Abdallah, Ahmad F.
AU  - Aryal, Jagannath
AU  - Park, Hyuck-Jin
TI  - Data Mining and Statistical Approaches in Debris-Flow Susceptibility Modelling Using Airborne LiDAR Data
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 16
SN  - 1424-8220

AB  - Cameron Highland is a popular tourist hub in the mountainous area of Peninsular Malaysia. Most communities in this area suffer frequent incidence of debris flow, especially during monsoon seasons. Despite the loss of lives and properties recorded annually from debris flow, most studies in the region concentrate on landslides and flood susceptibilities. In this study, debris-flow susceptibility prediction was carried out using two data mining techniques; Multivariate Adaptive Regression Splines (MARS) and Support Vector Regression (SVR) models. The existing inventory of debris-flow events (640 points) were selected for training 70% (448) and validation 30% (192). Twelve conditioning factors namely; elevation, plan-curvature, slope angle, total curvature, slope aspect, Stream Transport Index (STI), profile curvature, roughness index, Stream Catchment Area (SCA), Stream Power Index (SPI), Topographic Wetness Index (TWI) and Topographic Position Index (TPI) were selected from Light Detection and Ranging (LiDAR)-derived Digital Elevation Model (DEM) data. Multi-collinearity was checked using Information Factor, Cramer&rsquo;s V, and Gini Index to identify the relative importance of conditioning factors. The susceptibility models were produced and categorized into five classes; not-susceptible, low, moderate, high and very-high classes. Models performances were evaluated using success and prediction rates where the area under the curve (AUC) showed a higher performance of MARS (93% and 83%) over SVR (76% and 72%). The result of this study will be important in contingency hazards and risks management plans to reduce the loss of lives and properties in the area.
KW  - debris flows
KW  - susceptibility
KW  - machine learning
KW  - MARS
KW  - SVR
KW  - LiDAR
KW  - GIS
KW  - remote sensing
DO  - 10.3390/s19163451
ER  -
TY  - EJOU
AU  - Ghoussein, Youssra
AU  - Nicolas, Hervé
AU  - Haury, Jacques
AU  - Fadel, Ali
AU  - Pichelin, Pascal
AU  - Abou Hamdan, Hussein
AU  - Faour, Ghaleb
TI  - Multitemporal Remote Sensing Based on an FVC Reference Period Using Sentinel-2 for Monitoring Eichhornia crassipes on a Mediterranean River
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 16
SN  - 2072-4292

AB  - Invasive aquatic plants are a serious global ecological and socio-economic problem because they can cause local extinction of native species and alter navigation and fishing. Eichhornia crassipes (water hyacinth) is a dangerous invasive floating plant that is widely distributed throughout the world. In Lebanon, it has spread since 2006 in the Al Kabir River. Remote sensing techniques have been widely developed to detect and monitor dynamics and extents of invasive plants such as water hyacinth over large areas. However, they become challenging to use in narrow areas such as the Al Kabir River and we developed a new image-analysis method to extract water hyacinth areas on the river. The method is based on a time series of a biophysical variable obtained from Sentinel-2 images. After defining a reference period between two growing cycles, we used the fractional vegetation cover (FVC) to estimate the water hyacinth surface area in the river. This method makes it possible to monitor water hyacinth development and estimate the total area it colonizes in the river corridor. This method can help ecologists and other stakeholders to map invasive plants in rivers and improve their control.
KW  - Eichhornia crassipes
KW  - remote sensing
KW  - soil-adjusted vegetation index
KW  - FVC reference period
KW  - Sentinel-2
KW  - time series
KW  - Lebanon
DO  - 10.3390/rs11161856
ER  -
TY  - EJOU
AU  - Lygouras, Eleftherios
AU  - Santavas, Nicholas
AU  - Taitzoglou, Anastasios
AU  - Tarchanidis, Konstantinos
AU  - Mitropoulos, Athanasios
AU  - Gasteratos, Antonios
TI  - Unsupervised Human Detection with an Embedded Vision System on a Fully Autonomous UAV for Search and Rescue Operations
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 16
SN  - 1424-8220

AB  - Unmanned aerial vehicles (UAVs) play a primary role in a plethora of technical and scientific fields owing to their wide range of applications. In particular, the provision of emergency services during the occurrence of a crisis event is a vital application domain where such aerial robots can contribute, sending out valuable assistance to both distressed humans and rescue teams. Bearing in mind that time constraints constitute a crucial parameter in search and rescue (SAR) missions, the punctual and precise detection of humans in peril is of paramount importance. The paper in hand deals with real-time human detection onboard a fully autonomous rescue UAV. Using deep learning techniques, the implemented embedded system was capable of detecting open water swimmers. This allowed the UAV to provide assistance accurately in a fully unsupervised manner, thus enhancing first responder operational capabilities. The novelty of the proposed system is the combination of global navigation satellite system (GNSS) techniques and computer vision algorithms for both precise human detection and rescue apparatus release. Details about hardware configuration as well as the system&rsquo;s performance evaluation are fully discussed.
KW  - unmanned aerial vehicles (UAVs)
KW  - search and rescue (SAR) missions
KW  - human detection
KW  - deep learning
DO  - 10.3390/s19163542
ER  -
TY  - EJOU
AU  - Li, Qingyu
AU  - Dai, Keren
AU  - Wang, Xiaofeng
AU  - Zhang, Yu
AU  - Zhang, He
AU  - Jiang, Defu
TI  - Low-Complexity Failed Element Diagnosis for Radar-Communication mmWave Antenna Array with Low SNR
T2  - Electronics

PY  - 2019
VL  - 8
IS  - 8
SN  - 2079-9292

AB  - The millimeter-wave (mmWave) antenna array plays an important role in the excellent performance of wireless sensors networks (WSN) or unmanned aerial vehicle (UAV) clusters. However, the array elements are easily damaged in its harsh working environment but hard to be repaired or exchanged timely, resulting in a serious decline in the beamforming performance. Thus, accurate self-diagnosis of the failed elements is of great importance. In previous studies, there are still significant difficulties for large-scale arrays under extremely low SNR. In this paper, a diagnosis algorithm with low complexity and high reliability for the failed elements is proposed, which is based on a joint decision of communication signal and sensing echoes. Compared with the previous studies, the complexity of the algorithm is reduced by the construction of low-dimensional feature vectors for classification, the decoupling of the degree of arrival (DOA) estimation and the failed pattern diagnosis, with the help of the sub-array division. Simulation results show that, under an ultra-low SNR of &minus;12.5 dB for communication signals and &minus;16 dB for sensing echoes, an accurate self-diagnosis with a block error rate lower than 8% can be realized. The study in this paper will effectively promote the long-term and reliable operation of the mmWave antenna array in WSN, UAV clusters and other similar fields.
KW  - mmWave antenna array
KW  - failed elements diagnisis
KW  - joint radar-communication system
KW  - low complexity
KW  - low SNR
DO  - 10.3390/electronics8080904
ER  -
TY  - EJOU
AU  - Santos, Anderson A.
AU  - Marcato Junior, José
AU  - Araújo, Márcio S.
AU  - Di Martini, David R.
AU  - Tetila, Everton C.
AU  - Siqueira, Henrique L.
AU  - Aoki, Camila
AU  - Eltner, Anette
AU  - Matsubara, Edson T.
AU  - Pistori, Hemerson
AU  - Feitosa, Raul Q.
AU  - Liesenberg, Veraldo
AU  - Gonçalves, Wesley N.
TI  - Assessment of CNN-Based Methods for Individual Tree Detection on Images Captured by RGB Cameras Attached to UAVs
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 16
SN  - 1424-8220

AB  - Detection and classification of tree species from remote sensing data were performed using mainly multispectral and hyperspectral images and Light Detection And Ranging (LiDAR) data. Despite the comparatively lower cost and higher spatial resolution, few studies focused on images captured by Red-Green-Blue (RGB) sensors. Besides, the recent years have witnessed an impressive progress of deep learning methods for object detection. Motivated by this scenario, we proposed and evaluated the usage of Convolutional Neural Network (CNN)-based methods combined with Unmanned Aerial Vehicle (UAV) high spatial resolution RGB imagery for the detection of law protected tree species. Three state-of-the-art object detection methods were evaluated: Faster Region-based Convolutional Neural Network (Faster R-CNN), YOLOv3 and RetinaNet. A dataset was built to assess the selected methods, comprising 392 RBG images captured from August 2018 to February 2019, over a forested urban area in midwest Brazil. The target object is an important tree species threatened by extinction known as Dipteryx alata Vogel (Fabaceae). The experimental analysis delivered average precision around 92% with an associated processing times below 30 miliseconds.
KW  - object-detection
KW  - deep learning
KW  - remote sensing
DO  - 10.3390/s19163595
ER  -
TY  - EJOU
AU  - Liu, Chunting
AU  - Jia, Guozhu
TI  - Industrial Big Data and Computational Sustainability: Multi-Method Comparison Driven by High-Dimensional Data for Improving Reliability and Sustainability of Complex Systems
T2  - Sustainability

PY  - 2019
VL  - 11
IS  - 17
SN  - 2071-1050

AB  - Sustainable development is of great significance. The emerging research on data-driven computational sustainability has become an effective way to solve this problem. This paper presents a fault diagnosis and prediction framework for complex systems based on multi-dimensional data and multi-method comparison, aimed at improving the reliability and sustainability of the system by selecting methods with relatively superior performance. This study took the avionics system in the industrial field as an example. Based on the literature research on typical fault modes and fault diagnosis requirements of avionics systems, three popular high-dimensional data-driven fault diagnosis methods&mdash;support vector machine, convolutional neural network, and long- and short-term memory neural network&mdash;were comprehensively analyzed and compared. Finally, the actual bearing failure data were used for programming in order to verify and compare various methods and the process of selecting the superior method driven by high-dimensional data was fully demonstrated. We attempt to provide a sustainable development idea that continuously explores multi-method integration and comparison, aimed at improving the calculation efficiency and accuracy of reliability assessments, optimizing system performance, and ultimately achieving the goal of long-term improvement of system reliability and sustainability.
KW  - industrial big data
KW  - computational sustainability
KW  - multi-method comparison
KW  - reliability and sustainability
KW  - high-dimensional data
DO  - 10.3390/su11174557
ER  -
TY  - EJOU
AU  - Wu, Ruidong
AU  - Liu, Bing
AU  - Fu, Jiafeng
AU  - Xu, Mingzhu
AU  - Fu, Ping
AU  - Li, Junbao
TI  - Research and Implementation of ε-SVR Training Method Based on FPGA
T2  - Electronics

PY  - 2019
VL  - 8
IS  - 9
SN  - 2079-9292

AB  - Online training of Support Vector Regression (SVR) in the field of machine learning is a computationally complex algorithm. Due to the need for multiple iterative processing in training, SVR training is usually implemented on computer, and the existing training methods cannot be directly implemented on Field-Programmable Gate Array (FPGA), which restricts the application range. This paper reconstructs the training framework and implementation without precision loss to reduce the total latency required for matrix update, reducing time consumption by 90%. A general &epsilon;-SVR training system with low latency is implemented on Zynq platform. Taking the regression of samples in two-dimensional as an example, the maximum acceleration ratio is 27.014&times; compared with microcontroller platform and the energy consumption is 12.449% of microcontroller. From the experiments for the University of California, Riverside (UCR) time series data set. The regression results obtain excellent regression effects. The minimum coefficient of determination is 0.996, and running time is less than 30 ms, which can meet the requirements of different applications for real-time regression.
KW  - training method
KW  - Field-Programmable Gate Array (FPGA)
KW  - Support Vector Regression (SVR)
KW  - Zynq
DO  - 10.3390/electronics8090919
ER  -
TY  - EJOU
AU  - Lu, Bing
AU  - He, Yuhong
TI  - Evaluating Empirical Regression, Machine Learning, and Radiative Transfer Modelling for Estimating Vegetation Chlorophyll Content Using Bi-Seasonal Hyperspectral Images
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 17
SN  - 2072-4292

AB  - Different types of methods have been developed to retrieve vegetation attributes from remote sensing data, including conventional empirical regressions (i.e., linear regression (LR)), advanced empirical regressions (e.g., multivariable linear regression (MLR), partial least square regression (PLSR)), machine learning (e.g., random forest regression (RFR), decision tree regression (DTR)), and radiative transfer modelling (RTM, e.g., PROSAIL). Given that each algorithm has its own strengths and weaknesses, it is essential to compare them and evaluate their effectiveness. Previous studies have mainly used single-date multispectral imagery or ground-based hyperspectral reflectance data for evaluating the models, while multi-seasonal hyperspectral images have been rarely used. Extensive spectral and spatial information in hyperspectral images, as well as temporal variations of landscapes, potentially influence the model performance. In this research, LR, PLSR, RFR, and PROSAIL, representing different types of methods, were evaluated for estimating vegetation chlorophyll content from bi-seasonal hyperspectral images (i.e., a middle- and a late-growing season image, respectively). Results show that the PLSR and RFR generally performed better than LR and PROSAIL. RFR achieved the highest accuracy for both images. This research provides insights on the effectiveness of different models for estimating vegetation chlorophyll content using hyperspectral images, aiming to support future vegetation monitoring research.
KW  - vegetation properties
KW  - empirical regression
KW  - machine learning
KW  - radiative transfer modelling
KW  - hyperspectral
KW  - chlorophyll content
DO  - 10.3390/rs11171979
ER  -
TY  - EJOU
AU  - Ćwiąkała, Paweł
TI  - Testing Procedure of Unmanned Aerial Vehicles (UAVs) Trajectory in Automatic Missions
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 17
SN  - 2076-3417

AB  - This paper describes an experimental test campaign while using an Unmanned Aerial Vehicle (UAV) and measuring the obtained UAV positions during different flight tasks and in different operative conditions. A new test procedure has been presented and tested for different devices in various weather conditions. This paper describes and analyses the measurements of the flight trajectory of the UAV that was performed with the use of a robotic total station (RTS), as compared to the design data and the data recorded in the internal memory of the UAV. Five different test tasks have been conducted. The obtained results have allowed for the assessment of the correctness of task performance as compared to the design and to determine the flying accuracy of the entire UAV set. The proposed set of tasks can be successfully utilised to control the correctness of operation of various types of UAVs and it may be implemented as a universal test to verify the algorithms optimising take-offs and landings, test flights of the objects, as well as flight planning in various terrain and weather conditions, which will increase the safety of the flights while using UAVs.
KW  - unmanned aerial vehicle
KW  - UAV navigation
KW  - path planning
KW  - flight trajectory
KW  - positioning accuracy
KW  - barometric altitude
DO  - 10.3390/app9173488
ER  -
TY  - EJOU
AU  - Jeziorska, Justyna
TI  - UAS for Wetland Mapping and Hydrological Modeling
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 17
SN  - 2072-4292

AB  - The miniaturization and affordable production of integrated microelectronics have improved in recent years, making unmanned aerial systems (UAS) accessible to consumers and igniting their interest. Researchers have proposed UAS-based solutions for almost any conceivable problem, but the greatest impact will likely be in applications that exploit the unique advantages of the technology: work in dangerous or difficult-to-access areas, high spatial resolution and/or frequent measurements of environmental phenomena, and deployment of novel sensing technology over small to moderate spatial scales. Examples of such applications may be the identification of wetland areas and use of high-resolution spatial data for hydrological modeling. However, because of the large&mdash;and growing&mdash;assortment of aircraft and sensors available on the market, an evolving regulatory environment, and limited practical guidance or examples of wetland mapping with UAS, it has been difficult to confidently devise or recommend UAS-based monitoring strategies for these applications. This paper provides a comprehensive review of UAS hardware, software, regulations, scientific applications, and data collection/post-processing procedures that are relevant for wetland monitoring and hydrological modeling.
KW  - UAS
KW  - UAV
KW  - drone
KW  - wetlands
KW  - hydrological modeling
DO  - 10.3390/rs11171997
ER  -
TY  - EJOU
AU  - Khoufi, Ines
AU  - Laouiti, Anis
AU  - Adjih, Cedric
TI  - A Survey of Recent Extended Variants of the Traveling Salesman and Vehicle Routing Problems for Unmanned Aerial Vehicles
T2  - Drones

PY  - 2019
VL  - 3
IS  - 3
SN  - 2504-446X

AB  - The use of Unmanned Aerial Vehicles (UAVs) is rapidly growing in popularity. Initially introduced for military purposes, over the past few years, UAVs and related technologies have successfully transitioned to a whole new range of civilian applications such as delivery, logistics, surveillance, entertainment, and so forth. They have opened new possibilities such as allowing operation in otherwise difficult or hazardous areas, for instance. For all applications, one foremost concern is the selection of the paths and trajectories of UAVs, and at the same time, UAVs control comes with many challenges, as they have limited energy, limited load capacity and are vulnerable to difficult weather conditions. Generally, efficiently operating a drone can be mathematically formalized as a path optimization problem under some constraints. This shares some commonalities with similar problems that have been extensively studied in the context of urban vehicles and it is only natural that the recent literature has extended the latter to fit aerial vehicle constraints. The knowledge of such problems, their formulation, the resolution methods proposed—through the variants induced specifically by UAVs features—are of interest for practitioners for any UAV application. Hence, in this study, we propose a review of existing literature devoted to such UAV path optimization problems, focusing specifically on the sub-class of problems that consider the mobility on a macroscopic scale. These are related to the two existing general classic ones—the Traveling Salesman Problem and the Vehicle Routing Problem. We analyze the recent literature that adapted the problems to the UAV context, provide an extensive classification and taxonomy of their problems and their formulation and also give a synthetic overview of the resolution techniques, performance metrics and obtained numerical results.
KW  - UAVs
KW  - optimization problems
KW  - TSP
KW  - VRP
DO  - 10.3390/drones3030066
ER  -
TY  - EJOU
AU  - Yang, Qinchen
AU  - Liu, Man
AU  - Zhang, Zhitao
AU  - Yang, Shuqin
AU  - Ning, Jifeng
AU  - Han, Wenting
TI  - Mapping Plastic Mulched Farmland for High Resolution Images of Unmanned Aerial Vehicle Using Deep Semantic Segmentation
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 17
SN  - 2072-4292

AB  - With increasing consumption, plastic mulch benefits agriculture by promoting crop quality and yield, but the environmental and soil pollution is becoming increasingly serious. Therefore, research on the monitoring of plastic mulched farmland (PMF) has received increasing attention. Plastic mulched farmland in unmanned aerial vehicle (UAV) remote images due to the high resolution, shows a prominent spatial pattern, which brings difficulties to the task of monitoring PMF. In this paper, through a comparison between two deep semantic segmentation methods, SegNet and fully convolutional networks (FCN), and a traditional classification method, Support Vector Machine (SVM), we propose an end-to-end deep-learning method aimed at accurately recognizing PMF for UAV remote sensing images from Hetao Irrigation District, Inner Mongolia, China. After experiments with single-band, three-band and six-band image data, we found that deep semantic segmentation models built via single-band data which only use the texture pattern of PMF can identify it well; for example, SegNet reaching the highest accuracy of 88.68% in a 900 nm band. Furthermore, with three visual bands and six-band data (3 visible bands and 3 near-infrared bands), deep semantic segmentation models combining the texture and spectral features further improve the accuracy of PMF identification, whereas six-band data obtains an optimal performance for FCN and SegNet. In addition, deep semantic segmentation methods, FCN and SegNet, due to their strong feature extraction capability and direct pixel classification, clearly outperform the traditional SVM method in precision and speed. Among three classification methods, SegNet model built on three-band and six-band data obtains the optimal average accuracy of 89.62% and 90.6%, respectively. Therefore, the proposed deep semantic segmentation model, when tested against the traditional classification method, provides a promising path for mapping PMF in UAV remote sensing images.
KW  - plastic mulched farmland
KW  - fully convolutional networks
KW  - unmanned aerial vehicle remote sensing image
KW  - deep semantic segmentation
DO  - 10.3390/rs11172008
ER  -
TY  - EJOU
AU  - Ghorbanzadeh, Omid
AU  - Meena, Sansar R.
AU  - Blaschke, Thomas
AU  - Aryal, Jagannath
TI  - UAV-Based Slope Failure Detection Using Deep-Learning Convolutional Neural Networks
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 17
SN  - 2072-4292

AB  - Slope failures occur when parts of a slope collapse abruptly under the influence of gravity, often triggered by a rainfall event or earthquake. The resulting slope failures often cause problems in mountainous or hilly regions, and the detection of slope failure is therefore an important topic for research. Most of the methods currently used for mapping and modelling slope failures rely on classification algorithms or feature extraction, but the spatial complexity of slope failures, the uncertainties inherent in expert knowledge, and problems in transferability, all combine to inhibit slope failure detection. In an attempt to overcome some of these problems we have analyzed the potential of deep learning convolutional neural networks (CNNs) for slope failure detection, in an area along a road section in the northern Himalayas, India. We used optical data from unmanned aerial vehicles (UAVs) over two separate study areas. Different CNN designs were used to produce eight different slope failure distribution maps, which were then compared with manually extracted slope failure polygons using different accuracy assessment metrics such as the precision, F-score, and mean intersection-over-union (mIOU). A slope failure inventory data set was produced for each of the study areas using a frequency-area distribution (FAD). The CNN approach that was found to perform best (precision accuracy assessment of almost 90% precision, F-score 85%, mIOU 74%) was one that used a window size of 64 &times; 64 pixels for the sample patches, and included slope data as an additional input layer. The additional information from the slope data helped to discriminate between slope failure areas and roads, which had similar spectral characteristics in the optical imagery. We concluded that the effectiveness of CNNs for slope failure detection was strongly dependent on their design (i.e., the window size selected for the sample patch, the data used, and the training strategies), but that CNNs are currently only designed by trial and error. While CNNs can be powerful tools, such trial and error strategies make it difficult to explain why a particular pooling or layer numbering works better than any other.
KW  - landslide
KW  - unmanned aerial vehicle (UAV)
KW  - deep learning
KW  - frequency area distribution (FAD)
KW  - mean intersection-over-union (mIOU)
KW  - sample patches selection
DO  - 10.3390/rs11172046
ER  -
TY  - EJOU
AU  - Li, Kexin
AU  - Wang, Jun
AU  - Qi, Dawei
TI  - An Intelligent Warning Method for Diagnosing Underwater Structural Damage
T2  - Algorithms

PY  - 2019
VL  - 12
IS  - 9
SN  - 1999-4893

AB  - A number of intelligent warning techniques have been implemented for detecting underwater infrastructure diagnosis to partially replace human-conducted on-site inspections. However, the extensively varying real-world situation (e.g., the adverse environmental conditions, the limited sample space, and the complex defect types) can lead to challenges to the wide adoption of intelligent warning techniques. To overcome these challenges, this paper proposed an intelligent algorithm combing gray level co-occurrence matrix (GLCM) with self-organization map (SOM) for accurate diagnosis of the underwater structural damage. In order to optimize the generative criterion for GLCM construction, a triangle algorithm was proposed based on orthogonal experiments. The constructed GLCM were utilized to evaluate the texture features of the regions of interest (ROI) of micro-injury images of underwater structures and extracted damage image texture characteristic parameters. The digital feature screening (DFS) method was used to obtain the most relevant features as the input for the SOM network. According to the unique topology information of the SOM network, the classification result, recognition efficiency, parameters, such as the network layer number, hidden layer node, and learning step, were optimized. The robustness and adaptability of the proposed approach were tested on underwater structure images through the DFS method. The results showed that the proposed method revealed quite better performances and can diagnose structure damage in underwater realistic situations.
KW  - structural health monitoring
KW  - digital image processing
KW  - damage
KW  - gray level co-occurrence matrix
KW  - self-organization map
DO  - 10.3390/a12090183
ER  -
TY  - EJOU
AU  - Stodola, Petr
AU  - Drozd, Jan
AU  - Mazal, Jan
AU  - Hodický, Jan
AU  - Procházka, Dalibor
TI  - Cooperative Unmanned Aerial System Reconnaissance in a Complex Urban Environment and Uneven Terrain
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 17
SN  - 1424-8220

AB  - Using unmanned robotic systems in military operations such as reconnaissance or surveillance, as well as in many civil applications, is common practice. In this article, the problem of monitoring the specified area of interest by a fleet of unmanned aerial systems is examined. The monitoring is planned via the Cooperative Aerial Model, which deploys a number of waypoints in the area; these waypoints are visited successively by unmanned systems. The original model proposed in the past assumed that the area to be explored is perfectly flat. A new formulation of this model is introduced in this article so that the model can be used in a complex environment with uneven terrain and/or with many obstacles, which may occlude some parts of the area of interest. The optimization algorithm based on the simulated annealing principles is proposed for positioning of waypoints to cover as large an area as possible. A set of scenarios has been designed to verify and evaluate the proposed approach. The key experiments are aimed at finding the minimum number of waypoints needed to explore at least the minimum requested portion of the area. Furthermore, the results are compared to the algorithm based on the lawnmower pattern.
KW  - cooperative aerial reconnaissance
KW  - unmanned aerial systems
KW  - reconnaissance operation
KW  - simulated annealing
KW  - art gallery problem
KW  - waypoint optimization
KW  - occlusion effect
DO  - 10.3390/s19173754
ER  -
TY  - EJOU
AU  - Moeini Rad, Amir
AU  - Abkar, Ali A.
AU  - Mojaradi, Barat
TI  - Supervised Distance-Based Feature Selection for Hyperspectral Target Detection
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 17
SN  - 2072-4292

AB  - Feature/band selection (FS/BS) for target detection (TD) attempts to select features/bands that increase the discrimination between the target and the image background. Moreover, TD usually suffers from background interference. Therefore, bands that help detectors to effectively suppress the background and magnify the target signal are considered to be more useful. In this regard, three supervised distance-based filter FS methods are proposed in this paper. The first method is based on the TD concept. It uses the image autocorrelation matrix and the target signature in the detection space (DS) for FS. Features that increase the first-norm distance between the target energy and the mean energy of the background in DS are selected as optimal. The other two methods use background modeling via image clustering. The cluster mean spectra, along with the target spectrum, are then transferred into DS. Orthogonal subspace projection distance (OSPD) and first-norm distance (FND) are used as two FS criteria to select optimal features. Two datasets, HyMap RIT and SIM.GA, are used for the experiments. Several measures, i.e., true positives (TPs), false alarms (FAs), target detection accuracy (TDA), total negative score (TNS), and the receiver operating characteristics (ROC) area under the curve (AUC) are employed to evaluate the proposed methods and to investigate the impact of FS on the TD performance. The experimental results show that our proposed FS methods, as compared with five existing FS methods, have improving impacts on common target detectors and help them to yield better results.
KW  - supervised feature selection
KW  - target detection
KW  - background suppression
KW  - hyperspectral data
DO  - 10.3390/rs11172049
ER  -
TY  - EJOU
AU  - Shafi, Uferah
AU  - Mumtaz, Rafia
AU  - García-Nieto, José
AU  - Hassan, Syed A.
AU  - Zaidi, Syed A.
AU  - Iqbal, Naveed
TI  - Precision Agriculture Techniques and Practices: From Considerations to Applications
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 17
SN  - 1424-8220

AB  - Internet of Things (IoT)-based automation of agricultural events can change the agriculture sector from being static and manual to dynamic and smart, leading to enhanced production with reduced human efforts. Precision Agriculture (PA) along with Wireless Sensor Network (WSN) are the main drivers of automation in the agriculture domain. PA uses specific sensors and software to ensure that the crops receive exactly what they need to optimize productivity and sustainability. PA includes retrieving real data about the conditions of soil, crops and weather from the sensors deployed in the fields. High-resolution images of crops are obtained from satellite or air-borne platforms (manned or unmanned), which are further processed to extract information used to provide future decisions. In this paper, a review of near and remote sensor networks in the agriculture domain is presented along with several considerations and challenges. This survey includes wireless communication technologies, sensors, and wireless nodes used to assess the environmental behaviour, the platforms used to obtain spectral images of crops, the common vegetation indices used to analyse spectral images and applications of WSN in agriculture. As a proof of concept, we present a case study showing how WSN-based PA system can be implemented. We propose an IoT-based smart solution for crop health monitoring, which is comprised of two modules. The first module is a wireless sensor network-based system to monitor real-time crop health status. The second module uses a low altitude remote sensing platform to obtain multi-spectral imagery, which is further processed to classify healthy and unhealthy crops. We also highlight the results obtained using a case study and list the challenges and future directions based on our work.
KW  - smart agriculture
KW  - precision agriculture
KW  - vegetation index
KW  - Internet of Things
DO  - 10.3390/s19173796
ER  -
TY  - EJOU
AU  - Kim, Woo-Yong
AU  - Lee, Pyeong-Yeon
AU  - Kim, Jonghoon
AU  - Kim, Kyung-Soo
TI  - A Nonlinear-Model-Based Observer for a State-of-Charge Estimation of a Lithium-Ion Battery in Electric Vehicles
T2  - Energies

PY  - 2019
VL  - 12
IS  - 17
SN  - 1996-1073

AB  - This paper presents a nonlinear-model-based observer for the state of charge estimation of a lithium-ion battery cell that always exhibits a nonlinear relationship between the state of charge and the open-circuit voltage. The proposed nonlinear model for the battery cell and its observer can estimate the state of charge without the linearization technique commonly adopted by previous studies. The proposed method has the following advantages: (1) The observability condition of the proposed nonlinear-model-based observer is derived regardless of the shape of the open circuit voltage curve, and (2) because the terminal voltage is contained in the state vector, the proposed model and its observer are insensitive to sensor noise. A series of experiments using an INR 18650 25R battery cell are performed, and it is shown that the proposed method produces convincing results for the state of charge estimation compared to conventional SOC estimation methods.
KW  - nonlinear battery model
KW  - state of charge estimation
KW  - lithium-ion battery
KW  - Lipschitz nonlinear system
KW  - Luenberger observer
DO  - 10.3390/en12173383
ER  -
TY  - EJOU
AU  - Tan, Liguo
AU  - Wu, Juncheng
AU  - Yang, Xiaoyan
AU  - Song, Senmin
TI  - Research on Optimal Landing Trajectory Planning Method between an UAV and a Moving Vessel
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 18
SN  - 2076-3417

AB  - The location, velocity, and flight path angle of an autonomous unmanned aerial vehicle (UAV) landing on a moving vessel are key factors for an optimal landing trajectory. To tackle this challenge, this paper proposes a method for calculating the optimal approach landing trajectory between an UAV and a small vessel. A numerical approach (iterative method) is used to calculate the optimal approach landing trajectory, and the initial lead is introduced in the calculation process of the UAV trajectory for the inclination and heading angle for accuracy improvement, so that the UAV can track and calculate the optimal landing trajectory with high precision. Compared with the variational method, the proposed method can calculate an optimal turning direction angle for the UAV during the landing. Simulation experiments verify the effectiveness of the proposed algorithm and give optimal initialization values.
KW  - unmanned aerial system (UAS)
KW  - ship
KW  - trajectory planning
KW  - dichotomy search
DO  - 10.3390/app9183708
ER  -
TY  - EJOU
AU  - Bhardwaj, Anshuman
AU  - Sam, Lydia
AU  - Martín-Torres, F. J.
AU  - Zorzano, María-Paz
AU  - Ramírez Luque, Juan A.
TI  - UAV Imaging of a Martian Brine Analogue Environment in a Fluvio-Aeolian Setting
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 18
SN  - 2072-4292

AB  - Understanding extraterrestrial environments and landforms through remote sensing and terrestrial analogy has gained momentum in recent years due to advances in remote sensing platforms, sensors, and computing efficiency. The seasonal brines of the largest salt plateau on Earth in Salar de Uyuni (Bolivian Altiplano) have been inadequately studied for their localized hydrodynamics and the regolith volume transport across the freshwater-brine mixing zones. These brines have recently been projected as a new analogue site for the proposed Martian brines, such as recurring slope lineae (RSL) and slope streaks. The Martian brines have been postulated to be the result of ongoing deliquescence-based salt-hydrology processes on contemporary Mars, similar to the studied Salar de Uyuni brines. As part of a field-site campaign during the cold and dry season in the latter half of August 2017, we deployed an unmanned aerial vehicle (UAV) at two sites of the Salar de Uyuni to perform detailed terrain mapping and geomorphometry. We generated high-resolution (2 cm/pixel) photogrammetric digital elevation models (DEMs) for observing and quantifying short-term terrain changes within the brines and their surroundings. The achieved co-registration for the temporal DEMs was considerably high, from which precise inferences regarding the terrain dynamics were derived. The observed average rate of bottom surface elevation change for brines was ~1.02 mm/day, with localized signs of erosion and deposition. Additionally, we observed short-term changes in the adjacent geomorphology and salt cracks. We conclude that the transferred regolith volume via such brines can be extremely low, well within the resolution limits of the remote sensors that are currently orbiting Mars, thereby making it difficult to resolve the topographic relief and terrain perturbations that are produced by such flows on Mars. Thus, the absence of observable erosion and deposition features within or around most of the proposed Martian RSL and slope streaks cannot be used to dismiss the possibility of fluidized flow within these features.
KW  - unmanned aerial vehicle (UAV)
KW  - photogrammetry
KW  - salt flat
KW  - geomorphometry
KW  - analogue research
DO  - 10.3390/rs11182104
ER  -
TY  - EJOU
AU  - Moon, Jiyoun
AU  - Lee, Beom-Hee
TI  - PDDL Planning with Natural Language-Based Scene Understanding for UAV-UGV Cooperation
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 18
SN  - 2076-3417

AB  - Natural-language-based scene understanding can enable heterogeneous robots to cooperate efficiently in large and unconstructed environments. However, studies on symbolic planning rarely consider the semantic knowledge acquisition problem associated with the surrounding environments. Further, recent developments in deep learning methods show outstanding performance for semantic scene understanding using natural language. In this paper, a cooperation framework that connects deep learning techniques and a symbolic planner for heterogeneous robots is proposed. The framework is largely composed of the scene understanding engine, planning agent, and knowledge engine. We employ neural networks for natural-language-based scene understanding to share environmental information among robots. We then generate a sequence of actions for each robot using a planning domain definition language planner. JENA-TDB is used for knowledge acquisition storage. The proposed method is validated using simulation results obtained from one unmanned aerial and three ground vehicles.
KW  - mission planning
KW  - language descriptions
KW  - semantic graphs
KW  - autonomous robots
KW  - artificial intelligence
DO  - 10.3390/app9183789
ER  -
TY  - EJOU
AU  - Torres-Sospedra, Joaquín
AU  - Nebot, Patricio
TI  - Combining Satellite Images and Cadastral Information for Outdoor Autonomous Mapping and Navigation: A Proof-of-Concept Study in Citric Groves
T2  - Algorithms

PY  - 2019
VL  - 12
IS  - 9
SN  - 1999-4893

AB  - The development of robotic applications for agricultural environments has several problems which are not present in the robotic systems used for indoor environments. Some of these problems can be solved with an efficient navigation system. In this paper, a new system is introduced to improve the navigation tasks for those robots which operate in agricultural environments. Concretely, the paper focuses on the problem related to the autonomous mapping of agricultural parcels (i.e., an orange grove). The map created by the system will be used to help the robots navigate into the parcel to perform maintenance tasks such as weed removal, harvest, or pest inspection. The proposed system connects to a satellite positioning service to obtain the real coordinates where the robotic system is placed. With these coordinates, the parcel information is downloaded from an online map service in order to autonomously obtain a map of the parcel in a readable format for the robot. Finally, path planning is performed by means of Fast Marching techniques using the robot or a team of two robots. This paper introduces the proof-of-concept and describes all the necessary steps and algorithms to obtain the path planning just from the initial coordinates of the robot.
KW  - orange groves
KW  - autonomous mapping
KW  - satellite images
KW  - outdoor navigation
DO  - 10.3390/a12090193
ER  -
TY  - EJOU
AU  - Fan, Shurui
AU  - Li, Zirui
AU  - Xia, Kewen
AU  - Hao, Dongxia
TI  - Quantitative and Qualitative Analysis of Multicomponent Gas Using Sensor Array
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 18
SN  - 1424-8220

AB  - The gas sensor array has long been a major tool for measuring gas due to its high sensitivity, quick response, and low power consumption. This goal, however, faces a difficult challenge because of the cross-sensitivity of the gas sensor. This paper presents a novel gas mixture analysis method for gas sensor array applications. The features extracted from the raw data utilizing principal component analysis (PCA) were used to complete random forest (RF) modeling, which enabled qualitative identification. Support vector regression (SVR), optimized by the particle swarm optimization (PSO) algorithm, was used to select hyperparameters C and &gamma; to establish the optimal regression model for the purpose of quantitative analysis. Utilizing the dataset, we evaluated the effectiveness of our approach. Compared with logistic regression (LR) and support vector machine (SVM), the average recognition rate of PCA combined with RF was the highest (97%). The fitting effect of SVR optimized by PSO for gas concentration was better than that of SVR and solved the problem of hyperparameters selection.
KW  - gas sensor array
KW  - cross-sensitivity
KW  - PCA
KW  - random forest
KW  - particle swarm optimization
DO  - 10.3390/s19183917
ER  -
TY  - EJOU
AU  - Liu, Xiaolei
AU  - Liu, Liansheng
AU  - Wang, Lulu
AU  - Guo, Qing
AU  - Peng, Xiyuan
TI  - Performance Sensing Data Prediction for an Aircraft Auxiliary Power Unit Using the Optimized Extreme Learning Machine
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 18
SN  - 1424-8220

AB  - The aircraft auxiliary power unit (APU) is responsible for environmental control in the cabin and the main engines starting the aircraft. The prediction of its performance sensing data is significant for condition-based maintenance. As a complex system, its performance sensing data have a typically nonlinear feature. In order to monitor this process, a model with strong nonlinear fitting ability needs to be formulated. A neural network has advantages of solving a nonlinear problem. Compared with the traditional back propagation neural network algorithm, an extreme learning machine (ELM) has features of a faster learning speed and better generalization performance. To enhance the training of the neural network with a back propagation algorithm, an ELM is employed to predict the performance sensing data of the APU in this study. However, the randomly generated weights and thresholds of the ELM often may result in unstable prediction results. To address this problem, a restricted Boltzmann machine (RBM) is utilized to optimize the ELM. In this way, a stable performance parameter prediction model of the APU can be obtained and better performance parameter prediction results can be achieved. The proposed method is evaluated by the real APU sensing data of China Southern Airlines Company Limited Shenyang Maintenance Base. Experimental results show that the optimized ELM with an RBM is more stable and can obtain more accurate prediction results.
KW  - auxiliary power unit
KW  - improved neural network
KW  - stable prediction
KW  - performance sensing data prediction
DO  - 10.3390/s19183935
ER  -
TY  - EJOU
AU  - Tan, Yumin
AU  - Li, Yunxin
TI  - UAV Photogrammetry-Based 3D Road Distress Detection
T2  - ISPRS International Journal of Geo-Information

PY  - 2019
VL  - 8
IS  - 9
SN  - 2220-9964

AB  - The timely and proper rehabilitation of damaged roads is essential for road maintenance, and an effective method to detect road surface distress with high efficiency and low cost is urgently needed. Meanwhile, unmanned aerial vehicles (UAVs), with the advantages of high flexibility, low cost, and easy maneuverability, are a new fascinating choice for road condition monitoring. In this paper, road images from UAV oblique photogrammetry are used to reconstruct road three-dimensional (3D) models, from which road pavement distress is automatically detected and the corresponding dimensions are extracted using the developed algorithm. Compared with a field survey, the detection result presents a high precision with an error of around 1 cm in the height dimension for most cases, demonstrating the potential of the proposed method for future engineering practice.
KW  - UAV
KW  - road distress detection
KW  - digital surface model
KW  - point cloud
KW  - region growing algorithm
DO  - 10.3390/ijgi8090409
ER  -
TY  - EJOU
AU  - Han, Seongkyun
AU  - Yoo, Jisang
AU  - Kwon, Soonchul
TI  - Real-Time Vehicle-Detection Method in Bird-View Unmanned-Aerial-Vehicle Imagery
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 18
SN  - 1424-8220

AB  - Vehicle detection is an important research area that provides background information for the diversity of unmanned-aerial-vehicle (UAV) applications. In this paper, we propose a vehicle-detection method using a convolutional-neural-network (CNN)-based object detector. We design our method, DRFBNet300, with a Deeper Receptive Field Block (DRFB) module that enhances the expressiveness of feature maps to detect small objects in the UAV imagery. We also propose the UAV-cars dataset that includes the composition and angular distortion of vehicles in UAV imagery to train our DRFBNet300. Lastly, we propose a Split Image Processing (SIP) method to improve the accuracy of the detection model. Our DRFBNet300 achieves 21 mAP with 45 FPS in the MS COCO metric, which is the highest score compared to other lightweight single-stage methods running in real time. In addition, DRFBNet300, trained on the UAV-cars dataset, obtains the highest AP score at altitudes of 20&ndash;50 m. The gap of accuracy improvement by applying the SIP method became larger when the altitude increases. The DRFBNet300 trained on the UAV-cars dataset with SIP method operates at 33 FPS, enabling real-time vehicle detection.
KW  - vehicle detection
KW  - object detection
KW  - UAV imagery
KW  - convolutional neural network
DO  - 10.3390/s19183958
ER  -
TY  - EJOU
AU  - Bjaoui, Marwen
AU  - Khiari, Brahim
AU  - Benadli, Ridha
AU  - Memni, Mouad
AU  - Sellami, Anis
TI  - Practical Implementation of the Backstepping Sliding Mode Controller MPPT for a PV-Storage Application
T2  - Energies

PY  - 2019
VL  - 12
IS  - 18
SN  - 1996-1073

AB  - This study presents a design and an implementation of a robust Maximum Power Point Tracking (MPPT) for a stand-alone photovoltaic (PV) system with battery storage. A new control scheme is applied for the boost converter based on the combination of the adaptive perturb and observe fuzzy logic controller (P&amp;O-FLC) MPPT technique and the backstepping sliding mode control (BS-SMC) approach. The MPPT controller design was used to accurately track the PV operating point to its maximum power point (MPP) under changing climatic conditions. The presented MPPT based on the P&amp;O-FLC technique generates the reference PV voltage and then a cascade control loop type, based on the BS-SMC approach is used. The aims of this approach are applied to regulate the inductor current and then the PV voltage to its reference values. In order to reduce system costs and complexity, a high gain observer (HGO) was designed, based on the model of the PV system, to estimate online the real value of the boost converter&rsquo;s inductor current. The performance and the robustness of the BS-SMC approach are evaluated using a comparative simulation with a conventional proportional integral (PI) controller implemented in the MATLAB/Simulink environment. The obtained results demonstrate that the proposed approach not only provides a near-perfect tracking performance (dynamic response, overshoot, steady-state error), but also offers greater robustness and stability than the conventional PI controller. Experimental results fitted with dSPACE software reveal that the PV module could reach the MPP and achieve the performance and robustness of the designed BS-SMC MPPT controller.
KW  - photovoltaic system
KW  - maximum power point tracking
KW  - backstepping sliding mode control
KW  - high gain observer
KW  - stability analysis
DO  - 10.3390/en12183539
ER  -
TY  - EJOU
AU  - Wang, Jie
AU  - Simeonova, Sandra
AU  - Shahbazi, Mozhdeh
TI  - Orientation- and Scale-Invariant Multi-Vehicle Detection and Tracking from Unmanned Aerial Videos
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 18
SN  - 2072-4292

AB  - Along with the advancement of light-weight sensing and processing technologies, unmanned aerial vehicles (UAVs) have recently become popular platforms for intelligent traffic monitoring and control. UAV-mounted cameras can capture traffic-flow videos from various perspectives providing a comprehensive insight into road conditions. To analyze the traffic flow from remotely captured videos, a reliable and accurate vehicle detection-and-tracking approach is required. In this paper, we propose a deep-learning framework for vehicle detection and tracking from UAV videos for monitoring traffic flow in complex road structures. This approach is designed to be invariant to significant orientation and scale variations in the videos. The detection procedure is performed by fine-tuning a state-of-the-art object detector, You Only Look Once (YOLOv3), using several custom-labeled traffic datasets. Vehicle tracking is conducted following a tracking-by-detection paradigm, where deep appearance features are used for vehicle re-identification, and Kalman filtering is used for motion estimation. The proposed methodology is tested on a variety of real videos collected by UAVs under various conditions, e.g., in late afternoons with long vehicle shadows, in dawn with vehicles lights being on, over roundabouts and interchange roads where vehicle directions change considerably, and from various viewpoints where vehicles&rsquo; appearance undergo substantial perspective distortions. The proposed tracking-by-detection approach performs efficiently at 11 frames per second on color videos of 2720p resolution. Experiments demonstrated that high detection accuracy could be achieved with an average F1-score of 92.1%. Besides, the tracking technique performs accurately, with an average multiple-object tracking accuracy (MOTA) of 81.3%. The proposed approach also addressed the shortcomings of the state-of-the-art in multi-object tracking regarding frequent identity switching, resulting in a total of only one identity switch over every 305 tracked vehicles.
KW  - traffic monitoring
KW  - vehicle detection
KW  - multi-vehicle tracking
KW  - vehicle re-identification
KW  - unmanned aerial vehicles
KW  - deep convolutional neural network.
DO  - 10.3390/rs11182155
ER  -
TY  - EJOU
AU  - Salameh, Edward
AU  - Frappart, Frédéric
AU  - Almar, Rafael
AU  - Baptista, Paulo
AU  - Heygster, Georg
AU  - Lubac, Bertrand
AU  - Raucoules, Daniel
AU  - Almeida, Luis P.
AU  - Bergsma, Erwin W. J.
AU  - Capo, Sylvain
AU  - De Michele, Marcello
AU  - Idier, Deborah
AU  - Li, Zhen
AU  - Marieu, Vincent
AU  - Poupardin, Adrien
AU  - Silva, Paulo A.
AU  - Turki, Imen
AU  - Laignel, Benoit
TI  - Monitoring Beach Topography and Nearshore Bathymetry Using Spaceborne Remote Sensing: A Review
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 19
SN  - 2072-4292

AB  - With high anthropogenic pressure and the effects of climate change (e.g., sea level rise) on coastal regions, there is a greater need for accurate and up-to-date information about the topography of these systems. Reliable topography and bathymetry information are fundamental parameters for modelling the morpho-hydrodynamics of coastal areas, for flood forecasting, and for coastal management. Traditional methods such as ground, ship-borne, and airborne surveys suffer from limited spatial coverage and temporal sampling due to logistical constraints and high costs which limit their ability to provide the needed information. The recent advancements of spaceborne remote sensing techniques, along with their ability to acquire data over large spatial areas and to provide high frequency temporal monitoring, has made them very attractive for topography and bathymetry mapping. In this review, we present an overview of the current state of spaceborne-based remote sensing techniques used to estimate the topography and bathymetry of beaches, intertidal, and nearshore areas. We also provide some insights about the potential of these techniques when using data provided by new and future satellite missions.
KW  - spaceborne remote sensing
KW  - satellite
KW  - beaches
KW  - intertidal
KW  - nearshore
KW  - shallow waters
KW  - topography
KW  - bathymetry
KW  - digital elevation model (DEM)
DO  - 10.3390/rs11192212
ER  -
TY  - EJOU
AU  - Bai, Guoxing
AU  - Meng, Yu
AU  - Liu, Li
AU  - Luo, Weidong
AU  - Gu, Qing
AU  - Liu, Li
TI  - Review and Comparison of Path Tracking Based on Model Predictive Control
T2  - Electronics

PY  - 2019
VL  - 8
IS  - 10
SN  - 2079-9292

AB  - Recently, model predictive control (MPC) is increasingly applied to path tracking of mobile devices, such as mobile robots. The characteristics of these MPC-based controllers are not identical due to the different approaches taken during design. According to the differences in the prediction models, we believe that the existing MPC-based path tracking controllers can be divided into four categories. We named them linear model predictive control (LMPC), linear error model predictive control (LEMPC), nonlinear model predictive control (NMPC), and nonlinear error model predictive control (NEMPC). Subsequently, we built these four controllers for the same mobile robot and compared them. By comparison, we got some conclusions. The real-time performance of LMPC and LEMPC is good, but they are less robust to reference paths and positioning errors. NMPC performs well when the reference velocity is high and the radius of the reference path is small. It is also robust to positioning errors. However, the real-time performance of NMPC is slightly worse. NEMPC has many disadvantages. Like LMPC and LEMPC, it performs poorly when the reference velocity is high and the radius of the reference path is small. Its real-time performance is also not good enough.
KW  - path tracking
KW  - model predictive control
KW  - review
KW  - comparison
DO  - 10.3390/electronics8101077
ER  -
TY  - EJOU
AU  - Phuc, Le T.
AU  - Jeon, HyeJun
AU  - Truong, Nguyen T.
AU  - Hak, Jung J.
TI  - Applying the Haar-cascade Algorithm for Detecting Safety Equipment in Safety Management Systems for Multiple Working Environments
T2  - Electronics

PY  - 2019
VL  - 8
IS  - 10
SN  - 2079-9292

AB  - There are many ways to maintain the safety of workers on a working site, such as using a human supervisor, computer supervisor, and smoke&ndash;flame detecting system. In order to create a safety warning system for the working site, the machine-learning algorithm&mdash;Haar-cascade classifier&mdash;was used to build four different classes for safety equipment recognition. Then a proposed algorithm was applied to calculate a score to determine the dangerousness of the current working environment based on the safety equipment and working environment. With this data, the system decides whether it is necessary to give a warning signal. For checking the efficiency of this project, three different situations were installed with this system. Generally, with the promising outcome, this application can be used in maintaining, supervising, and controlling the safety of a worker.
KW  - Haar–cascade algorithm
KW  - safety equipment
KW  - safety management system
DO  - 10.3390/electronics8101079
ER  -
TY  - EJOU
AU  - Li, Yuxia
AU  - Peng, Bo
AU  - He, Lei
AU  - Fan, Kunlong
AU  - Li, Zhenxu
AU  - Tong, Ling
TI  - Road Extraction from Unmanned Aerial Vehicle Remote Sensing Images Based on Improved Neural Networks
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 19
SN  - 1424-8220

AB  - Roads are vital components of infrastructure, the extraction of which has become a topic of significant interest in the field of remote sensing. Because deep learning has been a popular method in image processing and information extraction, researchers have paid more attention to extracting road using neural networks. This article proposes the improvement of neural networks to extract roads from Unmanned Aerial Vehicle (UAV) remote sensing images. D-Linknet was first considered for its high performance; however, the huge scale of the net reduced computational efficiency. With a focus on the low computational efficiency problem of the popular D-LinkNet, this article made some improvements: (1) Replace the initial block with a stem block. (2) Rebuild the entire network based on ResNet units with a new structure, allowing for the construction of an improved neural network D-Linknetplus. (3) Add a 1 &times; 1 convolution layer before DBlock to reduce the input feature maps, reducing parameters and improving computational efficiency. Add another 1 &times; 1 convolution layer after DBlock to recover the required number of output channels. Accordingly, another improved neural network B-D-LinknetPlus was built. Comparisons were performed between the neural nets, and the verification were made with the Massachusetts Roads Dataset. The results show improved neural networks are helpful in reducing the network size and developing the precision needed for road extraction.
KW  - road
KW  - UAV sensors
KW  - image processing
KW  - convolutional neural net
DO  - 10.3390/s19194115
ER  -
TY  - EJOU
AU  - Nguyen, Ngoc P.
AU  - Hong, Sung K.
TI  - Active Fault-Tolerant Control of a Quadcopter against Time-Varying Actuator Faults and Saturations Using Sliding Mode Backstepping Approach
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 19
SN  - 2076-3417

AB  - Fault-tolerant control is becoming an interesting topic because of its reliability and safety. This paper reports an active fault-tolerant control method for a quadcopter unmanned aerial vehicle (UAV) to handle actuator faults, disturbances, and input constraints. A robust fault diagnosis based on the      H &infin;      scheme was designed to estimate the magnitude of a time-varying fault in the presence of disturbances with unknown upper bounds. Once the fault estimation was complete, a fault-tolerant control scheme was proposed for the attitude system, using adaptive sliding mode backstepping control to accommodate the actuator faults, despite actuator saturation limitation and disturbances. The Lyapunov theory was applied to prove the robustness and stability of the closed-loop system under faulty operation. Simulation results show the effectiveness of the fault diagnosis scheme and proposed controller for handling actuator faults.
KW  - backstepping control
KW  - fault-tolerant control
KW  - fault diagnosis
KW  - quadcopter UAVs
DO  - 10.3390/app9194010
ER  -
TY  - EJOU
AU  - Jiao, Leilei
AU  - Sun, Weiwei
AU  - Yang, Gang
AU  - Ren, Guangbo
AU  - Liu, Yinnian
TI  - A Hierarchical Classification Framework of Satellite Multispectral/Hyperspectral Images for Mapping Coastal Wetlands
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 19
SN  - 2072-4292

AB  - Mapping different land cover types with satellite remote sensing data is significant for restoring and protecting natural resources and ecological services in coastal wetlands. In this paper, we propose a hierarchical classification framework (HCF) that implements two levels of classification scheme to identify different land cover types of coastal wetlands. The first level utilizes the designed decision tree to roughly group land covers into four rough classes and the second level combines multiple features (i.e., spectral feature, texture feature and geometric feature) of each class to distinguish different subtypes of land covers in each rough class. Two groups of classification experiments on Landsat and Sentinel multispectral data and China Gaofen (GF)-5 hyperspectral data are carried out in order to testify the classification behaviors of two famous coastal wetlands of China, that is, Yellow River Estuary and Yancheng coastal wetland. Experimental results on Landsat data show that the proposed HCF performs better than support vector machine and random forest in classifying land covers of coastal wetlands. Moreover, HCF is suitable for both multispectral data and hyperspectral data and the GF-5 data is superior to Landsat-8 and Sentinel-2 multispectral data in obtaining fine classification results of coastal wetlands.
KW  - hierarchical classification framework
KW  - coastal wetlands
KW  - Landsat images
KW  - hyperspectral imagery
KW  - Sentinel-2
KW  - GF-5
DO  - 10.3390/rs11192238
ER  -
TY  - EJOU
AU  - Zhang, Lingling
AU  - Tang, Chengkai
AU  - Zhang, Yi
AU  - Song, Houbing
TI  - Inertial-Navigation-Aided Single-Satellite Highly Dynamic Positioning Algorithm
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 19
SN  - 1424-8220

AB  - Nowadays, research on global navigation satellite systems (GNSS) has reached a certain level of maturity to provide high-precision positioning services in many applications. Nonetheless, there are challenging GNSS-denial environments where a temporarily deployed single-satellite positioning system is a promising choice. To further meet the emergency call of highly dynamic targets in such situations, an augmented single-satellite positioning algorithm is proposed in this paper. First, the initial location of the highly dynamic target is found by real-time displacement feedback from the inertial navigation system (INS). Then, considering the continuity of position change, and taking advantage of the high accuracy and robustness of the unscented Kalman filter (UKF), target location is through iteration and fusion. Comparing this proposed method with the least-squares Newton-iterative Doppler single-satellite positioning system and the pseudorange rate-assisted method under synthetic error conditions, the positioning error of our algorithm was     10 %     less than the other two algorithms. This verified the validation of our algorithm in the single-satellite system with highly dynamic targets.
KW  - single-satellite system
KW  - highly dynamic positioning
KW  - inertial navigation system (INS)
KW  - unscented Kalman Filter (UKF)
KW  - pseudorange difference
DO  - 10.3390/s19194196
ER  -
TY  - EJOU
AU  - Hassler, Samuel C.
AU  - Baysal-Gurel, Fulya
TI  - Unmanned Aircraft System (UAS) Technology and Applications in Agriculture
T2  - Agronomy

PY  - 2019
VL  - 9
IS  - 10
SN  - 2073-4395

AB  - Numerous sensors have been developed over time for precision agriculture; though, only recently have these sensors been incorporated into the new realm of unmanned aircraft systems (UAS). This UAS technology has allowed for a more integrated and optimized approach to various farming tasks such as field mapping, plant stress detection, biomass estimation, weed management, inventory counting, and chemical spraying, among others. These systems can be highly specialized depending on the particular goals of the researcher or farmer, yet many aspects of UAS are similar. All systems require an underlying platform&mdash;or unmanned aerial vehicle (UAV)&mdash;and one or more peripherals and sensing equipment such as imaging devices (RGB, multispectral, hyperspectral, near infra-red, RGB depth), gripping tools, or spraying equipment. Along with these wide-ranging peripherals and sensing equipment comes a great deal of data processing. Common tools to aid in this processing include vegetation indices, point clouds, machine learning models, and statistical methods. With any emerging technology, there are also a few considerations that need to be analyzed like legal constraints, economic trade-offs, and ease of use. This review then concludes with a discussion on the pros and cons of this technology, along with a brief outlook into future areas of research regarding UAS technology in agriculture.
KW  - unmanned aircraft system (UAS)
KW  - unmanned aerial vehicle (UAV)
KW  - precision agriculture
KW  - remote sensing
KW  - aerial imaging
DO  - 10.3390/agronomy9100618
ER  -
TY  - EJOU
AU  - Zhang, Jianyong
AU  - Zhao, Yanling
AU  - Abbott, A. L.
AU  - Wynne, Randolph H.
AU  - Hu, Zhenqi
AU  - Zou, Yuzhu
AU  - Tian, Shuaishuai
TI  - Automated Mapping of Typical Cropland Strips in the North China Plain Using Small Unmanned Aircraft Systems (sUAS) Photogrammetry
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 20
SN  - 2072-4292

AB  - Accurate mapping of agricultural fields is needed for many purposes, including irrigation decisions and cadastral management. This paper is concerned with the automated mapping of cropland strips that are common in the North China Plain. These strips are commonly 3&ndash;8 m in width and 50&ndash;300 m in length, and are separated by small ridges that assist with irrigation. Conventional surveying methods are labor-intensive and time-consuming for this application, and only limited performance is possible with very high resolution satellite images. Small Unmanned Aircraft System (sUAS) images could provide an alternative approach to ridge detection and strip mapping. This paper presents a novel method for detecting cropland strips, utilizing centimeter spatial resolution imagery captured by sUAS flying at low altitude (60 m). Using digital surface models (DSM) and ortho-rectified imagery from sUAS data, this method extracts candidate ridge locations by surface roughness segmentation in combination with geometric constraints. This method then exploits vegetation removal and morphological operations to refine candidate ridge elements, leading to polyline-based representations of cropland strip boundaries. This procedure has been tested using sUAS data from four typical cropland plots located approximately 60 km west of Jinan, China. The plots contained early winter wheat. The results indicated an ability to detect ridges with comparatively high recall and precision (96.8% and 95.4%, respectively). Cropland strips were extracted with over 98.9% agreement relative to ground truth, with kappa coefficients over 97.4%. To our knowledge, this method is the first to attempt cropland strip mapping using centimeter spatial resolution sUAS images. These results have demonstrated that sUAS mapping is a viable approach for data collection to assist in agricultural land management in the North China Plain.
KW  - automated extraction
KW  - ridge detection
KW  - strip mapping
KW  - small unmanned aircraft systems (sUAS)
KW  - surface roughness
KW  - North China Plain
DO  - 10.3390/rs11202343
ER  -
TY  - EJOU
AU  - Zhang, Dongyan
AU  - Wang, Daoyong
AU  - Gu, Chunyan
AU  - Jin, Ning
AU  - Zhao, Haitao
AU  - Chen, Gao
AU  - Liang, Hongyi
AU  - Liang, Dong
TI  - Using Neural Network to Identify the Severity of Wheat Fusarium Head Blight in the Field Environment
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 20
SN  - 2072-4292

AB  - Fusarium head blight (FHB), one of the most important diseases of wheat, mainly occurs in the ear. Given that the severity of the disease cannot be accurately identified, the cost of pesticide application increases every year, and the agricultural ecological environment is also polluted. In this study, a neural network (NN) method was proposed based on the red-green-blue (RGB) image to segment wheat ear and disease spot in the field environment, and then to determine the disease grade. Firstly, a segmentation dataset of single wheat ear was constructed to provide a benchmark for the segmentation of the wheat ear. Secondly, a segmentation model of single wheat ear based on the fully convolutional network (FCN) was established to effectively realize the segmentation of the wheat ear in the field environment. An FHB segmentation algorithm was proposed based on a pulse-coupled neural network (PCNN) with K-means clustering of the improved artificial bee colony (IABC) to segment the diseased spot of wheat ear by automatic optimization of PCNN parameters. Finally, the disease grade was calculated using the ratio of the disease spot to the whole wheat ear. The experimental results show that: (1) the accuracy of the segmentation model for single wheat ear constructed in this study is 0.981. The segmentation time is less than 1 s, indicating that the model can quickly and accurately segment wheat ear in the field environment; (2) the segmentation method of the disease spot performed under each evaluation indicator is improved compared with the traditional segmentation methods, and the accuracy is 0.925 in the disease severity identification. These research results can provide important reference value for grading wheat FHB in the field environment, which also can be beneficial for real-time monitoring of other crops&rsquo; diseases under near-Earth remote sensing.
KW  - Fusarium head blight
KW  - fully convolutional network
KW  - pulse coupled neural network
KW  - artificial bee colony
KW  - disease grading
DO  - 10.3390/rs11202375
ER  -
TY  - EJOU
AU  - Kang, Junfeng
AU  - Fang, Lei
AU  - Li, Shuang
AU  - Wang, Xiangrong
TI  - Parallel Cellular Automata Markov Model for Land Use Change Prediction over MapReduce Framework
T2  - ISPRS International Journal of Geo-Information

PY  - 2019
VL  - 8
IS  - 10
SN  - 2220-9964

AB  - The Cellular Automata Markov model combines the cellular automata (CA) model&rsquo;s ability to simulate the spatial variation of complex systems and the long-term prediction of the Markov model. In this research, we designed a parallel CA-Markov model based on the MapReduce framework. The model was divided into two main parts: A parallel Markov model based on MapReduce (Cloud-Markov), and comprehensive evaluation method of land-use changes based on cellular automata and MapReduce (Cloud-CELUC). Choosing Hangzhou as the study area and using Landsat remote-sensing images from 2006 and 2013 as the experiment data, we conducted three experiments to evaluate the parallel CA-Markov model on the Hadoop environment. Efficiency evaluations were conducted to compare Cloud-Markov and Cloud-CELUC with different numbers of data. The results showed that the accelerated ratios of Cloud-Markov and Cloud-CELUC were 3.43 and 1.86, respectively, compared with their serial algorithms. The validity test of the prediction algorithm was performed using the parallel CA-Markov model to simulate land-use changes in Hangzhou in 2013 and to analyze the relationship between the simulation results and the interpretation results of the remote-sensing images. The Kappa coefficients of construction land, natural-reserve land, and agricultural land were 0.86, 0.68, and 0.66, respectively, which demonstrates the validity of the parallel model. Hangzhou land-use changes in 2020 were predicted and analyzed. The results show that the central area of construction land is rapidly increasing due to a developed transportation system and is mainly transferred from agricultural land.
KW  - CA Markov
KW  - land-use change prediction
KW  - Hadoop
KW  - MapReduce
KW  - cloud computing
DO  - 10.3390/ijgi8100454
ER  -
TY  - EJOU
AU  - Xia, Lang
AU  - Zhang, Ruirui
AU  - Chen, Liping
AU  - Huang, Yanbo
AU  - Xu, Gang
AU  - Wen, Yao
AU  - Yi, Tongchuan
TI  - Monitor Cotton Budding Using SVM and UAV Images
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 20
SN  - 2076-3417

AB  - Monitoring the cotton budding rate is important for growers so that they can replant cotton in a timely fashion at locations at which cotton density is sparse. In this study, a true-color camera was mounted on an unmanned aerial vehicle (UAV) and used to collect images of young cotton plants to estimate the germination of cotton plants. The collected images were preprocessed by stitching them together to obtain the single orthomosaic image. The support-vector machine method and maximum likelihood classification method were conducted to identify the cotton plants in the image. The accuracy evaluation indicated the overall accuracy of the classification for SVM is 96.65% with the Kappa coefficient of 93.99%, while for maximum likelihood classification, the accuracy is 87.85% with a Kappa coefficient of 80.67%. A method based on the morphological characteristics of cotton plants was proposed to identify and count the overlapping cotton plants in this study. The analysis showed that the method can improve the detection accuracy by 6.3% when compared to without it. The validation based on visual interpretation indicated that the method presented an accuracy of 91.13%. The study showed that the minimal resolution of no less than 1.2 cm/pixel in practice for image collection is necessary in order to recognize cotton plants accurately.
KW  - SVM
KW  - budding rate
KW  - UAV
DO  - 10.3390/app9204312
ER  -
TY  - EJOU
AU  - García Rubio, Víctor
AU  - Rodrigo Ferrán, Juan A.
AU  - Menéndez García, Jose M.
AU  - Sánchez Almodóvar, Nuria
AU  - Lalueza Mayordomo, José M.
AU  - Álvarez, Federico
TI  - Automatic Change Detection System over Unmanned Aerial Vehicle Video Sequences Based on Convolutional Neural Networks
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 20
SN  - 1424-8220

AB  - In recent years, the use of unmanned aerial vehicles (UAVs) for surveillance tasks has increased considerably. This technology provides a versatile and innovative approach to the field. However, the automation of tasks such as object recognition or change detection usually requires image processing techniques. In this paper we present a system for change detection in video sequences acquired by moving cameras. It is based on the combination of image alignment techniques with a deep learning model based on convolutional neural networks (CNNs). This approach covers two important topics. Firstly, the capability of our system to be adaptable to variations in the UAV flight. In particular, the difference of height between flights, and a slight modification of the camera&rsquo;s position or movement of the UAV because of natural conditions such as the effect of wind. These modifications can be produced by multiple factors, such as weather conditions, security requirements or human errors. Secondly, the precision of our model to detect changes in diverse environments, which has been compared with state-of-the-art methods in change detection. This has been measured using the Change Detection 2014 dataset, which provides a selection of labelled images from different scenarios for training change detection algorithms. We have used images from dynamic background, intermittent object motion and bad weather sections. These sections have been selected to test our algorithm&rsquo;s robustness to changes in the background, as in real flight conditions. Our system provides a precise solution for these scenarios, as the mean F-measure score from the image analysis surpasses 97%, and a significant precision in the intermittent object motion category, where the score is above 99%.
KW  - change detection
KW  - convolutional neural networks
KW  - moving camera
KW  - image alignment
KW  - UAV
DO  - 10.3390/s19204484
ER  -
TY  - EJOU
AU  - Woodget, Amy S.
AU  - Dietrich, James T.
AU  - Wilson, Robin T.
TI  - Quantifying Below-Water Fluvial Geomorphic Change: The Implications of Refraction Correction, Water Surface Elevations, and Spatially Variable Error
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 20
SN  - 2072-4292

AB  - Much of the geomorphic work of rivers occurs underwater. As a result, high resolutionquantification of geomorphic change in these submerged areas is important. Currently, to quantify thischange, multiple methods are required to get high resolution data for both the exposed and submergedareas. Remote sensing methods are often limited to the exposed areas due to the challenges imposedby the water, and those remote sensing methods for below the water surface require the collection ofextensive calibration data in-channel, which is time-consuming, labour-intensive, and sometimesprohibitive in dicult-to-access areas. Within this paper, we pioneer a novel approach for quantifyingabove- and below-water geomorphic change using Structure-from-Motion photogrammetry andinvestigate the implications of water surface elevations, refraction correction measures, and thespatial variability of topographic errors. We use two epochs of imagery from a site on the River Teme,Herefordshire, UK, collected using a remotely piloted aircraft system (RPAS) and processed usingStructure-from-Motion (SfM) photogrammetry. For the first time, we show that: (1) Quantification ofsubmerged geomorphic change to levels of accuracy commensurate with exposed areas is possiblewithout the need for calibration data or a dierent method from exposed areas; (2) there is minimaldierence in results produced by dierent refraction correction procedures using predominantlynadir imagery (small angle vs. multi-view), allowing users a choice of software packages/processingcomplexity; (3) improvements to our estimations of water surface elevations are critical for accuratetopographic estimation in submerged areas and can reduce mean elevation error by up to 73%;and (4) we can use machine learning, in the form of multiple linear regressions, and a Gaussian Na&iuml;veBayes classifier, based on the relationship between error and 11 independent variables, to generate ahigh resolution, spatially continuous model of geomorphic change in submerged areas, constrained byspatially variable error estimates. Our multiple regression model is capable of explaining up to 54%of magnitude and direction of topographic error, with accuracies of less than 0.04 m. With on-goingtesting and improvements, this machine learning approach has potential for routine application inspatially variable error estimation within the RPAS&ndash;SfM workflow.
KW  - fluvial
KW  - geomorphology
KW  - change detection
KW  - remotely piloted aircraft system
KW  - refraction correction
KW  - structure-from-motion photogrammetry
KW  - water surface elevation
KW  - topographic error
KW  - machine learning
DO  - 10.3390/rs11202415
ER  -
TY  - EJOU
AU  - Ghaffarian, Saman
AU  - Kerle, Norman
AU  - Pasolli, Edoardo
AU  - Jokar Arsanjani, Jamal
TI  - Post-Disaster Building Database Updating Using Automated Deep Learning: An Integration of Pre-Disaster OpenStreetMap and Multi-Temporal Satellite Data
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 20
SN  - 2072-4292

AB  - First responders and recovery planners need accurate and quickly derived information about the status of buildings as well as newly built ones to both help victims and to make decisions for reconstruction processes after a disaster. Deep learning and, in particular, convolutional neural network (CNN)-based approaches have recently become state-of-the-art methods to extract information from remote sensing images, in particular for image-based structural damage assessment. However, they are predominantly based on manually extracted training samples. In the present study, we use pre-disaster OpenStreetMap building data to automatically generate training samples to train the proposed deep learning approach after the co-registration of the map and the satellite images. The proposed deep learning framework is based on the U-net design with residual connections, which has been shown to be an effective method to increase the efficiency of CNN-based models. The ResUnet is followed by a Conditional Random Field (CRF) implementation to further refine the results. Experimental analysis was carried out on selected very high resolution (VHR) satellite images representing various scenarios after the 2013 Super Typhoon Haiyan in both the damage and the recovery phases in Tacloban, the Philippines. The results show the robustness of the proposed ResUnet-CRF framework in updating the building map after a disaster for both damage and recovery situations by producing an overall F1-score of 84.2%.
KW  - post-disaster
KW  - building database update
KW  - damage assessment
KW  - recovery assessment
KW  - OpenStreetMap
KW  - deep learning
KW  - convolutional neural network
KW  - multi-temporal satellite imagery
KW  - U-Net
KW  - Super Typhoon Haiyan
DO  - 10.3390/rs11202427
ER  -
TY  - EJOU
AU  - He, Zhi
AU  - He, Dan
AU  - Mei, Xiangqin
AU  - Hu, Saihan
TI  - Wetland Classification Based on a New Efficient Generative Adversarial Network and Jilin-1 Satellite Image
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 20
SN  - 2072-4292

AB  - Recent studies have shown that deep learning methods provide useful tools for wetland classification. However, it is difficult to perform species-level classification with limited labeled samples. In this paper, we propose a semi-supervised method for wetland species classification by using a new efficient generative adversarial network (GAN) and Jilin-1 satellite image. The main contributions of this paper are twofold. First, the proposed method, namely ShuffleGAN, requires only a small number of labeled samples. ShuffleGAN is composed of two neural networks (i.e., generator and discriminator), which perform an adversarial game in the training phase and ShuffleNet units are added in both generator and discriminator to obtain speed-accuracy tradeoff. Second, ShuffleGAN can perform species-level wetland classification. In addition to distinguishing the wetland areas from non-wetlands, different tree species located in the wetland are also identified, thus providing a more detailed distribution of the wetland land-covers. Experiments are conducted on the Haizhu Lake wetland data acquired by the Jilin-1 satellite. Compared with existing GAN, the improvement in overall accuracy (OA) of the proposed ShuffleGAN is more than 2%. This work can not only deepen the application of deep learning in wetland classification but also promote the study of fine classification of wetland land-covers.
KW  - wetland
KW  - classification
KW  - remote sensing
KW  - deep learning
KW  - generative adversarial networks
DO  - 10.3390/rs11202455
ER  -
TY  - EJOU
AU  - Zhu, Wanxue
AU  - Sun, Zhigang
AU  - Huang, Yaohuan
AU  - Lai, Jianbin
AU  - Li, Jing
AU  - Zhang, Junqiang
AU  - Yang, Bin
AU  - Li, Binbin
AU  - Li, Shiji
AU  - Zhu, Kangying
AU  - Li, Yang
AU  - Liao, Xiaohan
TI  - Improving Field-Scale Wheat LAI Retrieval Based on UAV Remote-Sensing Observations and Optimized VI-LUTs
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 20
SN  - 2072-4292

AB  - Leaf area index (LAI) is a key biophysical parameter for monitoring crop growth status, predicting crop yield, and quantifying crop variability in agronomic applications. Mapping the LAI at the field scale using multispectral cameras onboard unmanned aerial vehicles (UAVs) is a promising precision-agriculture application with specific requirements: The LAI retrieval method should be (1) robust so that crop LAI can be estimated with similar accuracy and (2) easy to use so that it can be applied to the adjustment of field management practices. In this study, three UAV remote-sensing missions (UAVs with Micasense RedEdge-M and Cubert S185 cameras) were carried out over six experimental plots from 2018 to 2019 to investigate the performance of reflectance-based lookup tables (LUTs) and vegetation index (VI)-based LUTs generated from the PROSAIL model for wheat LAI retrieval. The effects of the central wavelengths and bandwidths for the VI calculations on the LAI retrieval were further examined. We found that the VI-LUT strategy was more robust and accurate than the reflectance-LUT strategy. The differences in the LAI retrieval accuracy among the four VI-LUTs were small, although the improved modified chlorophyll absorption ratio index-lookup table (MCARI2-LUT) and normalized difference vegetation index-lookup table (NDVI-LUT) performed slightly better. We also found that both of the central wavelengths and bandwidths of the VIs had effects on the LAI retrieval. The VI-LUTs with optimized central wavelengths (red = 612 nm, near-infrared (NIR) = 756 nm) and narrow bandwidths (~4 nm) improved the wheat LAI retrieval accuracy (R2 &ge; 0.75). The results of this study provide an alternative method for retrieving crop LAI, which is robust and easy use for precision-agriculture applications and may be helpful for designing UAV multispectral cameras for agricultural monitoring.
KW  - leaf area index
KW  - unmanned aerial vehicle
KW  - vegetation indices
KW  - multispectral camera
KW  - hyperspectral camera
KW  - precision agriculture
DO  - 10.3390/rs11202456
ER  -
TY  - EJOU
AU  - Bohnenkamp, David
AU  - Behmann, Jan
AU  - Mahlein, Anne-Katrin
TI  - In-Field Detection of Yellow Rust in Wheat on the Ground Canopy and UAV Scale
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 21
SN  - 2072-4292

AB  - The application of hyperspectral imaging technology for plant disease detection in the field is still challenging. Existing equipment and analysis algorithms are adapted to highly controlled environmental conditions in the laboratory. However, only real time information from the field scale is able to guide plant protection measures and to optimize the use of resources. At the field scale, many parameters such as the optimal measurement distance, informative feature sets, and suitable algorithms have not been investigated. In this study, the hyperspectral detection and quantification of yellow rust in wheat was evaluated using two measurement platforms: a ground-based vehicle and an unmanned aerial vehicle (UAV). Different disease development stages and disease severities were provided in a plot-based field experiment. Measurements were performed weekly during the vegetation period. Data analysis was performed by three prediction algorithms with a focus on the selection of optimal feature sets. In this context, the across-scale application of optimized feature sets, an approach of information transfer between scales, was also evaluated. Relevant aspects for an on-line disease assessment in the field integrating affordable sensor technology, sensor spatial resolution, compact analysis models, and fast evaluation have been outlined and reflected upon. For the first time, a hyperspectral imaging observation experiment of a plant disease was comparatively performed at two scales, ground canopy and UAV.
KW  - feature selection
KW  - spectral angle mapper
KW  - support vector machine
KW  - support vector regression
KW  - hyperspectral imaging
KW  - UAV
KW  - cross-scale
KW  - yellow rust
KW  - spatial resolution
KW  - winter wheat
DO  - 10.3390/rs11212495
ER  -
TY  - EJOU
AU  - Xin, Jiang
AU  - Zhang, Xinchang
AU  - Zhang, Zhiqiang
AU  - Fang, Wu
TI  - Road Extraction of High-Resolution Remote Sensing Images Derived from DenseUNet
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 21
SN  - 2072-4292

AB  - Road network extraction is one of the significant assignments for disaster emergency response, intelligent transportation systems, and real-time updating road network. Road extraction base on high-resolution remote sensing images has become a hot topic. Presently, most of the researches are based on traditional machine learning algorithms, which are complex and computational because of impervious surfaces such as roads and buildings that are discernible in the images. Given the above problems, we propose a new method to extract the road network from remote sensing images using a DenseUNet model with few parameters and robust characteristics. DenseUNet consists of dense connection units and skips connections, which strengthens the fusion of different scales by connections at various network layers. The performance of the advanced method is validated on two datasets of high-resolution images by comparison with three classical semantic segmentation methods. The experimental results show that the method can be used for road extraction in complex scenes.
KW  - high-resolution remote sensing imagery
KW  - multi-scale
KW  - road extraction
KW  - machine learning
KW  - DenseUNet
DO  - 10.3390/rs11212499
ER  -
TY  - EJOU
AU  - Crommelinck, Sophie
AU  - Koeva, Mila
AU  - Yang, Michael Y.
AU  - Vosselman, George
TI  - Application of Deep Learning for Delineation of Visible Cadastral Boundaries from Remote Sensing Imagery
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 21
SN  - 2072-4292

AB  - Cadastral boundaries are often demarcated by objects that are visible in remote sensing imagery. Indirect surveying relies on the delineation of visible parcel boundaries from such images. Despite advances in automated detection and localization of objects from images, indirect surveying is rarely automated and relies on manual on-screen delineation. We have previously introduced a boundary delineation workflow, comprising image segmentation, boundary classification and interactive delineation that we applied on Unmanned Aerial Vehicle (UAV) data to delineate roads. In this study, we improve each of these steps. For image segmentation, we remove the need to reduce the image resolution and we limit over-segmentation by reducing the number of segment lines by 80% through filtering. For boundary classification, we show how Convolutional Neural Networks (CNN) can be used for boundary line classification, thereby eliminating the previous need for Random Forest (RF) feature generation and thus achieving 71% accuracy. For interactive delineation, we develop additional and more intuitive delineation functionalities that cover more application cases. We test our approach on more varied and larger data sets by applying it to UAV and aerial imagery of 0.02&ndash;0.25 m resolution from Kenya, Rwanda and Ethiopia. We show that it is more effective in terms of clicks and time compared to manual delineation for parcels surrounded by visible boundaries. Strongest advantages are obtained for rural scenes delineated from aerial imagery, where the delineation effort per parcel requires 38% less time and 80% fewer clicks compared to manual delineation.
KW  - cadastral mapping
KW  - indirect surveying
KW  - boundary extraction
KW  - boundary delineation
KW  - machine learning
KW  - deep learning
KW  - image analysis
KW  - CNN
KW  - RF
DO  - 10.3390/rs11212505
ER  -
TY  - EJOU
AU  - Kerle, Norman
AU  - Ghaffarian, Saman
AU  - Nawrotzki, Raphael
AU  - Leppert, Gerald
AU  - Lech, Malte
TI  - Evaluating Resilience-Centered Development Interventions with Remote Sensing
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 21
SN  - 2072-4292

AB  - Natural disasters are projected to increase in number and severity, in part due to climate change. At the same time a growing number of disaster risk reduction (DRR) and climate change adaptation measures are being implemented by governmental and non-governmental organizations, and substantial post-disaster donations are frequently pledged. At the same time there has been increasing demand for transparency and accountability, and thus evidence of those measures having a positive effect. We hypothesized that resilience-enhancing interventions should result in less damage during a hazard event, or at least quicker recovery. In this study we assessed recovery over a 3 year period of seven municipalities in the central Philippines devastated by Typhoon Haiyan in 2013. We used very high resolution optical images (&lt;1 m), and created detailed land cover and land use maps for four epochs before and after the event, using a machine learning approach with extreme gradient boosting. The spatially and temporally highly variable recovery maps were then statistically related to detailed questionnaire data acquired by DEval in 2012 and 2016, whose principal aim was to assess the impact of a 10 year land-planning intervention program by the German agency for technical cooperation (GIZ). The survey data allowed very detailed insights into DRR-related perspectives, motivations and drivers of the affected population. To some extent they also helped to overcome the principal limitation of remote sensing, which can effectively describe but not explain the reasons for differential recovery. However, while a number of causal links between intervention parameters and reconstruction was found, the common notion that a resilient community should recover better and more quickly could not be confirmed. The study also revealed a number of methodological limitations, such as the high cost for commercial image data not matching the spatially extensive but also detailed scale of field evaluations, the remote sensing analysis likely overestimating damage and thus providing incorrect recovery metrics, and image data catalogues especially for more remote communities often being incomplete. Nevertheless, the study provides a valuable proof of concept for the synergies resulting from an integration of socio-economic survey data and remote sensing imagery for recovery assessment.
KW  - disaster
KW  - resilience
KW  - impact
KW  - evaluation
KW  - Philippines
KW  - Haiyan
KW  - machine learning
KW  - gradient boosting
KW  - land use planning
KW  - German development cooperation
DO  - 10.3390/rs11212511
ER  -
TY  - EJOU
AU  - Xia, Wei
AU  - Ma, Caihong
AU  - Liu, Jianbo
AU  - Liu, Shibin
AU  - Chen, Fu
AU  - Yang, Zhi
AU  - Duan, Jianbo
TI  - High-Resolution Remote Sensing Imagery Classification of Imbalanced Data Using Multistage Sampling Method and Deep Neural Networks
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 21
SN  - 2072-4292

AB  - Class imbalance is a key issue for the application of deep learning for remote sensing image classification because a model generated by imbalanced samples training has low classification accuracy for minority classes. In this study, an accurate classification approach using the multistage sampling method and deep neural networks was proposed to classify imbalanced data. We first balance samples by multistage sampling to obtain the training sets. Then, a state-of-the-art model is adopted by combining the advantages of atrous spatial pyramid pooling (ASPP) and Encoder-Decoder for pixel-wise classification, which are two different types of fully convolutional networks (FCNs) that can obtain contextual information of multiple levels in the Encoder stage. The details and spatial dimensions of targets are restored using such information during the Decoder stage. We employ four deep learning-based classification algorithms (basic FCN, FCN-8S, ASPP, and Encoder-Decoder with ASPP of our approach) on multistage training sets (original, MUS1, and MUS2) of WorldView-3 images in southeastern Qinghai-Tibet Plateau and GF-2 images in northeastern Beijing for comparison. The experiments show that, compared with existing sets (original, MUS1, and identical) and existing method (cost weighting), the MUS2 training set of multistage sampling significantly enhance the classification performance for minority classes. Our approach shows distinct advantages for imbalanced data.
KW  - high-resolution remote sensing image
KW  - classification
KW  - deep learning
KW  - imbalanced data
KW  - multistage sampling
KW  - ASPP
KW  - encoder-decoder
DO  - 10.3390/rs11212523
ER  -
TY  - EJOU
AU  - Tavakkoli Piralilou, Sepideh
AU  - Shahabi, Hejar
AU  - Jarihani, Ben
AU  - Ghorbanzadeh, Omid
AU  - Blaschke, Thomas
AU  - Gholamnia, Khalil
AU  - Meena, Sansar R.
AU  - Aryal, Jagannath
TI  - Landslide Detection Using Multi-Scale Image Segmentation and Different Machine Learning Models in the Higher Himalayas
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 21
SN  - 2072-4292

AB  - Landslides represent a severe hazard in many areas of the world. Accurate landslide maps are needed to document the occurrence and extent of landslides and to investigate their distribution, types, and the pattern of slope failures. Landslide maps are also crucial for determining landslide susceptibility and risk. Satellite data have been widely used for such investigations—next to data from airborne or unmanned aerial vehicle (UAV)-borne campaigns and Digital Elevation Models (DEMs). We have developed a methodology that incorporates object-based image analysis (OBIA) with three machine learning (ML) methods, namely, the multilayer perceptron neural network (MLP-NN) and random forest (RF), for landslide detection. We identified the optimal scale parameters (SP) and used them for multi-scale segmentation and further analysis. We evaluated the resulting objects using the object pureness index (OPI), object matching index (OMI), and object fitness index (OFI) measures. We then applied two different methods to optimize the landslide detection task: (a) an ensemble method of stacking that combines the different ML methods for improving the performance, and (b) Dempster–Shafer theory (DST), to combine the multi-scale segmentation and classification results. Through the combination of three ML methods and the multi-scale approach, the framework enhanced landslide detection when it was tested for detecting earthquake-triggered landslides in Rasuwa district, Nepal. PlanetScope optical satellite images and a DEM were used, along with the derived landslide conditioning factors. Different accuracy assessment measures were used to compare the results against a field-based landslide inventory. All ML methods yielded the highest overall accuracies ranging from 83.3% to 87.2% when using objects with the optimal SP compared to other SPs. However, applying DST to combine the multi-scale results of each ML method significantly increased the overall accuracies to almost 90%. Overall, the integration of OBIA with ML methods resulted in appropriate landslide detections, but using the optimal SP and ML method is crucial for success.
KW  - landslide mapping
KW  - object-based image analysis (OBIA)
KW  - scale parameter (SP)
KW  - Dempster–Shafer theory (DST)
KW  - Planetscope
DO  - 10.3390/rs11212575
ER  -
TY  - EJOU
AU  - Mangewa, Lazaro J.
AU  - Ndakidemi, Patrick A.
AU  - Munishi, Linus K.
TI  - Integrating UAV Technology in an Ecological Monitoring System for Community Wildlife Management Areas in Tanzania
T2  - Sustainability

PY  - 2019
VL  - 11
IS  - 21
SN  - 2071-1050

AB  - Unmanned aerial vehicles (UAV) have recently emerged as a new remote sensing aerial platform, and they are seemingly advancing real-time data generation. Nonetheless, considerable uncertainties remain in the extent to which wildlife managers can integrate UAVs into ecological monitoring systems for wildlife and their habitats. In this review, we discuss the recent progress and gaps in UAV use in wildlife conservation and management. The review notes that there is scanty information on UAV use in ecological monitoring of medium-to-large mammals found in groups in heterogeneous habitats. We also explore the need and extent to which the technology can be integrated into ecological monitoring systems for mammals in heterogeneous habitats and in topographically-challenging community wildlife-management areas, as a complementary platform to the traditional techniques. Based on its ability to provide high-resolution images in real-time, further experiments on its wider use in the ecological monitoring of wildlife on a spatiotemporal scale are important. The experimentation outputs will make the UAV a very reliable remote sensing platform that addresses the challenges facing conventional techniques.
KW  - UAV
KW  - remote sensing
KW  - conventional ecological monitoring techniques
KW  - satellite platforms
KW  - medium-to-large mammals
KW  - UAV-based habitat assessment
DO  - 10.3390/su11216116
ER  -
TY  - EJOU
AU  - Rodriguez-Ramos, Alejandro
AU  - Alvarez-Fernandez, Adrian
AU  - Bavle, Hriday
AU  - Campoy, Pascual
AU  - How, Jonathan P.
TI  - Vision-Based Multirotor Following Using Synthetic Learning Techniques
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 21
SN  - 1424-8220

AB  - Deep- and reinforcement-learning techniques have increasingly required large sets of real data to achieve stable convergence and generalization, in the context of image-recognition, object-detection or motion-control strategies. On this subject, the research community lacks robust approaches to overcome unavailable real-world extensive data by means of realistic synthetic-information and domain-adaptation techniques. In this work, synthetic-learning strategies have been used for the vision-based autonomous following of a noncooperative multirotor. The complete maneuver was learned with synthetic images and high-dimensional low-level continuous robot states, with deep- and reinforcement-learning techniques for object detection and motion control, respectively. A novel motion-control strategy for object following is introduced where the camera gimbal movement is coupled with the multirotor motion during the multirotor following. Results confirm that our present framework can be used to deploy a vision-based task in real flight using synthetic data. It was extensively validated in both simulated and real-flight scenarios, providing proper results (following a multirotor up to 1.3 m/s in simulation and 0.3 m/s in real flights).
KW  - multirotor
KW  - UAV
KW  - following
KW  - synthetic learning
KW  - reinforcement learning
KW  - deep learning
DO  - 10.3390/s19214794
ER  -
TY  - EJOU
AU  - Fromm, Michael
AU  - Schubert, Matthias
AU  - Castilla, Guillermo
AU  - Linke, Julia
AU  - McDermid, Greg
TI  - Automated Detection of Conifer Seedlings in Drone Imagery Using Convolutional Neural Networks
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 21
SN  - 2072-4292

AB  - Monitoring tree regeneration in forest areas disturbed by resource extraction is a requirement for sustainably managing the boreal forest of Alberta, Canada. Small remotely piloted aircraft systems (sRPAS, a.k.a. drones) have the potential to decrease the cost of field surveys drastically, but produce large quantities of data that will require specialized processing techniques. In this study, we explored the possibility of using convolutional neural networks (CNNs) on this data for automatically detecting conifer seedlings along recovering seismic lines: a common legacy footprint from oil and gas exploration. We assessed three different CNN architectures, of which faster region-CNN (R-CNN) performed best (mean average precision 81%). Furthermore, we evaluated the effects of training-set size, season, seedling size, and spatial resolution on the detection performance. Our results indicate that drone imagery analyzed by artificial intelligence can be used to detect conifer seedling in regenerating sites with high accuracy, which increases with the size in pixels of the seedlings. By using a pre-trained network, the size of the training dataset can be reduced to a couple hundred seedlings without any significant loss of accuracy. Furthermore, we show that combining data from different seasons yields the best results. The proposed method is a first step towards automated monitoring of forest restoration/regeneration.
KW  - convolutional neural networks
KW  - forest restoration
KW  - regeneration surveys
KW  - seedling detection
KW  - UAVs
KW  - sRPAS
DO  - 10.3390/rs11212585
ER  -
TY  - EJOU
AU  - Ham, Sungil
AU  - Im, Junhyuck
AU  - Kim, Minjun
AU  - Cho, Kuk
TI  - Construction and Verification of a High-Precision Base Map for an Autonomous Vehicle Monitoring System
T2  - ISPRS International Journal of Geo-Information

PY  - 2019
VL  - 8
IS  - 11
SN  - 2220-9964

AB  - For autonomous driving, a control system that supports precise road maps is required to monitor the operation status of autonomous vehicles in the research stage. Such a system is also required for research related to automobile engineering, sensors, and artificial intelligence. The design of Google Maps and other map services is limited to the provision of map support at 20 levels of high-resolution precision. An ideal map should include information on roads, autonomous vehicles, and Internet of Things (IOT) facilities that support autonomous driving. The aim of this study was to design a map suitable for the control of autonomous vehicles in Gyeonggi Province in Korea. This work was part of the project &ldquo;Building a Testbed for Pilot Operations of Autonomous Vehicles&rdquo;. The map design scheme was redesigned for an autonomous vehicle control system based on the &ldquo;Easy Map&rdquo; developed by the National Geography Center, which provides free design schema. In addition, a vector-based precision map, including roads, sidewalks, and road markings, was produced to provide content suitable for 20 levels. A hybrid map that combines the vector layer of the road and an unmanned aerial vehicle (UAV) orthographic map was designed to facilitate vehicle identification. A control system that can display vehicle and sensor information based on the designed map was developed, and an environment to monitor the operation of autonomous vehicles was established. Finally, the high-precision map was verified through an accuracy test and driving data from autonomous vehicles.
KW  - high-precision map
KW  - schema design
KW  - autonomous vehicle
DO  - 10.3390/ijgi8110501
ER  -
TY  - EJOU
AU  - Yu, Lanbing
AU  - Cao, Ying
AU  - Zhou, Chao
AU  - Wang, Yang
AU  - Huo, Zhitao
TI  - Landslide Susceptibility Mapping Combining Information Gain Ratio and Support Vector Machines: A Case Study from Wushan Segment in the Three Gorges Reservoir Area, China
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 22
SN  - 2076-3417

AB  - Landslides are destructive geological hazards that occur all over the world. Due to the periodic regulation of reservoir water level, a large number of landslides occur in the Three Gorges Reservoir area (TGRA). The main objective of this study was to explore the preference of machine learning models for landslide susceptibility mapping in the TGRA. The Wushan segment of TGRA was selected as a case study. At first, 165 landslides were identified and a total of 14 landslide causal factors were constructed from different data sources. Multicollinearity analysis and information gain ratio (IGR) model were applied to select landslide causal factors. Subsequently, the landslide susceptibility mapping using the calculated results of four models, namely, support vector machines (SVM), artificial neural networks (ANN), classification and regression tree (CART), and logistic regression (LR). The accuracy of these four maps were evaluated using the receive operating characteristic (ROC) and the accuracy statistic. Results revealed that eliminating the inconsequential factors can perhaps improve the accuracy of landslide susceptibility modelling, and the SVM model had the best performance in this study, providing strong technical support for landslide susceptibility modelling in TGRA.
KW  - landslides
KW  - susceptibility mapping
KW  - support vector machines
KW  - Three Gorges Reservoir area (TGRA)
DO  - 10.3390/app9224756
ER  -
TY  - EJOU
AU  - Zhou, Jun
AU  - Tian, Yichen
AU  - Yuan, Chao
AU  - Yin, Kai
AU  - Yang, Guang
AU  - Wen, Meiping
TI  - Improved UAV Opium Poppy Detection Using an Updated YOLOv3 Model
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 22
SN  - 1424-8220

AB  - Rapid detection of illicit opium poppy plants using UAV (unmanned aerial vehicle) imagery has become an important means to prevent and combat crimes related to drug cultivation. However, current methods rely on time-consuming visual image interpretation. Here, the You Only Look Once version 3 (YOLOv3) network structure was used to assess the influence that different backbone networks have on the average precision and detection speed of an UAV-derived dataset of poppy imagery, with MobileNetv2 (MN) selected as the most suitable backbone network. A Spatial Pyramid Pooling (SPP) unit was introduced and Generalized Intersection over Union (GIoU) was used to calculate the coordinate loss. The resulting SPP-GIoU-YOLOv3-MN model improved the average precision by 1.62% (from 94.75% to 96.37%) without decreasing speed and achieved an average precision of 96.37%, with a detection speed of 29 FPS using an RTX 2080Ti platform. The sliding window method was used for detection in complete UAV images, which took approximately 2.2 sec/image, approximately 10&times; faster than visual interpretation. The proposed technique significantly improved the efficiency of poppy detection in UAV images while also maintaining a high detection accuracy. The proposed method is thus suitable for the rapid detection of illicit opium poppy cultivation in residential areas and farmland where UAVs with ordinary visible light cameras can be operated at low altitudes (relative height &lt; 200 m).
KW  - UAV
KW  - opium poppy
KW  - object detection
KW  - YOLOv3 model
KW  - deep learning
KW  - CNN
KW  - spatial pyramid pooling
KW  - GIoU
DO  - 10.3390/s19224851
ER  -
TY  - EJOU
AU  - Shahabi, Hejar
AU  - Jarihani, Ben
AU  - Tavakkoli Piralilou, Sepideh
AU  - Chittleborough, David
AU  - Avand, Mohammadtaghi
AU  - Ghorbanzadeh, Omid
TI  - A Semi-Automated Object-Based Gully Networks Detection Using Different Machine Learning Models: A Case Study of Bowen Catchment, Queensland, Australia
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 22
SN  - 1424-8220

AB  - Gully erosion is a dominant source of sediment and particulates to the Great Barrier Reef (GBR) World Heritage area. We selected the Bowen catchment, a tributary of the Burdekin Basin, as our area of study; the region is associated with a high density of gully networks. We aimed to use a semi-automated object-based gully networks detection process using a combination of multi-source and multi-scale remote sensing and ground-based data. An advanced approach was employed by integrating geographic object-based image analysis (GEOBIA) with current machine learning (ML) models. These included artificial neural networks (ANN), support vector machines (SVM), and random forests (RF), and an ensemble ML model of stacking to deal with the spatial scaling problem in gully networks detection. Spectral indices such as the normalized difference vegetation index (NDVI) and topographic conditioning factors, such as elevation, slope, aspect, topographic wetness index (TWI), slope length (SL), and curvature, were generated from Sentinel 2A images and the ALOS 12-m digital elevation model (DEM), respectively. For image segmentation, the ESP2 tool was used to obtain three optimal scale factors. On using object pureness index (OPI), object matching index (OMI), and object fitness index (OFI), the accuracy of each scale in image segmentation was evaluated. The scale parameter of 45 with OFI of 0.94, which is a combination of OPI and OMI indices, proved to be the optimal scale parameter for image segmentation. Furthermore, segmented objects based on scale 45 were overlaid with 70% and 30% of a prepared gully inventory map to select the ML models&rsquo; training and testing objects, respectively. The quantitative accuracy assessment methods of Precision, Recall, and an F1 measure were used to evaluate the model&rsquo;s performance. Integration of GEOBIA with the stacking model using a scale of 45 resulted in the highest accuracy in detection of gully networks with an F1 measure value of 0.89. Here, we conclude that the adoption of optimal scale object definition in the GEOBIA and application of the ensemble stacking of ML models resulted in higher accuracy in the detection of gully networks.
KW  - geographic object-based image analysis (GEOBIA)
KW  - gully erosion
KW  - optimal scale detection
KW  - stacking model
KW  - Bowen catchment
DO  - 10.3390/s19224893
ER  -
TY  - EJOU
AU  - Silva, Maurício R.
AU  - Souza, Elitelma S.
AU  - Alsina, Pablo J.
AU  - Leite, Deyvid L.
AU  - Morais, Mateus R.
AU  - Pereira, Diego S.
AU  - Nascimento, Luís B. P.
AU  - Medeiros, Adelardo A. D.
AU  - Junior, Francisco H. Cunha
AU  - Nogueira, Marcelo B.
AU  - Albuquerque, Glauberto L. A.
AU  - Dantas, João B. D.
TI  - Performance Evaluation of Multi-UAV Network Applied to Scanning Rocket Impact Area
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 22
SN  - 1424-8220

AB  - This paper presents a communication network for a squadron of unmanned aerial vehicles (UAVs) to be used in the scanning rocket impact area for Barreira do Inferno Launch Center&mdash;CLBI (Rio Grande do Norte, Brazil), aiming at detecting intruder boats. The main features of communication networks associated with multi-UAV systems are presented. This system sends information through Wireless Sensor Networks (WSN). After comparing and analyzing area scanning strategies, it presents the specification of a data communication network architecture for a squadron of UAVs within a sensor network using XBee Pro 900HP S3B modules. A brief description is made about the initial information from the construction of the system. The embedded hardware and the design procedure of a dedicated communication antenna to the XBee modules are presented. In order to evaluate the performance of the proposed architecture in terms of robustness and reliability, a set of experimental tests in different communication scenarios is carried out. Network management software is employed to measure the throughput, packet loss and other performance indicators in the communication links between the different network nodes. Experimental results allow verifying the quality and performance of the network nodes, as well as the reliability of the communication links, assessing signal received quality, range and latency.
KW  - ad hoc network
KW  - wireless sensor networks
KW  - FANET
KW  - multi-UAV system monitoring
KW  - communication architecture
KW  - network performance
DO  - 10.3390/s19224895
ER  -
TY  - EJOU
AU  - Tsouros, Dimosthenis C.
AU  - Bibi, Stamatia
AU  - Sarigiannidis, Panagiotis G.
TI  - A Review on UAV-Based Applications for Precision Agriculture
T2  - Information

PY  - 2019
VL  - 10
IS  - 11
SN  - 2078-2489

AB  - Emerging technologies such as Internet of Things (IoT) can provide significant potential in Smart Farming and Precision Agriculture applications, enabling the acquisition of real-time environmental data. IoT devices such as Unmanned Aerial Vehicles (UAVs) can be exploited in a variety of applications related to crops management, by capturing high spatial and temporal resolution images. These technologies are expected to revolutionize agriculture, enabling decision-making in days instead of weeks, promising significant reduction in cost and increase in the yield. Such decisions enable the effective application of farm inputs, supporting the four pillars of precision agriculture, i.e., apply the right practice, at the right place, at the right time and with the right quantity. However, the actual proliferation and exploitation of UAVs in Smart Farming has not been as robust as expected mainly due to the challenges confronted when selecting and deploying the relevant technologies, including the data acquisition and image processing methods. The main problem is that still there is no standardized workflow for the use of UAVs in such applications, as it is a relatively new area. In this article, we review the most recent applications of UAVs for Precision Agriculture. We discuss the most common applications, the types of UAVs exploited and then we focus on the data acquisition methods and technologies, appointing the benefits and drawbacks of each one. We also point out the most popular processing methods of aerial imagery and discuss the outcomes of each method and the potential applications of each one in the farming operations.
KW  - remote sensing
KW  - IoT
KW  - UAV
KW  - UAS
KW  - Unmanned Aerial Vehicle
KW  - Unmanned Aerial System
KW  - image processing
KW  - Precision Agriculture
KW  - Smart Farming
KW  - review
DO  - 10.3390/info10110349
ER  -
TY  - EJOU
AU  - Riid, Andri
AU  - Lõuk, Roland
AU  - Pihlak, Rene
AU  - Tepljakov, Aleksei
AU  - Vassiljeva, Kristina
TI  - Pavement Distress Detection with Deep Learning Using the Orthoframes Acquired by a Mobile Mapping System
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 22
SN  - 2076-3417

AB  - The subject matter of this research article is automatic detection of pavement distress on highway roads using computer vision algorithms. Specifically, deep learning convolutional neural network models are employed towards the implementation of the detector. Source data for training the detector come in the form of orthoframes acquired by a mobile mapping system. Compared to our previous work, the orthoframes are generally of better quality, but more importantly, in this work, we introduce a manual preprocessing step: sets of orthoframes are carefully selected for training and manually digitized to ensure adequate performance of the detector. Pretrained convolutional neural networks are then fine-tuned for the problem of pavement distress detection. Corresponding experimental results are provided and analyzed and indicate a successful implementation of the detector.
KW  - pavement distress
KW  - defect detection
KW  - image recognition
KW  - image processing
KW  - deep neural network
DO  - 10.3390/app9224829
ER  -
TY  - EJOU
AU  - Yu, Hao
AU  - Wang, Lei
AU  - Wang, Zongming
AU  - Ren, Chunying
AU  - Zhang, Bai
TI  - Using Landsat OLI and Random Forest to Assess Grassland Degradation with Aboveground Net Primary Production and Electrical Conductivity Data
T2  - ISPRS International Journal of Geo-Information

PY  - 2019
VL  - 8
IS  - 11
SN  - 2220-9964

AB  - Grassland coverage, aboveground net primary production (ANPP), and species composition are used as indicators of grassland degradation. However, soil salinization deficiency, which is also a factor of grassland degradation, is rarely used in grassland degradation assessment in semiarid regions. We assessed grassland degradation by its quality, quantity, and spatial pattern over semiarid west Jilin, China. Considering soil salinization in west Jilin, electrical conductivity (EC) is used as an index with ANPP to assess grassland degradation. First, the spatial distribution of the grassland was measured with information mined from multi-temporal remote sensing images using an object-based image analysis combined with classification and decision tree methods. Second, with 166 field samples, we utilized the random forest (RF) algorithm as the variable selection and regression method for predicting EC and ANPP. Finally, we created a new grassland degradation model (GDM) based on ANPP and EC. The results showed the R2 (0.91) and RMSE (0.057 mS/cm) of the EC model were generally highest and lowest when the ntree was 400; the ANPP model was optimal (R2 = 0.85 and RMSE = 15.81 gC/m2) when the ntree was 600. Grassland area of west Jilin was 609.67 &times; 103 ha in 2017, there were 373.79 &times; 103 ha of degraded grassland, with 210.47 &times; 103 ha being intensively degraded. This paper surpasses past limitations of excessive reliance on vegetation index to construct a grassland degradation model which considers the characteristics of the study area and soil salinity. The results confirm the positive influence of the ecological conservation projects sponsored by the government. The research outcome could offer supporting data for decision making to help alleviate grassland degradation and promote the rehabilitation of grassland vegetation.
KW  - remote sensing
KW  - aboveground net primary productivity (ANPP)
KW  - soil salinity
KW  - grassland degradation model (GDM)
KW  - random forest (RF)
KW  - principle component analysis (PCA)
DO  - 10.3390/ijgi8110511
ER  -
TY  - EJOU
AU  - Zhao, Longcai
AU  - Li, Qiangzi
AU  - Zhang, Yuan
AU  - Wang, Hongyan
AU  - Du, Xin
TI  - Integrating the Continuous Wavelet Transform and a Convolutional Neural Network to Identify Vineyard Using Time Series Satellite Images
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 22
SN  - 2072-4292

AB  - Grape is an economic crop of great importance and is widely cultivated in China. With the development of remote sensing, abundant data sources strongly guarantee that researchers can identify crop types and map their spatial distributions. However, to date, only a few studies have been conducted to identify vineyards using satellite image data. In this study, a vineyard is identified using satellite images, and a new approach is proposed that integrates the continuous wavelet transform (CWT) and a convolutional neural network (CNN). Specifically, the original time series of the normalized difference vegetation index (NDVI), enhanced vegetation index (EVI), and green chlorophyll vegetation index (GCVI) are reconstructed by applying an iterated Savitzky-Golay (S-G) method to form a daily time series for a full year; then, the CWT is applied to three reconstructed time series to generate corresponding scalograms; and finally, CNN technology is used to identify vineyards based on the stacked scalograms. In addition to our approach, a traditional and common approach that uses a random forest (RF) to identify crop types based on multi-temporal images is selected as the control group. The experimental results demonstrated the following: (i) the proposed approach was comprehensively superior to the RF approach; it improved the overall accuracy by 9.87% (up to 89.66%); (ii) the CWT had a stable and effective influence on the reconstructed time series, and the scalograms fully represented the unique time-related frequency pattern of each of the planting conditions; and (iii) the convolution and max pooling processing of the CNN captured the unique and subtle distribution patterns of the scalograms to distinguish vineyards from other crops. Additionally, the proposed approach is considered as able to be applied to other practical scenarios, such as using time series data to identify crop types, map landcover/land use, and is recommended to be tested in future practical applications.
KW  - vineyard
KW  - identification
KW  - CWT
KW  - CNN
KW  - Sentinel-2
KW  - remote sensing
DO  - 10.3390/rs11222641
ER  -
TY  - EJOU
AU  - Bui, Hoang-Bac
AU  - Nguyen, Hoang
AU  - Choi, Yosoon
AU  - Bui, Xuan-Nam
AU  - Nguyen-Thoi, Trung
AU  - Zandi, Yousef
TI  - A Novel Artificial Intelligence Technique to Estimate the Gross Calorific Value of Coal Based on Meta-Heuristic and Support Vector Regression Algorithms
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 22
SN  - 2076-3417

AB  - Gross calorific value (GCV) is one of the essential parameters for evaluating coal quality. Therefore, accurate GCV prediction is one of the primary ways to improve heating value as well as coal production. A novel evolutionary-based predictive system was proposed in this study for predicting GCV with high accuracy, namely the particle swarm optimization (PSO)-support vector regression (SVR) model. It was developed based on the SVR and PSO algorithms. Three different kernel functions were employed to establish the PSO-SVR models, including radial basis function, linear, and polynomial functions. Besides, three benchmark machine learning models including classification and regression trees (CART), multiple linear regression (MLR), and principle component analysis (PCA) were also developed to estimate GCV and then compared with the proposed PSO-SVR model; 2583 coal samples were used to analyze the proximate components and GCV for this study. Then, they were used to develop the mentioned models as well as check their performance in experimental results. Root-mean-squared error (RMSE), correlation coefficient (R2), ranking, and intensity color criteria were used and computed to evaluate the GCV predictive models developed. The results revealed that the proposed PSO-SVR model with radial basis function had better accuracy than the other models. The PSO algorithm was optimized in the SVR model with high efficiency. These should be used as a supporting tool in practical engineering to determine the heating value of coal seams in complex geological conditions.
KW  - gross calorific value
KW  - coal
KW  - proximate analyze
KW  - artificial intelligence
KW  - PSO-SVR
DO  - 10.3390/app9224868
ER  -
TY  - EJOU
AU  - Abdelbaki, Asmaa
AU  - Schlerf, Martin
AU  - Verhoef, Wout
AU  - Udelhoven, Thomas
TI  - Introduction of Variable Correlation for the Improved Retrieval of Crop Traits Using Canopy Reflectance Model Inversion
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 22
SN  - 2072-4292

AB  - Look-up table (LUT)-based canopy reflectance models are considered robust methods to estimate vegetation attributes from remotely sensed data. However, the LUT inversion approach is sensitive to measurements and model uncertainties, which raise the ill-posed inverse problem. Therefore, regularization options are needed to mitigate this problem and reduce the uncertainties of estimates. In this study, we introduce a new method to regularize the LUT inversion approach to improve the accuracy of biophysical parameters (leaf area index (LAI) and fractional vegetation cover (fCover)). This was achieved by incorporating known variable correlations that existed at the test site into the LUT approach to correlate the model variables of the Soil–Leaf–Canopy (SLC) model using the Cholesky decomposition algorithm. The retrievals of 27 potato plots obtained from the regularized LUT (LUTreg) were compared with the standard LUT (LUTstd), which did not consider variable correlations. Different solutions from both types of LUTs (LUTreg and LUTstd) were utilized to improve the quality of the model outputs. Results indicate that the present method improved the accuracy of LAI estimation, with the coefficient of determination R2 = 0.74 and normalized root-mean-square error NRMSE = 24.45% in LUTreg, compared with R2 = 0.71 and NRMSE = 25.57% in LUTstd. In addition, the variability of LAI decreased in LUTreg (5.10) compared with that in LUTstd (12.10). Hence, our results give new insight into the impact of adding the correlation between variables to the LUT inversion approach to improve the accuracy of estimations. In this study, only two correlated variables (LAI and fCover) were examined; in subsequent studies, the full correlation matrix based on the Cholesky algorithm should be explored.
KW  - LUT inversion-based
KW  - Cholesky decomposition
KW  - regularization strategies
KW  - fractional vegetation cover
KW  - canopy chlorophyll content
KW  - hyperspectral measurements
DO  - 10.3390/rs11222681
ER  -
TY  - EJOU
AU  - Arshad, Bilal
AU  - Ogie, Robert
AU  - Barthelemy, Johan
AU  - Pradhan, Biswajeet
AU  - Verstaevel, Nicolas
AU  - Perez, Pascal
TI  - Computer Vision and IoT-Based Sensors in Flood Monitoring and Mapping: A Systematic Review
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 22
SN  - 1424-8220

AB  - Floods are amongst the most common and devastating of all natural hazards. The alarming number of flood-related deaths and financial losses suffered annually across the world call for improved response to flood risks. Interestingly, the last decade has presented great opportunities with a series of scholarly activities exploring how camera images and wireless sensor data from Internet-of-Things (IoT) networks can improve flood management. This paper presents a systematic review of the literature regarding IoT-based sensors and computer vision applications in flood monitoring and mapping. The paper contributes by highlighting the main computer vision techniques and IoT sensor approaches utilised in the literature for real-time flood monitoring, flood modelling, mapping and early warning systems including the estimation of water level. The paper further contributes by providing recommendations for future research. In particular, the study recommends ways in which computer vision and IoT sensor techniques can be harnessed to better monitor and manage coastal lagoons&mdash;an aspect that is under-explored in the literature.
KW  - remote sensing
KW  - flood
KW  - disaster management
KW  - coastal
KW  - environmental sensor network (ESN)
KW  - IoT
KW  - drones
KW  - UAV
KW  - computer vision
KW  - wireless sensor network
DO  - 10.3390/s19225012
ER  -
TY  - EJOU
AU  - Wang, Wantian
AU  - Tang, Ziyue
AU  - Chen, Yichang
AU  - Zhang, Yuanpeng
AU  - Sun, Yongjian
TI  - Aircraft Target Classification for Conventional Narrow-Band Radar with Multi-Wave Gates Sparse Echo Data
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 22
SN  - 2072-4292

AB  - For a conventional narrow-band radar system, the detectable information of the target is limited, and it is difficult for the radar to accurately identify the target type. In particular, the classification probability will further decrease when part of the echo data is missed. By extracting the target features in time and frequency domains from multi-wave gates sparse echo data, this paper presents a classification algorithm in conventional narrow-band radar to identify three different types of aircraft target, i.e., helicopter, propeller and jet. Firstly, the classical sparse reconstruction algorithm is utilized to reconstruct the target frequency spectrum with single-wave gate sparse echo data. Then, the micro-Doppler effect caused by rotating parts of different targets is analyzed, and the micro-Doppler based features, such as amplitude deviation coefficient, time domain waveform entropy and frequency domain waveform entropy, are extracted from reconstructed echo data to identify targets. Thirdly, the target features extracted from multi-wave gates reconstructed echo data are weighted and fused to improve the accuracy of classification. Finally, the fused feature vectors are fed into a support vector machine (SVM) model for classification. By contrast with the conventional algorithm of aircraft target classification, the proposed algorithm can effectively process sparse echo data and achieve higher classification probability via weighted features fusion of multi-wave gates echo data. The experiments on synthetic data are carried out to validate the effectiveness of the proposed algorithm.
KW  - narrow-band radar
KW  - target classification
KW  - signal reconstruction
KW  - features extraction
KW  - weighted features fusion
DO  - 10.3390/rs11222700
ER  -
TY  - EJOU
AU  - Sun, Ying
AU  - Huang, Jianfeng
AU  - Ao, Zurui
AU  - Lao, Dazhao
AU  - Xin, Qinchuan
TI  - Deep Learning Approaches for the Mapping of Tree Species Diversity in a Tropical Wetland Using Airborne LiDAR and High-Spatial-Resolution Remote Sensing Images
T2  - Forests

PY  - 2019
VL  - 10
IS  - 11
SN  - 1999-4907

AB  - The monitoring of tree species diversity is important for forest or wetland ecosystem service maintenance or resource management. Remote sensing is an efficient alternative to traditional field work to map tree species diversity over large areas. Previous studies have used light detection and ranging (LiDAR) and imaging spectroscopy (hyperspectral or multispectral remote sensing) for species richness prediction. The recent development of very high spatial resolution (VHR) RGB images has enabled detailed characterization of canopies and forest structures. In this study, we developed a three-step workflow for mapping tree species diversity, the aim of which was to increase knowledge of tree species diversity assessment using deep learning in a tropical wetland (Haizhu Wetland) in South China based on VHR-RGB images and LiDAR points. Firstly, individual trees were detected based on a canopy height model (CHM, derived from LiDAR points) by the local-maxima-based method in the FUSION software (Version 3.70, Seattle, USA). Then, tree species at the individual tree level were identified via a patch-based image input method, which cropped the RGB images into small patches (the individually detected trees) based on the tree apexes detected. Three different deep learning methods (i.e., AlexNet, VGG16, and ResNet50) were modified to classify the tree species, as they can make good use of the spatial context information. Finally, four diversity indices, namely, the Margalef richness index, the Shannon&ndash;Wiener diversity index, the Simpson diversity index, and the Pielou evenness index, were calculated from the fixed subset with a size of 30 &times; 30 m for assessment. In the classification phase, VGG16 had the best performance, with an overall accuracy of 73.25% for 18 tree species. Based on the classification results, mapping of tree species diversity showed reasonable agreement with field survey data (R2Margalef = 0.4562, root-mean-square error RMSEMargalef = 0.5629; R2Shannon&ndash;Wiener = 0.7948, RMSEShannon&ndash;Wiener = 0.7202; R2Simpson = 0.7907, RMSESimpson = 0.1038; and R2Pielou = 0.5875, RMSEPielou = 0.3053). While challenges remain for individual tree detection and species classification, the deep-learning-based solution shows potential for mapping tree species diversity.
KW  - tree species diversity
KW  - tropical wetland
KW  - high-resolution remote sensing images
KW  - LiDAR
KW  - individual tree level
KW  - deep learning
DO  - 10.3390/f10111047
ER  -
TY  - EJOU
AU  - Zhang, Xiaoyan
AU  - Zhao, Jinming
AU  - Yang, Guijun
AU  - Liu, Jiangang
AU  - Cao, Jiqiu
AU  - Li, Chunyan
AU  - Zhao, Xiaoqing
AU  - Gai, Junyi
TI  - Establishment of Plot-Yield Prediction Models in Soybean Breeding Programs Using UAV-Based Hyperspectral Remote Sensing
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 23
SN  - 2072-4292

AB  - Yield evaluation of breeding lines is the key to successful release of cultivars, which is becoming a serious issue due to soil heterogeneity in enlarged field tests. This study aimed at establishing plot-yield prediction models using unmanned aerial vehicle (UAV)-based hyperspectral remote sensing for yield-selection in large-scale soybean breeding programs. Three sets of soybean breeding lines (1103 in total) were tested in blocks-in-replication experiments for plot yield and canopy spectral reflectance on 454~950 nm bands at different growth stages using a UAV-based hyperspectral spectrometer (Cubert UHD185 Firefly). The four elements for plot-yield prediction model construction were studied respectively and concluded as: the suitable reflectance-sampling unit-size in a plot was its 20%–80% central part; normalized difference vegetation index (NDVI) and ration vegetation index (RVI) were the best combination of vegetation indices; the initial seed-filling stage (R5) was the best for a single stage prediction, while another was the best combination for a two growth-stage prediction; and multi-variate linear regression was suitable for plot-yield prediction. In model establishment for each material-set, a random half was used for modelling and another half for verification. Twenty-one two growth-stage two vegetation-index prediction models were established and compared for their modelling coefficient of determination (RM2) and root mean square error of the model (RMSEM), verification RV2 and RMSEV, and their sum RS2 and RMSES. Integrated with the coincidence rate between the model predicted and the practical yield-selection results, the models, MA1-2, MA4-2 and MA6-2, with coincidence rates of 56.8%, 58.5% and 52.4%, respectively, were chosen for yield-prediction in yield-test nurseries. The established model construction elements and methods can be used as local models for pre-harvest yield-selection and post-harvest integrated yield-selection in advanced breeding nurseries as well as yield potential prediction in plant-derived-line nurseries. Furthermore, multiple models can be used jointly for plot-yield prediction in soybean breeding programs.
KW  - soybean breeding
KW  - plot-yield prediction
KW  - UAV-based hyperspectral remote sensing
KW  - vegetation index
KW  - multiple linear regression
KW  - determination coefficient (R2)
KW  - root mean square error (RMSE)
DO  - 10.3390/rs11232752
ER  -
TY  - EJOU
AU  - Bithas, Petros S.
AU  - Michailidis, Emmanouel T.
AU  - Nomikos, Nikolaos
AU  - Vouyioukas, Demosthenes
AU  - Kanatas, Athanasios G.
TI  - A Survey on Machine-Learning Techniques for UAV-Based Communications
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 23
SN  - 1424-8220

AB  - Unmanned aerial vehicles (UAVs) will be an integral part of the next generation wireless communication networks. Their adoption in various communication-based applications is expected to improve coverage and spectral efficiency, as compared to traditional ground-based solutions. However, this new degree of freedom that will be included in the network will also add new challenges. In this context, the machine-learning (ML) framework is expected to provide solutions for the various problems that have already been identified when UAVs are used for communication purposes. In this article, we provide a detailed survey of all relevant research works, in which ML techniques have been used on UAV-based communications for improving various design and functional aspects such as channel modeling, resource management, positioning, and security.
KW  - 5G networks
KW  - air-to-ground communications
KW  - machine-learning
KW  - unmanned aerial vehicles (UAVs)
KW  - cellular networks
DO  - 10.3390/s19235170
ER  -
TY  - EJOU
AU  - Röll, Georg
AU  - Hartung, Jens
AU  - Graeff-Hönninger, Simone
TI  - Determination of Plant Nitrogen Content in Wheat Plants via Spectral Reflectance Measurements: Impact of Leaf Number and Leaf Position
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 23
SN  - 2072-4292

AB  - The determination of plant nitrogen (N) content (%) in wheat via destructive lab analysis is expensive and inadequate for precision farming applications. Vegetation indices (VI) based on spectral reflectance can be used to predict plant N content indirectly. For these VI, reflectance from space-borne, airborne, or ground-borne sensors is captured. Measurements are often taken at the canopy level for practical reasons. Hence, translocation processes of nutrients that take place within the plant might be ignored or measurements might be less accurate if nutrient deficiency symptoms occur on the older leaves. This study investigated the impact of leaf number and measurement position on the leaf itself on the determination of plant N content (%) via reflectance measurements. Two hydroponic experiments were carried out. In the first experiment, the N fertilizer amount and growth stage for the determination of N content was varied, while the second experiment focused on a secondary induction of N deficiency due to drought stress. For each plant, reflectance measurements were taken from three leaves (L1, L2, L3) and at three positions on the leaf (P1, P2, P3). In addition, the N content (%) of the whole plant was determined by chemical lab analysis. Reflectance spectrometer measurements (400&ndash;1650 nm) were used to calculate 16 VI for each combination of leaf and position. N content (%) was predicted using each VI for each leaf and each position. Significant lower mean residual error variance (MREV) was found for leaves L1 and L3 and for measurement position on P3 in the N trial, but the difference of MREV between the leaves was very low and therefore considered as not relevant. The drought stress trial also led to no significant differences in MREV between leaves and positions. Neither the position on the leaf nor the leaf number had an impact on the accuracy of plant nitrogen determination via spectral reflectance measurements, wherefore measurements taken at the canopy level seem to be a valid approach.
KW  - wheat
KW  - spectrometer
KW  - nitrogen content
KW  - hydroponics
KW  - nitrogen treatments
KW  - growth stages
KW  - vegetation index
DO  - 10.3390/rs11232794
ER  -
TY  - EJOU
AU  - Zhang, Heng
AU  - Wu, Jiayu
AU  - Liu, Yanli
AU  - Yu, Jia
TI  - VaryBlock: A Novel Approach for Object Detection in Remote Sensed Images
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 23
SN  - 1424-8220

AB  - In recent years, the research on optical remote sensing images has received greater and greater attention. Object detection, as one of the most challenging tasks in the area of remote sensing, has been remarkably promoted by convolutional neural network (CNN)-based methods like You Only Look Once (YOLO) and Faster R-CNN. However, due to the complexity of backgrounds and the distinctive object distribution, directly applying these general object detection methods to the remote sensing object detection usually renders poor performance. To tackle this problem, a highly efficient and robust framework based on YOLO is proposed. We devise and integrate VaryBlock to the architecture which effectively offsets some of the information loss caused by downsampling. In addition, some techniques are utilized to facilitate the performance and to avoid overfitting. Experimental results show that our proposed method can enormously improve the mean average precision by a large margin on the NWPU VHR-10 dataset.
KW  - remote sensing
KW  - object detection
KW  - YOLO
KW  - VaryBlock
DO  - 10.3390/s19235284
ER  -
TY  - EJOU
AU  - Moreno-Armendáriz, Marco A.
AU  - Calvo, Hiram
AU  - Duchanoy, Carlos A.
AU  - López-Juárez, Anayantzin P.
AU  - Vargas-Monroy, Israel A.
AU  - Suarez-Castañon, Miguel S.
TI  - Deep Green Diagnostics: Urban Green Space Analysis Using Deep Learning and Drone Images
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 23
SN  - 1424-8220

AB  - Nowadays, more than half of the world’s population lives in urban areas, and this number continues increasing. Consequently, there are more and more scientific publications that analyze health problems of people associated with living in these highly urbanized locations. In particular, some of the recent work has focused on relating people’s health to the quality and quantity of urban green areas. In this context, and considering the huge amount of land area in large cities that must be supervised, our work seeks to develop a deep learning-based solution capable of determining the level of health of the land and to assess whether it is contaminated. The main purpose is to provide health institutions with software capable of creating updated maps that indicate where these phenomena are presented, as this information could be very useful to guide public health goals in large cities. Our software is released as open source code, and the data used for the experiments presented in this paper are also freely available.
KW  - deep learning (for social good)
KW  - remote sensing
KW  - biomass analysis
DO  - 10.3390/s19235287
ER  -
TY  - EJOU
AU  - Communier, David
AU  - Le Besnerais, Franck
AU  - Botez, Ruxandra M.
AU  - Wong, Tony
TI  - Design, Manufacturing, and Testing of a New Concept for a Morphing Leading Edge using a Subsonic Blow Down Wind Tunnel
T2  - Biomimetics

PY  - 2019
VL  - 4
IS  - 4
SN  - 2313-7673

AB  - This paper presents the design and wind tunnel test results of a wing including a morphing leading edge for a medium unmanned aerial vehicle with a maximum wingspan of 5 m. The design of the morphing leading edge system is part of research on the design of a morphing camber system. The concept presented here has the advantage of being simple to manufacture (wooden construction) and light for the structure of the wing (compliance mechanism). The morphing leading edge prototype demonstrates the possibility of modifying the stall angle of the wing. In addition, the modification of the stall angle is performed without affecting the slope of the lift coefficient. This prototype is designed to validate the functionality of the deformation method applied to the leading edge of the wing. The mechanism can be further optimized in terms of shape and material to obtain a greater deformation of the leading edge, and, thus, to have a higher impact on the increase of the stall angle than the first prototype of the morphing leading edge presented in this paper.
KW  - morphing leading edge
KW  - wind tunnel testing
KW  - morphing wing
DO  - 10.3390/biomimetics4040076
ER  -
TY  - EJOU
AU  - Kayad, Ahmed
AU  - Sozzi, Marco
AU  - Gatto, Simone
AU  - Marinello, Francesco
AU  - Pirotti, Francesco
TI  - Monitoring Within-Field Variability of Corn Yield using Sentinel-2 and Machine Learning Techniques
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 23
SN  - 2072-4292

AB  - Monitoring and prediction of within-field crop variability can support farmers to make the right decisions in different situations. The current advances in remote sensing and the availability of high resolution, high frequency, and free Sentinel-2 images improve the implementation of Precision Agriculture (PA) for a wider range of farmers. This study investigated the possibility of using vegetation indices (VIs) derived from Sentinel-2 images and machine learning techniques to assess corn (Zea mays) grain yield spatial variability within the field scale. A 22-ha study field in North Italy was monitored between 2016 and 2018; corn yield was measured and recorded by a grain yield monitor mounted on the harvester machine recording more than 20,000 georeferenced yield observation points from the study field for each season. VIs from a total of 34 Sentinel-2 images at different crop ages were analyzed for correlation with the measured yield observations. Multiple regression and two different machine learning approaches were also tested to model corn grain yield. The three main results were the following: (i) the Green Normalized Difference Vegetation Index (GNDVI) provided the highest R2 value of 0.48 for monitoring within-field variability of corn grain yield; (ii) the most suitable period for corn yield monitoring was a crop age between 105 and 135 days from the planting date (R4&ndash;R6); (iii) Random Forests was the most accurate machine learning approach for predicting within-field variability of corn yield, with an R2 value of almost 0.6 over an independent validation set of half of the total observations. Based on the results, within-field variability of corn yield for previous seasons could be investigated from archived Sentinel-2 data with GNDVI at crop stage (R4&ndash;R6).
KW  - Sentinel-2
KW  - precision agriculture
KW  - machine learning
KW  - vegetation indices
KW  - corn yield
KW  - within-field variability
KW  - digital farming
DO  - 10.3390/rs11232873
ER  -
TY  - EJOU
AU  - Liu, Wei
AU  - Yang, MengYuan
AU  - Xie, Meng
AU  - Guo, Zihui
AU  - Li, ErZhu
AU  - Zhang, Lianpeng
AU  - Pei, Tao
AU  - Wang, Dong
TI  - Accurate Building Extraction from Fused DSM and UAV Images Using a Chain Fully Convolutional Neural Network
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 24
SN  - 2072-4292

AB  - Accurate extraction of buildings using high spatial resolution imagery is essential to a wide range of urban applications. However, it is difficult to extract semantic features from a variety of complex scenes (e.g., suburban, urban and urban village areas) because various complex man-made objects usually appear heterogeneous with large intra-class and low inter-class variations. The automatic extraction of buildings is thus extremely challenging. The fully convolutional neural networks (FCNs) developed in recent years have performed well in the extraction of urban man-made objects due to their ability to learn state-of-the-art features and to label pixels end-to-end. One of the most successful FCNs used in building extraction is U-net. However, the commonly used skip connection and feature fusion refinement modules in U-net often ignore the problem of feature selection, and the ability to extract smaller buildings and refine building boundaries needs to be improved. In this paper, we propose a trainable chain fully convolutional neural network (CFCN), which fuses high spatial resolution unmanned aerial vehicle (UAV) images and the digital surface model (DSM) for building extraction. Multilevel features are obtained from the fusion data, and an improved U-net is used for the coarse extraction of the building. To solve the problem of incomplete extraction of building boundaries, a U-net network is introduced by chain, which is used for the introduction of a coarse building boundary constraint, hole filling, and "speckle" removal. Typical areas such as suburban, urban, and urban villages were selected for building extraction experiments. The results show that the CFCN achieved recall of 98.67%, 98.62%, and 99.52% and intersection over union (IoU) of 96.23%, 96.43%, and 95.76% in suburban, urban, and urban village areas, respectively. Considering the IoU in conjunction with the CFCN and U-net resulted in improvements of 6.61%, 5.31%, and 6.45% in suburban, urban, and urban village areas, respectively. The proposed method can extract buildings with higher accuracy and with clearer and more complete boundaries.
KW  - building extraction
KW  - digital surface model
KW  - unmanned aerial vehicle images
KW  - chain full convolution neural network
KW  - fusion
DO  - 10.3390/rs11242912
ER  -
TY  - EJOU
AU  - Prado Osco, Lucas
AU  - Marques Ramos, Ana P.
AU  - Roberto Pereira, Danilo
AU  - Akemi Saito Moriya, Érika
AU  - Nobuhiro Imai, Nilton
AU  - Takashi Matsubara, Edson
AU  - Estrabis, Nayara
AU  - de Souza, Maurício
AU  - Marcato Junior, José
AU  - Gonçalves, Wesley N.
AU  - Li, Jonathan
AU  - Liesenberg, Veraldo
AU  - Eduardo Creste, José
TI  - Predicting Canopy Nitrogen Content in Citrus-Trees Using Random Forest Algorithm Associated to Spectral Vegetation Indices from UAV-Imagery
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 24
SN  - 2072-4292

AB  - The traditional method of measuring nitrogen content in plants is a time-consuming and labor-intensive task. Spectral vegetation indices extracted from unmanned aerial vehicle (UAV) images and machine learning algorithms have been proved effective in assisting nutritional analysis in plants. Still, this analysis has not considered the combination of spectral indices and machine learning algorithms to predict nitrogen in tree-canopy structures. This paper proposes a new framework to infer the nitrogen content in citrus-tree at a canopy-level using spectral vegetation indices processed with the random forest algorithm. A total of 33 spectral indices were estimated from multispectral images acquired with a UAV-based sensor. Leaf samples were gathered from different planting-fields and the leaf nitrogen content (LNC) was measured in the laboratory, and later converted into the canopy nitrogen content (CNC). To evaluate the robustness of the proposed framework, we compared it with other machine learning algorithms. We used 33,600 citrus trees to evaluate the performance of the machine learning models. The random forest algorithm had higher performance in predicting CNC than all models tested, reaching an R2 of 0.90, MAE of 0.341 g&middot;kg&minus;1 and MSE of 0.307 g&middot;kg&minus;1. We demonstrated that our approach is able to reduce the need for chemical analysis of the leaf tissue and optimizes citrus orchard CNC monitoring.
KW  - UAV multispectral imagery
KW  - spectral vegetation indices
KW  - machine learning
KW  - plant nutrition
DO  - 10.3390/rs11242925
ER  -
TY  - EJOU
AU  - Zhou, Yu
AU  - Wu, Chunxue
AU  - Wu, Qunhui
AU  - Eli, Zelda M.
AU  - Xiong, Naixue
AU  - Zhang, Sheng
TI  - Design and Analysis of Refined Inspection of Field Conditions of Oilfield Pumping Wells Based on Rotorcraft UAV Technology
T2  - Electronics

PY  - 2019
VL  - 8
IS  - 12
SN  - 2079-9292

AB  - The traditional oil well monitoring method relies on manual acquisition and various high-precision sensors. Using the indicator diagram to judge the working condition of the well is not only difficult to establish but also consumes huge manpower and financial resources. This paper proposes the use of computer vision in the detection of working conditions in oil extraction. Combined with the advantages of an unmanned aerial vehicle (UAV), UAV aerial photography images are used to realize real-time detection of on-site working conditions by real-time tracking of the working status of the head working and other related parts of the pumping unit. Considering the real-time performance of working condition detection, this paper proposes a framework that combines You only look once version 3 (YOLOv3) and a sort algorithm to complete multi-target tracking in the form of tracking by detection. The quality of the target detection in the framework is the key factor affecting the tracking effect. The experimental results show that a good detector makes the tracking speed achieve the real-time effect and provides help for the real-time detection of the working condition, which has a strong practical application.
KW  - computer vision
KW  - oil well working condition
KW  - real-time detection
KW  - sort
KW  - unmanned aerial vehicle (UAV)
KW  - YOLOv3
DO  - 10.3390/electronics8121504
ER  -
TY  - EJOU
AU  - Barbedo, Jayme G.
AU  - Koenigkan, Luciano V.
AU  - Santos, Thiago T.
AU  - Santos, Patrícia M.
TI  - A Study on the Detection of Cattle in UAV Images Using Deep Learning
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 24
SN  - 1424-8220

AB  - Unmanned aerial vehicles (UAVs) are being increasingly viewed as valuable tools to aid the management of farms. This kind of technology can be particularly useful in the context of extensive cattle farming, as production areas tend to be expansive and animals tend to be more loosely monitored. With the advent of deep learning, and convolutional neural networks (CNNs) in particular, extracting relevant information from aerial images has become more effective. Despite the technological advancements in drone, imaging and machine learning technologies, the application of UAVs for cattle monitoring is far from being thoroughly studied, with many research gaps still remaining. In this context, the objectives of this study were threefold: (1) to determine the highest possible accuracy that could be achieved in the detection of animals of the Canchim breed, which is visually similar to the Nelore breed (Bos taurus indicus); (2) to determine the ideal ground sample distance (GSD) for animal detection; (3) to determine the most accurate CNN architecture for this specific problem. The experiments involved 1853 images containing 8629 samples of animals, and 15 different CNN architectures were tested. A total of 900 models were trained (15 CNN architectures &times; 3 spacial resolutions &times; 2 datasets &times; 10-fold cross validation), allowing for a deep analysis of the several aspects that impact the detection of cattle using aerial images captured using UAVs. Results revealed that many CNN architectures are robust enough to reliably detect animals in aerial images even under far from ideal conditions, indicating the viability of using UAVs for cattle monitoring.
KW  - unmanned aerial vehicles
KW  - drones
KW  - canchim breed
KW  - nelore breed
KW  - convolutional neural networks
DO  - 10.3390/s19245436
ER  -
TY  - EJOU
AU  - Hadavandsiri, Zahra
AU  - Lichti, Derek D.
AU  - Jahraus, Adam
AU  - Jarron, David
TI  - Concrete Preliminary Damage Inspection by Classification of Terrestrial Laser Scanner Point Clouds through Systematic Threshold Definition
T2  - ISPRS International Journal of Geo-Information

PY  - 2019
VL  - 8
IS  - 12
SN  - 2220-9964

AB  - This paper presents a novel approach for automatic, preliminary detection of damage in concrete structures using ground-based terrestrial laser scanners. The method is based on computation of defect-sensitive features such as the surface curvature, since the surface roughness changes strongly if an area is affected by damage. A robust version of principal component analysis (PCA) classification is proposed to distinguish between structural damage and outliers present in the laser scanning data. Numerical simulations were conducted to develop a systematic point-wise defect classifier that automatically diagnoses the location of superficial damage on the investigated region. The method provides a complete picture of the surface health of concrete structures. It has been tested on two real datasets: a concrete heritage aqueduct in Brooks, Alberta, Canada; and a civil pedestrian concrete structure. The experiment results demonstrate the validity and accuracy of the proposed systematic framework for detecting and localizing areas of damage as small as 1 cm or less.
KW  - structural damage assessment
KW  - TLS
KW  - automatic damage classification
KW  - robust PCA
KW  - systematic threshold
DO  - 10.3390/ijgi8120585
ER  -
TY  - EJOU
AU  - Ahn, Hyojung
AU  - Choi, Han-Lim
AU  - Kang, Minguk
AU  - Moon, SungTae
TI  - Learning-Based Anomaly Detection and Monitoring for Swarm Drone Flights
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 24
SN  - 2076-3417

AB  - This paper addresses anomaly detection and monitoring for swarm drone flights. While the current practice of swarm flight typically relies on the operator&rsquo;s naked eyes to monitor health of the multiple vehicles, this work proposes a machine learning-based framework to enable detection of abnormal behavior of a large number of flying drones on the fly. The method works in two steps: a sequence of two unsupervised learning procedures reduces the dimensionality of the real flight test data and labels them as normal and abnormal cases; then, a deep neural network classifier with one-dimensional convolution layers followed by fully connected multi-layer perceptron extracts the associated features and distinguishes the anomaly from normal conditions. The proposed anomaly detection scheme is validated on the real flight test data, highlighting its capability of online implementation.
KW  - swarm drone
KW  - anomaly detection
KW  - clustering
KW  - labeling
KW  - classification
DO  - 10.3390/app9245477
ER  -
TY  - EJOU
AU  - Lucas, Carlos
AU  - Hernández-Sosa, Daniel
AU  - Greiner, David
AU  - Zamuda, Aleš
AU  - Caldeira, Rui
TI  - An Approach to Multi-Objective Path Planning Optimization for Underwater Gliders
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 24
SN  - 1424-8220

AB  - Underwater gliders are energy-efficient vehicles that rely on changes in buoyancy in order to convert up and down movement into forward displacement. These vehicles are conceived as multi-sensor platforms, and can be used to collect ocean data for long periods in wide range areas. This endurance is achieved at the cost of low speed, which requires extensive planning to ensure vehicle safety and mission success, particularly when dealing with strong ocean currents. As gliders are often involved on missions that pursue multiple objectives (track events, reach a target point, avoid obstacles, sample specified areas, save energy), path planning requires a way to deal with several constraints at the same time; this makes glider path planning a multi-objective (MO) optimization problem. In this work, we analyse the usage of the non-dominated sorting genetic algorithm II (NSGA-II) to tackle a MO glider path planning application on a complex environment integrating 3D and time varying ocean currents. Multiple experiments using a glider kinematic simulator coupled with NSGA-II, combining different control parameters were carried out, to find the best parameter configuration that provided suitable paths for the desired mission. Ultimately, the system described in this work was able to optimize multi-objective trajectories, providing non dominated solutions. Such a planning tool could be of great interest in real mission planning, to assist glider pilots in selecting the most convenient paths for the vehicle, taking into account ocean forecasts and particular characteristics of the deployment location.
KW  - multi-objective optimization
KW  - underwater glider
KW  - path planning
KW  - genetic algorithm
KW  - NSGA-II
DO  - 10.3390/s19245506
ER  -
TY  - EJOU
AU  - Yang, Shengtian
AU  - Wang, Juan
AU  - Wang, Pengfei
AU  - Gong, Tongliang
AU  - Liu, Huiping
TI  - Low Altitude Unmanned Aerial Vehicles (UAVs) and Satellite Remote Sensing Are Used to Calculated River Discharge Attenuation Coefficients of Ungauged Catchments in Arid Desert
T2  - Water

PY  - 2019
VL  - 11
IS  - 12
SN  - 2073-4441

AB  - The arid desert ecosystem is very fragile, and the change of its river discharge has a direct impact on irrigation and natural environment. River discharge attenuation coefficients is a key index to reveal the stability of desert river ecosystem. However, due to the harsh conditions in desert areas, it is difficult to establish a hydrological station to obtain data and calculate the attenuation coefficients, so it is urgent to develop new methods to master the attenuation coefficients of rivers. In this study, Taklamakan desert river was selected as the research area, and the river discharge of the desert river were estimated by combining low-altitude UAV and satellite remote sensing technology, so as to calculate the attenuation status of the river in its natural state. Combined with satellite remote sensing, the surface runoff in the desert reaches of the Hotan River from 1993 to 2017 were estimated. The results showed that the base of runoff attenuation in the lower reaches of the Hotan River is 40%. Coupled UAV and satellite remote sensing technology can provide technical support for the study of surface runoff in desert rivers within ungauged basins. Using UAV and satellite remote sensing can monitor surface runoff effectively providing important reference for river discharge monitoring in ungauged catchments.
KW  - desert river
KW  - attenuation coefficients
KW  - ungauged basin
KW  - unmanned aerial vehicle (UAV)
KW  - satellite remote sensing
DO  - 10.3390/w11122633
ER  -
TY  - EJOU
AU  - Chen, Yayong
AU  - Hou, Chaojun
AU  - Tang, Yu
AU  - Zhuang, Jiajun
AU  - Lin, Jintian
AU  - He, Yong
AU  - Guo, Qiwei
AU  - Zhong, Zhenyu
AU  - Lei, Huan
AU  - Luo, Shaoming
TI  - Citrus Tree Segmentation from UAV Images Based on Monocular Machine Vision in a Natural Orchard Environment
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 24
SN  - 1424-8220

AB  - The segmentation of citrus trees in a natural orchard environment is a key technology for achieving the fully autonomous operation of agricultural unmanned aerial vehicles (UAVs). Therefore, a tree segmentation method based on monocular machine vision technology and a support vector machine (SVM) algorithm are proposed in this paper to segment citrus trees precisely under different brightness and weed coverage conditions. To reduce the sensitivity to environmental brightness, a selective illumination histogram equalization method was developed to compensate for the illumination, thereby improving the brightness contrast for the foreground without changing its hue and saturation. To accurately differentiate fruit trees from different weed coverage backgrounds, a chromatic aberration segmentation algorithm and the Otsu threshold method were combined to extract potential fruit tree regions. Then, 14 color features, five statistical texture features, and local binary pattern features of those regions were calculated to establish an SVM segmentation model. The proposed method was verified on a dataset with different brightness and weed coverage conditions, and the results show that the citrus tree segmentation accuracy reached 85.27% &plusmn; 9.43%; thus, the proposed method achieved better performance than two similar methods.
KW  - agricultural unmanned aerial vehicles
KW  - monocular computer vision
KW  - tree crown segmentation
KW  - circumstance brightness
KW  - weed environment orchard
DO  - 10.3390/s19245558
ER  -
TY  - EJOU
AU  - Kocur-Bera, Katarzyna
AU  - Dawidowicz, Agnieszka
TI  - Land Use versus Land Cover: Geo-Analysis of National Roads and Synchronisation Algorithms
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 24
SN  - 2072-4292

AB  - Technological progress in Earth surface observation provides a vast range of information on the land and methods of its use. This enables property owners, users and administrators to monitor the state of the boundaries of the land they own/administer. The land cover, monitored directly on the ground, is not always consistent with the land use entered in the Land and Property Registry (LPR). Discrepancies between these data are often found in former communist countries. One of the reasons for this was the rapid process of land privatisation, which took place in Poland, without updating information on the plot geodetic boundaries. The study examined and compared the land use (entered in the LPR) with the land cover (on the ground) for national roads (acr. LU-LC). The most frequent discrepancies were selected, using CLC2018, digital orthophotomaps (using the Web Map Service (WMS) browsing service compliant with Open Geospatial Consortium (OGC) standards), cadastral data, statistical modelling and an updated survey of the right-of-way. Subsequently, six algorithms were proposed to synchronise the land use and land cover when the right-of-way was used by unauthorised persons, and two algorithms for cases of unauthorised use of land by the road administrator. Currently, it is difficult to synchronise the land cover with the land use from the administrative, legal and social points of view. The results of analyses show that full synchronisation of land use and land cover is complicated and time-consuming, although desired.
KW  - spatial analysis
KW  - updating data
KW  - land use/cover (acr. LU-LC)
KW  - cadastral data
KW  - synchronisation algorithms
DO  - 10.3390/rs11243053
ER  -
TY  - EJOU
AU  - Khan, Muhammad F.
AU  - Yau, Kok-Lim A.
AU  - Noor, Rafidah M.
AU  - Imran, Muhammad A.
TI  - Routing Schemes in FANETs: A Survey
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 1
SN  - 1424-8220

AB  - Flying ad hoc network (FANET) is a self-organizing wireless network that enables inexpensive, flexible, and easy-to-deploy flying nodes, such as unmanned aerial vehicles (UAVs), to communicate among themselves in the absence of fixed network infrastructure. FANET is one of the emerging networks that has an extensive range of next-generation applications. Hence, FANET plays a significant role in achieving application-based goals. Routing enables the flying nodes to collaborate and coordinate among themselves and to establish routes to radio access infrastructure, particularly FANET base station (BS). With a longer route lifetime, the effects of link disconnections and network partitions reduce. Routing must cater to two main characteristics of FANETs that reduce the route lifetime. Firstly, the collaboration nature requires the flying nodes to exchange messages and to coordinate among themselves, causing high energy consumption. Secondly, the mobility pattern of the flying nodes is highly dynamic in a three-dimensional space and they may be spaced far apart, causing link disconnection. In this paper, we present a comprehensive survey of the limited research work of routing schemes in FANETs. Different aspects, including objectives, challenges, routing metrics, characteristics, and performance measures, are covered. Furthermore, we present open issues.
KW  - ad hoc networks
KW  - FANETs
KW  - routing
KW  - network topology
DO  - 10.3390/s20010038
ER  -
TY  - EJOU
AU  - de Castro, Ana I.
AU  - Peña, José M.
AU  - Torres-Sánchez, Jorge
AU  - Jiménez-Brenes, Francisco M.
AU  - Valencia-Gredilla, Francisco
AU  - Recasens, Jordi
AU  - López-Granados, Francisca
TI  - Mapping Cynodon Dactylon Infesting Cover Crops with an Automatic Decision Tree-OBIA Procedure and UAV Imagery for Precision Viticulture
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 1
SN  - 2072-4292

AB  - The establishment and management of cover crops are common practices widely used in irrigated viticulture around the world, as they bring great benefits not only to protect and improve the soil, but also to control vine vigor and improve the yield quality, among others. However, these benefits are often reduced when cover crops are infested by Cynodon dactylon (bermudagrass), which impacts crop production due to its competition for water and nutrients and causes important economic losses for the winegrowers. Therefore, the discrimination of Cynodon dactylon in cover crops would enable site-specific control to be applied and thus drastically mitigate damage to the vineyard. In this context, this research proposes a novel, automatic and robust image analysis algorithm for the quick and accurate mapping of Cynodon dactylon growing in vineyard cover crops. The algorithm was developed using aerial images taken with an Unmanned Aerial Vehicle (UAV) and combined decision tree (DT) and object-based image analysis (OBIA) approaches. The relevance of this work consisted in dealing with the constraint caused by the spectral similarity of these complex scenarios formed by vines, cover crops, Cynodon dactylon, and bare soil. The incorporation of height information from the Digital Surface Model and several features selected by machine learning tools in the DT-OBIA algorithm solved this spectral similarity limitation and allowed the precise design of Cynodon dactylon maps. Another contribution of this work is the short time needed to apply the full process from UAV flights to image analysis, which can enable useful maps to be created on demand (within two days of the farmer&acute;s request) and is thus timely for controlling Cynodon dactylon in the herbicide application window. Therefore, this combination of UAV imagery and a DT-OBIA algorithm would allow winegrowers to apply site-specific control of Cynodon dactylon and maintain cover crop-based management systems and their consequent benefits in the vineyards, and also comply with the European legal framework for the sustainable use of agricultural inputs and implementation of integrated crop management.
KW  - site-specific weed management
KW  - object-based image analysis (OBIA)
KW  - bermudagrass
KW  - vineyard
KW  - vegetation mapping
KW  - unmanned aerial vehicle
KW  - machine learning
DO  - 10.3390/rs12010056
ER  -
TY  - EJOU
AU  - Zollini, Sara
AU  - Alicandro, Maria
AU  - Cuevas-González, María
AU  - Baiocchi, Valerio
AU  - Dominici, Donatella
AU  - Buscema, Paolo M.
TI  - Shoreline Extraction Based on an Active Connection Matrix (ACM) Image Enhancement Strategy
T2  - Journal of Marine Science and Engineering

PY  - 2020
VL  - 8
IS  - 1
SN  - 2077-1312

AB  - Coastal environments are facing constant changes over time due to their dynamic nature and geological, geomorphological, hydrodynamic, biological, climatic and anthropogenic factors. For these reasons, the monitoring of these areas is crucial for the safeguarding of the cultural heritage and the populations living there. The focus of this paper is shoreline extraction by means of an experimental algorithm, called J-Net Dynamic (Semeion Research Center of Sciences of Communication, Rome, Italy). It was tested on two types of image: a very high resolution (VHR) multispectral image (WorldView-2) and a high resolution (HR) radar synthetic aperture radar (SAR) image (Sentinel-1). The extracted shorelines were compared with those manually digitized for both images independently. The results obtained with the J-Net Dynamic algorithm were also compared with common algorithms, widely used in the literature, including the WorldView water index and the Canny edge detector. The results show that the experimental algorithm is more effective than the others, as it improves shoreline extraction accuracy both in the optical and SAR images.
KW  - remote sensing
KW  - satellite images
KW  - synthetic aperture radar (SAR)
KW  - Sentinel-1
KW  - WorldView-2
KW  - shoreline extraction
KW  - coastline extraction
KW  - active connection matrix (ACM)
KW  - J-Net Dynamic
KW  - edge detection
KW  - canny edge detector
DO  - 10.3390/jmse8010009
ER  -
TY  - EJOU
AU  - Li, Hongjun
AU  - Zhang, Yuming
AU  - Lei, Yuping
AU  - Antoniuk, Vita
AU  - Hu, Chunsheng
TI  - Evaluating Different Non-Destructive Estimation Methods for Winter Wheat (Triticum aestivum L.) Nitrogen Status Based on Canopy Spectrum
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 1
SN  - 2072-4292

AB  - Compared to conventional laboratory testing methods, crop nitrogen estimation methods based on canopy spectral characteristics have advantages in terms of timeliness, cost, and practicality. A variety of rapid and non-destructive estimation methods based on the canopy spectrum have been developed on the scale of space, sky, and ground. In order to understand the differences in estimation accuracy and applicability of these methods, as well as for the convenience of users to select the suitable technology, models for estimation of nitrogen status of winter wheat were developed and compared for three methods: drone equipped with a multispectral camera, soil plant analysis development (SPAD) chlorophyll meter, and smartphone photography. Based on the correlations between observed nitrogen status in winter wheat and related vegetation indices, green normalized difference vegetation index (GNDVI) and visible atmospherically resistant index (VARI) were selected as the sensitive vegetation indices for the drone equipped with a multispectral camera and smartphone photography methods, respectively. The correlation coefficients between GNDVI, SPAD, and VARI were 0.92 ** and 0.89 **, and that between SPAD and VARI was 0.90 **, which indicated that three vegetation indices for these three estimation methods were significantly related to each other. The determination coefficients of the 0&ndash;90 cm soil nitrate nitrogen content estimation models for the drone equipped with a multispectral camera, SPAD, and smartphone photography methods were 0.63, 0.54, and 0.81, respectively. In the estimation accuracy evaluation, the method of smartphone photography had the smallest root mean square error (RMSE = 9.80 mg/kg). The accuracy of the smartphone photography method was slightly higher than the other two methods. Due to the limitations of these models, it was found that the crop nitrogen estimation methods based on canopy spectrum were not suitable for the crops under severe phosphate deficiency. In addition, in estimation of soil nitrate nitrogen content, there were saturation responses in the estimation indicators of the three methods. In order to introduce these three methods in the precise management of nitrogen fertilizer, it is necessary to further improve their estimation models.
KW  - canopy spectrum
KW  - non-destructive nitrogen status diagnosis
KW  - drone
KW  - multispectral camera
KW  - SPAD
KW  - smartphone photography
DO  - 10.3390/rs12010095
ER  -
TY  - EJOU
AU  - He, Qimin
AU  - Zhang, Kefei
AU  - Wu, Suqin
AU  - Zhao, Qingzhi
AU  - Wang, Xiaoming
AU  - Shen, Zhen
AU  - Li, Longjiang
AU  - Wan, Moufeng
AU  - Liu, Xiaoyang
TI  - Real-Time GNSS-Derived PWV for Typhoon Characterizations: A Case Study for Super Typhoon Mangkhut in Hong Kong
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 1
SN  - 2072-4292

AB  - Typhoons can be serious natural disasters for the sustainability and development of society. The development of a typhoon usually involves a pre-existing weather disturbance, warm tropical oceans, and a large amount of moisture. This implies that a large variation in the atmospheric water vapor over the path of a typhoon can be used to study the characteristics of the typhoon. This is the reason that the variation in precipitable water vapor (PWV) is often used to capture the signature of a typhoon in meteorology. This study investigates the usability of real-time PWV retrieved from global navigation satellite systems (GNSS) for typhoons&rsquo; characterizations, and especially, the following aspects were investigated: (1) The correlation between PWV and atmospheric parameters including pressure, temperature, precipitation, and wind speed; (2) water vapor transportation during a typhoon period; and (3) the correlation between the movement of a typhoon and the transportation of water vapor. The case study selected for this research was Super Typhoon Mangkhut that occurred in mid-September 2018 in Hong Kong. The PWV time series were obtained from a conversion of GNSS-derived zenith total delays (ZTDs) using observations at 10 stations selected from the Hong Kong GNSS continuously operating reference stations (CORS) network, which are also located along the path of the typhoon. The Bernese GNSS Software (ver. 5.2) was used to obtain the ZTDs; and the root mean square (RMS) of the differences between the GNSS-ZTDs and International GNSS Service post-processed ZTDs time series was less than 8 mm. The RMS of the differences between the GNSS-PWVs (i.e., the ZTDs converted PWVs) and radiosonde-derived PWVs (RS-PWVs) time series was less than 2 mm. The changes in PWV reflect the variation in wind speed during the typhoon period to a certain degree, and their correlation coefficient was 0.76, meaning a significant positive correlation. In addition, a new approach was proposed to estimate the direction and speed of a typhoon&rsquo;s movement using the time difference of PWV arrival at different sites. The direction and speed estimated agreed well with the ones published by the China Meteorological Administration. These results suggest that GNSS-derived PWV has a great potential for the monitoring and even prediction of typhoon events, especially for near real-time warnings.
KW  - typhoon
KW  - global navigation satellite systems
KW  - precipitable water vapor
KW  - radiosonde
KW  - Super Typhoon Mangkhut
DO  - 10.3390/rs12010104
ER  -
TY  - EJOU
AU  - Wijesingha, Jayan
AU  - Astor, Thomas
AU  - Schulze-Brüninghoff, Damian
AU  - Wengert, Matthias
AU  - Wachendorf, Michael
TI  - Predicting Forage Quality of Grasslands Using UAV-Borne Imaging Spectroscopy
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 1
SN  - 2072-4292

AB  - The timely knowledge of forage quality of grasslands is vital for matching the demands in animal feeding. Remote sensing (RS) is a promising tool for estimating field-scale forage quality compared with traditional methods, which usually do not provide equally detailed information. However, the applicability of RS prediction models depends on the variability of the underlying calibration data, which can be brought about by the inclusion of a multitude of grassland types and management practices in the model development. Major aims of this study were (i) to build forage quality estimation models for multiple grassland types based on an unmanned aerial vehicle (UAV)-borne imaging spectroscopy and (ii) to generate forage quality distribution maps using the best models obtained. The study examined data from eight grasslands in northern Hesse, Germany, which largely differed in terms of vegetation type and cutting regime. The UAV with a hyperspectral camera on board was utilised to acquire spectral images from the grasslands, and crude protein (CP) and acid detergent fibre (ADF) concentration of the forage was assessed at each cut. Five predictive modelling regression algorithms were applied to develop quality estimation models. Further, grassland forage quality distribution maps were created using the best models developed. The normalised spectral reflectance data showed the strongest relationship with both CP and ADF concentration. From all predictive algorithms, support vector regression provided the highest precision and accuracy for CP estimation (median normalised root mean square error prediction (nRMSEp) = 10.6%), while cubist regression model proved best for ADF estimation (median nRMSEp = 13.4%). The maps generated for both CP and ADF showed a distinct spatial variation in forage quality values for the different grasslands and cutting regimes. Overall, the results disclose that UAV-borne imaging spectroscopy, in combination with predictive modelling, provides a promising tool for accurate forage quality estimation of multiple grasslands.
KW  - unmanned aerial vehicle
KW  - hyperspectral
KW  - grassland
KW  - crude protein
KW  - acid detergent fibre
KW  - predictive modelling
DO  - 10.3390/rs12010126
ER  -
TY  - EJOU
AU  - Dong, Xinyu
AU  - Zhang, Zhichao
AU  - Yu, Ruiyang
AU  - Tian, Qingjiu
AU  - Zhu, Xicun
TI  - Extraction of Information about Individual Trees from High-Spatial-Resolution UAV-Acquired Images of an Orchard
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 1
SN  - 2072-4292

AB  - The extraction of information about individual trees is essential to supporting the growing of fruit in orchard management. Data acquired from spectral sensors mounted on unmanned aerial vehicles (UAVs) have very high spatial and temporal resolution. However, an efficient and reliable method for extracting information about individual trees with irregular tree-crown shapes and a complicated background is lacking. In this study, we developed and tested the performance of an approach, based on UAV imagery, to extracting information about individual trees in an orchard with a complicated background that includes apple trees (Plot 1) and pear trees (Plot 2). The workflow involves the construction of a digital orthophoto map (DOM), digital surface models (DSMs), and digital terrain models (DTMs) using the Structure from Motion (SfM) and Multi-View Stereo (MVS) approaches, as well as the calculation of the Excess Green minus Excess Red Index (ExGR) and the selection of various thresholds. Furthermore, a local-maxima filter method and marker-controlled watershed segmentation were used for the detection and delineation, respectively, of individual trees. The accuracy of the proposed method was evaluated by comparing its results with manual estimates of the numbers of trees and the areas and diameters of tree-crowns, all three of which parameters were obtained from the DOM. The results of the proposed method are in good agreement with these manual estimates: The F-scores for the estimated numbers of individual trees were 99.0% and 99.3% in Plot 1 and Plot 2, respectively, while the Producer&rsquo;s Accuracy (PA) and User&rsquo;s Accuracy (UA) for the delineation of individual tree-crowns were above 95% for both of the plots. For the area of individual tree-crowns, root-mean-square error (RMSE) values of 0.72 m2 and 0.48 m2 were obtained for Plot 1 and Plot 2, respectively, while for the diameter of individual tree-crowns, RMSE values of 0.39 m and 0.26 m were obtained for Plot 1 (339 trees correctly identified) and Plot 2 (203 trees correctly identified), respectively. Both the areas and diameters of individual tree-crowns were overestimated to varying degrees.
KW  - fruit tree growing
KW  - orchard
KW  - image processing
KW  - remote sensing
KW  - unmanned aerial vehicles
KW  - digital height model
KW  - image segmentation
DO  - 10.3390/rs12010133
ER  -
TY  - EJOU
AU  - Li, Yaxin
AU  - Li, Wenbin
AU  - Tang, Shengjun
AU  - Darwish, Walid
AU  - Hu, Yuling
AU  - Chen, Wu
TI  - Automatic Indoor as-Built Building Information Models Generation by Using Low-Cost RGB-D Sensors
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 1
SN  - 1424-8220

AB  - To generate indoor as-built building information models (AB BIMs) automatically and economically is a great technological challenge. Many approaches have been developed to address this problem in recent years, but it is far from being settled, particularly for the point cloud segmentation and the extraction of the relationship among different elements due to the complicated indoor environment. This is even more difficult for the low-quality point cloud generated by low-cost scanning equipment. This paper proposes an automatic as-built BIMs generation framework that transforms the noisy 3D point cloud produced by a low-cost RGB-D sensor (about 708 USD for data collection equipment, 379 USD for the Structure sensor and 329 USD for iPad) to the as-built BIMs, without any manual intervention. The experiment results show that the proposed method has competitive robustness and accuracy, compared to the high-quality Terrestrial Lidar System (TLS), with the element extraction accuracy of 100%, mean dimension reconstruction accuracy of 98.6% and mean area reconstruction accuracy of 93.6%. Also, the proposed framework makes the BIM generation workflows more efficient in both data collection and data processing. In the experiments, the time consumption of data collection for a typical room, with an area of 45&ndash;67      m 2     , is reduced to 4&ndash;6 min with an RGB-D sensor from 50&ndash;60 min with TLS. The processing time to generate BIM models is about half minutes automatically, from around 10 min with a conventional semi-manual method.
KW  - as-built BIMs
KW  - automatic
KW  - RGB-D sensors
DO  - 10.3390/s20010293
ER  -
TY  - EJOU
AU  - Tang, Wei
AU  - Wang, Lijian
AU  - Gu, Jiawei
AU  - Gu, Yunfeng
TI  - Single Neural Adaptive PID Control for Small UAV Micro-Turbojet Engine
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 2
SN  - 1424-8220

AB  - The micro-turbojet engine (MTE) is especially suitable for unmanned aerial vehicles (UAVs). Because the rotor speed is proportional to the thrust force, the accurate speed tracking control is indispensable for MTE. Thanks to its simplicity, the proportional&ndash;integral&ndash;derivative (PID) controller is commonly used for rotor speed regulation. However, the PID controller cannot guarantee superior performance over the entire operation range due to the time-variance and strong nonlinearity of MTE. The gain scheduling approach using a family of linear controllers is recognized as an efficient alternative, but such a solution heavily relies on the model sets and pre-knowledge. To tackle such challenges, a single neural adaptive PID (SNA-PID) controller is proposed herein for rotor speed control. The new controller featuring with a single-neuron network is able to adaptively tune the gains (weights) online. The simple structure of the controller reduces the computational load and facilitates the algorithm implementation on low-cost hardware. Finally, the proposed controller is validated by numerical simulations and experiments on the MTE in laboratory conditions, and the results show that the proposed controller achieves remarkable effectiveness for speed tracking control. In comparison with the PID controller, the proposed controller yields 54% and 66% reductions on static tracking error under two typical cases.
KW  - micro-turbojet engine
KW  - neural networks
KW  - adaptive control
KW  - PID
DO  - 10.3390/s20020345
ER  -
TY  - EJOU
AU  - Zha, Hainie
AU  - Miao, Yuxin
AU  - Wang, Tiantian
AU  - Li, Yue
AU  - Zhang, Jing
AU  - Sun, Weichao
AU  - Feng, Zhengqi
AU  - Kusnierek, Krzysztof
TI  - Improving Unmanned Aerial Vehicle Remote Sensing-Based Rice Nitrogen Nutrition Index Prediction with Machine Learning
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 2
SN  - 2072-4292

AB  - Optimizing nitrogen (N) management in rice is crucial for China&rsquo;s food security and sustainable agricultural development. Nondestructive crop growth monitoring based on remote sensing technologies can accurately assess crop N status, which may be used to guide the in-season site-specific N recommendations. The fixed-wing unmanned aerial vehicle (UAV)-based remote sensing is a low-cost, easy-to-operate technology for collecting spectral reflectance imagery, an important data source for precision N management. The relationships between many vegetation indices (VIs) derived from spectral reflectance data and crop parameters are known to be nonlinear. As a result, nonlinear machine learning methods have the potential to improve the estimation accuracy. The objective of this study was to evaluate five different approaches for estimating rice (Oryza sativa L.) aboveground biomass (AGB), plant N uptake (PNU), and N nutrition index (NNI) at stem elongation (SE) and heading (HD) stages in Northeast China: (1) single VI (SVI); (2) stepwise multiple linear regression (SMLR); (3) random forest (RF); (4) support vector machine (SVM); and (5) artificial neural networks (ANN) regression. The results indicated that machine learning methods improved the NNI estimation compared to VI-SLR and SMLR methods. The RF algorithm performed the best for estimating NNI (R2 = 0.94 (SE) and 0.96 (HD) for calibration and 0.61 (SE) and 0.79 (HD) for validation). The root mean square errors (RMSEs) were 0.09, and the relative errors were &lt;10% in all the models. It is concluded that the RF machine learning regression can significantly improve the estimation of rice N status using UAV remote sensing. The application machine learning methods offers a new opportunity to better use remote sensing data for monitoring crop growth conditions and guiding precision crop management. More studies are needed to further improve these machine learning-based models by combining both remote sensing data and other related soil, weather, and management information for applications in precision N and crop management.
KW  - fixed-wing UAV remote sensing
KW  - nitrogen status diagnosis
KW  - random forest
KW  - precision nitrogen management
KW  - machine learning
DO  - 10.3390/rs12020215
ER  -
TY  - EJOU
AU  - Zhang, Xiuwei
AU  - Jin, Jiaojiao
AU  - Lan, Zeze
AU  - Li, Chunjiang
AU  - Fan, Minhao
AU  - Wang, Yafei
AU  - Yu, Xin
AU  - Zhang, Yanning
TI  - ICENET: A Semantic Segmentation Deep Network for River Ice by Fusing Positional and Channel-Wise Attentive Features
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 2
SN  - 2072-4292

AB  - River ice monitoring is of great significance for river management, ship navigation and ice hazard forecasting in cold-regions. Accurate ice segmentation is one most important pieces of technology in ice monitoring research. It can provide the prerequisite information for the calculation of ice cover density, drift ice speed, ice cover distribution, change detection and so on. Unmanned aerial vehicle (UAV) aerial photography has the advantages of higher spatial and temporal resolution. As UAV technology has become more popular and cheaper, it has been widely used in ice monitoring. So, we focused on river ice segmentation based on UAV remote sensing images. In this study, the NWPU_YRCC dataset was built for river ice segmentation, in which all images were captured by different UAVs in the region of the Yellow River, the most difficult river to manage in the world. To the best of our knowledge, this is the first public UAV image dataset for river ice segmentation. Meanwhile, a semantic segmentation deep convolution neural network by fusing positional and channel-wise attentive features is proposed for river ice semantic segmentation, named ICENET. Experiments demonstrated that the proposed ICENET outperforms the state-of-the-art methods, achieving a superior result on the NWPU_YRCC dataset.
KW  - river ice
KW  - position attention
KW  - channel-wise attention
KW  - deep convolutional neural network
KW  - semantic segmentation
DO  - 10.3390/rs12020221
ER  -
TY  - EJOU
AU  - Wang, Ju
AU  - Wang, Guoqiang
AU  - Hu, Xiaoxuan
AU  - Luo, He
AU  - Xu, Haiqing
TI  - Cooperative Transmission Tower Inspection with a Vehicle and a UAV in Urban Areas
T2  - Energies

PY  - 2020
VL  - 13
IS  - 2
SN  - 1996-1073

AB  - To reduce the workload of inspectors and improve the inspection efficiency of urban transmission towers, a new inspection method is proposed in this paper, in which an unmanned aerial vehicle (UAV) and vehicle cooperate with each other. We investigate the cooperative path planning problem of a UAV and a vehicle for transmission tower inspection and develop a new 0&ndash;1 integer programming model to address the problem. An odd-even layered genetic algorithm (O-ELGA) is proposed to efficiently solve the model. Finally, the effectiveness of the algorithm is further verified by simulation experiments.
KW  - vehicle-carried UAV
KW  - TSP-D
KW  - transmission tower inspection
KW  - path planning
KW  - genetic algorithm
DO  - 10.3390/en13020326
ER  -
TY  - EJOU
AU  - Senthilnath, J.
AU  - Varia, Neelanshi
AU  - Dokania, Akanksha
AU  - Anand, Gaotham
AU  - Benediktsson, Jón A.
TI  - Deep TEC: Deep Transfer Learning with Ensemble Classifier for Road Extraction from UAV Imagery
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 2
SN  - 2072-4292

AB  - Unmanned aerial vehicle (UAV) remote sensing has a wide area of applications and in this paper, we attempt to address one such problem&mdash;road extraction from UAV-captured RGB images. The key challenge here is to solve the road extraction problem using the UAV multiple remote sensing scene datasets that are acquired with different sensors over different locations. We aim to extract the knowledge from a dataset that is available in the literature and apply this extracted knowledge on our dataset. The paper focuses on a novel method which consists of deep TEC (deep transfer learning with ensemble classifier) for road extraction using UAV imagery. The proposed deep TEC performs road extraction on UAV imagery in two stages, namely, deep transfer learning and ensemble classifier. In the first stage, with the help of deep learning methods, namely, the conditional generative adversarial network, the cycle generative adversarial network and the fully convolutional network, the model is pre-trained on the benchmark UAV road extraction dataset that is available in the literature. With this extracted knowledge (based on the pre-trained model) the road regions are then extracted on our UAV acquired images. Finally, for the road classified images, ensemble classification is carried out. In particular, the deep TEC method has an average quality of 71%, which is 10% higher than the next best standard deep learning methods. Deep TEC also shows a higher level of performance measures such as completeness, correctness and F1 score measures. Therefore, the obtained results show that the deep TEC is efficient in extracting road networks in an urban region.
KW  - UAV
KW  - remote sensing
KW  - road extraction
KW  - deep learning
KW  - transfer learning
KW  - ensemble classifier
DO  - 10.3390/rs12020245
ER  -
TY  - EJOU
AU  - González-Patiño, David
AU  - Villuendas-Rey, Yenny
AU  - Argüelles-Cruz, Amadeo J.
AU  - Camacho-Nieto, Oscar
AU  - Yáñez-Márquez, Cornelio
TI  - AISAC: An Artificial Immune System for Associative Classification Applied to Breast Cancer Detection
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 2
SN  - 2076-3417

AB  - Early breast cancer diagnosis is crucial, as it can prevent further complications and save the life of the patient by treating the disease at its most curable stage. In this paper, we propose a new artificial immune system model for associative classification with competitive performance for breast cancer detection. The proposed model has its foundations in the biological immune system; it mimics the detection skills of the immune system to provide correct identification of antigens. The Wilcoxon test was used to identify the statistically significant differences between our proposal and other classification algorithms based on the same bio-inspired model. These statistical tests evidenced the enhanced performance shown by the proposed model by outperforming other immune-based algorithms. The proposed model proved to be competitive with respect to other well-known classification models. In addition, the model benefits from a low computational cost. The success of this model for classification tasks shows that swarm intelligence is useful for this kind of problem, and that it is not limited to optimization tasks.
KW  - swarm intelligence
KW  - artificial immune systems
KW  - classification
KW  - breast cancer
DO  - 10.3390/app10020515
ER  -
TY  - EJOU
AU  - Rokhsaritalemi, Somaiieh
AU  - Sadeghi-Niaraki, Abolghasem
AU  - Choi, Soo-Mi
TI  - A Review on Mixed Reality: Current Trends, Challenges and Prospects
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 2
SN  - 2076-3417

AB  - Currently, new technologies have enabled the design of smart applications that are used as decision-making tools in the problems of daily life. The key issue in designing such an application is the increasing level of user interaction. Mixed reality (MR) is an emerging technology that deals with maximum user interaction in the real world compared to other similar technologies. Developing an MR application is complicated, and depends on the different components that have been addressed in previous literature. In addition to the extraction of such components, a comprehensive study that presents a generic framework comprising all components required to develop MR applications needs to be performed. This review studies intensive research to obtain a comprehensive framework for MR applications. The suggested framework comprises five layers: the first layer considers system components; the second and third layers focus on architectural issues for component integration; the fourth layer is the application layer that executes the architecture; and the fifth layer is the user interface layer that enables user interaction. The merits of this study are as follows: this review can act as a proper resource for MR basic concepts, and it introduces MR development steps and analytical models, a simulation toolkit, system types, and architecture types, in addition to practical issues for stakeholders such as considering MR different domains.
KW  - mixed reality
KW  - review
KW  - trend
KW  - challenge
KW  - future prospect
DO  - 10.3390/app10020636
ER  -
TY  - EJOU
AU  - Jung, Daekyo
AU  - Tran Tuan, Vu
AU  - Quoc Tran, Dai
AU  - Park, Minsoo
AU  - Park, Seunghee
TI  - Conceptual Framework of an Intelligent Decision Support System for Smart City Disaster Management
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 2
SN  - 2076-3417

AB  - In order to protect human lives and infrastructure, as well as to minimize the risk of damage, it is important to predict and respond to natural disasters in advance. However, currently, the standardized disaster response system in South Korea still needs further advancement, and the response phase systems need to be improved to ensure that they are properly equipped to cope with natural disasters. Existing studies on intelligent disaster management systems (IDSSs) in South Korea have focused only on storms, floods, and earthquakes, and they have not used past data. This research proposes a new conceptual framework of an IDSS for disaster management, with particular attention paid to wildfires and cold/heat waves. The IDSS uses big data collected from open application programming interface (API) and artificial intelligence (AI) algorithms to help decision-makers make faster and more accurate decisions. In addition, a simple example of the use of a convolutional neural network (CNN) to detect fire in surveillance video has been developed, which can be used for automatic fire detection and provide an appropriate response. The system will also consider connecting to open source intelligence (OSINT) to identify vulnerabilities, mitigate risks, and develop more robust security policies than those currently in place to prevent cyber-attacks.
KW  - decision support system
KW  - big data
KW  - artificial intelligence
KW  - Internet of Things
KW  - disaster management
DO  - 10.3390/app10020666
ER  -
TY  - EJOU
AU  - Zha, Yufei
AU  - Wu, Min
AU  - Qiu, Zhuling
AU  - Sun, Jingxian
AU  - Zhang, Peng
AU  - Huang, Wei
TI  - Online Semantic Subspace Learning with Siamese Network for UAV Tracking
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 2
SN  - 2072-4292

AB  - In urban environment monitoring, visual tracking on unmanned aerial vehicles (UAVs) can produce more applications owing to the inherent advantages, but it also brings new challenges for existing visual tracking approaches (such as complex background clutters, rotation, fast motion, small objects, and realtime issues due to camera motion and viewpoint changes). Based on the Siamese network, tracking can be conducted efficiently in recent UAV datasets. Unfortunately, the learned convolutional neural network (CNN) features are not discriminative when identifying the target from the background/clutter, In particular for the distractor, and cannot capture the appearance variations temporally. Additionally, occlusion and disappearance are also reasons for tracking failure. In this paper, a semantic subspace module is designed to be integrated into the Siamese network tracker to encode the local fine-grained details of the target for UAV tracking. More specifically, the target&rsquo;s semantic subspace is learned online to adapt to the target in the temporal domain. Additionally, the pixel-wise response of the semantic subspace can be used to detect occlusion and disappearance of the target, and this enables reasonable updating to relieve model drifting. Substantial experiments conducted on challenging UAV benchmarks illustrate that the proposed method can obtain competitive results in both accuracy and efficiency when they are applied to UAV videos.
KW  - UAV tracking
KW  - semantic subspace
KW  - siamese network
KW  - occlusion detection
DO  - 10.3390/rs12020325
ER  -
TY  - EJOU
AU  - Lobo Torres, Daliana
AU  - Queiroz Feitosa, Raul
AU  - Nigri Happ, Patrick
AU  - Elena Cué La Rosa, Laura
AU  - Marcato Junior, José
AU  - Martins, José
AU  - Olã Bressan, Patrik
AU  - Gonçalves, Wesley N.
AU  - Liesenberg, Veraldo
TI  - Applying Fully Convolutional Architectures for Semantic Segmentation of a Single Tree Species in Urban Environment on High Resolution UAV Optical Imagery
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 2
SN  - 1424-8220

AB  - This study proposes and evaluates five deep fully convolutional networks (FCNs) for the semantic segmentation of a single tree species: SegNet, U-Net, FC-DenseNet, and two DeepLabv3+ variants. The performance of the FCN designs is evaluated experimentally in terms of classification accuracy and computational load. We also verify the benefits of fully connected conditional random fields (CRFs) as a post-processing step to improve the segmentation maps. The analysis is conducted on a set of images captured by an RGB camera aboard a UAV flying over an urban area. The dataset also contains a mask that indicates the occurrence of an endangered species called Dipteryx alata Vogel, also known as cumbaru, taken as the species to be identified. The experimental analysis shows the effectiveness of each design and reports average overall accuracy ranging from 88.9% to 96.7%, an F1-score between 87.0% and 96.1%, and IoU from 77.1% to 92.5%. We also realize that CRF consistently improves the performance, but at a high computational cost.
KW  - deep learning
KW  - fully convolution neural networks
KW  - semantic segmentation
KW  - unmanned aerial vehicle (UAV)
DO  - 10.3390/s20020563
ER  -
TY  - EJOU
AU  - Zhang, Yishan
AU  - Wu, Lun
AU  - Ren, Huazhong
AU  - Liu, Yu
AU  - Zheng, Yongqian
AU  - Liu, Yaowen
AU  - Dong, Jiaji
TI  - Mapping Water Quality Parameters in Urban Rivers from Hyperspectral Images Using a New Self-Adapting Selection of Multiple Artificial Neural Networks
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 2
SN  - 2072-4292

AB  - Protection of water environments is an important part of overall environmental protection; hence, many people devote their efforts to monitoring and improving water quality. In this study, a self-adapting selection method of multiple artificial neural networks (ANNs) using hyperspectral remote sensing and ground-measured water quality data is proposed to quantitatively predict water quality parameters, including phosphorus, nitrogen, biochemical oxygen demand (BOD), chemical oxygen demand (COD), and chlorophyll a. Seventy-nine ground measured data samples are used as training data in the establishment of the proposed model, and 30 samples are used as testing data. The proposed method based on traditional ANNs of numerical prediction involves feature selection of bands, self-adapting selection based on multiple selection criteria, stepwise backtracking, and combined weighted correlation. Water quality parameters are estimated with coefficient of determination      R 2      ranging from 0.93 (phosphorus) to 0.98 (nitrogen), which is higher than the value (0.7 to 0.8) obtained by traditional ANNs. MPAE (mean percent of absolute error) values ranging from 5% to 11% are used rather than root mean square error to evaluate the predicting precision of the proposed model because the magnitude of each water quality parameter considerably differs, thereby providing reasonable and interpretable results. Compared with other ANNs with backpropagation, this study proposes an auto-adapting method assisted by the above-mentioned methods to select the best model with all settings, such as the number of hidden layers, number of neurons in each hidden layer, choice of optimizer, and activation function. Different settings for ANNS with backpropagation are important to improve precision and compatibility for different data. Furthermore, the proposed method is applied to hyperspectral remote sensing images collected using an unmanned aerial vehicle for monitoring the water quality in the Shiqi River, Zhongshan City, Guangdong Province, China. Obtained results indicate the locations of pollution sources.
KW  - self-adapting
KW  - deep learning
KW  - multiple neural network
KW  - hyperspectral image
KW  - water quality monitoring
DO  - 10.3390/rs12020336
ER  -
TY  - EJOU
AU  - Tian, Ai-Qing
AU  - Chu, Shu-Chuan
AU  - Pan, Jeng-Shyang
AU  - Cui, Huanqing
AU  - Zheng, Wei-Min
TI  - A Compact Pigeon-Inspired Optimization for Maximum Short-Term Generation Mode in Cascade Hydroelectric Power Station
T2  - Sustainability

PY  - 2020
VL  - 12
IS  - 3
SN  - 2071-1050

AB  - Pigeon-inspired optimization (PIO) is a new type of intelligent algorithm. It is proposed that the algorithm simulates the movement of pigeons going home. In this paper, a new pigeon herding algorithm called compact pigeon-inspired optimization (CPIO) is proposed. The challenging task for multiple algorithms is not only combining operations, but also constraining existing devices. The proposed algorithm aims to solve complex scientific and industrial problems with many data packets, including the use of classical optimization problems and the ability to find optimal solutions in many solution spaces with limited hardware resources. A real-valued prototype vector performs probability and statistical calculations, and then generates optimal candidate solutions for CPIO optimization algorithms. The CPIO algorithm was used to evaluate a variety of continuous multi-model functions and the largest model of hydropower short-term generation. The experimental results show that the proposed algorithm is a more effective way to produce competitive results in the case of limited memory devices.
KW  - compact pigeon-inspired optimization
KW  - maximum short-term generation
KW  - swarm intelligence
KW  - hydroelectric power station
DO  - 10.3390/su12030767
ER  -
TY  - EJOU
AU  - Alganci, Ugur
AU  - Soydas, Mehmet
AU  - Sertel, Elif
TI  - Comparative Research on Deep Learning Approaches for Airplane Detection from Very High-Resolution Satellite Images
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 3
SN  - 2072-4292

AB  - Object detection from satellite images has been a challenging problem for many years. With the development of effective deep learning algorithms and advancement in hardware systems, higher accuracies have been achieved in the detection of various objects from very high-resolution (VHR) satellite images. This article provides a comparative evaluation of the state-of-the-art convolutional neural network (CNN)-based object detection models, which are Faster R-CNN, Single Shot Multi-box Detector (SSD), and You Look Only Once-v3 (YOLO-v3), to cope with the limited number of labeled data and to automatically detect airplanes in VHR satellite images. Data augmentation with rotation, rescaling, and cropping was applied on the test images to artificially increase the number of training data from satellite images. Moreover, a non-maximum suppression algorithm (NMS) was introduced at the end of the SSD and YOLO-v3 flows to get rid of the multiple detection occurrences near each detected object in the overlapping areas. The trained networks were applied to five independent VHR test images that cover airports and their surroundings to evaluate their performance objectively. Accuracy assessment results of the test regions proved that Faster R-CNN architecture provided the highest accuracy according to the F1 scores, average precision (AP) metrics, and visual inspection of the results. The YOLO-v3 ranked as second, with a slightly lower performance but providing a balanced trade-off between accuracy and speed. The SSD provided the lowest detection performance, but it was better in object localization. The results were also evaluated in terms of the object size and detection accuracy manner, which proved that large- and medium-sized airplanes were detected with higher accuracy.
KW  - convolutional neural networks (CNNs)
KW  - end-to-end detection
KW  - transfer learning
KW  - remote sensing
KW  - single shot multi-box detector (SSD)
KW  - You Look Only Once-v3 (YOLO-v3)
KW  - Faster RCNN
DO  - 10.3390/rs12030458
ER  -
TY  - EJOU
AU  - Xiao, Qinggang
AU  - Du, Rui
AU  - Yang, Lin
AU  - Han, Xiaoqiang
AU  - Zhao, Sifeng
AU  - Zhang, Guoqiang
AU  - Fu, Wei
AU  - Wang, Guobin
AU  - Lan, Yubin
TI  - Comparison of Droplet Deposition Control Efficacy on Phytophthora capsica and Aphids in the Processing Pepper Field of the Unmanned Aerial Vehicle and Knapsack Sprayer
T2  - Agronomy

PY  - 2020
VL  - 10
IS  - 2
SN  - 2073-4395

AB  - Processing pepper planting and processing have become an important red pillar industry in Xinjiang. With the continuous growth of processing pepper planting areas in Xinjiang, diseases and pests are increasing year by year. The aim of this study was to compare the droplet deposition and control efficiency of unmanned aerial vehicle (UAV) and electric air-pressure knapsack (EAP) sprayers on a processing pepper field. The UAV sprayer had a poor droplet coverage rate, droplet density, and deposition uniformity, but displayed the best deposition (1.01 &mu;g/cm2, which was 98% more than the EAP sprayer). The control efficacy of the UAV sprayer on processing pepper fields with Phytophthora capsici and aphids was slightly lower than that of the EAP sprayer. When the UAV sprayer was used to control processing pepper diseases and pests, it could reduce the pesticide dosage on the premise of ensuring the control effect. Further study of the residue of high concentration pesticides in pepper fruit and environment sprayed by UAVs are needed.
KW  - unmanned aerial vehicle
KW  - processing pepper
KW  - droplets deposition
KW  - Phytophthora capsici and aphids
KW  - control efficiency
DO  - 10.3390/agronomy10020215
ER  -
TY  - EJOU
AU  - Hao, Yuzhu
AU  - Chen, Zhenjie
AU  - Huang, Qiuhao
AU  - Li, Feixue
AU  - Wang, Beibei
AU  - Ma, Lei
TI  - Bidirectional Segmented Detection of Land Use Change Based on Object-Level Multivariate Time Series
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 3
SN  - 2072-4292

AB  - High-precision information regarding the location, time, and type of land use change is integral to understanding global changes. Time series (TS) analysis of remote sensing images is a powerful method for land use change detection. To address the complexity of sample selection and the salt-and-pepper noise of pixels, we propose a bidirectional segmented detection (BSD) method based on object-level, multivariate TS, that detects the type and time of land use change from Landsat images. In the proposed method, based on the multiresolution segmentation of objects, three dimensions of object-level TS are constructed using the median of the following indices: the normalized difference vegetation index (NDVI), the normalized difference built index (NDBI), and the modified normalized difference water index (MNDWI). Then, BSD with forward and backward detection is performed on the segmented objects to identify the types and times of land use change. Experimental results indicate that the proposed BSD method effectively detects the type and time of land use change with an overall accuracy of 90.49% and a Kappa coefficient of 0.86. It was also observed that the median value of a segmented object is more representative than the commonly used mean value. In addition, compared with traditional methods such as LandTrendr, the proposed method is competitive in terms of time efficiency and accuracy. Thus, the BSD method can promote efficient and accurate land use change detection.
KW  - land use change
KW  - bidirectional segmented detection
KW  - object-level time series
KW  - remote sensing
DO  - 10.3390/rs12030478
ER  -
TY  - EJOU
AU  - Popescu, Dan
AU  - Stoican, Florin
AU  - Stamatescu, Grigore
AU  - Ichim, Loretta
AU  - Dragana, Cristian
TI  - Advanced UAV–WSN System for Intelligent Monitoring in Precision Agriculture
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 3
SN  - 1424-8220

AB  - The growing need for food worldwide requires the development of a high-performance, high-productivity, and sustainable agriculture, which implies the introduction of new technologies into monitoring activities related to control and decision-making. In this regard, this paper presents a hierarchical structure based on the collaboration between unmanned aerial vehicles (UAVs) and federated wireless sensor networks (WSNs) for crop monitoring in precision agriculture. The integration of UAVs with intelligent, ground WSNs, and IoT proved to be a robust and efficient solution for data collection, control, analysis, and decisions in such specialized applications. Key advantages lay in online data collection and relaying to a central monitoring point, while effectively managing network load and latency through optimized UAV trajectories and in situ data processing. Two important aspects of the collaboration were considered: designing the UAV trajectories for efficient data collection and implementing effective data processing algorithms (consensus and symbolic aggregate approximation) at the network level for the transmission of the relevant data. The experiments were carried out at a Romanian research institute where different crops and methods are developed. The results demonstrate that the collaborative UAV&ndash;WSN&ndash;IoT approach increases the performances in both precision agriculture and ecological agriculture.
KW  - unmanned aerial vehicles
KW  - wireless sensor networks
KW  - intelligent data processing
KW  - trajectory planning
KW  - relevant data extraction
KW  - data consensus
KW  - Internet of Things
KW  - precision agriculture
DO  - 10.3390/s20030817
ER  -
TY  - EJOU
AU  - Chang, Zhilu
AU  - Du, Zhen
AU  - Zhang, Fan
AU  - Huang, Faming
AU  - Chen, Jiawu
AU  - Li, Wenbin
AU  - Guo, Zizheng
TI  - Landslide Susceptibility Prediction Based on Remote Sensing Images and GIS: Comparisons of Supervised and Unsupervised Machine Learning Models
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 3
SN  - 2072-4292

AB  - Landslide susceptibility prediction (LSP) has been widely and effectively implemented by machine learning (ML) models based on remote sensing (RS) images and Geographic Information System (GIS). However, comparisons of the applications of ML models for LSP from the perspectives of supervised machine learning (SML) and unsupervised machine learning (USML) have not been explored. Hence, this study aims to compare the LSP performance of these SML and USML models, thus further to explore the advantages and disadvantages of these ML models and to realize a more accurate and reliable LSP result. Two representative SML models (support vector machine (SVM) and CHi-squared Automatic Interaction Detection (CHAID)) and two representative USML models (K-means and Kohonen models) are respectively used to scientifically predict the landslide susceptibility indexes, and then these prediction results are discussed. Ningdu County with 446 recorded landslides obtained through field investigations is introduced as case study. A total of 12 conditioning factors are obtained through procession of Landsat TM 8 images and high-resolution aerial images, topographical and hydrological spatial analysis of Digital Elevation Modeling in GIS software, and government reports. The area value under the curve of receiver operating features (AUC) is applied for evaluating the prediction accuracy of SML models, and the frequency ratio (FR) accuracy is then introduced to compare the remarkable prediction performance differences between SML and USML models. Overall, the receiver operation curve (ROC) results show that the AUC of the SVM is 0.892 and is slightly greater than the AUC of the CHAID model (0.872). The FR accuracy results show that the SVM model has the highest accuracy for LSP (77.80%), followed by the CHAID model (74.50%), the Kohonen model (72.8%) and the K-means model (69.7%), which indicates that the SML models can reach considerably better prediction capability than the USML models. It can be concluded that selecting recorded landslides as prior knowledge to train and test the LSP models is the key reason for the higher prediction accuracy of the SML models, while the lack of a priori knowledge and target guidance is an important reason for the low LSP accuracy of the USML models. Nevertheless, the USML models can also be used to implement LSP due to their advantages of efficient modeling processes, dimensionality reduction and strong scalability.
KW  - landslide susceptibility prediction
KW  - supervised machine learning
KW  - unsupervised machine learning
KW  - remote sensing
KW  - Geographic Information System
DO  - 10.3390/rs12030502
ER  -
TY  - EJOU
AU  - Fu, Zhaopeng
AU  - Jiang, Jie
AU  - Gao, Yang
AU  - Krienke, Brian
AU  - Wang, Meng
AU  - Zhong, Kaitai
AU  - Cao, Qiang
AU  - Tian, Yongchao
AU  - Zhu, Yan
AU  - Cao, Weixing
AU  - Liu, Xiaojun
TI  - Wheat Growth Monitoring and Yield Estimation based on Multi-Rotor Unmanned Aerial Vehicle
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 3
SN  - 2072-4292

AB  - Leaf area index (LAI) and leaf dry matter (LDM) are important indices of crop growth. Real-time, nondestructive monitoring of crop growth is instructive for the diagnosis of crop growth and prediction of grain yield. Unmanned aerial vehicle (UAV)-based remote sensing is widely used in precision agriculture due to its unique advantages in flexibility and resolution. This study was carried out on wheat trials treated with different nitrogen levels and seeding densities in three regions of Jiangsu Province in 2018&ndash;2019. Canopy spectral images were collected by the UAV equipped with a multi-spectral camera during key wheat growth stages. To verify the results of the UAV images, the LAI, LDM, and yield data were obtained by destructive sampling. We extracted the wheat canopy reflectance and selected the best vegetation index for monitoring growth and predicting yield. Simple linear regression (LR), multiple linear regression (MLR), stepwise multiple linear regression (SMLR), partial least squares regression (PLSR), artificial neural network (ANN), and random forest (RF) modeling methods were used to construct a model for wheat yield estimation. The results show that the multi-spectral camera mounted on the multi-rotor UAV has a broad application prospect in crop growth index monitoring and yield estimation. The vegetation index combined with the red edge band and the near-infrared band was significantly correlated with LAI and LDM. Machine learning methods (i.e., PLSR, ANN, and RF) performed better for predicting wheat yield. The RF model constructed by normalized difference vegetation index (NDVI) at the jointing stage, heading stage, flowering stage, and filling stage was the optimal wheat yield estimation model in this study, with an R2 of 0.78 and relative root mean square error (RRMSE) of 0.1030. The results provide a theoretical basis for monitoring crop growth with a multi-rotor UAV platform and explore a technical method for improving the precision of yield estimation.
KW  - UAV multispectral image
KW  - leaf area index
KW  - leaf dry matter
KW  - grain yield
KW  - estimation
KW  - wheat
KW  - machine learning
DO  - 10.3390/rs12030508
ER  -
TY  - EJOU
AU  - Maxwell, Aaron E.
AU  - Pourmohammadi, Pariya
AU  - Poyner, Joey D.
TI  - Mapping the Topographic Features of Mining-Related Valley Fills Using Mask R-CNN Deep Learning and Digital Elevation Data
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 3
SN  - 2072-4292

AB  - Modern elevation-determining remote sensing technologies such as light-detection and ranging (LiDAR) produce a wealth of topographic information that is increasingly being used in a wide range of disciplines, including archaeology and geomorphology. However, automated methods for mapping topographic features have remained a significant challenge. Deep learning (DL) mask regional-convolutional neural networks (Mask R-CNN), which provides context-based instance mapping, offers the potential to overcome many of the difficulties of previous approaches to topographic mapping. We therefore explore the application of Mask R-CNN to extract valley fill faces (VFFs), which are a product of mountaintop removal (MTR) coal mining in the Appalachian region of the eastern United States. LiDAR-derived slopeshades are provided as the only predictor variable in the model. Model generalization is evaluated by mapping multiple study sites outside the training data region. A range of assessment methods, including precision, recall, and F1 score, all based on VFF counts, as well as area- and a fuzzy area-based user&rsquo;s and producer&rsquo;s accuracy, indicate that the model was successful in mapping VFFs in new geographic regions, using elevation data derived from different LiDAR sensors. Precision, recall, and F1-score values were above 0.85 using VFF counts while user&rsquo;s and producer&rsquo;s accuracy were above 0.75 and 0.85 when using the area- and fuzzy area-based methods, respectively, when averaged across all study areas characterized with LiDAR data. Due to the limited availability of LiDAR data until relatively recently, we also assessed how well the model generalizes to terrain data created using photogrammetric methods that characterize past terrain conditions. Unfortunately, the model was not sufficiently general to allow successful mapping of VFFs using photogrammetrically-derived slopeshades, as all assessment metrics were lower than 0.60; however, this may partially be attributed to the quality of the photogrammetric data. The overall results suggest that the combination of Mask R-CNN and LiDAR has great potential for mapping anthropogenic and natural landscape features. To realize this vision, however, research on the mapping of other topographic features is needed, as well as the development of large topographic training datasets including a variety of features for calibrating and testing new methods.
KW  - light detection and ranging
KW  - LiDAR
KW  - deep learning
KW  - convolutional neural networks
KW  - CNNs
KW  - mask regional-convolutional neural networks
KW  - mask R-CNN
KW  - digital terrain analysis
KW  - resource extraction
DO  - 10.3390/rs12030547
ER  -
TY  - EJOU
AU  - Perera, Asanka G.
AU  - Khanam, Fatema-Tuz-Zohra
AU  - Al-Naji, Ali
AU  - Chahl, Javaan
TI  - Detection and Localisation of Life Signs from the Air Using Image Registration and Spatio-Temporal Filtering
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 3
SN  - 2072-4292

AB  - In search and rescue operations, it is crucial to rapidly identify those people who are alive from those who are not. If this information is known, emergency teams can prioritize their operations to save more lives. However, in some natural disasters the people may be lying on the ground covered with dust, debris, or ashes making them difficult to detect by video analysis that is tuned to human shapes. We present a novel method to estimate the locations of people from aerial video using image and signal processing designed to detect breathing movements. We have shown that this method can successfully detect clearly visible people and people who are fully occluded by debris. First, the aerial videos were stabilized using the key points of adjacent image frames. Next, the stabilized video was decomposed into tile videos and the temporal frequency bands of interest were motion magnified while the other frequencies were suppressed. Image differencing and temporal filtering were performed on each tile video to detect potential breathing signals. Finally, the detected frequencies were remapped to the image frame creating a life signs map that indicates possible human locations. The proposed method was validated with both aerial and ground recorded videos in a controlled environment. Based on the dataset, the results showed good reliability for aerial videos and no errors for ground recorded videos where the average precision measures for aerial videos and ground recorded videos were 0.913 and 1 respectively.
KW  - search and rescue
KW  - drone
KW  - breathing detection
KW  - human detection
DO  - 10.3390/rs12030577
ER  -
TY  - EJOU
AU  - Agapiou, Athos
TI  - Evaluation of Landsat 8 OLI/TIRS Level-2 and Sentinel 2 Level-1C Fusion Techniques Intended for Image Segmentation of Archaeological Landscapes and Proxies
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 3
SN  - 2072-4292

AB  - The use of medium resolution, open access, and freely distributed satellite images, such as those of Landsat, is still understudied in the domain of archaeological research, mainly due to restrictions of spatial resolution. This investigation aims to showcase how the synergistic use of Landsat and Sentinel optical sensors can efficiently support archaeological research through object-based image analysis (OBIA), a relatively new scientific trend, as highlighted in the relevant literature, in the domain of remote sensing archaeology. Initially, the fusion of a 30 m spatial resolution Landsat 8 OLI/TIRS Level-2 and a 10 m spatial resolution Sentinel 2 Level-1C optical images, over the archaeological site of &ldquo;Nea Paphos&rdquo; in Cyprus, are evaluated in order to improve the spatial resolution of the Landsat image. At this step, various known fusion models are implemented and evaluated, namely Gram&ndash;Schmidt, Brovey, principal component analysis (PCA), and hue-saturation-value (HSV) algorithms. In addition, all four 10 m available spectral bands of the Sentinel 2 sensor, namely the blue, green, red, and near-infrared bands (Bands 2 to 4 and Band 8, respectively) were assessed for each of the different fusion models. On the basis of these findings, the next step of the study, focused on the image segmentation process, through the evaluation of different scale factors. The segmentation process is an important step moving from pixel-based to object-based image analysis. The overall results show that the Gram&ndash;Schmidt fusion method based on the near-infrared band of the Sentinel 2 (Band 8) at a range of scale factor segmentation to 70 are the optimum parameters for the detection of standing visible monuments, monitoring excavated areas, and detecting buried archaeological remains, without any significant spectral distortion of the original Landsat image. The new 10 m fused Landsat 8 image provides further spatial details of the archaeological site and depicts, through the segmentation process, important details within the landscape under examination.
KW  - fusion
KW  - image segmentation
KW  - archaeological landscapes
KW  - archaeological proxies
KW  - Landsat 8
KW  - Sentinel 2
KW  - object-based image analysis (OBIA)
DO  - 10.3390/rs12030579
ER  -
TY  - EJOU
AU  - Zhang, Jing
AU  - Tian, Haiqing
AU  - Wang, Di
AU  - Li, Haijun
AU  - Mouazen, Abdul M.
TI  - A Novel Approach for Estimation of Above-Ground Biomass of Sugar Beet Based on Wavelength Selection and Optimized Support Vector Machine
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 4
SN  - 2072-4292

AB  - Timely diagnosis of sugar beet above-ground biomass (AGB) is critical for the prediction of yield and optimal precision crop management. This study established an optimal quantitative prediction model of AGB of sugar beet by using hyperspectral data. Three experiment campaigns in 2014, 2015 and 2018 were conducted to collect ground-based hyperspectral data at three different growth stages, across different sites, for different cultivars and nitrogen (N) application rates. A competitive adaptive reweighted sampling (CARS) algorithm was applied to select the most sensitive wavelengths to AGB. This was followed by developing a novel modified differential evolution grey wolf optimization algorithm (MDE&ndash;GWO) by introducing differential evolution algorithm (DE) and dynamic non-linear convergence factor to grey wolf optimization algorithm (GWO) to optimize the parameters c and &gamma; of a support vector machine (SVM) model for the prediction of AGB. The prediction performance of SVM models under the three GWO, DE&ndash;GWO and MDE&ndash;GWO optimization methods for CARS selected wavelengths and whole spectral data was examined. Results showed that CARS resulted in a huge wavelength reduction of 97.4% for the rapid growth stage of leaf cluster, 97.2% for the sugar growth stage and 97.4% for the sugar accumulation stage. Models resulted after CARS wavelength selection were found to be more accurate than models developed using the entire spectral data. The best prediction accuracy was achieved after the MDE&ndash;GWO optimization of SVM model parameters for the prediction of AGB in sugar beet, independent of growing stage, years, sites and cultivars. The best coefficient of determination (R2), root mean square error (RMSE) and residual prediction deviation (RPD) ranged, respectively, from 0.74 to 0.80, 46.17 to 65.68 g/m2 and 1.42 to 1.97 for the rapid growth stage of leaf cluster, 0.78 to 0.80, 30.16 to 37.03 g/m2 and 1.69 to 2.03 for the sugar growth stage, and 0.69 to 0.74, 40.17 to 104.08 g/m2 and 1.61 to 1.95 for the sugar accumulation stage. It can be concluded that the methodology proposed can be implemented for the prediction of AGB of sugar beet using proximal hyperspectral sensors under a wide range of environmental conditions.
KW  - sugar beet
KW  - above-ground biomass
KW  - grey wolf optimization
KW  - support vector machine
KW  - hyperspectral sensing
DO  - 10.3390/rs12040620
ER  -
TY  - EJOU
AU  - Karydas, Christos
AU  - Iatrou, Miltiadis
AU  - Kouretas, Dimitrios
AU  - Patouna, Anastasia
AU  - Iatrou, George
AU  - Lazos, Nikolaos
AU  - Gewehr, Sandra
AU  - Tseni, Xanthi
AU  - Tekos, Fotis
AU  - Zartaloudis, Zois
AU  - Mainos, Evangelos
AU  - Mourelatos, Spiros
TI  - Prediction of Antioxidant Activity of Cherry Fruits from UAS Multispectral Imagery Using Machine Learning
T2  - Antioxidants

PY  - 2020
VL  - 9
IS  - 2
SN  - 2076-3921

AB  - In this research, a model for the estimation of antioxidant content in cherry fruits from multispectral imagery acquired from drones was developed, based on machine learning methods. For two consecutive cultivation years, the trees were sampled on different dates and then analysed for their fruits&rsquo; radical scavenging activity (DPPH) and Folin&ndash;Ciocalteu (FCR) reducing capacity. Multispectral images from unmanned aerial vehicles were acquired on the same dates with fruit sampling. Soil samples were collected throughout the study fields at the end of the season. Topographic, hydrographic and weather data also were included in modelling. First-year data were used for model-fitting, whereas second-year data for testing. Spatial autocorrelation tests indicated unbiased sampling and, moreover, allowed restriction of modelling input parameters to a smaller group. The optimum model employs 24 input variables resulting in a 6.74 root mean square error. Provided that soil profiles and other ancillary data are known in advance of the cultivation season, capturing drone images in critical growth phases, together with contemporary weather data, can support site- and time-specific harvesting. It could also support site-specific treatments (precision farming) for improving fruit quality in the long-term, with analogous marketing perspectives.
KW  - antioxidant activity
KW  - machine learning
KW  - drones
KW  - precision farming
DO  - 10.3390/antiox9020156
ER  -
TY  - EJOU
AU  - Hufkens, Koen
AU  - de Haulleville, Thalès
AU  - Kearsley, Elizabeth
AU  - Jacobsen, Kim
AU  - Beeckman, Hans
AU  - Stoffelen, Piet
AU  - Vandelook, Filip
AU  - Meeus, Sofie
AU  - Amara, Michael
AU  - Van Hirtum, Leen
AU  - Van den Bulcke, Jan
AU  - Verbeeck, Hans
AU  - Wingate, Lisa
TI  - Historical Aerial Surveys Map Long-Term Changes of Forest Cover and Structure in the Central Congo Basin
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 4
SN  - 2072-4292

AB  - Given the impact of tropical forest disturbances on atmospheric carbon emissions, biodiversity, and ecosystem productivity, accurate long-term reporting of Land-Use and Land-Cover (LULC) change in the pre-satellite era (&lt;1972) is an imperative. Here, we used a combination of historical (1958) aerial photography and contemporary remote sensing data to map long-term changes in the extent and structure of the tropical forest surrounding Yangambi (DR Congo) in the central Congo Basin. Our study leveraged structure-from-motion and a convolutional neural network-based LULC classifier, using synthetic landscape-based image augmentation to map historical forest cover across a large orthomosaic (~93,431 ha) geo-referenced to ~4.7 ± 4.3 m at submeter resolution. A comparison with contemporary LULC data showed a shift from previously highly regular industrial deforestation of large areas to discrete smallholder farming clearing, increasing landscape fragmentation and providing opportunties for substantial forest regrowth. We estimated aboveground carbon gains through reforestation to range from 811 to 1592 Gg C, partially offsetting historical deforestation (2416 Gg C), in our study area. Efforts to quantify long-term canopy texture changes and their link to aboveground carbon had limited to no success. Our analysis provides methods and insights into key spatial and temporal patterns of deforestation and reforestation at a multi-decadal scale, providing a historical context for past and ongoing forest research in the area.
KW  - aerial survey
KW  - data recovery
KW  - CNN
KW  - deep learning
KW  - SfM
KW  - Congo Basin
DO  - 10.3390/rs12040638
ER  -
TY  - EJOU
AU  - Yu, Zhi
AU  - Shi, Xiuzhi
AU  - Zhou, Jian
AU  - Chen, Xin
AU  - Qiu, Xianyang
TI  - Effective Assessment of Blast-Induced Ground Vibration Using an Optimized Random Forest Model Based on a Harris Hawks Optimization Algorithm
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 4
SN  - 2076-3417

AB  - Most mines choose the drilling and blasting method which has the characteristics of being a cheap and efficient method to fragment rock mass, but blast-induced ground vibration damages the surrounding rock mass and structure and is a drawback. To predict, analyze and control the blast-induced ground vibration, the random forest (RF) model, Harris hawks optimization (HHO) algorithm and Monte Carlo simulation approach were utilized. A database consisting of 137 datasets was collected at different locations around the Tonglvshan open-cast mine, China. Seven variables were selected and collected as the input variables, and peak particle velocity was chosen as the output variable. At first, an RF model and a hybrid model, namely a HHO-RF model, were developed, and the prediction results checked by 3 performance indices to show that the proposed HHO-RF model can provide higher prediction performance. Then blast-induced ground vibration was simulated by using the Monte Carlo simulation approach and the developed HHO-RF model. After analyzing, the mean peak particle velocity value was 0.98 cm/s, and the peak particle velocity value did not exceed 1.95 cm/s with a probability of 90%. The research results of this study provided a simple, accurate method and basis for predicting, evaluating blast-induced ground vibration and optimizing the blast design before blast operation.
KW  - blast-induced ground vibration
KW  - random forest
KW  - Harris hawks optimization
KW  - Monte Carlo simulation
KW  - sensitive analysis
DO  - 10.3390/app10041403
ER  -
TY  - EJOU
AU  - Spachos, Petros
TI  - Towards a Low-Cost Precision Viticulture System Using Internet of Things Devices
T2  - IoT

PY  - 2020
VL  - 1
IS  - 1
SN  - 2624-831X

AB  - Precision Agriculture (PA) is an ever-expanding field that takes modern technological advancements and applies it to farming practices to reduce waste and increase output. One advancement that can play a significant role in achieving precision agriculture is wireless technology, and specifically the Internet of Things (IoT) devices. Small, inch scale and low-cost devices can be used to monitor great agricultural areas. In this paper, a system for precision viticulture which uses IoT devices for real-time monitoring is proposed. The different components of the system are programmed properly and the interconnection between them is designed to minimize energy consumption. Wireless sensor nodes measure soil moisture and soil temperature in the field and transmit the information to a base station. If the conditions are optimal for a disease or pest to occur, a drone flies towards the area. When the drone is over the node, pictures are captured and then it returns to the base station for further processing. The feasibility of the system is examined through experimentation in a realistic scenario.
KW  - precision viticulture
KW  - Internet of Things
KW  - sensors and instrumentation
KW  - smart agriculture
DO  - 10.3390/iot1010002
ER  -
TY  - EJOU
AU  - Pastick, Neal J.
AU  - Dahal, Devendra
AU  - Wylie, Bruce K.
AU  - Parajuli, Sujan
AU  - Boyte, Stephen P.
AU  - Wu, Zhouting
TI  - Characterizing Land Surface Phenology and Exotic Annual Grasses in Dryland Ecosystems Using Landsat and Sentinel-2 Data in Harmony
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 4
SN  - 2072-4292

AB  - Invasive annual grasses, such as cheatgrass (Bromus tectorum L.), have proliferated in dryland ecosystems of the western United States, promoting increased fire activity and reduced biodiversity that can be detrimental to socio-environmental systems. Monitoring exotic annual grass cover and dynamics over large areas requires the use of remote sensing that can support early detection and rapid response initiatives. However, few studies have leveraged remote sensing technologies and computing frameworks capable of providing rangeland managers with maps of exotic annual grass cover at relatively high spatiotemporal resolutions and near real-time latencies. Here, we developed a system for automated mapping of invasive annual grass (%) cover using in situ observations, harmonized Landsat and Sentinel-2 (HLS) data, maps of biophysical variables, and machine learning techniques. A robust and automated cloud, cloud shadow, water, and snow/ice masking procedure (mean overall accuracy &gt;81%) was implemented using time-series outlier detection and data mining techniques prior to spatiotemporal interpolation of HLS data via regression tree models (r = 0.94; mean absolute error (MAE) = 0.02). Weekly, cloud-free normalized difference vegetation index (NDVI) image composites (2016&ndash;2018) were used to construct a suite of spectral and phenological metrics (e.g., start and end of season dates), consistent with information derived from Moderate Resolution Image Spectroradiometer (MODIS) data. These metrics were incorporated into a data mining framework that accurately (r = 0.83; MAE = 11) modeled and mapped exotic annual grass (%) cover throughout dryland ecosystems in the western United States at a native, 30-m spatial resolution. Our results show that inclusion of weekly HLS time-series data and derived indicators improves our ability to map exotic annual grass cover, as compared to distribution models that use MODIS products or monthly, seasonal, or annual HLS composites as primary inputs. This research fills a critical gap in our ability to effectively assess, manage, and monitor drylands by providing a framework that allows for an accurate and timely depiction of land surface phenology and exotic annual grass cover at spatial and temporal resolutions that are meaningful to local resource managers.
KW  - data mining
KW  - invasive plants
KW  - Landsat
KW  - Sentinel-2
KW  - time-series analysis
KW  - phenology
DO  - 10.3390/rs12040725
ER  -
TY  - EJOU
AU  - Nogueira, Keiller
AU  - L. S. Machado, Gabriel
AU  - H. T. Gama, Pedro
AU  - C. V. da Silva, Caio
AU  - Balaniuk, Remis
AU  - A. dos Santos, Jefersson
TI  - Facing Erosion Identification in Railway Lines Using Pixel-Wise Deep-Based Approaches
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 4
SN  - 2072-4292

AB  - Soil erosion is considered one of the most expensive natural hazards with a high impact on several infrastructure assets. Among them, railway lines are one of the most likely constructions for the appearance of erosion and, consequently, one of the most troublesome due to the maintenance costs, risks of derailments, and so on. Therefore, it is fundamental to identify and monitor erosion in railway lines to prevent major consequences. Currently, erosion identification is manually performed by humans using huge image sets, a time-consuming and slow task. Hence, automatic machine learning methods appear as an appealing alternative. A crucial step for automatic erosion identification is to create a good feature representation. Towards such objective, deep learning can learn data-driven features and classifiers. In this paper, we propose a novel deep learning-based framework capable of performing erosion identification in railway lines. Six techniques were evaluated and the best one, Dynamic Dilated ConvNet, was integrated into this framework that was then encapsulated into a new ArcGIS plugin to facilitate its use by non-programmer users. To analyze such techniques, we also propose a new dataset, composed of almost 2000 high-resolution images.
KW  - deep learning
KW  - remote sensing
KW  - erosion identification
KW  - high-resolution images
DO  - 10.3390/rs12040739
ER  -
TY  - EJOU
AU  - Mhangara, Paidamwoyo
AU  - Mapurisa, Willard
AU  - Mudau, Naledzani
TI  - Image Interpretability of nSight-1 Nanosatellite Imagery for Remote Sensing Applications
T2  - Aerospace

PY  - 2020
VL  - 7
IS  - 2
SN  - 2226-4310

AB  - Nanosatellites are increasingly being used in space-related applications to demonstrate and test scientific capability and engineering ingenuity of space-borne instruments and for educational purposes due to their favourable low manufacturing costs, cheaper launch costs, and short development time. The use of CubeSat to demonstrate earth imaging capability has also grown in the last two decades. In 2017, a South African company known as Space Commercial Services launched a low-orbit nanosatellite named nSight-1. The demonstration nanosatellite has three payloads that include a modular designed SCS Gecko imaging payload, FIPEX atmospheric science instrument developed by the University of Dresden and a Radiation mitigation VHDL coding experiment supplied by Nelson Mandela University. The Gecko imager has a swath width of 64 km and captures 30 m spatial resolution images using the red, green, and blue (RGB) spectral bands. The objective of this study was to assess the interpretability of nSight-1 in the spatial dimension using Landsat 8 as a reference and to recommend potential earth observation applications for the mission. A blind image spatial quality evaluator known as Blind/Referenceless Image Spatial Quality Evaluator (BRISQUE) was used to compute the image quality for nSight-1 and Landsat 8 imagery in the spatial domain and the National Imagery Interpretability Rating Scale (NIIRS) method to quantify the interpretability of the images. A visual interpretation was used to propose some potential applications for the nSight1 images. The results indicate that Landsat 8 OLI images had significantly higher image quality scores and NIIRS results compared to nSight-1. Landsat 8 has a mean of 19.299 for the image quality score while nSight-1 achieved a mean of 25.873. Landsat 8 had NIIRS mean of 2.345 while nSight-1 had a mean of 1.622. The superior image quality and image interpretability of Landsat could be attributed for the mature optical design on the Landsat 8 satellite that is aimed for operational purposes. Landsat 8 has a GDS of 30-m compared to 32-m on nSight-1. The image degradation resulting from the lossy compression implemented on nSight-1 from 12-bit to 8-bit also has a negative impact on image visual quality and interpretability. Whereas it is evident that Landsat 8 has the better visual quality and NIIRS scores, the results also showed that nSight-1 are still very good if one considers that the categorical ratings consider that images to be of good to excellent quality and a NIIRS mean of 1.6 indicates that the images are interpretable. Our interpretation of the imagery shows that the data has considerable potential for use in geo-visualization and cartographic land use and land cover mapping applications. The image analysis also showed the capability of the nSight-1 sensor to capture features related to structural geology, geomorphology and topography quite prominently.
KW  - nanosatellites
KW  - remote sensing
KW  - image quality
KW  - image interpretability
KW  - land use and land cover applications
DO  - 10.3390/aerospace7020019
ER  -
TY  - EJOU
AU  - Ding, Hu
AU  - Liu, Kai
AU  - Chen, Xiaozheng
AU  - Xiong, Liyang
AU  - Tang, Guoan
AU  - Qiu, Fang
AU  - Strobl, Josef
TI  - Optimized Segmentation Based on the Weighted Aggregation Method for Loess Bank Gully Mapping
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 5
SN  - 2072-4292

AB  - The Chinese Loess Plateau suffers severe gully erosion. Gully mapping is a fundamental task for gully erosion monitoring in this region. Among the different gully types in the Loess Plateau, the bank gully is usually regarded as the most important source for the generation of sediment. However, approaches for bank gully extraction are still limited. This study put forward an integrated framework, including segmentation optimization, evaluation and Extreme Gradient Boosting (XGBoost)-based classification, for the bank gully mapping of Zhifanggou catchment in the Chinese Loess Plateau. The approach was conducted using a 1-m resolution digital elevation model (DEM), based on unmanned aerial vehicle (UAV) photogrammetry and WorldView-3 imagery. The methodology first divided the study area into different watersheds. Then, segmentation by weighted aggregation (SWA) was implemented to generate multi-level segments. For achieving an optimum segmentation, area-weighted variance (WV) and Moran&rsquo;s I (MI) were adopted and calculated within each sub-watershed. After that, a new discrepancy metric, the area-number index (ANI), was developed for evaluating the segmentation results, and the results were compared with the multi-resolution segmentation (MRS) algorithm. Finally, bank gully mappings were obtained based on the XGBoost model after fine-tuning. The experiment results demonstrate that the proposed method can achieve superior segmentation compared to MRS. Moreover, the overall accuracy of the bank gully extraction results was 78.57%. The proposed approach provides a credible tool for mapping bank gullies, which could be useful for the catchment-scale gully erosion process.
KW  - object-based image analysis
KW  - gully mapping
KW  - segmentation optimization
KW  - unmanned aerial vehicle (UAV)
KW  - XGBoost
DO  - 10.3390/rs12050793
ER  -
TY  - EJOU
AU  - Lee, Yong-Suk
AU  - Lee, Sunmin
AU  - Baek, Won-Kyung
AU  - Jung, Hyung-Sup
AU  - Park, Sung-Hwan
AU  - Lee, Moung-Jin
TI  - Mapping Forest Vertical Structure in Jeju Island from Optical and Radar Satellite Images Using Artificial Neural Network
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 5
SN  - 2072-4292

AB  - Recently, due to the acceleration of global warming, an accurate understanding and management of forest carbon stocks, such as forest aboveground biomass, has become very important. The vertical structure of the forest, which is the internal structure of the forest, was mainly investigated by field surveys that are labor intensive. Recently, remote sensing techniques have been actively used to explore large and inaccessible areas. In addition, machine learning techniques that could classify and analyze large amounts of data are being used in various fields. Thus, this study aims to analyze the forest vertical structure (number of tree layers) to estimate forest aboveground biomass in Jeju Island from optical and radar satellite images using artificial neural networks (ANN). For this purpose, the eight input neurons of the forest related layers, based on remote sensing data, were prepared: normalized difference vegetation index (NDVI), normalized difference water index (NDWI), NDVI texture, NDWI texture, average canopy height, standard deviation canopy height and two types of coherence maps were created using the Kompsat-3 optical image, L-band ALOS PALSAR-1 radar images, digital surface model (DSM), and digital terrain model (DTM). The forest vertical structure data, based on field surveys, was divided into the training/validation and test data and the hyper-parameters of ANN were trained using the training/validation data. The forest vertical classification result from ANN was evaluated by comparison to the test data. It showed about a 65.7% overall accuracy based on the error matrix. This result shows that the forest vertical structure map can be effectively generated from optical and radar satellite images and existing DEM and DTM using the ANN approach, especially for national scale mapping.
KW  - forest vertical structure
KW  - KOMPSAT-3
KW  - ALOS PALSAR-1
KW  - artificial neural network
DO  - 10.3390/rs12050797
ER  -
TY  - EJOU
AU  - Vilar, Pedro
AU  - Morais, Tiago G.
AU  - Rodrigues, Nuno R.
AU  - Gama, Ivo
AU  - Monteiro, Marta L.
AU  - Domingos, Tiago
AU  - Teixeira, Ricardo F. M.
TI  - Object-Based Classification Approaches for Multitemporal Identification and Monitoring of Pastures in Agroforestry Regions using Multispectral Unmanned Aerial Vehicle Products
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 5
SN  - 2072-4292

AB  - Sown Biodiverse Pastures (SBP) are the basis of a high-yield grazing system tailored for Mediterranean ecosystems and widely implemented in Southern Portugal. The application of precision farming methods in SBP requires cost-effective monitoring using remote sensing (RS). The main hurdle for the remote monitoring of SBP is the fact that the bulk of the pastures are installed in open Montado agroforestry systems. Sparsely distributed trees cast shadows that hinder the identification of the underlaying pasture using Unmanned Aerial Vehicles (UAV) imagery. Image acquisition in the Spring is made difficult by the presence of flowers that mislead the classification algorithms. Here, we tested multiple procedures for the geographical, object-based image classification (GEOBIA) of SBP, aiming to reduce the effects of tree shadows and flowers in open Montado systems. We used remotely sensed data acquired between November 2017 and May 2018 in three Portuguese farms. We used three machine learning supervised classification algorithms: Random Forests (RF), Support Vector Machine (SVM) and Artificial Neural Networks (ANN). We classified SBP based on: (1) a single-period image for the maximum Normalized Difference Vegetation Index (NDVI) epoch in each of the three farms, and (2) multi-temporal image stacking. RF, SVM and ANN were trained using some visible (red, green and blue bands) and near-infrared (NIR) reflectance bands, plus NDVI and a Digital Surface Model (DSM). We obtained high overall accuracy and kappa index (higher than 79% and 0.60, respectively). The RF algorithm had the highest overall accuracy (more than 92%) for all farms. Multitemporal image classification increased the accuracy of the algorithms. as it helped to correctly identify as SBP the areas covered by tree shadows and flower patches, which would be misclassified using single image classification. This study thus established the first workflow for SBP monitoring based on remotely sensed data, suggesting an operational approach for SBP identification. The workflow can be applied to other types of pastures in agroforestry regions to reduce the effects of shadows and flowering in classification problems.
KW  - remote sensing
KW  - multitemporal classification
KW  - machine learning algorithms
KW  - land cover classification
KW  - tree shadows
KW  - flowering
DO  - 10.3390/rs12050814
ER  -
TY  - EJOU
AU  - Guo, Han
AU  - Zhou, Jun
AU  - Liu, Fei
AU  - He, Yong
AU  - Huang, He
AU  - Wang, Hongyan
TI  - Application of Machine Learning Method to Quantitatively Evaluate the Droplet Size and Deposition Distribution of the UAV Spray Nozzle
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 5
SN  - 2076-3417

AB  - Unmanned Aerial Vehicle (UAV) spray has been used for efficient and adaptive pesticide applications with its low costs. However, droplet drift is the main problem for UAV spray and will induce pesticide waste and safety concerns. Droplet size and deposition distribution are both highly related to droplet drift and spray effect, which are determined by the nozzle. Therefore, it is necessary to propose an evaluating method for a specific UAV spray nozzles. In this paper, four machine learning methods (REGRESS, least squares support vector machines (LS-SVM), extreme learning machine, and radial basis function neural network (RBFNN)) were applied for quantitatively evaluating one type of UAV spray nozzle (TEEJET XR110015VS), and the case of twin nozzles was investigated. The results showed REGRESS and LS-SVM are good candidates for droplet size evaluation with the coefficient of determination in the calibration set above 0.9 and root means square errors of the prediction set around 2 &micro;m. RBFNN achieved the best performance for the evaluation of deposition distribution and showed its potential for determining the droplet size of overlapping area. Overall, this study proved the accuracy and efficiency of using the machine learning method for UAV spray nozzle evaluation. Additionally, the study demonstrated the feasibility of using machine learning model to predict the droplet size in the overlapping area of twin nozzles.
KW  - UAV spray nozzle
KW  - spray characteristics
KW  - machine learning
KW  - quantitative modeling
DO  - 10.3390/app10051759
ER  -
TY  - EJOU
AU  - Communier, David
AU  - Botez, Ruxandra M.
AU  - Wong, Tony
TI  - Design and Validation of a New Morphing Camber System by Testing in the Price—Païdoussis Subsonic Wind Tunnel
T2  - Aerospace

PY  - 2020
VL  - 7
IS  - 3
SN  - 2226-4310

AB  - This paper presents the design and wind tunnel testing of a morphing camber system and an estimation of performances on an unmanned aerial vehicle. The morphing camber system is a combination of two subsystems: the morphing trailing edge and the morphing leading edge. Results of the present study show that the aerodynamics effects of the two subsystems are combined, without interfering with each other on the wing. The morphing camber system acts only on the lift coefficient at a 0&deg; angle of attack when morphing the trailing edge, and only on the stall angle when morphing the leading edge. The behavior of the aerodynamics performances from the MTE and the MLE should allow individual control of the morphing camber trailing and leading edges. The estimation of the performances of the morphing camber on an unmanned aerial vehicle indicates that the morphing of the camber allows a drag reduction. This result is due to the smaller angle of attack needed for an unmanned aerial vehicle equipped with the morphing camber system than an unmanned aerial vehicle equipped with classical aileron. In the case study, the morphing camber system was found to allow a reduction of the drag when the lift coefficient was higher than 0.48.
KW  - morphing camber
KW  - morphing trailing edge
KW  - morphing leading edge
KW  - wind tunnel testing
KW  - morphing wing
DO  - 10.3390/aerospace7030023
ER  -
TY  - EJOU
AU  - Zhu, Xiaobo
AU  - He, Honglin
AU  - Ma, Mingguo
AU  - Ren, Xiaoli
AU  - Zhang, Li
AU  - Zhang, Fawei
AU  - Li, Yingnian
AU  - Shi, Peili
AU  - Chen, Shiping
AU  - Wang, Yanfen
AU  - Xin, Xiaoping
AU  - Ma, Yaoming
AU  - Zhang, Yu
AU  - Du, Mingyuan
AU  - Ge, Rong
AU  - Zeng, Na
AU  - Li, Pan
AU  - Niu, Zhongen
AU  - Zhang, Liyun
AU  - Lv, Yan
AU  - Song, Zengjing
AU  - Gu, Qing
TI  - Estimating Ecosystem Respiration in the Grasslands of Northern China Using Machine Learning: Model Evaluation and Comparison
T2  - Sustainability

PY  - 2020
VL  - 12
IS  - 5
SN  - 2071-1050

AB  - While a number of machine learning (ML) models have been used to estimate RE, systematic evaluation and comparison of these models are still limited. In this study, we developed three traditional ML models and a deep learning (DL) model, stacked autoencoders (SAE), to estimate RE in northern China&rsquo;s grasslands. The four models were trained with two strategies: training for all of northern China&rsquo;s grasslands and separate training for the alpine and temperate grasslands. Our results showed that all four ML models estimated RE in northern China&rsquo;s grasslands fairly well, while the SAE model performed best (R2 = 0.858, RMSE = 0.472 gC m&minus;2 d&minus;1, MAE = 0.304 gC m&minus;2 d&minus;1). Models trained with the two strategies had almost identical performances. The enhanced vegetation index and soil organic carbon density (SOCD) were the two most important environmental variables for estimating RE in the grasslands of northern China. Air temperature (Ta) was more important than the growing season land surface water index (LSWI) in the alpine grasslands, while the LSWI was more important than Ta in the temperate grasslands. These findings may promote the application of DL models and the inclusion of SOCD for RE estimates with increased accuracy.
KW  - ecosystem respiration
KW  - machine learning
KW  - deep learning
KW  - grasslands
KW  - northern China
DO  - 10.3390/su12052099
ER  -
TY  - EJOU
AU  - Liu, Haojie
AU  - Liao, Kang
AU  - Lin, Chunyu
AU  - Zhao, Yao
AU  - Liu, Meiqin
TI  - PLIN: A Network for Pseudo-LiDAR Point Cloud Interpolation
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 6
SN  - 1424-8220

AB  - LiDAR sensors can provide dependable 3D spatial information at a low frequency (around 10 Hz) and have been widely applied in the field of autonomous driving and unmanned aerial vehicle (UAV). However, the camera with a higher frequency (around 20 Hz) has to be decreased so as to match with LiDAR in a multi-sensor system. In this paper, we propose a novel Pseudo-LiDAR interpolation network (PLIN) to increase the frequency of LiDAR sensor data. PLIN can generate temporally and spatially high-quality point cloud sequences to match the high frequency of cameras. To achieve this goal, we design a coarse interpolation stage guided by consecutive sparse depth maps and motion relationship. We also propose a refined interpolation stage guided by the realistic scene. Using this coarse-to-fine cascade structure, our method can progressively perceive multi-modal information and generate accurate intermediate point clouds. To the best of our knowledge, this is the first deep framework for Pseudo-LiDAR point cloud interpolation, which shows appealing applications in navigation systems equipped with LiDAR and cameras. Experimental results demonstrate that PLIN achieves promising performance on the KITTI dataset, significantly outperforming the traditional interpolation method and the state-of-the-art video interpolation technique.
KW  - 3D point cloud
KW  - pseudo-LiDAR interpolation
KW  - convolutional neural networks
KW  - depth completion
KW  - video interpolation
DO  - 10.3390/s20061573
ER  -
TY  - EJOU
AU  - Osco, Lucas P.
AU  - Ramos, Ana P.
AU  - Faita Pinheiro, Mayara M.
AU  - Moriya, Érika A.
AU  - Imai, Nilton N.
AU  - Estrabis, Nayara
AU  - Ianczyk, Felipe
AU  - Araújo, Fábio F.
AU  - Liesenberg, Veraldo
AU  - Jorge, Lúcio A.
AU  - Li, Jonathan
AU  - Ma, Lingfei
AU  - Gonçalves, Wesley N.
AU  - Marcato Junior, José
AU  - Eduardo Creste, José
TI  - A Machine Learning Framework to Predict Nutrient Content in Valencia-Orange Leaf Hyperspectral Measurements
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - This paper presents a framework based on machine learning algorithms to predict nutrient content in leaf hyperspectral measurements. This is the first approach to evaluate macro- and micronutrient content with both machine learning and reflectance/first-derivative data. For this, citrus-leaves collected at a Valencia-orange orchard were used. Their spectral data was measured with a Fieldspec ASD FieldSpec&reg; HandHeld 2 spectroradiometer and the surface reflectance and first-derivative spectra from the spectral range of 380 to 1020 nm (640 spectral bands) was evaluated. A total of 320 spectral signatures were collected, and the leaf-nutrient content (N, P, K, Mg, S, Cu, Fe, Mn, and Zn) was associated with them. For this, 204,800 (320 &times; 640) combinations were used. The following machine learning algorithms were used in this framework: k-Nearest Neighbor (kNN), Lasso Regression, Ridge Regression, Support Vector Machine (SVM), Artificial Neural Network (ANN), Decision Tree (DT), and Random Forest (RF). The training methods were assessed based on Cross-Validation and Leave-One-Out. The Relief-F metric of the algorithms&rsquo; prediction was used to determine the most contributive wavelength or spectral region associated with each nutrient. This approach was able to return, with high predictions (R2), nutrients like N (0.912), Mg (0.832), Cu (0.861), Mn (0.898), and Zn (0.855), and, to a lesser extent, P (0.771), K (0.763), and S (0.727). These accuracies were obtained with different algorithms, but RF was the most suitable to model most of them. The results indicate that, for the Valencia-orange leaves, surface reflectance data is more suitable to predict macronutrients, while first-derivative spectra is better linked to micronutrients. A final contribution of this study is the identification of the wavelengths responsible for contributing to these predictions.
KW  - spectroscopy
KW  - proximal sensor
KW  - macronutrient
KW  - micronutrient
KW  - artificial intelligence
DO  - 10.3390/rs12060906
ER  -
TY  - EJOU
AU  - Shi, Haiyun
AU  - Li, Jie
AU  - Li, Zhi
TI  - A Distributed Strategy for Cooperative Autonomous Robots Using Pedestrian Behavior for Multi-Target Search in the Unknown Environment
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 6
SN  - 1424-8220

AB  - Searching multiple targets with swarm robots is a realistic and significant problem. The goal is to search the targets in the minimum time while avoiding collisions with other robots. In this paper, inspired by pedestrian behavior, swarm robotic pedestrian behavior (SRPB) was proposed. It considered many realistic constraints in the multi-target search problem, including limited communication range, limited working time, unknown sources, unknown extrema, the arbitrary initial location of robots, non-oriented search, and no central coordination. The performance of different cooperative strategies was evaluated in terms of average time to find the first, the half, and the last source, the number of located sources and the collision rate. Several experiments with different target signals, fixed initial location, arbitrary initial location, different population sizes, and the different number of targets were implemented. It was demonstrated by numerous experiments that SRPB had excellent stability, quick source seeking, a high number of located sources, and a low collision rate in various search strategies.
KW  - distributed strategy
KW  - pedestrian behavior
KW  - swarm intelligence
KW  - swarm robots
KW  - multi-target search
DO  - 10.3390/s20061606
ER  -
TY  - EJOU
AU  - Pashaei, Mohammad
AU  - Kamangir, Hamid
AU  - Starek, Michael J.
AU  - Tissot, Philippe
TI  - Review and Evaluation of Deep Learning Architectures for Efficient Land Cover Mapping with UAS Hyper-Spatial Imagery: A Case Study Over a Wetland
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - Deep learning has already been proved as a powerful state-of-the-art technique for many image understanding tasks in computer vision and other applications including remote sensing (RS) image analysis. Unmanned aircraft systems (UASs) offer a viable and economical alternative to a conventional sensor and platform for acquiring high spatial and high temporal resolution data with high operational flexibility. Coastal wetlands are among some of the most challenging and complex ecosystems for land cover prediction and mapping tasks because land cover targets often show high intra-class and low inter-class variances. In recent years, several deep convolutional neural network (CNN) architectures have been proposed for pixel-wise image labeling, commonly called semantic image segmentation. In this paper, some of the more recent deep CNN architectures proposed for semantic image segmentation are reviewed, and each model&rsquo;s training efficiency and classification performance are evaluated by training it on a limited labeled image set. Training samples are provided using the hyper-spatial resolution UAS imagery over a wetland area and the required ground truth images are prepared by manual image labeling. Experimental results demonstrate that deep CNNs have a great potential for accurate land cover prediction task using UAS hyper-spatial resolution images. Some simple deep learning architectures perform comparable or even better than complex and very deep architectures with remarkably fewer training epochs. This performance is especially valuable when limited training samples are available, which is a common case in most RS applications.
KW  - coastal wetland
KW  - land cover mapping
KW  - semantic image segmentation
KW  - machine learning
KW  - deep learning
KW  - convolutional neural networks
KW  - transfer learning
KW  - unmanned aircraft systems
DO  - 10.3390/rs12060959
ER  -
TY  - EJOU
AU  - Liu, Changyu
AU  - Huang, Xiaodong
AU  - Li, Xubing
AU  - Liang, Tiangang
TI  - MODIS Fractional Snow Cover Mapping Using Machine Learning Technology in a Mountainous Area
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - To improve the poor accuracy of the MODIS (Moderate Resolution Imaging Spectroradiometer) daily fractional snow cover product over the complex terrain of the Tibetan Plateau (RMSE = 0.30), unmanned aerial vehicle and machine learning technologies are employed to map the fractional snow cover based on MODIS over this terrain. Three machine learning models, including random forest, support vector machine, and back-propagation artificial neural network models, are trained and compared in this study. The results indicate that compared with the MODIS daily fractional snow cover product, the introduction of a highly accurate snow map acquired by unmanned aerial vehicles as a reference into machine learning models can significantly improve the MODIS fractional snow cover mapping accuracy. The random forest model shows the best accuracy among the three machine learning models, with an RMSE (root-mean-square error) of 0.23, especially over forestland and shrubland, with RMSEs of 0.13 and 0.18, respectively. Although the accuracy of the support vector machine and back-propagation artificial neural network models are worse over forestland and shrubland, their average errors are still better than that of MOD10A1. Different fractional snow cover gradients also affect the accuracy of the machine learning algorithms. Nevertheless, the random forest model remains stable in different fractional snow cover gradients and is, therefore, the best machine learning algorithm for MODIS fractional snow cover mapping in Tibetan Plateau areas with complex terrain and severely fragmented snow cover.
KW  - MODIS
KW  - fractinal snow cover
KW  - UAV
KW  - Tibetan Plateau
DO  - 10.3390/rs12060962
ER  -
TY  - EJOU
AU  - Sonobe, Rei
AU  - Hirono, Yuhei
AU  - Oi, Ayako
TI  - Non-Destructive Detection of Tea Leaf Chlorophyll Content Using Hyperspectral Reflectance and Machine Learning Algorithms
T2  - Plants

PY  - 2020
VL  - 9
IS  - 3
SN  - 2223-7747

AB  - Tea trees are kept in shaded locations to increase their chlorophyll content, which influences green tea quality. Therefore, monitoring change in chlorophyll content under low light conditions is important for managing tea trees and producing high-quality green tea. Hyperspectral remote sensing is one of the most frequently used methods for estimating chlorophyll content. Numerous studies based on data collected under relatively low-stress conditions and many hyperspectral indices and radiative transfer models show that shade-grown tea performs poorly. The performance of four machine learning algorithms&mdash;random forest, support vector machine, deep belief nets, and kernel-based extreme learning machine (KELM)&mdash;in evaluating data collected from tea leaves cultivated under different shade treatments was tested. KELM performed best with a root-mean-square error of 8.94 &plusmn; 3.05 &mu;g cm&minus;2 and performance to deviation values from 1.70 to 8.04 for the test data. These results suggest that a combination of hyperspectral reflectance and KELM has the potential to trace changes in the chlorophyll content of shaded tea leaves.
KW  - deep belief nets
KW  - extreme learning machine
KW  - first derivative spectra
KW  - random forest
KW  - shade-grown tea
KW  - support vector machine
DO  - 10.3390/plants9030368
ER  -
TY  - EJOU
AU  - Martin-Abadal, Miguel
AU  - Ruiz-Frau, Ana
AU  - Hinz, Hilmar
AU  - Gonzalez-Cid, Yolanda
TI  - Jellytoring: Real-Time Jellyfish Monitoring Based on Deep Learning Object Detection
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 6
SN  - 1424-8220

AB  - During the past decades, the composition and distribution of marine species have changed due to multiple anthropogenic pressures. Monitoring these changes in a cost-effective manner is of high relevance to assess the environmental status and evaluate the effectiveness of management measures. In particular, recent studies point to a rise of jellyfish populations on a global scale, negatively affecting diverse marine sectors like commercial fishing or the tourism industry. Past monitoring efforts using underwater video observations tended to be time-consuming and costly due to human-based data processing. In this paper, we present Jellytoring, a system to automatically detect and quantify different species of jellyfish based on a deep object detection neural network, allowing us to automatically record jellyfish presence during long periods of time. Jellytoring demonstrates outstanding performance on the jellyfish detection task, reaching an F1 score of 95.2%; and also on the jellyfish quantification task, as it correctly quantifies the number and class of jellyfish on a real-time processed video sequence up to a 93.8% of its duration. The results of this study are encouraging and provide the means towards a efficient way to monitor jellyfish, which can be used for the development of a jellyfish early-warning system, providing highly valuable information for marine biologists and contributing to the reduction of jellyfish impacts on humans.
KW  - deep learning
KW  - object detection
KW  - jellyfish quantification
KW  - jellyfish monitoring
DO  - 10.3390/s20061708
ER  -
TY  - EJOU
AU  - Shi, Wenlei
AU  - Li, Zerui
AU  - Lv, Wenjun
AU  - Wu, Yuping
AU  - Chang, Ji
AU  - Li, Xiaochuan
TI  - Laplacian Support Vector Machine for Vibration-Based Robotic Terrain Classification
T2  - Electronics

PY  - 2020
VL  - 9
IS  - 3
SN  - 2079-9292

AB  - The achievement of robot autonomy has environmental perception as a prerequisite. The hazards rendered from uneven, soft and slippery terrains, which are generally named non-geometric hazards, are another potential threat reducing the traversing efficient, and therefore receiving more and more attention from the robotics community. In the paper, the vibration-based terrain classification (VTC) is investigated by taking a very practical issue, i.e., lack of labels, into consideration. According to the intrinsic temporal correlation existing in the sampled terrain sequence, a modified Laplacian SVM is proposed to utilise the unlabelled data to improve the classification performance. To the best of our knowledge, this is the first paper studying semi-supervised learning problem in robotic terrain classification. The experiment demonstrates that: (1) supervised learning (SVM) achieves a relatively low classification accuracy if given insufficient labels; (2) feature-space homogeneity based semi-supervised learning (traditional Laplacian SVM) cannot improve supervised learning&rsquo;s accuracy, and even makes it worse; (3) feature- and temporal-space based semi-supervised learning (modified Laplacian SVM), which is proposed in the paper, could increase the classification accuracy very significantly.
KW  - non-geometric hazards
KW  - terrain classification
KW  - vibration
KW  - semi-supervised learning
DO  - 10.3390/electronics9030513
ER  -
TY  - EJOU
AU  - Tomaszewski, Michał
AU  - Michalski, Paweł
AU  - Osuchowski, Jakub
TI  - Evaluation of Power Insulator Detection Efficiency with the Use of Limited Training Dataset
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 6
SN  - 2076-3417

AB  - This article presents an analysis of the effectiveness of object detection in digital images with the application of a limited quantity of input. The possibility of using a limited set of learning data was achieved by developing a detailed scenario of the task, which strictly defined the conditions of detector operation in the considered case of a convolutional neural network. The described solution utilizes known architectures of deep neural networks in the process of learning and object detection. The article presents comparisons of results from detecting the most popular deep neural networks while maintaining a limited training set composed of a specific number of selected images from diagnostic video. The analyzed input material was recorded during an inspection flight conducted along high-voltage lines. The object detector was built for a power insulator. The main contribution of the presented papier is the evidence that a limited training set (in our case, just 60 training frames) could be used for object detection, assuming an outdoor scenario with low variability of environmental conditions. The decision of which network will generate the best result for such a limited training set is not a trivial task. Conducted research suggests that the deep neural networks will achieve different levels of effectiveness depending on the amount of training data. The most beneficial results were obtained for two convolutional neural networks: the faster region-convolutional neural network (faster R-CNN) and the region-based fully convolutional network (R-FCN). Faster R-CNN reached the highest AP (average precision) at a level of 0.8 for 60 frames. The R-FCN model gained a worse AP result; however, it can be noted that the relationship between the number of input samples and the obtained results has a significantly lower influence than in the case of other CNN models, which, in the authors&rsquo; assessment, is a desired feature in the case of a limited training set.
KW  - convolutional neural network
KW  - deep neural network
KW  - insulator detection
KW  - efficiency evaluation
KW  - power system maintenance
DO  - 10.3390/app10062104
ER  -
TY  - EJOU
AU  - Tmušić, Goran
AU  - Manfreda, Salvatore
AU  - Aasen, Helge
AU  - James, Mike R.
AU  - Gonçalves, Gil
AU  - Ben-Dor, Eyal
AU  - Brook, Anna
AU  - Polinova, Maria
AU  - Arranz, Jose J.
AU  - Mészáros, János
AU  - Zhuang, Ruodan
AU  - Johansen, Kasper
AU  - Malbeteau, Yoann
AU  - de Lima, Isabel P.
AU  - Davids, Corine
AU  - Herban, Sorin
AU  - McCabe, Matthew F.
TI  - Current Practices in UAS-based Environmental Monitoring
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - With the increasing role that unmanned aerial systems (UAS) are playing in data collection for environmental studies, two key challenges relate to harmonizing and providing standardized guidance for data collection, and also establishing protocols that are applicable across a broad range of environments and conditions. In this context, a network of scientists are cooperating within the framework of the Harmonious Project to develop and promote harmonized mapping strategies and disseminate operational guidance to ensure best practice for data collection and interpretation. The culmination of these efforts is summarized in the present manuscript. Through this synthesis study, we identify the many interdependencies of each step in the collection and processing chain, and outline approaches to formalize and ensure a successful workflow and product development. Given the number of environmental conditions, constraints, and variables that could possibly be explored from UAS platforms, it is impractical to provide protocols that can be applied universally under all scenarios. However, it is possible to collate and systematically order the fragmented knowledge on UAS collection and analysis to identify the best practices that can best ensure the streamlined and rigorous development of scientific products.
KW  - UAS-based mapping
KW  - environmental monitoring
KW  - effective workflow
KW  - guidelines
DO  - 10.3390/rs12061001
ER  -
TY  - EJOU
AU  - Xu, Jin
AU  - Wang, Haixia
AU  - Cui, Can
AU  - Zhao, Baigang
AU  - Li, Bo
TI  - Oil Spill Monitoring of Shipborne Radar Image Features Using SVM and Local Adaptive Threshold
T2  - Algorithms

PY  - 2020
VL  - 13
IS  - 3
SN  - 1999-4893

AB  - In the case of marine accidents, monitoring marine oil spills can provide an important basis for identifying liabilities and assessing the damage. Shipborne radar can ensure large-scale, real-time monitoring, in all weather, with high-resolution. It therefore has the potential for broad applications in oil spill monitoring. Considering the original gray-scale image from the shipborne radar acquired in the case of the Dalian 7.16 oil spill accident, a complete oil spill detection method is proposed. Firstly, the co-frequency interferences and speckles in the original image are eliminated by preprocessing. Secondly, the wave information is classified using a support vector machine (SVM), and the effective wave monitoring area is generated according to the gray distribution matrix. Finally, oil spills are detected by a local adaptive threshold and displayed on an electronic chart based on geographic information system (GIS). The results show that the SVM can extract the effective wave information from the original shipborne radar image, and the local adaptive threshold method has strong applicability for oil film segmentation. This method can provide a technical basis for real-time cleaning and liability determination in oil spill accidents.
KW  - oil spill
KW  - SVM
KW  - real-time monitoring
KW  - shipborne radar
KW  - remote sensing
KW  - image processing
KW  - GIS
DO  - 10.3390/a13030069
ER  -
TY  - EJOU
AU  - Nguyen, Truong L.
AU  - Han, DongYeob
TI  - Detection of Road Surface Changes from Multi-Temporal Unmanned Aerial Vehicle Images Using a Convolutional Siamese Network
T2  - Sustainability

PY  - 2020
VL  - 12
IS  - 6
SN  - 2071-1050

AB  - Road quality commonly decreases due to aging and deterioration of road surfaces. As the number of roads that need to be surveyed increases, general maintenance&mdash;particularly surveillance&mdash;can be quite costly if carried out using traditional methods. Therefore, using unmanned aerial vehicles (UAVs) and deep learning to detect changes via surveys is a promising strategy. This study proposes a method for detecting changes on road surfaces using pairs of UAV images captured at different times. First, a convolutional Siamese network is introduced to extract the features of an image pair and a Euclidean distance function is applied to calculate the distance between two features. Then, a contrastive loss function is used to enlarge the distance between changed feature pairs and reduce the distance between unchanged feature pairs. Finally, the initial change map is improved based on the preliminary differences between the two input images. Our experimental results confirm the effectiveness of this approach.
KW  - change detection
KW  - convolutional Siamese network
KW  - unmanned aerial vehicles
KW  - image processing
DO  - 10.3390/su12062482
ER  -
TY  - EJOU
AU  - Elmes, Arthur
AU  - Alemohammad, Hamed
AU  - Avery, Ryan
AU  - Caylor, Kelly
AU  - Eastman, J. R.
AU  - Fishgold, Lewis
AU  - Friedl, Mark A.
AU  - Jain, Meha
AU  - Kohli, Divyani
AU  - Laso Bayas, Juan C.
AU  - Lunga, Dalton
AU  - McCarty, Jessica L.
AU  - Pontius, Robert G.
AU  - Reinmann, Andrew B.
AU  - Rogan, John
AU  - Song, Lei
AU  - Stoynova, Hristiana
AU  - Ye, Su
AU  - Yi, Zhuang-Fang
AU  - Estes, Lyndon
TI  - Accounting for Training Data Error in Machine Learning Applied to Earth Observations
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - Remote sensing, or Earth Observation (EO), is increasingly used to understand Earth system dynamics and create continuous and categorical maps of biophysical properties and land cover, especially based on recent advances in machine learning (ML). ML models typically require large, spatially explicit training datasets to make accurate predictions. Training data (TD) are typically generated by digitizing polygons on high spatial-resolution imagery, by collecting in situ data, or by using pre-existing datasets. TD are often assumed to accurately represent the truth, but in practice almost always have error, stemming from (1) sample design, and (2) sample collection errors. The latter is particularly relevant for image-interpreted TD, an increasingly commonly used method due to its practicality and the increasing training sample size requirements of modern ML algorithms. TD errors can cause substantial errors in the maps created using ML algorithms, which may impact map use and interpretation. Despite these potential errors and their real-world consequences for map-based decisions, TD error is often not accounted for or reported in EO research. Here we review the current practices for collecting and handling TD. We identify the sources of TD error, and illustrate their impacts using several case studies representing different EO applications (infrastructure mapping, global surface flux estimates, and agricultural monitoring), and provide guidelines for minimizing and accounting for TD errors. To harmonize terminology, we distinguish TD from three other classes of data that should be used to create and assess ML models: training reference data, used to assess the quality of TD during data generation; validation data, used to iteratively improve models; and map reference data, used only for final accuracy assessment. We focus primarily on TD, but our advice is generally applicable to all four classes, and we ground our review in established best practices for map accuracy assessment literature. EO researchers should start by determining the tolerable levels of map error and appropriate error metrics. Next, TD error should be minimized during sample design by choosing a representative spatio-temporal collection strategy, by using spatially and temporally relevant imagery and ancillary data sources during TD creation, and by selecting a set of legend definitions supported by the data. Furthermore, TD error can be minimized during the collection of individual samples by using consensus-based collection strategies, by directly comparing interpreted training observations against expert-generated training reference data to derive TD error metrics, and by providing image interpreters with thorough application-specific training. We strongly advise that TD error is incorporated in model outputs, either directly in bias and variance estimates or, at a minimum, by documenting the sources and implications of error. TD should be fully documented and made available via an open TD repository, allowing others to replicate and assess its use. To guide researchers in this process, we propose three tiers of TD error accounting standards. Finally, we advise researchers to clearly communicate the magnitude and impacts of TD error on map outputs, with specific consideration given to the likely map audience.
KW  - training data
KW  - machine learning
KW  - map accuracy
KW  - error propagation
DO  - 10.3390/rs12061034
ER  -
TY  - EJOU
AU  - Godone, Danilo
AU  - Allasia, Paolo
AU  - Borrelli, Luigi
AU  - Gullà, Giovanni
TI  - UAV and Structure from Motion Approach to Monitor the Maierato Landslide Evolution
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - In February 2010 a large landslide affected the Maierato municipality (Calabria, Italy). The landslide, mainly caused by a period of prolonged and intense rainfalls, produced a mass displacement of about 5 million m&sup3; and several damages to farmlands, houses and infrastructures. In the aftermath several conventional monitoring actions were carried out. In the current post emergency phase, the monitoring was resumed by carrying out unmanned aerial vehicles (UAV) flights in order to describe the recent behavior of the landslide and to assess residual risk. Thanks to the potentialities of the structure from motion algorithms and the availability of post emergency reconnaissance photos and a previous 3D dataset, the three-dimensional evolution of the area was computed. Moreover, an experimental multispectral flight was carried out and its results supported the interpretation of local phenomena. The dataset allowed to quantify the elevation losses and raises in several peculiar sectors of the landslide. The obtained results confirm that the UAV monitoring and the structure from motion approach can effectively contribute to manage residual risk in the medium and long term within an integrated geotechnical monitoring network.
KW  - GIS analysis
KW  - large landslide
KW  - monitoring
KW  - residual risk
KW  - RPAS
KW  - salvaged datasets
DO  - 10.3390/rs12061039
ER  -
TY  - EJOU
AU  - Gibril, Mohamed Barakat A.
AU  - Kalantar, Bahareh
AU  - Al-Ruzouq, Rami
AU  - Ueda, Naonori
AU  - Saeidi, Vahideh
AU  - Shanableh, Abdallah
AU  - Mansor, Shattri
AU  - Shafri, Helmi Z. M.
TI  - Mapping Heterogeneous Urban Landscapes from the Fusion of Digital Surface Model and Unmanned Aerial Vehicle-Based Images Using Adaptive Multiscale Image Segmentation and Classification
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - Considering the high-level details in an ultrahigh-spatial-resolution (UHSR) unmanned aerial vehicle (UAV) dataset, detailed mapping of heterogeneous urban landscapes is extremely challenging because of the spectral similarity between classes. In this study, adaptive hierarchical image segmentation optimization, multilevel feature selection, and multiscale (MS) supervised machine learning (ML) models were integrated to accurately generate detailed maps for heterogeneous urban areas from the fusion of the UHSR orthomosaic and digital surface model (DSM). The integrated approach commenced through a preliminary MS image segmentation parameter selection, followed by the application of three supervised ML models, namely, random forest (RF), support vector machine (SVM), and decision tree (DT). These models were implemented at the optimal MS levels to identify preliminary information, such as the optimal segmentation level(s) and relevant features, for extracting 12 land use/land cover (LULC) urban classes from the fused datasets. Using the information obtained from the first phase of the analysis, detailed MS classification was iteratively conducted to improve the classification accuracy and derive the final urban LULC maps. Two UAV-based datasets were used to develop and assess the effectiveness of the proposed framework. The hierarchical classification of the pilot study area showed that the RF was superior with an overall accuracy (OA) of 94.40% and a kappa coefficient (K) of 0.938, followed by SVM (OA = 92.50% and K = 0.917) and DT (OA = 91.60% and K = 0.908). The classification results of the second dataset revealed that SVM was superior with an OA of 94.45% and K of 0.938, followed by RF (OA = 92.46% and K = 0.916) and DT (OA = 90.46% and K = 0.893). The proposed framework exhibited an excellent potential for the detailed mapping of heterogeneous urban landscapes from the fusion of UHSR orthophoto and DSM images using various ML models.
KW  - unmanned aerial vehicle
KW  - urban LULC
KW  - GEOBIA
KW  - multiscale classification
DO  - 10.3390/rs12071081
ER  -
TY  - EJOU
AU  - Zhang, Weixing
AU  - Liljedahl, Anna K.
AU  - Kanevskiy, Mikhail
AU  - Epstein, Howard E.
AU  - Jones, Benjamin M.
AU  - Jorgenson, M. T.
AU  - Kent, Kelcy
TI  - Transferability of the Deep Learning Mask R-CNN Model for Automated Mapping of Ice-Wedge Polygons in High-Resolution Satellite and UAV Images
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - State-of-the-art deep learning technology has been successfully applied to relatively small selected areas of very high spatial resolution (0.15 and 0.25 m) optical aerial imagery acquired by a fixed-wing aircraft to automatically characterize ice-wedge polygons (IWPs) in the Arctic tundra. However, any mapping of IWPs at regional to continental scales requires images acquired on different sensor platforms (particularly satellite) and a refined understanding of the performance stability of the method across sensor platforms through reliable evaluation assessments. In this study, we examined the transferability of a deep learning Mask Region-Based Convolutional Neural Network (R-CNN) model for mapping IWPs in satellite remote sensing imagery (~0.5 m) covering 272 km2 and unmanned aerial vehicle (UAV) (0.02 m) imagery covering 0.32 km2. Multi-spectral images were obtained from the WorldView-2 satellite sensor and pan-sharpened to ~0.5 m, and a 20 mp CMOS sensor camera onboard a UAV, respectively. The training dataset included 25,489 and 6022 manually delineated IWPs from satellite and fixed-wing aircraft aerial imagery near the Arctic Coastal Plain, northern Alaska. Quantitative assessments showed that individual IWPs were correctly detected at up to 72% and 70%, and delineated at up to 73% and 68% F1 score accuracy levels for satellite and UAV images, respectively. Expert-based qualitative assessments showed that IWPs were correctly detected at good (40&ndash;60%) and excellent (80&ndash;100%) accuracy levels for satellite and UAV images, respectively, and delineated at excellent (80&ndash;100%) level for both images. We found that (1) regardless of spatial resolution and spectral bands, the deep learning Mask R-CNN model effectively mapped IWPs in both remote sensing satellite and UAV images; (2) the model achieved a better accuracy in detection with finer image resolution, such as UAV imagery, yet a better accuracy in delineation with coarser image resolution, such as satellite imagery; (3) increasing the number of training data with different resolutions between the training and actual application imagery does not necessarily result in better performance of the Mask R-CNN in IWPs mapping; (4) and overall, the model underestimates the total number of IWPs particularly in terms of disjoint/incomplete IWPs.
KW  - ice-wedge polygons
KW  - Arctic
KW  - deep learning
KW  - Mask R-CNN
KW  - WorldView-2
KW  - UAV
DO  - 10.3390/rs12071085
ER  -
TY  - EJOU
AU  - Bao, Hanqing
AU  - Ming, Dongping
AU  - Guo, Ya
AU  - Zhang, Kui
AU  - Zhou, Keqi
AU  - Du, Shigao
TI  - DFCNN-Based Semantic Recognition of Urban Functional Zones by Integrating Remote Sensing Data and POI Data
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - The urban functional zone, as a special fundamental unit of the city, helps to understand the complex interaction between human space activities and environmental changes. Based on the recognition of physical and social semantics of buildings, combining remote sensing data and social sensing data is an effective way to quickly and accurately comprehend urban functional zone patterns. From the object level, this paper proposes a novel object-wise recognition strategy based on very high spatial resolution images (VHSRI) and social sensing data. First, buildings are extracted according to the physical semantics of objects; second, remote sensing and point of interest (POI) data are combined to comprehend the spatial distribution and functional semantics in the social function context; finally, urban functional zones are recognized and determined by building with physical and social functional semantics. When it comes to building geometrical information extraction, this paper, given the importance of building boundary information, introduces the deeper edge feature map (DEFM) into the segmentation and classification, and improves the result of building boundary recognition. Given the difficulty in understanding deeper semantics and spatial information and the limitation of traditional convolutional neural network (CNN) models in feature extraction, we propose the Deeper-Feature Convolutional Neural Network (DFCNN), which is able to extract more and deeper features for building semantic recognition. Experimental results conducted on a Google Earth image of Shenzhen City show that the proposed method and model are able to effectively, quickly, and accurately recognize urban functional zones by combining building physical semantics and social functional semantics, and are able to ensure the accuracy of urban functional zone recognition.
KW  - urban functional zones
KW  - semantic recognition
KW  - stratified scale estimation
KW  - deeper-feature CNN (DFCNN)
KW  - POIs
DO  - 10.3390/rs12071088
ER  -
TY  - EJOU
AU  - Song, Ahram
AU  - Kim, Yongil
TI  - Transfer Change Rules from Recurrent Fully Convolutional Networks for Hyperspectral Unmanned Aerial Vehicle Images without Ground Truth Data
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - Change detection (CD) networks based on supervised learning have been used in diverse CD tasks. However, such supervised CD networks require a large amount of data and only use information from current images. In addition, it is time consuming to manually acquire the ground truth data for newly obtained images. Here, we proposed a novel method for CD in case of a lack of training data in an area near by another one with the available ground truth data. The proposed method automatically entails generating training data and fine-tuning the CD network. To detect changes in target images without ground truth data, the difference images were generated using spectral similarity measure, and the training data were selected via fuzzy c-means clustering. Recurrent fully convolutional networks with multiscale three-dimensional filters were used to extract objects of various sizes from unmanned aerial vehicle (UAV) images. The CD network was pre-trained on labeled source domain data; then, the network was fine-tuned on target images using generated training data. Two further CD networks were trained with a combined weighted loss function. The training data in the target domain were iteratively updated using he prediction map of the CD network. Experiments on two hyperspectral UAV datasets confirmed that the proposed method is capable of transferring change rules and improving CD results based on training data extracted in an unsupervised way.
KW  - change detection
KW  - hyperspectral unmanned aerial vehicle
KW  - spectral similarity measures
DO  - 10.3390/rs12071099
ER  -
TY  - EJOU
AU  - Yuzugullu, Onur
AU  - Lorenz, Frank
AU  - Fröhlich, Peter
AU  - Liebisch, Frank
TI  - Understanding Fields by Remote Sensing: Soil Zoning and Property Mapping
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - Precision agriculture aims to optimize field management to increase agronomic yield, reduce environmental impact, and potentially foster soil carbon sequestration. In 2015, the Copernicus mission, with Sentinel-1 and -2, opened a new era by providing freely available high spatial and temporal resolution satellite data. Since then, many studies have been conducted to understand, monitor and improve agricultural systems. This paper presents results from the SolumScire project, focusing on the prediction of the spatial distribution of soil zones and topsoil properties, such as pH, soil organic matter (SOM) and clay content in agricultural fields through random forest algorithms. For this purpose, samples from 120 fields were investigated. The zoning and soil property prediction has an accuracy greater than 90%. This is supported by a high agreement of the derived zones with farmer&rsquo;s observations. The trained models revealed a prediction accuracy of 94%, 89% and 96% for pH, SOM and clay content, respectively. The obtained models for soil properties can support precision field management, the improvement of soil sampling and fertilization strategies, and eventually the management of soil properties such as SOM.
KW  - soil property prediction
KW  - pH
KW  - soil organic matter
KW  - soil clay content
KW  - precision agriculture
KW  - Copernicus mission
KW  - Sentinel
KW  - multi-spectral imagery
KW  - synthetic aperture radar imagery
KW  - machine learning
KW  - random forest
DO  - 10.3390/rs12071116
ER  -

TY  - EJOU
AU  - Kavats, Olena
AU  - Khramov, Dmitriy
AU  - Sergieieva, Kateryna
AU  - Vasyliev, Volodymyr
TI  - Monitoring of Sugarcane Harvest in Brazil Based on Optical and SAR Data
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 24
SN  - 2072-4292

AB  - The algorithms for determining sugarcane harvest dates are proposed; the algorithms allow the ability to monitor large areas and are based on the publicly available Synthetic Aperture Radar (SAR) and optical satellite data. Algorithm 1 uses the NDVI (Normalized Difference Vegetation Index) time series derived from Sentinel-2 data. Sharp and continuous decrease in the NDVI values is the main sign of sugarcane harvest. The NDVI time series allows the ability to determine most harvest dates. The best estimates of the sugarcane areas harvested per month have been obtained from March to August 2018 when cloudy pixel percentage is less than 45% of the image area. Algorithm 2 of the harvest monitoring uses the coherence time series derived from Sentinel-1 Single Look Complex (SLC) images and optical satellite data. Low coherence, demonstrating sharp growth upon the harvest completion, corresponds to the harvest period. The NDVI time series trends were used to refine the algorithm. It is supposed that the descending NDVI trend corresponds to harvest. The algorithms were used to identify the harvest dates and calculate the harvested areas of the reference sample of 574 sugarcane parcels with a total area of 3745 ha in the state of S&atilde;o Paulo, Brazil. The harvested areas identified by visual interpretation coincide with the optical-data algorithm (algorithm 1) by 97%; the coincidence with the algorithm based on SAR and optical data (algorithm 2) is 90%. The main practical applications of the algorithms are harvest monitoring and identification of the harvested fields to estimate the harvested area.
KW  - Sentinel-1
KW  - Sentinel-2
KW  - NDVI
KW  - SLC
KW  - harvest
KW  - sugarcane
KW  - coherence
KW  - Brazil
KW  - monitoring
DO  - 10.3390/rs12244080
TY  - EJOU
AU  - Zhang, Xuechen
AU  - Shen, Huanfeng
AU  - Li, Tongwen
AU  - Zhang, Liangpei
TI  - The Effects of Fireworks Discharge on Atmospheric PM2.5 Concentration in the Chinese Lunar New Year
T2  - International Journal of Environmental Research and Public Health

PY  - 2020
VL  - 17
IS  - 24
SN  - 1660-4601

AB  - Discharging fireworks during the Chinese Lunar New Year celebrations is a deep-rooted custom in China. In this paper, we analyze the effect of this cultural activity on PM2.5 concentration using both ground observations and satellite data. By combining remote sensing data, the problem of uneven spatial distribution of ground monitoring has been compensated, and the research time span has been expanded. The results show that the extensive firework displays on New Year&rsquo;s Eve lead to a remarkable increase in nationwide PM2.5 concentration, which were 159~223% of the average level, indicating the instantaneous effect far exceeds that of any other factor over the whole year. However, the averaged PM2.5 concentrations of the celebration period were 0.99~16.32 &mu;g/m3 lower compared to the average values of the corresponding pre-celebration period and post-celebration period, indicating the sustained effect is not very significant. The implementation of firework prohibition policies can greatly reduce the instantaneous PM2.5 increase, but no obvious air quality improvement is observed over the entire celebration period. Combining these findings and the cultural significance of this activity, we recommend that this custom is actively maintained, using new technologies and scientific governance programs to minimize the negative effects.
KW  - fireworks
KW  - PM2.5 concentration
KW  - Chinese Lunar New Year
KW  - remote sensing
KW  - firework prohibition policy
DO  - 10.3390/ijerph17249333
TY  - EJOU
AU  - Peng, Xi
AU  - Zhao, Anjiu
AU  - Chen, Yongfu
AU  - Chen, Qiao
AU  - Liu, Haodong
AU  - Wang, Juan
AU  - Li, Huayu
TI  - Comparison of Modeling Algorithms for Forest Canopy Structures Based on UAV-LiDAR: A Case Study in Tropical China
T2  - Forests

PY  - 2020
VL  - 11
IS  - 12
SN  - 1999-4907

AB  - Knowledge of forest structure is vital for sustainable forest management decisions. Terrestrial laser scanning cannot describe the canopy trees in a large area, and it is unclear whether unmanned aerial vehicle-light detection and ranging (UAV-LiDAR) data have the ability to capture the forest canopy structural parameters in tropical forests. In this study, we estimated five forest canopy structures (stand density (N), basic area (G), above-ground biomass (AGB), Lorey&rsquo;s mean height (HL), and under-crown height (hT)) with four modeling algorithms (linear regression (LR), bagged tree (BT), support vector regression (SVR), and random forest (RF)) based on UAV-LiDAR data and 60 sample plot data from tropical forests in Hainan and determined the optimal algorithms for the five canopy structures by comparing the performance of the four algorithms. First, we defined the canopy tree as a tree with a height &ge;70% HL. Then, UAV-LiDAR metrics were calculated, and the LiDAR metrics were screened by recursive feature elimination (RFE). Finally, a prediction model of the five forest canopy structural parameters was established by the four algorithms, and the results were compared. The metrics&rsquo; screening results show that the most important LiDAR indexes for estimating HL, AGB, and hT are the leaf area index and some height metrics, while the most important indexes for estimating N and G are the kurtosis of heights and the coefficient of variation of height. The relative root mean squared error (rRMSE) of five structure parameters showed the following: when modeling HL, the rRMSEs (10.60%&ndash;12.05%) obtained by the four algorithms showed little difference; when N was modeled, BT, RF, and SVR had lower rRMSEs (26.76%&ndash;27.44%); when G was modeled, the rRMSEs of RF and SVR (15.37%&ndash;15.87%) were lower; when hT was modeled, BT, RF, and SVR had lower rRMSEs (10.24%&ndash;11.07%); when AGB was modeled, RF had the lowest rRMSE (26.75%). Our results will help facilitate choosing LiDAR indexes and modeling algorithms for tropical forest resource inventories.
KW  - tropical forests
KW  - vertical structure
KW  - forest attributes
KW  - regression model
KW  - recursive feature elimination
DO  - 10.3390/f11121324
TY  - EJOU
AU  - Hamilton, Dale
AU  - Levandovsky, Enoch
AU  - Hamilton, Nicholas
TI  - Mapping Burn Extent of Large Wildland Fires from Satellite Imagery Using Machine Learning Trained from Localized Hyperspatial Imagery
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 24
SN  - 2072-4292

AB  - Wildfires burn 4&ndash;10 million acres annually across the United States and wildland fire related damages and suppression costs have exceeded $13 billion for a single year. High-intensity wildfires contribute to post-fire erosion, degraded wildlife habitat, and loss of timber resources. Accurate and temporally adequate assessment of the effects of wildland fire on the environment is critical to improving the of wildland fire as a tool for restoring ecosystem resilience. Sensor miniaturization and small unmanned aircraft systems (sUAS) provide affordable, on-demand monitoring of wildland fire effects at a much finer spatial resolution than is possible with satellite imagery. The use of sUAS would allow researchers to obtain data with more detail at a much lower initial cost. Unfortunately, current regulatory and technical constraints prohibit the acquisition of imagery using sUAS for the entire extent of large fires. This research examined the use of sUAS imagery to train and validate burn severity and extent mapping of large wildland fires from various satellite images. Despite the lower resolution of the satellite image, the research utilized the advantages of satellite imagery such as global coverage, low cost, temporal stability, and spectral extent while leveraging the higher resolution of hyperspatial sUAS imagery for training and validating the mapping analytics.
KW  - support vector machine
KW  - fuzzy logic
KW  - wildland fire extent
KW  - wildland fire severity
KW  - small unmanned aircraft systems
KW  - landsat
DO  - 10.3390/rs12244097
TY  - EJOU
AU  - Hacohen, Shlomi
AU  - Medina, Oded
AU  - Grinshpoun, Tal
AU  - Shvalb, Nir
TI  - Improved GNSS Localization and Byzantine Detection in UAV Swarms
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 24
SN  - 1424-8220

AB  - Many tasks performed by swarms of unmanned aerial vehicles require localization. In many cases, the sensors that take part in the localization process suffer from inherent measurement errors. This problem is amplified when disruptions are added, either endogenously through Byzantine failures of agents within the swarm, or exogenously by some external source, such as a GNSS jammer. In this paper, we first introduce an improved localization method based on distance observation. Then, we devise schemes for detecting Byzantine agents, in scenarios of endogenous disruptions, and for detecting a disrupted area, in case the source of the problem is exogenous. Finally, we apply pool testing techniques to reduce the communication traffic and the computation time of our schemes. The optimal pool size should be chosen carefully, as very small or very large pools may impair the ability to identify the source/s of disruption. A set of simulated experiments demonstrates the effectiveness of our proposed methods, which enable reliable error estimation even amid disruptions. This work is the first, to the best of our knowledge, that embeds identification of endogenous and exogenous disruptions into the localization process.
KW  - FANET
KW  - UAV swarm
KW  - GNSS localization
KW  - Byzantine detection
KW  - pool testing
DO  - 10.3390/s20247239
TY  - EJOU
AU  - Armenta-Medina, Dagoberto
AU  - Ramirez-delReal, Tania A.
AU  - Villanueva-VÃ¡squez, Daniel
AU  - Mejia-Aguirre, Cristian
TI  - Trends on Advanced Information and Communication Technologies for Improving Agricultural Productivities: A Bibliometric Analysis
T2  - Agronomy

PY  - 2020
VL  - 10
IS  - 12
SN  - 2073-4395

AB  - In this work, an exhaustive revision is given of the literature associated with advanced information and communication technologies in agriculture within a window of 25 years using bibliometric tools enabled to detect of the main actors, structure, and dynamics in the scientific papers. The main findings are a trend of growth in the dynamics of publications associated with advanced information and communication technologies in agriculture productivity. Another assertion is that countries, like the USA, China, and Brazil, stand out in many publications due to allocating more resources to research, development, and agricultural productivity. In addition, the collaboration networks between countries are frequently in regions with closer cultural and idiomatic ties; additionally, terms&rsquo; occurrence are obtained with Louvain algorithm predominating four clusters: precision agriculture, smart agriculture, remote sensing, and climate smart agriculture. Finally, the thematic-map characterization with Callon&rsquo;s density and centrality is applied in three periods. The first period of thematic analysis shows a transition in detecting the variability of a nutrient, such as nitrogen, through the help of immature georeferenced techniques, towards greater remote sensing involvement. In the transition from the second to the third stage, the maturation of technologies, such as unmanned aerial vehicles, wireless sensor networks, and the machine learning area, is observed.
KW  - bibliometrics
KW  - precision agriculture
KW  - science mapping
KW  - smart farming
KW  - IoT
DO  - 10.3390/agronomy10121989
TY  - EJOU
AU  - De Vita, Fabrizio
AU  - Bruneo, Dario
TI  - Leveraging Stack4Things for Federated Learning in Intelligent Cyber Physical Systems
T2  - Journal of Sensor and Actuator Networks

PY  - 2020
VL  - 9
IS  - 4
SN  - 2224-2708

AB  - During the last decade, the Internet of Things acted as catalyst for the big data phenomenon. As result, modern edge devices can access a huge amount of data that can be exploited to build useful services. In such a context, artificial intelligence has a key role to develop intelligent systems (e.g., intelligent cyber physical systems) that create a connecting bridge with the physical world. However, as time goes by, machine and deep learning applications are becoming more complex, requiring increasing amounts of data and training time, which makes the use of centralized approaches unsuitable. Federated learning is an emerging paradigm which enables the cooperation of edge devices to learn a shared model (while keeping private their training data), thereby abating the training time. Although federated learning is a promising technique, its implementation is difficult and brings a lot of challenges. In this paper, we present an extension of Stack4Things, a cloud platform developed in our department; leveraging its functionalities, we enabled the deployment of federated learning on edge devices without caring their heterogeneity. Experimental results show a comparison with a centralized approach and demonstrate the effectiveness of the proposed approach in terms of both training time and model accuracy.
KW  - federated learning
KW  - intelligent cyber physical systems
KW  - stack4things
DO  - 10.3390/jsan9040059
TY  - EJOU
AU  - Samarin, Maxim
AU  - Zweifel, Lauren
AU  - Roth, Volker
AU  - Alewell, Christine
TI  - Identifying Soil Erosion Processes in Alpine Grasslands on Aerial Imagery with a U-Net Convolutional Neural Network
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 24
SN  - 2072-4292

AB  - Erosion in alpine grasslands is a major threat to ecosystem services of alpine soils. Natural causes for the occurrence of soil erosion are steep topography and prevailing climate conditions in combination with soil fragility. To increase our understanding of ongoing erosion processes and support sustainable land-use management, there is a need to acquire detailed information on spatial occurrence and temporal trends. Existing approaches to identify these trends are typically laborious, have lack of transferability to other regions, and are consequently only applicable to smaller regions. In order to overcome these limitations and create a sophisticated erosion monitoring tool capable of large-scale analysis, we developed a model based on U-Net, a fully convolutional neural network, to map different erosion processes on high-resolution aerial images (RGB, 0.25&ndash;0.5 m). U-Net was trained on a high-quality data set consisting of labeled erosion sites mapped with object-based image analysis (OBIA) for the Urseren Valley (Central Swiss Alps) for five aerial images (16 year period). We used the U-Net model to map the same study area and conduct quality assessments based on a held-out test region and a temporal transferability test on new images. Erosion classes are assigned according to their type (shallow landslide and sites with reduced vegetation affected by sheet erosion) or land-use impacts (livestock trails and larger management affected areas). We show that results obtained by OBIA and U-Net follow similar linear trends for the 16 year study period, exhibiting increases in total degraded area of 167% and 201%, respectively. Segmentations of eroded sites are generally in good agreement, but also display method-specific differences, which lead to an overall precision of 73%, a recall of 84%, and a F1-score of 78%. Our results show that U-Net is transferable to spatially (within our study area) and temporally unseen data (data from new years) and is therefore a method suitable to efficiently and successfully capture the temporal trends and spatial heterogeneity of degradation in alpine grasslands. Additionally, U-Net is a powerful and robust tool to map erosion sites in a predictive manner utilising large amounts of new aerial imagery.
KW  - deep learning
KW  - semantic segmentation
KW  - remote sensing
KW  - object-based image analysis
KW  - erosion mapping
KW  - landslides
KW  - livestock trails
KW  - sheet erosion
DO  - 10.3390/rs12244149
TY  - EJOU
AU  - Hassanijalilian, Oveis
AU  - Igathinathane, C.
AU  - Bajwa, Sreekala
AU  - Nowatzki, John
TI  - Rating Iron Deficiency in Soybean Using Image Processing and Decision-Tree Based Models
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 24
SN  - 2072-4292

AB  - The most efficient way of soybean (Glycine max (L.) Merrill) iron deficiency chlorosis (IDC) management is to select a tolerant cultivar suitable for the specific growing condition. These cultivars are selected by field experts based on IDC visual ratings. However, this visual rating method is laborious, expensive, time-consuming, subjective, and impractical on larger scales. Therefore, a modern digital image-based method using tree-based machine learning classifier models for rating soybean IDC at plot-scale was developed. Data were collected from soybean IDC cultivar trial plots. Images were processed with MATLAB and corrected for light intensity by using a standard color board in the image. The three machine learning models used in this study were decision tree (DT), random forest (RF), and adaptive boosting (AdaBoost). Calculated indices from images, such as dark green color index (DGCI), canopy size, and pixel counts into DGCI ranges and IDC visual scoring were used as input and target variables to train these models. Metrics such as precision, recall, and f1-score were used to assess the performance of the classifier models. Among all three models, AdaBoost had the best performance (average f1-score = 0.75) followed by RF and DT the least. Therefore, a ready-to-use methodology of image processing with AdaBoost model for soybean IDC rating was recommended. The developed method can be easily adapted to smartphone applications or scaled-up using images from aerial platforms.
KW  - soybean
KW  - iron deficiency chlorosis
KW  - image processing
KW  - machine learning
KW  - AdaBoost
KW  - classification
DO  - 10.3390/rs12244143
TY  - EJOU
AU  - Li, Wenlong
AU  - Xue, Pengfei
AU  - Liu, Chenli
AU  - Yan, Hepiao
AU  - Zhu, Gaofeng
AU  - Cao, Yapeng
TI  - Monitoring and Landscape Dynamic Analysis of Alpine Wetland Area Based on Multiple Algorithms: A Case Study of Zoige Plateau
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 24
SN  - 1424-8220

AB  - As an important part of the wetland ecosystem, alpine wetland is not only one of the most important ecological water conservation areas in the Qinghai&ndash;Tibet Plateau region, but is also an effective regulator of the local climate. In this study, using three machine learning algorithms to extract wetland, we employ the landscape ecological index to quantitatively analyze the evolution of landscape patterns and grey correlation to analyze the driving factors of Zoige wetland landscape pattern change from 1995 to 2020. The following results were obtained. (1) The random forest algorithm (RF) performs best when dealing with high-dimensional data, and the accuracy of the decision tree algorithm (DT) is better. The performance of the RF and DT is better than that of the support vector machine algorithm. (2) The alpine wetland in the study area was degraded from 1995 to 2015, whereas wetland area began to increase after 2015. (3) The results of landscape analysis show the decrease in wetland area from 1995 to 2005 was mainly due to the fragmentation of larger patches into many small patches and loss of the original small patches, while the 2005 to 2015 decrease was caused by the loss of many middle patches and the decrease in large patches from the edge to the middle. The 2015 to 2020 increase is due to an increase in the number of smaller patches and recovery of original wetland area. (4) The grey correlation degree further shows that precipitation and evaporation are the main factors leading to the change in the landscape pattern of Zoige alpine wetland. The results are of great significance to the long-term monitoring of the Zoige wetland ecosystem.
KW  - wetland
KW  - random forest
KW  - Google Earth Engine (GEE)
KW  - Zoige Plateau
KW  - landscape analysis
DO  - 10.3390/s20247315
TY  - EJOU
AU  - Bolfe, Ãdson L.
AU  - Jorge, LÃºcio A.
AU  - Sanches, Ieda D.
AU  - Luchiari JÃºnior, Ariovaldo
AU  - da Costa, Cinthia C.
AU  - Victoria, Daniel D.
AU  - Inamasu, Ricardo Y.
AU  - Grego, CÃ©lia R.
AU  - Ferreira, Victor R.
AU  - Ramirez, Andrea R.
TI  - Precision and Digital Agriculture: Adoption of Technologies and Perception of Brazilian Farmers
T2  - Agriculture

PY  - 2020
VL  - 10
IS  - 12
SN  - 2077-0472

AB  - The rapid population growth has driven the demand for more food, fiber, energy, and water, which is associated to an increase in the need to use natural resources in a more sustainable way. The use of precision agriculture machinery and equipment since the 1990s has provided important productive gains and maximized the use of agricultural inputs. The growing connectivity in the rural environment, in addition to its greater integration with data from sensor systems, remote sensors, equipment, and smartphones have paved the way for new concepts from the so-called Agriculture 4.0 or Digital Agriculture. This article presents the results of a survey carried out with 504 Brazilian farmers about the digital technologies in use, as well as current and future applications, perceived benefits, and challenges. The questionnaire was prepared, organized, and made available to the public through the online platform LimeSurvey and was available from 17 April to 2 June 2020. The primary data obtained for each question previously defined were consolidated and analyzed statistically. The results indicate that 84% of the interviewed farmers use at least one digital technology in their production system that differs according to technological complexity level. The main perceived benefit refers to the perception of increased productivity and the main challenges are the acquisition costs of machines, equipment, software, and connectivity. It is also noteworthy that 95% of farmers would like to learn more about new technologies to strengthen the agricultural development in their properties.
KW  - agriculture 4.0
KW  - smart farming
KW  - farmerâs attitudes
KW  - Brazil
DO  - 10.3390/agriculture10120653
TY  - EJOU
AU  - Devaraja, Rahul R.
AU  - MaskeliÅ«nas, Rytis
AU  - DamaÅ¡eviÄius, Robertas
TI  - Design and Evaluation of Anthropomorphic Robotic Hand for Object Grasping and Shape Recognition
T2  - Computers

PY  - 2021
VL  - 10
IS  - 1
SN  - 2073-431X

AB  - We developed an anthropomorphic multi-finger artificial hand for a fine-scale object grasping task, sensing the grasped object&rsquo;s shape. The robotic hand was created using the 3D printer and has the servo bed for stand-alone finger movement. The data containing the robotic fingers&rsquo; angular position are acquired using the Leap Motion device, and a hybrid Support Vector Machine (SVM) classifier is used for object shape identification. We trained the designed robotic hand on a few monotonous convex-shaped items similar to everyday objects (ball, cylinder, and rectangular box) using supervised learning techniques. We achieve the mean accuracy of object shape recognition of 94.4%.
KW  - robot manipulator
KW  - shape recognition
KW  - supervised learning
KW  - object grasping
KW  - 3D printing
DO  - 10.3390/computers10010001
TY  - EJOU
AU  - Alhaqbani, Amjaad
AU  - Kurdi, Heba
AU  - Youcef-Toumi, Kamal
TI  - Fish-Inspired Task Allocation Algorithm for Multiple Unmanned Aerial Vehicles in Search and Rescue Missions
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 1
SN  - 2072-4292

AB  - The challenge concerning the optimal allocation of tasks across multiple unmanned aerial vehicles (multi-UAVs) has significantly spurred research interest due to its contribution to the success of various fleet missions. This challenge becomes more complex in time-constrained missions, particularly if they are conducted in hostile environments, such as search and rescue (SAR) missions. In this study, a novel fish-inspired algorithm for multi-UAV missions (FIAM) for task allocation is proposed, which was inspired by the adaptive schooling and foraging behaviors of fish. FIAM shows that UAVs in an SAR mission can be similarly programmed to aggregate in groups to swiftly survey disaster areas and rescue-discovered survivors. FIAM&rsquo;s performance was compared with three long-standing multi-UAV task allocation (MUTA) paradigms, namely, opportunistic task allocation scheme (OTA), auction-based scheme, and ant-colony optimization (ACO). Furthermore, the proposed algorithm was also compared with the recently proposed locust-inspired algorithm for MUTA problem (LIAM). The experimental results demonstrated FIAM&rsquo;s abilities to maintain a steady running time and a decreasing mean rescue time with a substantially increasing percentage of rescued survivors. For instance, FIAM successfully rescued 100% of the survivors with merely 16 UAVs, for scenarios of no more than eight survivors, whereas LIAM, Auction, ACO and OTA rescued a maximum of 75%, 50%, 35% and 35%, respectively, for the same scenarios. This superiority of FIAM performance was maintained under a different fleet size and number of survivors, demonstrating the approach&rsquo;s flexibility and scalability.
KW  - disaster risk management
KW  - search and rescue
KW  - remote sensing
KW  - task allocation
KW  - bio-inspired algorithms
KW  - unmanned aerial vehicle
KW  - fish
DO  - 10.3390/rs13010027
TY  - EJOU
AU  - Maung, Win S.
AU  - Sasaki, Jun
TI  - Assessing the Natural Recovery of Mangroves after Human Disturbance Using Neural Network Classification and Sentinel-2 Imagery in Wunbaik Mangrove Forest, Myanmar
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 1
SN  - 2072-4292

AB  - In this study, we examined the natural recovery of mangroves in abandoned shrimp ponds located in the Wunbaik Mangrove Forest (WMF) in Myanmar using artificial neural network (ANN) classification and a change detection approach with Sentinel-2 satellite images. In 2020, we conducted various experiments related to mangrove classification by tuning input features and hyper-parameters. The selected ANN model was used with a transfer learning approach to predict the mangrove distribution in 2015. Changes were detected using classification results from 2015 and 2020. Naturally recovering mangroves were identified by extracting the change detection results of three abandoned shrimp ponds selected during field investigation. The proposed method yielded an overall accuracy of 95.98%, a kappa coefficient of 0.92, mangrove and non-mangrove precisions of 0.95 and 0.98, respectively, recalls of 0.96, and F1 scores of 0.96 for the 2020 classification. For the 2015 prediction, transfer learning improved model performance, resulting in an overall accuracy of 97.20%, a kappa coefficient of 0.94, mangrove and non-mangrove precisions of 0.98 and 0.96, respectively, recalls of 0.98 and 0.97, and F1 scores of 0.96. The change detection results showed that mangrove forests in the WMF slightly decreased between 2015 and 2020. Naturally recovering mangroves were detected at approximately 50% of each abandoned site within a short abandonment period. This study demonstrates that the ANN method using Sentinel-2 imagery and topographic and canopy height data can produce reliable results for mangrove classification. The natural recovery of mangroves presents a valuable opportunity for mangrove rehabilitation at human-disturbed sites in the WMF.
KW  - mangrove
KW  - natural recovery
KW  - artificial neural network
KW  - Sentinel-2
KW  - transfer learning
KW  - change detection
DO  - 10.3390/rs13010052
TY  - EJOU
AU  - Biffi, Leonardo J.
AU  - Mitishita, Edson
AU  - Liesenberg, Veraldo
AU  - Santos, Anderson A.
AU  - GonÃ§alves, Diogo N.
AU  - Estrabis, Nayara V.
AU  - Silva, Jonathan D.
AU  - Osco, Lucas P.
AU  - Ramos, Ana P.
AU  - Centeno, Jorge A.
AU  - Schimalski, Marcos B.
AU  - Rufato, Leo
AU  - Neto, SÃ­lvio L.
AU  - Marcato Junior, JosÃ©
AU  - GonÃ§alves, Wesley N.
TI  - ATSS Deep Learning-Based Approach to Detect Apple Fruits
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 1
SN  - 2072-4292

AB  - In recent years, many agriculture-related problems have been evaluated with the integration of artificial intelligence techniques and remote sensing systems. Specifically, in fruit detection problems, several recent works were developed using Deep Learning (DL) methods applied in images acquired in different acquisition levels. However, the increasing use of anti-hail plastic net cover in commercial orchards highlights the importance of terrestrial remote sensing systems. Apples are one of the most highly-challenging fruits to be detected in images, mainly because of the target occlusion problem occurrence. Additionally, the introduction of high-density apple tree orchards makes the identification of single fruits a real challenge. To support farmers to detect apple fruits efficiently, this paper presents an approach based on the Adaptive Training Sample Selection (ATSS) deep learning method applied to close-range and low-cost terrestrial RGB images. The correct identification supports apple production forecasting and gives local producers a better idea of forthcoming management practices. The main advantage of the ATSS method is that only the center point of the objects is labeled, which is much more practicable and realistic than bounding-box annotations in heavily dense fruit orchards. Additionally, we evaluated other object detection methods such as RetinaNet, Libra Regions with Convolutional Neural Network (R-CNN), Cascade R-CNN, Faster R-CNN, Feature Selective Anchor-Free (FSAF), and High-Resolution Network (HRNet). The study area is a highly-dense apple orchard consisting of Fuji Suprema apple fruits (Malus domestica Borkh) located in a smallholder farm in the state of Santa Catarina (southern Brazil). A total of 398 terrestrial images were taken nearly perpendicularly in front of the trees by a professional camera, assuring both a good vertical coverage of the apple trees in terms of heights and overlapping between picture frames. After, the high-resolution RGB images were divided into several patches for helping the detection of small and/or occluded apples. A total of 3119, 840, and 2010 patches were used for training, validation, and testing, respectively. Moreover, the proposed method&rsquo;s generalization capability was assessed by applying simulated image corruptions to the test set images with different severity levels, including noise, blurs, weather, and digital processing. Experiments were also conducted by varying the bounding box size (80, 100, 120, 140, 160, and 180 pixels) in the image original for the proposed approach. Our results showed that the ATSS-based method slightly outperformed all other deep learning methods, between 2.4% and 0.3%. Also, we verified that the best result was obtained with a bounding box size of 160 &times; 160 pixels. The proposed method was robust regarding most of the corruption, except for snow, frost, and fog weather conditions. Finally, a benchmark of the reported dataset is also generated and publicly available.
KW  - convolutional neural network
KW  - object detection
KW  - precision agriculture
DO  - 10.3390/rs13010054
TY  - EJOU
AU  - Pineda, MÃ³nica
AU  - BarÃ³n, Matilde
AU  - PÃ©rez-Bueno, MarÃ­a-Luisa
TI  - Thermal Imaging for Plant Stress Detection and Phenotyping
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 1
SN  - 2072-4292

AB  - In the last few years, large efforts have been made to develop new methods to optimize stress detection in crop fields. Thus, plant phenotyping based on imaging techniques has become an essential tool in agriculture. In particular, leaf temperature is a valuable indicator of the physiological status of plants, responding to both biotic and abiotic stressors. Often combined with other imaging sensors and data-mining techniques, thermography is crucial in the implementation of a more automatized, precise and sustainable agriculture. However, thermal data need some corrections related to the environmental and measuring conditions in order to achieve a correct interpretation of the data. This review focuses on the state of the art of thermography applied to the detection of biotic stress. The work will also revise the most important abiotic stress factors affecting the measurements as well as practical issues that need to be considered in order to implement this technique, particularly at the field scale.
KW  - Remote sensing
KW  - proximal sensing
KW  - thermography
KW  - plant phenotyping
DO  - 10.3390/rs13010068
TY  - EJOU
AU  - Wittstruck, Lucas
AU  - KÃ¼hling, Insa
AU  - Trautz, Dieter
AU  - Kohlbrecher, Maik
AU  - Jarmer, Thomas
TI  - UAV-Based RGB Imagery for Hokkaido Pumpkin (Cucurbita max.) Detection and Yield Estimation
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 1
SN  - 1424-8220

AB  - Pumpkins are economically and nutritionally valuable vegetables with increasing popularity and acreage across Europe. Successful commercialization, however, require detailed pre-harvest information about number and weight of the fruits. To get a non-destructive and cost-effective yield estimation, we developed an image processing methodology for high-resolution RGB data from Unmanned aerial vehicle (UAV) and applied this on a Hokkaido pumpkin farmer&rsquo;s field in North-western Germany. The methodology was implemented in the programming language Python and comprised several steps, including image pre-processing, pixel-based image classification, classification post-processing for single fruit detection, and fruit size and weight quantification. To derive the weight from two-dimensional imagery, we calculated elliptical spheroids from lengths of diameters and heights. The performance of this processes was evaluated by comparison with manually harvested ground-truth samples and cross-checked for misclassification from randomly selected test objects. Errors in classification and fruit geometry could be successfully reduced based on the described processing steps. Additionally, different lighting conditions, as well as shadows, in the image data could be compensated by the proposed methodology. The results revealed a satisfactory detection of 95% (error rate of 5%) from the field sample, as well as a reliable volume and weight estimation with Pearson&rsquo;s correlation coefficients of 0.83 and 0.84, respectively, from the described ellipsoid approach. The yield was estimated with 1.51 kg m&minus;2 corresponding to an average individual fruit weight of 1100 g and an average number of 1.37 pumpkins per m2. Moreover, spatial distribution of aggregated fruit densities and weights were calculated to assess in-field optimization potential for agronomic management as demonstrated between a shaded edge compared to the rest of the field. The proposed approach provides the Hokkaido producer useful information for more targeted pre-harvest marketing strategies, since most food retailers request homogeneous lots within prescribed size or weight classes.
KW  - remote sensing
KW  - drones
KW  - random forest
KW  - low-cost sensor
KW  - winter squash
KW  - vegetables
KW  - fruit size
KW  - fruit weight
KW  - Europe
DO  - 10.3390/s21010118
TY  - EJOU
AU  - Tilahun, Tewodros
AU  - Seyoum, Wondwosen M.
TI  - High-Resolution Mapping of Tile Drainage in Agricultural Fields Using Unmanned Aerial System (UAS)-Based Radiometric Thermal and Optical Sensors
T2  - Hydrology

PY  - 2021
VL  - 8
IS  - 1
SN  - 2306-5338

AB  - With the growing concerns of water quality related to tile drainage in agricultural lands, developing an efficient and cost-effective method of mapping tile drainage is essential. This research aimed to establish mapping of tile drainage systems in agricultural fields using optical and radiometric thermal sensors mounted on Unmanned Aerial System (UAS). The overarching hypothesis is that in a tile-drained land, spatial distribution of soil water content is affected by tile lines, therefore, contrasting soil temperature signals exist between areas along the tile lines and between the tile lines. Designated flights were conducted to assess the effectiveness of the UAS under various conditions such as rainfall, crop cover, crop maturity and time of the day. Image correction, mosaicking, image enhancements and map production were conducted using Agisoft and ENVI image analysis software. The results showed intermediate growth stage of soybean plants and rainfall helped delineating tile lines. In-situ soil temperature measurements revealed appropriate time of the day (14:00 to 18:00 h) for thermal image detection of the tile lines. The role of soil moisture and plant cover is not resolved, thus, further refinement of the approach considering these factors is necessary to develop efficient mapping techniques of tile drainage using UAS thermal and optical sensors.
KW  - tile drainage
KW  - thermal sensor
KW  - optical sensor
KW  - image processing
KW  - UAS
KW  - remote sensing
DO  - 10.3390/hydrology8010002
TY  - EJOU
AU  - Shrestha, Maryada
AU  - Broadbent, Eben N.
AU  - Vogel, Jason G.
TI  - Using GatorEye UAV-Borne LiDAR to Quantify the Spatial and Temporal Effects of a Prescribed Fire on Understory Height and Biomass in a Pine Savanna
T2  - Forests

PY  - 2021
VL  - 12
IS  - 1
SN  - 1999-4907

AB  - In the pine savannas of the southeastern United States, prescribed fire is commonly used to manipulate understory structure and composition. Understory characteristics have traditionally been monitored with field sampling; however, remote sensing could provide rapid, spatially explicit monitoring of understory dynamics. We contrasted pre- vs. post-fire understory characteristics collected with fixed area plots with estimates from high-density LiDAR point clouds collected using the unmanned aerial vehicle (UAV)-borne GatorEye system. Measuring within 1 &times; 1 m field plots (n = 20), we found average understory height ranged from 0.17&ndash;1.26 m and biomass from 0.26&ndash;4.86 Mg C ha&minus;1 before the fire (May 2018), and five months after the fire (November 2018), height ranged from 0.11&ndash;1.09 m and biomass from 0.04&ndash;3.03 Mg C ha&minus;1. Understory heights estimated with LiDAR were significantly correlated with plot height measurements (R2 = 0.576, p &le; 0.001). Understory biomass was correlated with in situ heights (R2 = 0.579, p &le; 0.001) and LiDAR heights (R2 = 0.507, p &le; 0.001). The biomass estimates made with either height measurement did not differ for the measurement plots (p = 0.263). However, for the larger research area, the understory biomass estimated with the LiDAR indicated a smaller difference after the burn (~12.7% biomass reduction) than observed with in situ measurements (~16% biomass reduction). The two approaches likely differed because the research area&rsquo;s spatial variability was not captured by the in-situ measurements (0.2% of the research area measured) versus the wall-to-wall coverage provided by LiDAR. The additional benefit of having spatially explicit measurements with LiDAR, and its ease of use, make it a promising tool for land managers wanting greater spatial and temporal resolution in tracking understory biomass and its response to prescribed fire.
KW  - field sampling
KW  - prescribed fire
KW  - UAV LiDAR
KW  - understory height and biomass
DO  - 10.3390/f12010038
TY  - EJOU
AU  - Yin, Jian
AU  - Qiu, Yuanhong
AU  - Zhang, Bin
TI  - Identification of Poverty Areas by Remote Sensing and Machine Learning: A Case Study in Guizhou, Southwest China
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 1
SN  - 2220-9964

AB  - As an objective social phenomenon, poverty has accompanied the vicissitudes of human society, which is a chronic dilemma hindering human civilization. Remote sensing data, such as nighttime lights imagery, provides abundant poverty-related information that can be related to poverty. However, it may be insufficient to rely merely on nighttime lights data, because poverty is a comprehensive problem, and poverty identification may be affected by topography, especially in some developing countries or regions where agriculture accounts for a large proportion. Therefore, some geographical features may be necessary for supplements. With the support of the random forest machine learning method, we extracted 23 spatial features base on remote sensing including nighttime lights data and geographical data, and carried out the poverty identification in Guizhou Province, China, since 2012. Compared with the identifications using support vector machines and the artificial neural network, random forest showed a better accuracy. The results supported that nighttime lights and geographical features are better than those only by nighttime lights features. From 2012 to 2019, the identified poor counties in Guizhou Province showed obvious dynamic spatiotemporal characteristics. The number of poor counties has decreased consistently and contiguous poverty-stricken areas have fragmented; the number of poor counties in the northeast and southwest regions decreased faster than other areas. The reduction in poverty probability exhibited a pattern of spreading from the central and northern regions to the periphery parts. The poverty reduction was relatively slow in areas with large slope and large topographic relief. When poor counties are adjacent to more non-poor counties, they can get rid of poverty easier. This study provides a method for feature selection and recognition of poor counties by remote sensing images and offers new insights into poverty identification and regional sustainable development for other developing countries and areas.
KW  - poverty probability
KW  - random forest
KW  - nighttime lights
KW  - spatiotemporal characteristics
DO  - 10.3390/ijgi10010011
TY  - EJOU
AU  - Rahman, Mohammad F.
AU  - Fan, Shurui
AU  - Zhang, Yan
AU  - Chen, Lei
TI  - A Comparative Study on Application of Unmanned Aerial Vehicle Systems in Agriculture
T2  - Agriculture

PY  - 2021
VL  - 11
IS  - 1
SN  - 2077-0472

AB  - Presently in agriculture, there is much ample scope for drone and UAS (Unmanned Aircraft System) development. Because of their low cost and small size, these devices have the ability to help many developing countries with economic prosperity. The entire aggregation of financial investments in the agricultural area has increased appreciably in recent years. Sooth to say, agriculture remains a massive part of the world&rsquo;s commercial growth, and due to some complications, the agriculture fields withstand massive losses. Pets and destructive insects seem to be the primary reasons for certain degenerative diseases. It minimizes the potential productivity of the crops. For increasing the quality of the plants, fertilizers and pesticides are appropriately applied. Using UAVs (Unmanned Aerial Vehicles) for spraying pesticides and fertilizing materials is an exuberant contraption. It adequately reduces the rate of health dilemma and the number of workers, which is quite an impressive landmark. Willing producers are also adopting UAVs in agriculture to soil and field analysis, seed sowing, lessen the time and costs correlated with crop scouting, and field mapping. It is rapid, and it can sensibly diminish a farmer&rsquo;s workload, which is significantly a part of the agricultural revolution. This article aims to proportionally represent the concept of agricultural purposed UAV clear to the neophytes. First, this paper outlines the harmonic framework of the agricultural UAV, and then it abundantly illustrates the methods and materials. Finally, the article portrays the outcome.
KW  - UAV
KW  - unmanned aerial vehicle
KW  - agricultural UAV
KW  - NDVI (Normalized Difference Vegetation Index)
KW  - spraying system
KW  - livestock
KW  - agricultural monitoring
DO  - 10.3390/agriculture11010022
TY  - EJOU
AU  - Guo, Anting
AU  - Huang, Wenjiang
AU  - Dong, Yingying
AU  - Ye, Huichun
AU  - Ma, Huiqin
AU  - Liu, Bo
AU  - Wu, Wenbin
AU  - Ren, Yu
AU  - Ruan, Chao
AU  - Geng, Yun
TI  - Wheat Yellow Rust Detection Using UAV-Based Hyperspectral Technology
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 1
SN  - 2072-4292

AB  - Yellow rust is a worldwide disease that poses a serious threat to the safety of wheat production. Numerous studies on near-surface hyperspectral remote sensing at the leaf scale have achieved good results for disease monitoring. The next step is to monitor the disease at the field scale, which is of great significance for disease control. In our study, an unmanned aerial vehicle (UAV) equipped with a hyperspectral sensor was used to obtain hyperspectral images at the field scale. Vegetation indices (VIs) and texture features (TFs) extracted from the UAV-based hyperspectral images and their combination were used to establish partial least-squares regression (PLSR)-based disease monitoring models in different infection periods. In addition, we resampled the original images with 1.2 cm spatial resolution to images with different spatial resolutions (3 cm, 5 cm, 7 cm, 10 cm, 15 cm, and 20 cm) to evaluate the effect of spatial resolution on disease monitoring accuracy. The findings showed that the VI-based model had the highest monitoring accuracy (R2 = 0.75) in the mid-infection period. The TF-based model could be used to monitor yellow rust at the field scale and obtained the highest R2 in the mid- and late-infection periods (0.65 and 0.82, respectively). The VI-TF-based models had the highest accuracy in each infection period and outperformed the VI-based or TF-based models. The spatial resolution had a negligible influence on the VI-based monitoring accuracy, but significantly influenced the TF-based monitoring accuracy. Furthermore, the optimal spatial resolution for monitoring yellow rust using the VI-TF-based model in each infection period was 10 cm. The findings provide a reference for accurate disease monitoring using UAV hyperspectral images.
KW  - UAV hyperspectral
KW  - wheat yellow rust
KW  - disease monitoring
KW  - vegetation index
KW  - texture
KW  - spatial resolution
DO  - 10.3390/rs13010123
TY  - EJOU
AU  - Papp, Levente
AU  - van Leeuwen, Boudewijn
AU  - Szilassi, PÃ©ter
AU  - Tobak, ZalÃ¡n
AU  - SzatmÃ¡ri, JÃ³zsef
AU  - Ãrvai, MÃ¡tyÃ¡s
AU  - MÃ©szÃ¡ros, JÃ¡nos
AU  - PÃ¡sztor, LÃ¡szlÃ³
TI  - Monitoring Invasive Plant Species Using Hyperspectral Remote Sensing Data
T2  - Land

PY  - 2021
VL  - 10
IS  - 1
SN  - 2073-445X

AB  - The species richness and biodiversity of vegetation in Hungary are increasingly threatened by invasive plant species brought in from other continents and foreign ecosystems. These invasive plant species have spread aggressively in the natural and semi-natural habitats of Europe. Common milkweed (Asclepias syriaca) is one of the species that pose the greatest ecological menace. Therefore, the primary purpose of the present study is to map and monitor the spread of common milkweed, the most common invasive plant species in Europe. Furthermore, the possibilities to detect and validate this special invasive plant by analyzing hyperspectral remote sensing data were investigated. In combination with field reference data, high-resolution hyperspectral aerial images acquired by an unmanned aerial vehicle (UAV) platform in 138 spectral bands in areas infected by common milkweed were examined. Then, support vector machine (SVM) and artificial neural network (ANN) classification algorithms were applied to the highly accurate field reference data. As a result, common milkweed individuals were distinguished in hyperspectral images, achieving an overall accuracy of 92.95% in the case of supervised SVM classification. Using the ANN model, an overall accuracy of 99.61% was achieved. To evaluate the proposed approach, two experimental tests were conducted, and in both cases, we managed to distinguish the individual specimens within the large variety of spreading invasive species in a study area of 2 ha, based on centimeter spatial resolution hyperspectral UAV imagery.
KW  - invasive species
KW  - common milkweed
KW  - hyperspectral imaging
KW  - UAV
KW  - artificial neural networks
KW  - SVM classification
DO  - 10.3390/land10010029
TY  - EJOU
AU  - Flores, Donovan
AU  - GonzÃ¡lez-HernÃ¡ndez, IvÃ¡n
AU  - Lozano, Rogelio
AU  - Vazquez-Nicolas, Jesus M.
AU  - Hernandez Toral, Jorge L.
TI  - Automated Agave Detection and Counting Using a Convolutional Neural Network and Unmanned Aerial Systems
T2  - Drones

PY  - 2021
VL  - 5
IS  - 1
SN  - 2504-446X

AB  - We present an automatic agave detection method for counting plants based on aerial data from a UAV (Unmanned Aerial Vehicle). Our objective is to autonomously count the number of agave plants in an area to aid management of the yield. An orthomosaic is obtained from agave plantations, which is then used to create a database. This database is in turn used to train a Convolutional Neural Network (CNN). The proposed method is based on computer image processing, and the CNN increases the detection performance of the approach. The main contribution of the present paper is to propose a method for agave plant detection with a high level of precision. In order to test the proposed method in a real agave plantation, we develop a UAV platform, which is equipped with several sensors to reach accurate counting. Therefore, our prototype can safely track a desired path to detect and count agave plants. For comparison purposes, we perform the same application using a simpler algorithm. The result shows that our proposed algorithm has better performance reaching an F1 score of 0.96 as opposed to 0.57 for the Haar algorithm. The obtained experimental results suggest that the proposed algorithm is robust and has considerable potential to help farmers manage agave agroecosystems.
KW  - precision agriculture
KW  - plant detection
KW  - monitoring
KW  - deep learning
KW  - counting
DO  - 10.3390/drones5010004
TY  - EJOU
AU  - Yeh, Chia-Cheng
AU  - Chang, Yang-Lang
AU  - Alkhaleefah, Mohammad
AU  - Hsu, Pai-Hui
AU  - Eng, Weiyong
AU  - Koo, Voon-Chet
AU  - Huang, Bormin
AU  - Chang, Lena
TI  - YOLOv3-Based Matching Approach for Roof Region Detection from Drone Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 1
SN  - 2072-4292

AB  - Due to the large data volume, the UAV image stitching and matching suffers from high computational cost. The traditional feature extraction algorithms&mdash;such as Scale-Invariant Feature Transform (SIFT), Speeded Up Robust Features (SURF), and Oriented FAST Rotated BRIEF (ORB)&mdash;require heavy computation to extract and describe features in high-resolution UAV images. To overcome this issue, You Only Look Once version 3 (YOLOv3) combined with the traditional feature point matching algorithms is utilized to extract descriptive features from the drone dataset of residential areas for roof detection. Unlike the traditional feature extraction algorithms, YOLOv3 performs the feature extraction solely on the proposed candidate regions instead of the entire image, thus the complexity of the image matching is reduced significantly. Then, all the extracted features are fed into Structural Similarity Index Measure (SSIM) to identify the corresponding roof region pair between consecutive image sequences. In addition, the candidate corresponding roof pair by our architecture serves as the coarse matching region pair and limits the search range of features matching to only the detected roof region. This further improves the feature matching consistency and reduces the chances of wrong feature matching. Analytical results show that the proposed method is 13&times; faster than the traditional image matching methods with comparable performance.
KW  - image matching
KW  - deep learning
KW  - YOLOv3
KW  - roof region detection
KW  - drone images
KW  - high-performance computing
DO  - 10.3390/rs13010127
TY  - EJOU
AU  - Zhao, Xuehua
AU  - Lv, Hanfang
AU  - Wei, Yizhao
AU  - Lv, Shujin
AU  - Zhu, Xueping
TI  - Streamflow Forecasting via Two Types of Predictive Structure-Based Gated Recurrent Unit Models
T2  - Water

PY  - 2021
VL  - 13
IS  - 1
SN  - 2073-4441

AB  - Data-intelligent methods designed for forecasting the streamflow of the Fenhe River are crucial for enhancing water resource management. Herein, the gated recurrent unit (GRU) is coupled with the optimization algorithm improved grey wolf optimizer (IGWO) to design a hybrid model (IGWO-GRU) to carry out streamflow forecasting. Two types of predictive structure-based models (sequential IGWO-GRU and monthly IGWO-GRU) are compared with other models, such as the single least-squares support vector machine (LSSVM) and single extreme learning machine (ELM) models. These models incorporate the historical streamflow series as inputs of the model to forecast the future streamflow with data from January 1956 to December 2016 at the Shangjingyou station and from January 1958 to December 2016 at the Fenhe reservoir station. The IGWO-GRU model exhibited a strong ability for mapping in streamflow series when the parameters were carefully tuned. The monthly predictive structure can effectively extract the instinctive hydrological information that is more easily learned by the predictive model than the traditional sequential predictive structure. The monthly IGWO-GRU model was found to be a better forecasting tool, with an average qualification rate of 91.66% in two stations. It also showed good performance in absolute error and peak flow forecasting.
KW  - gated recurrent unit
KW  - improved grey wolf optimizer
KW  - monthly streamflow forecasting
KW  - data-driven modeling
DO  - 10.3390/w13010091
TY  - EJOU
AU  - De Swaef, Tom
AU  - Maes, Wouter H.
AU  - Aper, Jonas
AU  - Baert, Joost
AU  - Cougnon, Mathias
AU  - Reheul, Dirk
AU  - Steppe, Kathy
AU  - RoldÃ¡n-Ruiz, Isabel
AU  - Lootens, Peter
TI  - Applying RGB- and Thermal-Based Vegetation Indices from UAVs for High-Throughput Field Phenotyping of Drought Tolerance in Forage Grasses
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 1
SN  - 2072-4292

AB  - The persistence and productivity of forage grasses, important sources for feed production, are threatened by climate change-induced drought. Breeding programs are in search of new drought tolerant forage grass varieties, but those programs still rely on time-consuming and less consistent visual scoring by breeders. In this study, we evaluate whether Unmanned Aerial Vehicle (UAV) based remote sensing can complement or replace this visual breeder score. A field experiment was set up to test the drought tolerance of genotypes from three common forage types of two different species: Festuca arundinacea, diploid Lolium perenne and tetraploid Lolium perenne. Drought stress was imposed by using mobile rainout shelters. UAV flights with RGB and thermal sensors were conducted at five time points during the experiment. Visual-based indices from different colour spaces were selected that were closely correlated to the breeder score. Furthermore, several indices, in particular H and NDLab, from the HSV (Hue Saturation Value) and CIELab (Commission Internationale de l&rsquo;&eacute;clairage) colour space, respectively, displayed a broad-sense heritability that was as high or higher than the visual breeder score, making these indices highly suited for high-throughput field phenotyping applications that can complement or even replace the breeder score. The thermal-based Crop Water Stress Index CWSI provided complementary information to visual-based indices, enabling the analysis of differences in ecophysiological mechanisms for coping with reduced water availability between species and ploidy levels. All species/types displayed variation in drought stress tolerance, which confirms that there is sufficient variation for selection within these groups of grasses. Our results confirmed the better drought tolerance potential of Festuca arundinacea, but also showed which Lolium perenne genotypes are more tolerant.
KW  - UAV
KW  - RGB camera
KW  - thermal camera
KW  - drought tolerance
KW  - forage grass
KW  - HSV
KW  - CIELab
KW  - broad-sense heritability
KW  - phenotyping gap
KW  - high throughput field phenotyping
DO  - 10.3390/rs13010147
TY  - EJOU
AU  - Qin, Jun
AU  - Wang, Biao
AU  - Wu, Yanlan
AU  - Lu, Qi
AU  - Zhu, Haochen
TI  - Identifying Pine Wood Nematode Disease Using UAV Images and Deep Learning Algorithms
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 2
SN  - 2072-4292

AB  - Pine nematode is a highly contagious disease that causes great damage to the world&rsquo;s pine forest resources. Timely and accurate identification of pine nematode disease can help to control it. At present, there are few research on pine nematode disease identification, and it is difficult to accurately identify and locate nematode disease in a single pine by existing methods. This paper proposes a new network, SCANet (spatial-context-attention network), to identify pine nematode disease based on unmanned aerial vehicle (UAV) multi-spectral remote sensing images. In this method, a spatial information retention module is designed to reduce the loss of spatial information; it preserves the shallow features of pine nematode disease and expands the receptive field to enhance the extraction of deep features through a context information module. SCANet reached an overall accuracy of 79% and a precision and recall of around 0.86, and 0.91, respectively. In addition, 55 disease points among 59 known disease points were identified, which is better than other methods (DeepLab V3+, DenseNet, and HRNet). This paper presents a fast, precise, and practical method for identifying nematode disease and provides reliable technical support for the surveillance and control of pine wood nematode disease.
KW  - UAV remote sensing
KW  - pine wood nematode disease
KW  - deep learning
KW  - intelligent identifying
DO  - 10.3390/rs13020162
TY  - EJOU
AU  - Doukari, Michaela
AU  - Katsanevakis, Stelios
AU  - Soulakellis, Nikolaos
AU  - Topouzelis, Konstantinos
TI  - The Effect of Environmental Conditions on the Quality of UAS Orthophoto-Maps in the Coastal Environment
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 1
SN  - 2220-9964

AB  - Marine conservation and management require detailed and accurate habitat mapping, which is usually produced by collecting data using remote sensing methods. In recent years, unmanned aerial systems (UAS) are used for marine data acquisition, as they provide detailed and reliable information through very high-resolution orthophoto-maps. However, as for all remotely sensed data, it is important to study and understand the accuracy and reliability of the produced maps. In this study, the effect of different environmental conditions on the quality of UAS orthophoto-maps was examined through a positional and thematic accuracy assessment. Selected objects on the orthophoto-maps were also assessed as to their position, shape, and extent. The accuracy assessment results showed significant errors in the different maps and objects. The accuracy of the classified images varied between 2.1% and 27%. Seagrasses were under-classified, while the mixed substrate class was overclassified when environmental conditions were not optimal. The highest misclassifications were caused due to sunglint presence in combination with a rough sea-surface. A change detection workflow resulted in detecting misclassifications of up to 45%, on orthophoto-maps that had been generated under non-optimal environmental conditions. The results confirmed the importance of optimal conditions for the acquisition of reliable marine information using UAS.
KW  - UAS
KW  - UAS imagery
KW  - classification accuracy
KW  - accuracy assessment
KW  - change detection
KW  - remote sensing
DO  - 10.3390/ijgi10010018
TY  - EJOU
AU  - Koteluk, Oliwia
AU  - Wartecki, Adrian
AU  - Mazurek, Sylwia
AU  - KoÅodziejczak, Iga
AU  - Mackiewicz, Andrzej
TI  - How Do Machines Learn? Artificial Intelligence as a New Era in Medicine
T2  - Journal of Personalized Medicine

PY  - 2021
VL  - 11
IS  - 1
SN  - 2075-4426

AB  - With an increased number of medical data generated every day, there is a strong need for reliable, automated evaluation tools. With high hopes and expectations, machine learning has the potential to revolutionize many fields of medicine, helping to make faster and more correct decisions and improving current standards of treatment. Today, machines can analyze, learn, communicate, and understand processed data and are used in health care increasingly. This review explains different models and the general process of machine learning and training the algorithms. Furthermore, it summarizes the most useful machine learning applications and tools in different branches of medicine and health care (radiology, pathology, pharmacology, infectious diseases, personalized decision making, and many others). The review also addresses the futuristic prospects and threats of applying artificial intelligence as an advanced, automated medicine tool.
KW  - machine learning
KW  - artificial intelligence
KW  - bioinformatics
KW  - medicine
KW  - algorithm
KW  - decision making
KW  - personalized medicine
KW  - data processing
KW  - data mining
KW  - personalized treatment
DO  - 10.3390/jpm11010032
TY  - EJOU
AU  - Zhao, Rongkun
AU  - Li, Yuechen
AU  - Ma, Mingguo
TI  - Mapping Paddy Rice with Satellite Remote Sensing: A Review
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 2
SN  - 2071-1050

AB  - Paddy rice is a staple food of three billion people in the world. Timely and accurate estimation of the paddy rice planting area and paddy rice yield can provide valuable information for the government, planners and decision makers to formulate policies. This article reviews the existing paddy rice mapping methods presented in the literature since 2010, classifies these methods, and analyzes and summarizes the basic principles, advantages and disadvantages of these methods. According to the data sources used, the methods are divided into three categories: (I) Optical mapping methods based on remote sensing; (II) Mapping methods based on microwave remote sensing; and (III) Mapping methods based on the integration of optical and microwave remote sensing. We found that the optical remote sensing data sources are mainly MODIS, Landsat, and Sentinel-2, and the emergence of Sentinel-1 data has promoted research on radar mapping methods for paddy rice. Multisource data integration further enhances the accuracy of paddy rice mapping. The best methods are phenology algorithms, paddy rice mapping combined with machine learning, and multisource data integration. Innovative methods include the time series similarity method, threshold method combined with mathematical models, and object-oriented image classification. With the development of computer technology and the establishment of cloud computing platforms, opportunities are provided for obtaining large-scale high-resolution rice maps. Multisource data integration, paddy rice mapping under different planting systems and the connection with global changes are the focus of future development priorities.
KW  - optical remote sensing
KW  - microwave remote sensing
KW  - phenology-based method
DO  - 10.3390/su13020503
TY  - EJOU
AU  - Kulsinskas, Andrius
AU  - Durdevic, Petar
AU  - Ortiz-Arroyo, Daniel
TI  - Internal Wind Turbine Blade Inspections Using UAVs: Analysis and Design Issues
T2  - Energies

PY  - 2021
VL  - 14
IS  - 2
SN  - 1996-1073

AB  - Interior and exterior wind turbine blade inspections are necessary to extend the lifetime of wind turbine generators. The use of unmanned vehicles is an alternative to exterior wind turbine blade inspections performed by technicians that require the use of cranes and ropes. Interior wind turbine blade inspections are even more challenging due to the confined spaces, lack of illumination, and the presence of potentially harmful internal structural components. Additionally, the cost of manned interior wind turbine blade inspections is a major limiting factor. This paper analyses all aspects of the viability of using manually controlled or autonomous aerial vehicles for interior wind turbine blade inspections. We discuss why the size, weight, and flight time of a vehicle, in addition to the structure of the wind turbine blade, are the main limiting factors in performing internal blade inspections. We also describe the design issues that must be considered to provide autonomy to unmanned vehicles and the control system, the sensors that can be used, and introduce some of the algorithms for localization, obstacle avoidance and path planning that are best suited for the task. Lastly, we briefly describe which non-destructive test instrumentation can be used for the purpose.
KW  - UAV
KW  - wind turbine inspection
KW  - autonomy
KW  - wind turbine blade
KW  - indoors UAV
DO  - 10.3390/en14020294
TY  - EJOU
AU  - Mongay Batalla, Jordi
AU  - Mavromoustakis, Constandinos X.
AU  - Mastorakis, George
AU  - Markakis, Evangelos K.
AU  - Pallis, Evangelos
AU  - Wichary, Tomasz
AU  - Krawiec, Piotr
AU  - Lekston, PrzemysÅaw
TI  - On Analyzing Routing Selection for Aerial Autonomous Vehicles Connected to Mobile Network
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 2
SN  - 1424-8220

AB  - This paper proposes a two-phase algorithm for multi-criteria selection of packet forwarding in unmanned aerial vehicles (UAV), which communicate with the control station through commercial mobile network. The selection of proper data forwarding in the two radio link: From UAV to the antenna and from the antenna to the control station, are independent but subject to constrains. The proposed approach is independent of the intra-domain forwarding, so it may be useful for a number of different scenarios of Unmanned Aerial Vehicles connectivity (e.g., a swarm of drones). In the implementation developed in this paper, the connection is served by three different mobile network operators in order to ensure reliable connectivity. The proposed algorithm makes use of Machine Learning tools that are properly trained for predicting the behavior of the link connectivity during the flight duration. The results presented in the last section validate the algorithm and the training process of the machines.
KW  - machine learning
KW  - two-phase selection algorithms
KW  - UAV
KW  - routing and forwarding
KW  - optimization
DO  - 10.3390/s21020399
TY  - EJOU
AU  - Dirscherl, Mariel
AU  - Dietz, Andreas J.
AU  - Kneisel, Christof
AU  - Kuenzer, Claudia
TI  - A Novel Method for Automated Supraglacial Lake Mapping in Antarctica Using Sentinel-1 SAR Imagery and Deep Learning
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 2
SN  - 2072-4292

AB  - Supraglacial meltwater accumulation on ice sheets can be a main driver for accelerated ice discharge, mass loss, and global sea-level-rise. With further increasing surface air temperatures, meltwater-induced hydrofracturing, basal sliding, or surface thinning will cumulate and most likely trigger unprecedented ice mass loss on the Greenland and Antarctic ice sheets. While the Greenland surface hydrological network as well as its impacts on ice dynamics and mass balance has been studied in much detail, Antarctic supraglacial lakes remain understudied with a circum-Antarctic record of their spatio-temporal development entirely lacking. This study provides the first automated supraglacial lake extent mapping method using Sentinel-1 synthetic aperture radar (SAR) imagery over Antarctica and complements the developed optical Sentinel-2 supraglacial lake detection algorithm presented in our companion paper. In detail, we propose the use of a modified U-Net for semantic segmentation of supraglacial lakes in single-polarized Sentinel-1 imagery. The convolutional neural network (CNN) is implemented with residual connections for optimized performance as well as an Atrous Spatial Pyramid Pooling (ASPP) module for multiscale feature extraction. The algorithm is trained on 21,200 Sentinel-1 image patches and evaluated in ten spatially or temporally independent test acquisitions. In addition, George VI Ice Shelf is analyzed for intra-annual lake dynamics throughout austral summer 2019/2020 and a decision-level fused Sentinel-1 and Sentinel-2 maximum lake extent mapping product is presented for January 2020 revealing a more complete supraglacial lake coverage (~770 km2) than the individual single-sensor products. Classification results confirm the reliability of the proposed workflow with an average Kappa coefficient of 0.925 and a F1-score of 93.0% for the supraglacial water class across all test regions. Furthermore, the algorithm is applied in an additional test region covering supraglacial lakes on the Greenland ice sheet which further highlights the potential for spatio-temporal transferability. Future work involves the integration of more training data as well as intra-annual analyses of supraglacial lake occurrence across the whole continent and with focus on supraglacial lake development throughout a summer melt season and into Antarctic winter.
KW  - Antarctica
KW  - Antarctic ice sheet
KW  - supraglacial lakes
KW  - ice sheet hydrology
KW  - Sentinel-1
KW  - remote sensing
KW  - machine learning
KW  - deep learning
KW  - semantic segmentation
KW  - convolutional neural network
DO  - 10.3390/rs13020197
TY  - EJOU
AU  - Korznikov, Kirill A.
AU  - Kislov, Dmitry E.
AU  - Altman, Jan
AU  - DoleÅ¾al, JiÅÃ­
AU  - Vozmishcheva, Anna S.
AU  - Krestov, Pavel V.
TI  - Using U-Net-Like Deep Convolutional Neural Networks for Precise Tree Recognition in Very High Resolution RGB (Red, Green, Blue) Satellite Images
T2  - Forests

PY  - 2021
VL  - 12
IS  - 1
SN  - 1999-4907

AB  - Very high resolution satellite imageries provide an excellent foundation for precise mapping of plant communities and even single plants. We aim to perform individual tree recognition on the basis of very high resolution RGB (red, green, blue) satellite images using deep learning approaches for northern temperate mixed forests in the Primorsky Region of the Russian Far East. We used a pansharpened satellite RGB image by GeoEye-1 with a spatial resolution of 0.46 m/pixel, obtained in late April 2019. We parametrized the standard U-Net convolutional neural network (CNN) and trained it in manually delineated satellite images to solve the satellite image segmentation problem. For comparison purposes, we also applied standard pixel-based classification algorithms, such as random forest, k-nearest neighbor classifier, naive Bayes classifier, and quadratic discrimination. Pattern-specific features based on grey level co-occurrence matrices (GLCM) were computed to improve the recognition ability of standard machine learning methods. The U-Net-like CNN allowed us to obtain precise recognition of Mongolian poplar (Populus suaveolens Fisch. ex Loudon s.l.) and evergreen coniferous trees (Abies holophylla Maxim., Pinus koraiensis Siebold &amp; Zucc.). We were able to distinguish species belonging to either poplar or coniferous groups but were unable to separate species within the same group (i.e. A. holophylla and P. koraiensis were not distinguishable). The accuracy of recognition was estimated by several metrics and exceeded values obtained for standard machine learning approaches. In contrast to pixel-based recognition algorithms, the U-Net-like CNN does not lead to an increase in false-positive decisions when facing green-colored objects that are similar to trees. By means of U-Net-like CNN, we obtained a mean accuracy score of up to 0.96 in our computational experiments. The U-Net-like CNN recognizes tree crowns not as a set of pixels with known RGB intensities but as spatial objects with a specific geometry and pattern. This CNN&rsquo;s specific feature excludes misclassifications related to objects of similar colors as objects of interest. We highlight that utilization of satellite images obtained within the suitable phenological season is of high importance for successful tree recognition. The suitability of the phenological season is conceptualized as a group of conditions providing highlighting objects of interest over other components of vegetation cover. In our case, the use of satellite images captured in mid-spring allowed us to recognize evergreen fir and pine trees as the first class of objects (&ldquo;conifers&rdquo;) and poplars as the second class, which were in a leafless state among other deciduous tree species.
KW  - tree recognition
KW  - machine learning
KW  - convolutional neural network
DO  - 10.3390/f12010066
TY  - EJOU
AU  - Wang, Yutang
AU  - Wang, Jia
AU  - Chang, Shuping
AU  - Sun, Lu
AU  - An, Likun
AU  - Chen, Yuhan
AU  - Xu, Jiangqi
TI  - Classification of Street Tree Species Using UAV Tilt Photogrammetry
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 2
SN  - 2072-4292

AB  - As an important component of the urban ecosystem, street trees have made an outstanding contribution to alleviating urban environmental pollution. Accurately extracting tree characteristics and species information can facilitate the monitoring and management of street trees, as well as aiding landscaping and studies of urban ecology. In this study, we selected the suburban areas of Beijing and Zhangjiakou and investigated six representative street tree species using unmanned aerial vehicle (UAV) tilt photogrammetry. We extracted five tree attributes and four combined attribute parameters and used four types of commonly-used machine learning classification algorithms as classifiers for tree species classification. The results show that random forest (RF), support vector machine (SVM), and back propagation (BP) neural network provide better classification results when using combined parameters for tree species classification, compared with those using individual tree attributes alone; however, the K-nearest neighbor (KNN) algorithm produced the opposite results. The best combination for classification is the BP neural network using combined attributes, with a classification precision of 89.1% and F-measure of 0.872, and we conclude that this approach best meets the requirements of street tree surveys. The results also demonstrate that optical UAV tilt photogrammetry combined with a machine learning classification algorithm is a low-cost, high-efficiency, and high-precision method for tree species classification.
KW  - tree species classification
KW  - street trees
KW  - UAV
KW  - machine learning
KW  - tilt photogrammetry
DO  - 10.3390/rs13020216
TY  - EJOU
AU  - Xu, Jin
AU  - Pan, Xinxiang
AU  - Jia, Baozhu
AU  - Wu, Xuerui
AU  - Liu, Peng
AU  - Li, Bo
TI  - Oil Spill Detection Using LBP Feature and K-Means Clustering in Shipborne Radar Image
T2  - Journal of Marine Science and Engineering

PY  - 2021
VL  - 9
IS  - 1
SN  - 2077-1312

AB  - Oil spill accidents have seriously harmed the marine environment. Effective oil spill monitoring can provide strong scientific and technological support for emergency response of law enforcement departments. Shipborne radar can be used to monitor oil spills immediately after the accident. In this paper, the original shipborne radar image collected by the teaching-practice ship Yukun of Dalian Maritime University during the oil spill accident of Dalian on 16 July 2010 was taken as the research data, and an oil spill detection method was proposed by using LBP texture feature and K-means algorithm. First, Laplacian operator, Otsu algorithm, and mean filter were used to suppress the co-frequency interference noises and high brightness pixels. Then the gray intensity correction matrix was used to reduce image nonuniformity. Next, using LBP texture feature and K-means clustering algorithm, the effective oil spill regions were extracted. Finally, the adaptive threshold was applied to identify the oil films. This method can automatically detect oil spills in shipborne radar image. It can provide a guarantee for real-time monitoring of oil spill accidents.
KW  - oil spill
KW  - LBP
KW  - K-means
KW  - shipborne radar
KW  - remote sensing
KW  - oil pollution
KW  - image analysis
KW  - machine learning
KW  - radar detection
DO  - 10.3390/jmse9010065
TY  - EJOU
AU  - Moeini, Mohammadreza
AU  - Shojaeizadeh, Ali
AU  - Geza, Mengistu
TI  - Supervised Machine Learning for Estimation of Total Suspended Solids in Urban Watersheds
T2  - Water

PY  - 2021
VL  - 13
IS  - 2
SN  - 2073-4441

AB  - Machine Learning (ML) algorithms provide an alternative for the prediction of pollutant concentration. We compared eight ML algorithms (Linear Regression (LR), uniform weighting k-Nearest Neighbor (UW-kNN), variable weighting k-Nearest Neighbor (VW-kNN), Support Vector Regression (SVR), Artificial Neural Network (ANN), Regression Tree (RT), Random Forest (RF), and Adaptive Boosting (AdB)) to evaluate the feasibility of ML approaches for estimation of Total Suspended Solids (TSS) using the national stormwater quality database. Six factors were used as features to train the algorithms with TSS concentration as the target parameter: Drainage area, land use, percent of imperviousness, rainfall depth, runoff volume, and antecedent dry days. Comparisons among the ML methods demonstrated a higher degree of variability in model performance, with the coefficient of determination (R2) and Nash&ndash;Sutcliffe (NSE) values ranging from 0.15 to 0.77. The Root Mean Square (RMSE) values ranged from 110 mg/L to 220 mg/L. The best fit was obtained using the AdB and RF models, with R2 values of 0.77 and 0.74 in the training step and 0.67 and 0.64 in the prediction step. The NSE values were 0.76 and 0.72 in the training step and 0.67 and 0.62 in the prediction step. The predictions from AdB were sensitive to all six factors. However, the sensitivity level was variable.
KW  - stormwater quality
KW  - urban watersheds
KW  - machine learning algorithms
KW  - total suspended solids
DO  - 10.3390/w13020147
TY  - EJOU
AU  - Yu, Tong
AU  - Wu, Wenjin
AU  - Gong, Chen
AU  - Li, Xinwu
TI  - Residual Multi-Attention Classification Network for A Forest Dominated Tropical Landscape Using High-Resolution Remote Sensing Imagery
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 1
SN  - 2220-9964

AB  - Tropical forests are of vital importance for maintaining biodiversity, regulating climate and material cycles while facing deforestation, agricultural reclamation, and managing various pressures. Remote sensing (RS) can support effective monitoring and mapping approaches for tropical forests, and to facilitate this we propose a deep neural network with an encoder&ndash;decoder architecture here to classify tropical forests and their environment. To deal with the complexity of tropical landscapes, this method utilizes a multi-scale convolution neural network (CNN) to expand the receptive field and extract multi-scale features. The model refines the features with several attention modules and fuses them through an upsampling module. A two-stage training strategy is proposed to alleviate misclassifications caused by sample imbalances. A joint loss function based on cross-entropy loss and the generalized Dice loss is applied in the first stage, and the second stage used the focal loss to fine-tune the weights. As a case study, we use Hainan tropical reserves to test the performance of this model. Compared with four state-of-the-art (SOTA) semantic segmentation networks, our network achieves the best performance with two Hainan datasets (mean intersection over union (MIoU) percentages of 85.78% and 82.85%). We also apply the new model to classify a public true color dataset which has 17 semantic classes and obtain results with an 83.75% MIoU. This further demonstrates the applicability and potential of this model in complex classification tasks.
KW  - remote sensing
KW  - deep convolution network
KW  - image analysis
KW  - land use and land cover (LULC)
KW  - tropical forest
DO  - 10.3390/ijgi10010022
TY  - EJOU
AU  - Canata, Tatiana F.
AU  - Wei, Marcelo C.
AU  - Maldaner, Leonardo F.
AU  - Molin, JosÃ© P.
TI  - Sugarcane Yield Mapping Using High-Resolution Imagery Data and Machine Learning Technique
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 2
SN  - 2072-4292

AB  - Yield maps provide essential information to guide precision agriculture (PA) practices. Yet, on-board yield monitoring for sugarcane can be challenging. At the same time, orbital images have been widely used for indirect crop yield estimation for many crops like wheat, corn, and rice, but not for sugarcane. Due to this, the objective of this study is to explore the potential of multi-temporal imagery data as an alternative for sugarcane yield mapping. The study was based on developing predictive sugarcane yield models integrating time-series orbital imaging and a machine learning technique. A commercial sugarcane site was selected, and Sentinel-2 images were acquired from the beginning of the ratoon sprouting until harvesting of two consecutive cropping seasons. The predictive yield models RF (Random forest) and MLR (Multiple Linear Regression) were developed using orbital images and yield maps generated by a commercial sensor-system on harvesting. Original yield data were filtered and interpolated with the same spatial resolution of the orbital images. The entire dataset was divided into training and testing datasets. Spectral bands, especially the near-infrared at tillering crop stage showed greater contribution to predicting sugarcane yield than the use of derived spectral vegetation indices. The Root Mean Squared Error (RMSE) obtained for the RF regression based on multiple spectral bands was 4.63 Mg ha&minus;1 with an R2 of 0.70 for the testing dataset. Overall, the RF regression had better performance than the MLR to predict sugarcane yield.
KW  - orbital images
KW  - precision agriculture
KW  - remote sensing
KW  - vegetation index
DO  - 10.3390/rs13020232
TY  - EJOU
AU  - Basan, Elena
AU  - Basan, Alexandr
AU  - Nekrasov, Alexey
AU  - Fidge, Colin
AU  - Gamec, JÃ¡n
AU  - GamcovÃ¡, MÃ¡ria
TI  - A Self-Diagnosis Method for Detecting UAV Cyber Attacks Based on Analysis of Parameter Changes
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 2
SN  - 1424-8220

AB  - We consider how to protect Unmanned Aerial Vehicles (UAVs) from Global Positioning System (GPS) spoofing attacks to provide safe navigation. The Global Navigation Satellite System (GNSS) is widely used for locating drones and is by far the most popular navigation solution. This is because of the simplicity and relatively low cost of this technology, as well as the accuracy of the transmitted coordinates. Nevertheless, there are many security threats to GPS navigation. These are primarily related to the nature of the GPS signal, as an intruder can jam and spoof the GPS signal. We discuss methods of protection against this type of attack and have developed an experimental stand and conducted scenarios of attacks on a drone&rsquo;s GPS system. Data from the UAV&rsquo;s flight log were collected and analyzed in order to see the attack&rsquo;s impact on sensor readings. From this we identify a new method for detecting UAV anomalies by analyzing changes in internal parameters of the UAV. This self-diagnosis method allows a UAV to independently assess the presence of changes in its own subsystems indicative of cyber attacks.
KW  - UAV
KW  - GPS
KW  - cyber threats
KW  - anomalies
KW  - spoofing
KW  - entropy
KW  - cyber attacks
DO  - 10.3390/s21020509
TY  - EJOU
AU  - Wang, Le
AU  - Xiang, Lirong
AU  - Tang, Lie
AU  - Jiang, Huanyu
TI  - A Convolutional Neural Network-Based Method for Corn Stand Counting in the Field
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 2
SN  - 1424-8220

AB  - Accurate corn stand count in the field at early season is of great interest to corn breeders and plant geneticists. However, the commonly used manual counting method is time consuming, laborious, and prone to error. Nowadays, unmanned aerial vehicles (UAV) tend to be a popular base for plant-image-collecting platforms. However, detecting corn stands in the field is a challenging task, primarily because of camera motion, leaf fluttering caused by wind, shadows of plants caused by direct sunlight, and the complex soil background. As for the UAV system, there are mainly two limitations for early seedling detection and counting. First, flying height cannot ensure a high resolution for small objects. It is especially difficult to detect early corn seedlings at around one week after planting, because the plants are small and difficult to differentiate from the background. Second, the battery life and payload of UAV systems cannot support long-duration online counting work. In this research project, we developed an automated, robust, and high-throughput method for corn stand counting based on color images extracted from video clips. A pipeline developed based on the YoloV3 network and Kalman filter was used to count corn seedlings online. The results demonstrate that our method is accurate and reliable for stand counting, achieving an accuracy of over 98% at growth stages V2 and V3 (vegetative stages with two and three visible collars) with an average frame rate of 47 frames per second (FPS). This pipeline can also be mounted easily on manned cart, tractor, or field robotic systems for online corn counting.
KW  - deep learning
KW  - YoloV3
KW  - video tracking
KW  - corn stand counting
DO  - 10.3390/s21020507
TY  - EJOU
AU  - Dundas, Shannon J.
AU  - Vardanega, Molly
AU  - OâBrien, Patrick
AU  - McLeod, Steven R.
TI  - Quantifying Waterfowl Numbers: Comparison of Drone and Ground-Based Survey Methods for Surveying Waterfowl on Artificial Waterbodies
T2  - Drones

PY  - 2021
VL  - 5
IS  - 1
SN  - 2504-446X

AB  - Drones are becoming a common method for surveying wildlife as they offer an aerial perspective of the landscape. For waterbirds in particular, drones can overcome challenges associated with surveying locations not accessible on foot. With the rapid uptake of drone technology for bird surveys, there is a need to compare and calibrate new technologies with existing survey methods. We compared waterfowl counts derived from ground- and drone-based survey methods. We sought to determine if group size and waterbody size influenced the difference between counts of non-nesting waterfowl and if detection of species varied between survey methods. Surveys of waterfowl were carried out at constructed irrigation dams and wastewater treatment ponds throughout the Riverina region of New South Wales (NSW), Australia. Data were analyzed using Bayesian multilevel models (BMLM) with weakly informative priors. Overall, drone-derived counts of waterfowl were greater (+36%) than ground counts using a spotting scope (&beta;_ground= 0.64 [0.62&ndash;0.66], (R2 = 0.973)). Ground counts also tended to underestimate the size of groups. Waterbody size had an effect on comparative counts, with ground counts being proportionally less than drone counts (mean = 0.74). The number of species identified in each waterbody type was similar regardless of survey method. Drone-derived counts are more accurate compared to traditional ground counts, but drones do have some drawbacks including initial equipment costs and time-consuming image or photo processing. Future surveys should consider using drones for more accurately surveying waterbirds, especially when large groups of birds are present on larger waterbodies.
KW  - population estimates
KW  - UAV
KW  - Australian ducks
DO  - 10.3390/drones5010005
TY  - EJOU
AU  - Nguyen, Ha T.
AU  - Lopez Caceres, Maximo L.
AU  - Moritake, Koma
AU  - Kentsch, Sarah
AU  - Shu, Hase
AU  - Diez, Yago
TI  - Individual Sick Fir Tree (Abies mariesii) Identification in Insect Infested Forests by Means of UAV Images and Deep Learning
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 2
SN  - 2072-4292

AB  - Insect outbreaks are a recurrent natural phenomenon in forest ecosystems expected to increase due to climate change. Recent advances in Unmanned Aerial Vehicles (UAV) and Deep Learning (DL) Networks provide us with tools to monitor them. In this study we used nine orthomosaics and normalized Digital Surface Models (nDSM) to detect and classify healthy and sick Maries fir trees as well as deciduous trees. This study aims at automatically classifying treetops by means of a novel computer vision treetops detection algorithm and the adaptation of existing DL architectures. Considering detection alone, the accuracy results showed 85.70% success. In terms of detection and classification, we were able to detect/classify correctly 78.59% of all tree classes (39.64% for sick fir). However, with data augmentation, detection/classification percentage of the sick fir class rose to 73.01% at the cost of the result accuracy of all tree classes that dropped 63.57%. The implementation of UAV, computer vision and DL techniques contribute to the development of a new approach to evaluate the impact of insect outbreaks in forest.
KW  - deep learning
KW  - computer vision
KW  - UAV
KW  - individual tree detection
KW  - tree classification
KW  - sick tree detection
DO  - 10.3390/rs13020260
TY  - EJOU
AU  - Wada, Daichi
AU  - Araujo-Estrada, Sergio A.
AU  - Windsor, Shane
TI  - Unmanned Aerial Vehicle Pitch Control Using Deep Reinforcement Learning with Discrete Actions in Wind Tunnel Test
T2  - Aerospace

PY  - 2021
VL  - 8
IS  - 1
SN  - 2226-4310

AB  - Deep reinforcement learning is a promising method for training a nonlinear attitude controller for fixed-wing unmanned aerial vehicles. Until now, proof-of-concept studies have demonstrated successful attitude control in simulation. However, detailed experimental investigations have not yet been conducted. This study applied deep reinforcement learning for one-degree-of-freedom pitch control in wind tunnel tests with the aim of gaining practical understandings of attitude control application. Three controllers with different discrete action choices, that is, elevator angles, were designed. The controllers with larger action rates exhibited better performance in terms of following angle-of-attack commands. The root mean square errors for tracking angle-of-attack commands decreased from 3.42&deg; to 1.99&deg; as the maximum action rate increased from 10&deg;/s to 50&deg;/s. The comparison between experimental and simulation results showed that the controller with a smaller action rate experienced the friction effect, and the controllers with larger action rates experienced fluctuating behaviors in elevator maneuvers owing to delay. The investigation of the effect of friction and delay on pitch control highlighted the importance of conducting experiments to understand actual control performances, specifically when the controllers were trained with a low-fidelity model.
KW  - attitude control
KW  - deep reinforcement learning
KW  - fixed-wing aircraft
KW  - unmanned aerial vehicle
KW  - wind tunnel test
DO  - 10.3390/aerospace8010018
TY  - EJOU
AU  - Zheng, Qiong
AU  - Ye, Huichun
AU  - Huang, Wenjiang
AU  - Dong, Yingying
AU  - Jiang, Hao
AU  - Wang, Chongyang
AU  - Li, Dan
AU  - Wang, Li
AU  - Chen, Shuisen
TI  - Integrating Spectral Information and Meteorological Data to Monitor Wheat Yellow Rust at a Regional Scale: A Case Study
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 2
SN  - 2072-4292

AB  - Wheat yellow rust has a severe impact on wheat production and threatens food security in China; as such, an effective monitoring method is necessary at the regional scale. We propose a model for yellow rust monitoring based on Sentinel-2 multispectral images and a series of two-stage vegetation indices and meteorological data. Sensitive spectral vegetation indices (single- and two-stage indices) and meteorological features for wheat yellow rust discrimination were selected using the random forest method. Wheat yellow rust monitoring models were established using three different classification methods: linear discriminant analysis (LDA), support vector machine (SVM), and artificial neural network (ANN). The results show that models based on two-stage indices (i.e., those calculated using images from two different days) significantly outperform single-stage index models (i.e., those calculated using an image from a single day), the overall accuracy improved from 63.2% to 78.9%. The classification accuracies of models combining a vegetation index with meteorological feature are higher than those of pure vegetation index models. Among them, the model based on two-stage vegetation indices and meteorological features performs best, with a classification accuracy exceeding 73.7%. The SVM algorithm performed best for wheat yellow rust monitoring among the three algorithms; its classification accuracy (84.2%) was ~10.5% and 5.3% greater than those of LDA and ANN, respectively. Combined with crop growth and environmental information, our model has great potential for monitoring wheat yellow rust at a regional scale. Future work will focus on regional-scale monitoring and forecasting of crop disease.
KW  - wheat yellow rust
KW  - vegetation indices
KW  - meteorological information
KW  - food security
KW  - regional remote sensing
DO  - 10.3390/rs13020278
TY  - EJOU
AU  - Raheem, Dele
AU  - Dayoub, Moammar
AU  - Birech, Rhoda
AU  - Nakiyemba, Alice
TI  - The Contribution of Cereal Grains to Food Security and Sustainability in Africa: Potential Application of UAV in Ghana, Nigeria, Uganda, and Namibia
T2  - Urban Science

PY  - 2021
VL  - 5
IS  - 1
SN  - 2413-8851

AB  - Africa is a net importer of food, especially cereal grains, despite the importance of agriculture in the continent. The agricultural growth in Africa has been undermined by low investment in agriculture, poor infrastructure, high population growth rate, and low adoption of technologies. The agri-food value chain in many African countries will benefit from the adoption of appropriate technologies that are available in the digital landscape to leverage the agricultural sector, make it more attractive to the teeming youth population, and to reverse rural-urban migration. Attention to indigenous cereal grains and other crops that are grown locally and processed into different local foods would ensure food security. However, the availability of these crops in the market is often reduced due to damage before harvest by pests and predators leading to economic losses for farmers. In this article, we review the literature from a multidisciplinary perspective on the relevance of African indigenous food grains to food security in general and we highlight the potential application of drones to increase the yield of cereal grains in three regions of the continent&mdash;eastern, western, and southern Africa.
KW  - food security
KW  - food sovereignty
KW  - precision agriculture
KW  - cereal grains
KW  - Ghana
KW  - Nigeria
KW  - Uganda
KW  - Namibia
KW  - Africa
DO  - 10.3390/urbansci5010008
TY  - EJOU
AU  - Zhang, Xiaomin
AU  - Zhao, Zhiyao
AU  - Wang, Zhaoyang
AU  - Wang, Xiaoyi
TI  - Fault Detection and Identification Method for Quadcopter Based on Airframe Vibration Signals
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 2
SN  - 1424-8220

AB  - Quadcopters are widely used in a variety of military and civilian mission scenarios. Real-time online detection of the abnormal state of the quadcopter is vital to the safety of aircraft. Existing data-driven fault detection methods generally usually require numerous sensors to collect data. However, quadcopter airframe space is limited. A large number of sensors cannot be loaded, meaning that it is difficult to use additional sensors to capture fault signals for quadcopters. In this paper, without additional sensors, a Fault Detection and Identification (FDI) method for quadcopter blades based on airframe vibration signals is proposed using the airborne acceleration sensor. This method integrates multi-axis data information and effectively detects and identifies quadcopter blade faults through Long and Short-Term Memory (LSTM) network models. Through flight experiments, the quadcopter triaxial accelerometer data are collected for airframe vibration signals at first. Then, the wavelet packet decomposition method is employed to extract data features, and the standard deviations of the wavelet packet coefficients are employed to form the feature vector. Finally, the LSTM-based FDI model is constructed for quadcopter blade FDI. The results show that the method can effectively detect and identify quadcopter blade faults with a better FDI performance and a higher model accuracy compared with the Back Propagation (BP) neural network-based FDI model.
KW  - quadcopter
KW  - fault detection and identification
KW  - wavelet packet decomposition
KW  - LSTM network
KW  - airframe vibration signals
DO  - 10.3390/s21020581
TY  - EJOU
AU  - Berger, Katja
AU  - Rivera Caicedo, Juan P.
AU  - Martino, Luca
AU  - Wocher, Matthias
AU  - Hank, Tobias
AU  - Verrelst, Jochem
TI  - A Survey of Active Learning for Quantifying Vegetation Traits from Terrestrial Earth Observation Data
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 2
SN  - 2072-4292

AB  - The current exponential increase of spatiotemporally explicit data streams from satellite-based Earth observation missions offers promising opportunities for global vegetation monitoring. Intelligent sampling through active learning (AL) heuristics provides a pathway for fast inference of essential vegetation variables by means of hybrid retrieval approaches, i.e., machine learning regression algorithms trained by radiative transfer model (RTM) simulations. In this study we summarize AL theory and perform a brief systematic literature survey about AL heuristics used in the context of Earth observation regression problems over terrestrial targets. Across all relevant studies it appeared that: (i) retrieval accuracy of AL-optimized training data sets outperformed models trained over large randomly sampled data sets, and (ii) Euclidean distance-based (EBD) diversity method tends to be the most efficient AL technique in terms of accuracy and computational demand. Additionally, a case study is presented based on experimental data employing both uncertainty and diversity AL criteria. Hereby, a a simulated training data base by the PROSAIL-PRO canopy RTM is used to demonstrate the benefit of AL techniques for the estimation of total leaf carotenoid content (Cxc) and leaf water content (Cw). Gaussian process regression (GPR) was incorporated to minimize and optimize the training data set with AL. Training the GPR algorithm on optimally AL-based sampled data sets led to improved variable retrievals compared to training on full data pools, which is further demonstrated on a mapping example. From these findings we can recommend the use of AL-based sub-sampling procedures to select the most informative samples out of large training data pools. This will not only optimize regression accuracy due to exclusion of redundant information, but also speed up processing time and reduce final model size of kernel-based machine learning regression algorithms, such as GPR. With this study we want to encourage further testing and implementation of AL sampling methods for hybrid retrieval workflows. AL can contribute to the solution of regression problems within the framework of operational vegetation monitoring using satellite imaging spectroscopy data, and may strongly facilitate data processing for cloud-computing platforms.
KW  - Gaussian process regression
KW  - EnMAP
KW  - hyperspectral
KW  - query strategies
KW  - optimal experimental design
DO  - 10.3390/rs13020287
TY  - EJOU
AU  - Debella-Gilo, Misganu
AU  - Gjertsen, Arnt K.
TI  - Mapping Seasonal Agricultural Land Use Types Using Deep Learning on Sentinel-2 Image Time Series
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 2
SN  - 2072-4292

AB  - The size and location of agricultural fields that are in active use and the type of use during the growing season are among the vital information that is needed for the careful planning and forecasting of agricultural production at national and regional scales. In areas where such data are not readily available, an independent seasonal monitoring method is needed. Remote sensing is a widely used tool to map land use types, although there are some limitations that can partly be circumvented by using, among others, multiple observations, careful feature selection and appropriate analysis methods. Here, we used Sentinel-2 satellite image time series (SITS) over the land area of Norway to map three agricultural land use classes: cereal crops, fodder crops (grass) and unused areas. The Multilayer Perceptron (MLP) and two variants of the Convolutional Neural Network (CNN), are implemented on SITS data of four different temporal resolutions. These enabled us to compare twelve model-dataset combinations to identify the model-dataset combination that results in the most accurate predictions. The CNN is implemented in the spectral and temporal dimensions instead of the conventional spatial dimension. Rather than using existing deep learning architectures, an autotuning procedure is implemented so that the model hyperparameters are empirically optimized during the training. The results obtained on held-out test data show that up to 94% overall accuracy and 90% Cohen&rsquo;s Kappa can be obtained when the 2D CNN is applied on the SITS data with a temporal resolution of 7 days. This is closely followed by the 1D CNN on the same dataset. However, the latter performs better than the former in predicting data outside the training set. It is further observed that cereal is predicted with the highest accuracy, followed by grass. Predicting the unused areas has been found to be difficult as there is no distinct surface condition that is common for all unused areas.
KW  - multilayer perceptron
KW  - CNN
KW  - hyperparameter tuning
KW  - cereal
KW  - grass
DO  - 10.3390/rs13020289
TY  - EJOU
AU  - FernÃ¡ndez-Lozano, Javier
AU  - Sanz-Ablanedo, Enoc
TI  - Unraveling the Morphological Constraints on Roman Gold Mining Hydraulic Infrastructure in NW Spain. A UAV-Derived Photogrammetric and Multispectral Approach
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 2
SN  - 2072-4292

AB  - The province of Le&oacute;n preserves a unique hydraulic infrastructure 1200 km-long, used for the exploitation of auriferous deposits in Roman times. It represents the most extensive waterworks in Europe and is one of the best-preserved examples of mining heritage in Antiquity. In this work, three mining exploitation sectors (upper, middle, and lower) characterized by channels and leats developed in different geological materials were examined, using Unmanned Aerial Vehicles (UAVs). A multi-approach based on a comparison of photogrammetric and multispectral data improved the identification and description of the hydraulic network. Comparison with traditional orthoimages and LiDAR data suggests that UAV-derived multispectral images are of great interest in areas where these sets of data have low resolution or areas that are densely covered by vegetation. The results showed that the size of the channel box and its width were factors that do not depend exclusively on the available water resources, as previously suggested, but also on the geological and hydraulic conditioning factors that intervene in each sector. Additionally, the detailed study allowed the establishment of a water sheet maximum height that was much lower than previously thought. All in all, these inferences might help researchers develop new strategies for mapping the Roman mining infrastructure and establishing the importance of geological inheritance on the construction of the hydraulic system that led the Romans to the accomplishment of the largest mining infrastructure ever known in Europe.
KW  - Roman gold mining
KW  - hydraulic network
KW  - UAV-derived photogrammetry
KW  - multispectral images
KW  - Roman channels
KW  - mining infrastructure
KW  - geoarchaeology
DO  - 10.3390/rs13020291
TY  - EJOU
AU  - Teng, Shuai
AU  - Liu, Zongchao
AU  - Chen, Gongfa
AU  - Cheng, Li
TI  - Concrete Crack Detection Based on Well-Known Feature Extractor Model and the YOLO_v2 Network
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 2
SN  - 2076-3417

AB  - This paper compares the crack detection performance (in terms of precision and computational cost) of the YOLO_v2 using 11 feature extractors, which provides a base for realizing fast and accurate crack detection on concrete structures. Cracks on concrete structures are an important indicator for assessing their durability and safety, and real-time crack detection is an essential task in structural maintenance. The object detection algorithm, especially the YOLO series network, has significant potential in crack detection, while the feature extractor is the most important component of the YOLO_v2. Hence, this paper employs 11 well-known CNN models as the feature extractor of the YOLO_v2 for crack detection. The results confirm that a different feature extractor model of the YOLO_v2 network leads to a different detection result, among which the AP value is 0.89, 0, and 0 for &lsquo;resnet18&rsquo;, &lsquo;alexnet&rsquo;, and &lsquo;vgg16&rsquo;, respectively meanwhile, the &lsquo;googlenet&rsquo; (AP = 0.84) and &lsquo;mobilenetv2&rsquo; (AP = 0.87) also demonstrate comparable AP values. In terms of computing speed, the &lsquo;alexnet&rsquo; takes the least computational time, the &lsquo;squeezenet&rsquo; and &lsquo;resnet18&rsquo; are ranked second and third respectively; therefore, the &lsquo;resnet18&rsquo; is the best feature extractor model in terms of precision and computational cost. Additionally, through the parametric study (influence on detection results of the training epoch, feature extraction layer, and testing image size), the associated parameters indeed have an impact on the detection results. It is demonstrated that: excellent crack detection results can be achieved by the YOLO_v2 detector, in which an appropriate feature extractor model, training epoch, feature extraction layer, and testing image size play an important role.
KW  - crack detection
KW  - YOLO network
KW  - feature extractor
KW  - feature extraction layer
KW  - computational cost
KW  - detection precision
DO  - 10.3390/app11020813
TY  - EJOU
AU  - Yang, Baohua
AU  - Ma, Jifeng
AU  - Yao, Xia
AU  - Cao, Weixing
AU  - Zhu, Yan
TI  - Estimation of Leaf Nitrogen Content in Wheat Based on Fusion of Spectral Features and Deep Features from Near Infrared Hyperspectral Imagery
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 2
SN  - 1424-8220

AB  - Nitrogen is an important indicator for monitoring wheat growth. The rapid development and wide application of non-destructive detection provide many approaches for estimating leaf nitrogen content (LNC) in wheat. Previous studies have shown that better results have been obtained in the estimation of LNC in wheat based on spectral features. However, the lack of automatically extracted features leads to poor universality of the estimation model. Therefore, a feature fusion method for estimating LNC in wheat by combining spectral features with deep features (spatial features) was proposed. The deep features were automatically obtained with a convolutional neural network model based on the PyTorch framework. The spectral features were obtained using spectral information including position features (PFs) and vegetation indices (VIs). Different models based on feature combination for evaluating LNC in wheat were constructed: partial least squares regression (PLS), gradient boosting decision tree (GBDT), and support vector regression (SVR). The results indicate that the model based on the fusion feature from near-ground hyperspectral imagery has good estimation effect. In particular, the estimation accuracy of the GBDT model is the best (R2 = 0.975 for calibration set, R2 = 0.861 for validation set). These findings demonstrate that the approach proposed in this study improved the estimation performance of LNC in wheat, which could provide technical support in wheat growth monitoring.
KW  - convolutional neural network
KW  - leaf nitrogen content
KW  - deep features
KW  - wheat
KW  - spectral features
DO  - 10.3390/s21020613
TY  - EJOU
AU  - Biney, James K.
AU  - Saberioon, Mohammadmehdi
AU  - BorÅ¯vka, LuboÅ¡
AU  - HouÅ¡ka, Jakub
AU  - VaÅ¡Ã¡t, Radim
AU  - Chapman Agyeman, Prince
AU  - Coblinski, JoÃ£o A.
AU  - Klement, AleÅ¡
TI  - Exploring the Suitability of UAS-Based Multispectral Images for Estimating Soil Organic Carbon: Comparison with Proximal Soil Sensing and Spaceborne Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 2
SN  - 2072-4292

AB  - Soil organic carbon (SOC) is a variable of vital environmental significance in terms of soil quality and function, global food security, and climate change mitigation. Estimation of its content and prediction accuracy on a broader scale remain crucial. Although, spectroscopy under proximal sensing remains one of the best approaches to accurately predict SOC, however, spectroscopy limitation to estimate SOC on a larger spatial scale remains a concern. Therefore, for an efficient quantification of SOC content, faster and less costly techniques are needed, recent studies have suggested the use of remote sensing approaches. The primary aim of this research was to evaluate and compare the capabilities of small Unmanned Aircraft Systems (UAS) for monitoring and estimation of SOC with those obtained from spaceborne (Sentinel-2) and proximal soil sensing (field spectroscopy measurements) on an agricultural field low in SOC content. Nine calculated spectral indices were added to the remote sensing approaches (UAS and Sentinel-2) to enhance their predictive accuracy. Modeling was carried out using various bands/wavelength (UAS (6), Sentinel-2 (9)) and the calculated spectral indices were used as independent variables to generate soil prediction models using five-fold cross-validation built using random forest (RF) and support vector machine regression (SVMR). The correlation regarding SOC and the selected indices and bands/wavelengths was determined prior to the prediction. Our results revealed that the selected spectral indices slightly influenced the output of UAS compared to Sentinel-2 dataset as the latter had only one index correlated with SOC. For prediction, the models built on UAS data had a better accuracy with RF than the two other data used. However, using SVMR, the field spectral prediction models achieved a better overall result for the entire study (log(1/R), RPD = 1.40; R2CV = 0.48; RPIQ = 1.65; RMSEPCV = 0.24), followed by UAS and then Sentinel-2, respectively. This study has shown that UAS imagery can be exploited efficiently using spectral indices.
KW  - soil organic carbon
KW  - proximal soil sensing
KW  - remote sensing multispectral sensors
KW  - agricultural soil
KW  - spectral indices
DO  - 10.3390/rs13020308
TY  - EJOU
AU  - Li, Haolu
AU  - Wang, Guojie
AU  - Dong, Zhen
AU  - Wei, Xikun
AU  - Wu, Mengjuan
AU  - Song, Huihui
AU  - Amankwah, Solomon O.
TI  - Identifying Cotton Fields from Remote Sensing Images Using Multiple Deep Learning Networks
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 1
SN  - 2073-4395

AB  - Remote sensing imageries processed through empirical and deterministic approaches help predict multiple agronomic traits throughout the growing season. Accurate identification of cotton crop from remotely sensed imageries is a significant task in precision agriculture. This study aims to utilize a deep learning-based framework for cotton crop field identification with Gaofen-1 (GF-1) high-resolution (16 m) imageries in Wei-Ku region, China. An optimized model for the pixel-wise multidimensional densely connected convolutional neural network (DenseNet) was used. Four widely-used classic convolutional neural networks (CNNs), including ResNet, VGG, SegNet, and DeepLab v3+, were also used for accuracy assessment. The results infer that DenseNet can identify cotton crop features within a relatively shorter time about 5 h for training convergence. The model performance was examined by multiple indicators (P, F1, R, and mIou) produced through the confusion matrix, and the derived cotton fields were then visualized. The DenseNet model has illustrated considerable improvements in comparison with the preceding mainstream models. The results showed that the retrieval precision was 0.948, F1 score was 0.953, and mIou was 0.911. Furthermore, its performance is relatively better in discriminating cotton crop fields&rsquo; fine structures when clouds, mountain shadows, and urban built up.
KW  - cotton identification
KW  - deep learning
KW  - DenseNet
KW  - remote sensing images
DO  - 10.3390/agronomy11010174
TY  - EJOU
AU  - Ni, Ming
AU  - Wang, Hongjie
AU  - Liu, Xudong
AU  - Liao, Yilin
AU  - Fu, Lin
AU  - Wu, Qianqian
AU  - Mu, Jiong
AU  - Chen, Xiaoyan
AU  - Li, Jun
TI  - Design of Variable Spray System for Plant Protection UAV Based on CFD Simulation and Regression Analysis
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 2
SN  - 1424-8220

AB  - Multi-rotor unmanned aerial vehicles (UAVs) for plant protection are widely used in China&rsquo;s agricultural production. However, spray droplets often drift and distribute nonuniformly, thereby harming its utilization and the environment. A variable spray system is designed, discussed, and verified to solve this problem. The distribution characteristics of droplet deposition under different spray states (flight state, environment state, nozzle state) are obtained through computational fluid dynamics simulation. In the verification experiment, the wind velocity error of most sample points is less than 1 m/s, and the deposition ratio error is less than 10%, indicating that the simulation is reliable. A simulation data set is used to train support vector regression and back propagation neural network with multiple parameters. An optimal regression model with the root mean square error of 6.5% is selected. The UAV offset and nozzle flow of the variable spray system can be obtained in accordance with the current spray state by multi-sensor fusion and the predicted deposition distribution characteristics. The farmland experiment shows that the deposition volume error between the prediction and experiment is within 30%, thereby proving the effectiveness of the system. This article provides a reference for the improvement of UAV intelligent spray system.
KW  - aviation plant protection
KW  - downwash wind field
KW  - deposition distribution characteristic
KW  - support vector regression
KW  - back propagation neural network
KW  - farmland experiment
DO  - 10.3390/s21020638
TY  - EJOU
AU  - Kadhim, Israa
AU  - Abed, Fanar M.
TI  - The Potential of LiDAR and UAV-Photogrammetric Data Analysis to Interpret Archaeological Sites: A Case Study of Chun Castle in South-West England
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 1
SN  - 2220-9964

AB  - With the increasing demands to use remote sensing approaches, such as aerial photography, satellite imagery, and LiDAR in archaeological applications, there is still a limited number of studies assessing the differences between remote sensing methods in extracting new archaeological finds. Therefore, this work aims to critically compare two types of fine-scale remotely sensed data: LiDAR and an Unmanned Aerial Vehicle (UAV) derived Structure from Motion (SfM) photogrammetry. To achieve this, aerial imagery and airborne LiDAR datasets of Chun Castle were acquired, processed, analyzed, and interpreted. Chun Castle is one of the most remarkable ancient sites in Cornwall County (Southwest England) that had not been surveyed and explored by non-destructive techniques. The work outlines the approaches that were applied to the remotely sensed data to reveal potential remains: Visualization methods (e.g., hillshade and slope raster images), ISODATA clustering, and Support Vector Machine (SVM) algorithms. The results display various archaeological remains within the study site that have been successfully identified. Applying multiple methods and algorithms have successfully improved our understanding of spatial attributes within the landscape. The outcomes demonstrate how raster derivable from inexpensive approaches can be used to identify archaeological remains and hidden monuments, which have the possibility to revolutionize archaeological understanding.
KW  - archaeology
KW  - automatic detection
KW  - Chun Castle
KW  - drone
KW  - hidden features
KW  - Iron Age
KW  - LiDAR
KW  - SfM-photogrammetry
KW  - remote sensing
KW  - RRIMs
KW  - visualization methods
DO  - 10.3390/ijgi10010041
TY  - EJOU
AU  - Cesco, Stefano
AU  - Pii, Youry
AU  - Borruso, Luigimaria
AU  - Orzes, Guido
AU  - Lugli, Paolo
AU  - Mazzetto, Fabrizio
AU  - Genova, Giulio
AU  - Signorini, Marco
AU  - Brunetto, Gustavo
AU  - Terzano, Roberto
AU  - Vigani, Gianpiero
AU  - Mimmo, Tanja
TI  - A Smart and Sustainable Future for Viticulture Is Rooted in Soil: How to Face Cu Toxicity
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 3
SN  - 2076-3417

AB  - In recent decades, agriculture has faced the fundamental challenge of needing to increase food production and quality in order to meet the requirements of a growing global population. Similarly, viticulture has also been undergoing change. Several countries are reducing their vineyard areas, and several others are increasing them. In addition, viticulture is moving towards higher altitudes and latitudes due to climate change. Furthermore, global warming is also exacerbating the incidence of fungal diseases in vineyards, forcing farmers to apply agrochemicals to preserve production yields and quality. The repeated application of copper (Cu)-based fungicides in conventional and organic farming has caused a stepwise accumulation of Cu in vineyard soils, posing environmental and toxicological threats. High Cu concentrations in soils can have multiple impacts on agricultural systems. In fact, it can (i) alter the chemical-physical properties of soils, thus compromising their fertility; (ii) induce toxicity phenomena in plants, producing detrimental effects on growth and productivity; and (iii) affect the microbial biodiversity of soils, thereby influencing some microbial-driven soil processes. However, several indirect (e.g., management of rhizosphere processes through intercropping and/or fertilization strategies) and direct (e.g., exploitation of vine resistant genotypes) strategies have been proposed to restrain Cu accumulation in soils. Furthermore, the application of precision and smart viticulture paradigms and their related technologies could allow a timely, localized and balanced distribution of agrochemicals to achieve the required goals. The present review highlights the necessity of applying multidisciplinary approaches to meet the requisites of sustainability demanded of modern viticulture.
KW  - copper
KW  - rhizosphere
KW  - smart agriculture
KW  - microbes
KW  - vineyard
DO  - 10.3390/app11030907
TY  - EJOU
AU  - Sahal, Radhya
AU  - Alsamhi, Saeed H.
AU  - Breslin, John G.
AU  - Ali, Muhammad I.
TI  - Industry 4.0 towards Forestry 4.0: Fire Detection Use Case
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 3
SN  - 1424-8220

AB  - Forestry 4.0 is inspired by the Industry 4.0 concept, which plays a vital role in the next industrial generation revolution. It is ushering in a new era for efficient and sustainable forest management. Environmental sustainability and climate change are related challenges to promote sustainable forest management of natural resources. Internet of Forest Things (IoFT) is an emerging technology that helps manage forest sustainability and protect forest from hazards via distributing smart devices for gathering data stream during monitoring and detecting fire. Stream processing is a well-known research area, and recently, it has gained a further significance due to the emergence of IoFT devices. Distributed stream processing platforms have emerged, e.g., Apache Flink, Storm, and Spark, etc. Querying windowing is the heart of any stream-processing platform which splits infinite data stream into chunks of finite data to execute a query. Dynamic query window-based processing can reduce the reporting time in case of missing and delayed events caused by data drift.In this paper, we present a novel dynamic mechanism to recommend the optimal window size and type based on the dynamic context of IoFT application. In particular, we designed a dynamic window selector for stream queries considering input stream data characteristics, application workload and resource constraints to recommend the optimal stream query window configuration. A research gap on the likelihood of adopting smart IoFT devices in environmental sustainability indicates a lack of empirical studies to pursue forest sustainability, i.e., sustainable forestry applications. So, we focus on forest fire management and detection as a use case of Forestry 4.0, one of the dynamic environmental management challenges, i.e., climate change, to deliver sustainable forestry goals. According to the dynamic window selector&rsquo;s experimental results, end-to-end latency time for the reported fire alerts has been reduced by dynamical adaptation of window size with IoFT stream rate changes.
KW  - IoT
KW  - query
KW  - industry 4.0
KW  - stream processing
KW  - window size
KW  - forestry 4.0
KW  - internet of forestry things
KW  - forest fire detection
KW  - forest sustainability
DO  - 10.3390/s21030694
TY  - EJOU
AU  - Butcher, Paul A.
AU  - Colefax, Andrew P.
AU  - Gorkin, Robert A.
AU  - Kajiura, Stephen M.
AU  - LÃ³pez, Naima A.
AU  - Mourier, Johann
AU  - Purcell, Cormac R.
AU  - Skomal, Gregory B.
AU  - Tucker, James P.
AU  - Walsh, Andrew J.
AU  - Williamson, Jane E.
AU  - Raoult, Vincent
TI  - The Drone Revolution of Shark Science: A Review
T2  - Drones

PY  - 2021
VL  - 5
IS  - 1
SN  - 2504-446X

AB  - Over the past decade, drones have become a popular tool for wildlife management and research. Drones have shown significant value for animals that were often difficult or dangerous to study using traditional survey methods. In the past five years drone technology has become commonplace for shark research with their use above, and more recently, below the water helping to minimise knowledge gaps about these cryptic species. Drones have enhanced our understanding of shark behaviour and are critically important tools, not only due to the importance and conservation of the animals in the ecosystem, but to also help minimise dangerous encounters with humans. To provide some guidance for their future use in relation to sharks, this review provides an overview of how drones are currently used with critical context for shark monitoring. We show how drones have been used to fill knowledge gaps around fundamental shark behaviours or movements, social interactions, and predation across multiple species and scenarios. We further detail the advancement in technology across sensors, automation, and artificial intelligence that are improving our abilities in data collection and analysis and opening opportunities for shark-related beach safety. An investigation of the shark-based research potential for underwater drones (ROV/AUV) is also provided. Finally, this review provides baseline observations that have been pioneered for shark research and recommendations for how drones might be used to enhance our knowledge in the future.
KW  - artificial intelligence
KW  - AUV
KW  - drones
KW  - protocols
KW  - ROV
KW  - sharks
KW  - UAV
DO  - 10.3390/drones5010008
TY  - EJOU
AU  - Nguyen, Canh
AU  - Sagan, Vasit
AU  - Maimaitiyiming, Matthew
AU  - Maimaitijiang, Maitiniyazi
AU  - Bhadra, Sourav
AU  - Kwasniewski, Misha T.
TI  - Early Detection of Plant Viral Disease Using Hyperspectral Imaging and Deep Learning
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 3
SN  - 1424-8220

AB  - Early detection of grapevine viral diseases is critical for early interventions in order to prevent the disease from spreading to the entire vineyard. Hyperspectral remote sensing can potentially detect and quantify viral diseases in a nondestructive manner. This study utilized hyperspectral imagery at the plant level to identify and classify grapevines inoculated with the newly discovered DNA virus grapevine vein-clearing virus (GVCV) at the early asymptomatic stages. An experiment was set up at a test site at South Farm Research Center, Columbia, MO, USA (38.92 N, &minus;92.28 W), with two grapevine groups, namely healthy and GVCV-infected, while other conditions were controlled. Images of each vine were captured by a SPECIM IQ 400&ndash;1000 nm hyperspectral sensor (Oulu, Finland). Hyperspectral images were calibrated and preprocessed to retain only grapevine pixels. A statistical approach was employed to discriminate two reflectance spectra patterns between healthy and GVCV vines. Disease-centric vegetation indices (VIs) were established and explored in terms of their importance to the classification power. Pixel-wise (spectral features) classification was performed in parallel with image-wise (joint spatial&ndash;spectral features) classification within a framework involving deep learning architectures and traditional machine learning. The results showed that: (1) the discriminative wavelength regions included the 900&ndash;940 nm range in the near-infrared (NIR) region in vines 30 days after sowing (DAS) and the entire visual (VIS) region of 400&ndash;700 nm in vines 90 DAS; (2) the normalized pheophytization index (NPQI), fluorescence ratio index 1 (FRI1), plant senescence reflectance index (PSRI), anthocyanin index (AntGitelson), and water stress and canopy temperature (WSCT) measures were the most discriminative indices; (3) the support vector machine (SVM) was effective in VI-wise classification with smaller feature spaces, while the RF classifier performed better in pixel-wise and image-wise classification with larger feature spaces; and (4) the automated 3D convolutional neural network (3D-CNN) feature extractor provided promising results over the 2D convolutional neural network (2D-CNN) in learning features from hyperspectral data cubes with a limited number of samples.
KW  - plant disease
KW  - spectral statistics
KW  - machine learning
KW  - 2D-CNN
KW  - 3D-CNN
KW  - grapevine vein-clearing virus (GVCV)
DO  - 10.3390/s21030742
TY  - EJOU
AU  - Chen, Xinxin
AU  - Jiang, Kang
AU  - Zhu, Yushi
AU  - Wang, Xiangjun
AU  - Yun, Ting
TI  - Individual Tree Crown Segmentation Directly from UAV-Borne LiDAR Data Using the PointNet of Deep Learning
T2  - Forests

PY  - 2021
VL  - 12
IS  - 2
SN  - 1999-4907

AB  - Accurate individual tree crown (ITC) segmentation from scanned point clouds is a fundamental task in forest biomass monitoring and forest ecology management. Light detection and ranging (LiDAR) as a mainstream tool for forest survey is advancing the pattern of forest data acquisition. In this study, we performed a novel deep learning framework directly processing the forest point clouds belonging to the four forest types (i.e., the nursery base, the monastery garden, the mixed forest, and the defoliated forest) to realize the ITC segmentation. The specific steps of our approach were as follows: first, a voxelization strategy was conducted to subdivide the collected point clouds with various tree species from various forest types into many voxels. These voxels containing point clouds were taken as training samples for the PointNet deep learning framework to identify the tree crowns at the voxel scale. Second, based on the initial segmentation results, we used the height-related gradient information to accurately depict the boundaries of each tree crown. Meanwhile, the retrieved tree crown breadths of individual trees were compared with field measurements to verify the effectiveness of our approach. Among the four forest types, our results revealed the best performance for the nursery base (tree crown detection rate r = 0.90; crown breadth estimation R2 &gt; 0.94 and root mean squared error (RMSE) &lt; 0.2m). A sound performance was also achieved for the monastery garden and mixed forest, which had complex forest structures, complicated intersections of branches and different building types, with r = 0.85, R2 &gt; 0.88 and RMSE &lt; 0.6 m for the monastery garden and r = 0.80, R2 &gt; 0.85 and RMSE &lt; 0.8 m for the mixed forest. For the fourth forest plot type with the distribution of crown defoliation across the woodland, we achieved the performance with r = 0.82, R2 &gt; 0.79 and RMSE &lt; 0.7 m. Our method presents a robust framework inspired by the deep learning technology and computer graphics theory that solves the ITC segmentation problem and retrieves forest parameters under various forest conditions.
KW  - deep learning
KW  - individual tree crown segmentation
KW  - Airborne LiDAR data
KW  - computer graphics
DO  - 10.3390/f12020131
TY  - EJOU
AU  - Dias Santana, Guilherme M.
AU  - Cristo, Rogers S.
AU  - Lucas Jaquie Castelo Branco, Kalinka R.
TI  - Integrating Cognitive Radio with Unmanned Aerial Vehicles: An Overview
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 3
SN  - 1424-8220

AB  - Unmanned Aerial Vehicles (UAVs) demand technologies so they can not only fly autonomously, but also communicate with base stations, flight controllers, computers, devices, or even other UAVs. Still, UAVs usually operate within unlicensed spectrum bands, competing against the increasing number of mobile devices and other wireless networks. Combining UAVs with Cognitive Radio (CR) may increase their general communication performance, thus allowing them to execute missions where the conventional UAVs face limitations. CR provides a smart wireless communication which, instead of using a transmission frequency defined in the hardware, uses software transmission. CR smartly uses free transmission channels and/or chooses them according to application&rsquo;s requirements. Moreover, CR is considered a key enabler for deploying technologies that require high connectivity, such as Smart Cities, 5G, Internet of Things (IoT), and the Internet of Flying Things (IoFT). This paper presents an overview on the field of CR for UAV communications and its state-of-the-art, testbed alternatives for real data experiments, as well as specifications to build a simple and low-cost testbed, and indicates key opportunities and future challenges in the field.
KW  - unmanned aerial vehicles
KW  - cognitive radio networks
KW  - software defined radio
KW  - network sensing
KW  - security
KW  - internet of flying things
KW  - machine learning
KW  - energy management
DO  - 10.3390/s21030830
TY  - EJOU
AU  - Avtar, Ram
AU  - Kouser, Asma
AU  - Kumar, Ashwani
AU  - Singh, Deepak
AU  - Misra, Prakhar
AU  - Gupta, Ankita
AU  - Yunus, Ali P.
AU  - Kumar, Pankaj
AU  - Johnson, Brian A.
AU  - Dasgupta, Rajarshi
AU  - Sahu, Netrananda
AU  - Besse Rimba, Andi
TI  - Remote Sensing for International Peace and Security: Its Role and Implications
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 3
SN  - 2072-4292

AB  - Remote sensing technology has seen a massive rise in popularity over the last two decades, becoming an integral part of our lives. Space-based satellite technologies facilitated access to the inaccessible terrains, helped humanitarian teams, support complex emergencies, and contributed to monitoring and verifying conflict zones. The scoping phase of this review investigated the utility of the role of remote sensing application to complement international peace and security activities owing to their ability to provide objective near real-time insights at the ground level. The first part of this review looks into the major research concepts and implementation of remote sensing-based techniques for international peace and security applications and presented a meta-analysis on how advanced sensor capabilities can support various aspects of peace and security. With key examples, we demonstrated how this technology assemblage enacts multiple versions of peace and security: for refugee relief operations, in armed conflicts monitoring, tracking acts of genocide, providing evidence in courts of law, and assessing contravention in human rights. The second part of this review anticipates future challenges that can hinder the applicative capabilities of remote sensing in peace and security. Varying types of sensors pose discrepancies in image classifications and issues like cost, resolution, and difficulty of ground-truth in conflict areas. With emerging technologies and sufficient secondary resources available, remote sensing plays a vital operational tool in conflict-affected areas by supporting an extensive diversity in public policy actions for peacekeeping processes.
KW  - conflict resources monitoring
KW  - disease control and prevention
KW  - human rights
KW  - genocide tracking
KW  - human rights violation
KW  - geopolitics
DO  - 10.3390/rs13030439
TY  - EJOU
AU  - Zhou, Xixuan
AU  - Yang, Liao
AU  - Wang, Weisheng
AU  - Chen, Baili
TI  - UAV Data as an Alternative to Field Sampling to Monitor Vineyards Using Machine Learning Based on UAV/Sentinel-2 Data Fusion
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 3
SN  - 2072-4292

AB  - Pests and diseases affect the yield and quality of grapes directly and engender noteworthy economic losses. Diagnosing &ldquo;lesions&rdquo; on vines as soon as possible and dynamically monitoring symptoms caused by pests and diseases at a larger scale are essential to pest control. This study has appraised the capabilities of high-resolution unmanned aerial vehicle (UAV) data as an alternative to manual field sampling to obtain sampling canopy sets and to supplement satellite-based monitoring using machine learning models including partial least squared regression (PLSR), support vector regression (SVR), random forest regression (RFR), and extreme learning regression (ELR) with a new activation function. UAV data were acquired from two flights in Turpan to determine disease severity (DS) and disease incidence (DI) and compared with field visual assessments. The UAV-derived canopy structure including canopy height (CH) and vegetation fraction cover (VFC), as well as satellite-based spectral features calculated from Sentinel-2A/B data were analyzed to evaluate the potential of UAV data to replace manual sampling data and predict DI. It was found that SVR slightly outperformed the other methods with a root mean square error (RMSE) of 1.89%. Moreover, the combination of canopy structure (CS) and vegetation index (VIs) improved prediction accuracy compared with single-type features (RMSEcs of 2.86% and RMSEVIs of 1.93%). This study tested the ability of UAV sampling to replace manual sampling on a large scale and introduced opportunities and challenges of fusing different features to monitor vineyards using machine learning. Within this framework, disease incidence can be estimated efficiently and accurately for larger area monitoring operation.
KW  - unmanned aircraft system (UAS)
KW  - vineyard monitoring
KW  - machine learning
KW  - pests and diseases
KW  - Sentinel-2 data
KW  - UAV data
DO  - 10.3390/rs13030457
TY  - EJOU
AU  - Milne, Sol
AU  - Martin, Julien G. A.
AU  - Reynolds, Glen
AU  - Vairappan, Charles S.
AU  - Slade, Eleanor M.
AU  - Brodie, Jedediah F.
AU  - Wich, Serge A.
AU  - Williamson, Nicola
AU  - Burslem, David F. R. P.
TI  - Drivers of Bornean Orangutan Distribution across a Multiple-Use Tropical Landscape
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 3
SN  - 2072-4292

AB  - Logging and conversion of tropical forests in Southeast Asia have resulted in the expansion of landscapes containing a mosaic of habitats that may vary in their ability to sustain local biodiversity. However, the complexity of these landscapes makes it difficult to assess abundance and distribution of some species using ground-based surveys alone. Here, we deployed a combination of ground-transects and aerial surveys to determine drivers of the critically endangered Bornean Orangutan (Pongo pygmaeus morio) distribution across a large multiple-use landscape in Sabah, Malaysian Borneo. Ground-transects and aerial surveys using drones were conducted for orangutan nests and hemi-epiphytic strangler fig trees (Ficus spp.) (an important food resource) in 48 survey areas across 76 km2, within a study landscape of 261 km2. Orangutan nest count data were fitted to models accounting for variation in land use, above-ground carbon density (ACD, a surrogate for forest quality), strangler fig density, and elevation (between 117 and 675 m). Orangutan nest counts were significantly higher in all land uses possessing natural forest cover, regardless of degradation status, than in monoculture plantations. Within these natural forests, nest counts increased with higher ACD and strangler fig density, but not with elevation. In logged forest (ACD 14â150 Mg haâ1), strangler fig density had a significant, positive relationship with orangutan nest counts, but this relationship disappeared in a forest with higher carbon content (ACD 150â209 Mg haâ1). Based on an area-to-area comparison, orangutan nest counts from ground transects were higher than from counts derived from aerial surveys, but this did not constitute a statistically significant difference. Although the difference in nest counts was not significantly different, this analysis indicates that both methods under-sample the total number of nests present within a given area. Aerial surveys are, therefore, a useful method for assessing the orangutan habitat use over large areas. However, the under-estimation of nest counts by both methods suggests that a small number of ground surveys should be retained in future surveys using this technique, particularly in areas with dense understory vegetation. This study shows that even highly degraded forests may be a suitable orangutan habitat as long as strangler fig trees remain intact after areas of forest are logged. Enrichment planting of strangler figs may, therefore, be a valuable tool for orangutan conservation in these landscapes.
KW  - aboveground carbon
KW  - aerial survey
KW  - drone
KW  - forest disturbance
KW  - ground-transect
KW  - land use
KW  - multiple-use landscape
KW  - strangler fig
DO  - 10.3390/rs13030458
TY  - EJOU
AU  - Astaoui, Ghizlane
AU  - Dadaiss, Jamal E.
AU  - Sebari, Imane
AU  - Benmansour, Samir
AU  - Mohamed, Ettarid
TI  - Mapping Wheat Dry Matter and Nitrogen Content Dynamics and Estimation of Wheat Yield Using UAV Multispectral Imagery Machine Learning and a Variety-Based Approach: Case Study of Morocco
T2  - AgriEngineering

PY  - 2021
VL  - 3
IS  - 1
SN  - 2624-7402

AB  - Our work aims to monitor wheat crop using a variety-based approach by taking into consideration four different phenological stages of wheat crop development. In addition to highlighting the contribution of Red-Edge vegetation indices in mapping wheat dry matter and nitrogen content dynamics, as well as using Random Forest regressor in the estimation of wheat yield, dry matter and nitrogen uptake relying on UAV (Unmanned Aerial Vehicle) multispectral imagery. The study was conducted on an experimental platform with 12 wheat varieties located in Sidi Slimane (Morocco). Several flight missions were conducted using eBee UAV with MultiSpec4C camera according to phenological growth stages of wheat. The proposed methodology is subdivided into two approaches, the first aims to find the most suitable vegetation index for wheatâs biophysical parameters estimation and the second to establish a global model regardless of the varieties to estimate the biophysical parameters of wheat: Dry matter and nitrogen uptake. The two approaches were conducted according to six main steps: (1) UAV flight missions and in-situ data acquisition during four phenological stages of wheat development, (2) Processing of UAV multispectral images which enabled us to elaborate the vegetation indices maps (RTVI, MTVI2, NDVI, NDRE, GNDVI, GNDRE, SR-RE et SR-NIR), (3) Automatic extraction of plots by Object-based image analysis approach and creating a spatial database combining the spectral information and wheatâs biophysical parameters, (4) Monitoring wheat growth by generating dry biomass and wheatâs nitrogen uptake model using exponential, polynomial and linear regression for each variety this step resumes the varietal approach, (5) Engendering a global model employing both linear regression and Random Forest technique, (6) Wheat yield estimation. The proposed method has allowed to predict from 1 up to 21% difference between actual and estimated yield when using both RTVI index and Random Forest technique as well as mapping wheatâs dry biomass and nitrogen uptake along with the nitrogen nutrition index (NNI) and therefore facilitate a careful monitoring of the health and the growth of wheat crop. Nevertheless, some wheat varieties have shown a significant difference in yield between 2.6 and 3.3 t/ha.
KW  - wheat yield
KW  - unmanned aerial vehicle (UAV)
KW  - multispectral imagery
KW  - RTVI
KW  - regression, random forest
KW  - NNI
KW  - red-edge
KW  - dry biomass
KW  - nitrogen nutrition
DO  - 10.3390/agriengineering3010003
TY  - EJOU
AU  - De Stefano, Rita
AU  - Repola, Leopoldo
AU  - Guerriero, Luigi
AU  - Iovane, Domenico
AU  - Morra, Vincenzo
AU  - Pagano, Fabio
AU  - Di Martire, Diego
TI  - Rockfall Threatening Cumae Archeological Site Fruition (Phlegraean Fields ParkâNaples)
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 3
SN  - 2071-1050

AB  - Natural hazards threaten many archaeological sites in the world; therefore, susceptibility analysis is essential to reduce their impacts and support site fruition by visitors. In this paper, rockfall susceptibility analysis of the western slope of the Cumae Mount in the Cumae Archaeological Site (Phlegraean Fields, Naples), already affected by rockfall events, is described as support to a management plan for fruition and site conservation. Being the first Greek settlement in southern Italy, the site has great historical importance and offers unique historical elements such as the Cumaean Sibyl&rsquo;s Cave. The analysis began with a 3D modeling of the slope through digital terrestrial photogrammetry, which forms a basis for a geomechanical analysis. Digital discontinuity measurements and cluster analysis provide data for kinematic analysis, which pointed out the planar, wedge and toppling failure potential. Subsequently, a propagation-based susceptibility analysis was completed into a GIS environment: it shows that most of the western sector of the site is susceptible to rockfall, including the access course, a segment of the Cumana Railroad and its local station. The work highlights the need for specific mitigation measures to increase visitor safety and the efficacy of filed-based digital reconstruction to support susceptibility analysis in rockfall prone areas.
KW  - rockfall
KW  - cultural heritage fruition
KW  - photogrammetry
KW  - kinematic analysis
KW  - geomechanical analysis
KW  - Phlegraean Fields
DO  - 10.3390/su13031390
TY  - EJOU
AU  - Casas, Roberto
AU  - Hermosa, Arturo
AU  - Marco, Ãlvaro
AU  - Blanco, Teresa
AU  - Zarazaga-Soria, Francisco J.
TI  - Real-Time Extensive Livestock Monitoring Using LPWAN Smart Wearable and Infrastructure
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 3
SN  - 2076-3417

AB  - Extensive unsupervised livestock farming is a habitual technique in many places around the globe. Animal release can be done for months, in large areas and with different species packing and behaving very differently. Nevertheless, the farmerâs needs are similar: where livestock is (and where has been) and how healthy they are. The geographical areas involved usually have difficult access with harsh orography and lack of communications infrastructure. This paper presents the design of a solution for extensive livestock monitoring in these areas. Our proposal is based in a wearable equipped with inertial sensors, global positioning system and wireless communications; and a Low-Power Wide Area Network infrastructure that can run with and without internet connection. Using adaptive analysis and data compression, we provide real-time monitoring and logging of cattleâs position and activities. Hardware and firmware design achieve very low energy consumption allowing months of battery life. We have thoroughly tested the devices in different laboratory setups and evaluated the system performance in real scenarios in the mountains and in the forest.
KW  - animal monitoring
KW  - low-power wide area networks
KW  - LoRaWAN
KW  - wearable devices design
DO  - 10.3390/app11031240
TY  - EJOU
AU  - Dâhont, Barbara
AU  - Calders, Kim
AU  - Bartholomeus, Harm
AU  - Whiteside, Tim
AU  - Bartolo, Renee
AU  - Levick, Shaun
AU  - Krishna Moorthy, Sruthi M.
AU  - Terryn, Louise
AU  - Verbeeck, Hans
TI  - Characterising Termite Mounds in a Tropical Savanna with UAV Laser Scanning
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 3
SN  - 2072-4292

AB  - Termite mounds are found over vast areas in northern Australia, delivering essential ecosystem services, such as enhancing nutrient cycling and promoting biodiversity. Currently, the detection of termite mounds over large areas requires airborne laser scanning (ALS) or high-resolution satellite data, which lack precise information on termite mound shape and size. For detailed structural measurements, we generally rely on time-consuming field assessments that can only cover a limited area. In this study, we explore if unmanned aerial vehicle (UAV)-based observations can serve as a precise and scalable tool for termite mound detection and morphological characterisation. We collected a unique data set of terrestrial laser scanning (TLS) and UAV laser scanning (UAV-LS) point clouds of a woodland savanna site in Litchfield National Park (Australia). We developed an algorithm that uses several empirical parameters for the semi-automated detection of termite mounds from UAV-LS and used the TLS data set (1 ha) for benchmarking. We detected 81% and 72% of the termite mounds in the high resolution (1800 points m&minus;2) and low resolution (680 points m&minus;2) UAV-LS data, respectively, resulting in an average detection of eight mounds per hectare. Additionally, we successfully extracted information about mound height and volume from the UAV-LS data. The high resolution data set resulted in more accurate estimates; however, there is a trade-off between area and detectability when choosing the required resolution for termite mound detection Our results indicate that UAV-LS data can be rapidly acquired and used to monitor and map termite mounds over relatively large areas with higher spatial detail compared to airborne and spaceborne remote sensing.
KW  - termite mounds
KW  - LiDAR
KW  - UAV
KW  - UAV-LS
KW  - remote sensing
DO  - 10.3390/rs13030476
TY  - EJOU
AU  - Maltezos, Evangelos
AU  - Douklias, Athanasios
AU  - Dadoukis, Aris
AU  - Misichroni, Fay
AU  - Karagiannidis, Lazaros
AU  - Antonopoulos, Markos
AU  - Voulgary, Katerina
AU  - Ouzounoglou, Eleftherios
AU  - Amditis, Angelos
TI  - The INUS Platform: A Modular Solution for Object Detection and Tracking from UAVs and Terrestrial Surveillance Assets
T2  - Computation

PY  - 2021
VL  - 9
IS  - 2
SN  - 2079-3197

AB  - Situational awareness is a critical aspect of the decision-making process in emergency response and civil protection and requires the availability of up-to-date information on the current situation. In this context, the related research should not only encompass developing innovative single solutions for (real-time) data collection, but also on the aspect of transforming data into information so that the latter can be considered as a basis for action and decision making. Unmanned systems (UxV) as data acquisition platforms and autonomous or semi-autonomous measurement instruments have become attractive for many applications in emergency operations. This paper proposes a multipurpose situational awareness platform by exploiting advanced on-board processing capabilities and efficient computer vision, image processing, and machine learning techniques. The main pillars of the proposed platform are: (1) a modular architecture that exploits unmanned aerial vehicle (UAV) and terrestrial assets; (2) deployment of on-board data capturing and processing; (3) provision of geolocalized object detection and tracking events; and (4) a user-friendly operational interface for standalone deployment and seamless integration with external systems. Experimental results are provided using RGB and thermal video datasets and applying novel object detection and tracking algorithms. The results show the utility and the potential of the proposed platform, and future directions for extension and optimization are presented.
KW  - UAV
KW  - UxV
KW  - terrestrial
KW  - situational awareness
KW  - computer vision
KW  - machine learning
KW  - object detection
KW  - object tracking
DO  - 10.3390/computation9020012
TY  - EJOU
AU  - Li, Xiaoting
AU  - Hu, Tengyun
AU  - Gong, Peng
AU  - Du, Shihong
AU  - Chen, Bin
AU  - Li, Xuecao
AU  - Dai, Qi
TI  - Mapping Essential Urban Land Use Categories in Beijing with a Fast Area of Interest (AOI)-Based Method
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 3
SN  - 2072-4292

AB  - Urban land use mapping is critical to understanding human activities in space. The first national mapping result of essential urban land use categories of China (EULUC-China) was released in 2019. However, the overall accuracies in some of the plain cities such as Beijing, Chengdu, and Zhengzhou were lower than 50% because many parcel-based mapping units are large with mixed land uses. To address this shortcoming, we proposed an area of interest (AOI)-based mapping approach, choosing Beijing as our study area. The mapping process includes two major steps. First, grids with different sizes (i.e., 300 m, 200 m, and 100 m) were derived from original land parcels to obtain classification units with a suitable size. Then, features within these grids were extracted from Sentinel-2 spectral data, point of interest (POI), and Tencent Easygo crowdedness data. These features were classified using a random forest (RF) classifier with AOI data, resulting in a 10-category map of EULUC. Second, we superimposed the AOIs layer on classified units to do some rectification and offer more details at the building scale. The overall accuracy of the AOI layer reached 98%, and the overall accuracy of the mapping results reached 77%. This study provides a fast method for accurate geographic sample collection, which substantially reduces the amount of fieldwork for sample collection and improves the classification accuracy compared to previous EULUC mapping. The detailed urban land use map could offer more support for urban planning and environmental policymaking.
KW  - area of interest
KW  - urban land use
KW  - sample collection
KW  - building scale
KW  - random forest
DO  - 10.3390/rs13030477
TY  - EJOU
AU  - CarramiÃ±ana, David
AU  - CampaÃ±a, IvÃ¡n
AU  - Bergesio, Luca
AU  - Bernardos, Ana M.
AU  - Besada, Juan A.
TI  - Sensors and Communication Simulation for Unmanned Traffic Management
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 3
SN  - 1424-8220

AB  - Unmanned traffic management (UTM) systems will become a key enabler to the future drone market ecosystem, enabling the safe concurrent operation of both manned and unmanned aircrafts. Currently, these systems are usually tested by performing real scenarios that are costly, limited, hardly scalable, and poorly repeatable. As a solution, in this paper we propose an agent-based simulation platform, implemented through a micro service architecture, which may simulate UTM information sources, such as flight plans, telemetry messages, or tracks from a surveillance network. The final objective of this simulator is to use these information streams to perform a system-level evaluation of UTM systems both in the pre-flight and in-flight stages. The proposed platform, with a focus on simulation of communications and sensors, allows to model UTM actors&rsquo; behaviors and their interactions. In addition, it also considers the manual definition of events to simulate unexpected behaviors/events (contingencies), such as communications failures or pilots&rsquo; actions. In order to validate our architecture, we implemented a simulator that considers the following actors: drones, pilots, ground control stations, surveillance networks, and communications networks. This platform enables the simulation of the drone trajectory and control, the C2 (command and control) link, drone detection by surveillance sensors, and the communication of all agents by means of a mobile communications network. Our results show that it is possible to truthfully recreate complex scenarios using this simulator, mitigating the disadvantages of real testbeds.
KW  - UAV
KW  - drone
KW  - UTM
KW  - U-Space
KW  - C2
KW  - surveillance networks
KW  - agent-based simulation
DO  - 10.3390/s21030927
TY  - EJOU
AU  - Yang, Wanting
AU  - Zhang, Xianfeng
AU  - Luo, Peng
TI  - Transferability of Convolutional Neural Network Models for Identifying Damaged Buildings Due to Earthquake
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 3
SN  - 2072-4292

AB  - The collapse of buildings caused by earthquakes can lead to a large loss of life and property. Rapid assessment of building damage with remote sensing image data can support emergency rescues. However, current studies indicate that only a limited sample set can usually be obtained from remote sensing images immediately following an earthquake. Consequently, the difficulty in preparing sufficient training samples constrains the generalization of the model in the identification of earthquake-damaged buildings. To produce a deep learning network model with strong generalization, this study adjusted four Convolutional Neural Network (CNN) models for extracting damaged building information and compared their performance. A sample dataset of damaged buildings was constructed by using multiple disaster images retrieved from the xBD dataset. Using satellite and aerial remote sensing data obtained after the 2008 Wenchuan earthquake, we examined the geographic and data transferability of the deep network model pre-trained on the xBD dataset. The result shows that the network model pre-trained with samples generated from multiple disaster remote sensing images can extract accurately collapsed building information from satellite remote sensing data. Among the adjusted CNN models tested in the study, the adjusted DenseNet121 was the most robust. Transfer learning solved the problem of poor adaptability of the network model to remote sensing images acquired by different platforms and could identify disaster-damaged buildings properly. These results provide a solution to the rapid extraction of earthquake-damaged building information based on a deep learning network model.
KW  - earthquake
KW  - disaster-damaged buildings
KW  - transfer learning
KW  - CNN
KW  - VHR images
DO  - 10.3390/rs13030504
TY  - EJOU
AU  - Sassu, Alberto
AU  - Gambella, Filippo
AU  - Ghiani, Luca
AU  - Mercenaro, Luca
AU  - Caria, Maria
AU  - Pazzona, Antonio L.
TI  - Advances in Unmanned Aerial System Remote Sensing for Precision Viticulture
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 3
SN  - 1424-8220

AB  - New technologies for management, monitoring, and control of spatio-temporal crop variability in precision viticulture scenarios are numerous. Remote sensing relies on sensors able to provide useful data for the improvement of management efficiency and the optimization of inputs. unmanned aerial systems (UASs) are the newest and most versatile tools, characterized by high precision and accuracy, flexibility, and low operating costs. The work aims at providing a complete overview of the application of UASs in precision viticulture, focusing on the different application purposes, the applied equipment, the potential of technologies combined with UASs for identifying vineyardsâ variability. The review discusses the potential of UASs in viticulture by distinguishing five areas of application: rows segmentation and crop features detection techniques; vineyard variability monitoring; estimation of row area and volume; disease detection; vigor and prescription maps creation. Technological innovation and low purchase costs make UASs the core tools for decision support in the customary use by winegrowers. The ability of the systems to respond to the current demands for the acquisition of digital technologies in agricultural fields makes UASs a candidate to play an increasingly important role in future scenarios of viticulture application.
KW  - UAS
KW  - vegetation index
KW  - 3D vineyard characterization
KW  - canopy height model
KW  - precision farming
KW  - precision viticulture
KW  - remote sensing
KW  - sustainability of resources
KW  - vineyard detection and segmentation
DO  - 10.3390/s21030956
TY  - EJOU
AU  - Rahman, Ehab U.
AU  - Zhang, Yihong
AU  - Ahmad, Sohail
AU  - Ahmad, Hafiz I.
AU  - Jobaer, Sayed
TI  - Autonomous Vision-Based Primary Distribution Systems Porcelain Insulators Inspection Using UAVs
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 3
SN  - 1424-8220

AB  - The early detection of damaged (partially broken) outdoor insulators in primary distribution systems is of paramount importance for continuous electricity supply and public safety. Unmanned aerial vehicles (UAVs) present a safer, autonomous, and efficient way to examine the power system components without closing the power distribution system. In this work, a novel dataset is designed by capturing real images using UAVs and manually generated images collected to overcome the data insufficiency problem. A deep Laplacian pyramid-based super-resolution network is implemented to reconstruct high-resolution training images. To improve the visibility of low-light images, a low-light image enhancement technique is used for the robust exposure correction of the training images. A different fine-tuning strategy is implemented for fine-tuning the object detection model to increase detection accuracy for the specific faulty insulators. Several flight path strategies are proposed to overcome the shuttering effect of insulators, along with providing a less complex and time- and energy-efficient approach for capturing a video stream of the power system components. The performance of different object detection models is presented for selecting the most suitable one for fine-tuning on the specific faulty insulator dataset. For the detection of damaged insulators, our proposed method achieved an F1-score of 0.81 and 0.77 on two different datasets and presents a simple and more efficient flight strategy. Our approach is based on real aerial inspection of in-service porcelain insulators by extensive evaluation of several video sequences showing robust fault recognition and diagnostic capabilities. Our approach is demonstrated on data acquired by a drone in Swat, Pakistan.
KW  - primary distribution systems
KW  - transfer learning
KW  - YoloV4
KW  - porcelain insulator detection
KW  - UAVs
KW  - BRISQUE
KW  - LIME
KW  - LapSRN
KW  - YoloV5
DO  - 10.3390/s21030974
TY  - EJOU
AU  - Oleksyn, Semonn
AU  - Tosetto, Louise
AU  - Raoult, Vincent
AU  - Joyce, Karen E.
AU  - Williamson, Jane E.
TI  - Going Batty: The Challenges and Opportunities of Using Drones to Monitor the Behaviour and Habitat Use of Rays
T2  - Drones

PY  - 2021
VL  - 5
IS  - 1
SN  - 2504-446X

AB  - The way an animal behaves in its habitat provides insight into its ecological role. As such, collecting robust, accurate datasets in a time-efficient manner is an ever-present pressure for the field of behavioural ecology. Faced with the shortcomings and physical limitations of traditional ground-based data collection techniques, particularly in marine studies, drones offer a low-cost and efficient approach for collecting data in a range of coastal environments. Despite drones being widely used to monitor a range of marine animals, they currently remain underutilised in ray research. The innovative application of drones in environmental and ecological studies has presented novel opportunities in animal observation and habitat assessment, although this emerging field faces substantial challenges. As we consider the possibility to monitor rays using drones, we face challenges related to local aviation regulations, the weather and environment, as well as sensor and platform limitations. Promising solutions continue to be developed, however, growing the potential for drone-based monitoring of behaviour and habitat use of rays. While the barriers to enter this field may appear daunting for researchers with little experience with drones, the technology is becoming increasingly accessible, helping ray researchers obtain a wide range of highly useful data.
KW  - UAV
KW  - UAS
KW  - RPA
KW  - benthic habitat mapping
KW  - ray ecology
KW  - coastal environments
KW  - batoidea
DO  - 10.3390/drones5010012
TY  - EJOU
AU  - Papaioannou, Panagiotis
AU  - Papadopoulos, Efthymis
AU  - Nikolaidou, Anastasia
AU  - Politis, Ioannis
AU  - Basbas, Socrates
AU  - Kountouri, Eleni
TI  - Dilemma Zone: Modeling Driversâ Decision at Signalized Intersections against Aggressiveness and Other Factors Using UAV Technology
T2  - Safety

PY  - 2021
VL  - 7
IS  - 1
SN  - 2313-576X

AB  - Intersection safety and driversâ behavior are strongly interrelated, especially when the latter are located in dilemma zone. This paper explores, among others, the main factors affecting driver behavior, such as distance to stop line, approaching speed and acceleration/deceleration, and two additional factors, namely, driverâs aggressiveness and driverâs relative position at the onset of the yellow signal. Field data were collected using unmanned aerial vehicle (UAV) technology. Two binary choice models were developed, the first relying on observed data and the latter enriched by the latent factor driversâ aggressiveness and the vehiclesâ relative position. Drivers were classified to aggressive and non-aggressive ones using a latent class model that combined approaching speed and acceleration/deceleration data. Drivers were further grouped according to their expected reaction/decision to stop or cross the intersection in relation to their relative position. Both models equally explain driversâ decisions adequately, but the second one offers additional explanatory power attributed to aggressiveness. Being able to identify the level of aggressiveness among the drivers enables the calculation of the probability that drivers will cross the intersection even if caught in a dilemma zone or in a zone in which the obvious decision is to stop. Such findings can be valuable when designing a signalized intersection and the traffic time settings, as well as the posted speed limit.
KW  - UAV video-observed vehicle trajectory data
KW  - driver behavior
KW  - signalized intersection
KW  - dilemma zone
KW  - choice model
KW  - latent class model
KW  - acceleration/deceleration
KW  - driversâ aggressiveness
DO  - 10.3390/safety7010011
TY  - EJOU
AU  - Marques, LuÃ­s
AU  - Vale, Alberto
AU  - Vaz, Pedro
TI  - State-of-the-Art Mobile Radiation Detection Systems for Different Scenarios
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 4
SN  - 1424-8220

AB  - In the last decade, the development of more compact and lightweight radiation detection systems led to their application in handheld and small unmanned systems, particularly air-based platforms. Examples of improvements are: the use of silicon photomultiplier-based scintillators, new scintillating crystals, compact dual-mode detectors (gamma/neutron), data fusion, mobile sensor networks, cooperative detection and search. Gamma cameras and dual-particle cameras are increasingly being used for source location. This study reviews and discusses the research advancements in the field of gamma-ray and neutron measurements using mobile radiation detection systems since the Fukushima nuclear accident. Four scenarios are considered: radiological and nuclear accidents and emergencies; illicit traffic of special nuclear materials and radioactive materials; nuclear, accelerator, targets, and irradiation facilities; and naturally occurring radioactive materials monitoring-related activities. The work presented in this paper aims to: compile and review information on the radiation detection systems, contextual sensors and platforms used for each scenario; assess their advantages and limitations, looking prospectively to new research and challenges in the field; and support the decision making of national radioprotection agencies and response teams in respect to adequate detection system for each scenario. For that, an extensive literature review was conducted.
KW  - mobile radiation detection systems
KW  - NORM
KW  - radiological emergencies
KW  - nuclear accidents
KW  - illicit trafficking
KW  - accelerators
KW  - targets and irradiation facilities
KW  - gamma and neutron detectors
DO  - 10.3390/s21041051
TY  - EJOU
AU  - Kamarudin, Mohd H.
AU  - Ismail, Zool H.
AU  - Saidi, Noor B.
TI  - Deep Learning Sensor Fusion in Plant Water Stress Assessment: A Comprehensive Review
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 4
SN  - 2076-3417

AB  - Water stress is one of the major challenges to food security, causing a significant economic loss for the nation as well for growers. Accurate assessment of water stress will enhance agricultural productivity through optimization of plant water usage, maximizing plant breeding strategies, and preventing forest wildfire for better ecosystem management. Recent advancements in sensor technologies have enabled high-throughput, non-contact, and cost-efficient plant water stress assessment through intelligence system modeling. The advanced deep learning sensor fusion technique has been reported to improve the performance of the machine learning application for processing the collected sensory data. This paper extensively reviews the state-of-the-art methods for plant water stress assessment that utilized the deep learning sensor fusion approach in their application, together with future prospects and challenges of the application domain. Notably, 37 deep learning solutions fell under six main areas, namely soil moisture estimation, soil water modelling, evapotranspiration estimation, evapotranspiration forecasting, plant water status estimation and plant water stress identification. Basically, there are eight deep learning solutions compiled for the 3D-dimensional data and plant varieties challenge, including unbalanced data that occurred due to isohydric plants, and the effect of variations that occur within the same species but cultivated from different locations.
KW  - artificial intelligence
KW  - agriculture monitoring system
KW  - modelling
KW  - plant-based water stress
KW  - smart sensor
DO  - 10.3390/app11041403
TY  - EJOU
AU  - Melo, Aurelio G.
AU  - Pinto, Milena F.
AU  - Marcato, Andre L. M.
AU  - HonÃ³rio, Leonardo M.
AU  - Coelho, FabrÃ­cio O.
TI  - Dynamic Optimization and Heuristics Based Online Coverage Path Planning in 3D Environment for UAVs
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 4
SN  - 1424-8220

AB  - Path planning is one of the most important issues in the robotics field, being applied in many domains ranging from aerospace technology and military tasks to manufacturing and agriculture. Path planning is a branch of autonomous navigation. In autonomous navigation, dynamic decisions about the path have to be taken while the robot moves towards its goal. Among the navigation area, an important class of problems is Coverage Path Planning (CPP). The CPP technique is associated with determining a collision-free path that passes through all viewpoints in a specific area. This paper presents a method to perform CPP in 3D environment for Unmanned Aerial Vehicles (UAVs) applications, namely 3D dynamic for CPP applications (3DD-CPP). The proposed method can be deployed in an unknown environment through a combination of linear optimization and heuristics. A model to estimate cost matrices accounting for UAV power usage is proposed and evaluated for a few different flight speeds. As linear optimization methods can be computationally demanding to be used on-board a UAV, this work also proposes a distributed execution of the algorithm through fog-edge computing. Results showed that 3DD-CPP had a good performance in both local execution and fog-edge for different simulated scenarios. The proposed heuristic is capable of re-optimization, enabling execution in environments with local knowledge of the environments.
KW  - coverage path planning
KW  - 3D path planning
KW  - waypoint graph
KW  - mapping
KW  - navigation
KW  - UAVs
DO  - 10.3390/s21041108
TY  - EJOU
AU  - Bolch, Erik A.
AU  - Hestir, Erin L.
AU  - Khanna, Shruti
TI  - Performance and Feasibility of Drone-Mounted Imaging Spectroscopy for Invasive Aquatic Vegetation Detection
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 4
SN  - 2072-4292

AB  - Invasive plants are non-native species that can spread rapidly, leading to detrimental economic, ecological, or environmental impact. In aquatic systems such as the Sacramento-San Joaquin River Delta in California, USA, management agencies use manned aerial vehicles (MAV) imaging spectroscopy missions to map and track annual changes in invasive aquatic plants. Advances in unmanned aerial vehicles (UAV) and sensor miniaturization are enabling higher spatial resolution species mapping, which is promising for early detection of invasions before they spread over larger areas. This study compared maps made from UAV-based imaging spectroscopy with the manned airborne imaging spectroscopy-derived maps that are currently produced for monitoring invasive aquatic plants in the Sacramento-San Joaquin Delta. Concurrent imagery was collected using the MAV mounted HyMap sensor and the UAV mounted Nano-Hyperspec at a wetland study site and classification maps generated using random forest models were compared. Classification accuracies were comparable between the Nano- and HyMap-derived maps, with the Nano-derived map having a slightly higher overall accuracy. Additionally, the higher resolution of the Nano imagery allowed detection of patches of water hyacinth present in the study site that the HyMap could not. However, it would not be feasible to operate the Nano as a replacement to HyMap at scale despite its improved detection capabilities due to the high costs associated with overcoming area coverage limitations. Overall, UAV-based imaging spectroscopy provides comparable or improved capability, and we suggest it could be used to supplement existing monitoring programs by focusing on target areas of high ecologic or economic priority.
KW  - imaging spectroscopy
KW  - invasive species
KW  - hyperspectral remote sensing
KW  - unmanned aircraft
KW  - UAV
KW  - aquatic vegetation
DO  - 10.3390/rs13040582
TY  - EJOU
AU  - Jiang, Xueqin
AU  - Fang, Shenghui
AU  - Huang, Xia
AU  - Liu, Yanghua
AU  - Guo, Linlin
TI  - Rice Mapping and Growth Monitoring Based on Time Series GF-6 Images and Red-Edge Bands
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 4
SN  - 2072-4292

AB  - Accurate rice mapping and growth monitoring are of great significance for ensuring food security and agricultural sustainable development. Remote sensing (RS), as an efficient observation technology, is expected to be useful for rice mapping and growth monitoring. Due to the fragmented distribution of paddy fields and the undulating terrain in Southern China, it is very difficult in rice mapping. Moreover, there are many crops with the same growth period as rice, resulting in low accuracy of rice mapping. We proposed a red-edge decision tree (REDT) method based on the combination of time series GF-6 images and red-edge bands to solve this problem. The red-edge integral and red-edge vegetation index integral were computed by using two red-edge bands derived from GF-6 images to construct the REDT. Meanwhile, the conventional method based on time series normalized difference vegetation index (NDVI), normalized difference water index (NDWI), enhanced vegetation index (EVI) (NNE) was employed to compare the effectiveness of rice mapping. The results indicated that the overall accuracy and Kappa coefficient of REDT ranged from 91%â94% and 0.82â0.87, improving about 7% and 0.15 compared with the NNE method. This proved that the proposed technology was able to efficiently solve the problem of rice mapping on a large scale and regions with fragmented landscapes. Additionally, two red-edge bands of GF-6 images were applied to monitor rice growth. It concluded that the two red-edge bands played different roles in rice growth monitoring. The red-edge bands of GF-6 images were superior in rice mapping and growth monitoring. Further study needs to develop more vegetation indices (VIs) related to the red-edge to make the best use of red-edge characteristics in precision agriculture.
KW  - rice mapping
KW  - red-edge
KW  - growth monitoring
KW  - GF-6
KW  - time series
DO  - 10.3390/rs13040579
TY  - EJOU
AU  - PraticÃ², Salvatore
AU  - Solano, Francesco
AU  - Di Fazio, Salvatore
AU  - Modica, Giuseppe
TI  - Machine Learning Classification of Mediterranean Forest Habitats in Google Earth Engine Based on Seasonal Sentinel-2 Time-Series and Input Image Composition Optimisation
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 4
SN  - 2072-4292

AB  - The sustainable management of natural heritage is presently considered a global strategic issue. Owing to the ever-growing availability of free data and software, remote sensing (RS) techniques have been primarily used to map, analyse, and monitor natural resources for conservation purposes. The need to adopt multi-scale and multi-temporal approaches to detect different phenological aspects of different vegetation types and species has also emerged. The time-series composite image approach allows for capturing much of the spectral variability, but presents some criticalities (e.g., time-consuming research, downloading data, and the required storage space). To overcome these issues, the Google Earth engine (GEE) has been proposed, a free cloud-based computational platform that allows users to access and process remotely sensed data at petabyte scales. The application was tested in a natural protected area in Calabria (South Italy), which is particularly representative of the Mediterranean mountain forest environment. In the research, random forest (RF), support vector machine (SVM), and classification and regression tree (CART) algorithms were used to perform supervised pixel-based classification based on the use of Sentinel-2 images. A process to select the best input image (seasonal composition strategies, statistical operators, band composition, and derived vegetation indices (VIs) information) for classification was implemented. A set of accuracy indicators, including overall accuracy (OA) and multi-class F-score (Fm), were computed to assess the results of the different classifications. GEE proved to be a reliable and powerful tool for the classification process. The best results (OA = 0.88 and Fm = 0.88) were achieved using RF with the summer image composite, adding three VIs (NDVI, EVI, and NBR) to the Sentinel-2 bands. SVM and RF produced OAs of 0.83 and 0.80, respectively.
KW  - random forest (RF)
KW  - support vector machine (SVM)
KW  - classification and regression tree (CART)
KW  - cloud platform
KW  - vegetation indices (VIs)
KW  - Natura 2000
KW  - Aspromonte National Park
DO  - 10.3390/rs13040586
TY  - EJOU
AU  - Wasonga, Daniel O.
AU  - Yaw, Afrane
AU  - Kleemola, Jouko
AU  - Alakukku, Laura
AU  - MÃ¤kelÃ¤, Pirjo S.A.
TI  - Red-Green-Blue and Multispectral Imaging as Potential Tools for Estimating Growth and Nutritional Performance of Cassava under Deficit Irrigation and Potassium Fertigation
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 4
SN  - 2072-4292

AB  - Cassava has high energy value and rich nutritional content, yet its productivity in the tropics is seriously constrained by abiotic stresses such as water deficit and low potassium (K) nutrition. Systems that allow evaluation of genotypes in the field and greenhouse for nondestructive estimation of plant performance would be useful means for monitoring the health of plants for crop-management decisions. We investigated whether the redâgreenâblue (RGB) and multispectral images could be used to detect the previsual effects of water deficit and low K in cassava, and whether the crop quality changes due to low moisture and low K could be observed from the images. Pot experiments were conducted with cassava cuttings. The experimental design was a split-plot arranged in a completely randomized design. Treatments were three irrigation doses split into various K rates. Plant images were captured beginning 30 days after planting (DAP) and ended at 90 DAP when plants were harvested. Results show that biomass, chlorophyll, and net photosynthesis were estimated with the highest accuracy (R2 = 0.90), followed by leaf area (R2 = 0.76). Starch, energy, carotenoid, and cyanide were also estimated satisfactorily (R2 &gt; 0.80), although cyanide showed negative regression coefficients. All mineral elements showed lower estimation accuracy (R2 = 0.14â0.48) and exhibited weak associations with the spectral indices. Use of the normalized difference vegetation index (NDVI), green area (GA), and simple ratio (SR) indices allowed better estimation of growth and key nutritional traits. Irrigation dose 30% of pot capacity enriched with 0.01 mM K reduced most index values but increased the crop senescence index (CSI). Increasing K to 16 mM over the irrigation doses resulted in high index values, but low CSI. The findings indicate that RGB and multispectral imaging can provide indirect measurements of growth and key nutritional traits in cassava. Hence, they can be used as a tool in various breeding programs to facilitate cultivar evaluation and support management decisions to avert stress, such as the decision to irrigate or apply fertilizers.
KW  - early growth
KW  - Manihot esculenta
KW  - nondestructive
KW  - regression models
KW  - spectral indices
DO  - 10.3390/rs13040598
TY  - EJOU
AU  - Islam, Nahina
AU  - Rashid, Md M.
AU  - Pasandideh, Faezeh
AU  - Ray, Biplob
AU  - Moore, Steven
AU  - Kadel, Rajan
TI  - A Review of Applications and Communication Technologies for Internet of Things (IoT) and Unmanned Aerial Vehicle (UAV) Based Sustainable Smart Farming
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 4
SN  - 2071-1050

AB  - To reach the goal of sustainable agriculture, smart farming is taking advantage of the Unmanned Aerial Vehicles (UAVs) and Internet of Things (IoT) paradigm. These smart farms are designed to be run by interconnected devices and vehicles. Some enormous potentials can be achieved by the integration of different IoT technologies to achieve automated operations with minimum supervision. This paper outlines some major applications of IoT and UAV in smart farming, explores the communication technologies, network functionalities and connectivity requirements for Smart farming. The connectivity limitations of smart agriculture and itâs solutions are analysed with two case studies. In case study-1, we propose and evaluate meshed Long Range Wide Area Network (LoRaWAN) gateways to address connectivity limitations of Smart Farming. While in case study-2, we explore satellite communication systems to provide connectivity to smart farms in remote areas of Australia. Finally, we conclude the paper by identifying future research challenges on this topic and outlining directions to address those challenges.
KW  - agriculture
KW  - Internet of Things (IoT)
KW  - smart farming
KW  - sustainable future
KW  - sustainable smart farming
KW  - Unmanned Aerial Vehicles (UAVs)
DO  - 10.3390/su13041821
TY  - EJOU
AU  - Vangi, Elia
AU  - DâAmico, Giovanni
AU  - Francini, Saverio
AU  - Giannetti, Francesca
AU  - Lasserre, Bruno
AU  - Marchetti, Marco
AU  - Chirici, Gherardo
TI  - The New Hyperspectral Satellite PRISMA: Imagery for Forest Types Discrimination
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 4
SN  - 1424-8220

AB  - Different forest types based on different tree species composition may have similar spectral signatures if observed with traditional multispectral satellite sensors. Hyperspectral imagery, with a more continuous representation of their spectral behavior may instead be used for their classification. The new hyperspectral Precursore IperSpettrale della Missione Applicativa (PRISMA) sensor, developed by the Italian Space Agency, is able to capture images in a continuum of 240 spectral bands ranging between 400 and 2500 nm, with a spectral resolution smaller than 12 nm. The new sensor can be employed for a large number of remote sensing applications, including forest types discrimination. In this study, we compared the capabilities of the new PRISMA sensor against the well-known Sentinel-2 Multi-Spectral Instrument (MSI) in recognition of different forest types through a pairwise separability analysis carried out in two study areas in Italy, using two different nomenclature systems and four separability metrics. The PRISMA hyperspectral sensor, compared to Sentinel-2 MSI, allowed for a better discrimination in all forest types, increasing the performance when the complexity of the nomenclature system also increased. PRISMA achieved an average improvement of 40% for the discrimination between two forest categories (coniferous vs. broadleaves) and of 102% in the discrimination between five forest types based on main tree species groups.
KW  - PRISMA
KW  - hyperspectral sensor
KW  - hyperspectral imagery
KW  - forest types discrimination
KW  - separability analysis
DO  - 10.3390/s21041182
TY  - EJOU
AU  - Neumann, Carsten
AU  - Schindhelm, Anne
AU  - MÃ¼ller, JÃ¶rg
AU  - Weiss, Gabriele
AU  - Liu, Anna
AU  - Itzerott, Sibylle
TI  - The Regenerative Potential of Managed Calluna HeathlandsâRevealing Optical and Structural Traits for Predicting Recovery Dynamics
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 4
SN  - 2072-4292

AB  - The potential of vegetation recovery through resprouting of plant tissue from buds after the removal of aboveground biomass is a key resilience strategy for populations under abrupt environmental change. Resprouting leads to fast regeneration, particularly after the implementation of mechanical mowing as part of active management for promoting open habitats. We investigated whether recovery dynamics of resprouting and the threat of habitat conversion can be predicted by optical and structural stand traits derived from drone imagery in a protected heathland area. We conducted multivariate regression for variable selection and random forest regression for predictive modeling using 50 spectral predictors, textural features and height parameters to quantify Calluna resprouting and grass invasion in before-mowing images that were related to vegetation recovery in after-mowing imagery. The study reveals that Calluna resprouting can be explained by significant optical predictors of mainly green reflectance in parental individuals. In contrast, grass encroachment is identified by structural canopy properties that indicate before-mowing grass interpenetration as starting points for after-mowing dispersal. We prove the concept of trait propagation through time providing significant derivates for a low-cost drone system. It can be utilized to build drone-based decision support systems for evaluating consequences and requirements of habitat management practice.
KW  - resprouting
KW  - habitat management
KW  - heathland
KW  - trait mapping
KW  - UAV
DO  - 10.3390/rs13040625
TY  - EJOU
AU  - Zhang, Xiuwei
AU  - Zhou, Yang
AU  - Jin, Jiaojiao
AU  - Wang, Yafei
AU  - Fan, Minhao
AU  - Wang, Ning
AU  - Zhang, Yanning
TI  - ICENETv2: A Fine-Grained River Ice Semantic Segmentation Network Based on UAV Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 4
SN  - 2072-4292

AB  - Accurate ice segmentation is one of the most crucial techniques for intelligent ice monitoring. Compared with ice segmentation, it can provide more information for ice situation analysis, change trend prediction, and so on. Therefore, the study of ice segmentation has important practical significance. In this study, we focused on fine-grained river ice segmentation using unmanned aerial vehicle (UAV) images. This has the following difficulties: (1) The scale of river ice varies greatly in different images and even in the same image; (2) the same kind of river ice differs greatly in color, shape, texture, size, and so on; and (3) the appearances of different kinds of river ice sometimes appear similar due to the complex formation and change procedure. Therefore, to perform this study, the NWPU_YRCC2 dataset was built, in which all UAV images were collected in the NingxiaâInner Mongolia reach of the Yellow River. Then, a novel semantic segmentation method based on deep convolution neural network, named ICENETv2, is proposed. To achieve multiscale accurate prediction, we design a multilevel features fusion framework, in which multi-scale high-level semantic features and lower-level finer features are effectively fused. Additionally, a dual attention module is adopted to highlight distinguishable characteristics, and a learnable up-sampling strategy is further used to improve the segmentation accuracy of the details. Experiments show that ICENETv2 achieves the state-of-the-art on the NWPU_YRCC2 dataset. Finally, our ICENETv2 is also applied to solve a realistic problem, calculating drift ice cover density, which is one of the most important factors to predict the freeze-up data of the river. The results demonstrate that the performance of ICENETv2 meets the actual application demand.
KW  - fine-grained river ice
KW  - position attention
KW  - channel attention
KW  - drift ice cover density
KW  - semantic segmentation
DO  - 10.3390/rs13040633
TY  - EJOU
AU  - KopaÄkovÃ¡-StrnadovÃ¡, Veronika
AU  - KouckÃ¡, Lucie
AU  - JelÃ©nek, Jan
AU  - LhotÃ¡kovÃ¡, Zuzana
AU  - Oulehle, Filip
TI  - Canopy Top, Height and Photosynthetic Pigment Estimation Using Parrot Sequoia Multispectral Imagery and the Unmanned Aerial Vehicle (UAV)
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 4
SN  - 2072-4292

AB  - Remote sensing is one of the modern methods that have significantly developed over the last two decades and, nowadays, it provides a new means for forest monitoring. High spatial and temporal resolutions are demanded for the accurate and timely monitoring of forests. In this study, multi-spectral Unmanned Aerial Vehicle (UAV) images were used to estimate canopy parameters (definition of crown extent, top, and height, as well as photosynthetic pigment contents). The UAV images in Green, Red, Red-Edge, and Near infrared (NIR) bands were acquired by Parrot Sequoia camera over selected sites in two small catchments (Czech Republic) covered dominantly by Norway spruce monocultures. Individual tree extents, together with tree tops and heights, were derived from the Canopy Height Model (CHM). In addition, the following were tested: (i) to what extent can the linear relationship be established between selected vegetation indexes (Normalized Difference Vegetation Index (NDVI) and NDVIred edge) derived for individual trees and the corresponding ground truth (e.g., biochemically assessed needle photosynthetic pigment contents) and (ii) whether needle age selection as a ground truth and crown light conditions affect the validity of linear models. The results of the conducted statistical analysis show that the two vegetation indexes (NDVI and NDVIred edge) tested here have the potential to assess photosynthetic pigments in Norway spruce forests at a semi-quantitative level; however, the needle-age selection as a ground truth was revealed to be a very important factor. The only usable results were obtained for linear models when using the second year needle pigment contents as a ground truth. On the other hand, the illumination conditions of the crown proved to have very little effect on the modelâs validity. No study was found to directly compare these results conducted on coniferous forest stands. This shows that there is a further need for studies dealing with a quantitative estimation of the biochemical variables of nature coniferous forests when employing spectral data that were acquired by the UAV platform at a very high spatial resolution.
KW  - UAV
KW  - Parrot Sequoia multispectral camera
KW  - photosynthetic pigments
KW  - Norway spruce
KW  - forest
KW  - linear models
KW  - ground truth
KW  - needle age
KW  - crown detection
DO  - 10.3390/rs13040705
TY  - EJOU
AU  - Liu, Feng
AU  - Dai, Shuling
AU  - Zhao, Yongjia
TI  - Learning to Have a Civil Aircraft Take Off under Crosswind Conditions by Reinforcement Learning with Multimodal Data and Preprocessing Data
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 4
SN  - 1424-8220

AB  - Autopilot technology in the field of aviation has developed over many years. However, it is difficult for an autopilot system to autonomously operate a civil aircraft under bad weather conditions. In this paper, we present a reinforcement learning (RL) algorithm using multimodal data and preprocessing data to have a civil aircraft take off autonomously under crosswind conditions. The multimodal data include the common flight status and visual information. The preprocessing is a new design that maps some flight data by nonlinear functions based on the general flight dynamics before these data are fed into the RL model. Extensive experiments under different crosswind conditions with a professional flight simulator demonstrate that the proposed method can effectively control a civil aircraft to take off under various crosswind conditions and achieve better performance than trials without visual information or preprocessing data.
KW  - autopilot
KW  - civil aircraft
KW  - multimodal data
KW  - reinforcement learning
KW  - preprocessing
DO  - 10.3390/s21041386
TY  - EJOU
AU  - Gao, Bowen
AU  - Chen, Ninghua
AU  - Blaschke, Thomas
AU  - Wu, Chase Q.
AU  - Chen, Jianyu
AU  - Xu, Yaochen
AU  - Yang, Xiaoping
AU  - Du, Zhenhong
TI  - Automated Characterization of Yardangs Using Deep Convolutional Neural Networks
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 4
SN  - 2072-4292

AB  - The morphological characteristics of yardangs are the direct evidence that reveals the wind and fluvial erosion for lacustrine sediments in arid areas. These features can be critical indicators in reconstructing local wind directions and environment conditions. Thus, the fast and accurate extraction of yardangs is key to studying their regional distribution and evolution process. However, the existing automated methods to characterize yardangs are of limited generalization that may only be feasible for specific types of yardangs in certain areas. Deep learning methods, which are superior in representation learning, provide potential solutions for mapping yardangs with complex and variable features. In this study, we apply Mask region-based convolutional neural networks (Mask R-CNN) to automatically delineate and classify yardangs using very high spatial resolution images from Google Earth. The yardang field in the Qaidam Basin, northwestern China is selected to conduct the experiments and the method yields mean average precisions of 0.869 and 0.671 for intersection of union (IoU) thresholds of 0.5 and 0.75, respectively. The manual validation results on images of additional study sites show an overall detection accuracy of 74%, while more than 90% of the detected yardangs can be correctly classified and delineated. We then conclude that Mask R-CNN is a robust model to characterize multi-scale yardangs of various types and allows for the research of the morphological and evolutionary aspects of aeolian landform.
KW  - aeolian landform
KW  - yardang
KW  - morphological characteristic
KW  - deep learning
KW  - Mask R-CNN
KW  - Google Earth imagery
DO  - 10.3390/rs13040733
TY  - EJOU
AU  - Blekos, Kostas
AU  - Tsakas, Anastasios
AU  - Xouris, Christos
AU  - Evdokidis, Ioannis
AU  - Alexandropoulos, Dimitris
AU  - Alexakos, Christos
AU  - Katakis, Sofoklis
AU  - Makedonas, Andreas
AU  - Theoharatos, Christos
AU  - Lalos, Aris
TI  - Analysis, Modeling and Multi-Spectral Sensing for the Predictive Management of Verticillium Wilt in Olive Groves
T2  - Journal of Sensor and Actuator Networks

PY  - 2021
VL  - 10
IS  - 1
SN  - 2224-2708

AB  - The intensification and expansion in the cultivation of olives have contributed to the significant spread of Verticillium wilt, which is the most important fungal problem affecting olive trees. Recent studies confirm that practices such as the use of innovative natural minerals (Zeoshell ZF1) and the application of beneficial microorganisms (Micosat F BS WP) restore health in infected trees. However, for their efficient implementation the above methodologies require the marking of trees in the early stages of infestationâa task that is impractical with traditional means (manual labor) but also very difficult, as early stages are difficult to perceive with the naked eye. In this paper, we present the results of the My Olive Grove Coach (MyOGC) project, which used multispectral imaging from unmanned aerial vehicles to develop an olive grove monitoring system based on the autonomous and automatic processing of the multispectral images using computer vision and machine learning techniques. The goal of the system is to monitor and assess the health of olive groves, help in the prediction of Verticillium wilt spread and implement a decision support system that guides the farmer/agronomist.
KW  - precision agriculture
KW  - intelligent management
KW  - multi-spectral sensing
KW  - multi-spectral co-registration
KW  - multi-spectral fusion of multispectral spectroscopy data
DO  - 10.3390/jsan10010015
TY  - EJOU
AU  - Liao, Kuo-Chien
AU  - Lu, Jau-Huai
TI  - Using UAV to Detect Solar Module Fault Conditions of a Solar Power Farm with IR and Visual Image Analysis
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 4
SN  - 2076-3417

AB  - In recent years, solar energy has been regarded as one of the most important sustainable energy sources. Under the rapid and large-scale construction of solar farms, the maintenance and inspection of the health conditions of solar modules in a large solar farm become an important issue. This article proposes a method for detecting solar cell faults with unmanned aerial vehicle (UAV) equipped with a thermal imager and a visible light camera, and providing a fast and reliable detection method. The detection process includes a new concept of real-time monitoring of the detected area and analysis of the health of solar panels. An image process is proposed that may quickly and accurately detect the abnormality of a solar module. The whole process includes grayscale conversion, filtering, 3-D temperature representation, probability density function, and cumulative density function analysis. Ten cases in real fields have been studied with this process, including large scale solar farms and small size solar modules installed on buildings. Results show that the cumulative density function is a convenient way to determine the health status of the solar panel and may provide maintenance personnel a basis for determining whether replacement of solar cells is necessary for improving the overall power generation efficiency and simplify the maintenance process. It is worth noting that image recognition can increase the clarity of IR images and the cumulative chart can judge the defect rate of the cell. These two methods were combined to provide an instant, fast and accurate defect judgment.
KW  - UAV
KW  - solar farms
KW  - IR images
KW  - probability density function
KW  - cumulative distribution function
DO  - 10.3390/app11041835
TY  - EJOU
AU  - Li, Guoming
AU  - Huang, Yanbo
AU  - Chen, Zhiqian
AU  - Chesser, Gary D.
AU  - Purswell, Joseph L.
AU  - Linhoss, John
AU  - Zhao, Yang
TI  - Practices and Applications of Convolutional Neural Network-Based Computer Vision Systems in Animal Farming: A Review
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 4
SN  - 1424-8220

AB  - Convolutional neural network (CNN)-based computer vision systems have been increasingly applied in animal farming to improve animal management, but current knowledge, practices, limitations, and solutions of the applications remain to be expanded and explored. The objective of this study is to systematically review applications of CNN-based computer vision systems on animal farming in terms of the five deep learning computer vision tasks: image classification, object detection, semantic/instance segmentation, pose estimation, and tracking. Cattle, sheep/goats, pigs, and poultry were the major farm animal species of concern. In this research, preparations for system development, including camera settings, inclusion of variations for data recordings, choices of graphics processing units, image preprocessing, and data labeling were summarized. CNN architectures were reviewed based on the computer vision tasks in animal farming. Strategies of algorithm development included distribution of development data, data augmentation, hyperparameter tuning, and selection of evaluation metrics. Judgment of model performance and performance based on architectures were discussed. Besides practices in optimizing CNN-based computer vision systems, system applications were also organized based on year, country, animal species, and purposes. Finally, recommendations on future research were provided to develop and improve CNN-based computer vision systems for improved welfare, environment, engineering, genetics, and management of farm animals.
KW  - deep learning
KW  - convolutional neural network
KW  - computer vision system
KW  - animal farming
DO  - 10.3390/s21041492
TY  - EJOU
AU  - Neupane, Bipul
AU  - Horanont, Teerayut
AU  - Aryal, Jagannath
TI  - Deep Learning-Based Semantic Segmentation of Urban Features in Satellite Images: A Review and Meta-Analysis
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 4
SN  - 2072-4292

AB  - Availability of very high-resolution remote sensing images and advancement of deep learning methods have shifted the paradigm of image classification from pixel-based and object-based methods to deep learning-based semantic segmentation. This shift demands a structured analysis and revision of the current status on the research domain of deep learning-based semantic segmentation. The focus of this paper is on urban remote sensing images. We review and perform a meta-analysis to juxtapose recent papers in terms of research problems, data source, data preparation methods including pre-processing and augmentation techniques, training details on architectures, backbones, frameworks, optimizers, loss functions and other hyper-parameters and performance comparison. Our detailed review and meta-analysis show that deep learning not only outperforms traditional methods in terms of accuracy, but also addresses several challenges previously faced. Further, we provide future directions of research in this domain.
KW  - deep learning
KW  - remote sensing
KW  - review
KW  - semantic segmentation
KW  - urban image classification
DO  - 10.3390/rs13040808
TY  - EJOU
AU  - Qi, Haixia
AU  - Liang, Yu
AU  - Ding, Quanchen
AU  - Zou, Jun
TI  - Automatic Identification of Peanut-Leaf Diseases Based on Stack Ensemble
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 4
SN  - 2076-3417

AB  - Peanut is an important food crop, and diseases of its leaves can directly reduce its yield and quality. In order to solve the problem of automatic identification of peanut-leaf diseases, this paper uses a traditional machine-learning method to ensemble the output of a deep learning model to identify diseases of peanut leaves. The identification of peanut-leaf diseases included healthy leaves, rust disease on a single leaf, leaf-spot disease on a single leaf, scorch disease on a single leaf, and both rust disease and scorch disease on a single leaf. Three types of data-augmentation methods were used: image flipping, rotation, and scaling. In this experiment, the deep-learning model had a higher accuracy than the traditional machine-learning methods. Moreover, the deep-learning model achieved better performance when using data augmentation and a stacking ensemble. After ensemble by logistic regression, the accuracy of residual network with 50 layers (ResNet50) was as high as 97.59%, and the F1 score of dense convolutional network with 121 layers (DenseNet121) was as high as 90.50. The deep-learning model used in this experiment had the greatest improvement in F1 score after the logistic regression ensemble. Deep-learning networks with deeper network layers like ResNet50 and DenseNet121 performed better in this experiment. This study can provide a reference for the identification of peanut-leaf diseases.
KW  - peanut-leaf diseases
KW  - deep learning
KW  - convolutional neural network
KW  - identification
DO  - 10.3390/app11041950
TY  - EJOU
AU  - Megahed, Yasmine
AU  - Shaker, Ahmed
AU  - Yan, Wai Y.
TI  - Fusion of Airborne LiDAR Point Clouds and Aerial Images for Heterogeneous Land-Use Urban Mapping
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 4
SN  - 2072-4292

AB  - The World Health Organization has reported that the number of worldwide urban residents is expected to reach 70% of the total world population by 2050. In the face of challenges brought about by the demographic transition, there is an urgent need to improve the accuracy of urban land-use mappings to more efficiently inform about urban planning processes. Decision-makers rely on accurate urban mappings to properly assess current plans and to develop new ones. This study investigates the effects of including conventional spectral signatures acquired by different sensors on the classification of airborne LiDAR (Light Detection and Ranging) point clouds using multiple feature spaces. The proposed method applied three machine learning algorithmsâML (Maximum Likelihood), SVM (Support Vector Machines), and MLP (Multilayer Perceptron Neural Network)âto classify LiDAR point clouds of a residential urban area after being geo-registered to aerial photos. The overall classification accuracy passed 97%, with height as the only geometric feature in the classifying space. Misclassifications occurred among different classes due to independent acquisition of aerial and LiDAR data as well as shadow and orthorectification problems from aerial images. Nevertheless, the outcomes are promising as they surpassed those achieved with large geometric feature spaces and are encouraging since the approach is computationally reasonable and integrates radiometric properties from affordable sensors.
KW  - urban land-use
KW  - LiDAR-aerial integration
KW  - LiDAR-aerial geo-registration
KW  - LiDAR classification
KW  - supervised machine learning
KW  - maximum likelihood
KW  - support vector machines
KW  - neural networks
KW  - bootstrap aggregation
KW  - k-fold cross-validation
DO  - 10.3390/rs13040814
TY  - EJOU
AU  - Imran
AU  - Iqbal, Naeem
AU  - Ahmad, Shabir
AU  - Kim, Do H.
TI  - Towards Mountain Fire Safety Using Fire Spread Predictive Analytics and Mountain Fire Containment in IoT Environment
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 5
SN  - 2071-1050

AB  - Mountains are popular tourist destinations due to their climate, fresh atmosphere, breathtaking sceneries, and varied topography. However, they are at times exposed to accidents, such as fire caused due to natural hazards and human activities. Such unforeseen fire accidents have a social, economic, and environmental impact on mountain towns worldwide. Protecting mountains from such fire accidents is also very challenging in terms of the high cost of fire containment resources, tracking fire spread, and evacuating the people at risk. This paper aims to fill this gap and proposes a three-fold methodology for fire safety in the mountains. The first part of the methodology is an optimization model for effective fire containment resource utilization. The second part of the methodology is a novel ensemble model based on machine learning, the heuristic approach, and principal component regression for predictive analytics of fire spread data. The final part of the methodology consists of an Internet of Things-based task orchestration approach to notify fire safety information to safety authorities. The proposed three-fold fire safety approach provides in-time information to safety authorities for making on-time decisions to minimize the damage caused by mountain fire with minimum containment cost. The performance of optimization models is evaluated in terms of execution time and cost. The particle swarm optimization-based model performs better in terms of cost, whereas the bat algorithm performs better in terms of execution time. The prediction modelsâ performance is evaluated in terms of root mean square error, mean absolute error, and mean absolute percentage error. The proposed ensemble-based prediction model accuracy for fire spread and burned area prediction is higher than that of the state-of-the-art algorithms. It is evident from the results that the proposed fire safety mechanism is a step towards efficient mountain fire safety management.
KW  - fire spread prediction
KW  - fire spread notification
KW  - predictive analysis
KW  - optimization
KW  - fire containment
DO  - 10.3390/su13052461
TY  - EJOU
AU  - Pant, Shashank
AU  - Nooralishahi, Parham
AU  - Avdelidis, Nicolas P.
AU  - Ibarra-Castanedo, Clemente
AU  - Genest, Marc
AU  - Deane, Shakeb
AU  - Valdes, Julio J.
AU  - Zolotas, Argyrios
AU  - Maldague, Xavier P. V.
TI  - Evaluation and Selection of Video Stabilization Techniques for UAV-Based Active Infrared Thermography Application
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 5
SN  - 1424-8220

AB  - Unmanned Aerial Vehicles (UAVs) that can fly around an aircraft carrying several sensors, e.g., thermal and optical cameras, to inspect the parts of interest without removing them can have significant impact in reducing inspection time and cost. One of the main challenges in the UAV based active InfraRed Thermography (IRT) inspection is the UAVâs unexpected motions. Since active thermography is mainly concerned with the analysis of thermal sequences, unexpected motions can disturb the thermal profiling and cause data misinterpretation especially for providing an automated process pipeline of such inspections. Additionally, in the scenarios where post-analysis is intended to be applied by an inspector, the UAVâs unexpected motions can increase the risk of human error, data misinterpretation, and incorrect characterization of possible defects. Therefore, post-processing is required to minimize/eliminate such undesired motions using digital video stabilization techniques. There are number of video stabilization algorithms that are readily available; however, selecting the best suited one is also challenging. Therefore, this paper evaluates video stabilization algorithms to minimize/mitigate undesired UAV motion and proposes a simple method to find the best suited stabilization algorithm as a fundamental first step towards a fully operational UAV-IRT inspection system.
KW  - active infrared thermography
KW  - unmanned aerial vehicle (UAV)
KW  - composites
KW  - aerospace components
KW  - video stabilization
DO  - 10.3390/s21051604
TY  - EJOU
AU  - Safonova, Anastasiia
AU  - Guirado, Emilio
AU  - Maglinets, Yuriy
AU  - Alcaraz-Segura, Domingo
AU  - Tabik, Siham
TI  - Olive Tree Biovolume from UAV Multi-Resolution Image Segmentation with Mask R-CNN
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 5
SN  - 1424-8220

AB  - Olive tree growing is an important economic activity in many countries, mostly in the Mediterranean Basin, Argentina, Chile, Australia, and California. Although recent intensification techniques organize olive groves in hedgerows, most olive groves are rainfed and the trees are scattered (as in Spain and Italy, which account for 50% of the worldâs olive oil production). Accurate measurement of trees biovolume is a first step to monitor their performance in olive production and health. In this work, we use one of the most accurate deep learning instance segmentation methods (Mask R-CNN) and unmanned aerial vehicles (UAV) images for olive tree crown and shadow segmentation (OTCS) to further estimate the biovolume of individual trees. We evaluated our approach on images with different spectral bands (red, green, blue, and near infrared) and vegetation indices (normalized difference vegetation indexâNDVIâand green normalized difference vegetation indexâGNDVI). The performance of red-green-blue (RGB) images were assessed at two spatial resolutions 3 cm/pixel and 13 cm/pixel, while NDVI and GNDV images were only at 13 cm/pixel. All trained Mask R-CNN-based models showed high performance in the tree crown segmentation, particularly when using the fusion of all dataset in GNDVI and NDVI (F1-measure from 95% to 98%). The comparison in a subset of trees of our estimated biovolume with ground truth measurements showed an average accuracy of 82%. Our results support the use of NDVI and GNDVI spectral indices for the accurate estimation of the biovolume of scattered trees, such as olive trees, in UAV images.
KW  - instance segmentation
KW  - machine learning
KW  - deep neural networks
KW  - olive trees
KW  - ultra-high resolution images
DO  - 10.3390/s21051617
TY  - EJOU
AU  - Koh, Joshua C.O.
AU  - Spangenberg, German
AU  - Kant, Surya
TI  - Automated Machine Learning for High-Throughput Image-Based Plant Phenotyping
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 5
SN  - 2072-4292

AB  - Automated machine learning (AutoML) has been heralded as the next wave in artificial intelligence with its promise to deliver high-performance end-to-end machine learning pipelines with minimal effort from the user. However, despite AutoML showing great promise for computer vision tasks, to the best of our knowledge, no study has used AutoML for image-based plant phenotyping. To address this gap in knowledge, we examined the application of AutoML for image-based plant phenotyping using wheat lodging assessment with unmanned aerial vehicle (UAV) imagery as an example. The performance of an open-source AutoML framework, AutoKeras, in image classification and regression tasks was compared to transfer learning using modern convolutional neural network (CNN) architectures. For image classification, which classified plot images as lodged or non-lodged, transfer learning with Xception and DenseNet-201 achieved the best classification accuracy of 93.2%, whereas AutoKeras had a 92.4% accuracy. For image regression, which predicted lodging scores from plot images, transfer learning with DenseNet-201 had the best performance (R2 = 0.8303, root mean-squared error (RMSE) = 9.55, mean absolute error (MAE) = 7.03, mean absolute percentage error (MAPE) = 12.54%), followed closely by AutoKeras (R2 = 0.8273, RMSE = 10.65, MAE = 8.24, MAPE = 13.87%). In both tasks, AutoKeras models had up to 40-fold faster inference times compared to the pretrained CNNs. AutoML has significant potential to enhance plant phenotyping capabilities applicable in crop breeding and precision agriculture.
KW  - automated machine learning
KW  - neural architecture search
KW  - high-throughput plant phenotyping
KW  - wheat lodging assessment
KW  - unmanned aerial vehicle
DO  - 10.3390/rs13050858
TY  - EJOU
AU  - Ali, Luqman
AU  - Alnajjar, Fady
AU  - Jassmi, Hamad A.
AU  - Gocho, Munkhjargal
AU  - Khan, Wasif
AU  - Serhani, M. A.
TI  - Performance Evaluation of Deep CNN-Based Crack Detection and Localization Techniques for Concrete Structures
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 5
SN  - 1424-8220

AB  - This paper proposes a customized convolutional neural network for crack detection in concrete structures. The proposed method is compared to four existing deep learning methods based on training data size, data heterogeneity, network complexity, and the number of epochs. The performance of the proposed convolutional neural network (CNN) model is evaluated and compared to pretrained networks, i.e., the VGG-16, VGG-19, ResNet-50, and Inception V3 models, on eight datasets of different sizes, created from two public datasets. For each model, the evaluation considered computational time, crack localization results, and classification measures, e.g., accuracy, precision, recall, and F1-score. Experimental results demonstrated that training data size and heterogeneity among data samples significantly affect model performance. All models demonstrated promising performance on a limited number of diverse training data; however, increasing the training data size and reducing diversity reduced generalization performance, and led to overfitting. The proposed customized CNN and VGG-16 models outperformed the other methods in terms of classification, localization, and computational time on a small amount of data, and the results indicate that these two models demonstrate superior crack detection and localization for concrete structures.
KW  - automatic inspection
KW  - convolutional neural networks
KW  - crack detection
KW  - deep learning
KW  - transfer learning
DO  - 10.3390/s21051688
TY  - EJOU
AU  - Liu, Dan
AU  - Li, Dajun
AU  - Wang, Meizhen
AU  - Wang, Zhiming
TI  - 3D Change Detection Using Adaptive Thresholds Based on Local Point Cloud Density
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 3
SN  - 2220-9964

AB  - In recent years, because of highly developed LiDAR (Light Detection and Ranging) technologies, there has been increasing demand for 3D change detection in urban monitoring, urban model updating, and disaster assessment. In order to improve the effectiveness of 3D change detection based on point clouds, an approach for 3D change detection using point-based comparison is presented in this paper. To avoid density variation in point clouds, adaptive thresholds are calculated through the k-neighboring average distance and the local point cloud density. A series of experiments for quantitative evaluation is performed. In the experiments, the influencing factors including threshold, registration error, and neighboring number of 3D change detection are discussed and analyzed. The results of the experiments demonstrate that the approach using adaptive thresholds based on local point cloud density are effective and suitable.
KW  - 3D change detection
KW  - adaptive thresholds
KW  - point-based comparison
KW  - point clouds
DO  - 10.3390/ijgi10030127
TY  - EJOU
AU  - Najafi, Payam
AU  - Feizizadeh, Bakhtiar
AU  - Navid, Hossein
TI  - A Comparative Approach of Fuzzy Object Based Image Analysis and Machine Learning Techniques Which Are Applied to Crop Residue Cover Mapping by Using Sentinel-2 Satellite and UAV Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 5
SN  - 2072-4292

AB  - Conservation tillage methods through leaving the crop residue cover (CRC) on the soil surface protect it from water and wind erosions. Hence, the percentage of the CRC on the soil surface is very critical for the evaluation of tillage intensity. The objective of this study was to develop a new methodology based on the semiautomated fuzzy object based image analysis (fuzzy OBIA) and compare its efficiency with two machine learning algorithms which include: support vector machine (SVM) and artificial neural network (ANN) for the evaluation of the previous CRC and tillage intensity. We also considered the spectral images from two remotely sensed platforms of the unmanned aerial vehicle (UAV) and Sentinel-2 satellite, respectively. The results indicated that fuzzy OBIA for multispectral Sentinel-2 image based on Gaussian membership function with overall accuracy and Cohenâs kappa of 0.920 and 0.874, respectively, surpassed machine learning algorithms and represented the useful results for the classification of tillage intensity. The results also indicated that overall accuracy and Cohenâs kappa for the classification of RGB images from the UAV using fuzzy OBIA method were 0.860 and 0.779, respectively. The semiautomated fuzzy OBIA clearly outperformed machine learning approaches in estimating the CRC and the classification of the tillage methods and also it has the potential to substitute or complement field techniques.
KW  - fuzzy object based approach
KW  - neural network
KW  - support vector machine
KW  - tillage intensity
KW  - soil erosion
DO  - 10.3390/rs13050937
TY  - EJOU
AU  - Xue, Yongan
AU  - Zhao, Jinling
AU  - Zhang, Mingmei
TI  - A Watershed-Segmentation-Based Improved Algorithm for Extracting Cultivated Land Boundaries
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 5
SN  - 2072-4292

AB  - To accurately extract cultivated land boundaries based on high-resolution remote sensing imagery, an improved watershed segmentation algorithm was proposed herein based on a combination of pre- and post-improvement procedures. Image contrast enhancement was used as the pre-improvement, while the color distance of the Commission Internationale de lÂ´Eclairage (CIE) color space, including the Lab and Luv, was used as the regional similarity measure for region merging as the post-improvement. Furthermore, the area relative error criterion (Î´A), the pixel quantity error criterion (Î´P), and the consistency criterion (Khat) were used for evaluating the image segmentation accuracy. The region merging in RedâGreenâBlue (RGB) color space was selected to compare the proposed algorithm by extracting cultivated land boundaries. The validation experiments were performed using a subset of Chinese Gaofen-2 (GF-2) remote sensing image with a coverage area of 0.12 km2. The results showed the following: (1) The contrast-enhanced image exhibited an obvious gain in terms of improving the image segmentation effect and time efficiency using the improved algorithm. The time efficiency increased by 10.31%, 60.00%, and 40.28%, respectively, in the RGB, Lab, and Luv color spaces. (2) The optimal segmentation and merging scale parameters in the RGB, Lab, and Luv color spaces were C for minimum areas of 2000, 1900, and 2000, and D for a color difference of 1000, 40, and 40. (3) The algorithm improved the time efficiency of cultivated land boundary extraction in the Lab and Luv color spaces by 35.16% and 29.58%, respectively, compared to the RGB color space. The extraction accuracy was compared to the RGB color space using the Î´A, Î´P, and Khat, that were improved by 76.92%, 62.01%, and 16.83%, respectively, in the Lab color space, while they were 55.79%, 49.67%, and 13.42% in the Luv color space. (4) Through the visual comparison, time efficiency, and segmentation accuracy, the comprehensive extraction effect using the proposed algorithm was obviously better than that of RGB color-based space algorithm. The established accuracy evaluation indicators were also proven to be consistent with the visual evaluation. (5) The proposed method has a satisfying transferability by a wider test area with a coverage area of 1 km2. In addition, the proposed method, based on the image contrast enhancement, was to perform the region merging in the CIE color space according to the simulated immersion watershed segmentation results. It is a useful attempt for the watershed segmentation algorithm to extract cultivated land boundaries, which provides a reference for enhancing the watershed algorithm.
KW  - cultivated land
KW  - watershed segmentation algorithm
KW  - image contrast enhancement
KW  - region merging
KW  - CIE color space
KW  - Lab
KW  - Luv
DO  - 10.3390/rs13050939
TY  - EJOU
AU  - MÃ¼ezzinoÄlu, Taha
AU  - KarakÃ¶se, Mehmet
TI  - An Intelligent HumanâUnmanned Aerial Vehicle Interaction Approach in Real Time Based on Machine Learning Using Wearable Gloves
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 5
SN  - 1424-8220

AB  - The interactions between humans and unmanned aerial vehicles (UAVs), whose applications are increasing in the civilian field rather than for military purposes, are a popular future research area. HumanâUAV interactions are a challenging problem because UAVs move in a three-dimensional space. In this paper, we present an intelligent humanâUAV interaction approach in real time based on machine learning using wearable gloves. The proposed approach offers scientific contributions such as a multi-mode command structure, machine-learning-based recognition, task scheduling algorithms, real-time usage, robust and effective use, and high accuracy rates. For this purpose, two wearable smart gloves working in real time were designed. The signal data obtained from the gloves were processed with machine-learning-based methods and classified multi-mode commands were included in the humanâUAV interaction process via the interface according to the task scheduling algorithm to facilitate sequential and fast operation. The performance of the proposed approach was verified on a data set created using 25 different hand gestures from 20 different people. In a test using the proposed approach on 49,000 datapoints, process time performance of a few milliseconds was achieved with approximately 98 percent accuracy.
KW  - humanâUAV interaction
KW  - wearable technologies
KW  - Internet of Things (IoT)
KW  - humanâcomputer interaction
KW  - smart systems
DO  - 10.3390/s21051766
TY  - EJOU
AU  - Gray, Ross E. J.
AU  - Ewers, Robert M.
TI  - Monitoring Forest Phenology in a Changing World
T2  - Forests

PY  - 2021
VL  - 12
IS  - 3
SN  - 1999-4907

AB  - Plant phenology is strongly interlinked with ecosystem processes and biodiversity. Like many other aspects of ecosystem functioning, it is affected by habitat and climate change, with both global change drivers altering the timings and frequency of phenological events. As such, there has been an increased focus in recent years to monitor phenology in different biomes. A range of approaches for monitoring phenology have been developed to increase our understanding on its role in ecosystems, ranging from the use of satellites and drones to collection traps, each with their own merits and limitations. Here, we outline the trade-offs between methods (spatial resolution, temporal resolution, cost, data processing), and discuss how their use can be optimised in different environments and for different goals. We also emphasise emerging technologies that will be the focus of monitoring in the years to follow and the challenges of monitoring phenology that still need to be addressed. We conclude that there is a need to integrate studies that incorporate multiple monitoring methods, allowing the strengths of one to compensate for the weaknesses of another, with a view to developing robust methods for upscaling phenological observations from point locations to biome and global scales and reconciling data from varied sources and environments. Such developments are needed if we are to accurately quantify the impacts of a changing world on plant phenology.
KW  - drones
KW  - ecosystem change
KW  - methods
KW  - monitoring
KW  - phenology
KW  - remote sensing
KW  - UAVs
DO  - 10.3390/f12030297
TY  - EJOU
AU  - Niu, Yaxiao
AU  - Zhang, Huihui
AU  - Han, Wenting
AU  - Zhang, Liyuan
AU  - Chen, Haipeng
TI  - A Fixed-Threshold Method for Estimating Fractional Vegetation Cover of Maize under Different Levels of Water Stress
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 5
SN  - 2072-4292

AB  - Accurate estimation of fractional vegetation cover (FVC) from digital images taken by commercially available cameras is of great significance in order to monitor the vegetation growth status, especially when plants are under water stress. Two classic threshold-based methods, namely, the intersection method (T1 method) and the equal misclassification probability method (T2 method), have been widely applied to Red-Green-Blue (RGB) images. However, the high coverage and severe water stress of crops in the field make it difficult to extract FVC stably and accurately. To solve this problem, this paper proposes a fixed-threshold method based on the statistical analysis of thresholds obtained from the two classic threshold approaches. Firstly, a Gaussian mixture model (GMM), including the distributions of green vegetation and backgrounds, was fitted on four color features: excessive green index, H channel of the Hue-Saturation-Value (HSV) color space, a* channel of the CIE L*a*b* color space, and the brightness-enhanced a* channel (denoted as a*_I). Secondly, thresholds were calculated by applying the T1 and T2 methods to the GMM of each color feature. Thirdly, based on the statistical analysis of the thresholds with better performance between T1 and T2, the fixed-threshold method was proposed. Finally, the fixed-threshold method was applied to the optimal color feature a*_I to estimate FVC, and was compared with the two classic approaches. Results showed that, for some images with high reference FVC, FVC was seriously underestimated by 0.128 and 0.141 when using the T1 and T2 methods, respectively, but this problem was eliminated by the proposed fixed-threshold method. Compared with the T1 and T2 methods, for images taken in plots under severe water stress, the mean absolute error of FVC obtained by the fixed-threshold method was decreased by 0.043 and 0.193, respectively. Overall, the FVC estimation using the proposed fixed-threshold method has the advantages of robustness, accuracy, and high efficiency, with a coefficient of determination (R2) of 0.99 and root mean squared error (RMSE) of 0.02.
KW  - proximal RGB image
KW  - color feature
KW  - Gaussian mixture model
KW  - expectation-maximization algorithm
DO  - 10.3390/rs13051009
TY  - EJOU
AU  - Belmonte, Adam
AU  - Sankey, Temuulen
AU  - Biederman, Joel
AU  - Bradford, John
AU  - Goetz, Scott
AU  - Kolb, Thomas
TI  - UAV-Based Estimate of Snow Cover Dynamics: Optimizing Semi-Arid Forest Structure for Snow Persistence
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 5
SN  - 2072-4292

AB  - Seasonal snow cover in the dry forests of the American West provides essential water resources to both human and natural systems. The structure of trees and their arrangement across the landscape are important drivers of snow cover distribution across these forests, varying widely in both space and time. We used unmanned aerial vehicle (UAV) multispectral imagery and Structure-from-Motion (SfM) models to quantify rapidly melting snow cover dynamics and examine the effects of forest structure shading on persistent snow cover in a recently thinned ponderosa pine forest. Using repeat UAV multispectral imagery (n = 11 dates) across the 76 ha forest, we first developed a rapid and effective method for identifying persistent snow cover with 90.2% overall accuracy. The SfM model correctly identified 98% (n = 1280) of the trees, when compared with terrestrial laser scanner validation data. Using the SfM-derived forest structure variables, we then found that canopy shading associated with the vertical and horizontal metrics was a significant driver of persistent snow cover patches (R2 = 0.70). The results indicate that UAV image-derived forest structure metrics can be used to accurately predict snow patch size and persistence. Our results provide insight into the importance of forest structure, specifically canopy shading, in the amount and distribution of persistent seasonal snow cover in a typical dry forest environment. An operational understanding of forest structure effects on snow cover will help drive forest management that can target snow cover dynamics in addition to forest health.
KW  - unmanned aerial vehicle (UAV)
KW  - drone
KW  - point cloud data
KW  - 3D data
KW  - wildfire
KW  - fire behavior
KW  - structure-from-motion
KW  - SfM
KW  - lidar
KW  - BLK360
KW  - canopy base height
KW  - bulk density
KW  - canopy cover
DO  - 10.3390/rs13051036
TY  - EJOU
AU  - Nemer, Ibrahim
AU  - Sheltami, Tarek
AU  - Ahmad, Irfan
AU  - Yasar, Ansar U.
AU  - Abdeen, Mohammad A. R.
TI  - RF-Based UAV Detection and Identification Using Hierarchical Learning Approach
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 6
SN  - 1424-8220

AB  - Unmanned Aerial Vehicles (UAVs) are widely available in the current market to be used either for recreation as a hobby or to serve specific industrial requirements, such as agriculture and construction. However, illegitimate and criminal usage of UAVs is also on the rise which introduces their effective identification and detection as a research challenge. This paper proposes a novel machine learning-based for efficient identification and detection of UAVs. Specifically, an improved UAV identification and detection approach is presented using an ensemble learning based on the hierarchical concept, along with pre-processing and feature extraction stages for the Radio Frequency (RF) data. Filtering is applied on the RF signals in the detection approach to improve the output. This approach consists of four classifiers and they are working in a hierarchical way. The sample will pass the first classifier to check the availability of the UAV, and then it will specify the type of the detected UAV using the second classifier. The last two classifiers will handle the sample that is related to Bebop and AR to specify their mode. Evaluation of the proposed approach with publicly available dataset demonstrates better efficiency compared to existing detection systems in the literature. It has the ability to investigate whether a UAV is flying within the area or not, and it can directly identify the type of UAV and then the flight mode of the detected UAV with accuracy around 99%.
KW  - radio frequency
KW  - unmanned aerial vehicles
KW  - machine learning
KW  - detection and identification
DO  - 10.3390/s21061947
TY  - EJOU
AU  - Dainelli, Riccardo
AU  - Toscano, Piero
AU  - Di Gennaro, Salvatore F.
AU  - Matese, Alessandro
TI  - Recent Advances in Unmanned Aerial Vehicle Forest Remote SensingâA Systematic Review. Part I: A General Framework
T2  - Forests

PY  - 2021
VL  - 12
IS  - 3
SN  - 1999-4907

AB  - Natural, semi-natural, and planted forests are a key asset worldwide, providing a broad range of positive externalities. For sustainable forest planning and management, remote sensing (RS) platforms are rapidly going mainstream. In a framework where scientific production is growing exponentially, a systematic analysis of unmanned aerial vehicle (UAV)-based forestry research papers is of paramount importance to understand trends, overlaps and gaps. The present review is organized into two parts (Part I and Part II). Part II inspects specific technical issues regarding the application of UAV-RS in forestry, together with the pros and cons of different UAV solutions and activities where additional effort is needed, such as the technology transfer. Part I systematically analyzes and discusses general aspects of applying UAV in natural, semi-natural and artificial forestry ecosystems in the recent peer-reviewed literature (2018âmid-2020). The specific goals are threefold: (i) create a carefully selected bibliographic dataset that other researchers can draw on for their scientific works; (ii) analyze general and recent trends in RS forest monitoring (iii) reveal gaps in the general research framework where an additional activity is needed. Through double-step filtering of research items found in the Web of Science search engine, the study gathers and analyzes a comprehensive dataset (226 articles). Papers have been categorized into six main topics, and the relevant information has been subsequently extracted. The strong points emerging from this study concern the wide range of topics in the forestry sector and in particular the retrieval of tree inventory parameters often through Digital Aerial Photogrammetry (DAP), RGB sensors, and machine learning techniques. Nevertheless, challenges still exist regarding the promotion of UAV-RS in specific parts of the world, mostly in the tropical and equatorial forests. Much additional research is required for the full exploitation of hyperspectral sensors and for planning long-term monitoring.
KW  - UAV
KW  - drone
KW  - forest
KW  - precision forestry
KW  - remote sensing
KW  - meta-analysis
KW  - management
KW  - natural woodland
KW  - plantation forests
DO  - 10.3390/f12030327
TY  - EJOU
AU  - Ma, Qian
AU  - Han, Wenting
AU  - Huang, Shenjin
AU  - Dong, Shide
AU  - Li, Guang
AU  - Chen, Haipeng
TI  - Distinguishing Planting Structures of Different Complexity from UAV Multispectral Images
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 6
SN  - 1424-8220

AB  - This study explores the classification potential of a multispectral classification model for farmland with planting structures of different complexity. Unmanned aerial vehicle (UAV) remote sensing technology is used to obtain multispectral images of three study areas with low-, medium-, and high-complexity planting structures, containing three, five, and eight types of crops, respectively. The feature subsets of three study areas are selected by recursive feature elimination (RFE). Object-oriented random forest (OB-RF) and object-oriented support vector machine (OB-SVM) classification models are established for the three study areas. After training the models with the feature subsets, the classification results are evaluated using a confusion matrix. The OB-RF and OB-SVM modelsâ classification accuracies are 97.09% and 99.13%, respectively, for the low-complexity planting structure. The equivalent values are 92.61% and 99.08% for the medium-complexity planting structure and 88.99% and 97.21% for the high-complexity planting structure. For farmland with fragmentary plots and a high-complexity planting structure, as the planting structure complexity changed from low to high, both modelsâ overall accuracy levels decreased. The overall accuracy of the OB-RF model decreased by 8.1%, and that of the OB-SVM model only decreased by 1.92%. OB-SVM achieves an overall classification accuracy of 97.21%, and a single-crop extraction accuracy of at least 85.65%. Therefore, UAV multispectral remote sensing can be used for classification applications in highly complex planting structures.
KW  - UAV
KW  - multispectral remote sensing
KW  - farmland objects
KW  - classification
KW  - RF
KW  - SVM
DO  - 10.3390/s21061994
TY  - EJOU
AU  - Elsayed, Salah
AU  - El-Hendawy, Salah
AU  - Khadr, Mosaad
AU  - Elsherbiny, Osama
AU  - Al-Suhaibani, Nasser
AU  - Dewir, Yaser H.
AU  - Tahir, Muhammad U.
AU  - Mubushar, Muhammad
AU  - Darwish, Waleed
TI  - Integration of Spectral Reflectance Indices and Adaptive Neuro-Fuzzy Inference System for Assessing the Growth Performance and Yield of Potato under Different Drip Irrigation Regimes
T2  - Chemosensors

PY  - 2021
VL  - 9
IS  - 3
SN  - 2227-9040

AB  - Simultaneous and timely assessment of growth and water status-related plant traits is critical for precision irrigation management in arid regions. Here, we used proximal hyperspectral sensing tools to estimate biomass fresh weight (BFW), biomass dry weight (BDW), canopy water content (CWC), and total tuber yield (TTY) of two potato varieties irrigated with 100%, 75%, and 50% of the estimated crop evapotranspiration (ETc). Plant traits were assessed remotely using published and newly constructed vegetation and water spectral reflectance indices (SRIs). We integrated genetic algorithm (GA) and adaptive neuro-fuzzy inference system (ANFIS) models to predict the measured traits based on all SRIs. The different plant traits and SRIs varied significantly (p &lt; 0.05) between the three irrigation regimes for the two varieties. The values of plant traits and majority SRIs showed a continuous decrease from the 100% ETc to the 50% ETc. Water-SRIs performed better than vegetation-SRIs for estimating the four plant traits. Almost all indices of the two SRI types had a weak relationship with the four plant traits (R2 = 0.00â0.37) under each irrigation regime. However, the majority of vegetation-SRIs and all water-SRIs showed strong relationships with BFW, CWC, and TTY (R2 â¥ 0.65) and moderate relationships with BDW (R2 â¥ 0.40) when the data of all irrigation regimes and varieties were analyzed together for each growing season or the data of all irrigation regimes, varieties, and seasons were combined together. The ANFIS-GA model predicted plant traits with satisfactory accuracy in both calibration (R2 = 1.0) and testing (R2 = 0.72â0.97) modes. The results indicate that SRI-based ANFIS models can improve plant trait estimation. This analysis also confirmed the benefits of applying GA to ANFIS to estimate plant responses to different growth conditions.
KW  - ANFIS
KW  - biomass
KW  - data driven
KW  - genetic algorithm
KW  - proximal remote sensing
KW  - spectral indices
KW  - tuber yield
DO  - 10.3390/chemosensors9030055
TY  - EJOU
AU  - Beselly, Sebrian M.
AU  - van der Wegen, Mick
AU  - Grueters, Uwe
AU  - Reyns, Johan
AU  - Dijkstra, Jasper
AU  - Roelvink, Dano
TI  - Eleven Years of MangroveâMudflat Dynamics on the Mud Volcano-Induced Prograding Delta in East Java, Indonesia: Integrating UAV and Satellite Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 6
SN  - 2072-4292

AB  - This article presents a novel approach to explore mangrove dynamics on a prograding delta by integrating unmanned aerial vehicle (UAV) and satellite imagery. The Porong Delta in Indonesia has a unique geographical setting with rapid delta development and expansion of the mangrove belt. This is due to an unprecedented mud load from the LUSI mud volcanic eruption. The mangrove dynamics analysis combines UAV-based Structure from Motion (SfM) photogrammetry and 11 years (2009â2019) satellite imagery cloud computing analysis by Google Earth Engine (GEE). Our analysis shows unique, high-spatiotemporal-resolution mangrove extent maps. The SfM photogrammetry analysis leads to a 3D representation of the mangrove canopy and an estimate of mangrove biophysical properties with accurate height and individual position of the mangroves stand. GEE derived vegetation indices resulted in high (three-monthly) resolution mangrove coverage dynamics over 11 years (2009â2019), yielding a value of more than 98% for the overall, producer and consumer accuracy. Combining the satellite-derived age maps and the UAV-derived spatial tree structure allowed us to monitor the mangrove dynamics on a rapidly prograding delta along with its structural attributes. This analysis is of essential value to ecologists, coastal managers, and policymakers.
KW  - mangroves
KW  - remote sensing
KW  - Google Earth Engine
KW  - SfM photogrammetry
KW  - UAV
DO  - 10.3390/rs13061084
TY  - EJOU
AU  - Peng, Xingshuo
AU  - Han, Wenting
AU  - Ao, Jianyi
AU  - Wang, Yi
TI  - Assimilation of LAI Derived from UAV Multispectral Data into the SAFY Model to Estimate Maize Yield
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 6
SN  - 2072-4292

AB  - In this study, we develop a method to estimate corn yield based on remote sensing data and ground monitoring data under different water treatments. Spatially explicit information on crop yields is essential for farmers and agricultural agencies to make well-informed decisions. One approach to estimate crop yield with remote sensing is data assimilation, which integrates sequential observations of canopy development from remote sensing into model simulations of crop growth processes. We found that leaf area index (LAI) inversion based on unmanned aerial vehicle (UAV) vegetation index has a high accuracy, with R2 and root mean square error (RMSE) values of 0.877 and 0.609, respectively. Maize yield estimation based on UAV remote sensing data and simple algorithm for yield (SAFY) crop model data assimilation has different yield estimation accuracy under different water treatments. This method can be used to estimate corn yield, where R2 is 0.855 and RMSE is 692.8kg/ha. Generally, the higher the water stress, the lower the estimation accuracy. Furthermore, we perform the yield estimate mapping at 2 m spatial resolution, which has a higher spatial resolution and accuracy than satellite remote sensing. The great potential of incorporating UAV observations with crop data to monitor crop yield, and improve agricultural management is therefore indicated.
KW  - UAV
KW  - leaf area index
KW  - yield estimation
KW  - yield
KW  - SAFY model
KW  - EnKF
DO  - 10.3390/rs13061094
TY  - EJOU
AU  - Gkoumas, Konstantinos
AU  - Gkoktsi, Kyriaki
AU  - Bono, Flavio
AU  - Galassi, Maria C.
AU  - Tirelli, Daniel
TI  - The Way Forward for Indirect Structural Health Monitoring (iSHM) Using Connected and Automated Vehicles in Europe
T2  - Infrastructures

PY  - 2021
VL  - 6
IS  - 3
SN  - 2412-3811

AB  - Europeâs aging transportation infrastructure requires optimized maintenance programs. However, data and monitoring systems may not be readily available to support strategic decisions or they may require costly installations in terms of time and labor requirements. In recent years, the possibility of monitoring bridges by indirectly sensing relevant parameters from traveling vehicles has emergedâan approach that would allow for the elimination of the costly installation of sensors and monitoring campaigns. The advantages of cooperative, connected, and automated mobility (CCAM), which is expected to become a reality in Europe towards the end of this decade, should therefore be considered for the future development of iSHM strategies. A critical review of methods and strategies for CCAM, including Intelligent Transportation Systems, is a prerequisite for moving towards the goal of identifying the synergies between CCAM and civil infrastructures, in line with future developments in vehicle automation. This study presents the policy framework of CCAM in Europe and discusses the policy enablers and bottlenecks of using CCAM in the drive-by monitoring of transport infrastructure. It also highlights the current direction of research within the iSHM paradigm towards the identification of technologies and methods that could benefit from the use of connected and automated vehicles (CAVs).
KW  - iSHM
KW  - drive-by monitoring
KW  - vehicleâbridge interactions
KW  - connected and automated vehicles
KW  - bridge safety
KW  - Europe
DO  - 10.3390/infrastructures6030043
TY  - EJOU
AU  - Fossette, Sabrina
AU  - Loewenthal, Graham
AU  - Peel, Lauren R.
AU  - Vitenbergs, Anna
AU  - Hamel, Melanie A.
AU  - Douglas, Corrine
AU  - Tucker, Anton D.
AU  - Mayer, Florian
AU  - Whiting, Scott D.
TI  - Using Aerial Photogrammetry to Assess Stock-Wide Marine Turtle Nesting Distribution, Abundance and Cumulative Exposure to Industrial Activity
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 6
SN  - 2072-4292

AB  - The lack of accurate distribution maps and reliable abundance estimates for marine species can limit the ability of managers to design scale-appropriate management measures for a stock or population. Here, we tested the utility of aerial photogrammetry for conducting large-scale surveys of nesting marine turtles at remote locations, with a focus on the flatback turtle (Natator depressus) in the Pilbara region of Western Australia. Aerial surveys were conducted between 29 November and 6 December 2016 to overlap with the peak nesting season for flatback turtles and collected imagery was used to examine marine turtle distribution, abundance, and cumulative exposure to industrial activity relative to overlap with protected areas. Two observers independently reviewed aerial georeferenced photographs of 644 beaches and recorded turtle tracks and other evidence of turtle nesting activity. A total of 375 beaches showed signs of nesting activity by either flatback, green (Chelonia mydas) or hawksbill (Eretmochelys imbricata) turtles. Most of these beaches (85.3%) were located on islands, and the rest (14.7%) on the mainland. Half (n = 174) of the active beaches showed evidence of fresh (0â36 h. old) flatback nesting activity, with track abundance varying from 1.0 to 222.0 tracksÂ·nightâ1. Six rookeries accounted for 62% of the Pilbara flatback stock. Remarkably, 77% of identified flatback rookeries occurred within protected areas. However, one-third (34%) of those were also located within 5 km of a major industrial site, including eight of the highest abundance beaches (50â250 tracksÂ·nightâ1). Several key rookeries were also identified as being relatively unexposed to industry-related pressures but currently unprotected, highlighting the need for a cumulative impact assessment to be completed for this flatback stock. Finally, our aerial tallies and multiple ground-survey flatback track tallies were highly correlated and together with low intra- and inter-observer errors suggested that reliable data can be collected via aerial photogrammetry for nesting marine turtles. Such large-scale digitized surveys can therefore be used to assess the cumulative exposure of marine turtles to pressures, and to reveal new conservation opportunities.
KW  - aerial survey
KW  - cumulative impact
KW  - marine turtles
KW  - nesting distribution
KW  - population trends
DO  - 10.3390/rs13061116
TY  - EJOU
AU  - Swinney, Carolyn J.
AU  - Woods, John C.
TI  - Unmanned Aerial Vehicle Operating Mode Classification Using Deep Residual Learning Feature Extraction
T2  - Aerospace

PY  - 2021
VL  - 8
IS  - 3
SN  - 2226-4310

AB  - Unmanned Aerial Vehicles (UAVs) undoubtedly pose many security challenges. We need only look to the December 2018 Gatwick Airport incident for an example of the disruption UAVs can cause. In total, 1000 flights were grounded for 36 h over the Christmas period which was estimated to cost over 50 million pounds. In this paper, we introduce a novel approach which considers UAV detection as an imagery classification problem. We consider signal representations Power Spectral Density (PSD); Spectrogram, Histogram and raw IQ constellation as graphical images presented to a deep Convolution Neural Network (CNN) ResNet50 for feature extraction. Pre-trained on ImageNet, transfer learning is utilised to mitigate the requirement for a large signal dataset. We evaluate performance through machine learning classifier Logistic Regression. Three popular UAVs are classified in different modes; switched on; hovering; flying; flying with video; and no UAV present, creating a total of 10 classes. Our results, validated with 5-fold cross validation and an independent dataset, show PSD representation to produce over 91% accuracy for 10 classifications. Our paper treats UAV detection as an imagery classification problem by presenting signal representations as images to a ResNet50, utilising the benefits of transfer learning and outperforming previous work in the field.
KW  - unmanned aerial vehicles
KW  - UAV detection
KW  - RF spectrum analysis
KW  - machine learning classification
KW  - deep learning
KW  - convolutional neural network
KW  - transfer learning
KW  - signal analysis
DO  - 10.3390/aerospace8030079
TY  - EJOU
AU  - Hardy, Tom
AU  - Kooistra, Lammert
AU  - Domingues Franceschini, Marston
AU  - Richter, Sebastiaan
AU  - Vonk, Erwin
AU  - van den Eertwegh, GÃ©
AU  - van Deijl, Dion
TI  - Sen2Grass: A Cloud-Based Solution to Generate Field-Specific Grassland Information Derived from Sentinel-2 Imagery
T2  - AgriEngineering

PY  - 2021
VL  - 3
IS  - 1
SN  - 2624-7402

AB  - Grasslands are important for their ecological values and for agricultural activities such as livestock production worldwide. Efficient grassland management is vital to these values and activities, and remote sensing technologies are increasingly being used to characterize the spatiotemporal variation of grasslands to support those management practices. For this study, Sentinel-2 satellite imagery was used as an input to develop an open-source and automated monitoring system (Sen2Grass) to gain field-specific grassland information on the national and regional level for any given time range as of January 2016. This system was implemented in a cloud-computing platform (StellaSpark Nexus) designed to process large geospatial data streams from a variety of sources and was tested for a number of parcels from the Haus Riswick experimental farm in Germany. Despite outliers due to fluctuating weather conditions, vegetation index time series suggested four distinct growing cycles per growing season. Established relationships between vegetation indices and grassland yield showed poor to moderate positive trends, implying that vegetation indices could be a potential predictor for grassland biomass and chlorophyll content. However, the inclusion of larger and additional datasets such as Sentinel-1 imagery could be beneficial to developing more robust prediction models and for automatic detection of mowing events for grasslands.
KW  - sen2grass
KW  - sentinel-2
KW  - stellaspark
KW  - nexus
KW  - grassland monitoring
KW  - time series
KW  - vegetation indices
KW  - cloud cover
DO  - 10.3390/agriengineering3010008
TY  - EJOU
AU  - El-Alem, Anas
AU  - Chokmani, Karem
AU  - Venkatesan, Aarthi
AU  - Rachid, Lhissou
AU  - Agili, Hachem
AU  - Dedieu, Jean-Pierre
TI  - How Accurate Is an Unmanned Aerial Vehicle Data-Based Model Applied on Satellite Imagery for Chlorophyll-a Estimation in Freshwater Bodies?
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 6
SN  - 2072-4292

AB  - Optical sensors are increasingly sought to estimate the amount of chlorophyll a (chl_a) in freshwater bodies. Most, whether empirical or semi-empirical, are data-oriented. Two main limitations are often encountered in the development of such models. The availability of data needed for model calibration, validation, and testing and the locality of the model developedâthe majority need a re-parameterization from lake to lake. An Unmanned aerial vehicle (UAV) data-based model for chl_a estimation is developed in this work and tested on Sentinel-2 imagery without any re-parametrization. The Ensemble-based system (EBS) algorithm was used to train the model. The leave-one-out cross validation technique was applied to evaluate the EBS, at a local scale, where results were satisfactory (R2 = Nash = 0.94 and RMSE = 5.6 Âµg chl_a Lâ1). A blind database (collected over 89 lakes) was used to challenge the EBSâ Sentine-2-derived chl_a estimates at a regional scale. Results were relatively less good, yet satisfactory (R2 = 0.85, RMSE= 2.4 Âµg chl_a Lâ1, and Nash = 0.79). However, the EBS has shown some failure to correctly retrieve chl_a concentration in highly turbid waterbodies. This particularity nonetheless does not affect EBS performance, since turbid waters can easily be pre-recognized and masked before the chl_a modeling.
KW  - Sentinel-2
KW  - unmanned aerial vehicle
KW  - remote sensing
KW  - chlorophyll-a
KW  - machine learning
KW  - ensemble-based system
KW  - freshwaters
KW  - water quality
DO  - 10.3390/rs13061134
TY  - EJOU
AU  - Cooper, Hannah M.
AU  - Wasklewicz, Thad
AU  - Zhu, Zhen
AU  - Lewis, William
AU  - LeCompte, Karley
AU  - Heffentrager, Madison
AU  - Smaby, Rachel
AU  - Brady, Julian
AU  - Howard, Robert
TI  - Evaluating the Ability of Multi-Sensor Techniques to Capture Topographic Complexity
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 6
SN  - 1424-8220

AB  - This study provides an evaluation of multiple sensors by examining their precision and ability to capture topographic complexity. Five different small unmanned aerial systems (sUAS) were evaluated, each with a different camera, Global Navigation Satellite System (GNSS), and Inertial Measurement Unit (IMU). A lidar was also used on the largest sUAS and as a mobile scanning system. The quality of each of the seven platforms were compared to actual surface measurements gathered with real-time kinematic (RTK)-GNSS and terrestrial laser scanning. Rigorous field and photogrammetric assessment workflows were designed around a combination of structure-from-motion to align images, Monte Carlo simulations to calculate spatially variable error, object-based image analysis to create objects, and MC32-PM algorithm to calculate vertical differences between two dense point clouds. The precision of the sensors ranged 0.115 m (minimum of 0.11 m for MaRS with Sony A7iii camera and maximum of 0.225 m for Mavic2 Pro). In a heterogenous test location with varying slope and high terrain roughness, only three of the seven mobile platforms performed well (MaRS, Inspire 2, and Phantom 4 Pro). All mobile sensors performed better for the homogenous test location, but the sUAS lidar and mobile lidar contained the most noise. The findings presented herein provide insights into costâbenefit of purchasing various sUAS and sensors and their ability to capture high-definition topography.
KW  - structure-from-motion
KW  - terrestrial laser scanning
KW  - lidar
KW  - OBIA
KW  - UAS
KW  - precision
DO  - 10.3390/s21062105
TY  - EJOU
AU  - Hou, Yuewu
AU  - Liu, Zhaoying
AU  - Zhang, Ting
AU  - Li, Yujian
TI  - C-UNet: Complement UNet for Remote Sensing Road Extraction
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 6
SN  - 1424-8220

AB  - Roads are important mode of transportation, which are very convenient for peopleâs daily work and life. However, it is challenging to accuratly extract road information from a high-resolution remote sensing image. This paper presents a road extraction method for remote sensing images with a complement UNet (C-UNet). C-UNet contains four modules. Firstly, the standard UNet is used to roughly extract road information from remote sensing images, getting the first segmentation result; secondly, a fixed threshold is utilized to erase partial extracted information; thirdly, a multi-scale dense dilated convolution UNet (MD-UNet) is introduced to discover the complement road areas in the erased masks, obtaining the second segmentation result; and, finally, we fuse the extraction results of the first and the third modules, getting the final segmentation results. Experimental results on the Massachusetts Road dataset indicate that our C-UNet gets the higher results than the state-of-the-art methods, demonstrating its effectiveness.
KW  - UNet
KW  - complementary UNet
KW  - fixed threshold
KW  - dilated convolution
KW  - remote sensing
DO  - 10.3390/s21062153
TY  - EJOU
AU  - Akumu, Clement E.
AU  - Amadi, Eze O.
AU  - Dennis, Samuel
TI  - Application of Drone and WorldView-4 Satellite Data in Mapping and Monitoring Grazing Land Cover and Pasture Quality: Pre- and Post-Flooding
T2  - Land

PY  - 2021
VL  - 10
IS  - 3
SN  - 2073-445X

AB  - Frequent flooding worldwide, especially in grazing environments, requires mapping and monitoring grazing land cover and pasture quality to support land management. Although drones, satellite, and machine learning technologies can be used to map land cover and pasture quality, there have been limited applications in grazing land environments, especially monitoring land cover change and pasture quality pre- and post-flood events. The use of high spatial resolution drone and satellite data such as WorldView-4 can provide effective mapping and monitoring in grazing land environments. The aim of this study was to utilize high spatial resolution drone and WorldView-4 satellite data to map and monitor grazing land cover change and pasture quality pre-and post-flooding. The grazing land cover was mapped pre-flooding using WorldView-4 satellite data and post-flooding using real-time drone data. The machine learning Random Forest classification algorithm was used to delineate land cover types and the normalized difference vegetation index (NDVI) was used to monitor pasture quality. This study found a seven percent (7%) increase in pasture cover and a one hundred percent (100%) increase in pasture quality post-flooding. The drone and WorldView-4 satellite data were useful to detect grazing land cover change at a finer scale.
KW  - drone and satellite data
KW  - mapping grazing land cover change
KW  - flood event
DO  - 10.3390/land10030321
TY  - EJOU
AU  - Rufo, RubÃ©n
AU  - Soriano, Jose M.
AU  - Villegas, Dolors
AU  - Royo, Conxita
AU  - Bellvert, Joaquim
TI  - Using Unmanned Aerial Vehicle and Ground-Based RGB Indices to Assess Agronomic Performance of Wheat Landraces and Cultivars in a Mediterranean-Type Environment
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 6
SN  - 2072-4292

AB  - The adaptability and stability of new bread wheat cultivars that can be successfully grown in rainfed conditions are of paramount importance. Plant improvement can be boosted using effective high-throughput phenotyping tools in dry areas of the Mediterranean basin, where drought and heat stress are expected to increase yield instability. Remote sensing has been of growing interest in breeding programs since it is a cost-effective technology useful for assessing the canopy structure as well as the physiological traits of large genotype collections. The purpose of this study was to evaluate the use of a 4-band multispectral camera on-board an unmanned aerial vehicle (UAV) and ground-based RGB imagery to predict agronomic traits as well as quantify the best estimation of leaf area index (LAI) in rainfed conditions. A collection of 365 bread wheat genotypes, including 181 Mediterranean landraces and 184 modern cultivars, was evaluated during two consecutive growing seasons. Several vegetation indices (VI) derived from multispectral UAV and ground-based RGB images were calculated at different image acquisition dates of the crop cycle. The modified triangular vegetation index (MTVI2) proved to have a good accuracy to estimate LAI (R2 = 0.61). Although the stepwise multiple regression analysis showed that grain yield and number of grains per square meter (NGm2) were the agronomic traits most suitable to be predicted, the R2 were low due to field trials were conducted under rainfed conditions. Moreover, the prediction of agronomic traits was slightly better with ground-based RGB VI rather than with UAV multispectral VIs. NDVI and GNDVI, from multispectral images, were present in most of the prediction equations. Repeated measurements confirmed that the ability of VIs to predict yield depends on the range of phenotypic data. The current study highlights the potential use of VI and RGB images as an efficient tool for high-throughput phenotyping under rainfed Mediterranean conditions.
KW  - high-throughput phenotyping
KW  - drought stress
KW  - UAV imagery
KW  - ground-based RGB image
KW  - vegetation indices
KW  - phenology
KW  - grain yield
KW  - biomass
DO  - 10.3390/rs13061187
TY  - EJOU
AU  - Liu, Bi-Yuan
AU  - Chen, Huai-Xin
AU  - Huang, Zhou
AU  - Liu, Xing
AU  - Yang, Yun-Zhi
TI  - ZoomInNet: A Novel Small Object Detector in Drone Images with Cross-Scale Knowledge Distillation
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 6
SN  - 2072-4292

AB  - Drone-based object detection has been widely applied in ground object surveillance, urban patrol, and some other fields. However, the dramatic scale changes and complex backgrounds of drone images usually result in weak feature representation of small objects, which makes it challenging to achieve high-precision object detection. Aiming to improve small objects detection, this paper proposes a novel cross-scale knowledge distillation (CSKD) method, which enhances the features of small objects in a manner similar to image enlargement, so it is termed as ZoomInNet. First, based on an efficient feature pyramid network structure, the teacher and student network are trained with images in different scales to introduce the cross-scale feature. Then, the proposed layer adaption (LA) and feature level alignment (FA) mechanisms are applied to align the feature size of the two models. After that, the adaptive key distillation point (AKDP) algorithm is used to get the crucial positions in feature maps that need knowledge distillation. Finally, the position-aware L2 loss is used to measure the difference between feature maps from cross-scale models, realizing the cross-scale information compression in a single model. Experiments on the challenging Visdrone2018 dataset show that the proposed method draws on the advantages of the image pyramid methods, while avoids the large calculation of them and significantly improves the detection accuracy of small objects. Simultaneously, the comparison with mainstream methods proves that our method has the best performance in small object detection.
KW  - small object detection
KW  - drone image
KW  - image pyramid
KW  - feature enhancement
KW  - cross-scale knowledge distillation
DO  - 10.3390/rs13061198
TY  - EJOU
AU  - Park, Kyung H.
AU  - Park, Eunji
AU  - Kim, Huy K.
TI  - Unsupervised Fault Detection on Unmanned Aerial Vehicles: Encoding and Thresholding Approach
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 6
SN  - 1424-8220

AB  - Unmanned Aerial Vehicles are expected to create enormous benefits to society, but there are safety concerns in recognizing faults at the vehicleâs control component. Prior studies proposed various fault detection approaches leveraging heuristics-based rules and supervised learning-based models, but there were several drawbacks. The rule-based approaches required an engineer to update the rules on every type of fault, and the supervised learning-based approaches necessitated the acquisition of a finely-labeled training dataset. Moreover, both prior approaches commonly include a limit that the detection model can identify the trained type of faults only, but fail to recognize the unseen type of faults. In pursuit of resolving the aforementioned drawbacks, we proposed a fault detection model utilizing a stacked autoencoder that lies under unsupervised learning. The autoencoder was trained with data from safe UAV states, and its reconstruction loss was examined to distinguish the safe states and faulty states. The key contributions of our study are, as follows. First, we presented a series of analyses to extract essential features from raw UAV flight logs. Second, we designed a fault detection model consisting of the stacked autoencoder and the classifier. Lastly, we validated our approachâs fault detection performance with two datasets consisting of different types of UAV faults.
KW  - Unmanned Aerial Vehicle
KW  - fault detection
KW  - anomaly detection
KW  - unsupervised learning
KW  - autoencoder
DO  - 10.3390/s21062208
TY  - EJOU
AU  - Passafiume, Marco
AU  - Rojhani, Neda
AU  - Collodi, Giovanni
AU  - Cidronali, Alessandro
TI  - Modeling Small UAV Micro-Doppler Signature Using Millimeter-Wave FMCW Radar
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 6
SN  - 2079-9292

AB  - With the increase in small unmanned aerial vehicle (UAV) applications in several technology areas, detection and small UAVs classification have become of interest. To cope with small radar cross-sections (RCSs), slow-flying speeds, and low flying altitudes, the micro-Doppler signature provides some of the most distinctive information to identify and classify targets in many radar systems. In this paper, we introduce an effective model for the micro-Doppler effect that is suitable for frequency-modulated continuous-wave (FMCW) radar applications, and exploit it to investigate UAV signatures. The latter depends on the number of UAV motors, which are considered vibrational sources, and their rotation speed. To demonstrate the reliability of the proposed model, it is used to build simulated FMCW radar images, which are compared with experimental data acquired by a 77 GHz FMCW multiple-input multiple-output (MIMO) cost-effective automotive radar platform. The experimental results confirm the modelâs ability to estimate the class of the UAV, namely its number of motors, in different operative scenarios. In addition, the experimental results show that the motors rotation speed does not imprint a significant signature on the classification of the UAV; thus, the estimation of the number of motors represents the only viable parameter for small UAV classification using the micro-Doppler effect.
KW  - UAV classification
KW  - feature extraction
KW  - micro-Doppler signature
KW  - FMCW radar
KW  - automotive radar
DO  - 10.3390/electronics10060747
TY  - EJOU
AU  - Magstadt, Shayne
AU  - Gwenzi, David
AU  - Madurapperuma, Buddhika
TI  - Can a Remote Sensing Approach with Hyperspectral Data Provide Early Detection and Mapping of Spatial Patterns of Black Bear Bark Stripping in Coast Redwoods?
T2  - Forests

PY  - 2021
VL  - 12
IS  - 3
SN  - 1999-4907

AB  - The prevalence of black bear (Ursus americanus) bark stripping in commercial redwood (Sequoia sempervirens (D. Don) Endl.) timber stands has been increasing in recent years. This stripping is a threat to commercial timber production because of the deleterious effects on redwood tree fitness. This study sought to unveil a remote sensing method to detect these damaged trees early and map their spatial patterns. By developing a timely monitoring method, forest timber companies can manipulate their timber harvesting routines to adapt to the consequences of the problem. We explored the utility of high spatial resolution UAV-collected hyperspectral imagery as a means for early detection of individual trees stripped by black bears. A hyperspectral sensor was used to capture ultra-high spatial and spectral information pertaining to redwood trees with no damage, those that have been recently attacked by bears, and those with old bear damage. This spectral information was assessed using the Jeffries-Matusita (JM) distance to determine regions along the electromagnetic spectrum that are useful for discerning these three-health classes. While we were able to distinguish healthy trees from trees with old damage, we were unable to distinguish healthy trees from recently damaged trees due to the inherent characteristics of redwood tree growth and the subtle spectral changes within individual tree crowns for the time period assessed. The results, however, showed that with further assessment, a time window may be identified that informs damage before trees completely lose value.
KW  - bear bark stripping
KW  - redwoods
KW  - hyperspectral
KW  - UAV
KW  - support vector machine
KW  - vegetation indices
DO  - 10.3390/f12030378
TY  - EJOU
AU  - Delavarpour, Nadia
AU  - Koparan, Cengiz
AU  - Nowatzki, John
AU  - Bajwa, Sreekala
AU  - Sun, Xin
TI  - A Technical Study on UAV Characteristics for Precision Agriculture Applications and Associated Practical Challenges
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 6
SN  - 2072-4292

AB  - The incorporation of advanced technologies into Unmanned Aerial Vehicles (UAVs) platforms have enabled many practical applications in Precision Agriculture (PA) over the past decade. These PA tools offer capabilities that increase agricultural productivity and inputsâ efficiency and minimize operational costs simultaneously. However, these platforms also have some constraints that limit the application of UAVs in agricultural operations. The constraints include limitations in providing imagery of adequate spatial and temporal resolutions, dependency on weather conditions, and geometric and radiometric correction requirements. In this paper, a practical guide on technical characterizations of common types of UAVs used in PA is presented. This paper helps select the most suitable UAVs and on-board sensors for different agricultural operations by considering all the possible constraints. Over a hundred research studies were reviewed on UAVs applications in PA and practical challenges in monitoring and mapping field crops. We concluded by providing suggestions and future directions to overcome challenges in optimizing operational proficiency.
KW  - crop monitoring
KW  - drones
KW  - fixed-wings
KW  - hybrid UAVs
KW  - precision agriculture
KW  - remote sensing
KW  - rotary-wings
KW  - UAVs
KW  - Vertical Take-Off and Landing
DO  - 10.3390/rs13061204
TY  - EJOU
AU  - Colucci, Elisabetta
AU  - Xing, Xufeng
AU  - Kokla, Margarita
AU  - Mostafavi, Mir A.
AU  - Noardo, Francesca
AU  - SpanÃ², Antonia
TI  - Ontology-Based Semantic Conceptualisation of Historical Built Heritage to Generate Parametric Structured Models from Point Clouds
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 6
SN  - 2076-3417

AB  - Nowadays, cultural and historical built heritage can be more effectively preserved, valorised and documented using advanced geospatial technologies. In such a context, there is a major issue concerning the automation of the process and the extraction of useful information from a huge amount of spatial information acquired by means of advanced survey techniques (i.e., highly detailed LiDAR point clouds). In particular, in the case of historical built heritage (HBH) there are very few effective efforts. Therefore, in this paper, the focus is on establishing the connections between semantic and geometrical information in order to generate a parametric, structured model from point clouds using ontology as an effective approach for the formal conceptualisation of application domains. Hence, in this paper, an ontological schema is proposed to structure HBH representations, starting with international standards, vocabularies, and ontologies (CityGML-Geography Markup Language, International Committee for Documentation conceptual reference model (CIDOC-CRM), Industry Foundation Classes (IFC), Getty Art and Architecture Thesaurus (AAT), as well as reasoning about morphology of historical centres by analysis of real case studies) to represent the built and architecture domain. The validation of such schema is carried out by means of its use to guide the segmentation of a LiDAR point cloud from a castle, which is later used to generate parametric geometries to be used in a historical building information model (HBIM).
KW  - ontology
KW  - semantic segmentation
KW  - conceptualisation
KW  - HBH (historical built heritage)
KW  - point clouds
KW  - parametric models
KW  - HBIM (historical building modelling)
DO  - 10.3390/app11062813
TY  - EJOU
AU  - Li, Ke
AU  - Zhang, Kun
AU  - Zhang, Zhenchong
AU  - Liu, Zekun
AU  - Hua, Shuai
AU  - He, Jianliang
TI  - A UAV Maneuver Decision-Making Algorithm for Autonomous Airdrop Based on Deep Reinforcement Learning
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 6
SN  - 1424-8220

AB  - How to operate an unmanned aerial vehicle (UAV) safely and efficiently in an interactive environment is challenging. A large amount of research has been devoted to improve the intelligence of a UAV while performing a mission, where finding an optimal maneuver decision-making policy of the UAV has become one of the key issues when we attempt to enable the UAV autonomy. In this paper, we propose a maneuver decision-making algorithm based on deep reinforcement learning, which generates efficient maneuvers for a UAV agent to execute the airdrop mission autonomously in an interactive environment. Particularly, the training set of the learning algorithm by the Prioritized Experience Replay is constructed, that can accelerate the convergence speed of decision network training in the algorithm. It is shown that a desirable and effective maneuver decision-making policy can be found by extensive experimental results.
KW  - UAV
KW  - maneuver decision-making
KW  - autonomous airdrop
KW  - deep reinforcement learning
KW  - prioritized experience replay
DO  - 10.3390/s21062233
TY  - EJOU
AU  - Kaivosoja, Jere
AU  - Hautsalo, Juho
AU  - Heikkinen, Jaakko
AU  - Hiltunen, Lea
AU  - Ruuttunen, Pentti
AU  - NÃ¤si, Roope
AU  - NiemelÃ¤inen, Oiva
AU  - Lemsalu, Madis
AU  - Honkavaara, Eija
AU  - Salonen, Jukka
TI  - Reference Measurements in Developing UAV Systems for Detecting Pests, Weeds, and Diseases
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 7
SN  - 2072-4292

AB  - The development of UAV (unmanned aerial vehicle) imaging technologies for precision farming applications is rapid, and new studies are published frequently. In cases where measurements are based on aerial imaging, there is the need to have ground truth or reference data in order to develop reliable applications. However, in several precision farming use cases such as pests, weeds, and diseases detection, the reference data can be subjective or relatively difficult to capture. Furthermore, the collection of reference data is usually laborious and time consuming. It also appears that it is difficult to develop generalisable solutions for these areas. This review studies previous research related to pests, weeds, and diseases detection and mapping using UAV imaging in the precision farming context, underpinning the applied reference measurement techniques. The majority of the reviewed studies utilised subjective visual observations of UAV images, and only a few applied in situ measurements. The conclusion of the review is that there is a lack of quantitative and repeatable reference data measurement solutions in the areas of mapping pests, weeds, and diseases. In addition, the results that the studies present should be reflected in the applied references. An option in the future approach could be the use of synthetic data as reference.
KW  - UAS
KW  - drone
KW  - unmanned aerial vehicle
KW  - in situ
KW  - reference data
KW  - ground truth
KW  - monitoring
KW  - precision agriculture
KW  - smart farming
DO  - 10.3390/rs13071238
TY  - EJOU
AU  - Oliveira, Luiz F. P.
AU  - Moreira, AntÃ³nio P.
AU  - Silva, Manuel F.
TI  - Advances in Agriculture Robotics: A State-of-the-Art Review and Challenges Ahead
T2  - Robotics

PY  - 2021
VL  - 10
IS  - 2
SN  - 2218-6581

AB  - The constant advances in agricultural robotics aim to overcome the challenges imposed by population growth, accelerated urbanization, high competitiveness of high-quality products, environmental preservation and a lack of qualified labor. In this sense, this review paper surveys the main existing applications of agricultural robotic systems for the execution of land preparation before planting, sowing, planting, plant treatment, harvesting, yield estimation and phenotyping. In general, all robots were evaluated according to the following criteria: its locomotion system, what is the final application, if it has sensors, robotic arm and/or computer vision algorithm, what is its development stage and which country and continent they belong. After evaluating all similar characteristics, to expose the research trends, common pitfalls and the characteristics that hinder commercial development, and discover which countries are investing into Research and Development (R&amp;D) in these technologies for the future, four major areas that need future research work for enhancing the state of the art in smart agriculture were highlighted: locomotion systems, sensors, computer vision algorithms and communication technologies. The results of this research suggest that the investment in agricultural robotic systems allows to achieve shortâharvest monitoringâand long-term objectivesâyield estimation.
KW  - agricultural robots
KW  - agriculture 4.0
KW  - precision agriculture
DO  - 10.3390/robotics10020052
TY  - EJOU
AU  - Liu, Chuanyang
AU  - Wu, Yiquan
AU  - Liu, Jingjing
AU  - Sun, Zuo
TI  - Improved YOLOv3 Network for Insulator Detection in Aerial Images with Diverse Background Interference
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 7
SN  - 2079-9292

AB  - Automatic inspection of insulators from high-voltage transmission lines is of paramount importance to the safety and reliable operation of the power grid. Due to different size insulators and the complex background of aerial images, it is a difficult task to recognize insulators in aerial views. Most of the traditional image processing methods and machine learning methods cannot achieve sufficient performance for insulator detection when diverse background interference is present. In this study, a deep learning methodâbased on You Only Look Once (YOLO)âwill be proposed, capable of detecting insulators from aerial images with complex backgrounds. Firstly, aerial images with common aerial scenes were collected by Unmanned Aerial Vehicle (UAV), and a novel insulator dataset was constructed. Secondly, to enhance feature reuse and propagation, on the basis of YOLOv3 and Dense-Blocks, the YOLOv3-dense network was utilized for insulator detection. To improve detection accuracy for different sized insulators, a structure of multiscale feature fusion was adapted to the YOLOv3-dense network. To obtain abundant semantic information of upper and lower layers, multilevel feature mapping modules were employed across the YOLOv3-dense network. Finally, the YOLOv3-dense network and compared networks were trained and tested on the testing set. The average precision of YOLOv3-dense, YOLOv3, and YOLOv2 were 94.47%, 90.31%, and 83.43%, respectively. Experimental results and analysis validate the claim that the proposed YOLOv3-dense network achieves good performance in the detection of different size insulators amid diverse background interference.
KW  - aerial image
KW  - insulator detection
KW  - YOLO
KW  - background interference
KW  - image processing
KW  - deep learning
KW  - Dense-Block
DO  - 10.3390/electronics10070771
TY  - EJOU
AU  - He, Shaokun
AU  - Gu, Lei
AU  - Tian, Jing
AU  - Deng, Lele
AU  - Yin, Jiabo
AU  - Liao, Zhen
AU  - Zeng, Ziyue
AU  - Shen, Youjiang
AU  - Hui, Yu
TI  - Machine Learning Improvement of Streamflow Simulation by Utilizing Remote Sensing Data and Potential Application in Guiding Reservoir Operation
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 7
SN  - 2071-1050

AB  - Hydro-meteorological datasets are key components for understanding physical hydrological processes, but the scarcity of observational data hinders their potential application in poorly gauged regions. Satellite-retrieved and atmospheric reanalysis products exhibit considerable advantages in filling the spatial gaps in in-situ gauging networks and are thus forced to drive the physically lumped hydrological models for long-term streamflow simulation in data-sparse regions. As machine learning (ML)-based techniques can capture the relationship between different elements, they may have potential in further exploring meteorological predictors and hydrological responses. To examine the application prospects of a physically constrained ML algorithm using earth observation data, we used a short-series hydrological observation of the Hanjiang River basin in China as a case study. In this study, the prevalent modÃ¨le du GÃ©nie Rural Ã  9 paramÃ¨tres Journalier (GR4J-9) hydrological model was used to initially simulate streamflow, and then, the simulated series and remote sensing data were used to train the long short-term memory (LSTM) method. The results demonstrated that the advanced GR4J9âLSTM model chain effectively improves the performance of the streamflow simulation by using more remote sensing data related to the hydrological response variables. Additionally, we derived a reservoir operation model by feeding the LSTM-based simulation outputs, which further revealed the potential application of our proposed technique.
KW  - ungauged basin
KW  - machine learning
KW  - streamflow simulation
KW  - satellite precipitation
KW  - atmospheric reanalysis
DO  - 10.3390/su13073645
TY  - EJOU
AU  - Peinado, Jairo
AU  - Jiao-Wang, Liu
AU  - Olmedo, Ãlvaro
AU  - Santiuste, Carlos
TI  - Use of Artificial Neural Networks to Optimize Stacking Sequence in UHMWPE Protections
T2  - Polymers

PY  - 2021
VL  - 13
IS  - 7
SN  - 2073-4360

AB  - The aim of the present work is to provide a methodology to evaluate the influence of stacking sequence on the ballistic performance of ultra-high molecular weight polyethylene (UHMWPE) protections. The proposed methodology is based on the combination of experimental tests, numerical modelling, and Artificial Neural Networks (ANN). High-velocity impact experimental tests were conducted to validate the numerical model. The validated Finite Element Method (FEM) model was used to provide data to train and to validate the ANN. Finally, the ANN was used to find the best stacking sequence combining layers of three UHMWPE materials with different qualities. The results showed that the three UHMWPE materials can be properly combined to provide a solution with a better ballistic performance than using only the material with highest quality. These results imply that costs can be reduced increasing the ballistic limit of the UHMWPE protections. When the weight ratios of the three materials remain constant, the optimal results occur when the highest-performance material is placed in the back face. Furthermore, ANN simulation showed that the optimal results occur when the weight ratio of the highest-performance material is 79.2%.
KW  - UHMWPE
KW  - impact
KW  - FEM
KW  - neural networks
DO  - 10.3390/polym13071012
TY  - EJOU
AU  - LÃ³pez-Andreu, Francisco J.
AU  - Erena, Manuel
AU  - Dominguez-GÃ³mez, Jose A.
AU  - LÃ³pez-Morales, Juan A.
TI  - Sentinel-2 Images and Machine Learning as Tool for Monitoring of the Common Agricultural Policy: Calasparra Rice as a Case Study
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 4
SN  - 2073-4395

AB  - The European Commission introduces the Control by Monitoring through new technologies to manage Common Agricultural Policy funds through the Regulation 2018/746. The advances in remote sensing have been considered one of these new technologies, mainly since the European Space Agency designed the Copernicus Programme. The Sentinel-1 (radar range) and Sentinel-2 (optical range) satellites have been designed for monitoring agricultural problems based on the characteristics they provide. The data provided by the Sentinel 2 missions, together with the emergence of different scientific disciplines in artificial intelligence âespecially machine learningâ offer the perfect basis for identifying and classifying any crop and its phenological state. Our research is based on developing and evaluating a pixel-based supervised classification scheme to produce accurate rice crop mapping in a smallholder agricultural zone in Calasparra, Murcia, Spain. Several models are considered to obtain the most suitable model for each element of the time series used; pixel-based classification is performed and finished with a statistical treatment. The highly accurate results obtained, especially across the most significant vegetative development dates, indicate the benefits of using Sentinel-2 data combined with Machine Learning techniques to identify rice crops. It should be noted that it was possible to locate rice crop areas with an overall accuracy of 94% and standard deviation of 1%, which could be increased to 96% (Â±1%) if we focus on the months of the cropâs highest development state. Thanks to the proposed methodology, the on-site inspections carried out, 5% of the files, have been replaced by remote sensing evaluations of 100% of the analyzed season files. Besides, by adjusting the model input data, it is possible to detect unproductive or abandoned plots.
KW  - multispectral remote sensing
KW  - Copernicus
KW  - sentinel
KW  - image processing
KW  - machine learning
KW  - agriculture
KW  - land cover
KW  - rice crop
KW  - common agricultural policy
DO  - 10.3390/agronomy11040621
TY  - EJOU
AU  - Shahbazi, Nooshin
AU  - Ashworth, Michael B.
AU  - Callow, J. N.
AU  - Mian, Ajmal
AU  - Beckie, Hugh J.
AU  - Speidel, Stuart
AU  - Nicholls, Elliot
AU  - Flower, Ken C.
TI  - Assessing the Capability and Potential of LiDAR for Weed Detection
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 7
SN  - 1424-8220

AB  - Conventional methods of uniformly spraying fields to combat weeds, requires large herbicide inputs at significant cost with impacts on the environment. More focused weed control methods such as site-specific weed management (SSWM) have become popular but require methods to identify weed locations. Advances in technology allows the potential for automated methods such as drone, but also ground-based sensors for detecting and mapping weeds. In this study, the capability of Light Detection and Ranging (LiDAR) sensors were assessed to detect and locate weeds. For this purpose, two trials were performed using artificial targets (representing weeds) at different heights and diameter to understand the detection limits of a LiDAR. The results showed the detectability of the target at different scanning distances from the LiDAR was directly influenced by the size of the target and its orientation toward the LiDAR. A third trial was performed in a wheat plot where the LiDAR was used to scan different weed species at various heights above the crop canopy, to verify the capacity of the stationary LiDAR to detect weeds in a field situation. The results showed that 100% of weeds in the wheat plot were detected by the LiDAR, based on their height differences with the crop canopy.
KW  - light detection and ranging (LiDAR) sensors
KW  - weed detection
KW  - target size
KW  - scanning distance
KW  - target orientation
DO  - 10.3390/s21072328
TY  - EJOU
AU  - SÃ¡nchez, JosÃ© D.
AU  - Urquiza-Aguiar, Luis
AU  - Paredes Paredes, Martha C.
TI  - Fading Channel Models for mm-Wave Communications
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 7
SN  - 2079-9292

AB  - A realistic performance assessment of any wireless communication system requires the use of a fading channel model that reflects its main characteristics. The traditional Rayleigh and Nakagami-m models have been (and still are) the basis of most theoretical research on wireless technologies today, even for emerging technologies, such as millimeter-wave communications (mm-Wave). In this article, we show that the fluctuating multiple-ray (FMR) and Îº-Î¼ shadowed models had a better fit (i.e., lowest mean square error statistical test) to field measurements in outdoor environments at 28 GHz than the conventional channel models. Therefore, these generalized models are feasible alternatives that can be used as a benchmark when evaluating communication performance in mm-Wave scenarios.
KW  - generalized fading channels
KW  - mm-Wave
KW  - Îº-Î¼ shadowed
KW  - fluctuating multiple-ray model
DO  - 10.3390/electronics10070798
TY  - EJOU
AU  - Li, Tong
AU  - Cui, Lizhen
AU  - Xu, Zhihong
AU  - Hu, Ronghai
AU  - Joshi, Pawan K.
AU  - Song, Xiufang
AU  - Tang, Li
AU  - Xia, Anquan
AU  - Wang, Yanfen
AU  - Guo, Da
AU  - Zhu, Jiapei
AU  - Hao, Yanbin
AU  - Song, Lan
AU  - Cui, Xiaoyong
TI  - Quantitative Analysis of the Research Trends and Areas in Grassland Remote Sensing: A Scientometrics Analysis of Web of Science from 1980 to 2020
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 7
SN  - 2072-4292

AB  - Grassland remote sensing (GRS) is an important research topic that applies remote sensing technology to grassland ecosystems, reflects the number of grassland resources and grassland health promptly, and provides inversion information used in sustainable development management. A scientometrics analysis based on Science Citation Index-Expanded (SCI-E) was performed to understand the research trends and areas of focus in GRS research studies. A total of 2692 papers related to GRS research studies and 82,208 references published from 1980 to 2020 were selected as the research objects. A comprehensive overview of the field based on the annual documents, research areas, institutions, influential journals, core authors, and temporal trends in keywords were presented in this study. The results showed that the annual number of documents increased exponentially, and more than 100 papers were published each year since 2010. Remote sensing, environmental sciences, and ecology were the most popular Web of Science research areas. The journal Remote Sensing was one of the most popular for researchers to publish documents and shows high development and publishing potential in GRS research studies. The institution with the greatest research documents and most citations was the Chinese Academy of Sciences. Guo X.L., Hill M.J., and Zhang L. were the most productive authors across the 40-year study period in terms of the number of articles published. Seven clusters of research areas were identified that generated contributions to this topic by keyword co-occurrence analysis. We also detected 17 main future directions of GRS research studies by document co-citation analysis. Emerging or underutilized methodologies and technologies, such as unmanned aerial systems (UASs), cloud computing, and deep learning, will continue to further enhance GRS research in the process of achieving sustainable development goals. These results can help related researchers better understand the past and future of GRS research studies.
KW  - grassland
KW  - remote sensing
KW  - CiteSpace
KW  - scientometrics analysis
KW  - research progress
KW  - network analysis
KW  - visualization
KW  - Web of Science
DO  - 10.3390/rs13071279
TY  - EJOU
AU  - Grekhov, Andrii
AU  - Kondratiuk, Vasyl
AU  - Ilnytska, Svitlana
TI  - Data Traffic Modeling in RPAS/UAV Networks with Different Architectures
T2  - Modelling

PY  - 2021
VL  - 2
IS  - 2
SN  - 2673-3951

AB  - Deploying of Fifth Generation and Beyond Fifth Generation (5G/B5G) wireless networks will require wider coverage, flexible connectivity, low latency, support for a large number of user devices, and more bandwidth. This article explores the paradigm that Remotely Piloted Air Systems (RPASs) or Unmanned Aerial Vehicles (UAVs) are integrated as a communication platform with cellular networks using radio access. It is important to know the possibilities and ways of such integration for effective interaction with RPASs. This paper studies the issues of ensuring the required Quality of Service (QoS) during heavy traffic and the choice of necessary data transmission modes for this. Models of RPAS communication channels with different architectures were created. The relationships between modelsâ performance and traffic parameters were obtained using the NetCracker Professional 4.1 software. The dependencies of the Average Utilization (AU) on the Transaction Size (TS) were analyzed. The effects of different bandwidths and the Bit Error Rate (BER) were studied. The traffic characteristics in all models were compared.
KW  - remotely piloted air systems (RPAS)
KW  - unmanned aerial vehicles (UAVs)
KW  - 5G/B5G
KW  - data traffic
KW  - transaction size
KW  - average utilization
KW  - BER
KW  - bandwidth
DO  - 10.3390/modelling2020011
TY  - EJOU
AU  - Campos, Javier
AU  - GarcÃ­a-RuÃ­z, Francisco
AU  - Gil, Emilio
TI  - Assessment of Vineyard Canopy Characteristics from Vigour Maps Obtained Using UAV and Satellite Imagery
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 7
SN  - 1424-8220

AB  - Canopy characterisation is a key factor for the success and efficiency of the pesticide application process in vineyards. Canopy measurements to determine the optimal volume rate are currently conducted manually, which is time-consuming and limits the adoption of precise methods for volume rate selection. Therefore, automated methods for canopy characterisation must be established using a rapid and reliable technology capable of providing precise information about crop structure. This research providedregression models for obtaining canopy characteristics of vineyards from unmanned aerial vehicle (UAV) and satellite images collected in three significant growth stages. Between 2018 and 2019, a total of 1400 vines were characterised manually and remotely using a UAV and a satellite-based technology. The information collected from the sampled vines was analysed by two different procedures. First, a linear relationship between the manual and remote sensing data was investigated considering every single vine as a data point. Second, the vines were clustered based on three vigour levels in the parcel, and regression models were fitted to the average values of the ground-based and remote sensing-estimated canopy parameters. Remote sensing could detect the changes in canopy characteristics associated with vegetation growth. The combination of normalised differential vegetation index (NDVI) and projected area extracted from the UAV images is correlated with the tree row volume (TRV) when raw point data were used. This relationship was improved and extended to canopy height, width, leaf wall area, and TRV when the data were clustered. Similarly, satellite-based NDVI yielded moderate coefficients of determination for canopy width with raw point data, and for canopy width, height, and TRV when the vines were clustered according to the vigour. The proposed approach should facilitate the estimation of canopy characteristics in each area of a field using a cost-effective, simple, and reliable technology, allowing variable rate application in vineyards.
KW  - vineyard
KW  - pesticide application
KW  - variable rate application
KW  - unmanned aerial vehicle
KW  - satellite
KW  - nanosatellite
DO  - 10.3390/s21072363
TY  - EJOU
AU  - Xu, Danqing
AU  - Wu, Yiquan
TI  - FE-YOLO: A Feature Enhancement Network for Remote Sensing Target Detection
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 7
SN  - 2072-4292

AB  - In the past few decades, target detection from remote sensing images gained from aircraft or satellites has become one of the hottest topics. However, the existing algorithms are still limited by the detection of small remote sensing targets. Benefiting from the great development of computing power, deep learning has also made great breakthroughs. Due to a large number of small targets and complexity of background, the task of remote sensing target detection is still a challenge. In this work, we establish a series of feature enhancement modules for the network based on YOLO (You Only Look Once) -V3 to improve the performance of feature extraction. Therefore, we term our proposed network as FE-YOLO. In addition, to realize fast detection, the original Darknet-53 was simplified. Experimental results on remote sensing datasets show that our proposed FE-YOLO performs better than other state-of-the-art target detection models.
KW  - target detection
KW  - remote sensing images
KW  - YOLO-V3
KW  - feature enhancement
KW  - deep learning
DO  - 10.3390/rs13071311
TY  - EJOU
AU  - You, Hojun
AU  - Kim, Dongsu
TI  - Development of an Image Registration Technique for Fluvial Hyperspectral Imagery Using an Optical Flow Algorithm
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 7
SN  - 1424-8220

AB  - Fluvial remote sensing has been used to monitor diverse riverine properties through processes such as river bathymetry and visual detection of suspended sediment, algal blooms, and bed materials more efficiently than laborious and expensive in-situ measurements. Redâgreenâblue (RGB) optical sensors have been widely used in traditional fluvial remote sensing. However, owing to their three confined bands, they rely on visual inspection for qualitative assessments and are limited to performing quantitative and accurate monitoring. Recent advances in hyperspectral imaging in the fluvial domain have enabled hyperspectral images to be geared with more than 150 spectral bands. Thus, various riverine properties can be quantitatively characterized using sensors in low-altitude unmanned aerial vehicles (UAVs) with a high spatial resolution. Many efforts are ongoing to take full advantage of hyperspectral band information in fluvial research. Although geo-referenced hyperspectral images can be acquired for satellites and manned airplanes, few attempts have been made using UAVs. This is mainly because the synthesis of line-scanned images on top of image registration using UAVs is more difficult owing to the highly sensitive and heavy image driven by dense spatial resolution. Therefore, in this study, we propose a practical technique for achieving high spatial accuracy in UAV-based fluvial hyperspectral imaging through efficient image registration using an optical flow algorithm. Template matching algorithms are the most common image registration technique in RGB-based remote sensing; however, they require many calculations and can be error-prone depending on the user, as decisions regarding various parameters are required. Furthermore, the spatial accuracy of this technique needs to be verified, as it has not been widely applied to hyperspectral imagery. The proposed technique resulted in an average reduction of spatial errors by 91.9%, compared to the case where the image registration technique was not applied, and by 78.7% compared to template matching.
KW  - fluvial remote sensing
KW  - hyperspectral imagery
KW  - optical flow
KW  - image registration
DO  - 10.3390/s21072407
TY  - EJOU
AU  - Wang, Fei
AU  - Liu, Zhendong
AU  - Zhu, Hongchun
AU  - Wu, Pengda
AU  - Li, Chengming
TI  - An Improved Method for Stable Feature Points Selection in Structure-from-Motion Considering Image Semantic and Structural Characteristics
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 7
SN  - 1424-8220

AB  - Feature matching plays a crucial role in the process of 3D reconstruction based on the structure from motion (SfM) technique. For a large collection of oblique images, feature matching is one of the most time-consuming steps, and the matching result directly affects the accuracy of subsequent tasks. Therefore, how to extract the reasonable feature points robustly and efficiently to improve the matching speed and quality has received extensive attention from scholars worldwide. Most studies perform quantitative feature point selection based on image Difference-of-Gaussian (DoG) pyramids in practice. However, the stability and spatial distribution of feature points are not considered enough, resulting in selected feature points that may not adequately reflect the scene structures and cannot guarantee the matching rate and the aerial triangulation accuracy. To address these issues, an improved method for stable feature point selection in SfM considering image semantic and structural characteristics is proposed. First, the visible-band difference vegetation index is used to identify the vegetation areas from oblique images, and the line feature in the image is extracted by the optimized line segment detector algorithm. Second, the feature point two-tuple classification model is established, in which the vegetation area recognition result is used as the semantic constraint, the line feature extraction result is used as the structural constraint, and the feature points are divided into three types. Finally, a progressive selection algorithm for feature points is proposed, in which feature points in the DoG pyramid are selected by classes and levels until the number of feature points is satisfied. Oblique images of a 40-km2 area in Dongying city, China, were used for validation. The experimental results show that compared to the state-of-the-art method, the method proposed in this paper not only effectively reduces the number of feature points but also better reflects the scene structure. At the same time, the average reprojection error of the aerial triangulation decrease by 20%, the feature point matching rate increase by 3%, the selected feature points are more stable and reasonable.
KW  - 3D reconstruction
KW  - oblique images
KW  - feature point selection
KW  - image semantic and structural characteristics
KW  - two-tuple classification model
DO  - 10.3390/s21072416
TY  - EJOU
AU  - AraÃºjo, Sara O.
AU  - Peres, Ricardo S.
AU  - Barata, JosÃ©
AU  - Lidon, Fernando
AU  - Ramalho, JosÃ© C.
TI  - Characterising the Agriculture 4.0 LandscapeâEmerging Trends, Challenges and Opportunities
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 4
SN  - 2073-4395

AB  - Investment in technological research is imperative to stimulate the development of sustainable solutions for the agricultural sector. Advances in Internet of Things, sensors and sensor networks, robotics, artificial intelligence, big data, cloud computing, etc. foster the transition towards the Agriculture 4.0 era. This fourth revolution is currently seen as a possible solution for improving agricultural growth, ensuring the future needs of the global population in a fair, resilient and sustainable way. In this context, this article aims at characterising the current Agriculture 4.0 landscape. Emerging trends were compiled using a semi-automated process by analysing relevant scientific publications published in the past ten years. Subsequently, a literature review focusing these trends was conducted, with a particular emphasis on their applications in real environments. From the results of the study, some challenges are discussed, as well as opportunities for future research. Finally, a high-level cloud-based IoT architecture is presented, serving as foundation for designing future smart agricultural systems. It is expected that this work will positively impact the research around Agriculture 4.0 systems, providing a clear characterisation of the concept along with guidelines to assist the actors in a successful transition towards the digitalisation of the sector.
KW  - Agriculture 4.0
KW  - artificial intelligence
KW  - cloud computing
KW  - decision support system
KW  - internet of things
KW  - robotics
KW  - sensors
DO  - 10.3390/agronomy11040667
TY  - EJOU
AU  - Appeltans, Simon
AU  - Pieters, Jan G.
AU  - Mouazen, Abdul M.
TI  - Detection of Leek Rust Disease under Field Conditions Using Hyperspectral Proximal Sensing and Machine Learning
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 7
SN  - 2072-4292

AB  - Rust disease is an important problem for leek cultivation worldwide. It reduces market value and in extreme cases destroys the entire harvest. Farmers have to resort to periodical full-field fungicide applications to prevent the spread of disease, once every 1 to 5 weeks, depending on the cultivar and weather conditions. This implies an economic cost for the farmer and an environmental cost for society. Hyperspectral sensors have been extensively used to address this issue in research, but their application in the field has been limited to a relatively low number of crops, excluding leek, due to the high investment costs and complex data gathering and analysis associated with these sensors. To fill this gap, a methodology was developed for detecting leek rust disease using hyperspectral proximal sensing data combined with supervised machine learning. First, a hyperspectral library was constructed containing 43,416 spectra with a waveband range of 400â1000 nm, measured under field conditions. Then, an extensive evaluation of 11 common classifiers was performed using the scikit-learn machine learning library in Python, combined with a variety of wavelength selection techniques and preprocessing strategies. The best performing model was a (linear) logistic regression model that was able to correctly classify rust disease with an accuracy of 98.14%, using reflectance values at 556 and 661 nm, combined with the value of the first derivative at 511 nm. This model was used to classify unlabelled hyperspectral images, confirming that the model was able to accurately classify leek rust disease symptoms. It can be concluded that the results in this work are an important step towards the mapping of leek rust disease, and that future research is needed to overcome certain challenges before variable rate fungicide applications can be adopted against leek rust disease.
KW  - hyperspectral
KW  - proximal sensing
KW  - disease detection
KW  - leek
KW  - rust
KW  - machine learning
DO  - 10.3390/rs13071341
TY  - EJOU
AU  - Li, Changlong
AU  - Li, Zengyuan
AU  - Gao, Zhihai
AU  - Sun, Bin
TI  - Estimation of Evapotranspiration in Sparse Vegetation Areas by Applying an Optimized Two-Source Model
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 7
SN  - 2072-4292

AB  - Evapotranspiration (ET) is an important part of the water, carbon, and energy cycles in ecosystems, especially in the drylands. However, due to the particularity of sparse vegetation, the estimation accuracy of ET has been relatively low in the drylands. Therefore, based on the dry climate and sparse vegetation distribution characteristics of the drylands, this study optimized the core algorithms (canopy boundary resistance, aerodynamic resistance, and sparse vegetation coverage) and explored an ET estimation method in the ShuttleworthâWallace two-layer model (SW model). Then, the BeijingâTianjin sandstorm source region (BTSSR) was used as the study area to evaluate the applicability of the improved model in the drylands. Results show that: (1) The R2 value of the improved model results was increased by 1.4 and the RMSE was reduced by 1.9 mm, especially in extreme value regions of ET (maximum or minimum). (2) Regardless of the spatial distribution and seasonal changes of the ET (63â790 mm), the improved ET estimation model could accurately capture the differences. Furtherly, the different vegetation regions could stand for the different climate regions to a certain extent. The accuracy of the optimized model was higher in the semi-arid region (R2 = 0.92 and 0.93), while the improved model had the best improvement effect in the arid region, with R2 increasing by 0.12. (3) Precipitation was the decisive factor affecting vegetation transpiration and ET, with R2 value for both exceeding 0.9. The effect of vegetation coverage (VC) was less. This method is expected to provide a more accurate and adaptable model for the estimation of ET in the drylands.
KW  - ShuttleworthâWallace two-layer model
KW  - BeijingâTianjin sandstorm source region
KW  - vegetation transpiration
KW  - soil water evaporation
KW  - evapotranspiration
DO  - 10.3390/rs13071344
TY  - EJOU
AU  - Li, Bonan
AU  - Good, Stephen P.
AU  - URycki, Dawn R.
TI  - The Value of L-Band Soil Moisture and Vegetation Optical Depth Estimates in the Prediction of Vegetation Phenology
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 7
SN  - 2072-4292

AB  - Vegetation phenology is a key ecosystem characteristic that is sensitive to environmental conditions. Here, we examined the utility of soil moisture (SM) and vegetation optical depth (VOD) observations from NASAâs L-band Soil Moisture Active Passive (SMAP) mission for the prediction of leaf area index (LAI), a common metric of canopy phenology. We leveraged mutual information theory to determine whether SM and VOD contain information about the temporal dynamics of LAI that is not contained in traditional LAI predictors (i.e., precipitation, temperature, and radiation) and known LAI climatology. We found that adding SMAP SM and VOD to multivariate non-linear empirical models to predict daily LAI anomalies improved model fit and reduced error by 5.2% compared with models including only traditional LAI predictors and LAI climatology (average R2 = 0.22 vs. 0.15 and unbiased root mean square error [ubRMSE] = 0.130 vs. 0.137 for cross-validated models with and without SM and VOD, respectively). SMAP SM and VOD made the more improvement in model fit in grasslands (R2 = 0.24 vs. 0.16 and ubRMSE = 0.118 vs. 0.126 [5.7% reduction] for models with and without SM and VOD, respectively); model predictions were least improved in shrublands. Analysis of feature importance indicates that LAI climatology and temperature were overall the two most informative variables for LAI anomaly prediction. SM was more important in drier regions, whereas VOD was consistently the second least important factor. Variations in total LAI were mostly explained by local daily LAI climatology. On average, the R2s and ubRMSE of total LAI predictions by the traditional drivers and its climatology are 0.81 and 0.137, respectively. Adding SMAP SM and VOD to these existing predictors improved the R2s to 0.83 (0.02 improvement in R2s) and reduced the ubRMSE to 0.13 (5.2% reduction). Though these improvements were modest on average, in locations where LAI climatology is not reflective of LAI dynamics and anomalies are larger, we find SM and VOD to be considerably more useful for LAI prediction. Overall, we find that L-band SM and VOD observations can be useful for prediction of LAI, though the informational contribution varies with land cover and environmental conditions.
KW  - SMAP
KW  - soil moisture
KW  - vegetation optical depth
KW  - regression
DO  - 10.3390/rs13071343
TY  - EJOU
AU  - NeuwirthovÃ¡, Eva
AU  - Kuusk, Andres
AU  - LhotÃ¡kovÃ¡, Zuzana
AU  - Kuusk, Joel
AU  - AlbrechtovÃ¡, Jana
AU  - Hallik, Lea
TI  - Leaf Age Matters in Remote Sensing: Taking Ground Truth for Spectroscopic Studies in Hemiboreal Deciduous Trees with Continuous Leaf Formation
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 7
SN  - 2072-4292

AB  - We examined the seasonal changes in biophysical, anatomical, and optical traits of young leaves, formed throughout the vegetative season due to sylleptic growth, and mature leaves formed by proleptic growth in spring. Leaf developmental categories contribute to the top-of-canopy reflectance and should be considered when taking ground truth for remote sensing studies (RS). Deciduous tree species, Betula pendula, Populus tremula, and Alnus incana, were sampled from May to October 2018 in an Estonian hemiboreal forest. Chlorophyll and carotenoid content were detected biochemically; leaf anatomical traits (leaf, palisade, and spongy mesophyll thickness) were measured on leaf cross-sections; leaf reflectance was measured by a spectroradiometer with an integrating sphere (350â2500 nm). Biophysical and anatomical leaf traits were related to 64 vegetation indices (VIs). Linear models based on VIs for all tested leaf traits were more robust if both juvenile and mature leaves were included. This study provides information on which VIs are interchangeable or independent. Pigment and leaf thickness sensitive indices formed PC1; water and structural trait related VIs formed an independent group associated with PC3. Type of growth and leaf age could affect the validation of biophysical and anatomical leaf trait retrieval from the optical signal. It is, therefore, necessary to sample both leaf developmental categoriesâyoung and matureâin RS, especially if sampling is only once within the vegetation season.
KW  - sylleptic growth
KW  - asynchrony development
KW  - phenology
KW  - pigments
KW  - leaf anatomy
KW  - Betula pendula
KW  - Populus tremula
KW  - Alnus incana
KW  - vegetation indices
KW  - PCA
DO  - 10.3390/rs13071353
TY  - EJOU
AU  - VÃ©lez-NicolÃ¡s, Mercedes
AU  - GarcÃ­a-LÃ³pez, Santiago
AU  - Barbero, Luis
AU  - Ruiz-Ortiz, VerÃ³nica
AU  - SÃ¡nchez-BellÃ³n, Ãngel
TI  - Applications of Unmanned Aerial Systems (UASs) in Hydrology: A Review
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 7
SN  - 2072-4292

AB  - In less than two decades, UASs (unmanned aerial systems) have revolutionized the field of hydrology, bridging the gap between traditional satellite observations and ground-based measurements and allowing the limitations of manned aircraft to be overcome. With unparalleled spatial and temporal resolutions and product-tailoring possibilities, UAS are contributing to the acquisition of large volumes of data on water bodies, submerged parameters and their interactions in different hydrological contexts and in inaccessible or hazardous locations. This paper provides a comprehensive review of 122 works on the applications of UASs in surface water and groundwater research with a purpose-oriented approach. Concretely, the review addresses: (i) the current applications of UAS in surface and groundwater studies, (ii) the type of platforms and sensors mainly used in these tasks, (iii) types of products generated from UAS-borne data, (iv) the associated advantages and limitations, and (v) knowledge gaps and future prospects of UASs application in hydrology. The first aim of this review is to serve as a reference or introductory document for all researchers and water managers who are interested in embracing this novel technology. The second aim is to unify in a single document all the possibilities, potential approaches and results obtained by different authors through the implementation of UASs.
KW  - drone applications
KW  - surface water
KW  - groundwater
KW  - photogrammetry
KW  - optical sensing
KW  - thermal infrared
DO  - 10.3390/rs13071359
TY  - EJOU
AU  - Park, Jonghyuk
AU  - Park, Jonghun
AU  - Shin, Dongmin
AU  - Choi, Yerim
TI  - A BCI Based Alerting System for Attention Recovery of UAV Operators
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 7
SN  - 1424-8220

AB  - As unmanned aerial vehicles have become popular, the number of accidents caused by an operatorâs inattention have increased. To prevent such accidents, the operator should maintain an attention status. However, limited research has been conducted on the brain-computer interface (BCI)-based system with an alerting module for the operatorâs attention recovery of unmanned aerial vehicles. Therefore, we introduce a detection and alerting system that prevents an unmanned aerial vehicle operator from falling into inattention status by using the operatorâs electroencephalogram signal. The proposed system consists of the following three components: a signal processing module, which collects and preprocesses an electroencephalogram signal of an operator, an inattention detection module, which determines whether an inattention status occurred based on the preprocessed signal, and, lastly, an alert providing module that presents stimulus to an operator when inattention is detected. As a result of evaluating the performance with a real-world dataset, it was shown that the proposed system successfully contributed to the recovery of operator attention in the evaluating dataset, although statistical significance could not be established due to the small number of subjects.
KW  - brain computer interaction
KW  - unmanned aerial vehicle
KW  - EEG-signal
KW  - attention recovery
KW  - alerting system
KW  - graphical user interface
DO  - 10.3390/s21072447
TY  - EJOU
AU  - Wang, Junshu
AU  - Yang, Yue
AU  - Chen, Yuan
AU  - Han, Yuxing
TI  - LighterGAN: An Illumination Enhancement Method for Urban UAV Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 7
SN  - 2072-4292

AB  - In unmanned aerial vehicle based urban observation and monitoring, the performance of computer vision algorithms is inevitably limited by the low illumination and light pollution caused degradation, therefore, the application image enhancement is a considerable prerequisite for the performance of subsequent image processing algorithms. Therefore, we proposed a deep learning and generative adversarial network based model for UAV low illumination image enhancement, named LighterGAN. The design of LighterGAN refers to the CycleGAN model with two improvementsâattention mechanism and semantic consistency lossâhaving been proposed to the original structure. Additionally, an unpaired dataset that was captured by urban UAV aerial photography has been used to train this unsupervised learning model. Furthermore, in order to explore the advantages of the improvements, both the performance in the illumination enhancement task and the generalization ability improvement of LighterGAN were proven in the comparative experiments combining subjective and objective evaluations. In the experiments with five cutting edge image enhancement algorithms, in the test set, LighterGAN achieved the best results in both visual perception and PIQE (perception based image quality evaluator, a MATLAB build-in function, the lower the score, the higher the image quality) score of enhanced images, scores were 4.91 and 11.75 respectively, better than EnlightenGAN the state-of-the-art. In the enhancement of low illumination sub-dataset Y (containing 2000 images), LighterGAN also achieved the lowest PIQE score of 12.37, 2.85 points lower than second place. Moreover, compared with the CycleGAN, the improvement of generalization ability was also demonstrated. In the test set generated images, LighterGAN was 6.66 percent higher than CycleGAN in subjective authenticity assessment and 3.84 lower in PIQE score, meanwhile, in the whole dataset generated images, the PIQE score of LighterGAN is 11.67, 4.86 lower than CycleGAN.
KW  - UAV
KW  - unsupervised learning
KW  - LighterGAN
KW  - unpaired dataset
KW  - illumination enhancement
KW  - attention mechanism
KW  - semantic consistency loss
KW  - PIQE
KW  - generalization ability
DO  - 10.3390/rs13071371
TY  - EJOU
AU  - Han, Dongyeob
AU  - Lee, Suk B.
AU  - Song, Mihwa
AU  - Cho, Jun S.
TI  - Change Detection in Unmanned Aerial Vehicle Images for Progress Monitoring of Road Construction
T2  - Buildings

PY  - 2021
VL  - 11
IS  - 4
SN  - 2075-5309

AB  - Currently, unmanned aerial vehicles are increasingly being used in various construction projects such as housing developments, road construction, and bridge maintenance. If a drone is used at a road construction site, elevation information and orthoimages can be generated to acquire the construction status quantitatively. However, the detection of detailed changes in the site owing to construction depends on visual video interpretation. This study develops a method for automatic detection of the construction area using multitemporal images and a deep learning method. First, a deep learning model was trained using images of the changing area as reference. Second, we obtained an effective application method by applying various parameters to the deep learning process. The application of the time-series images of a construction site to the selected deep learning model enabled more effective identification of the changed areas than the existing pixel-based change detection. The proposed method is expected to be very helpful in construction management by aiding in the development of smart construction technology.
KW  - convolutional Siamese network
KW  - multitemporal
KW  - construction project
KW  - change detection
DO  - 10.3390/buildings11040150
TY  - EJOU
AU  - Fernandez-Beltran, Ruben
AU  - Baidar, Tina
AU  - Kang, Jian
AU  - Pla, Filiberto
TI  - Rice-Yield Prediction with Multi-Temporal Sentinel-2 Data and 3D CNN: A Case Study in Nepal
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 7
SN  - 2072-4292

AB  - Crop yield estimation is a major issue of crop monitoring which remains particularly challenging in developing countries due to the problem of timely and adequate data availability. Whereas traditional agricultural systems mainly rely on scarce ground-survey data, freely available multi-temporal and multi-spectral remote sensing images are excellent tools to support these vulnerable systems by accurately monitoring and estimating crop yields before harvest. In this context, we introduce the use of Sentinel-2 (S2) imagery, with a medium spatial, spectral and temporal resolutions, to estimate rice crop yields in Nepal as a case study. Firstly, we build a new large-scale rice crop database (RicePAL) composed by multi-temporal S2 and climate/soil data from the Terai districts of Nepal. Secondly, we propose a novel 3D Convolutional Neural Network (CNN) adapted to these intrinsic data constraints for the accurate rice crop yield estimation. Thirdly, we study the effect of considering different temporal, climate and soil data configurations in terms of the performance achieved by the proposed approach and several state-of-the-art regression and CNN-based yield estimation methods. The extensive experiments conducted in this work demonstrate the suitability of the proposed CNN-based framework for rice crop yield estimation in the developing country of Nepal using S2 data.
KW  - Sentinel-2
KW  - rice-yield estimation
KW  - regression
KW  - deep learning
KW  - Nepal
DO  - 10.3390/rs13071391
TY  - EJOU
AU  - Doukhi, Oualid
AU  - Lee, Deok-Jin
TI  - Deep Reinforcement Learning for End-to-End Local Motion Planning of Autonomous Aerial Robots in Unknown Outdoor Environments: Real-Time Flight Experiments
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 7
SN  - 1424-8220

AB  - Autonomous navigation and collision avoidance missions represent a significant challenge for robotics systems as they generally operate in dynamic environments that require a high level of autonomy and flexible decision-making capabilities. This challenge becomes more applicable in micro aerial vehicles (MAVs) due to their limited size and computational power. This paper presents a novel approach for enabling a micro aerial vehicle system equipped with a laser range finder to autonomously navigate among obstacles and achieve a user-specified goal location in a GPS-denied environment, without the need for mapping or path planning. The proposed system uses an actorâcritic-based reinforcement learning technique to train the aerial robot in a Gazebo simulator to perform a point-goal navigation task by directly mapping the noisy MAVâs state and laser scan measurements to continuous motion control. The obtained policy can perform collision-free flight in the real world while being trained entirely on a 3D simulator. Intensive simulations and real-time experiments were conducted and compared with a nonlinear model predictive control technique to show the generalization capabilities to new unseen environments, and robustness against localization noise. The obtained results demonstrate our systemâs effectiveness in flying safely and reaching the desired points by planning smooth forward linear velocity and heading rates.
KW  - autonomous navigation
KW  - collision-free
KW  - deep reinforcement learning
KW  - unmanned aerial vehicle
DO  - 10.3390/s21072534
TY  - EJOU
AU  - Kari, Raheleh
AU  - Steinert, Martin
TI  - Human Factor Issues in Remote Ship Operations: Lesson Learned by Studying Different Domains
T2  - Journal of Marine Science and Engineering

PY  - 2021
VL  - 9
IS  - 4
SN  - 2077-1312

AB  - The idea of remote controlling ships for operational and commercial uses has developed beyond concepts. Controlling and monitoring vessels from a distant location requires updating the concept and requirements of shore control centers (SCCs), where human operators control the fleet via cameras, GPS, and many other types of sensors. While remote ship operation promises to reduce operational and maintenance costs, while increasing loading capacity and safety, it also brings significant uncertainty related to both the human-machine and human-human interactions which will affect operations. Achieving safe, reliable, and efficient remote ship operations requires consideration of both technological, cultural, social and human factor aspects of the system. Indeed, operators will act as captain and crew remotely, from the SCC, introducing new types of hardware and software interactions. This paper provides an overview of human factor issues that may affect human-machine and human-human interactions in the course of remote ship operations. In doing so, the literature related to remote operations in the domains of shipping, aerial vehicles, cranes, train transportation, automobiles, and mining is reviewed. Findings revealed that human factor issues are likely to fall into 13 distinct groups based on the type of human interactions that take place in SCCs.
KW  - remote ship operations
KW  - human factor issues
KW  - human-machine interactions
DO  - 10.3390/jmse9040385
TY  - EJOU
AU  - MartÃ­nez, Anselmo
AU  - Belmonte, Lidia M.
AU  - GarcÃ­a, Arturo S.
AU  - FernÃ¡ndez-Caballero, Antonio
AU  - Morales, Rafael
TI  - Facial Emotion Recognition from an Unmanned Flying Social Robot for Home Care of Dependent People
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 7
SN  - 2079-9292

AB  - This work is part of an ongoing research project to develop an unmanned flying social robot to monitor dependants at home in order to detect the personâs state and bring the necessary assistance. In this sense, this paper focuses on the description of a virtual reality (VR) simulation platform for the monitoring process of an avatar in a virtual home by a rotatory-wing autonomous unmanned aerial vehicle (UAV). This platform is based on a distributed architecture composed of three modules communicated through the message queue telemetry transport (MQTT) protocol: the UAV Simulator implemented in MATLAB/Simulink, the VR Visualiser developed in Unity, and the new emotion recognition (ER) system developed in Python. Using a face detection algorithm and a convolutional neural network (CNN), the ER System is able to detect the personâs face in the image captured by the UAVâs on-board camera and classify the emotion among seven possible ones (surprise; fear; happiness; sadness; disgust; anger; or neutral expression). The experimental results demonstrate the correct integration of this new computer vision module within the VR platform, as well as the good performance of the designed CNN, with around 85% in the F1-score, a mean of the precision and recall of the model. The developed emotion detection system can be used in the future implementation of the assistance UAV that monitors dependent people in a real environment, since the methodology used is valid for images of real people.
KW  - flying social robot
KW  - autonomous unmanned aerial vehicle (UAV)
KW  - emotion recognition
KW  - convolution neural network (CNN)
KW  - virtual reality (VR)
KW  - unity
KW  - MATLAB/Simulink
KW  - python
DO  - 10.3390/electronics10070868
TY  - EJOU
AU  - Zhang, Yanchao
AU  - Yang, Wen
AU  - Sun, Ying
AU  - Chang, Christine
AU  - Yu, Jiya
AU  - Zhang, Wenbo
TI  - Fusion of Multispectral Aerial Imagery and Vegetation Indices for Machine Learning-Based Ground Classification
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - Unmanned Aerial Vehicles (UAVs) are emerging and promising platforms for carrying different types of cameras for remote sensing. The application of multispectral vegetation indices for ground cover classification has been widely adopted and has proved its reliability. However, the fusion of spectral bands and vegetation indices for machine learning-based land surface investigation has hardly been studied. In this paper, we studied the fusion of spectral bands information from UAV multispectral images and derived vegetation indices for almond plantation classification using several machine learning methods. We acquired multispectral images over an almond plantation using a UAV. First, a multispectral orthoimage was generated from the acquired multispectral images using SfM (Structure from Motion) photogrammetry methods. Eleven types of vegetation indexes were proposed based on the multispectral orthoimage. Then, 593 data points that contained multispectral bands and vegetation indexes were randomly collected and prepared for this study. After comparing six machine learning algorithms (Support Vector Machine, K-Nearest Neighbor, Linear Discrimination Analysis, Decision Tree, Random Forest, and Gradient Boosting), we selected three (SVM, KNN, and LDA) to study the fusion of multi-spectral bands information and derived vegetation index for classification. With the vegetation indexes increased, the model classification accuracy of all three selected machine learning methods gradually increased, then dropped. Our results revealed that that: (1) spectral information from multispectral images can be used for machine learning-based ground classification, and among all methods, SVM had the best performance; (2) combination of multispectral bands and vegetation indexes can improve the classification accuracy comparing to only spectral bands among all three selected methods; (3) among all VIs, NDEGE, NDVIG, and NDVGE had consistent performance in improving classification accuracies, and others may reduce the accuracy. Machine learning methods (SVM, KNN, and LDA) can be used for classifying almond plantation using multispectral orthoimages, and fusion of multispectral bands with vegetation indexes can improve machine learning-based classification accuracy if the vegetation indexes are properly selected.
KW  - multispectral
KW  - vegetation indexes
KW  - information fusion
KW  - UAV
KW  - plantation classification
KW  - machine learning
DO  - 10.3390/rs13081411
TY  - EJOU
AU  - Bao, Min
AU  - Chala Urgessa, Guyo
AU  - Xing, Mengdao
AU  - Han, Liang
AU  - Chen, Rui
TI  - Toward More Robust and Real-Time Unmanned Aerial Vehicle Detection and Tracking via Cross-Scale Feature Aggregation Based on the Center Keypoint
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - Unmanned aerial vehicles (UAVs) play an essential role in various applications, such as transportation and intelligent environmental sensing. However, due to camera motion and complex environments, it can be difficult to recognize the UAV from its surroundings thus, traditional methods often miss detection of UAVs and generate false alarms. To address these issues, we propose a novel method for detecting and tracking UAVs. First, a cross-scale feature aggregation CenterNet (CFACN) is constructed to recognize the UAVs. CFACN is a free anchor-based center point estimation method that can effectively decrease the false alarm rate, the misdetection of small targets, and computational complexity. Secondly, the region of interest-scale-crop-resize (RSCR) method is utilized to merge CFACN and region-of-interest (ROI) CFACN (ROI-CFACN) further, in order to improve the accuracy at a lower computational cost. Finally, the Kalman filter is adopted to track the UAV. The effectiveness of our method is validated using a collected UAV dataset. The experimental results demonstrate that our methods can achieve higher accuracy with lower computational cost, being superior to BiFPN, CenterNet, YoLo, and their variants on the same dataset.
KW  - cross-scale feature aggregation
KW  - center point estimation
KW  - region of interest
KW  - unmanned aerial vehicle
DO  - 10.3390/rs13081416
TY  - EJOU
AU  - Tang, Mingliang
AU  - Esmaeili, Kamran
TI  - Heap Leach Pad Surface Moisture Monitoring Using Drone-Based Aerial Images and Convolutional Neural Networks: A Case Study at the El Gallo Mine, Mexico
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - An efficient metal recovery in heap leach operations relies on uniform distribution of leaching reagent solution over the heap leach pad surface. However, the current practices for heap leach pad (HLP) surface moisture monitoring often rely on manual inspection, which is labor-intensive, time-consuming, discontinuous, and intermittent. In order to complement the manual monitoring process and reduce the frequency of exposing technical manpower to the hazardous leaching reagent (e.g., dilute cyanide solution in gold leaching), this manuscript describes a case study of implementing an HLP surface moisture monitoring method based on drone-based aerial images and convolutional neural networks (CNNs). Field data collection was conducted on a gold HLP at the El Gallo mine, Mexico. A commercially available hexa-copter drone was equipped with one visible-light (RGB) camera and one thermal infrared sensor to acquire RGB and thermal images from the HLP surface. The collected data had high spatial and temporal resolutions. The high-quality aerial images were used to generate surface moisture maps of the HLP based on two CNN approaches. The generated maps provide direct visualization of the different moisture zones across the HLP surface, and such information can be used to detect potential operational issues related to distribution of reagent solution and to facilitate timely decision making in heap leach operations.
KW  - heap leach pad monitoring
KW  - convolutional neural network
KW  - surface moisture mapping
KW  - unmanned aerial vehicle
KW  - drone
KW  - gold leaching
KW  - mining
DO  - 10.3390/rs13081420
TY  - EJOU
AU  - Kanniah, Kasturi D.
AU  - Kang, Chuen S.
AU  - Sharma, Sahadev
AU  - Amir, A. A.
TI  - Remote Sensing to Study Mangrove Fragmentation and Its Impacts on Leaf Area Index and Gross Primary Productivity in the South of Peninsular Malaysia
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - Mangrove is classified as an important ecosystem along the shorelines of tropical and subtropical landmasses, which are being degraded at an alarming rate despite numerous international treaties having been agreed. Iskandar Malaysia (IM) is a fast-growing economic region in southern Peninsular Malaysia, where three Ramsar Sites are located. Since the beginning of the 21st century (2000â2019), a total loss of 2907.29 ha of mangrove area has been estimated based on medium-high resolution remote sensing data. This corresponds to an annual loss rate of 1.12%, which is higher than the world mangrove depletion rate. The causes of mangrove loss were identified as land conversion to urban, plantations, and aquaculture activities, where large mangrove areas were shattered into many smaller patches. Fragmentation analysis over the mangrove area shows a reduction in the mean patch size (from 105 ha to 27 ha) and an increase in the number of mangrove patches (130 to 402), edge, and shape complexity, where smaller and isolated mangrove patches were found to be related to the rapid development of IM region. The Moderate Resolution Imaging Spectro-radiometer (MODIS) Leaf Area Index (LAI) and Gross Primary Productivity (GPP) products were used to inspect the impact of fragmentation on the mangrove ecosystem process. The mean LAI and GPP of mangrove areas that had not undergone any land cover changes over the years showed an increase from 3.03 to 3.55 (LAI) and 5.81 g C mâ2 to 6.73 g C mâ2 (GPP), highlighting the ability of the mangrove forest to assimilate CO2 when it is not disturbed. Similarly, GPP also increased over the gained areas (from 1.88 g C mâ2 to 2.78 g C mâ2). Meanwhile, areas that lost mangroves, but replaced them with oil palm, had decreased mean LAI from 2.99 to 2.62. In fragmented mangrove patches an increase in GPP was recorded, and this could be due to the smaller patches (&lt;9 ha) and their edge effects where abundance of solar radiation along the edges of the patches may increase productivity. The impact on GPP due to fragmentation is found to rely on the type of land transformation and patch characteristics (size, edge, and shape complexity). The preservation of mangrove forests in a rapidly developing region such as IM is vital to ensure ecosystem, ecology, environment, and biodiversity conservation, in addition to providing economical revenue and supporting human activities.
KW  - mangrove
KW  - coastal region
KW  - remote sensing
KW  - fragmentation
KW  - productivity
KW  - land cover change
DO  - 10.3390/rs13081427
TY  - EJOU
AU  - Marang, Ian J.
AU  - Filippi, Patrick
AU  - Weaver, Tim B.
AU  - Evans, Bradley J.
AU  - Whelan, Brett M.
AU  - Bishop, Thomas F. A.
AU  - Murad, Mohammed O. F.
AU  - Al-Shammari, Dhahi
AU  - Roth, Guy
TI  - Machine Learning Optimised Hyperspectral Remote Sensing Retrieves Cotton Nitrogen Status
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - Hyperspectral imaging spectrometers mounted on unmanned aerial vehicle (UAV) can capture high spatial and spectral resolution to provide cotton crop nitrogen status for precision agriculture. The aim of this research was to explore machine learning use with hyperspectral datacubes over agricultural fields. Hyperspectral imagery was collected over a mature cotton crop, which had high spatial (~5.2 cm) and spectral (5 nm) resolution over the spectral range 475â925 nm that allowed discrimination of individual crop rows and field features as well as a continuous spectral range for calculating derivative spectra. The nominal reflectance and its derivatives clearly highlighted the different treatment blocks and were strongly related to N concentration in leaf and petiole samples, both in traditional vegetation indices (e.g., Vogelman 1, R2 = 0.8) and novel combinations of spectra (R2 = 0.85). The key hyperspectral bands identified were at the red-edge inflection point (695â715 nm). Satellite multispectral was compared against the UAV hyperspectral remote sensingâs performance by testing the ability of Sentinel MSI to predict N concentration using the bands in VIS-NIR spectral region. The Sentinel 2A Green band (B3; mid-point 559.8 nm) explained the same amount of variation in N as the hyperspectral data and more than the Sentinel Red Edge Point 1 (B5; mid-point 704.9 nm) with the lower 10 m resolution Green band reporting an R2 = 0.85, compared with the R2 = 0.78 of downscaled Sentinel Red Edge Point 1 at 5 m. The remaining Sentinel bands explained much lower variation (maximum was NIR at R2 = 0.48). Investigation of the red edge peak region in the first derivative showed strong promise with RIDAmid (R2 = 0.81) being the best index. The machine learning approach narrowed the range of bands required to investigate plant condition over this trial site, greatly improved processing time and reduced processing complexity. While Sentinel performed well in this comparison and would be useful in a broadacre crop production context, the impact of pixel boundaries relative to a region of interest and coarse spatial and temporal resolution impacts its utility in a research capacity.
KW  - remote sensing
KW  - hyperspectral
KW  - multispectral
KW  - machine learning
KW  - nitrogen
KW  - cotton
DO  - 10.3390/rs13081428
TY  - EJOU
AU  - Pacheco-Angulo, Carlos
AU  - Plata-Rocha, Wenseslao
AU  - Serrano, Julio
AU  - Vilanova, Emilio
AU  - Monjardin-Armenta, Sergio
AU  - GonzÃ¡lez, Alvaro
AU  - Camargo, Cristopher
TI  - A Low-Cost and Robust Landsat-Based Approach to Study Forest Degradation and Carbon Emissions from Selective Logging in the Venezuelan Amazon
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - Selective logging in the tropics is a major driver of forest degradation by altering forest structure and function, including significant losses of aboveground carbon. In this study, we used a 30-year Landsat time series (1985â2015) to analyze forest degradation and carbon emissions due to selective logging in a Forest Reserve of the Venezuelan Amazon. Our work was conducted in two phases: the first, by means of a direct method we detected the infrastructure related to logging at the sub-pixel level, and for the second, we used an indirect approach using buffer areas applied to the results of the selective logging mapping. Pre- and post-logging forest inventory data, combined with the mapping analysis were used to quantify the effects of logging on aboveground carbon emissions for three different sources: hauling, skidding and tree felling. With an overall precision of 0.943, we demonstrate the potential of this method to efficiently map selective logging and forest degradation with commission and omission errors of +7.6 Â± 4.5 (Mean Â± SD %) and â7.5% Â± 9.1 respectively. Forest degradation due to logging directly affected close to 24,480 ha, or about ~1% of the total area of the Imataca Forest Reserve. On average, with a relatively low harvest intensity of 2.8 Â± 1.2 trees haâ1 or 10.5 Â± 4.6 m3 haâ1, selective logging was responsible for the emission of 61 Â± 21.9 Mg C haâ1. Lack of reduced impact logging guidelines contributed to pervasive effects reflected in a mean reduction of ~35% of the aboveground carbon compared to unlogged stands. This research contributes to further improve our understanding of the relationships between selective logging and forest degradation in tropical managed forests and serves as input for the potential implementation of projects for reducing emissions from deforestation and forest degradation (REDD+).
KW  - carbon
KW  - climate change
KW  - forest degradation
KW  - Landsat
KW  - REDD+
KW  - selective logging
KW  - Venezuelan Amazon
KW  - TerraAmazon
KW  - Imataca Forest Reserve
DO  - 10.3390/rs13081435
TY  - EJOU
AU  - Ludwig, Christina
AU  - Hecht, Robert
AU  - Lautenbach, Sven
AU  - Schorcht, Martin
AU  - Zipf, Alexander
TI  - Mapping Public Urban Green Spaces Based on OpenStreetMap and Sentinel-2 Imagery Using Belief Functions
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 4
SN  - 2220-9964

AB  - Public urban green spaces are important for the urban quality of life. Still, comprehensive open data sets on urban green spaces are not available for most cities. As open and globally available data sets, the potential of Sentinel-2 satellite imagery and OpenStreetMap (OSM) data for urban green space mapping is high but limited due to their respective uncertainties. Sentinel-2 imagery cannot distinguish public from private green spaces and its spatial resolution of 10 m fails to capture fine-grained urban structures, while in OSM green spaces are not mapped consistently and with the same level of completeness everywhere. To address these limitations, we propose to fuse these data sets under explicit consideration of their uncertainties. The Sentinel-2 derived Normalized Difference Vegetation Index was fused with OSM data using the DempsterâShafer theory to enhance the detection of small vegetated areas. The distinction between public and private green spaces was achieved using a Bayesian hierarchical model and OSM data. The analysis was performed based on land use parcels derived from OSM data and tested for the city of Dresden, Germany. The overall accuracy of the final map of public urban green spaces was 95% and was mainly influenced by the uncertainty of the public accessibility model.
KW  - OpenStreetMap
KW  - volunteered geographic information
KW  - remote sensing
KW  - data fusion
KW  - land use
KW  - DempsterâShafer theory
KW  - urban areas
DO  - 10.3390/ijgi10040251
TY  - EJOU
AU  - Yang, Yukun
AU  - Ma, Bo
AU  - Liu, Xiangdong
AU  - Zhao, Liang
AU  - Huang, Shoudong
TI  - GSAP: A Global Structure Attention Pooling Method for Graph-Based Visual Place Recognition
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - The Visual Place Recognition problem aims to use an image to recognize the location that has been visited before. In most of the scenes revisited, the appearance and view are drastically different. Most previous works focus on the 2-D image-based deep learning method. However, the convolutional features are not robust enough to the challenging scenes mentioned above. In this paper, in order to take advantage of the information that helps the Visual Place Recognition task in these challenging scenes, we propose a new graph construction approach to extract the useful information from an RGB image and a depth image and fuse them in graph data. Then, we deal with the Visual Place Recognition problem as a graph classification problem. We propose a new Global Pooling methodâGlobal Structure Attention Pooling (GSAP), which improves the classification accuracy by improving the expression ability of the Global Pooling component. The experiments show that our GSAP method improves the accuracy of graph classification by approximately 2â5%, the graph construction method improves the accuracy of graph classification by approximately 4â6%, and that the whole Visual Place Recognition model is robust to appearance change and view change.
KW  - graph construction
KW  - graph neural networks
KW  - graph convolution
KW  - graph global pooling
KW  - visual place recognition
DO  - 10.3390/rs13081467
TY  - EJOU
AU  - Marin, Diego B.
AU  - Ferraz, Gabriel A.
AU  - GuimarÃ£es, Paulo H.
AU  - Schwerz, Felipe
AU  - Santana, Lucas S.
AU  - Barbosa, Brenon D.
AU  - Barata, Rafael A.
AU  - Faria, Rafael D.
AU  - Dias, Jessica E.
AU  - Conti, Leonardo
AU  - Rossi, Giuseppe
TI  - Remotely Piloted Aircraft and Random Forest in the Evaluation of the Spatial Variability of Foliar Nitrogen in Coffee Crop
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - The development of approaches to determine the spatial variability of nitrogen (N) into coffee leaves is essential to increase productivity and reduce production costs and environmental impacts associated with excessive N applications. Thus, this study aimed to assess the potential of the Random Forest (RF) machine learning method applied to vegetation indices (VI) obtained from Remotely Piloted Aircraft (RPA) images to measure the N content in coffee plants. A total of 10 VI were obtained from multispectral images by a camera attached to a rotary-wing RPA. The RGB orthomosaic was used to determine sampling points at the crop area, which were ranked by N levels in the plants as deficient, critical, or sufficient. The chemical analysis of N content in the coffee leaves, as well as the VI values in sample points, were used as input parameters for the image training and its classification by the RF. The suggested model has shown global accuracy and a kappa coefficient of up to 0.91 and 0.86, respectively. The best results were achieved using the Green Normalized Difference Vegetation (GNDVI) and Green Optimized Soil Adjusted Vegetation Index (GOSAVI). In addition, the model enabled the evaluation of the spatial distribution of N in the coffee trees, as well as quantification of N deficiency in the crop for the whole area. The GNDVI and GOSAVI allowed the verification that 22% of the entire crop area had plants with N deficiency symptoms, which would result in a reduction of 78% in the amount of N applied by the producer.
KW  - machine learning
KW  - vegetation indices
KW  - unmanned aerial vehicle
KW  - nitrogen management
KW  - RGB camera
DO  - 10.3390/rs13081471
TY  - EJOU
AU  - Kim, Jeonghwan
AU  - Lee, Soomin
AU  - Seo, Jongwon
AU  - Lee, Dong-Eun
AU  - Choi, Hee S.
TI  - The Integration of Earthwork Design Review and Planning Using UAV-Based Point Cloud and BIM
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 8
SN  - 2076-3417

AB  - Earthwork is seemingly guesswork, but it requires a high level of accuracy and precise planning. Differences between earthwork design and finishing levels cause project delays and cost overrun due to the time-consuming nature of earthwork re-work. Therefore, error-free earthwork planning and design review is a key to the success of earthwork projects. This study utilized an integrated approach of an unmanned aerial vehicle (UAV)-based point cloud and BIM (Building Information Modeling) to verify the design and to operate the earthwork planning. The integrated approach was proposed and applied to a 420 square meters housing construction project to review an original earthwork design and create an earthwork plan for excavator work. As a result, errors in earthwork design that caused by inaccurate initial DEM was revealed, thus the earthwork design was revised with a UAV-based point cloud map. Additionally, the integrated approach was able to generate an explicit task sequence for an excavator.
KW  - earthwork
KW  - point cloud
KW  - excavation
KW  - BIM
KW  - UAV
KW  - earthwork design
DO  - 10.3390/app11083435
TY  - EJOU
AU  - Crawford, Brandon
AU  - Swanson, Erika
AU  - Schultz-Fellenz, Emily
AU  - Collins, Adam
AU  - Dann, Julian
AU  - Lathrop, Emma
AU  - Milazzo, Damien
TI  - A New Method for High Resolution Surface Change Detection: Data Collection and Validation of Measurements from UAS at the Nevada National Security Site, Nevada, USA
T2  - Drones

PY  - 2021
VL  - 5
IS  - 2
SN  - 2504-446X

AB  - The use of uncrewed aerial systems (UAS) increases the opportunities for detecting surface changes in remote areas and in challenging terrain. Detecting surface topographic changes offers an important constraint for understanding earthquake damage, groundwater depletion, effects of mining, and other events. For these purposes, changes on the order of 5â10 cm are readily detected, but sometimes it is necessary to detect smaller changes. An example is the surface changes that result from underground explosions, which can be as small as 3 cm. Previous studies that described change detection methodologies were generally not aimed at detecting sub-5-cm changes. Additionally, studies focused on high-fidelity accuracy were either computationally modeled or did not fully provide the necessary examples to highlight the usability of these workflows. Detecting changes at this threshold may be critical in certain applications, such as global security research and monitoring for high-consequence natural hazards, including landslides. Here we provide a detailed description of the methodology we used to detect 2â3 cm changes in an important applied research settingâsurface changes related to underground explosions. This methodology improves the accuracy of change detection data collection and analysis through the optimization of pre-field planning, surveying, flight operations, and post-processing the collected data, all of which are critical to obtaining the highest output data resolution possible. We applied this methodology to a field study location, collecting 1.4 Tb of images over the course of 30 flights, and location data for 239 ground control points (GCPs). We independently verified changes with orthoimagery, and found that structure-from-motion, software-reported root mean square errors (RMSEs) for both control and check points underestimated the actual error. We found that 3 cm changes are detectable with this methodology, thereby improving our knowledge of a rockâs response to underground explosions.
KW  - structure from motion (SFM)
KW  - global security
KW  - change detection
KW  - UAS
KW  - underground explosions
DO  - 10.3390/drones5020025
TY  - EJOU
AU  - Kang, Yeseong
AU  - Nam, Jinwoo
AU  - Kim, Younggwang
AU  - Lee, Seongtae
AU  - Seong, Deokgyeong
AU  - Jang, Sihyeong
AU  - Ryu, Chanseok
TI  - Assessment of Regression Models for Predicting Rice Yield and Protein Content Using Unmanned Aerial Vehicle-Based Multispectral Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - Unmanned aerial vehicle-based multispectral imagery including five spectral bands (blue, green, red, red-edge, and near-infrared) for a rice field in the ripening stage was used to develop regression models for predicting the rice yield and protein content and to select the most suitable regression analysis method for the year-invariant model: partial least squares regression, ridge regression, and artificial neural network (ANN). The regression models developed with six vegetation indices (green normalization difference vegetation index (GNDVI), normalization difference red-edge index (NDRE), chlorophyll index red edge (CIrededge), difference NIR/Green green difference vegetation index (GDVI), green-red NDVI (GRNDVI), and medium resolution imaging spectrometer terrestrial chlorophyll index (MTCI)), calculated from the spectral bands, were applied to single years (2018, 2019, and 2020) and multiple years (2018 + 2019, 2018 + 2020, 2019 + 2020, and all years). The regression models were cross-validated through mutual prediction against the vegetation indices in nonoverlapping years, and the prediction errors were evaluated via root mean squared error of prediction (RMSEP). The ANN model was reproducible, with low and sustained prediction errors of 24.2 kg/1000 m2 â¤ RMSEP â¤ 59.1 kg/1000 m2 in rice yield and 0.14% â¤ RMSEP â¤ 0.28% in rice-protein content in all single-year and multiple-year analyses. When the importance of each vegetation index of the regression models was evaluated, only the ANN model showed the same ranking in the vegetation index of the first (MTCI in both rice yield and protein content) and second importance (CIrededge in rice yield and GRNDVI in rice-protein content). Overall, this means that the ANN model has the highest potential for developing a year-invariant model with stable RMSEP and consistent variable ranking.
KW  - multispectral imagery
KW  - mutual prediction
KW  - regression model
KW  - rice-protein content
KW  - rice yield
DO  - 10.3390/rs13081508
TY  - EJOU
AU  - Xiong, Quan
AU  - Di, Liping
AU  - Feng, Quanlong
AU  - Liu, Diyou
AU  - Liu, Wei
AU  - Zan, Xuli
AU  - Zhang, Lin
AU  - Zhu, Dehai
AU  - Liu, Zhe
AU  - Yao, Xiaochuang
AU  - Zhang, Xiaodong
TI  - Deriving Non-Cloud Contaminated Sentinel-2 Images with RGB and Near-Infrared Bands from Sentinel-1 Images Based on a Conditional Generative Adversarial Network
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - Sentinel-2 images have been widely used in studying land surface phenomena and processes, but they inevitably suffer from cloud contamination. To solve this critical optical data availability issue, it is ideal to fuse Sentinel-1 and Sentinel-2 images to create fused, cloud-free Sentinel-2-like images for facilitating land surface applications. In this paper, we propose a new data fusion model, the Multi-channels Conditional Generative Adversarial Network (MCcGAN), based on the conditional generative adversarial network, which is able to convert images from Domain A to Domain B. With the model, we were able to generate fused, cloud-free Sentinel-2-like images for a target date by using a pair of reference Sentinel-1/Sentinel-2 images and target-date Sentinel-1 images as inputs. In order to demonstrate the superiority of our method, we also compared it with other state-of-the-art methods using the same data. To make the evaluation more objective and reliable, we calculated the root-mean-square-error (RSME), R2, KlingâGupta efficiency (KGE), structural similarity index (SSIM), spectral angle mapper (SAM), and peak signal-to-noise ratio (PSNR) of the simulated Sentinel-2 images generated by different methods. The results show that the simulated Sentinel-2 images generated by the MCcGAN have a higher quality and accuracy than those produced via the previous methods.
KW  - Sentinel-1
KW  - Sentinel-2
KW  - generative adversarial network
KW  - non-cloud contamination
KW  - data fusion
DO  - 10.3390/rs13081512
TY  - EJOU
AU  - Liu, Li-Wei
AU  - Hsieh, Sheng-Hsin
AU  - Lin, Su-Ju
AU  - Wang, Yu-Min
AU  - Lin, Wen-Shin
TI  - Rice Blast (Magnaporthe oryzae) Occurrence Prediction and the Key Factor Sensitivity Analysis by Machine Learning
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 4
SN  - 2073-4395

AB  - This study aimed to establish a machine learning (ML)-based rice blast predicting model to decrease the appreciable losses based on short-term environment data. The average, highest and lowest air temperature, average relative humidity, soil temperature and solar energy were selected for model development. The developed multilayer perceptron (MLP), support vector machine (SVM), Elman recurrent neural network (Elman RNN) and probabilistic neural network (PNN) were evaluated by F-measures. Finally, a sensitivity analysis (SA) was conducted for the factor importance assessment. The study result shows that the PNN performed best with the F-measure (Î² = 2) of 96.8%. The SA was conducted in the PNN model resulting in the main effect period is 10 days before the rice blast happened. The key factors found are minimum air temperature, followed by solar energy and equaled sensitivity of average relative humidity, maximum air temperature and soil temperature. The temperature phase lag in air and soil may cause a lower dew point and suitable for rice blast pathogens growth. Through this studyâs results, rice blast warnings can be issued 10 days in advance, increasing the response time for farmers preparing related preventive measures, further reducing the losses caused by rice blast.
KW  - rice disease
KW  - precision agriculture
KW  - artificial neural networks (ANN)
KW  - soil temperature
KW  - confusion matrix
KW  - F-measure
DO  - 10.3390/agronomy11040771
TY  - EJOU
AU  - Hou, Xiaoyu
AU  - Zhang, Kunlin
AU  - Xu, Jihui
AU  - Huang, Wei
AU  - Yu, Xinmiao
AU  - Xu, Huaiyu
TI  - Object Detection in Drone Imagery via Sample Balance Strategies and Local Feature Enhancement
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 8
SN  - 2076-3417

AB  - With the advent of drones, new potential applications have emerged for the unconstrained analysis of images and videos from aerial view cameras. Despite the tremendous success of the generic object detection methods developed using ground-based photos, a considerable performance drop is observed when these same methods are directly applied to images captured by Unmanned Aerial Vehicles (UAVs). Usually, most of the work goes into improving the performance of the detector in aspects such as design loss, training sample selection, feature enhancement, and so forth. This paper proposes a detection framework based on an anchor-free detector with several modules, including a sample balance strategies module and super-resolved generated feature module, to improve performance. We proposed the sample balance strategies module to optimize the imbalance among training samples, especially the imbalance between positive and negative, and easy and hard samples. Due to the high frequencies and noisy representation of the small objects in images captured by drones, the detection task is extraordinarily challenging. However, when compared with other algorithms of this kind, our method achieves better results. We also propose a super-resolved generated GAN (Generative Adversarial Network) module with center-ness weights to effectively enhance the local feature map. Finally, we demonstrate our methodâs effectiveness with the proposed modules by carrying out a state-of-the-art performance on Visdrone2020 benchmarks.
KW  - object detection
KW  - drones
KW  - deep learning
KW  - sample imbalance
KW  - super-resolve GAN
DO  - 10.3390/app11083547
TY  - EJOU
AU  - Jiang, Yufeng
AU  - Zhang, Li
AU  - Yan, Min
AU  - Qi, Jianguo
AU  - Fu, Tianmeng
AU  - Fan, Shunxiang
AU  - Chen, Bowei
TI  - High-Resolution Mangrove Forests Classification with Machine Learning Using Worldview and UAV Hyperspectral Data
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - Mangrove forests, as important ecological and economic resources, have suffered a loss in the area due to natural and human activities. Monitoring the distribution of and obtaining accurate information on mangrove species is necessary for ameliorating the damage and protecting and restoring mangrove forests. In this study, we compared the performance of UAV Rikola hyperspectral images, WorldView-2 (WV-2) satellite-based multispectral images, and a fusion of data from both in the classification of mangrove species. We first used recursive feature eliminationârandom forest (RFE-RF) to select the vegetationâs spectral and texture feature variables, and then implemented random forest (RF) and support vector machine (SVM) algorithms as classifiers. The results showed that the accuracy of the combined data was higher than that of UAV and WV-2 data; the vegetation index features of UAV hyperspectral data and texture index of WV-2 data played dominant roles; the overall accuracy of the RF algorithm was 95.89% with a Kappa coefficient of 0.95, which is more accurate and efficient than SVM. The use of combined data and RF methods for the classification of mangrove species could be useful in biomass estimation and breeding cultivation.
KW  - mangrove species classification
KW  - hyperspectral
KW  - WorldView-2
KW  - feature selection
KW  - machine learning
DO  - 10.3390/rs13081529
TY  - EJOU
AU  - Chao, Luomeng
AU  - Wu, Celimuge
AU  - Yoshinaga, Tsutomu
AU  - Bao, Wugedele
AU  - Ji, Yusheng
TI  - A Brief Review of Multipath TCP for Vehicular Networks
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 8
SN  - 1424-8220

AB  - Multipath TCP (MPTCP) is one of the most important extensions to TCP that enables the use of multiple paths in data transmissions for a TCP connection. In MPTCP, the end hosts transmit data across a number of TCP subflows simultaneously on one connection. MPTCP can sufficiently utilize the bandwidth resources to improve the transmission efficiency while providing TCP fairness to other TCP connections. Meanwhile, it also offers resilience due to multipath data transfers. MPTCP attracts tremendous attention from the academic and industry field due to the explosive data growth in recent times and limited network bandwidth for each single available communication interface. The vehicular Internet-of-Things systems, such as cooperative autonomous driving, require reliable high speed data transmission and robustness. MPTCP could be a promising approach to solve these challenges. In this paper, we first conduct a brief survey of existing MPTCP studies and give a brief overview to multipath routing. Then we discuss the significance technical challenges in applying MPTCP for vehicular networks and point out future research directions.
KW  - MPTCP
KW  - multipath routing
KW  - vehicular networks
DO  - 10.3390/s21082793
TY  - EJOU
AU  - Song, Yongze
AU  - Wu, Peng
TI  - Earth Observation for Sustainable Infrastructure: A Review
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - Infrastructure is a fundamental sector for sustainable development and Earth observation has great potentials for sustainable infrastructure development (SID). However, implementations of the timely, largeâscale and multiâsource Earth observation are still limited in satisfying the huge global requirements of SID. This study presents a systematical literature review to identify trends of Earth observation for sustainable infrastructure (EOSI), investigate the relationship between EOSI and Sustainable Development Goals (SDGs), and explore challenges and future directions of EOSI. Results reveal the close associations of infrastructure, urban development, ecosystems, climate, Earth observation and GIS in EOSI, and indicate their relationships. In addition, from the perspective of EOSIâSDGs relationship, the huge potentials of EOSI are demonstrated from the 70% of the infrastructure influenced targets that can be directly or indirectly derived from Earth observation data, but have not been included in current SDG indicators. Finally, typical EOSI cases are presented to indicate challenges and future research directions. This review emphasizes the contributions and potentials of Earth observation to SID and EOSI is a powerful pathway to deliver on SDGs.
KW  - sustainable infrastructure
KW  - earth observation
KW  - remote sensing
KW  - earth big data
KW  - Sustainable Development Goals (SDGs)
KW  - SDG targets
KW  - bibliographic analysis
DO  - 10.3390/rs13081528
TY  - EJOU
AU  - Zhang, Fan
AU  - Hu, Zhenqi
AU  - Yang, Kun
AU  - Fu, Yaokun
AU  - Feng, Zewei
AU  - Bai, Mingbo
TI  - The Surface Crack Extraction Method Based on Machine Learning of Image and Quantitative Feature Information Acquisition Method
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - In order to effectively control the damage caused by surface cracks to a geological environment, we need to find a convenient, efficient, and accurate method to obtain crack information. The existing crack extraction methods based on unmanned air vehicle (UAV) images inevitably have some erroneous pixels because of the complexity of background information. At the same time, there are few researches on crack feature information. In view of this, this article proposes a surface crack extraction method based on machine learning of UAV images, the data preprocessing steps, and the content and calculation methods for crack feature information: length, width, direction, location, fractal dimension, number, crack rate, and dispersion rate. The results show that the method in this article can effectively avoid the interference by vegetation and soil crust. By introducing the concept of dispersion rate, the method combining crack rate and dispersion rate can describe the distribution characteristics of regional cracks more clearly. Compared to field survey data, the calculation result of the crack feature information in this article is close to the true value, which proves that this is a reliable method for obtaining quantitative crack feature information.
KW  - machine learning
KW  - remote sensing
KW  - UAV image
KW  - crack extraction
KW  - feature acquisition
DO  - 10.3390/rs13081534
TY  - EJOU
AU  - Xu, Gaofei
AU  - Guo, Wei
AU  - Zhao, Yang
AU  - Zhou, Yue
AU  - Zhang, Yinlong
AU  - Liu, Xinyu
AU  - Xu, Gaopeng
AU  - Li, Guangwei
TI  - Online Learning Based Underwater Robotic Thruster Fault Detection
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 8
SN  - 2076-3417

AB  - This paper presents a novel online learning-based fault detection designed for underwater robotic thruster health monitoring. In the fault detection algorithm, we build a mathematical model between the control variable and the propeller speed by fitting collected online work status data to the model. To improve the accuracy of online modeling, a multi-center PSO algorithm with memory ability is utilized to optimize the modeling parameters. Additionally, a model online update mechanism is designed to accommodate the model to the change of thruster work status and sea environment. During the operation, propeller speed of the underwater robot is predicted through the online learning-based model, and the model residuals are used for thruster health monitoring. To avoid false alarm, an adaptive fault detection strategy is established based on model online update mechanism. The proposed method has been extensively evaluated using different underwater robotics, through a sea trial data simulation, a pool test fault detection experiment and a sea trial fault detection experiment. Compared with fixed model-based method, speed prediction MAE of the online learning model is at least 37.9% lower than that of the fixed model. The online learning-based method show no misdiagnosis in experiments, while the fixed model-based method is misdiagnosed. Experimental results show that the proposed method is competitive in terms of accuracy, adaptability, and robustness.
KW  - underwater robotic
KW  - thruster system
KW  - time delay estimation
KW  - particle swarm optimization
KW  - online learning
KW  - adaptive fault detection
DO  - 10.3390/app11083586
TY  - EJOU
AU  - Coluccia, Angelo
AU  - Fascista, Alessio
AU  - Schumann, Arne
AU  - Sommer, Lars
AU  - Dimou, Anastasios
AU  - Zarpalas, Dimitrios
AU  - MÃ©ndez, Miguel
AU  - de la Iglesia, David
AU  - GonzÃ¡lez, Iago
AU  - Mercier, Jean-Philippe
AU  - GagnÃ©, Guillaume
AU  - Mitra, Arka
AU  - Rajashekar, Shobha
TI  - Drone vs. Bird Detection: Deep Learning Algorithms and Results from a Grand Challenge
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 8
SN  - 1424-8220

AB  - Adopting effective techniques to automatically detect and identify small drones is a very compelling need for a number of different stakeholders in both the public and private sectors. This work presents three different original approaches that competed in a grand challenge on the âDrone vs. Birdâ detection problem. The goal is to detect one or more drones appearing at some time point in video sequences where birds and other distractor objects may be also present, together with motion in background or foreground. Algorithms should raise an alarm and provide a position estimate only when a drone is present, while not issuing alarms on birds, nor being confused by the rest of the scene. In particular, three original approaches based on different deep learning strategies are proposed and compared on a real-world dataset provided by a consortium of universities and research centers, under the 2020 edition of the Drone vs. Bird Detection Challenge. Results show that there is a range in difficulty among different test sequences, depending on the size and the shape visibility of the drone in the sequence, while sequences recorded by a moving camera and very distant drones are the most challenging ones. The performance comparison reveals that the different approaches perform somewhat complementary, in terms of correct detection rate, false alarm rate, and average precision.
KW  - drone detection
KW  - deep learning
KW  - drone vs. bird
KW  - automatic recognition
KW  - image and video signal processing
DO  - 10.3390/s21082824
TY  - EJOU
AU  - Li, Joan Y. Q.
AU  - Duce, Stephanie
AU  - Joyce, Karen E.
AU  - Xiang, Wei
TI  - SeeCucumbers: Using Deep Learning and Drone Imagery to Detect Sea Cucumbers on Coral Reef Flats
T2  - Drones

PY  - 2021
VL  - 5
IS  - 2
SN  - 2504-446X

AB  - Sea cucumbers (Holothuroidea or holothurians) are a valuable fishery and are also crucial nutrient recyclers, bioturbation agents, and hosts for many biotic associates. Their ecological impacts could be substantial given their high abundance in some reef locations and thus monitoring their populations and spatial distribution is of research interest. Traditional in situ surveys are laborious and only cover small areas but drones offer an opportunity to scale observations more broadly, especially if the holothurians can be automatically detected in drone imagery using deep learning algorithms. We adapted the object detection algorithm YOLOv3 to detect holothurians from drone imagery at Hideaway Bay, Queensland, Australia. We successfully detected 11,462 of 12,956 individuals over 2.7ha with an average density of 0.5 individual/m2. We tested a range of hyperparameters to determine the optimal detector performance and achieved 0.855 mAP, 0.82 precision, 0.83 recall, and 0.82 F1 score. We found as few as ten labelled drone images was sufficient to train an acceptable detection model (0.799 mAP). Our results illustrate the potential of using small, affordable drones with direct implementation of open-source object detection models to survey holothurians and other shallow water sessile species.
KW  - holothurian
KW  - remote sensing
KW  - UAV
KW  - machine learning
KW  - object detection
KW  - YOLOv3
KW  - Great Barrier Reef
KW  - marine ecology
KW  - ecological monitoring
KW  - FAIR data
DO  - 10.3390/drones5020028
TY  - EJOU
AU  - Kazaz, Billur
AU  - Poddar, Subhadipto
AU  - Arabi, Saeed
AU  - Perez, Michael A.
AU  - Sharma, Anuj
AU  - Whitman, J. B.
TI  - Deep Learning-Based Object Detection for Unmanned Aerial Systems (UASs)-Based Inspections of Construction Stormwater Practices
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 8
SN  - 1424-8220

AB  - Construction activities typically create large amounts of ground disturbance, which can lead to increased rates of soil erosion. Construction stormwater practices are used on active jobsites to protect downstream waterbodies from offsite sediment transport. Federal and state regulations require routine pollution prevention inspections to ensure that temporary stormwater practices are in place and performing as intended. This study addresses the existing challenges and limitations in the construction stormwater inspections and presents a unique approach for performing unmanned aerial system (UAS)-based inspections. Deep learning-based object detection principles were applied to identify and locate practices installed on active construction sites. The system integrates a post-processing stage by clustering results. The developed framework consists of data preparation with aerial inspections, model training, validation of the model, and testing for accuracy. The developed model was created from 800 aerial images and was used to detect four different types of construction stormwater practices at 100% accuracy on the Mean Average Precision (MAP) with minimal false positive detections. Results indicate that object detection could be implemented on UAS-acquired imagery as a novel approach to construction stormwater inspections and provide accurate results for site plan comparisons by rapidly detecting the quantity and location of field-installed stormwater practices.
KW  - construction stormwater management
KW  - inspections
KW  - unmanned aerial systems
KW  - photogrammetry
KW  - deep learning-based object detection
DO  - 10.3390/s21082834
TY  - EJOU
AU  - Poudel, Sabitri
AU  - Moh, Sangman
TI  - Hybrid Path Planning for Efficient Data Collection in UAV-Aided WSNs for Emergency Applications
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 8
SN  - 1424-8220

AB  - In unmanned aerial vehicle (UAV)-aided wireless sensor networks (UWSNs), a UAV is employed as a mobile sink to gather data from sensor nodes. Incorporating UAV helps prolong the network lifetime and avoid the energy-hole problem faced by sensor networks. In emergency applications, timely data collection from sensor nodes and transferal of the data to the base station (BS) is a prime requisite. The timely and safe path of UAV is one of the fundamental premises for effective UWSN operations. It is essential and challenging to identify a suitable path in an environment comprising various obstacles and to ensure that the path can efficiently reach the target point. This paper proposes a hybrid path planning (HPP) algorithm for efficient data collection by assuring the shortest collision-free path for UAV in emergency environments. In the proposed HPP scheme, the probabilistic roadmap (PRM) algorithm is used to design the shortest trajectory map and the optimized artificial bee colony (ABC) algorithm to improve different path constraints in a three-dimensional environment. Our simulation results show that the proposed HPP outperforms the PRM and conventional ABC schemes significantly in terms of flight time, energy consumption, convergence time, and flight path.
KW  - wireless sensor network
KW  - data gathering
KW  - unmanned aerial vehicle
KW  - path planning
KW  - artificial bee colony
KW  - collision avoidance
KW  - delay minimization
KW  - probabilistic roadmap
DO  - 10.3390/s21082839
TY  - EJOU
AU  - Ge, Xiangyu
AU  - Ding, Jianli
AU  - Jin, Xiuliang
AU  - Wang, Jingzhe
AU  - Chen, Xiangyue
AU  - Li, Xiaohang
AU  - Liu, Jie
AU  - Xie, Boqiang
TI  - Estimating Agricultural Soil Moisture Content through UAV-Based Hyperspectral Images in the Arid Region
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - Unmanned aerial vehicle (UAV)-based hyperspectral remote sensing is an important monitoring technology for the soil moisture content (SMC) of agroecological systems in arid regions. This technology develops precision farming and agricultural informatization. However, hyperspectral data are generally used in data mining. In this study, UAV-based hyperspectral imaging data with a resolution o 4 cm and totaling 70 soil samples (0â10 cm) were collected from farmland (2.5 Ã 104 m2) near Fukang City, Xinjiang Uygur Autonomous Region, China. Four estimation strategies were tested: the original image (strategy I), first- and second-order derivative methods (strategy II), the fractional-order derivative (FOD) technique (strategy III), and the optimal fractional order combined with the optimal multiband indices (strategy IV). These strategies were based on the eXtreme Gradient Boost (XGBoost) algorithm, with the aim of building the best estimation model for agricultural SMC in arid regions. The results demonstrated that FOD technology could effectively mine information (with an absolute maximum correlation coefficient of 0.768). By comparison, strategy IV yielded the best estimates out of the methods tested (R2val = 0.921, RMSEP = 1.943, and RPD = 2.736) for the SMC. The model derived from the order of 0.4 within strategy IV worked relatively well among the different derivative methods (strategy I, II, and III). In conclusion, the combination of FOD technology and the optimal multiband indices generated a highly accurate model within the XGBoost algorithm for SMC estimation. This research provided a promising data mining approach for UAV-based hyperspectral imaging data.
KW  - fractional-order derivatives
KW  - ensemble learning
KW  - hyperspectral data
KW  - precision agriculture
DO  - 10.3390/rs13081562
TY  - EJOU
AU  - Peng, Xing
AU  - Kong, Lingbao
AU  - Fuh, Jerry Y.
AU  - Wang, Hao
TI  - A Review of Post-Processing Technologies in Additive Manufacturing
T2  - Journal of Manufacturing and Materials Processing

PY  - 2021
VL  - 5
IS  - 2
SN  - 2504-4494

AB  - Additive manufacturing (AM) technology has rapidly evolved with research advances related to AM processes, materials, and designs. The advantages of AM over conventional techniques include an augmented capability to produce parts with complex geometries, operational flexibility, and reduced production time. However, AM processes also face critical issues, such as poor surface quality and inadequate mechanical properties. Therefore, several post-processing technologies are applied to improve the surface quality of the additively manufactured parts. This work aims to document post-processing technologies and their applications concerning different AM processes. Various types of post-process treatments are reviewed and their integrations with AM process are discussed.
KW  - additive manufacturing
KW  - post-processing
KW  - surface quality
KW  - mechanical properties
DO  - 10.3390/jmmp5020038
TY  - EJOU
AU  - Jimenez, Jose M.
AU  - Parra, Lorena
AU  - GarcÃ­a, Laura
AU  - Lloret, Jaime
AU  - Mauri, Pedro V.
AU  - Lorenz, Pascal
TI  - New Protocol and Architecture for a Wastewater Treatment System Intended for Irrigation
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 8
SN  - 2076-3417

AB  - Water quality may be affected by aspects such as pollution from industries, agricultural fertilizers and pesticides, and waste produced by humans. This contamination can affect the produce of the fields irrigated by untreated water. Therefore, it is necessary to add a treatment process in irrigation systems. In this paper, an architecture, communication protocol, and a data analysis algorithm for a wastewater treatment system intended for irrigation are presented. Our system includes a smart group-based wireless sensor network that is able to detect high salinity levels and pollution stains, such as oil spills. When contamination is detected, the water is led into auxiliary canals that perform the biosorption process to treat the water and dump it back into the main canal. Simulations were performed to assess the amount of data stored on the secure digital (SD) card, the consumed bandwidth, and the energy consumption of our proposal. The results show the system has a low bandwidth consumption with a maximum of 2.58 kbps for the setting of two daily data transmissions of the node in the last auxiliary canal. Furthermore, it can sustain the energy consumption in adverse conditions, where the node with the highest energy consumption reaches the lowest energy value of 12,320 mW/h.
KW  - sensor network
KW  - LoRa
KW  - water quality
KW  - contamination
KW  - precision agriculture
DO  - 10.3390/app11083648
TY  - EJOU
AU  - Wang, Yuping
AU  - Shen, Zehao
TI  - Comparing Luojia 1-01 and VIIRS Nighttime Light Data in Detecting Urban Spatial Structure Using a Threshold-Based Kernel Density Estimation
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - Nighttime light (NTL) data are increasingly used in urban studies and urban planning owing to their strong connection with human activities, although the detection capacity is limited by the spatial resolution of older data. In the present study, we comparedthe results of extractions of urban built-up areas using data obtained from the first professional NTL satellite Luojia 1-01 with a resolution of 130 m and the Visible Infrared Imaging Radiometer Suite (VIIRS). We applied an analyzing framework combing kernel density estimation (KDE) under different search radii and threshold-based extraction to detect the boundary and spatial structure of urban areas. The results showed that: (1) Benefiting from a higher spatial resolution, Luojia 1-01 data was more sensitive in detecting new emerging urban built-up areas, thus better reflected the spatial structure of urban system, and can achieve a higher extraction accuracy than that of VIIRS data; (2) Combining with a proper threshold, KDE improves the extraction accuracy of NTL data by making use of the spatial autocorrelation of nighttime light, thus better detects the scale of the spatial pattern of urban built-up areas; (3) A proper searching radius for KDE is critical for achieving the optimal result, which was 1000 m for Luojia 1-01 and 1600 m for VIIRS in this study. Our findings indicate the usefulness of the KDE method in applying the upcoming high-resolution NTL data such as Luojia 1-01 data in urban spatial analysis and planning.
KW  - kernel density estimation
KW  - Luojia 1-01 satellite
KW  - nighttime light
KW  - spatial resolution
KW  - searching radius threshold
KW  - urban built-up area
DO  - 10.3390/rs13081574
TY  - EJOU
AU  - Haque, Amlan
AU  - Islam, Nahina
AU  - Samrat, Nahidul H.
AU  - Dey, Shuvashis
AU  - Ray, Biplob
TI  - Smart Farming through Responsible Leadership in Bangladesh: Possibilities, Opportunities, and Beyond
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 8
SN  - 2071-1050

AB  - Smart farming has the potential to overcome the challenge of 2050 to feed 10 billion people. Both artificial intelligence (AI) and the internet of things (IoT) have become critical prerequisites to smart farming due to their high interoperability, sensors, and cutting-edge technologies. Extending the role of responsible leadership, this paper proposes an AI and IoT based smart farming system in Bangladesh. With a comprehensive literature review, this paper counsels the need to go beyond the simple application of traditional farming and irrigation practices and recommends implementing smart farming enabling responsible leadership to uphold sustainable agriculture. It contributes to the current literature of smart farming in several ways. First, this paper helps to understand the prospect and challenges of both AI and IoT and the requirement of smart farming in a nonwestern context. Second, it clarifies the interventions of responsible leadership into Bangladeshâs agriculture sector and justifies the demand for sustainable smart farming. Third, this paper is a step forward to explore future empirical studies for the effective and efficient use of AI and IoT to adopt smart farming. Finally, this paper will help policymakers to take responsible initiatives to plan and apply smart farming in a developing economy like Bangladesh.
KW  - sustainable farming
KW  - artificial intelligence (AI)
KW  - internet of things (IoT)
KW  - smart farming
KW  - responsible leadership
KW  - remote communication
DO  - 10.3390/su13084511
TY  - EJOU
AU  - Bukowiecki, Josephine
AU  - Rose, Till
AU  - Kage, Henning
TI  - Sentinel-2 Data for Precision Agriculture?âA UAV-Based Assessment
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 8
SN  - 1424-8220

AB  - An approach of exploiting and assessing the potential of Sentinel-2 data in the context of precision agriculture by using data from an unmanned aerial vehicle (UAV) is presented based on a four-year dataset. An established model for the estimation of the green area index (GAI) of winter wheat from a UAV-based multispectral camera was used to calibrate the Sentinel-2 data. Large independent datasets were used for evaluation purposes. Furthermore, the potential of the satellite-based GAI-predictions for crop monitoring and yield prediction was tested. Therefore, the total absorbed photosynthetic radiation between spring and harvest was calculated with satellite and UAV data and correlated with the final grain yield. Yield maps at the same resolution were generated by combining yield data on a plot level with a UAV-based crop coverage map. The best tested model for satellite-based GAI-prediction was obtained by combining the near-, infrared- and Red Edge-waveband in a simple ratio (R2 = 0.82, mean absolute error = 0.52 m2/m2). Yet, the Sentinel-2 data seem to depict average GAI-developments through the seasons, rather than to map site-specific variations at single acquisition dates. The results show that the lower information content of the satellite-based crop monitoring might be mainly traced back to its coarser Red Edge-band. Additionally, date-specific effects within the Sentinel-2 data were detected. Due to cloud coverage, the temporal resolution was found to be unsatisfactory as well. These results emphasize the need for further research on the applicability of the Sentinel-2 data and a cautious use in the context of precision agriculture.
KW  - Sentinel-2
KW  - UAV
KW  - GAI
KW  - winter wheat
KW  - precision agriculture
DO  - 10.3390/s21082861
TY  - EJOU
AU  - Gibert MartÃ­nez, Isaac
AU  - Afonso, Frederico
AU  - Rodrigues, SimÃ£o
AU  - Lau, Fernando
TI  - A Sequential Approach for Aerodynamic Shape Optimization with Topology Optimization of Airfoils
T2  - Mathematical and Computational Applications

PY  - 2021
VL  - 26
IS  - 2
SN  - 2297-8747

AB  - The objective of this work is to study the coupling of two efficient optimization techniques, Aerodynamic Shape Optimization (ASO) and Topology Optimization (TO), in 2D airfoils. To achieve such goal two open-source codes, SU2 and Calculix, are employed for ASO and TO, respectively, using the Sequential Least SQuares Programming (SLSQP) and the Bi-directional Evolutionary Structural Optimization (BESO) algorithms; the latter is well-known for allowing the addition of material in the TO which constitutes, as far as our knowledge, a novelty for this kind of application. These codes are linked by means of a script capable of reading the geometry and pressure distribution obtained from the ASO and defining the boundary conditions to be applied in the TO. The Free-Form Deformation technique is chosen for the definition of the design variables to be used in the ASO, while the densities of the inner elements are defined as design variables of the TO. As a test case, a widely used benchmark transonic airfoil, the RAE2822, is chosen here with an internal geometric constraint to simulate the wing-box of a transonic wing. First, the two optimization procedures are tested separately to gain insight and then are run in a sequential way for two test cases with available experimental data: (i) Mach 0.729 at Î±=2.31Â°; and (ii) Mach 0.730 at Î±=2.79Â°. In the ASO problem, the lift is fixed and the drag is minimized; while in the TO problem, compliance minimization is set as the objective for a prescribed volume fraction. Improvements in both aerodynamic and structural performance are found, as expected: the ASO reduced the total pressure on the airfoil surface in order to minimize drag, which resulted in lower stress values experienced by the structure.
KW  - aerodynamic shape optimization
KW  - computational fluid dynamics
KW  - topology optimization
KW  - airfoil
DO  - 10.3390/mca26020034
TY  - EJOU
AU  - Zeng, Jie
AU  - Roussis, Panayiotis C.
AU  - Mohammed, Ahmed S.
AU  - Maraveas, Chrysanthos
AU  - Fatemi, Seyed A.
AU  - Armaghani, Danial J.
AU  - Asteris, Panagiotis G.
TI  - Prediction of Peak Particle Velocity Caused by Blasting through the Combinations of Boosted-CHAID and SVM Models with Various Kernels
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 8
SN  - 2076-3417

AB  - This research examines the feasibility of hybridizing boosted Chi-Squared Automatic Interaction Detection (CHAID) with different kernels of support vector machine (SVM) techniques for the prediction of the peak particle velocity (PPV) induced by quarry blasting. To achieve this objective, a boosting-CHAID technique was applied to a big experimental database comprising six input variables. The technique identified four input parameters (distance from blast-face, stemming length, powder factor, and maximum charge per delay) as the most significant parameters affecting the prediction accuracy and utilized them to propose the SVM models with various kernels. The kernel types used in this study include radial basis function, polynomial, sigmoid, and linear. Several criteria, including mean absolute error (MAE), correlation coefficient (R), and gains, were calculated to evaluate the developed modelsâ accuracy and applicability. In addition, a simple ranking system was used to evaluate the modelsâ performance systematically. The performance of the R and MAE index of the radial basis function kernel of SVM in training and testing phases, respectively, confirm the high capability of this SVM kernel in predicting PPV values. This study successfully demonstrates that a combination of boosting-CHAID and SVM models can identify and predict with a high level of accuracy the most effective parameters affecting PPV values.
KW  - ground vibration
KW  - blasting operation
KW  - boosting-CHAID: support vector machine
KW  - input selection
DO  - 10.3390/app11083705
TY  - EJOU
AU  - Seitsonen, Oula
AU  - IkÃ¤heimo, Janne
TI  - Detecting Archaeological Features with Airborne Laser Scanning in the Alpine Tundra of SÃ¡pmi, Northern Finland
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 8
SN  - 2072-4292

AB  - Open access airborne laser scanning (ALS) data have been available in Finland for over a decade and have been actively applied by the Finnish archaeologists in that time. The low resolution of this laser scanning 2008â2019 dataset (0.5 points/m2), however, has hindered its usability for archaeological prospection. In the summer of 2020, the situation changed markedly, when the Finnish National Land Survey started a new countrywide ALS survey with a higher resolution of 5 points/m2. In this paper we present the first results of applying this newly available ALS material for archaeological studies. Finnish LIDARK consortium has initiated the development of semi-automated approaches for visualizing, detecting, and analyzing archaeological features with this new dataset. Our first case studies are situated in the Alpine tundra environment of SÃ¡pmi in northern Finland, and the assessed archaeological features range from prehistoric sites to indigenous SÃ¡mi reindeer herding features and Second Word War-era German military structures. Already the initial analyses of the new ALS-5p data show their huge potential for locating, mapping, and assessing archaeological material. These results also suggest an imminent burst in the number of known archaeological sites, especially in the poorly accessible and little studied northern wilderness areas, when more data become available.
KW  - archaeology
KW  - airborne laser scanning
KW  - LiDAR
KW  - Finland
KW  - Lapland
KW  - SÃ¡pmi
KW  - tundra
DO  - 10.3390/rs13081599
TY  - EJOU
AU  - HrÃºz, Michal
AU  - Bugaj, Martin
AU  - NovÃ¡k, Andrej
AU  - Kandera, Branislav
AU  - BadÃ¡nik, Benedikt
TI  - The Use of UAV with Infrared Camera and RFID for Airframe Condition Monitoring
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 9
SN  - 2076-3417

AB  - The new progressive smart technologies announced in the fourth industrial revolution in aviationâAviation 4.0ârepresent new possibilities and big challenges in aircraft maintenance processes. The main benefit of these technologies is the possibility to monitor, transfer, store, and analyze huge datasets. Based on analysis outputs, there is a possibility to improve current preventive maintenance processes and implement predictive maintenance processes. These solutions lower the downtime, save manpower, and extend the componentsâ lifetime; thus, the maximum effectivity and safety is achieved. The article deals with the possible implementation of an unmanned aerial vehicle (UAV) with an infrared camera and Radio Frequency Identification (RFID) as two of the smart hangar technologies for airframe condition monitoring. The presented implementations of smart technologies follow up the specific results of a case study focused on trainer aircraft failure monitoring and its impact on maintenance strategy changes. The case study failure indexes show the critical parts of aircraft that are subjected to damage the most. The aim of the article was to justify the need for thorough monitoring of critical parts of the aircraft and then analyze and propose a more effective and the most suitable form of technical condition monitoring of aircraft critical parts. The article describes the whole process of visual inspection performed by an unmanned aerial vehicle (UAV) with an IR camera and its related processes; in addition, it covers the possible usage of RFID tags as a labeling tool supporting the visual inspection. The implementations criteria apply to the repair and overhaul small aircraft maintenance organization, and later, it can also increase operational efficiency. The final suggestions describe the possible usage of proposed solutions, their main benefits, and also the limitations of their implementations in maintenance of trainer aircraft.
KW  - smart technologies
KW  - smart hangar
KW  - technical condition monitoring
KW  - UAV
KW  - RFID
DO  - 10.3390/app11093737
TY  - EJOU
AU  - Yan, Bin
AU  - Fan, Pan
AU  - Lei, Xiaoyan
AU  - Liu, Zhijie
AU  - Yang, Fuzeng
TI  - A Real-Time Apple Targets Detection Method for Picking Robot Based on Improved YOLOv5
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - The apple target recognition algorithm is one of the core technologies of the apple picking robot. However, most of the existing apple detection algorithms cannot distinguish between the apples that are occluded by tree branches and occluded by other apples. The apples, grasping end-effector and mechanical picking arm of the robot are very likely to be damaged if the algorithm is directly applied to the picking robot. Based on this practical problem, in order to automatically recognize the graspable and ungraspable apples in an apple tree image, a light-weight apple targets detection method was proposed for picking robot using improved YOLOv5s. Firstly, BottleneckCSP module was improved designed to BottleneckCSP-2 module which was used to replace the BottleneckCSP module in backbone architecture of original YOLOv5s network. Secondly, SE module, which belonged to the visual attention mechanism network, was inserted to the proposed improved backbone network. Thirdly, the bonding fusion mode of feature maps, which were inputs to the target detection layer of medium size in the original YOLOv5s network, were improved. Finally, the initial anchor box size of the original network was improved. The experimental results indicated that the graspable apples, which were unoccluded or only occluded by tree leaves, and the ungraspable apples, which were occluded by tree branches or occluded by other fruits, could be identified effectively using the proposed improved network model in this study. Specifically, the recognition recall, precision, mAP and F1 were 91.48%, 83.83%, 86.75% and 87.49%, respectively. The average recognition time was 0.015 s per image. Contrasted with original YOLOv5s, YOLOv3, YOLOv4 and EfficientDet-D0 model, the mAP of the proposed improved YOLOv5s model increased by 5.05%, 14.95%, 4.74% and 6.75% respectively, the size of the model compressed by 9.29%, 94.6%, 94.8% and 15.3% respectively. The average recognition speeds per image of the proposed improved YOLOv5s model were 2.53, 1.13 and 3.53 times of EfficientDet-D0, YOLOv4 and YOLOv3 and model, respectively. The proposed method can provide technical support for the real-time accurate detection of multiple fruit targets for the apple picking robot.
KW  - artificial intelligence
KW  - convolutional neural network
KW  - YOLOv5
KW  - object detection
KW  - apple picking robot
KW  - lightweight
KW  - real-time detection
DO  - 10.3390/rs13091619
TY  - EJOU
AU  - Kwak, Geun-Ho
AU  - Park, Chan-won
AU  - Lee, Kyung-do
AU  - Na, Sang-il
AU  - Ahn, Ho-yong
AU  - Park, No-Wook
TI  - Potential of Hybrid CNN-RF Model for Early Crop Mapping with Limited Input Data
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - When sufficient time-series images and training data are unavailable for crop classification, features extracted from convolutional neural network (CNN)-based representative learning may not provide useful information to discriminate crops with similar spectral characteristics, leading to poor classification accuracy. In particular, limited input data are the main obstacles to obtain reliable classification results for early crop mapping. This study investigates the potential of a hybrid classification approach, i.e., CNN-random forest (CNN-RF), in the context of early crop mapping, that combines the automatic feature extraction capability of CNN with the superior discrimination capability of an RF classifier. Two experiments on incremental crop classification with unmanned aerial vehicle images were conducted to compare the performance of CNN-RF with that of CNN and RF with respect to the length of the time-series and training data sizes. When sufficient time-series images and training data were used for the classification, the accuracy of CNN-RF was slightly higher or comparable with that of CNN. In contrast, when fewer images and the smallest training data were used at the early crop growth stage, CNN-RF was substantially beneficial and the overall accuracy increased by maximum 6.7%p and 4.6%p in the two study areas, respectively, compared to CNN. This is attributed to its ability to discriminate crops from features with insufficient information using a more sophisticated classifier. The experimental results demonstrate that CNN-RF is an effective classifier for early crop mapping when only limited input images and training samples are available.
KW  - crop classification
KW  - convolution neural networks
KW  - random forest
KW  - hybrid model
KW  - training data
KW  - time-series images
DO  - 10.3390/rs13091629
TY  - EJOU
AU  - Ge, Haixiao
AU  - Xiang, Haitao
AU  - Ma, Fei
AU  - Li, Zhenwang
AU  - Qiu, Zhengchao
AU  - Tan, Zhengzheng
AU  - Du, Changwen
TI  - Estimating Plant Nitrogen Concentration of Rice through Fusing Vegetation Indices and Color Moments Derived from UAV-RGB Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - Estimating plant nitrogen concentration (PNC) has been conducted using vegetation indices (VIs) from UAV-based imagery, but color features have been rarely considered as additional variables. In this study, the VIs and color moments (color feature) were calculated from UAV-based RGB images, then partial least square regression (PLSR) and random forest regression (RF) models were established to estimate PNC through fusing VIs and color moments. The results demonstrated that the fusion of VIs and color moments as inputs yielded higher accuracies of PNC estimation compared to VIs or color moments as input; the RF models based on the combination of VIs and color moments (R2 ranging from 0.69 to 0.91 and NRMSE ranging from 0.07 to 0.13) showed similar performances to the PLSR models (R2 ranging from 0.68 to 0.87 and NRMSE ranging from 0.10 to 0.29); Among the top five important variables in the RF models, there was at least one variable which belonged to the color moments in different datasets, indicating the significant contribution of color moments in improving PNC estimation accuracy. This revealed the great potential of combination of RGB-VIs and color moments for the estimation of rice PNC.
KW  - UAV
KW  - plant nitrogen concentration
KW  - RGB-VIs
KW  - color moments
KW  - PLSR
KW  - RF
DO  - 10.3390/rs13091620
TY  - EJOU
AU  - Pourroostaei Ardakani, Saeid
TI  - MINDS: Mobile Agent Itinerary Planning Using Named Data Networking in Wireless Sensor Networks
T2  - Journal of Sensor and Actuator Networks

PY  - 2021
VL  - 10
IS  - 2
SN  - 2224-2708

AB  - Mobile agents have the potential to offer benefits, as they are able to either independently or cooperatively move throughout networks and collect/aggregate sensory data samples. They are programmed to autonomously move and visit sensory data stations through optimal paths, which are established according to the application requirements. However, mobile agent routing protocols still suffer heavy computation/communication overheads, lack of route planning accuracy and long-delay mobile agent migrations. For this, mobile agent route planning protocols aim to find the best-fitted paths for completing missions (e.g., data collection) with minimised delay, maximised performance and minimised transmitted traffic. This article proposes a mobile agent route planning protocol for sensory data collection called MINDS. The key goal of this MINDS is to reduce network traffic, maximise data robustness and minimise delay at the same time. This protocol utilises the Hamming distance technique to partition a sensor network into a number of data-centric clusters. In turn, a named data networking approach is used to form the cluster-heads as a data-centric, tree-based communication infrastructure. The mobile agents utilise a modified version of the Depth-First Search algorithm to move through the tree infrastructure according to a hop-count-aware fashion. As the simulation results show, MINDS reduces path length, reduces network traffic and increases data robustness as compared with two conventional benchmarks (ZMA and TBID) in dense and large wireless sensor networks.
KW  - wireless sensor networks
KW  - named data networking
KW  - mobile agents
KW  - itinerary planning
DO  - 10.3390/jsan10020028
TY  - EJOU
AU  - Azar, Ahmad T.
AU  - Koubaa, Anis
AU  - Ali Mohamed, Nada
AU  - Ibrahim, Habiba A.
AU  - Ibrahim, Zahra F.
AU  - Kazim, Muhammad
AU  - Ammar, Adel
AU  - Benjdira, Bilel
AU  - Khamis, Alaa M.
AU  - Hameed, Ibrahim A.
AU  - Casalino, Gabriella
TI  - Drone Deep Reinforcement Learning: A Review
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 9
SN  - 2079-9292

AB  - Unmanned Aerial Vehicles (UAVs) are increasingly being used in many challenging and diversified applications. These applications belong to the civilian and the military fields. To name a few; infrastructure inspection, traffic patrolling, remote sensing, mapping, surveillance, rescuing humans and animals, environment monitoring, and Intelligence, Surveillance, Target Acquisition, and Reconnaissance (ISTAR) operations. However, the use of UAVs in these applications needs a substantial level of autonomy. In other words, UAVs should have the ability to accomplish planned missions in unexpected situations without requiring human intervention. To ensure this level of autonomy, many artificial intelligence algorithms were designed. These algorithms targeted the guidance, navigation, and control (GNC) of UAVs. In this paper, we described the state of the art of one subset of these algorithms: the deep reinforcement learning (DRL) techniques. We made a detailed description of them, and we deduced the current limitations in this area. We noted that most of these DRL methods were designed to ensure stable and smooth UAV navigation by training computer-simulated environments. We realized that further research efforts are needed to address the challenges that restrain their deployment in real-life scenarios.
KW  - unmanned aerial vehicles
KW  - UAVs
KW  - guidance
KW  - navigation
KW  - control
KW  - machine learning
KW  - deep reinforcement learning (DRL)
KW  - literature review
DO  - 10.3390/electronics10090999
TY  - EJOU
AU  - Kashyap, Bhuwan
AU  - Kumar, Ratnesh
TI  - Sensing Methodologies in Agriculture for Monitoring Biotic Stress in Plants Due to Pathogens and Pests
T2  - Inventions

PY  - 2021
VL  - 6
IS  - 2
SN  - 2411-5134

AB  - Reducing agricultural losses is an effective way to sustainably increase agricultural output efficiency to meet our present and future needs for food, fiber, fodder, and fuel. Our ever-improving understanding of the ways in which plants respond to stress, biotic and abiotic, has led to the development of innovative sensing technologies for detecting crop stresses/stressors and deploying efficient measures. This article aims to present the current state of the methodologies applied in the field of agriculture towards the detection of biotic stress in crops. Key sensing methodologies for plant pathogen (or phytopathogen), as well as herbivorous insects/pests are presented, where the working principles are described, and key recent works discussed. The detection methods overviewed for phytopathogen-related stress identification include nucleic acid-based methods, immunological methods, imaging-based techniques, spectroscopic methods, phytohormone biosensing methods, monitoring methods for plant volatiles, and active remote sensing technologies. Whereas the pest-related sensing techniques include machine-vision-based methods, pest acoustic-emission sensors, and volatile organic compound-based stress monitoring methods. Additionally, Comparisons have been made between different sensing techniques as well as recently reported works, where the strengths and limitations are identified. Finally, the prospective future directions for monitoring biotic stress in crops are discussed.
KW  - biosensors
KW  - hyperspectral
KW  - thermography
KW  - electrochemical
KW  - hormones
KW  - fluorescence
KW  - acoustic
KW  - spectroscopy
KW  - remote sensing
KW  - volatile organic compounds
DO  - 10.3390/inventions6020029
TY  - EJOU
AU  - Gargees, Rasha S.
AU  - Scott, Grant J.
TI  - Large-Scale, Multiple Level-of-Detail Change Detection from Remote Sensing Imagery Using Deep Visual Feature Clustering
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 9
SN  - 2072-4292

AB  - In the era of big data, where massive amounts of remotely sensed imagery can be obtained from various satellites accompanied by the rapid change in the surface of the Earth, new techniques for large-scale change detection are necessary to facilitate timely and effective human understanding of natural and human-made phenomena. In this research, we propose a chip-based change detection method that is enabled by using deep neural networks to extract visual features. These features are transformed into deep orthogonal visual features that are then clustered based on land cover characteristics. The resulting chip cluster memberships allow arbitrary level-of-detail change analysis that can also support irregular geospatial extent based agglomerations. The proposed methods naturally support cross-resolution temporal scenes without requiring normalization of the pixel resolution across scenes and without requiring pixel-level coregistration processes. This is achieved with configurable spatial locality comparisons between years, where the aperture of a unit of measure can be a single chip, a small neighborhood of chips, or a large irregular geospatial region. The performance of our proposed method has been validated using various quantitative and statistical metrics in addition to presenting the visual geo-maps and the percentage of the change. The results show that our proposed method efficiently detected the change from a large scale area.
KW  - change detection
KW  - big data
KW  - deep features
KW  - fuzzy clustering
KW  - transfer learning
KW  - land cover
DO  - 10.3390/rs13091661

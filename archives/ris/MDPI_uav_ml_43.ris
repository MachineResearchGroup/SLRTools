TY  - EJOU
AU  - Ma, Huiqin
AU  - Huang, Wenjiang
AU  - Dong, Yingying
AU  - Liu, Linyi
AU  - Guo, Anting
TI  - Using UAV-Based Hyperspectral Imagery to Detect Winter Wheat Fusarium Head Blight
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 15
SN  - 2072-4292

AB  - Fusarium head blight (FHB) is a major winter wheat disease in China. The accurate and timely detection of wheat FHB is vital to scientific field management. By combining three types of spectral features, namely, spectral bands (SBs), vegetation indices (VIs), and wavelet features (WFs), in this study, we explore the potential of using hyperspectral imagery obtained from an unmanned aerial vehicle (UAV), to detect wheat FHB. First, during the wheat filling period, two UAV-based hyperspectral images were acquired. SBs, VIs, and WFs that were sensitive to wheat FHB were extracted and optimized from the two images. Subsequently, a field-scale wheat FHB detection model was formulated, based on the optimal spectral feature combination of SBs, VIs, and WFs (SBs + VIs + WFs), using a support vector machine. Two commonly used data normalization algorithms were utilized before the construction of the model. The single WFs, and the spectral feature combination of optimal SBs and VIs (SBs + VIs), were respectively used to formulate models for comparison and testing. The results showed that the detection model based on the normalized SBs + VIs + WFs, using min–max normalization algorithm, achieved the highest R2 of 0.88 and the lowest RMSE of 2.68% among the three models. Our results suggest that UAV-based hyperspectral imaging technology is promising for the field-scale detection of wheat FHB. Combining traditional SBs and VIs with WFs can improve the detection accuracy of wheat FHB effectively.
KW  - crop disease
KW  - remote sensing detection
KW  - hyperspectral imaging
KW  - spectral feature combination
KW  - data normalization
DO  - 10.3390/rs13153024
ER  -
TY  - EJOU
AU  - Sharma, Meenakshi
AU  - Kaushik, Prashant
AU  - Chawade, Aakash
TI  - Frontiers in the Solicitation of Machine Learning Approaches in Vegetable Science Research
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 15
SN  - 2071-1050

AB  - Along with essential nutrients and trace elements, vegetables provide raw materials for the food processing industry. Despite this, plant diseases and unfavorable weather patterns continue to threaten the delicate balance between vegetable production and consumption. It is critical to utilize machine learning (ML) in this setting because it provides context for decision-making related to breeding goals. Cutting-edge technologies for crop genome sequencing and phenotyping, combined with advances in computer science, are currently fueling a revolution in vegetable science and technology. Additionally, various ML techniques such as prediction, classification, and clustering are frequently used to forecast vegetable crop production in the field. In the vegetable seed industry, machine learning algorithms are used to assess seed quality before germination and have the potential to improve vegetable production with desired features significantly; whereas, in plant disease detection and management, the ML approaches can improve decision-support systems that assist in converting massive amounts of data into valuable recommendations. On similar lines, in vegetable breeding, ML approaches are helpful in predicting treatment results, such as what will happen if a gene is silenced. Furthermore, ML approaches can be a saviour to insufficient coverage and noisy data generated using various omics platforms. This article examines ML models in the field of vegetable sciences, which encompasses breeding, biotechnology, and genome sequencing.
KW  - machine learning
KW  - vegetables
KW  - models
KW  - predictions
KW  - breeding
KW  - biotechnology
KW  - genomics
DO  - 10.3390/su13158600
ER  -
TY  - EJOU
AU  - Doukari, Michaela
AU  - Batsaris, Marios
AU  - Topouzelis, Konstantinos
TI  - UASea: A Data Acquisition Toolbox for Improving Marine Habitat Mapping
T2  - Drones

PY  - 2021
VL  - 5
IS  - 3
SN  - 2504-446X

AB  - Unmanned aerial systems (UAS) are widely used in the acquisition of high-resolution information in the marine environment. Although the potential applications of UAS in marine habitat mapping are constantly increasing, many limitations need to be overcome—most of which are related to the prevalent environmental conditions—to reach efficient UAS surveys. The knowledge of the UAS limitations in marine data acquisition and the examination of the optimal flight conditions led to the development of the UASea toolbox. This study presents the UASea, a data acquisition toolbox that is developed for efficient UAS surveys in the marine environment. The UASea uses weather forecast data (i.e., wind speed, cloud cover, precipitation probability, etc.) and adaptive thresholds in a ruleset that calculates the optimal flight times in a day for the acquisition of reliable marine imagery using UAS in a given day. The toolbox provides hourly positive and negative suggestions, based on optimal or non-optimal survey conditions in a day, calculated according to the ruleset calculations. We acquired UAS images in optimal and non-optimal conditions and estimated their quality using an image quality equation. The image quality estimates are based on the criteria of sunglint presence, sea surface texture, water turbidity, and image naturalness. The overall image quality estimates were highly correlated with the suggestions of the toolbox, with a correlation coefficient of −0.84. The validation showed that 40% of the toolbox suggestions were a positive match to the images with higher quality. Therefore, we propose the optimal flight times to acquire reliable and accurate UAS imagery in the coastal environment through the UASea. The UASea contributes to proper flight planning and efficient UAS surveys by providing valuable information for mapping, monitoring, and management of the marine environment, which can be used globally in research and marine applications.
KW  - UAS
KW  - UASea
KW  - marine habitat mapping
KW  - image quality
KW  - UAS toolbox
DO  - 10.3390/drones5030073
ER  -
TY  - EJOU
AU  - Sheu, Ming-Hwa
AU  - Jhang, Yu-Syuan
AU  - Morsalin, S M.
AU  - Huang, Yao-Fong
AU  - Sun, Chi-Chia
AU  - Lai, Shin-Chi
TI  - UAV Object Tracking Application Based on Patch Color Group Feature on Embedded System
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 15
SN  - 2079-9292

AB  - The discriminative object tracking system for unmanned aerial vehicles (UAVs) is widely used in numerous applications. While an ample amount of research has been carried out in this domain, implementing a low computational cost algorithm on a UAV onboard embedded system is still challenging. To address this issue, we propose a low computational complexity discriminative object tracking system for UAVs approach using the patch color group feature (PCGF) framework in this work. The tracking object is separated into several non-overlapping local image patches then the features are extracted into the PCGFs, which consist of the Gaussian mixture model (GMM). The object location is calculated by the similar PCGFs comparison from the previous frame and current frame. The background PCGFs of the object are removed by four directions feature scanning and dynamic threshold comparison, which improve the performance accuracy. In the terms of speed execution, the proposed algorithm accomplished 32.5 frames per second (FPS) on the x64 CPU platform without a GPU accelerator and 17 FPS in Raspberry Pi 4. Therefore, this work could be considered as a good solution for achieving a low computational complexity PCGF algorithm on a UAV onboard embedded system to improve flight times.
KW  - unmanned aerial vehicle (UAV)
KW  - UAV object tracking
KW  - Gaussian mixture model (GMM)
KW  - patch color group feature (PCGF)
KW  - embedded system
DO  - 10.3390/electronics10151864
ER  -
TY  - EJOU
AU  - Lee, Dong-Ho
AU  - Kim, Hyeon-Jin
AU  - Park, Jong-Hwa
TI  - UAV, a Farm Map, and Machine Learning Technology Convergence Classification Method of a Corn Cultivation Area
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 8
SN  - 2073-4395

AB  - South Korea’s agriculture is characterized by a mixture of various cultivated crops. In such an agricultural environment, convergence technology for ICT (information, communications, and technology) and AI (artificial intelligence) as well as agriculture is required to classify objects and predict yields. In general, the classification of paddy fields and field boundaries takes a lot of time and effort. The Farm Map was developed to clearly demarcate and classify the boundaries of paddy fields and fields in Korea. Therefore, this study tried to minimize the time and effort required to divide paddy fields and fields through the application of the Farm Map. To improve the fact that UAV image processing for a wide area requires a lot of time and effort to classify objects, we suggest a method for optimizing cultivated crop recognition. This study aimed to evaluate the applicability and effectiveness of machine learning classification techniques using a Farm Map in object-based mapping of agricultural land using unmanned aerial vehicles (UAVs). In this study, the advanced function selection method for object classification is to improve classification accuracy by using two types of classifiers, support vector machine (SVM) and random forest (RF). As a result of classification by applying a Farm Map-based SVM algorithm to wide-area UAV images, producer’s accuracy (PA) was 81.68%, user’s accuracy (UA) was 75.09%, the Kappa coefficient was 0.77, and the F-measure was 0.78. The results of classification by the Farm Map-based RF algorithm were as follows: PA of 96.58%, UA of 92.27%, a Kappa coefficient of 0.94, and the F-measure of 0.94. In the cultivation environment in which various crops were mixed, the corn cultivation area was estimated to be 96.54 ha by SVM, showing an accuracy of 90.27%. RF provided an estimate of 98.77 ha and showed an accuracy of 92.36%, which was higher than that of SVM. As a result of using the Farm Map for the object-based classification method, the agricultural land classification showed a higher efficiency in terms of time than the existing object classification method. Most importantly, it was confirmed that the efficiency of data processing can be increased by minimizing the possibility of misclassification in the obtained results. The obtained results confirmed that rapid and reliable analysis is possible when the cultivated area of crops is identified using UAV images, a Farm Map, and machine learning.
KW  - unmanned aerial vehicles
KW  - Farm Map
KW  - support vector machines
KW  - random forest
DO  - 10.3390/agronomy11081554
ER  -
TY  - EJOU
AU  - Ghajar, Shayan
AU  - Tracy, Benjamin
TI  - Proximal Sensing in Grasslands and Pastures
T2  - Agriculture

PY  - 2021
VL  - 11
IS  - 8
SN  - 2077-0472

AB  - Reliable measures of biomass, species composition, nitrogen status, and nutritive value provide important indicators of the status of pastures and rangelands, allowing managers to make informed decisions. Traditional methods of sample collection necessitate significant investments in time and labor. Proximal sensing technologies have the potential to collect more data with a smaller investment in time and labor. However, methods and protocols for conducting pasture assessments with proximal sensors are still in development, equipment and software vary considerably, and the accuracy and utility of these assessments differ between methods and sites. This review summarizes the methods currently being developed to assess pastures and rangelands worldwide and discusses these emerging technologies in the context of diffusion of innovation theory.
KW  - proximal
KW  - sensing
KW  - LiDAR
KW  - photogrammetry
KW  - grasslands
KW  - pastures
DO  - 10.3390/agriculture11080740
ER  -
TY  - EJOU
AU  - Santana, Lucas S.
AU  - Ferraz, Gabriel A.
AU  - Teodoro, Alberdan J.
AU  - Santana, Mozarte S.
AU  - Rossi, Giuseppe
AU  - Palchetti, Enrico
TI  - Advances in Precision Coffee Growing Research: A Bibliometric Review
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 8
SN  - 2073-4395

AB  - Precision coffee-growing technologies contribute to increased yield, operational efficiency, and final product quality. In addition, they strengthen coffee growing in the global agricultural scenario, which makes this activity increasingly competitive. Scientific research is essential for technological development and offering security regarding its application. For relevant research identification, bibliometric revision methods expose the best studies and their relationships with countries and authors, providing a complete map of research directions. This study identified the main contributions and contributors to academic research generation about precision coffee growing from 2000 to 2021. Bibliometric analysis was performed in VOSViewer software from the referential bases Scopus and Web of Science that identified 150 articles. Based on the number of citations, publications about precision coffee-growing showed Brazilian institutions at the top of the list, and Brazil’s close relationships with North American and South African institutions. Geostatistical analysis, remote sensing and spatial variability mapping of cultivation areas were used in most experimental research. A trend in research exploring machine learning technologies and autonomous systems was evident. The identification of the main agents of scientific development in precision coffee growing contributes to objective advances in the development and application of new management systems. Overall, this analysis represents wide precision coffee growing research providing valuable information for farmers, policymakers, and researchers.
KW  - precision agriculture
KW  - analysis
KW  - bibliometry
KW  - coffee farm
KW  - systematic review
DO  - 10.3390/agronomy11081557
ER  -
TY  - EJOU
AU  - Stuart, Mary B.
AU  - McGonigle, Andrew J. S.
AU  - Davies, Matthew
AU  - Hobbs, Matthew J.
AU  - Boone, Nicholas A.
AU  - Stanger, Leigh R.
AU  - Zhu, Chengxi
AU  - Pering, Tom D.
AU  - Willmott, Jon R.
TI  - Low-Cost Hyperspectral Imaging with A Smartphone
T2  - Journal of Imaging

PY  - 2021
VL  - 7
IS  - 8
SN  - 2313-433X

AB  - Recent advances in smartphone technologies have opened the door to the development of accessible, highly portable sensing tools capable of accurate and reliable data collection in a range of environmental settings. In this article, we introduce a low-cost smartphone-based hyperspectral imaging system that can convert a standard smartphone camera into a visible wavelength hyperspectral sensor for ca. £100. To the best of our knowledge, this represents the first smartphone capable of hyperspectral data collection without the need for extensive post processing. The Hyperspectral Smartphone’s abilities are tested in a variety of environmental applications and its capabilities directly compared to the laboratory-based analogue from our previous research, as well as the wider existing literature. The Hyperspectral Smartphone is capable of accurate, laboratory- and field-based hyperspectral data collection, demonstrating the significant promise of both this device and smartphone-based hyperspectral imaging as a whole.
KW  - hyperspectral
KW  - smartphone
KW  - low-cost
KW  - environmental monitoring
KW  - field deployable
KW  - portable
DO  - 10.3390/jimaging7080136
ER  -
TY  - EJOU
AU  - Pikalov, Simon
AU  - Azaria, Elisha
AU  - Sonnenberg, Shaya
AU  - Ben-Moshe, Boaz
AU  - Azaria, Amos
TI  - Vision-Less Sensing for Autonomous Micro-Drones
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 16
SN  - 1424-8220

AB  - This work presents a concept of intelligent vision-less micro-drones, which are motivated by flying animals such as insects, birds, and bats. The presented micro-drone (named BAT: Blind Autonomous Tiny-drone) can perform bio-inspired complex tasks without the use of cameras. The BAT uses LIDARs and self-emitted optical-flow in order to perform obstacle avoiding and maze-solving. The controlling algorithms were implemented on an onboard micro-controller, allowing the BAT to be fully autonomous. We further present a method for using the information collected by the drone to generate a detailed mapping of the environment. A complete model of the BAT was implemented and tested using several scenarios both in simulation and field experiments, in which it was able to explore and map complex building autonomously even in total darkness.
KW  - autonomous micro-drones
KW  - sensor fusion
KW  - indoor mapping
KW  - bio-inspired micro-robotics
DO  - 10.3390/s21165293
ER  -
TY  - EJOU
AU  - Qi, Guanghui
AU  - Chang, Chunyan
AU  - Yang, Wei
AU  - Gao, Peng
AU  - Zhao, Gengxing
TI  - Soil Salinity Inversion in Coastal Corn Planting Areas by the Satellite-UAV-Ground Integration Approach
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 16
SN  - 2072-4292

AB  - Soil salinization is a significant factor affecting corn growth in coastal areas. How to use multi-source remote sensing data to achieve the target of rapid, efficient and accurate soil salinity monitoring in a large area is worth further study. In this research, using Kenli District of the Yellow River Delta as study area, the inversion of soil salinity in a corn planting area was carried out based on the integration of ground imaging hyperspectral, unmanned aerial vehicles (UAV) multispectral and Sentinel-2A satellite multispectral images. The UAV and ground images were fused, and the partial least squares inversion model was constructed by the fused UAV image. Then, inversion model was scaled up to the satellite by the TsHARP method, and finally, the accuracy of the satellite-UAV-ground inversion model and results was verified. The results show that the band fusion of UAV and ground images effectively enrich the spectral information of the UAV image. The accuracy of the inversion model constructed based on the fused UAV images was improved. The inversion results of soil salinity based on the integration of satellite-UAV-ground were highly consistent with the measured soil salinity (R2 = 0.716 and RMSE = 0.727), and the inversion model had excellent universal applicability. This research integrated the advantages of multi-source data to establish a unified satellite-UAV-ground model, which improved the ability of large-scale remote sensing data to finely indicate soil salinity.
KW  - Sentinel-2A
KW  - UAV
KW  - ground imaging hyperspectral
KW  - multi-source remote sensing data
KW  - soil salinity
DO  - 10.3390/rs13163100
ER  -
TY  - EJOU
AU  - Sinaice, Brian B.
AU  - Owada, Narihiro
AU  - Saadat, Mahdi
AU  - Toriya, Hisatoshi
AU  - Inagaki, Fumiaki
AU  - Bagai, Zibisani
AU  - Kawamura, Youhei
TI  - Coupling NCA Dimensionality Reduction with Machine Learning in Multispectral Rock Classification Problems
T2  - Minerals

PY  - 2021
VL  - 11
IS  - 8
SN  - 2075-163X

AB  - Though multitudes of industries depend on the mining industry for resources, this industry has taken hits in terms of declining mineral ore grades and its current use of traditional, time-consuming and computationally costly rock and mineral identification methods. Therefore, this paper proposes integrating Hyperspectral Imaging, Neighbourhood Component Analysis (NCA) and Machine Learning (ML) as a combined system that can identify rocks and minerals. Modestly put, hyperspectral imaging gathers electromagnetic signatures of the rocks in hundreds of spectral bands. However, this data suffers from what is termed the ‘dimensionality curse’, which led to our employment of NCA as a dimensionality reduction technique. NCA, in turn, highlights the most discriminant feature bands, number of which being dependent on the intended application(s) of this system. Our envisioned application is rock and mineral classification via unmanned aerial vehicle (UAV) drone technology. In this study, we performed a 204-hyperspectral to 5-band multispectral reduction, because current production drones are limited to five multispectral bands sensors. Based on these bands, we applied ML to identify and classify rocks, thereby proving our hypothesis, reducing computational costs, attaining an ML classification accuracy of 71%, and demonstrating the potential mining industry optimisations attainable through this integrated system.
KW  - hyperspectral imaging
KW  - multispectral imaging
KW  - dimensionality reduction
KW  - neighbourhood component analysis
KW  - artificial intelligence
KW  - machine learning
DO  - 10.3390/min11080846
ER  -
TY  - EJOU
AU  - Jembre, Yalew Z.
AU  - Nugroho, Yuniarto W.
AU  - Khan, Muhammad T.
AU  - Attique, Muhammad
AU  - Paul, Rajib
AU  - Shah, Syed H.
AU  - Kim, Beomjoon
TI  - Evaluation of Reinforcement and Deep Learning Algorithms in Controlling Unmanned Aerial Vehicles
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 16
SN  - 2076-3417

AB  - Unmanned Aerial Vehicles (UAVs) are abundantly becoming a part of society, which is a trend that is expected to grow even further. The quadrotor is one of the drone technologies that is applicable in many sectors and in both military and civilian activities, with some applications requiring autonomous flight. However, stability, path planning, and control remain significant challenges in autonomous quadrotor flights. Traditional control algorithms, such as proportional-integral-derivative (PID), have deficiencies, especially in tuning. Recently, machine learning has received great attention in flying UAVs to desired positions autonomously. In this work, we configure the quadrotor to fly autonomously by using agents (the machine learning schemes being used to fly the quadrotor autonomously) to learn about the virtual physical environment. The quadrotor will fly from an initial to a desired position. When the agent brings the quadrotor closer to the desired position, it is rewarded; otherwise, it is punished. Two reinforcement learning models, Q-learning and SARSA, and a deep learning deep Q-network network are used as agents. The simulation is conducted by integrating the robot operating system (ROS) and Gazebo, which allowed for the implementation of the learning algorithms and the physical environment, respectively. The result has shown that the Deep Q-network network with Adadelta optimizer is the best setting to fly the quadrotor from the initial to desired position.
KW  - reinforcement learning
KW  - UAV
KW  - quadrotor
KW  - flight control
KW  - intelligent control
DO  - 10.3390/app11167240
ER  -
TY  - EJOU
AU  - Kim, Yongsu
AU  - Kang, Hyoeun
AU  - Suryanto, Naufal
AU  - Larasati, Harashta T.
AU  - Mukaroh, Afifatul
AU  - Kim, Howon
TI  - Extended Spatially Localized Perturbation GAN (eSLP-GAN) for Robust Adversarial Camouflage Patches
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 16
SN  - 1424-8220

AB  - Deep neural networks (DNNs), especially those used in computer vision, are highly vulnerable to adversarial attacks, such as adversarial perturbations and adversarial patches. Adversarial patches, often considered more appropriate for a real-world attack, are attached to the target object or its surroundings to deceive the target system. However, most previous research employed adversarial patches that are conspicuous to human vision, making them easy to identify and counter. Previously, the spatially localized perturbation GAN (SLP-GAN) was proposed, in which the perturbation was only added to the most representative area of the input images, creating a spatially localized adversarial camouflage patch that excels in terms of visual fidelity and is, therefore, difficult to detect by human vision. In this study, the use of the method called eSLP-GAN was extended to deceive classifiers and object detection systems. Specifically, the loss function was modified for greater compatibility with an object-detection model attack and to increase robustness in the real world. Furthermore, the applicability of the proposed method was tested on the CARLA simulator for a more authentic real-world attack scenario.
KW  - adversarial patch
KW  - generative adversarial networks
KW  - camouflage
DO  - 10.3390/s21165323
ER  -
TY  - EJOU
AU  - Yu, Jody
AU  - Wang, Jinfei
AU  - Leblon, Brigitte
TI  - Evaluation of Soil Properties, Topographic Metrics, Plant Height, and Unmanned Aerial Vehicle Multispectral Imagery Using Machine Learning Methods to Estimate Canopy Nitrogen Weight in Corn
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 16
SN  - 2072-4292

AB  - Management of nitrogen (N) fertilizers is an important agricultural practice and field of research to minimize environmental impacts and the cost of production. To apply N fertilizer at the right rate, time, and place depends on the crop type, desired yield, and field conditions. The objective of this study is to use Unmanned Aerial Vehicle (UAV) multispectral imagery, vegetation indices (VI), crop height, field topographic metrics, and soil properties to predict canopy nitrogen weight (g/m2) of a corn field in southwestern Ontario, Canada. Random Forests (RF) and support vector regression (SVR) models were evaluated for canopy nitrogen weight prediction from 29 variables. RF consistently had better performance than SVR, and the top-performing validation model was RF using 15 selected height, spectral, and topographic variables with an R2 of 0.73 and Root Mean Square Error (RMSE) of 2.21 g/m2. Of the model’s 15 variables, crop height was the most important predictor, followed by 10 VIs, three MicaSense band reflectance mosaics (blue, red, and green), and topographic profile curvature. The model information can be used to improve field nitrogen prediction, leading to more effective and efficient N fertilizer management.
KW  - Unmanned Aerial Vehicle (UAV)
KW  - precision agriculture
KW  - nitrogen management
KW  - machine learning
KW  - Random Forests
KW  - canopy nitrogen weight
KW  - maize
DO  - 10.3390/rs13163105
ER  -
TY  - EJOU
AU  - Li, Clyde Z.
AU  - Hu, Mingcong
AU  - Xiao, Bing
AU  - Chen, Zhe
AU  - Tam, Vivian W. Y.
AU  - Zhao, Yiyu
TI  - Mapping the Knowledge Domains of Emerging Advanced Technologies in the Management of Prefabricated Construction
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 16
SN  - 2071-1050

AB  - Emerging advanced technologies (EAT) have been regarded as significant technological innovations which can greatly improve the transforming construction industry. Given that research on EAT related to the management of prefabricated construction (MPC) has not yet been conducted, various researchers require a state-of-the-art summary of EAT research and implementation in the MPC field. The purpose of this paper is to provide a systematic literature review by analysing the selected 526 related publications in peer-reviewed leading journals during 2009–2020. Through a thorough review of selected papers from the state-of-the-art academic journals in the construction industry, EAT is recognised as the key area affecting the development of the MPC discipline. This study has value in offering original insights to summarise the advanced status quo of this field, helping subsequent researchers gain an in-depth understanding of the underlying structure of this field and allowing them to continue future research directions.
KW  - emerging advanced technologies
KW  - prefabricated construction
KW  - knowledge map
KW  - literature review
DO  - 10.3390/su13168800
ER  -
TY  - EJOU
AU  - Ramalingam, Balakrishnan
AU  - Tun, Thein
AU  - Mohan, Rajesh E.
AU  - Gómez, Braulio F.
AU  - Cheng, Ruoxi
AU  - Balakrishnan, Selvasundari
AU  - Mohan Rayaguru, Madan
AU  - Hayat, Abdullah A.
TI  - AI Enabled IoRT Framework for Rodent Activity Monitoring in a False Ceiling Environment
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 16
SN  - 1424-8220

AB  - Routine rodent inspection is essential to curbing rat-borne diseases and infrastructure damages within the built environment. Rodents find false ceilings to be a perfect spot to seek shelter and construct their habitats. However, a manual false ceiling inspection for rodents is laborious and risky. This work presents an AI-enabled IoRT framework for rodent activity monitoring inside a false ceiling using an in-house developed robot called “Falcon”. The IoRT serves as a bridge between the users and the robots, through which seamless information sharing takes place. The shared images by the robots are inspected through a Faster RCNN ResNet 101 object detection algorithm, which is used to automatically detect the signs of rodent inside a false ceiling. The efficiency of the rodent activity detection algorithm was tested in a real-world false ceiling environment, and detection accuracy was evaluated with the standard performance metrics. The experimental results indicate that the algorithm detects rodent signs and 3D-printed rodents with a good confidence level.
KW  - rodent detection
KW  - faster RCNN
KW  - deep learning
KW  - object detection
KW  - IoRT
KW  - inspection robot
DO  - 10.3390/s21165326
ER  -
TY  - EJOU
AU  - Bakó, Gábor
AU  - Molnár, Zsolt
AU  - Bakk, Lilla
AU  - Horváth, Ferenc
AU  - Fehér, Luca
AU  - Ábrám, Örs
AU  - Morvai, Edina
AU  - Biro, Csaba
AU  - Pápay, Gergely
AU  - Fűrész, Attila
AU  - Penksza, Károly
AU  - Pácsonyi, Diána
AU  - Demény, Krisztina
AU  - Juhász, Erika
AU  - Dékány, Dorottya
AU  - Csernyava, Lili
AU  - Illés, Gábor
AU  - Molnár, András
TI  - Toward a High Spatial Resolution Aerial Monitoring Network for Nature Conservation—How Can Remote Sensing Help Protect Natural Areas?
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 16
SN  - 2071-1050

AB  - Aerial surveys have always significantly contributed to the accurate mapping of certain geographical phenomena. Remote sensing opened up new perspectives in nature monitoring with state-of-the-art technical solutions using modern onboard recording equipment. We developed the technical background and the methodology that supports detailed and cost-effective monitoring of a network of natural areas, thereby detecting temporal changes in the spatial pattern of land cover, species, biodiversity, and other natural features. In this article, we share our experiences of the technical background, geometric accuracy and results of comparisons with selected Copernicus Land Monitoring products and an Ecosystem Map based on the testing of our methodology at 25 sites in Hungary. We combined a high-spatial-resolution aerial remote sensing service with field studies to support an efficient nature conservation monitoring network at 25 permanent sites. By analyzing annually (or more frequently) orthophotos taken with a range of 0.5–5 cm spatial resolution and 3D surface models of aerial surveys, it is possible to map the upper canopy of vegetation species. Furthermore, it allows us to accurately follow the changes in the dynamics at the forest edge and upper canopy, or the changes in species’ dominance in meadows. Additionally, spatial data obtained from aerial surveys and field studies can expand the knowledge base of the High-Resolution Aerial Monitoring Network (HRAMN) and support conservation and restoration management. A well-conducted high-resolution survey can reveal the impacts of land interventions and habitat regeneration. By building the HRAMN network, nature conservation could have an up-to-date database that could prompt legal processes, establish protection designation procedures and make environmental habitat management more cost-effective. Landscape protection could also utilize the services of HRAMN in planning and risk reduction interventions through more reliable inputs to environmental models.
KW  - nature conservation
KW  - habitat mapping
KW  - monitoring
KW  - remote sensing
KW  - aerial survey
DO  - 10.3390/su13168807
ER  -
TY  - EJOU
AU  - Chao, Zhenhua
AU  - Fang, Xuan
AU  - Na, Jiaming
AU  - Che, Mingliang
TI  - A Collaborative Sensing System for Farmland Water Conservancy Project Maintenance through Integrating Satellite, Aerial, and Ground Observations
T2  - Water

PY  - 2021
VL  - 13
IS  - 16
SN  - 2073-4441

AB  - More and more attention has been paid to farmland water conservancy project (FWCP) maintenance in China, which can reallocate water resources in a more rational and efficient manner. Compared with the traditional survey such as field survey, FWCP maintenance can be improved efficiently with geospatial technology. To improve the level of FWCP maintenance in China, a collaborative sensing system framework by integrating satellite, aerial, and ground remote sensing is put forward. The structure of the system framework includes three sections, namely the data acquisition, the operational work, and the application and service. Through the construction and operation of such collaborative sensing system, it will break through the limitation of any single remote sensing platform and provide all-around and real-time information on FWCP. The collaborative monitoring schemes for the designed FWCP maintenance can engage ditch riders to maintain more effectively, which will enable them to communicate more specifically with smallholders in the process of irrigation. Only when ditch riders and farmers are fully involved, irrigation efficiency will be improved. Furthermore, the collaborative sensing system needs feasible standards for multi-source remote sensing data processing and intelligent information extraction such as data fusion, data assimilation, and data mining. In a way, this will promote the application of remote sensing in the field of agricultural irrigation and water saving. On the whole, it will be helpful to improve the traditional maintenance problems and is also the guarantee for establishing a long-term scientific management mechanism of FWCP maintenance in developing countries, especially in China.
KW  - unmanned aerial vehicle
KW  - hydroelectric conversion coefficient of pumping station
KW  - irrigation pump station
KW  - routine maintenance
KW  - emergency maintenance
KW  - irrigation performance
DO  - 10.3390/w13162163
ER  -
TY  - EJOU
AU  - Zheng, Yuemin
AU  - Tao, Jin
AU  - Sun, Hao
AU  - Sun, Qinglin
AU  - Chen, Zengqiang
AU  - Dehmer, Matthias
AU  - Zhou, Quan
TI  - Load Frequency Active Disturbance Rejection Control for Multi-Source Power System Based on Soft Actor-Critic
T2  - Energies

PY  - 2021
VL  - 14
IS  - 16
SN  - 1996-1073

AB  - To ensure the safe operation of an interconnected power system, it is necessary to maintain the stability of the frequency and the tie-line exchanged power. This is one of the hottest issues in the power system field and is usually called load frequency control. To overcome the influences of load disturbances on multi-source power systems containing thermal power plants, hydropower plants, and gas turbine plants, we design a linear active disturbance rejection control (LADRC) based on the tie-line bias control mode. For LADRC, the parameter selection of the controller directly affects the response performance of the entire system, and it is usually not feasible to manually adjust parameters. Therefore, to obtain the optimal controller parameters, we use the Soft Actor-Critic algorithm in reinforcement learning to obtain the controller parameters in real time, and we design the reward function according to the needs of the power system. We carry out simulation experiments to verify the effectiveness of the proposed method. Compared with the results of other proportional–integral–derivative control techniques using optimization algorithms and LADRC with constant parameters, the proposed method shows significant advantages in terms of overshoot, undershoot, and settling time. In addition, by adding different disturbances to different areas of the multi-source power system, we demonstrate the robustness of the proposed control strategy.
KW  - load frequency control
KW  - linear active disturbance rejection control
KW  - soft actor-critic
KW  - multi-source power system
KW  - reinforcement learning
DO  - 10.3390/en14164804
ER  -
TY  - EJOU
AU  - Tait, Leigh W.
AU  - Orchard, Shane
AU  - Schiel, David R.
TI  - Missing the Forest and the Trees: Utility, Limits and Caveats for Drone Imaging of Coastal Marine Ecosystems
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 16
SN  - 2072-4292

AB  - Coastal marine ecosystems are under stress, yet actionable information about the cumulative effects of human impacts has eluded ecologists. Habitat-forming seaweeds in temperate regions provide myriad irreplaceable ecosystem services, but they are increasingly at risk of local and regional extinction from extreme climatic events and the cumulative impacts of land-use change and extractive activities. Informing appropriate management strategies to reduce the impacts of stressors requires comprehensive knowledge of species diversity, abundance and distributions. Remote sensing undoubtedly provides answers, but collecting imagery at appropriate resolution and spatial extent, and then accurately and precisely validating these datasets is not straightforward. Comprehensive and long-running monitoring of rocky reefs exist globally but are often limited to a small subset of reef platforms readily accessible to in-situ studies. Key vulnerable habitat-forming seaweeds are often not well-assessed by traditional in-situ methods, nor are they well-captured by passive remote sensing by satellites. Here we describe the utility of drone-based methods for monitoring and detecting key rocky intertidal habitat types, the limitations and caveats of these methods, and suggest a standardised workflow for achieving consistent results that will fulfil the needs of managers for conservation efforts.
KW  - intertidal
KW  - seaweed
KW  - biodiversity
KW  - drone
KW  - imaging
KW  - monitoring
KW  - survey
DO  - 10.3390/rs13163136
ER  -
TY  - EJOU
AU  - Monteiro, António
AU  - Santos, Sérgio
AU  - Gonçalves, Pedro
TI  - Precision Agriculture for Crop and Livestock Farming—Brief Review
T2  - Animals

PY  - 2021
VL  - 11
IS  - 8
SN  - 2076-2615

AB  - In the last few decades, agriculture has played an important role in the worldwide economy. The need to produce more food for a rapidly growing population is creating pressure on crop and animal production and a negative impact to the environment. On the other hand, smart farming technologies are becoming increasingly common in modern agriculture to assist in optimizing agricultural and livestock production and minimizing the wastes and costs. Precision agriculture (PA) is a technology-enabled, data-driven approach to farming management that observes, measures, and analyzes the needs of individual fields and crops. Precision livestock farming (PLF), relying on the automatic monitoring of individual animals, is used for animal growth, milk production, and the detection of diseases as well as to monitor animal behavior and their physical environment, among others. This study aims to briefly review recent scientific and technological trends in PA and their application in crop and livestock farming, serving as a simple research guide for the researcher and farmer in the application of technology to agriculture. The development and operation of PA applications involve several steps and techniques that need to be investigated further to make the developed systems accurate and implementable in commercial environments.
KW  - crop and animal production
KW  - smart farming technologies
KW  - precision agriculture
KW  - precision livestock farming
KW  - trends
DO  - 10.3390/ani11082345
ER  -
TY  - EJOU
AU  - Zhang, Qiang
AU  - Sun, Banyong
AU  - Cheng, Yaxiong
AU  - Li, Xijie
TI  - Residual Self-Calibration and Self-Attention Aggregation Network for Crop Disease Recognition
T2  - International Journal of Environmental Research and Public Health

PY  - 2021
VL  - 18
IS  - 16
SN  - 1660-4601

AB  - The correct diagnosis and recognition of crop diseases play an important role in ensuring crop yields and preventing food safety. The existing methods for crop disease recognition mainly focus on accuracy while ignoring the algorithm’s robustness. In practice, the acquired images are often accompanied by various noises. These noises lead to a huge challenge for improving the robustness and accuracy of the recognition algorithm. In order to solve this problem, this paper proposes a residual self-calibration and self-attention aggregation network (RCAA-Net) for crop disease recognition in actual scenarios. The proposed RCAA-Net is composed of three main modules: (1) multi-scale residual module, (2) feedback self-calibration module, and (3) self-attention aggregation module. Specifically, the multi-scale residual module is designed to learn multi-scale features and provide both global and local information for the appearance of the disease to improve the performance of the model. The feedback self-calibration is proposed to improve the robustness of the model by suppressing the background noise in the original deep features. The self-attention aggregation module is introduced to further improve the robustness and accuracy of the model by capturing multi-scale information in different semantic spaces. The experimental results on the challenging 2018ai_challenger crop disease recognition dataset show that the proposed RCAA-Net achieves state-of-the-art performance on robustness and accuracy for crop disease recognition in actual scenarios.
KW  - crop disease recognition
KW  - self-calibration
KW  - self-attention
KW  - residual
DO  - 10.3390/ijerph18168404
ER  -
TY  - EJOU
AU  - Ma, Yue
AU  - Rose, Francis
AU  - Wong, Leslie
AU  - Vien, Benjamin S.
AU  - Kuen, Thomas
AU  - Rajic, Nik
AU  - Kodikara, Jayantha
AU  - Chiu, Wingkong
TI  - Detection of Defects in Geomembranes Using Quasi-Active Infrared Thermography
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 16
SN  - 1424-8220

AB  - High-density polyethylene geomembranes are employed as covers for the sewage treatment lagoons at Melbourne Water Corporation’s Western Treatment Plant, to harvest the biogas produced during anaerobic degradation, which is then used to generate electricity. Due to its size, inspecting the cover for defects, particularly subsurface defects, can be challenging, as well as the potential for the underside of the membrane to come into contact with different substrates, viz. liquid sewage, scum (consolidated solid matter), and biogas. This paper presents the application of a novel quasi-active thermography inspection method for subsurface defect detection in the geomembrane. The proposed approach utilises ambient sunlight as the input thermal energy and cloud shading as the trigger for thermal transients. Outdoor laboratory-scale experiments were conducted to study the proposed inspection technique. A pyranometer was used to measure the intensity of solar radiation, and an infrared thermal camera was used to measure the surface temperature of the geomembrane. The measured temperature profile was analysed using three different algorithms for thermal transient analysis, based on (i) the cooling constant from Newton’s law of cooling, (ii) the peak value of the logarithmic second derivative, and (iii) a frame subtraction method. The outcomes from each algorithm were examined and compared. The results show that, while each algorithm has some limitations, when used in combination the three algorithms could be used to distinguish between different substrates and to determine the presence of subsurface defects.
KW  - non-contact inspection
KW  - quasi-active thermography
KW  - HDPE geomembrane
KW  - defect detection
KW  - floating covers
KW  - thermal image processing
DO  - 10.3390/s21165365
ER  -
TY  - EJOU
AU  - Yu, Bo
AU  - Chen, Fang
AU  - Xu, Chong
AU  - Wang, Lei
AU  - Wang, Ning
TI  - Matrix SegNet: A Practical Deep Learning Framework for Landslide Mapping from Images of Different Areas with Different Spatial Resolutions
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 16
SN  - 2072-4292

AB  - Practical landslide inventory maps covering large-scale areas are essential in emergency response and geohazard analysis. Recently proposed techniques in landslide detection generally focused on landslides in pure vegetation backgrounds and image radiometric correction. There are still challenges in regard to robust methods that automatically detect landslides from images with multiple platforms and without radiometric correction. It is a significant issue in practical application. In order to detect landslides from images over different large-scale areas with different spatial resolutions, this paper proposes a two-branch Matrix SegNet to semantically segment input images by change detection. The Matrix SegNet learns landslide features in multiple scales and aspect ratios. The pre- and post- event images are captured directly from Google Earth, without radiometric correction. To evaluate the proposed framework, we conducted landslide detection in four study areas with two different spatial resolutions. Moreover, two other widely used frameworks: U-Net and SegNet, were adapted to detect landslides via the same data by change detection. The experiments show that our model improves the performance largely in terms of recall, precision, F1-score, and IOU. It is a good starting point to develop a practical, deep learning landslide detection framework for large scale application, using images from different areas, with different spatial resolutions.
KW  - landslide detection
KW  - Matrix nets
KW  - different spatial resolutions
DO  - 10.3390/rs13163158
ER  -
TY  - EJOU
AU  - Song, Yang
AU  - Wang, Jinfei
AU  - Shan, Bo
TI  - Estimation of Winter Wheat Yield from UAV-Based Multi-Temporal Imagery Using Crop Allometric Relationship and SAFY Model
T2  - Drones

PY  - 2021
VL  - 5
IS  - 3
SN  - 2504-446X

AB  - Crop yield prediction and estimation play essential roles in the precision crop management system. The Simple Algorithm for Yield Estimation (SAFY) has been applied to Unmanned Aerial Vehicle (UAV)-based data to provide high spatial yield prediction and estimation for winter wheat. However, this crop model relies on the relationship between crop leaf weight and biomass, which only considers the contribution of leaves on the final biomass and yield calculation. This study developed the modified SAFY-height model by incorporating an allometric relationship between ground-based measured crop height and biomass. A piecewise linear regression model is used to establish the relationship between crop height and biomass. The parameters of the modified SAFY-height model are calibrated using ground measurements. Then, the calibrated modified SAFY-height model is applied on the UAV-based photogrammetric point cloud derived crop height and effective leaf area index (LAIe) maps to predict winter wheat yield. The growing accumulated temperature turning points of an allometric relationship between crop height and biomass is 712 °C. The modified SAFY-height model, relative to traditional SAFY, provided more accurate yield estimation for areas with LAI higher than 1.01 m2/m2. The RMSE and RRMSE are improved by 3.3% and 0.5%, respectively.
KW  - crop biomass
KW  - crop height
KW  - leaf area index
KW  - remote sensing
KW  - photogrammetric point cloud
KW  - Unmanned Aerial Vehicle
KW  - Simple Algorithm for Yield Estimation
DO  - 10.3390/drones5030078
ER  -
TY  - EJOU
AU  - Haider, Tazeem
AU  - Farid, Muhammad S.
AU  - Mahmood, Rashid
AU  - Ilyas, Areeba
AU  - Khan, Muhammad H.
AU  - Haider, Sakeena T.
AU  - Chaudhry, Muhammad H.
AU  - Gul, Mehreen
TI  - A Computer-Vision-Based Approach for Nitrogen Content Estimation in Plant Leaves
T2  - Agriculture

PY  - 2021
VL  - 11
IS  - 8
SN  - 2077-0472

AB  - Nitrogen is an essential nutrient element required for optimum crop growth and yield. If a specific amount of nitrogen is not applied to crops, their yield is affected. Estimation of nitrogen level in crops is momentous to decide the nitrogen fertilization in crops. The amount of nitrogen in crops is measured through different techniques, including visual inspection of leaf color and texture and by laboratory analysis of plant leaves. Laboratory analysis-based techniques are more accurate than visual inspection, but they are costly, time-consuming, and require skilled laboratorian and precise equipment. Therefore, computer-based systems are required to estimate the amount of nitrogen in field crops. In this paper, a computer vision-based solution is introduced to solve this problem as well as to help farmers by providing an easier, cheaper, and faster approach for measuring nitrogen deficiency in crops. The system takes an image of the crop leaf as input and estimates the amount of nitrogen in it. The image is captured by placing the leaf on a specially designed slate that contains the reference green and yellow colors for that crop. The proposed algorithm automatically extracts the leaf from the image and computes its color similarity with the reference colors. In particular, we define a green color value (GCV) index from this analysis, which serves as a nitrogen indicator. We also present an evaluation of different color distance models to find a model able to accurately capture the color differences. The performance of the proposed system is evaluated on a Spinacia oleracea dataset. The results of the proposed system and laboratory analysis are highly correlated, which shows the effectiveness of the proposed system.
KW  - nitrogen estimation
KW  - image processing
KW  - leaf contents
KW  - crop yield
KW  - color distance models
DO  - 10.3390/agriculture11080766
ER  -
TY  - EJOU
AU  - Takechi, Hitoshi
AU  - Aragaki, Shunsuke
AU  - Irie, Mitsuteru
TI  - Differentiation of River Sediments Fractions in UAV Aerial Images by Convolution Neural Network
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 16
SN  - 2072-4292

AB  - Riverbed material has multiple functions in river ecosystems, such as habitats, feeding grounds, spawning grounds, and shelters for aquatic organisms, and particle size of riverbed material reflects the tractive force of the channel flow. Therefore, regular surveys of riverbed material are conducted for environmental protection and river flood control projects. The field method is the most conventional riverbed material survey. However, conventional surveys of particle size of riverbed material require much labor, time, and cost to collect material on site. Furthermore, its spatial representativeness is also a problem because of the limited survey area against a wide riverbank. As a further solution to these problems, in this study, we tried an automatic classification of riverbed conditions using aerial photography with an unmanned aerial vehicle (UAV) and image recognition with artificial intelligence (AI) to improve survey efficiency. Due to using AI for image processing, a large number of images can be handled regardless of whether they are of fine or coarse particles. We tried a classification of aerial riverbed images that have the difference of particle size characteristics with a convolutional neural network (CNN). GoogLeNet, Alexnet, VGG-16 and ResNet, the common pre-trained networks, were retrained to perform the new task with the 70 riverbed images using transfer learning. Among the networks tested, GoogleNet showed the best performance for this study. The overall accuracy of the image classification reached 95.4%. On the other hand, it was supposed that shadows of the gravels caused the error of the classification. The network retrained with the images taken in the uniform temporal period gives higher accuracy for classifying the images taken in the same period as the training data. The results suggest the potential of evaluating riverbed materials using aerial photography with UAV and image recognition with CNN.
KW  - channel bed condition
KW  - particle size
KW  - convolution neural network
KW  - UAV
DO  - 10.3390/rs13163188
ER  -
TY  - EJOU
AU  - Li, Kai-Yun
AU  - Burnside, Niall G.
AU  - de Lima, Raul S.
AU  - Peciña, Miguel V.
AU  - Sepp, Karli
AU  - Cabral Pinheiro, Victor H.
AU  - de Lima, Bruno R.
AU  - Yang, Ming-Der
AU  - Vain, Ants
AU  - Sepp, Kalev
TI  - An Automated Machine Learning Framework in Unmanned Aircraft Systems: New Insights into Agricultural Management Practices Recognition Approaches
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 16
SN  - 2072-4292

AB  - The recent trend of automated machine learning (AutoML) has been driving further significant technological innovation in the application of artificial intelligence from its automated algorithm selection and hyperparameter optimization of the deployable pipeline model for unraveling substance problems. However, a current knowledge gap lies in the integration of AutoML technology and unmanned aircraft systems (UAS) within image-based data classification tasks. Therefore, we employed a state-of-the-art (SOTA) and completely open-source AutoML framework, Auto-sklearn, which was constructed based on one of the most widely used ML systems: Scikit-learn. It was combined with two novel AutoML visualization tools to focus particularly on the recognition and adoption of UAS-derived multispectral vegetation indices (VI) data across a diverse range of agricultural management practices (AMP). These include soil tillage methods (STM), cultivation methods (CM), and manure application (MA), and are under the four-crop combination fields (i.e., red clover-grass mixture, spring wheat, pea-oat mixture, and spring barley). Furthermore, they have currently not been efficiently examined and accessible parameters in UAS applications are absent for them. We conducted the comparison of AutoML performance using three other common machine learning classifiers, namely Random Forest (RF), support vector machine (SVM), and artificial neural network (ANN). The results showed AutoML achieved the highest overall classification accuracy numbers after 1200 s of calculation. RF yielded the second-best classification accuracy, and SVM and ANN were revealed to be less capable among some of the given datasets. Regarding the classification of AMPs, the best recognized period for data capture occurred in the crop vegetative growth stage (in May). The results demonstrated that CM yielded the best performance in terms of classification, followed by MA and STM. Our framework presents new insights into plant–environment interactions with capable classification capabilities. It further illustrated the automatic system would become an important tool in furthering the understanding for future sustainable smart farming and field-based crop phenotyping research across a diverse range of agricultural environmental assessment and management applications.
KW  - unmanned aircraft system
KW  - automated machine learning
KW  - agricultural management practices
KW  - image classification
KW  - precision agriculture
KW  - variety performance trials
KW  - crop breeding
KW  - crop phenotyping
KW  - agriculture decision-making
DO  - 10.3390/rs13163190
ER  -
TY  - EJOU
AU  - Ezzy, Haitham
AU  - Charter, Motti
AU  - Bonfante, Antonello
AU  - Brook, Anna
TI  - How the Small Object Detection via Machine Learning and UAS-Based Remote-Sensing Imagery Can Support the Achievement of SDG2: A Case Study of Vole Burrows
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 16
SN  - 2072-4292

AB  - Small mammals, and particularly rodents, are common inhabitants of farmlands, where they play key roles in the ecosystem, but when overabundant, they can be major pests, able to reduce crop production and farmers’ incomes, with tangible effects on the achievement of Sustainable Development Goals no 2 (SDG2, Zero Hunger) of the United Nations. Farmers do not currently have a standardized, accurate method of detecting the presence, abundance, and locations of rodents in their fields, and hence do not have environmentally efficient methods of rodent control able to promote sustainable agriculture oriented to reduce the environmental impacts of cultivation. New developments in unmanned aerial system (UAS) platforms and sensor technology facilitate cost-effective data collection through simultaneous multimodal data collection approaches at very high spatial resolutions in environmental and agricultural contexts. Object detection from remote-sensing images has been an active research topic over the last decade. With recent increases in computational resources and data availability, deep learning-based object detection methods are beginning to play an important role in advancing remote-sensing commercial and scientific applications. However, the performance of current detectors on various UAS-based datasets, including multimodal spatial and physical datasets, remains limited in terms of small object detection. In particular, the ability to quickly detect small objects from a large observed scene (at field scale) is still an open question. In this paper, we compare the efficiencies of applying one- and two-stage detector models to a single UAS-based image and a processed (via Pix4D mapper photogrammetric program) UAS-based orthophoto product to detect rodent burrows, for agriculture/environmental applications as to support farmer activities in the achievements of SDG2. Our results indicate that the use of multimodal data from low-cost UASs within a self-training YOLOv3 model can provide relatively accurate and robust detection for small objects (mAP of 0.86 and an F1-score of 93.39%), and can deliver valuable insights for field management with high spatial precision able to reduce the environmental costs of crop production in the direction of precision agriculture management.
KW  - small object detection
KW  - UAS
KW  - YOLOv3
KW  - Faster R-CNN
KW  - EfficientNet
KW  - RetinaNet
DO  - 10.3390/rs13163191
ER  -
TY  - EJOU
AU  - Zhang, Binghan
AU  - Yang, Bin
AU  - Wang, Congjun
AU  - Wang, Zhichen
AU  - Liu, Boda
AU  - Fang, Tengwei
TI  - Computer Vision-Based Construction Process Sensing for Cyber–Physical Systems: A Review
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 16
SN  - 1424-8220

AB  - Cyber–physical systems (CPSs) are generally considered to be the next generation of engineered systems. However, the actual application of CPSs in the Architecture, Engineering and Construction (AEC) industry is still at a low level. The sensing method in the construction process plays a very important role in the establishment of CPSs. Therefore, the purpose of this paper is to discuss the application potential of computer vision-based sensing methods and provide practical suggestions through a literature review. This paper provides a review of the current application of CPSs in the AEC industry, summarizes the current knowledge gaps, and discusses the problems with the current construction site sensing approach. Considering the unique advantages of the computer vision (CV) method at the construction site, the application of CV for different construction entities was reviewed and summarized to achieve a CV-based construction site sensing approach for construction process CPSs. The potential of CPS can be further stimulated by providing rich information from on-site sensing using CV methods. According to the review, this approach has unique advantages in the specific environment of the construction site. Based on the current knowledge gap identified in the literature review, this paper proposes a novel concept of visual-based construction site sensing method for CPS application, and an architecture for CV-based CPS is proposed as an implementation of this concept. The main contribution of this paper is to propose a CPS architecture using computer vision as the main information acquisition method based on the literature review. This architecture innovatively introduces computer vision as a sensing method of construction sites, and realizes low-cost and non-invasive information acquisition in complex construction scenarios. This method can be used as an important supplement to on-site sensing to further promote the automation and intelligence of the construction process.
KW  - computer vision
KW  - cyber–physical systems
KW  - sensing system
KW  - review
DO  - 10.3390/s21165468
ER  -
TY  - EJOU
AU  - Munawar, Hafiz S.
AU  - Hammad, Ahmed W. A.
AU  - Haddad, Assed
AU  - Soares, Carlos A.
AU  - Waller, S. T.
TI  - Image-Based Crack Detection Methods: A Review
T2  - Infrastructures

PY  - 2021
VL  - 6
IS  - 8
SN  - 2412-3811

AB  - Annually, millions of dollars are spent to carry out defect detection in key infrastructure including roads, bridges, and buildings. The aftermath of natural disasters like floods and earthquakes leads to severe damage to the urban infrastructure. Maintenance operations that follow for the damaged infrastructure often involve a visual inspection and assessment of their state to ensure their functional and physical integrity. Such damage may appear in the form of minor or major cracks, which gradually spread, leading to ultimate collapse or destruction of the structure. Crack detection is a very laborious task if performed via manual visual inspection. Many infrastructure elements need to be checked regularly and it is therefore not feasible as it will require significant human resources. This may also result in cases where cracks go undetected. A need, therefore, exists for performing automatic defect detection in infrastructure to ensure its effectiveness and reliability. Using image processing techniques, the captured or scanned images of the infrastructure parts can be analyzed to identify any possible defects. Apart from image processing, machine learning methods are being increasingly applied to ensure better performance outcomes and robustness in crack detection. This paper provides a review of image-based crack detection techniques which implement image processing and/or machine learning. A total of 30 research articles have been collected for the review which is published in top tier journals and conferences in the past decade. A comprehensive analysis and comparison of these methods are performed to highlight the most promising automated approaches for crack detection.
KW  - crack detection
KW  - machine learning
KW  - artificial intelligence
KW  - image processing
DO  - 10.3390/infrastructures6080115
ER  -
TY  - EJOU
AU  - Bhatia, Jyoti
AU  - Dayal, Aveen
AU  - Jha, Ajit
AU  - Vishvakarma, Santosh K.
AU  - Joshi, Soumya
AU  - Srinivas, M. B.
AU  - Yalavarthy, Phaneendra K.
AU  - Kumar, Abhinav
AU  - Lalitha, V.
AU  - Koorapati, Sagar
AU  - Cenkeramaddi, Linga R.
TI  - Classification of Targets Using Statistical Features from Range FFT of mmWave FMCW Radars
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 16
SN  - 2079-9292

AB  - Radars with mmWave frequency modulated continuous wave (FMCW) technology accurately estimate the range and velocity of targets in their field of view (FoV). The targeted angle of arrival (AoA) estimation can be improved by increasing receiving antennas or by using multiple-input multiple-output (MIMO). However, obtaining target features such as target type remains challenging. In this paper, we present a novel target classification method based on machine learning and features extracted from a range fast Fourier transform (FFT) profile by using mmWave FMCW radars operating in the frequency range of 77–81 GHz. The measurements are carried out in a variety of realistic situations, including pedestrian, automotive, and unmanned aerial vehicle (UAV) (also known as drone). Peak, width, area, variance, and range are collected from range FFT profile peaks and fed into a machine learning model. In order to evaluate the performance, various light weight classification machine learning models such as logistic regression, Naive Bayes, support vector machine (SVM), and lightweight gradient boosting machine (GBM) are used. We demonstrate our findings by using outdoor measurements and achieve a classification accuracy of 95.6% by using LightGBM. The proposed method will be extremely useful in a wide range of applications, including cost-effective and dependable ground station traffic management and control systems for autonomous operations, and advanced driver-assistance systems (ADAS). The presented classification technique extends the potential of mmWave FMCW radar beyond the detection of range, velocity, and AoA to classification. mmWave FMCW radars will be more robust in computer vision, visual perception, and fully autonomous ground control and traffic management cyber-physical systems as a result of the added new feature.
KW  - mmWave radar
KW  - FMCW radar
KW  - autonomous systems
KW  - machine learning
KW  - ground station radar
KW  - targets classification
KW  - range FFT features
DO  - 10.3390/electronics10161965
ER  -
TY  - EJOU
AU  - Li, Guan-Sin
AU  - Wu, Dong-Hong
AU  - Su, Yuan-Chih
AU  - Kuo, Bo-Jein
AU  - Yang, Ming-Der
AU  - Lai, Ming-Hsin
AU  - Lu, Hsiu-Ying
AU  - Yang, Chin-Ying
TI  - Prediction of Plant Nutrition State of Rice under Water-Saving Cultivation and Panicle Fertilization Application Decision Making
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 8
SN  - 2073-4395

AB  - Rice is a staple food crop in Asia. The rice farming industry has been influenced by global urbanization, rapid industrialization, and climate change. A combination of precise agricultural and smart water management systems to investigate the nutrition state in rice is important. Results indicated that plant nitrogen and chlorophyll content at the maximum tillering stage were significantly influenced by the interaction between water and fertilizer. The normalized difference vegetation index (NDVI) and normalized difference red edge (NDRE), obtained from the multispectral images captured by a UAV, exhibited the highest positive correlations (0.83 and 0.82) with plant nitrogen content at the maximum tillering stage. The leave-one-out cross-validation method was used for validation, and a final plant nitrogen content prediction model was obtained. A regression function constructed using a nitrogen nutrition index and the difference in field cumulative nitrogen had favorable variation explanatory power, and its adjusted coefficient of determination was 0.91. We provided a flow chart showing how the nutrition state of rice can be predicted with the vegetation indices obtained from UAV image analysis. Differences in field cumulative nitrogen can be further used to diagnose the demand of nitrogen topdressing during the panicle initiation stage. Thus, farmers can be provided with precise panicle fertilization strategies for rice fields.
KW  - rice
KW  - water-saving cultivation
KW  - UAV remote sensing
KW  - vegetation index
KW  - nitrogen fertilizer
DO  - 10.3390/agronomy11081626
ER  -
TY  - EJOU
AU  - Shen, Shengyu
AU  - Chen, Jiasheng
AU  - Zhang, Shaoyi
AU  - Cheng, Dongbing
AU  - Wang, Zhigang
AU  - Zhang, Tong
TI  - Deep Fusion of DOM and DSM Features for Benggang Discovery
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 8
SN  - 2220-9964

AB  - Benggang is a typical erosional landform in southern and southeastern China. Since benggang poses significant risks to local ecological environments and economic infrastructure, it is vital to accurately detect benggang-eroded areas. Relying only on remote sensing imagery for benggang detection cannot produce satisfactory results. In this study, we propose integrating high-resolution Digital Orthophoto Map (DOM) and Digital Surface Model (DSM) data for efficient and automatic benggang discovery. The fusion of complementary rich information hidden in both DOM and DSM data is realized by a two-stream convolutional neural network (CNN), which integrates aggregated terrain and activation image features that are both extracted by supervised deep learning. We aggregate local low-level geomorphic features via a supervised diffusion-convolutional embedding branch for expressive representations of benggang terrain variations. Activation image features are obtained from an image-oriented convolutional neural network branch. The two sources of information (DOM and DSM) are fused via a gated neural network, which learns the most discriminative features for the detection of benggang. The evaluation of a challenging benggang dataset demonstrates that our method exceeds several baselines, even with limited training examples. The results show that the fusion of DOM and DSM data is beneficial for benggang detection via supervised convolutional and deep fusion networks.
KW  - benggang
KW  - deep learning
KW  - fusion
KW  - CNN
KW  - DOM
KW  - DSM
DO  - 10.3390/ijgi10080556
ER  -
TY  - EJOU
AU  - Tina, Giuseppe M.
AU  - Ventura, Cristina
AU  - Ferlito, Sergio
AU  - De Vito, Saverio
TI  - A State-of-Art-Review on Machine-Learning Based Methods for PV
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 16
SN  - 2076-3417

AB  - In the current era, Artificial Intelligence (AI) is becoming increasingly pervasive with applications in several applicative fields effectively changing our daily life. In this scenario, machine learning (ML), a subset of AI techniques, provides machines with the ability to programmatically learn from data to model a system while adapting to new situations as they learn more by data they are ingesting (on-line training). During the last several years, many papers have been published concerning ML applications in the field of solar systems. This paper presents the state of the art ML models applied in solar energy’s forecasting field i.e., for solar irradiance and power production forecasting (both point and interval or probabilistic forecasting), electricity price forecasting and energy demand forecasting. Other applications of ML into the photovoltaic (PV) field taken into account are the modelling of PV modules, PV design parameter extraction, tracking the maximum power point (MPP), PV systems efficiency optimization, PV/Thermal (PV/T) and Concentrating PV (CPV) system design parameters’ optimization and efficiency improvement, anomaly detection and energy management of PV’s storage systems. While many review papers already exist in this regard, they are usually focused only on one specific topic, while in this paper are gathered all the most relevant applications of ML for solar systems in many different fields. The paper gives an overview of the most recent and promising applications of machine learning used in the field of photovoltaic systems.
KW  - machine learning
KW  - solar energy
KW  - forecast
KW  - diagnostic
KW  - electricity markets
DO  - 10.3390/app11167550
ER  -
TY  - EJOU
AU  - Wang, Kaixuan
AU  - Zhang, Jiaqiao
AU  - Ni, Hongjun
AU  - Ren, Fuji
TI  - Thermal Defect Detection for Substation Equipment Based on Infrared Image Using Convolutional Neural Network
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 16
SN  - 2079-9292

AB  - Thermal defects of substation equipment have a great impact on the stability of power systems. Temperature is crucial for thermal defect detection in infrared images. The traditional detection methods, which have low efficiency and poor accuracy, record the temperature of infrared images manually. In this study, a thermal defect detection method based on infrared images using a convolutional neural network (CNN) is proposed. Firstly, the improved pre-processing method is applied to reduce background information, and the region of interest is located according to the contour and position information, hence improving the quality of images. Then, the temperature values are segmented to establish the dataset (T-IR11), which contains 11 labels. Finally, the CNN model is constructed to extract features, and the support vector machine is trained for classification. To verify the effectiveness of the proposed method, precision, recall, and F1 score are adopted and 10-fold cross-validation is employed on the T-IR11 dataset. The results demonstrate that the accuracy of the proposed method is 99.50%, and the performance is superior to that of previous methods in terms of infrared images. The proposed method can realize automatic temperature recognition and equipment with thermal defects can be recorded systematically, which has significant practical value for defect detection in substation equipment.
KW  - infrared image
KW  - substation equipment
KW  - thermal defect detection
KW  - adaptive binarization
KW  - character recognition
KW  - convolutional neural network
DO  - 10.3390/electronics10161986
ER  -
TY  - EJOU
AU  - Parra, Lorena
AU  - Mostaza-Colado, David
AU  - Yousfi, Salima
AU  - Marin, Jose F.
AU  - Mauri, Pedro V.
AU  - Lloret, Jaime
TI  - Drone RGB Images as a Reliable Information Source to Determine Legumes Establishment Success
T2  - Drones

PY  - 2021
VL  - 5
IS  - 3
SN  - 2504-446X

AB  - The use of drones in agriculture is becoming a valuable tool for crop monitoring. There are some critical moments for crop success; the establishment is one of those. In this paper, we present an initial approximation of a methodology that uses RGB images gathered from drones to evaluate the establishment success in legumes based on matrixes operations. Our aim is to provide a method that can be implemented in low-cost nodes with relatively low computational capacity. An index (B1/B2) is used for estimating the percentage of green biomass to evaluate the establishment success. In the study, we include three zones with different establishment success (high, regular, and low) and two species (chickpea and lentils). We evaluate data usability after applying aggregation techniques, which reduces the picture’s size to improve long-term storage. We test cell sizes from 1 to 10 pixels. This technique is tested with images gathered in production fields with intercropping at 4, 8, and 12 m relative height to find the optimal aggregation for each flying height. Our results indicate that images captured at 4 m with a cell size of 5, at 8 m with a cell size of 3, and 12 m without aggregation can be used to determine the establishment success. Comparing the storage requirements, the combination that minimises the data size while maintaining its usability is the image at 8 m with a cell size of 3. Finally, we show the use of generated information with an artificial neural network to classify the data. The dataset was split into a training dataset and a verification dataset. The classification of the verification dataset offered 83% of the cases as well classified. The proposed tool can be used in the future to compare the establishment success of different legume varieties or species.
KW  - chickpea
KW  - lentil
KW  - vegetation index
KW  - artificial neural network
KW  - aggregation
DO  - 10.3390/drones5030079
ER  -
TY  - EJOU
AU  - Hurst, Stance
AU  - Johnson, Eileen
AU  - Cunningham, Doug
AU  - Fernandez-Cespedes, Glenn
TI  - Aerial Photogrammetry in the American West: Documenting the Construction of Cattle Water Tanks by Texas Cowboys
T2  - Heritage

PY  - 2021
VL  - 4
IS  - 3
SN  - 2571-9408

AB  - Aerial photogrammetry is increasingly being used to discover, document, and interpret the cultural heritage of landscapes. Information on the constructed cultural heritage left behind by the first cattle ranchers in the American West is being lost as the land is transformed and modified, and stewardship of the land changes across generations. An unmanned aerial vehicle (UAV) has been used in this research to record and interpret two surface water cattle tanks constructed by Texas cowboys in the mid-1880s. Similar size rocks have been used and placed in a similar pattern across the walls of both tanks. This similarity suggests both tanks were constructed at the same time. This research also demonstrates that UAV photogrammetry can be used to rapidly record and analyze the constructed cultural heritage of American West cowboys.
KW  - Southern High Plains
KW  - unmanned aerial vehicle
KW  - photogrammetry
KW  - cattle water tanks
KW  - cowboys
KW  - historical ranches
KW  - American West
DO  - 10.3390/heritage4030107
ER  -
TY  - EJOU
AU  - Soubry, Irini
AU  - Doan, Thuy
AU  - Chu, Thuan
AU  - Guo, Xulin
TI  - A Systematic Review on the Integration of Remote Sensing and GIS to Forest and Grassland Ecosystem Health Attributes, Indicators, and Measures
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 16
SN  - 2072-4292

AB  - It is important to protect forest and grassland ecosystems because they are ecologically rich and provide numerous ecosystem services. Upscaling monitoring from local to global scale is imperative in reaching this goal. The SDG Agenda does not include indicators that directly quantify ecosystem health. Remote sensing and Geographic Information Systems (GIS) can bridge the gap for large-scale ecosystem health assessment. We systematically reviewed field-based and remote-based measures of ecosystem health for forests and grasslands, identified the most important ones and provided an overview on remote sensing and GIS-based measures. We included 163 English language studies within terrestrial non-tropical biomes and used a pre-defined classification system to extract ecological stressors and attributes, collected corresponding indicators, measures, and proxy values. We found that the main ecological attributes of each ecosystem contribute differently in the literature, and that almost half of the examined studies used remote sensing to estimate indicators. The major stressor for forests was “climate change”, followed by “insect infestation”; for grasslands it was “grazing”, followed by “climate change”. “Biotic interactions, composition, and structure” was the most important ecological attribute for both ecosystems. “Fire disturbance” was the second most important for forests, while for grasslands it was “soil chemistry and structure”. Less than a fifth of studies used vegetation indices; NDVI was the most common. There are monitoring inconsistencies from the broad range of indicators and measures. Therefore, we recommend a standardized field, GIS, and remote sensing-based approach to monitor ecosystem health and integrity and facilitate land managers and policy-makers.
KW  - ecosystem health assessment
KW  - grassland
KW  - forest
KW  - remote sensing
KW  - GIS
KW  - ecological integrity
KW  - ecosystem attributes
KW  - ecosystem indicators
KW  - ecosystem stressors
DO  - 10.3390/rs13163262
ER  -
TY  - EJOU
AU  - Liu, Zhijie
AU  - Guo, Pengju
AU  - Liu, Heng
AU  - Fan, Pan
AU  - Zeng, Pengzong
AU  - Liu, Xiangyang
AU  - Feng, Ce
AU  - Wang, Wang
AU  - Yang, Fuzeng
TI  - Gradient Boosting Estimation of the Leaf Area Index of Apple Orchards in UAV Remote Sensing
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 16
SN  - 2072-4292

AB  - The leaf area index (LAI) is a key parameter for describing the canopy structure of apple trees. This index is also employed in evaluating the amount of pesticide sprayed per unit volume of apple trees. Hence, numerous manual and automatic methods have been explored for LAI estimation. In this work, the leaf area indices for different types of apple trees are obtained in terms of multispectral remote-sensing data collected with an unmanned aerial vehicle (UAV), along with simultaneous measurements of apple orchards. The proposed approach was tested on apple trees of the “Fuji”, “Golden Delicious”, and “Ruixue” types, which were planted in the Apple Experimental Station of the Northwest Agriculture and Forestry University in Baishui County, Shaanxi Province, China. Five vegetation indices of strong correlation with the apple leaf area index were selected and used to train models of support vector regression (SVR) and gradient-boosting decision trees (GBDT) for predicting the leaf area index of apple trees. The best model was selected based on the metrics of the coefficient of determination (R2) and the root-mean-square error (RMSE). The experimental results showed that the gradient-boosting decision tree model achieved the best performance with an R2 of 0.846, an RMSE of 0.356, and a spatial efficiency (SPAEF) of 0.57. This demonstrates the feasibility of our approach for fast and accurate remote-sensing-based estimation of the leaf area index of apple trees.
KW  - leaf area index
KW  - gradient-boosting decision trees
KW  - UAV remote sensing
KW  - apple orchards
KW  - vegetation index
DO  - 10.3390/rs13163263
ER  -
TY  - EJOU
AU  - Ivošević, Bojana
AU  - Lugonja, Predrag
AU  - Brdar, Sanja
AU  - Radulović, Mirjana
AU  - Vujić, Ante
AU  - Valente, João
TI  - UAV-Based Land Cover Classification for Hoverfly (Diptera: Syrphidae) Habitat Condition Assessment: A Case Study on Mt. Stara Planina (Serbia)
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 16
SN  - 2072-4292

AB  - Habitat degradation, mostly caused by human impact, is one of the key drivers of biodiversity loss. This is a global problem, causing a decline in the number of pollinators, such as hoverflies. In the process of digitalizing ecological studies in Serbia, remote-sensing-based land cover classification has become a key component for both current and future research. Object-based land cover classification, using machine learning algorithms of very high resolution (VHR) imagery acquired by an unmanned aerial vehicle (UAV) was carried out in three different study sites on Mt. Stara Planina, Eastern Serbia. UAV land cover classified maps with seven land cover classes (trees, shrubs, meadows, road, water, agricultural land, and forest patches) were studied. Moreover, three different classification algorithms—support vector machine (SVM), random forest (RF), and k-NN (k-nearest neighbors)—were compared. This study shows that the random forest classifier performs better with respect to the other classifiers in all three study sites, with overall accuracy values ranging from 0.87 to 0.96. The overall results are robust to changes in labeling ground truth subsets. The obtained UAV land cover classified maps were compared with the Map of the Natural Vegetation of Europe (EPNV) and used to quantify habitat degradation and assess hoverfly species richness. It was concluded that the percentage of habitat degradation is primarily caused by anthropogenic pressure, thus affecting the richness of hoverfly species in the study sites. In order to enable research reproducibility, the datasets used in this study are made available in a public repository.
KW  - unmanned aerial vehicle
KW  - object-based image analysis
KW  - Orfeo ToolBox
KW  - QGIS
KW  - random forest
KW  - hoverfly
KW  - Map of the Natural Vegetation of Europe
DO  - 10.3390/rs13163272
ER  -
TY  - EJOU
AU  - Ulhaq, Anwaar
AU  - Adams, Peter
AU  - Cox, Tarnya E.
AU  - Khan, Asim
AU  - Low, Tom
AU  - Paul, Manoranjan
TI  - Automated Detection of Animals in Low-Resolution Airborne Thermal Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 16
SN  - 2072-4292

AB  - Detecting animals to estimate abundance can be difficult, particularly when the habitat is dense or the target animals are fossorial. The recent surge in the use of thermal imagers in ecology and their use in animal detections can increase the accuracy of population estimates and improve the subsequent implementation of management programs. However, the use of thermal imagers results in many hours of captured flight videos which require manual review for confirmation of species detection and identification. Therefore, the perceived cost and efficiency trade-off often restricts the use of these systems. Additionally, for many off-the-shelf systems, the exported imagery can be quite low resolution (&lt;9 Hz), increasing the difficulty of using automated detections algorithms to streamline the review process. This paper presents an animal species detection system that utilises the cost-effectiveness of these lower resolution thermal imagers while harnessing the power of transfer learning and an enhanced small object detection algorithm. We have proposed a distant object detection algorithm named Distant-YOLO (D-YOLO) that utilises YOLO (You Only Look Once) and improves its training and structure for the automated detection of target objects in thermal imagery. We trained our system on thermal imaging data of rabbits, their active warrens, feral pigs, and kangaroos collected by thermal imaging researchers in New South Wales and Western Australia. This work will enhance the visual analysis of animal species while performing well on low, medium and high-resolution thermal imagery.
KW  - invasive species
KW  - thermal imaging
KW  - habitat identification
KW  - deep learning
KW  - drone
DO  - 10.3390/rs13163276
ER  -
TY  - EJOU
AU  - Martins, Leandro do C.
AU  - Tordecilla, Rafael D.
AU  - Castaneda, Juliana
AU  - Juan, Angel A.
AU  - Faulin, Javier
TI  - Electric Vehicle Routing, Arc Routing, and Team Orienteering Problems in Sustainable Transportation
T2  - Energies

PY  - 2021
VL  - 14
IS  - 16
SN  - 1996-1073

AB  - The increasing use of electric vehicles in road and air transportation, especially in last-mile delivery and city mobility, raises new operational challenges due to the limited capacity of electric batteries. These limitations impose additional driving range constraints when optimizing the distribution and mobility plans. During the last years, several researchers from the Computer Science, Artificial Intelligence, and Operations Research communities have been developing optimization, simulation, and machine learning approaches that aim at generating efficient and sustainable routing plans for hybrid fleets, including both electric and internal combustion engine vehicles. After contextualizing the relevance of electric vehicles in promoting sustainable transportation practices, this paper reviews the existing work in the field of electric vehicle routing problems. In particular, we focus on articles related to the well-known vehicle routing, arc routing, and team orienteering problems. The review is followed by numerical examples that illustrate the gains that can be obtained by employing optimization methods in the aforementioned field. Finally, several research opportunities are highlighted.
KW  - electric batteries
KW  - vehicle routing problem
KW  - arc routing problem
KW  - team orienteering problem
DO  - 10.3390/en14165131
ER  -
TY  - EJOU
AU  - Anderson, Connor J.
AU  - Heins, Daniel
AU  - Pelletier, Keith C.
AU  - Bohnen, Julia L.
AU  - Knight, Joseph F.
TI  - Mapping Invasive Phragmites australis Using Unoccupied Aircraft System Imagery, Canopy Height Models, and Synthetic Aperture Radar
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 16
SN  - 2072-4292

AB  - Invasive plant species are an increasing worldwide threat both ecologically and financially. Knowing the location of these invasive plant infestations is the first step in their control. Surveying for invasive Phragmites australis is particularly challenging due to limited accessibility in wetland environments. Unoccupied aircraft systems (UAS) are a popular choice for invasive species management due to their ability to survey challenging environments and their high spatial and temporal resolution. This study tested the utility of three-band (i.e., red, green, and blue; RGB) UAS imagery for mapping Phragmites in the St. Louis River Estuary in Minnesota, U.S.A. and Saginaw Bay in Michigan, U.S.A. Iterative object-based image analysis techniques were used to identify two classes, Phragmites and Not Phragmites. Additionally, the effectiveness of canopy height models (CHMs) created from two data types, UAS imagery and commercial satellite stereo retrievals, and the RADARSAT-2 horizontal-horizontal (HH) polarization were tested for Phragmites identification. The highest overall classification accuracy of 90% was achieved when pairing the UAS imagery with a UAS-derived CHM. Producer’s accuracy for the Phragmites class ranged from 3 to 76%, and the user’s accuracies were above 90%. The Not Phragmites class had user’s and producer’s accuracies above 88%. Inclusion of the RADARSAT-2 HH polarization caused a slight reduction in classification accuracy. Commercial satellite stereo retrievals increased commission errors due to decreased spatial resolution and vertical accuracy. The lowest classification accuracy was seen when using only the RGB UAS imagery. UAS are promising for Phragmites identification, but the imagery should be used in conjunction with a CHM.
KW  - Phragmites australis
KW  - UAS
KW  - invasive species
KW  - object-based classification
KW  - OBIA
DO  - 10.3390/rs13163303
ER  -
TY  - EJOU
AU  - Huang, Jie
AU  - Tian, Guoqing
AU  - Zhang, Jiancheng
AU  - Chen, Yutao
TI  - On Unmanned Aerial Vehicles Light Show Systems: Algorithms, Software and Hardware
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 16
SN  - 2076-3417

AB  - Unmanned aerial vehicle (UAV) light shows (UAV-LS) have a wow factor due to their advantages in terms of environment friendliness and controllability compared to traditional fireworks. In this paper, a UAV-LS system is developed including a collision-free formation transformation trajectory planning algorithm, a software package that facilitates animation design and real-time monitoring and control, and hardware design and realization. In particular, a dynamic task assignment algorithm based on graph theory is proposed to reduce the impact of UAV collision avoidance on task assignment and the frequency of task assignment in the formation transformation. In addition, the software package consists of an animation interface for formation drawing and 3D animation simulation, which helps the monitoring and control of UAVs through a real-time monitoring application. The developed UAV-LS system hardware consists of subsystems of decision-making, real-time kinematic (RTK) global positioning system (GPS), wireless communication, and UAV platforms. Outdoor experiments using six quadrotors are performed and details of implementations of high-accuracy positioning, communication, and computation are presented. Results show that the developed UAV-LS system can successfully complete a light show and the proposed task assignment algorithm performs better than traditional static ones.
KW  - unmanned aerial vehicle
KW  - light show
KW  - formation transformation
KW  - task assignment
KW  - trajectory planning
DO  - 10.3390/app11167687
ER  -
TY  - EJOU
AU  - Li, Dan
AU  - Miao, Yuxin
AU  - Gupta, Sanjay K.
AU  - Rosen, Carl J.
AU  - Yuan, Fei
AU  - Wang, Chongyang
AU  - Wang, Li
AU  - Huang, Yanbo
TI  - Improving Potato Yield Prediction by Combining Cultivar Information and UAV Remote Sensing Data Using Machine Learning
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 16
SN  - 2072-4292

AB  - Accurate high-resolution yield maps are essential for identifying spatial yield variability patterns, determining key factors influencing yield variability, and providing site-specific management insights in precision agriculture. Cultivar differences can significantly influence potato (Solanum tuberosum L.) tuber yield prediction using remote sensing technologies. The objective of this study was to improve potato yield prediction using unmanned aerial vehicle (UAV) remote sensing by incorporating cultivar information with machine learning methods. Small plot experiments involving different cultivars and nitrogen (N) rates were conducted in 2018 and 2019. UAV-based multi-spectral images were collected throughout the growing season. Machine learning models, i.e., random forest regression (RFR) and support vector regression (SVR), were used to combine different vegetation indices with cultivar information. It was found that UAV-based spectral data from the early growing season at the tuber initiation stage (late June) were more correlated with potato marketable yield than the spectral data from the later growing season at the tuber maturation stage. However, the best performing vegetation indices and the best timing for potato yield prediction varied with cultivars. The performance of the RFR and SVR models using only remote sensing data was unsatisfactory (R2 = 0.48–0.51 for validation) but was significantly improved when cultivar information was incorporated (R2 = 0.75–0.79 for validation). It is concluded that combining high spatial-resolution UAV images and cultivar information using machine learning algorithms can significantly improve potato yield prediction than methods without using cultivar information. More studies are needed to improve potato yield prediction using more detailed cultivar information, soil and landscape variables, and management information, as well as more advanced machine learning models.
KW  - potato marketable yield
KW  - random forest
KW  - support vector regression
KW  - growing degree days
KW  - growth stage
DO  - 10.3390/rs13163322
ER  -
TY  - EJOU
AU  - Kelechi, Anabi H.
AU  - Alsharif, Mohammed H.
AU  - Oluwole, Damilare A.
AU  - Achimugu, Philip
AU  - Ubadike, Osichinaka
AU  - Nebhen, Jamel
AU  - Aaron-Anthony, Atayero
AU  - Uthansakul, Peerapong
TI  - The Recent Advancement in Unmanned Aerial Vehicle Tracking Antenna: A Review
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 16
SN  - 1424-8220

AB  - Unmanned aerial vehicle (UAV) antenna tracking system is an electromechanical component designed to track and steer the signal beams from the ground control station (GCS) to the airborne platform for optimum signal alignment. In a tracking system, an antenna continuously tracks a moving target and records their position. A UAV tracking antenna system is susceptible to signal loss if omnidirectional antenna is deployed as the preferred design. Therefore, to achieve longer UAV distance communication, there is a need for directional high gain antenna. From design principle, directional antennas are known to focus their signal energy in a particular direction viewed from their radiation pattern which is concentrated in a particular azimuth direction. Unfortunately, a directional antenna is limited by angle, thus, it must always be directed to the target. The other limitation of a UAV mechanical beam steering system is that the system is expensive to maintain and with low reliability. To solve this problem, we are proposing the use of MIMO technology as a readily available technology for UAV beyond line of sight technology. Although UAV antenna tracking is domiciled in the mechanical beam steering arrangement, this study shows that this native technology could be usurped by MIMO beam forming.
KW  - UAV
KW  - tracking antenna system
KW  - azimuth angle
KW  - elevation angle
KW  - range
KW  - MIMO technology
KW  - beam steering
KW  - antenna array
DO  - 10.3390/s21165662
ER  -
TY  - EJOU
AU  - Chen, Tianxin
AU  - Liu, Yongxue
TI  - A Quick Band-to-Band Mis-Registration Detection Method for Sentinel-2 MSI Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 17
SN  - 2072-4292

AB  - A band-to-band mis-registration (BBMR) error often occurs in remote sensing (RS) images acquired by multi-spectral push broom spectrometers such as the Sentinel-2 Multi-spectral Instrument (MSI), leading to adverse impacts on the reliability of further RS applications. Although the systematic band-to-band registration conducted during the image production process corrects most BBMR errors, there are still quite a few images being observed with discernible BBMR. Thus, a quick BBMR detection method is needed to assess the quality of online RS products. We here propose a hybrid framework for detecting BBMR between the visible bands in MSI images. This framework comprises three main steps: first, candidate chips are captured based on Google Earth Engine (GEE) spatial analysis functions to shrink the valid areas inside image scenes as potential target chips. The redundant data pertaining to the local operation process are thus narrowed down. Second, spectral abnormal areas are precisely extracted from inside every single chip, excluding the influences of clouds and water surfaces. Finally, the abnormal areas are matched pixel by pixel between bands, and the best-fit coordinates are then determined to compare with tolerance. Here, the proposed method was applied to 71,493 scenes of MSI Level-1C images covering China and its surrounding areas on the GEE platform. From these images, 4356 chips from 442 scenes were detected with inter-band offsets among the visible bands. Further manual visual inspection revealed that the proposed method had an accuracy of 98.07% at the chip scale and 88.46% at the scene scale.
KW  - band-to-band mis-registration (BBMR)
KW  - spectral anomaly detection
KW  - multi-spectral instrument (MSI)
KW  - Google Earth Engine (GEE)
KW  - hybrid computation
DO  - 10.3390/rs13173351
ER  -
TY  - EJOU
AU  - Marzialetti, Flavio
AU  - Frate, Ludovico
AU  - De Simone, Walter
AU  - Frattaroli, Anna R.
AU  - Acosta, Alicia T.
AU  - Carranza, Maria L.
TI  - Unmanned Aerial Vehicle (UAV)-Based Mapping of Acacia saligna Invasion in the Mediterranean Coast
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 17
SN  - 2072-4292

AB  - Remote Sensing (RS) is a useful tool for detecting and mapping Invasive Alien Plants (IAPs). IAPs mapping on dynamic and heterogeneous landscapes, using satellite RS data, is not always feasible. Unmanned aerial vehicles (UAV) with ultra-high spatial resolution data represent a promising tool for IAPs detection and mapping. This work develops an operational workflow for detecting and mapping Acacia saligna invasion along Mediterranean coastal dunes. In particular, it explores and tests the potential of RGB (Red, Green, Blue) and multispectral (Green, Red, Red Edge, Near Infra—Red) UAV images collected in pre-flowering and flowering phenological stages for detecting and mapping A. saligna. After ortho—mosaics generation, we derived from RGB images the DSM (Digital Surface Model) and HIS (Hue, Intensity, Saturation) variables, and we calculated the NDVI (Normalized Difference Vegetation Index). For classifying images of the two phenological stages we built a set of raster stacks which include different combination of variables. For image classification, we used the Geographic Object-Based Image Analysis techniques (GEOBIA) in combination with Random Forest (RF) classifier. All classifications derived from RS information (collected on pre-flowering and flowering stages and using different combinations of variables) produced A. saligna maps with acceptable accuracy values, with higher performances on classification derived from flowering period images, especially using DSM + HIS combination. The adopted approach resulted an efficient method for mapping and early detection of IAPs, also in complex environments offering a sound support to the prioritization of conservation and management actions claimed by the EU IAS Regulation 1143/2014.
KW  - invasive plant species
KW  - coastal dunes
KW  - RGB and multispectral images
KW  - species flowering
KW  - drones
KW  - GEOBIA
KW  - HIS variables
KW  - random forest
DO  - 10.3390/rs13173361
ER  -
TY  - EJOU
AU  - Abdelmaboud, Abdelzahir
TI  - The Internet of Drones: Requirements, Taxonomy, Recent Advances, and Challenges of Research Trends
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 17
SN  - 1424-8220

AB  - The use of unmanned aerial vehicles or drones are a valuable technique in coping with issues related to life in the general public’s daily routines. Given the growing number of drones in low-altitude airspace, linking drones to form the Internet of drones (IoD) is a highly desirable trend to improve the safety as well as the quality of flight. However, there remain security, privacy, and communication issues related to IoD. In this paper, we discuss the key requirements of security, privacy, and communication and we present a taxonomy of IoD based on the most relevant considerations. Furthermore, we present the most commonly used commercial case studies and address the latest advancements and solutions proposed for the IoD environments. Lastly, we discuss the challenges and future research directions of IoD.
KW  - Internet of drones
KW  - communication
KW  - security
KW  - privacy
DO  - 10.3390/s21175718
ER  -
TY  - EJOU
AU  - Grau, Joan
AU  - Liang, Kang
AU  - Ogilvie, Jae
AU  - Arp, Paul
AU  - Li, Sheng
AU  - Robertson, Bonnie
AU  - Meng, Fan-Rui
TI  - Using Unmanned Aerial Vehicle and LiDAR-Derived DEMs to Estimate Channels of Small Tributary Streams
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 17
SN  - 2072-4292

AB  - Defining stream channels in a watershed is important for assessing freshwater habitat availability, complexity, and quality. However, mapping channels of small tributary streams becomes challenging due to frequent channel change and dense vegetation coverage. In this study, we used an Unmanned Aerial Vehicle (UAV) and photogrammetry method to obtain a 3D Digital Surface Model (DSM) to estimate the total in-stream channel and channel width within grazed riparian pastures. We used two methods to predict the stream channel boundary: the Slope Gradient (SG) and Vertical Slope Position (VSP). As a comparison, the same methods were also applied using low-resolution DEM, obtained with traditional photogrammetry (coarse resolution) and two more LiDAR-derived DEMs with different resolution. When using the SG method, the higher-resolution, UAV-derived DEM provided the best agreement with the field-validated area followed by the high-resolution LiDAR DEM, with Mean Squared Errors (MSE) of 1.81 m and 1.91 m, respectively. The LiDAR DEM collected at low resolution was able to predict the stream channel with a MSE of 3.33 m. Finally, the coarse DEM did not perform accurately and the MSE obtained was 26.76 m. On the other hand, when the VSP method was used we found that low-resolution LiDAR DEM performed the best followed by high-resolution LiDAR, with MSE values of 9.70 and 11.45 m, respectively. The MSE for the UAV-derived DEM was 15.12 m and for the coarse DEM was 20.78 m. We found that the UAV-derived DEM could be used to identify steep bank which could be used for mapping the hydrogeomorphology of lower order streams. Therefore, UAVs could be applied to efficiently map small stream channels in order to monitor the dynamic changes occurring in these ecosystems at a local scale. However, the VSP method should be used to map stream channels in small watersheds when high resolution DEM data is not available.
KW  - DEM
KW  - LiDAR
KW  - UAV
KW  - stream bank
KW  - VSP
KW  - Slope Gradient
DO  - 10.3390/rs13173380
ER  -
TY  - EJOU
AU  - Qader, Sarchil H.
AU  - Dash, Jadu
AU  - Alegana, Victor A.
AU  - Khwarahm, Nabaz R.
AU  - Tatem, Andrew J.
AU  - Atkinson, Peter M.
TI  - The Role of Earth Observation in Achieving Sustainable Agricultural Production in Arid and Semi-Arid Regions of the World
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 17
SN  - 2072-4292

AB  - Crop production is a major source of food and livelihood for many people in arid and semi-arid (ASA) regions across the world. However, due to irregular climatic events, ASA regions are affected commonly by frequent droughts that can impact food production. In addition, ASA regions in the Middle East and Africa are often characterised by political instability, which can increase population vulnerability to hunger and ill health. Remote sensing (RS) provides a platform to improve the spatial prediction of crop production and food availability, with the potential to positively impact populations. This paper, firstly, describes some of the important characteristics of agriculture in ASA regions that require monitoring to improve their management. Secondly, it demonstrates how freely available RS data can support decision-making through a cost-effective monitoring system that complements traditional approaches for collecting agricultural data. Thirdly, it illustrates the challenges of employing freely available RS data for mapping and monitoring crop area, crop status and forecasting crop yield in these regions. Finally, existing approaches used in these applications are evaluated, and the challenges associated with their use and possible future improvements are discussed. We demonstrate that agricultural activities can be monitored effectively and both crop area and crop yield can be predicted in advance using RS data. We also discuss the future challenges associated with maintaining food security in ASA regions and explore some recent advances in RS that can be used to monitor cropland and forecast crop production and yield.
KW  - agriculture
KW  - arid and semi-arid regions
KW  - crop monitoring
KW  - remote sensing
KW  - crop yield
DO  - 10.3390/rs13173382
ER  -
TY  - EJOU
AU  - Sibanda, Mbulisi
AU  - Mutanga, Onisimo
AU  - Chimonyo, Vimbayi G. P.
AU  - Clulow, Alistair D.
AU  - Shoko, Cletah
AU  - Mazvimavi, Dominic
AU  - Dube, Timothy
AU  - Mabhaudhi, Tafadzwanashe
TI  - Application of Drone Technologies in Surface Water Resources Monitoring and Assessment: A Systematic Review of Progress, Challenges, and Opportunities in the Global South
T2  - Drones

PY  - 2021
VL  - 5
IS  - 3
SN  - 2504-446X

AB  - Accurate and timely information on surface water quality and quantity is critical for various applications, including irrigation agriculture. In-field water quality and quantity data from unmanned aerial vehicle systems (UAVs) could be useful in closing spatial data gaps through the generation of near-real-time, fine resolution, spatially explicit information required for water resources accounting. This study assessed the progress, opportunities, and challenges in mapping and modelling water quality and quantity using data from UAVs. To achieve this research objective, a systematic review was adopted. The results show modest progress in the utility of UAVs, especially in the global south. This could be attributed, in part, to high costs, a lack of relevant skills, and the regulations associated with drone procurement and operational costs. The progress is further compounded by a general lack of research focusing on UAV application in water resources monitoring and assessment. More importantly, the lack of robust and reliable water quantity and quality data needed to parameterise models remains challenging. However, there are opportunities to advance scientific inquiry for water quality and quantity accounting by integrating UAV data and machine learning.
KW  - drones
KW  - green water
KW  - integrated water management strategies
KW  - remote sensing
KW  - smallholder farms
KW  - water productivity
DO  - 10.3390/drones5030084
ER  -
TY  - EJOU
AU  - Amicone, Donatello
AU  - Cannas, Andrea
AU  - Marci, Alberto
AU  - Tortora, Giuseppe
TI  - A Smart Capsule Equipped with Artificial Intelligence for Autonomous Delivery of Medical Material through Drones
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 17
SN  - 2076-3417

AB  - In the last few years, many examples of blood and medicine delivery drones have been demonstrated worldwide, which mainly rely on aeronautical experience that is not common in the medical world. Speaking about drone delivery, attention should focus on the most important thing: the transported lifesaving good. Traditional boxes that monitor temperature are not usually in real time, and are not suitable for drone transportation because they are heavy and bulky. This means that the biomedical characteristics of delivery are of primary importance. A Smart Capsule, equipped with artificial intelligence (AI), is the first system ever proposed to provide a fully autonomous drone delivery service for perishable and high-value medical products, integrating real-time quality monitoring and control. It consists in a smart casing that is able to guide any autonomous aerial vehicle attached to it, specifically designed for transporting blood, organs, tissues, test samples and drugs, among others. The system monitors the conditions of the product (e.g., temperature, agitation and humidity) and adjusts them when needed by exploiting, for instance, vibrations to maintain the required agitation, ensuring that goods are ready to be used as soon as they are delivered. The Smart Capsule also leverages external temperature to reduce energy uptake from the drone, thus improving the drone’s battery life and flight range. The system replaces the need for specialized drivers and traditional road-bound transportation means, while guaranteeing compliance with all applicable safety regulations. A series of 16 experimental tests was performed to demonstrate the possibility of using the smart capsule to manage the flight and internal good delivery. Eighty-one missions were carried out for a total of 364 min of flight. The Smart Capsule greatly improves emergency response and efficiency of healthcare systems by reducing delivery times by up to 80% and costs by at least 28%. The Smart Capsule and its enabling technology based on AI for drone deliveries are discussed in this paper. The aim of this work is to show the possibility of managing drone delivery with an AI-based device.
KW  - medical delivery
KW  - drone delivery
KW  - telemedicine
KW  - autonomous robot
KW  - AI
DO  - 10.3390/app11177976
ER  -
TY  - EJOU
AU  - Specht, Mariusz
AU  - Stateczny, Andrzej
AU  - Specht, Cezary
AU  - Widźgowski, Szymon
AU  - Lewicka, Oktawia
AU  - Wiśniewska, Marta
TI  - Concept of an Innovative Autonomous Unmanned System for Bathymetric Monitoring of Shallow Waterbodies (INNOBAT System)
T2  - Energies

PY  - 2021
VL  - 14
IS  - 17
SN  - 1996-1073

AB  - Bathymetry is a subset of hydrography, aimed at measuring the depth of waterbodies and waterways. Measurements are taken inter alia to detect natural obstacles or other navigational obstacles that endanger the safety of navigation, to examine the navigability conditions, anchorages, waterways and other commercial waterbodies, and to determine the parameters of the safe depth of waterbodies in the vicinity of ports, etc. Therefore, it is necessary to produce precise and reliable seabed maps, so that any hazards that may occur, particularly in shallow waterbodies, can be prevented, including the high dynamics of hydromorphological changes. This publication is aimed at developing a concept of an innovative autonomous unmanned system for bathymetric monitoring of shallow waterbodies. A bathymetric and topographic system will use autonomous unmanned aerial and surface vehicles to study the seabed relief in the littoral zone (even at depths of less than 1 m), in line with the requirements set out for the most stringent International Hydrographic Organization (IHO) order—exclusive. Unlike other existing solutions, the INNOBAT system will enable the coverage of the entire surveyed area with measurements, which will allow a comprehensive assessment of the hydrographic and navigation situation in the waterbody to be conducted.
KW  - unmanned surface vehicle (USV)
KW  - unmanned aerial vehicle (UAV)
KW  - bathymetric monitoring system
KW  - shallow waterbody
KW  - hydrography
DO  - 10.3390/en14175370
ER  -
TY  - EJOU
AU  - Aghababaei, Masoumeh
AU  - Ebrahimi, Ataollah
AU  - Naghipour, Ali A.
AU  - Asadi, Esmaeil
AU  - Verrelst, Jochem
TI  - Classification of Plant Ecological Units in Heterogeneous Semi-Steppe Rangelands: Performance Assessment of Four Classification Algorithms
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 17
SN  - 2072-4292

AB  - Plant Ecological Unit’s (PEUs) are the abstraction of vegetation communities that occur on a site which similarly respond to management actions and natural disturbances. Identification and monitoring of PEUs in a heterogeneous landscape is the most difficult task in medium resolution satellite images datasets. The main objective of this study is to compare pixel-based classification versus object-based classification for accurately classifying PEUs with four selected different algorithms across heterogeneous rangelands in Central Zagros, Iran. We used images of Landsat-8 OLI that were pan-sharpened to 15 m to classify four PEU classes based on a random dataset collected in the field (40%). In the first stage, we applied the following classification algorithms to distinguish PEUs: Minimum Distance (MD), Maximum Likelihood Classification (MLC), Neural Network-Multi Layer Perceptron (NN-MLP) and Classification Tree Analysis (CTA) for pixel based method and object based method. Then, by using the most accurate classification approach, in the second stage auxiliary data (Principal Component Analysis (PCA)) was incorporated to improve the accuracy of the PEUs classification process. At the end, test data (60%) were used for accuracy assessment of the resulting maps. Object-based maps clearly outperformed pixel-based maps, especially with CTA, NN-MLP and MD algorithms with overall accuracies of 86%, 72% and 59%, respectively. The MLC algorithm did not reveal any significant difference between the object-based and pixel-based analyses. Finally, complementing PCA auxiliary bands to the CTA algorithms offered the most successful PEUs classification strategy, with the highest overall accuracy (89%). The results clearly underpin the importance of object-based classification with the CTA classifier together with PCA auxiliary data to optimize identification of PEU classes.
KW  - object-based classification
KW  - machine learning algorithms
KW  - principal component analysis
KW  - plant ecological units mapping
DO  - 10.3390/rs13173433
ER  -
TY  - EJOU
AU  - Qi, Yuan
AU  - Dong, Xuhua
AU  - Chen, Pengchao
AU  - Lee, Kyeong-Hwan
AU  - Lan, Yubin
AU  - Lu, Xiaoyang
AU  - Jia, Ruichang
AU  - Deng, Jizhong
AU  - Zhang, Yali
TI  - Canopy Volume Extraction of Citrus reticulate Blanco cv. Shatangju Trees Using UAV Image-Based Point Cloud Deep Learning
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 17
SN  - 2072-4292

AB  - Automatic acquisition of the canopy volume parameters of the Citrus reticulate Blanco cv. Shatangju tree is of great significance to precision management of the orchard. This research combined the point cloud deep learning algorithm with the volume calculation algorithm to segment the canopy of the Citrus reticulate Blanco cv. Shatangju trees. The 3D (Three-Dimensional) point cloud model of a Citrus reticulate Blanco cv. Shatangju orchard was generated using UAV tilt photogrammetry images. The segmentation effects of three deep learning models, PointNet++, MinkowskiNet and FPConv, on Shatangju trees and the ground were compared. The following three volume algorithms: convex hull by slices, voxel-based method and 3D convex hull were applied to calculate the volume of Shatangju trees. Model accuracy was evaluated using the coefficient of determination (R2) and Root Mean Square Error (RMSE). The results show that the overall accuracy of the MinkowskiNet model (94.57%) is higher than the other two models, which indicates the best segmentation effect. The 3D convex hull algorithm received the highest R2 (0.8215) and the lowest RMSE (0.3186 m3) for the canopy volume calculation, which best reflects the real volume of Citrus reticulate Blanco cv. Shatangju trees. The proposed method is capable of rapid and automatic acquisition for the canopy volume of Citrus reticulate Blanco cv. Shatangju trees.
KW  - canopy volume
KW  - UAV tilt photogrammetry
KW  - point cloud
KW  - deep learning
KW  - Citrus reticulate Blanco cv. Shatangju trees
DO  - 10.3390/rs13173437
ER  -
TY  - EJOU
AU  - Grigusova, Paulina
AU  - Larsen, Annegret
AU  - Achilles, Sebastian
AU  - Klug, Alexander
AU  - Fischer, Robin
AU  - Kraus, Diana
AU  - Übernickel, Kirstin
AU  - Paulino, Leandro
AU  - Pliscoff, Patricio
AU  - Brandl, Roland
AU  - Farwig, Nina
AU  - Bendix, Jörg
TI  - Area-Wide Prediction of Vertebrate and Invertebrate Hole Density and Depth across a Climate Gradient in Chile Based on UAV and Machine Learning
T2  - Drones

PY  - 2021
VL  - 5
IS  - 3
SN  - 2504-446X

AB  - Burrowing animals are important ecosystem engineers affecting soil properties, as their burrowing activity leads to the redistribution of nutrients and soil carbon sequestration. The magnitude of these effects depends on the spatial density and depth of such burrows, but a method to derive this type of spatially explicit data is still lacking. In this study, we test the potential of using consumer-oriented UAV RGB imagery to determine the density and depth of holes created by burrowing animals at four study sites along a climate gradient in Chile, by combining UAV data with empirical field plot observations and machine learning techniques. To enhance the limited spectral information in RGB imagery, we derived spatial layers representing vegetation type and height and used landscape textures and diversity to predict hole parameters. Across-site models for hole density generally performed better than those for depth, where the best-performing model was for the invertebrate hole density (R2 = 0.62). The best models at individual study sites were obtained for hole density in the arid climate zone (R2 = 0.75 and 0.68 for invertebrates and vertebrates, respectively). Hole depth models only showed good to fair performance. Regarding predictor importance, the models heavily relied on vegetation height, texture metrics, and diversity indices.
KW  - UAV
KW  - machine learning
KW  - burrowing animals
KW  - climate gradient
KW  - Chile
KW  - vegetation patterns
KW  - heterogeneity
DO  - 10.3390/drones5030086
ER  -
TY  - EJOU
AU  - Tan, Junxiang
AU  - Zhao, Haojie
AU  - Yang, Ronghao
AU  - Liu, Hua
AU  - Li, Shaoda
AU  - Liu, Jianfei
TI  - An Entropy-Weighting Method for Efficient Power-Line Feature Evaluation and Extraction from LiDAR Point Clouds
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 17
SN  - 2072-4292

AB  - Power-line inspection is an important means to maintain the safety of power networks. Light detection and ranging (LiDAR) technology can provide high-precision 3D information about power corridors for automated power-line inspection, so there are more and more utility companies relying on LiDAR systems instead of traditional manual operation. However, it is still a challenge to automatically detect power lines with high precision. To achieve efficient and accurate power-line extraction, this paper proposes an algorithm using entropy-weighting feature evaluation (EWFE), which is different from the existing hierarchical-multiple-rule evaluation of many geometric features. Six significant features are selected (Height above Ground Surface (HGS), Vertical Range Ratio (VRR), Horizontal Angle (HA), Surface Variation (SV), Linearity (LI) and Curvature Change (CC)), and then the features are combined to construct a vector for quantitative evaluation. The feature weights are determined by an entropy-weighting method (EWM) to achieve optimal distribution. The point clouds are filtered out by the HGS feature, which possesses the highest entropy value, and a portion of non-power-line points can be removed without loss of power-line points. The power lines are extracted by evaluation of the other five features. To decrease the interference from pylon points, this paper analyzes performance in different pylon situations and performs an adaptive weight transformation. We evaluate the EWFE method using four datasets with different transmission voltage scales captured by a light unmanned aerial vehicle (UAV) LiDAR system and a mobile LiDAR system. Experimental results show that our method demonstrates efficient performance, while algorithm parameters remain consistent for the four datasets. The precision F value ranges from 98.4% to 99.7%, and the efficiency ranges from 0.9 million points/s to 5.2 million points/s.
KW  - unmanned aerial vehicle (UAV)
KW  - power-line extraction
KW  - entropy weighting
KW  - feature evaluation
DO  - 10.3390/rs13173446
ER  -
TY  - EJOU
AU  - Gutiérrez, Álvaro G.
AU  - Chávez, Roberto O.
AU  - Díaz-Hormazábal, Ignacio
TI  - Canopy Gap Structure as an Indicator of Intact, Old-Growth Temperate Rainforests in the Valdivian Ecoregion
T2  - Forests

PY  - 2021
VL  - 12
IS  - 9
SN  - 1999-4907

AB  - Forest degradation continues to increase globally, threatening biodiversity and the survival of species. In this context, identifying intact, old-growth forest stands is both urgent and vital to ensure their existence and multiple contributions to society. Despite the global ecological importance of the Valdivian temperate rainforests, they are threatened by forest degradation resulting from constant and intense human use in the region. Identification of remnant intact forests in this region is urgent to global forest protection efforts. In this paper, we analyzed whether forests-canopy alterations due to logging produce a distinctive canopy gap structure (e.g., a gap area and a fraction of canopy gaps in the forest) that can be used to remotely distinguish intact from altered forests. We tested this question by comparing the canopy gap structure of 12 old-growth temperate rainforests in south-central Chile (39–40° S), with different levels of canopy alterations due to logging. At each stand, we obtained aerial or satellite very high spatial-resolution images that were automatically segmented using the Mean-Shift segmentation algorithm. We validated the results obtained remotely with ground data on the canopy gap structure. We found that the variables, canopy gap fraction, gap area frequency distribution, and mean gap area could be measured remotely with a high level of accuracy. Intact forests have a distinct canopy gap structure in comparison to forests with canopy alterations due to logging. Our results provided a fast, low-cost, and reliable method to obtain canopy gap structure indicators for mapping and monitoring intact forests in the Valdivian ecoregion. The method provided valuable information for managers interested in maintaining and restoring old-growth forest structures in these southern-temperate rainforests.
KW  - forest degradation
KW  - uneven-aged forest structure
KW  - human-induced disturbances
KW  - treefall canopy gaps
KW  - remote sensing
DO  - 10.3390/f12091183
ER  -
TY  - EJOU
AU  - Gupta, Anunay
AU  - Afrin, Tanzina
AU  - Scully, Evan
AU  - Yodo, Nita
TI  - Advances of UAVs toward Future Transportation: The State-of-the-Art, Challenges, and Opportunities
T2  - Future Transportation

PY  - 2021
VL  - 1
IS  - 2
SN  - 2673-7590

AB  - The adoption of Unmanned Aerial Vehicles (UAVs) in numerous sectors is projected to grow exponentially in the future as technology advances and regulation evolves. One of the promising applications of UAVs is in transportation systems. As the current transportation system is moving towards Intelligent Transportation Systems (ITS), UAVs will play a significant role in the functioning of ITS. This paper presents a survey on the recent advances of UAVs and their roles in current and future transportation systems. Moreover, the emerging technologies of UAVs in the transportation section and the current research areas are summarized. From the discussion, the challenges and opportunities of integrating UAVs towards future ITS are highlighted. In addition, some of the potential research areas involving UAVs in future ITS are also identified. This study aims to lay a foundation for the development of future intelligent and resilient transportation systems.
KW  - Unmanned Aerial Vehicles (UAV)
KW  - drone
KW  - future transportation
KW  - intelligent transportation systems
KW  - ITS
DO  - 10.3390/futuretransp1020019
ER  -
TY  - EJOU
AU  - Pranga, Joanna
AU  - Borra-Serrano, Irene
AU  - Aper, Jonas
AU  - De Swaef, Tom
AU  - Ghesquiere, An
AU  - Quataert, Paul
AU  - Roldán-Ruiz, Isabel
AU  - Janssens, Ivan A.
AU  - Ruysschaert, Greet
AU  - Lootens, Peter
TI  - Improving Accuracy of Herbage Yield Predictions in Perennial Ryegrass with UAV-Based Structural and Spectral Data Fusion and Machine Learning
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 17
SN  - 2072-4292

AB  - High-throughput field phenotyping using close remote sensing platforms and sensors for non-destructive assessment of plant traits can support the objective evaluation of yield predictions of large breeding trials. The main objective of this study was to examine the potential of unmanned aerial vehicle (UAV)-based structural and spectral features and their combination in herbage yield predictions across diploid and tetraploid varieties and breeding populations of perennial ryegrass (Lolium perenne L.). Canopy structural (i.e., canopy height) and spectral (i.e., vegetation indices) information were derived from data gathered with two sensors: a consumer-grade RGB and a 10-band multispectral (MS) camera system, which were compared in the analysis. A total of 468 field plots comprising 115 diploid and 112 tetraploid varieties and populations were considered in this study. A modelling framework established to predict dry matter yield (DMY), was used to test three machine learning algorithms, including Partial Least Squares Regression (PLSR), Random Forest (RF), and Support Vector Machines (SVM). The results of the nested cross-validation revealed: (a) the fusion of structural and spectral features achieved better DMY estimates as compared to models fitted with structural or spectral data only, irrespective of the sensor, ploidy level or machine learning algorithm applied; (b) models built with MS-based predictor variables, despite their lower spatial resolution, slightly outperformed the RGB-based models, as lower mean relative root mean square error (rRMSE) values were delivered; and (c) on average, the RF technique reported the best model performances among tested algorithms, regardless of the dataset used. The approach introduced in this study can provide accurate yield estimates (up to an RMSE = 308 kg ha−1) and useful information for breeders and practical farm-scale applications.
KW  - high-throughput field phenotyping (HTFP)
KW  - pasture
KW  - forage
KW  - RGB sensor
KW  - multispectral sensor
KW  - close remote sensing
KW  - partial least squares regression (PLSR)
KW  - random forest (RF)
KW  - support vector machines (SVM)
DO  - 10.3390/rs13173459
ER  -
TY  - EJOU
AU  - Alexandris, Stavros
AU  - Psomiadis, Emmanouil
AU  - Proutsos, Nikolaos
AU  - Philippopoulos, Panos
AU  - Charalampopoulos, Ioannis
AU  - Kakaletris, George
AU  - Papoutsi, Eleni-Magda
AU  - Vassilakis, Stylianos
AU  - Paraskevopoulos, Antoniοs
TI  - Integrating Drone Technology into an Innovative Agrometeorological Methodology for the Precise and Real-Time Estimation of Crop Water Requirements
T2  - Hydrology

PY  - 2021
VL  - 8
IS  - 3
SN  - 2306-5338

AB  - Precision agriculture has been at the cutting edge of research during the recent decade, aiming to reduce water consumption and ensure sustainability in agriculture. The proposed methodology was based on the crop water stress index (CWSI) and was applied in Greece within the ongoing research project GreenWaterDrone. The innovative approach combines real spatial data, such as infrared canopy temperature, air temperature, air relative humidity, and thermal infrared image data, taken above the crop field using an aerial micrometeorological station (AMMS) and a thermal (IR) camera installed on an unmanned aerial vehicle (UAV). Following an initial calibration phase, where the ground micrometeorological station (GMMS) was installed in the crop, no equipment needed to be maintained in the field. Aerial and ground measurements were transferred in real time to sophisticated databases and applications over existing mobile networks for further processing and estimation of the actual water requirements of a specific crop at the field level, dynamically alerting/informing local farmers/agronomists of the irrigation necessity and additionally for potential risks concerning their fields. The supported services address farmers’, agricultural scientists’, and local stakeholders’ needs to conform to regional water management and sustainable agriculture policies. As preliminary results of this study, we present indicative original illustrations and data from applying the methodology to assess UAV functionality while aiming to evaluate and standardize all system processes.
KW  - CWSI
KW  - UAV
KW  - remote sensing
KW  - micrometeorological data
KW  - spatial IRT measurements
KW  - crop irrigation scheduling and management
KW  - infrared radiometer sensors
KW  - real-time data analysis
DO  - 10.3390/hydrology8030131
ER  -
TY  - EJOU
AU  - Roy Choudhury, Malini
AU  - Das, Sumanta
AU  - Christopher, Jack
AU  - Apan, Armando
AU  - Chapman, Scott
AU  - Menzies, Neal W.
AU  - Dang, Yash P.
TI  - Improving Biomass and Grain Yield Prediction of Wheat Genotypes on Sodic Soil Using Integrated High-Resolution Multispectral, Hyperspectral, 3D Point Cloud, and Machine Learning Techniques
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 17
SN  - 2072-4292

AB  - Sodic soils adversely affect crop production over extensive areas of rain-fed cropping worldwide, with particularly large areas in Australia. Crop phenotyping may assist in identifying cultivars tolerant to soil sodicity. However, studies to identify the most appropriate traits and reliable tools to assist crop phenotyping on sodic soil are limited. Hence, this study evaluated the ability of multispectral, hyperspectral, 3D point cloud, and machine learning techniques to improve estimation of biomass and grain yield of wheat genotypes grown on a moderately sodic (MS) and highly sodic (HS) soil sites in northeastern Australia. While a number of studies have reported using different remote sensing approaches and crop traits to quantify crop growth, stress, and yield variation, studies are limited using the combination of these techniques including machine learning to improve estimation of genotypic biomass and yield, especially in constrained sodic soil environments. At close to flowering, unmanned aerial vehicle (UAV) and ground-based proximal sensing was used to obtain remote and/or proximal sensing data, while biomass yield and crop heights were also manually measured in the field. Grain yield was machine-harvested at maturity. UAV remote and/or proximal sensing-derived spectral vegetation indices (VIs), such as normalized difference vegetation index, optimized soil adjusted vegetation index, and enhanced vegetation index and crop height were closely corresponded to wheat genotypic biomass and grain yields. UAV multispectral VIs more closely associated with biomass and grain yields compared to proximal sensing data. The red-green-blue (RGB) 3D point cloud technique was effective in determining crop height, which was slightly better correlated with genotypic biomass and grain yield than ground-measured crop height data. These remote sensing-derived crop traits (VIs and crop height) and wheat biomass and grain yields were further simulated using machine learning algorithms (multitarget linear regression, support vector machine regression, Gaussian process regression, and artificial neural network) with different kernels to improve estimation of biomass and grain yield. The artificial neural network predicted biomass yield (R2 = 0.89; RMSE = 34.8 g/m2 for the MS and R2 = 0.82; RMSE = 26.4 g/m2 for the HS site) and grain yield (R2 = 0.88; RMSE = 11.8 g/m2 for the MS and R2 = 0.74; RMSE = 16.1 g/m2 for the HS site) with slightly less error than the others. Wheat genotypes Mitch, Corack, Mace, Trojan, Lancer, and Bremer were identified as more tolerant to sodic soil constraints than Emu Rock, Janz, Flanker, and Gladius. The study improves our ability to select appropriate traits and techniques in accurate estimation of wheat genotypic biomass and grain yields on sodic soils. This will also assist farmers in identifying cultivars tolerant to sodic soil constraints.
KW  - phenotyping
KW  - vegetation indices
KW  - crop height
KW  - machine learning
KW  - biomass and grain yields
KW  - sodic soil
DO  - 10.3390/rs13173482
ER  -
TY  - EJOU
AU  - Zhang, Zhen
AU  - Wang, Leilei
AU  - Xue, Naiting
AU  - Du, Zhiheng
TI  - Spatiotemporal Analysis of Active Fires in the Arctic Region during 2001–2019 and a Fire Risk Assessment Model
T2  - Fire

PY  - 2021
VL  - 4
IS  - 3
SN  - 2571-6255

AB  - The increasing frequency of active fires worldwide has caused significant impacts on terrestrial, aquatic, and atmospheric systems. Polar regions have received little attention due to their sparse populations, but active fires in the Arctic cause carbon losses from peatlands, which affects the global climate system. Therefore, it is necessary to focus on the spatiotemporal variations in active fires in the Arctic and to assess the fire risk. We used MODIS C6 data from 2001 to 2019 and VIIRS V1 data from 2012 to 2019 to analyse the spatiotemporal characteristics of active fires and establish a fire risk assessment model based on logistic regression. The trends in active fire frequency based on MODIS C6 and VIIRS V1 data are consistent. Throughout the Arctic, the fire frequency appears to be fluctuating and overall increasing. Fire occurrence has obvious seasonality, being concentrated in summer (June–August) and highest in July, when lightning is most frequent. The frequency of active fires is related to multiple factors, such as vegetation type, NDVI, elevation, slope, air temperature, precipitation, wind speed, and distances from roads and settlements. A risk assessment model was constructed based on logistic regression and found to be accurate. The results are helpful in understanding the risk of fires in the Arctic under climate change and provide a scientific basis for fire prediction and control and for reducing fire-related carbon emissions.
KW  - active fires
KW  - fire risk assessment
KW  - arctic
KW  - MODIS
KW  - VIIRS
DO  - 10.3390/fire4030057
ER  -
TY  - EJOU
AU  - Tyc, Jakub
AU  - Sunguroğlu Hensel, Defne
AU  - Parisi, Erica I.
AU  - Tucci, Grazia
AU  - Hensel, Michael U.
TI  - Integration of Remote Sensing Data into a Composite Voxel Model for Environmental Performance Analysis of Terraced Vineyards in Tuscany, Italy
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 17
SN  - 2072-4292

AB  - Understanding socio-ecological systems and the discovery, recovery and adaptation of land knowledge are key challenges for sustainable land use. The analysis of sustainable agricultural systems and practices, for instance, requires interdisciplinary and transdisciplinary research and coordinated data acquisition, data integration and analysis. However, datasets, which are acquired using remote sensing, geospatial analysis and simulation techniques, are often limited by narrow disciplinary boundaries and therefore fall short in enabling a holistic approach across multiple domains and scales. In this work, we demonstrate a new workflow for interdisciplinary data acquisition and integration, focusing on terraced vineyards in Tuscany, Italy. We used multi-modal data acquisition and performed data integration via a voxelised point cloud that we term a composite voxel model. The latter facilitates a multi-domain and multi-scale data-integrated approach for advancing the discovery and recovery of land knowledge. This approach enables integration, correlation and analysis of data pertaining to different domains and scales in a single data structure.
KW  - photogrammetry
KW  - thermography
KW  - point cloud
KW  - geospatial analysis
KW  - composite voxel model
KW  - environmental performance
KW  - terraced vineyards
DO  - 10.3390/rs13173483
ER  -
TY  - EJOU
AU  - Kalyani, Yogeswaranathan
AU  - Collier, Rem
TI  - A Systematic Survey on the Role of Cloud, Fog, and Edge Computing Combination in Smart Agriculture
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 17
SN  - 1424-8220

AB  - Cloud Computing is a well-established paradigm for building service-centric systems. However, ultra-low latency, high bandwidth, security, and real-time analytics are limitations in Cloud Computing when analysing and providing results for a large amount of data. Fog and Edge Computing offer solutions to the limitations of Cloud Computing. The number of agricultural domain applications that use the combination of Cloud, Fog, and Edge is increasing in the last few decades. This article aims to provide a systematic literature review of current works that have been done in Cloud, Fog, and Edge Computing applications in the smart agriculture domain between 2015 and up-to-date. The key objective of this review is to identify all relevant research on new computing paradigms with smart agriculture and propose a new architecture model with the combinations of Cloud–Fog–Edge. Furthermore, it also analyses and examines the agricultural application domains, research approaches, and the application of used combinations. Moreover, this survey discusses the components used in the architecture models and briefly explores the communication protocols used to interact from one layer to another. Finally, the challenges of smart agriculture and future research directions are briefly pointed out in this article.
KW  - cloud
KW  - fog
KW  - edge
KW  - smart agriculture
DO  - 10.3390/s21175922
ER  -
TY  - EJOU
AU  - Vrochidou, Eleni
AU  - Bazinas, Christos
AU  - Manios, Michail
AU  - Papakostas, George A.
AU  - Pachidis, Theodore P.
AU  - Kaburlasos, Vassilis G.
TI  - Machine Vision for Ripeness Estimation in Viticulture Automation
T2  - Horticulturae

PY  - 2021
VL  - 7
IS  - 9
SN  - 2311-7524

AB  - Ripeness estimation of fruits and vegetables is a key factor for the optimization of field management and the harvesting of the desired product quality. Typical ripeness estimation involves multiple manual samplings before harvest followed by chemical analyses. Machine vision has paved the way for agricultural automation by introducing quicker, cost-effective, and non-destructive methods. This work comprehensively surveys the most recent applications of machine vision techniques for ripeness estimation. Due to the broad area of machine vision applications in agriculture, this review is limited only to the most recent techniques related to grapes. The aim of this work is to provide an overview of the state-of-the-art algorithms by covering a wide range of applications. The potential of current machine vision techniques for specific viticulture applications is also analyzed. Problems, limitations of each technique, and future trends are discussed. Moreover, the integration of machine vision algorithms in grape harvesting robots for real-time in-field maturity assessment is additionally examined.
KW  - machine vision
KW  - grape ripeness estimation
KW  - image analysis
KW  - precision agriculture
KW  - agrobots
KW  - harvesting robot
DO  - 10.3390/horticulturae7090282
ER  -
TY  - EJOU
AU  - Mohammadi, Masoud
AU  - Rashidi, Maria
AU  - Mousavi, Vahid
AU  - Karami, Ali
AU  - Yu, Yang
AU  - Samali, Bijan
TI  - Quality Evaluation of Digital Twins Generated Based on UAV Photogrammetry and TLS: Bridge Case Study
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 17
SN  - 2072-4292

AB  - In the current modern era of information and technology, emerging remote advancements have been widely established for detailed virtual inspections and assessments of infrastructure assets, especially bridges. These technologies are capable of creating an accurate digital representation of the existing assets, commonly known as the digital twins. Digital twins are suitable alternatives to in-person and on-site based assessments that can provide safer, cheaper, more reliable, and less distributive bridge inspections. In the case of bridge monitoring, Unmanned Aerial Vehicle (UAV) photogrammetry and Terrestrial Laser Scanning (TLS) are among the most common advanced technologies that hold the potential to provide qualitative digital models; however, the research is still lacking a reliable methodology to evaluate the generated point clouds in terms of quality and geometric accuracy for a bridge size case study. Therefore, this paper aims to provide a comprehensive methodology along with a thorough bridge case study to evaluate two digital point clouds developed from an existing Australian heritage bridge via both UAV-based photogrammetry and TLS. In this regard, a range of proposed approaches were employed to compare point clouds in terms of points’ distribution, level of outlier noise, data completeness, surface deviation, and geometric accuracy. The comparative results of this case study not only proved the capability and applicability of the proposed methodology and approaches in evaluating these two voluminous point clouds, but they also exhibited a higher level of point density and more acceptable agreements with as-is measurements in TLS-based point clouds subjected to the implementation of a precise data capture and a 3D reconstruction model.
KW  - digital twin
KW  - quality evaluation
KW  - geometric accuracy
KW  - point cloud
KW  - UAV-based photogrammetry
KW  - terrestrial laser scanning (TLS)
KW  - bridge inspection
DO  - 10.3390/rs13173499
ER  -
TY  - EJOU
AU  - Fuentes, Sigfredo
AU  - Tongson, Eden
AU  - Unnithan, Ranjith R.
AU  - Gonzalez Viejo, Claudia
TI  - Early Detection of Aphid Infestation and Insect-Plant Interaction Assessment in Wheat Using a Low-Cost Electronic Nose (E-Nose), Near-Infrared Spectroscopy and Machine Learning Modeling
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 17
SN  - 1424-8220

AB  - Advances in early insect detection have been reported using digital technologies through camera systems, sensor networks, and remote sensing coupled with machine learning (ML) modeling. However, up to date, there is no cost-effective system to monitor insect presence accurately and insect-plant interactions. This paper presents results on the implementation of near-infrared spectroscopy (NIR) and a low-cost electronic nose (e-nose) coupled with machine learning. Several artificial neural network (ANN) models were developed based on classification to detect the level of infestation and regression to predict insect numbers for both e-nose and NIR inputs, and plant physiological response based on e-nose to predict photosynthesis rate (A), transpiration (E) and stomatal conductance (gs). Results showed high accuracy for classification models ranging within 96.5–99.3% for NIR and between 94.2–99.2% using e-nose data as inputs. For regression models, high correlation coefficients were obtained for physiological parameters (gs, E and A) using e-nose data from all samples as inputs (R = 0.86) and R = 0.94 considering only control plants (no insect presence). Finally, R = 0.97 for NIR and R = 0.99 for e-nose data as inputs were obtained to predict number of insects. Performances for all models developed showed no signs of overfitting. In this paper, a field-based system using unmanned aerial vehicles with the e-nose as payload was proposed and described for deployment of ML models to aid growers in pest management practices.
KW  - remote sensing
KW  - volatile compounds
KW  - artificial neural networks
KW  - photosynthesis modeling
KW  - plant water status modeling
DO  - 10.3390/s21175948
ER  -
TY  - EJOU
AU  - Arredondo-Méndez, Víctor H.
AU  - Para-González, Lorena
AU  - Mascaraque-Ramírez, Carlos
AU  - Domínguez, Manuel
TI  - The 4.0 Industry Technologies and Their Impact in the Continuous Improvement and the Organizational Results: An Empirical Approach
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 17
SN  - 2071-1050

AB  - This study analyses the relationships between the technologies of Industry 4.0, continuous improvement, and the business results. To carry out this study, 109 questionnaires to companies of different sectors were collected, but an indispensable condition to take into account was the fact that these companies develop themselves their logistics management. The analysis of the results obtained through the Partial Least Squares (PLS) methodology argues that there is a positive relationship between 4.0 Industry and continuous improvement processes, as well as between continuous improvement processes and organizational results, although it cannot be concluded that a direct relationship between 4.0 Industry and organizational results exists, which means that there are other variables, such as continuous improvement, mediating between them. With this work, there is already an accredited reference of the relationship, which has been verified to exist, between the Industry 4.0, the continuous improvement, and the business results.
KW  - 4.0 Industry
KW  - continuous improvement
KW  - organizational results
KW  - partial least squares
DO  - 10.3390/su13179965
ER  -
TY  - EJOU
AU  - Iqbal, Irfan A.
AU  - Osborn, Jon
AU  - Stone, Christine
AU  - Lucieer, Arko
TI  - A Comparison of ALS and Dense Photogrammetric Point Clouds for Individual Tree Detection in Radiata Pine Plantations
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 17
SN  - 2072-4292

AB  - Digital aerial photogrammetry (DAP) has emerged as a potentially cost-effective alternative to airborne laser scanning (ALS) for forest inventory methods that employ point cloud data. Forest inventory derived from DAP using area-based methods has been shown to achieve accuracy similar to that of ALS data. At the tree level, individual tree detection (ITD) algorithms have been developed to detect and/or delineate individual trees either from ALS point cloud data or from ALS- or DAP-based canopy height models. An examination of the application of ITDs to DAP-based point clouds has not yet been reported. In this research, we evaluate the suitability of DAP-based point clouds for individual tree detection in the Pinus radiata plantation. Two ITD algorithms designed to work with point cloud data are applied to dense point clouds generated from small- and medium-format photography and to an ALS point cloud. Performance of the two ITD algorithms, the influence of stand structure on tree detection rates, and the relationship between tree detection rates and canopy structural metrics are investigated. Overall, we show that there is a good agreement between ALS- and DAP-based ITD results (proportion of false negatives for ALS, SFP, and MFP was always lower than 29.6%, 25.3%, and 28.6%, respectively, whereas, the proportion of false positives for ALS, SFP, and MFP was always lower than 39.4%, 30.7%, and 33.7%, respectively). Differences between small- and medium-format DAP results were minor (for SFP and MFP, differences between recall, precision, and F-score were always less than 0.08, 0.03, and 0.05, respectively), suggesting that DAP point cloud data is robust for ITD. Our results show that among all the canopy structural metrics, the number of trees per hectare has the greatest influence on the tree detection rates.
KW  - forest inventory
KW  - Pinus radiata plantation
KW  - individual tree detection
KW  - airborne laser scanning
KW  - photogrammetry
KW  - digital aerial photography
KW  - small-format photography
KW  - medium-format photography
KW  - image point cloud
DO  - 10.3390/rs13173536
ER  -
TY  - EJOU
AU  - Du, Chunyu
AU  - Fan, Wenyi
AU  - Ma, Ye
AU  - Jin, Hung-Il
AU  - Zhen, Zhen
TI  - The Effect of Synergistic Approaches of Features and Ensemble Learning Algorithms on Aboveground Biomass Estimation of Natural Secondary Forests Based on ALS and Landsat 8
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 17
SN  - 1424-8220

AB  - Although the combination of Airborne Laser Scanning (ALS) data and optical imagery and machine learning algorithms were proved to improve the estimation of aboveground biomass (AGB), the synergistic approaches of different data and ensemble learning algorithms have not been fully investigated, especially for natural secondary forests (NSFs) with complex structures. This study aimed to explore the effects of the two factors on AGB estimation of NSFs based on ALS data and Landsat 8 imagery. The synergistic method of extracting novel features (i.e., COLI1 and COLI2) using optimal Landsat 8 features and the best-performing ALS feature (i.e., elevation mean) yielded higher accuracy of AGB estimation than either optical-only or ALS-only features. However, both of them failed to improve the accuracy compared to the simple combination of the untransformed features that generated them. The convolutional neural networks (CNN) model was much superior to other classic machine learning algorithms no matter of features. The stacked generalization (SG) algorithms, a kind of ensemble learning algorithms, greatly improved the accuracies compared to the corresponding base model, and the SG with the CNN meta-model performed best. This study provides technical support for a wall-to-wall AGB mapping of NSFs of northeastern China using efficient features and algorithms.
KW  - ensemble learning
KW  - machine learning
KW  - feature extraction
KW  - AGB
KW  - NSFs
DO  - 10.3390/s21175974
ER  -
TY  - EJOU
AU  - Resop, Jonathan P.
AU  - Lehmann, Laura
AU  - Hession, W. C.
TI  - Quantifying the Spatial Variability of Annual and Seasonal Changes in Riverscape Vegetation Using Drone Laser Scanning
T2  - Drones

PY  - 2021
VL  - 5
IS  - 3
SN  - 2504-446X

AB  - Riverscapes are complex ecosystems consisting of dynamic processes influenced by spatially heterogeneous physical features. A critical component of riverscapes is vegetation in the stream channel and floodplain, which influences flooding and provides habitat. Riverscape vegetation can be highly variable in size and structure, including wetland plants, grasses, shrubs, and trees. This vegetation variability is difficult to precisely measure over large extents with traditional surveying tools. Drone laser scanning (DLS), or UAV-based lidar, has shown potential for measuring topography and vegetation over large extents at a high resolution but has yet to be used to quantify both the temporal and spatial variability of riverscape vegetation. Scans were performed on a reach of Stroubles Creek in Blacksburg, VA, USA six times between 2017 and 2019. Change was calculated both annually and seasonally over the two-year period. Metrics were derived from the lidar scans to represent different aspects of riverscape vegetation: height, roughness, and density. Vegetation was classified as scrub or tree based on the height above ground and 604 trees were manually identified in the riverscape, which grew on average by 0.74 m annually. Trees had greater annual growth and scrub had greater seasonal variability. Height and roughness were better measures of annual growth and density was a better measure of seasonal variability. The results demonstrate the advantage of repeat surveys with high-resolution DLS for detecting seasonal variability in the riverscape environment, including the growth and decay of floodplain vegetation, which is critical information for various hydraulic and ecological applications.
KW  - UAVs
KW  - lidar
KW  - streams
KW  - canopy height
KW  - roughness
KW  - vegetation density
KW  - change detection
DO  - 10.3390/drones5030091
ER  -
TY  - EJOU
AU  - Koeva, Mila
AU  - Gasuku, Oscar
AU  - Lengoiboni, Monica
AU  - Asiama, Kwabena
AU  - Bennett, Rohan M.
AU  - Potel, Jossam
AU  - Zevenbergen, Jaap
TI  - Remote Sensing for Property Valuation: A Data Source Comparison in Support of Fair Land Taxation in Rwanda
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 18
SN  - 2072-4292

AB  - Remotely sensed data is increasingly applied across many domains, including fit-for-purpose land administration (FFPLA), where the focus is on fast, affordable, and accurate property information collection. Property valuation, as one of the main functions of land administration systems, is influenced by locational, physical, legal, and economic factors. Despite the importance of property valuation to economic development, there are often no standardized rules or strict data requirements for property valuation for taxation in developing contexts, such as Rwanda. This study aims at assessing different remote sensing data in support of developing a new approach for property valuation for taxation in Rwanda; one that aligns with the FFPLA philosophy. Three different remote sensing technologies, (i) aerial images acquired with a digital camera, (ii) WorldView2 satellite images, and (iii) unmanned aerial vehicle (UAV) images obtained with a DJI Phantom 2 Vision Plus quadcopter, are compared and analyzed in terms of their fitness to fulfil the requirements for valuation for taxation purposes. Quantitative and qualitative methods are applied for the comparative analysis. Prior to the field visit, the fundamental concepts of property valuation for taxation and remote sensing were reviewed. In the field, reference data using high precision GNSS (Leica) was collected and used for quantitative assessment. Primary data was further collected via semi-structured interviews and focus group discussions. The results show that UAVs have the highest potential for collecting data to support property valuation for taxation. The main reasons are the prime need for accurate-enough and up-to-date information. The comparison of the different remote sensing techniques and the provided new approach can support land valuers and professionals in the field in bottom-up activities following the FFPLA principles and maintaining the temporal quality of data needed for fair taxation.
KW  - property valuation
KW  - property taxation
KW  - remote sensing
KW  - land
KW  - UAV
DO  - 10.3390/rs13183563
ER  -
TY  - EJOU
AU  - Roslim, Muhammad H.
AU  - Juraimi, Abdul S.
AU  - Che’Ya, Nik N.
AU  - Sulaiman, Nursyazyla
AU  - Manaf, Muhammad N.
AU  - Ramli, Zaid
AU  - Motmainna, Mst.
TI  - Using Remote Sensing and an Unmanned Aerial System for Weed Management in Agricultural Crops: A Review
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 9
SN  - 2073-4395

AB  - Weeds are unwanted plants that can reduce crop yields by competing for water, nutrients, light, space, and carbon dioxide, which need to be controlled to meet future food production requirements. The integration of drones, artificial intelligence, and various sensors, which include hyperspectral, multi-spectral, and RGB (red-green-blue), ensure the possibility of a better outcome in managing weed problems. Most of the major or minor challenges caused by weed infestation can be faced by implementing remote sensing systems in various agricultural tasks. It is a multi-disciplinary science that includes spectroscopy, optics, computer, photography, satellite launching, electronics, communication, and several other fields. Future challenges, including food security, sustainability, supply and demand, climate change, and herbicide resistance, can also be overcome by those technologies based on machine learning approaches. This review provides an overview of the potential and practical use of unmanned aerial vehicle and remote sensing techniques in weed management practices and discusses how they overcome future challenges.
KW  - weeds
KW  - artificial intelligence
KW  - hyperspectral
KW  - multi-spectral
KW  - weeds management
DO  - 10.3390/agronomy11091809
ER  -
TY  - EJOU
AU  - Xia, Lang
AU  - Zhang, Ruirui
AU  - Chen, Liping
AU  - Li, Longlong
AU  - Yi, Tongchuan
AU  - Wen, Yao
AU  - Ding, Chenchen
AU  - Xie, Chunchun
TI  - Evaluation of Deep Learning Segmentation Models for Detection of Pine Wilt Disease in Unmanned Aerial Vehicle Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 18
SN  - 2072-4292

AB  - Pine wilt disease (PWD) is a serious threat to pine forests. Combining unmanned aerial vehicle (UAV) images and deep learning (DL) techniques to identify infected pines is the most efficient method to determine the potential spread of PWD over a large area. In particular, image segmentation using DL obtains the detailed shape and size of infected pines to assess the disease’s degree of damage. However, the performance of such segmentation models has not been thoroughly studied. We used a fixed-wing UAV to collect images from a pine forest in Laoshan, Qingdao, China, and conducted a ground survey to collect samples of infected pines and construct prior knowledge to interpret the images. Then, training and test sets were annotated on selected images, and we obtained 2352 samples of infected pines annotated over different backgrounds. Finally, high-performance DL models (e.g., fully convolutional networks for semantic segmentation, DeepLabv3+, and PSPNet) were trained and evaluated. The results demonstrated that focal loss provided a higher accuracy and a finer boundary than Dice loss, with the average intersection over union (IoU) for all models increasing from 0.656 to 0.701. From the evaluated models, DeepLLabv3+ achieved the highest IoU and an F1 score of 0.720 and 0.832, respectively. Also, an atrous spatial pyramid pooling module encoded multiscale context information, and the encoder–decoder architecture recovered location/spatial information, being the best architecture for segmenting trees infected by the PWD. Furthermore, segmentation accuracy did not improve as the depth of the backbone network increased, and neither ResNet34 nor ResNet50 was the appropriate backbone for most segmentation models.
KW  - deep learning
KW  - image segmentation
KW  - pine wilt disease
KW  - infected pine DeepLabv3+
KW  - focal loss
DO  - 10.3390/rs13183594
ER  -
TY  - EJOU
AU  - Zdziebko, Paweł
AU  - Holak, Krzysztof
TI  - Synthetic Image Generation Using the Finite Element Method and Blender Graphics Program for Modeling of Vision-Based Measurement Systems
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 18
SN  - 1424-8220

AB  - Computer vision is a frequently used approach in static and dynamic measurements of various mechanical structures. Sometimes, however, conducting a large number of experiments is time-consuming and may require significant financial and human resources. On the contrary, the authors propose a simulation approach for performing experiments to synthetically generate vision data. Synthetic images of mechanical structures subjected to loads are generated in the following way. The finite element method is adopted to compute deformations of the studied structure, and next, the Blender graphics program is used to render images presenting that structure. As a result of the proposed approach, it is possible to obtain synthetic images that reliably reflect static and dynamic experiments. This paper presents the results of the application of the proposed approach in the analysis of a complex-shaped structure for which experimental validation was carried out. In addition, the second example of the process of 3D reconstruction of the examined structure (in a multicamera system) is provided. The results for the structure with damage (cantilever beam) are also presented. The obtained results allow concluding that the proposed approach reliably imitates the images captured during real experiments. In addition, the method can become a tool supporting the vision system configuration process before conducting final experimental research.
KW  - image-based measurement
KW  - vision sensor modeling
KW  - vision system simulation
KW  - image-based reconstruction
KW  - finite element method
KW  - physics-based computer graphics
DO  - 10.3390/s21186046
ER  -
TY  - EJOU
AU  - Lytridis, Chris
AU  - Kaburlasos, Vassilis G.
AU  - Pachidis, Theodore
AU  - Manios, Michalis
AU  - Vrochidou, Eleni
AU  - Kalampokas, Theofanis
AU  - Chatzistamatis, Stamatis
TI  - An Overview of Cooperative Robotics in Agriculture
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 9
SN  - 2073-4395

AB  - Agricultural robotics has been a popular subject in recent years from an academic as well as a commercial point of view. This is because agricultural robotics addresses critical issues such as seasonal shortages in manual labor, e.g., during harvest, as well as the increasing concern regarding environmentally friendly practices. On one hand, several individual agricultural robots have already been developed for specific tasks (e.g., for monitoring, spraying, harvesting, transport, etc.) with varying degrees of effectiveness. On the other hand, the use of cooperative teams of agricultural robots in farming tasks is not as widespread; yet, it is an emerging trend. This paper presents a comprehensive overview of the work carried out so far in the area of cooperative agricultural robotics and identifies the state-of-the-art. This paper also outlines challenges to be addressed in fully automating agricultural production; the latter is promising for sustaining an increasingly vast human population, especially in cases of pandemics such as the recent COVID-19 pandemic.
KW  - agricultural robots
KW  - agriculture 4.0/5.0
KW  - cooperative robots
KW  - farming automation
DO  - 10.3390/agronomy11091818
ER  -
TY  - EJOU
AU  - Fourlas, George K.
AU  - Karras, George C.
TI  - A Survey on Fault Diagnosis and Fault-Tolerant Control Methods for Unmanned Aerial Vehicles
T2  - Machines

PY  - 2021
VL  - 9
IS  - 9
SN  - 2075-1702

AB  - The continuous evolution of modern technology has led to the creation of increasingly complex and advanced systems. This has been also reflected in the technology of Unmanned Aerial Vehicles (UAVs), where the growing demand for more reliable performance necessitates the development of sophisticated techniques that provide fault diagnosis and fault tolerance in a timely and accurate manner. Typically, a UAV consists of three types of subsystems: actuators, main structure and sensors. Therefore, a fault-monitoring system must be specifically designed to supervise and debug each of these subsystems, so that any faults can be addressed before they lead to disastrous consequences. In this survey article, we provide a detailed overview of recent advances and studies regarding fault diagnosis, Fault-Tolerant Control (FTC) and anomaly detection for UAVs. Concerning fault diagnosis, our interest is mainly focused on sensors and actuators, as these subsystems are mostly prone to faults, while their healthy operation usually ensures the smooth and reliable performance of the aerial vehicle.
KW  - fault diagnosis
KW  - fault tolerant control
KW  - anomaly detection
KW  - unmanned aerial vehicles
DO  - 10.3390/machines9090197
ER  -
TY  - EJOU
AU  - Jung, Sejung
AU  - Lee, Won H.
AU  - Han, Youkyung
TI  - Change Detection of Building Objects in High-Resolution Single-Sensor and Multi-Sensor Imagery Considering the Sun and Sensor’s Elevation and Azimuth Angles
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 18
SN  - 2072-4292

AB  - Building change detection is a critical field for monitoring artificial structures using high-resolution multitemporal images. However, relief displacement depending on the azimuth and elevation angles of the sensor causes numerous false alarms and misdetections of building changes. Therefore, this study proposes an effective object-based building change detection method that considers azimuth and elevation angles of sensors in high-resolution images. To this end, segmentation images were generated using a multiresolution technique from high-resolution images after which object-based building detection was performed. For detecting building candidates, we calculated feature information that could describe building objects, such as rectangular fit, gray-level co-occurrence matrix (GLCM) homogeneity, and area. Final building detection was then performed considering the location relationship between building objects and their shadows using the Sun’s azimuth angle. Subsequently, building change detection of final building objects was performed based on three methods considering the relationship of the building object properties between the images. First, only overlaying objects between images were considered to detect changes. Second, the size difference between objects according to the sensor’s elevation angle was considered to detect the building changes. Third, the direction between objects according to the sensor’s azimuth angle was analyzed to identify the building changes. To confirm the effectiveness of the proposed object-based building change detection performance, two building density areas were selected as study sites. Site 1 was constructed using a single sensor of KOMPSAT-3 bitemporal images, whereas Site 2 consisted of multi-sensor images of KOMPSAT-3 and unmanned aerial vehicle (UAV). The results from both sites revealed that considering additional shadow information showed more accurate building detection than using feature information only. Furthermore, the results of the three object-based change detections were compared and analyzed according to the characteristics of the study area and the sensors. Accuracy of the proposed object-based change detection results was achieved over the existing building detection methods.
KW  - relief displacement
KW  - azimuth and elevation angles
KW  - object-based building change detection
KW  - feature information
DO  - 10.3390/rs13183660
ER  -
TY  - EJOU
AU  - Liu, Wenyao
AU  - Meng, Qingfeng
AU  - Li, Zhen
AU  - Hu, Xin
TI  - Applications of Computer Vision in Monitoring the Unsafe Behavior of Construction Workers: Current Status and Challenges
T2  - Buildings

PY  - 2021
VL  - 11
IS  - 9
SN  - 2075-5309

AB  - The unsafe behavior of construction workers is one of the main causes of safety accidents at construction sites. To reduce the incidence of construction accidents and improve the safety performance of construction projects, there is a need to identify risky factors by monitoring the behavior of construction workers. Computer vision (CV) technology, which is a powerful and automated tool used for extracting images and video information from construction sites, has been recognized and adopted as an effective construction site monitoring technology for the identification of risky factors resulting from the unsafe behavior of construction workers. In this article, we introduce the research background of this field and conduct a systematic statistical analysis of the relevant literature in this field through the bibliometric analysis method. Thereafter, we adopt a content-based analysis method to depict the historical explorations in the field. On this basis, the limitations and challenges in this field are identified, and future research directions are proposed. It is found that CV technology can effectively monitor the unsafe behaviors of construction workers. The research findings can enhance people’s understanding of construction safety management.
KW  - computer vision
KW  - construction workers
KW  - monitoring
KW  - unsafe behavior
KW  - literature review
DO  - 10.3390/buildings11090409
ER  -
TY  - EJOU
AU  - Liu, Shenzhou
AU  - Zeng, Wenzhi
AU  - Wu, Lifeng
AU  - Lei, Guoqing
AU  - Chen, Haorui
AU  - Gaiser, Thomas
AU  - Srivastava, Amit K.
TI  - Simulating the Leaf Area Index of Rice from Multispectral Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 18
SN  - 2072-4292

AB  - Accurate estimation of the leaf area index (LAI) is essential for crop growth simulations and agricultural management. This study conducted a field experiment with rice and measured the LAI in different rice growth periods. The multispectral bands (B) including red edge (RE, 730 nm ± 16 nm), near-infrared (NIR, 840 nm ± 26 nm), green (560 nm ± 16 nm), red (650 nm ± 16 nm), blue (450 nm ± 16 nm), and visible light (RGB) were also obtained by an unmanned aerial vehicle (UAV) with multispectral sensors (DJI-P4M, SZ DJI Technology Co., Ltd.). Based on the bands, five vegetation indexes (VI) including Green Normalized Difference Vegetation Index (GNDVI), Leaf Chlorophyll Index (LCI), Normalized Difference Red Edge Index (NDRE), Normalized Difference Vegetation Index (NDVI), and Optimization Soil-Adjusted Vegetation Index (OSAVI) were calculated. The semi-empirical model (SEM), the random forest model (RF), and the Extreme Gradient Boosting model (XGBoost) were used to estimate rice LAI based on multispectral bands, VIs, and their combinations, respectively. The results indicated that the GNDVI had the highest accuracy in the SEM (R2 = 0.78, RMSE = 0.77). For the single band, NIR had the highest accuracy in both RF (R2 = 0.73, RMSE = 0.98) and XGBoost (R2 = 0.77, RMSE = 0.88). Band combination of NIR + red improved the estimation accuracy in both RF (R2 = 0.87, RMSE = 0.65) and XGBoost (R2 = 0.88, RMSE = 0.63). NDRE and LCI were the first two single VIs for LAI estimation using both RF and XGBoost. However, putting more than one VI together could only increase the LAI estimation accuracy slightly. Meanwhile, the bands + VIs combinations could improve the accuracy in both RF and XGBoost. Our study recommended estimating rice LAI by a combination of red + NIR + OSAVI + NDVI + GNDVI + LCI + NDRE (2B + 5V) with XGBoost to obtain high accuracy and overcome the potential over-fitting issue (R2 = 0.91, RMSE = 0.54).
KW  - leaf area index (LAI)
KW  - rice
KW  - multispectral images
KW  - random forest (RF)
KW  - Extreme Gradient Boosting model (XGBoost)
DO  - 10.3390/rs13183663
ER  -
TY  - EJOU
AU  - Li, Wangbin
AU  - Sun, Kaimin
AU  - Du, Zhuotong
AU  - Hu, Xiuqing
AU  - Li, Wenzhuo
AU  - Wei, Jinjiang
AU  - Gao, Song
TI  - PCNet: Cloud Detection in FY-3D True-Color Imagery Using Multi-Scale Pyramid Contextual Information
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 18
SN  - 2072-4292

AB  - Cloud, one of the poor atmospheric conditions, significantly reduces the usability of optical remote-sensing data and hampers follow-up applications. Thus, the identification of cloud remains a priority for various remote-sensing activities, such as product retrieval, land-use/cover classification, object detection, and especially for change detection. However, the complexity of clouds themselves make it difficult to detect thin clouds and small isolated clouds. To accurately detect clouds in satellite imagery, we propose a novel neural network named the Pyramid Contextual Network (PCNet). Considering the limited applicability of a regular convolution kernel, we employed a Dilated Residual Block (DRB) to extend the receptive field of the network, which contains a dilated convolution and residual connection. To improve the detection ability for thin clouds, the proposed new model, pyramid contextual block (PCB), was used to generate global information at different scales. FengYun-3D MERSI-II remote-sensing images covering China with 14,165 × 24,659 pixels, acquired on 17 July 2019, are processed to conduct cloud-detection experiments. Experimental results show that the overall precision rates of the trained network reach 97.1% and the overall recall rates reach 93.2%, which performs better both in quantity and quality than U-Net, UNet++, UNet3+, PSPNet and DeepLabV3+.
KW  - cloud detection
KW  - FY-3D remote-sensing images
KW  - pyramid contextual
KW  - deep learning
DO  - 10.3390/rs13183670
ER  -
TY  - EJOU
AU  - Daranagama, Samitha
AU  - Witayangkurn, Apichon
TI  - Automatic Building Detection with Polygonizing and Attribute Extraction from High-Resolution Images
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 9
SN  - 2220-9964

AB  - Buildings can be introduced as a fundamental element for forming a city. Therefore, up-to-date building maps have become vital for many applications, including urban mapping and urban expansion analysis. With the development of deep learning, segmenting building footprints from high-resolution remote sensing imagery has become a subject of intense study. Here, a modified version of the U-Net architecture with a combination of pre- and post-processing techniques was developed to extract building footprints from high-resolution aerial imagery and unmanned aerial vehicle (UAV) imagery. Data pre-processing with the logarithmic correction image enhancing algorithm showed the most significant improvement in the building detection accuracy for aerial images; meanwhile, the CLAHE algorithm improved the most concerning UAV images. This study developed a post-processing technique using polygonizing and polygon smoothing called the Douglas–Peucker algorithm, which made the building output directly ready to use for different applications. The attribute information, land use data, and population count data were applied using two open datasets. In addition, the building area and perimeter of each building were calculated as geometric attributes.
KW  - deep learning
KW  - building extraction
KW  - UAV images
KW  - aerial images
KW  - semantic segmentation
KW  - transfer learning
KW  - polygonizing
KW  - polygon smoothing
KW  - attribute extraction
DO  - 10.3390/ijgi10090606
ER  -
TY  - EJOU
AU  - Krause, Johannes R.
AU  - Hinojosa-Corona, Alejandro
AU  - Gray, Andrew B.
AU  - Burke Watson, Elizabeth
TI  - Emerging Sensor Platforms Allow for Seagrass Extent Mapping in a Turbid Estuary and from the Meadow to Ecosystem Scale
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 18
SN  - 2072-4292

AB  - Seagrass meadows are globally important habitats, protecting shorelines, providing nursery areas for fish, and sequestering carbon. However, both anthropogenic and natural environmental stressors have led to a worldwide reduction seagrass habitats. For purposes of management and restoration, it is essential to produce accurate maps of seagrass meadows over a variety of spatial scales, resolutions, and at temporal frequencies ranging from months to years. Satellite remote sensing has been successfully employed to produce maps of seagrass in the past, but turbid waters and difficulty in obtaining low-tide scenes pose persistent challenges. This study builds on an increased availability of affordable high temporal frequency imaging platforms, using seasonal unmanned aerial vehicle (UAV) surveys of seagrass extent at the meadow scale, to inform machine learning classifications of satellite imagery of a 40 km2 bay. We find that object-based image analysis is suitable to detect seasonal trends in seagrass extent from UAV imagery and find that trends vary between individual meadows at our study site Bahía de San Quintín, Baja California, México, during our study period in 2019. We further suggest that compositing multiple satellite imagery classifications into a seagrass probability map allows for an estimation of seagrass extent in turbid waters and report that in 2019, seagrass covered 2324 ha of Bahía de San Quintín, indicating a recovery from losses reported for previous decades.
KW  - seagrass
KW  - unmanned aerial vehicle (UAV)
KW  - object-based image analysis
KW  - planet
KW  - machine learning
KW  - turbid
KW  - estuary
DO  - 10.3390/rs13183681
ER  -
TY  - EJOU
AU  - Oseland, Eric
AU  - Shannon, Kent
AU  - Zhou, Jianfeng
AU  - Fritschi, Felix
AU  - Bish, Mandy D.
AU  - Bradley, Kevin W.
TI  - Evaluating the Spectral Response and Yield of Soybean Following Exposure to Sublethal Rates of 2,4-D and Dicamba at Vegetative and Reproductive Growth Stages
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 18
SN  - 2072-4292

AB  - The commercialization of synthetic auxin-resistant crops and the commensurate increase in post-emergent auxin-mimic herbicide applications has resulted in millions of hectares of injury to sensitive soybeans in the United States since 2016. Visual yield loss estimations following auxin injury can be difficult. The goal of this research was to determine if spectral variations following auxin injury to soybean allow for more precise yield loss estimations. Identical field experiments were performed in 2018, 2019, and 2020 in Columbia, Missouri to compare the ability of established vegetative indices to differentiate between exposure levels of 2,4-D and dicamba in soybean and predict yield loss. Soybeans were planted at three timings for growth stage separation and were exposed to sublethal rates of 2,4-D and dicamba at the R2, R1, and V3 growth stages. A UAV-mounted multispectral sensor was flown over the trial 14 days after the herbicide treatments. The results of this research found that vegetative indices incorporating the red-edge wavelength were more consistent in estimating yield loss than indices comprised of only visible or NIR wavelengths. Yield loss estimations became difficult when soybean injury occurred during later reproductive stages when soybean biomass was increased. This research also determined that when injury occurs to soybean in vegetative growth stages late in the growing season there is a greater likelihood for yield loss to occur due to decreased time for recovery. The results of this research could provide direction for more objective and accurate evaluations of yield loss following synthetic auxin injury than what is currently available.
KW  - dicamba
KW  - 2,4-D
KW  - UAV
KW  - vegetative index
DO  - 10.3390/rs13183682
ER  -
TY  - EJOU
AU  - Wang, Mudan
AU  - Wang, Cynthia C.
AU  - Zlatanova, Sisi
AU  - Sepasgozar, Samad
AU  - Aleksandrov, Mitko
TI  - Onsite Quality Check for Installation of Prefabricated Wall Panels Using Laser Scanning
T2  - Buildings

PY  - 2021
VL  - 11
IS  - 9
SN  - 2075-5309

AB  - Prefabricated construction has gained increasing popularity to meet the needs of rapid city development in recent years. Installation quality check is a critical task in prefabricated construction, and currently mostly still carried out manually, which is slow and ineffective. To provide an efficient and practical quality check method to replace the current manual method, this paper elaborates on an approach for checking prefabricated wall panels using laser scanning. The approach is validated in an actual case study. A common laser scanner BLK 360 is adopted to collect onsite 3D scenes after panel installation. The point clouds collected are co-roistered, classified, and segmented. Geometric parameters such as angles and distances allow for determining whether the installation meets the quality requirement. The outcome is compared with the quality check results using the conventional manual method. The results show that the panels, which need rectification, are correctly identified by the proposed approach. The major contribution of this study is determining the set of segmentation parameters to be adopted in similar quality check-up procedures. A practical and efficient quality check process is also proposed and can be readily implemented for certain prefabricated elements in many construction cases.
KW  - prefabricated wall panel
KW  - installation quality check
KW  - laser scanning
KW  - 3D point cloud
KW  - segmentation
KW  - plane fitting
DO  - 10.3390/buildings11090412
ER  -
TY  - EJOU
AU  - Yang, Su
AU  - Hou, Miaole
AU  - Shaker, Ahmed
AU  - Li, Songnian
TI  - Modeling and Processing of Smart Point Clouds of Cultural Relics with Complex Geometries
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 9
SN  - 2220-9964

AB  - The digital documentation of cultural relics plays an important role in archiving, protection, and management. In the field of cultural heritage, three-dimensional (3D) point cloud data is effective at expressing complex geometric structures and geometric details on the surface of cultural relics, but lacks semantic information. To elaborate the geometric information of cultural relics and add meaningful semantic information, we propose a modeling and processing method of smart point clouds of cultural relics with complex geometries. An information modeling framework for complex geometric cultural relics was designed based on the concept of smart point clouds, in which 3D point cloud data are organized through the time dimension and different spatial scales indicating different geometric details. The proposed model allows smart point clouds or a subset to be linked with semantic information or related documents. As such, this novel information modeling framework can be used to describe rich semantic information and high-level details of geometry. The proposed information model not only expresses the complex geometric structure of the cultural relics and the geometric details on the surface, but also has rich semantic information, and can even be associated with documents. A case study of the Dazu Thousand-Hand Bodhisattva Statue, which is characterized by a variety of complex geometries, reveals that our proposed framework is capable of modeling and processing the statue with excellent applicability and expansibility. This work provides insights into the sustainable development of cultural heritage protection globally.
KW  - cultural heritage
KW  - point cloud
KW  - 3D model
KW  - information modeling
KW  - complex geometry
DO  - 10.3390/ijgi10090617
ER  -
TY  - EJOU
AU  - Joseph, Seena
AU  - Olugbara, Oludayo O.
TI  - Detecting Salient Image Objects Using Color Histogram Clustering for Region Granularity
T2  - Journal of Imaging

PY  - 2021
VL  - 7
IS  - 9
SN  - 2313-433X

AB  - Salient object detection represents a novel preprocessing stage of many practical image applications in the discipline of computer vision. Saliency detection is generally a complex process to copycat the human vision system in the processing of color images. It is a convoluted process because of the existence of countless properties inherent in color images that can hamper performance. Due to diversified color image properties, a method that is appropriate for one category of images may not necessarily be suitable for others. The selection of image abstraction is a decisive preprocessing step in saliency computation and region-based image abstraction has become popular because of its computational efficiency and robustness. However, the performances of the existing region-based salient object detection methods are extremely hooked on the selection of an optimal region granularity. The incorrect selection of region granularity is potentially prone to under- or over-segmentation of color images, which can lead to a non-uniform highlighting of salient objects. In this study, the method of color histogram clustering was utilized to automatically determine suitable homogenous regions in an image. Region saliency score was computed as a function of color contrast, contrast ratio, spatial feature, and center prior. Morphological operations were ultimately performed to eliminate the undesirable artifacts that may be present at the saliency detection stage. Thus, we have introduced a novel, simple, robust, and computationally efficient color histogram clustering method that agglutinates color contrast, contrast ratio, spatial feature, and center prior for detecting salient objects in color images. Experimental validation with different categories of images selected from eight benchmarked corpora has indicated that the proposed method outperforms 30 bottom-up non-deep learning and seven top-down deep learning salient object detection methods based on the standard performance metrics.
KW  - color contrast
KW  - contrast ratio
KW  - histogram clustering
KW  - region saliency
KW  - saliency detection
DO  - 10.3390/jimaging7090187
ER  -
TY  - EJOU
AU  - Abdollahi, Abolfazl
AU  - Pradhan, Biswajeet
AU  - Shukla, Nagesh
AU  - Chakraborty, Subrata
AU  - Alamri, Abdullah
TI  - Multi-Object Segmentation in Complex Urban Scenes from High-Resolution Remote Sensing Data
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 18
SN  - 2072-4292

AB  - Terrestrial features extraction, such as roads and buildings from aerial images using an automatic system, has many usages in an extensive range of fields, including disaster management, change detection, land cover assessment, and urban planning. This task is commonly tough because of complex scenes, such as urban scenes, where buildings and road objects are surrounded by shadows, vehicles, trees, etc., which appear in heterogeneous forms with lower inter-class and higher intra-class contrasts. Moreover, such extraction is time-consuming and expensive to perform by human specialists manually. Deep convolutional models have displayed considerable performance for feature segmentation from remote sensing data in the recent years. However, for the large and continuous area of obstructions, most of these techniques still cannot detect road and building well. Hence, this work’s principal goal is to introduce two novel deep convolutional models based on UNet family for multi-object segmentation, such as roads and buildings from aerial imagery. We focused on buildings and road networks because these objects constitute a huge part of the urban areas. The presented models are called multi-level context gating UNet (MCG-UNet) and bi-directional ConvLSTM UNet model (BCL-UNet). The proposed methods have the same advantages as the UNet model, the mechanism of densely connected convolutions, bi-directional ConvLSTM, and squeeze and excitation module to produce the segmentation maps with a high resolution and maintain the boundary information even under complicated backgrounds. Additionally, we implemented a basic efficient loss function called boundary-aware loss (BAL) that allowed a network to concentrate on hard semantic segmentation regions, such as overlapping areas, small objects, sophisticated objects, and boundaries of objects, and produce high-quality segmentation maps. The presented networks were tested on the Massachusetts building and road datasets. The MCG-UNet improved the average F1 accuracy by 1.85%, and 1.19% and 6.67% and 5.11% compared with UNet and BCL-UNet for road and building extraction, respectively. Additionally, the presented MCG-UNet and BCL-UNet networks were compared with other state-of-the-art deep learning-based networks, and the results proved the superiority of the networks in multi-object segmentation tasks.
KW  - building extraction
KW  - boundary-aware loss
KW  - deep learning
KW  - remote sensing
KW  - road extraction
DO  - 10.3390/rs13183710
ER  -
TY  - EJOU
AU  - Jamali, Ali
AU  - Mahdianpari, Masoud
TI  - A Cloud-Based Framework for Large-Scale Monitoring of Ocean Plastics Using Multi-Spectral Satellite Imagery and Generative Adversarial Network
T2  - Water

PY  - 2021
VL  - 13
IS  - 18
SN  - 2073-4441

AB  - Marine debris is considered a threat to the inhabitants, as well as the marine environments. Accumulation of marine debris, besides climate change factors, including warming water, sea-level rise, and changes in oceans’ chemistry, are causing the potential collapse of the marine environment’s health. Due to the increase of marine debris, including plastics in coastlines, ocean and sea surfaces, and even in deep ocean layers, there is a need for developing new advanced technology for the detection of large-sized marine pollution (with sizes larger than 1 m) using state-of-the-art remote sensing and machine learning tools. Therefore, we developed a cloud-based framework for large-scale marine pollution detection with the integration of Sentinel-2 satellite imagery and advanced machine learning tools on the Sentinel Hub cloud application programming interface (API). Moreover, we evaluated the performance of two shallow machine learning algorithms of random forest (RF) and support vector machine (SVM), as well as the deep learning method of the generative adversarial network-random forest (GAN-RF) for the detection of ocean plastics in the pilot site of Mytilene Island, Greece. Based on the obtained results, the shallow algorithms of RF and SVM achieved an overall accuracy of 88% and 84%, respectively, with available training data of plastic debris. The GAN-RF classifier improved the detection of ocean plastics of the RF method by 8%, achieving an overall accuracy of 96% by generating several synthetic ocean plastic samples.
KW  - ocean plastics
KW  - support vector machine
KW  - random forest
KW  - marine debris
KW  - marine pollution
KW  - Sentinel Hub
KW  - generative adversarial network
DO  - 10.3390/w13182553
ER  -
TY  - EJOU
AU  - Richardson, Galen
AU  - Leblanc, Sylvain G.
AU  - Lovitt, Julie
AU  - Rajaratnam, Krishan
AU  - Chen, Wenjun
TI  - Leveraging AI to Estimate Caribou Lichen in UAV Orthomosaics from Ground Photo Datasets
T2  - Drones

PY  - 2021
VL  - 5
IS  - 3
SN  - 2504-446X

AB  - Relating ground photographs to UAV orthomosaics is a key linkage required for accurate multi-scaled lichen mapping. Conventional methods of multi-scaled lichen mapping, such as random forest models and convolutional neural networks, heavily rely on pixel DN values for classification. However, the limited spectral range of ground photos requires additional characteristics to differentiate lichen from spectrally similar objects, such as bright logs. By applying a neural network to tiles of a UAV orthomosaics, additional characteristics, such as surface texture and spatial patterns, can be used for inferences. Our methodology used a neural network (UAV LiCNN) trained on ground photo mosaics to predict lichen in UAV orthomosaic tiles. The UAV LiCNN achieved mean user and producer accuracies of 85.84% and 92.93%, respectively, in the high lichen class across eight different orthomosaics. We compared the known lichen percentages found in 77 vegetation microplots with the predicted lichen percentage calculated from the UAV LiCNN, resulting in a R2 relationship of 0.6910. This research shows that AI models trained on ground photographs effectively classify lichen in UAV orthomosaics. Limiting factors include the misclassification of spectrally similar objects to lichen in the RGB bands and dark shadows cast by vegetation.
KW  - image classification
KW  - lichen mapping
KW  - orthomosaics
KW  - artificial intelligence
KW  - UAV
DO  - 10.3390/drones5030099
ER  -
TY  - EJOU
AU  - Li, Daoliang
AU  - Du, Ling
TI  - AUV Trajectory Tracking Models and Control Strategies: A Review
T2  - Journal of Marine Science and Engineering

PY  - 2021
VL  - 9
IS  - 9
SN  - 2077-1312

AB  - Autonomous underwater vehicles (AUVs) have been widely used to perform underwater tasks. Due to the environmental disturbances, underactuated problems, system constraints, and system coupling, AUV trajectory tracking control is challenging. Thus, further investigation of dynamic characteristics and trajectory tracking control methods of the AUV motion system will be of great importance to improve underwater task performance. An AUV controller must be able to cope with various challenges with the underwater vehicle, adaptively update the reference model, and overcome unexpected deviations. In order to identify modeling strategies and the best control practices, this paper presents an overview of the main factors of control-oriented models and control strategies for AUVs. In modeling, two fields are considered: (i) models that come from simplifications of Fossen’s equations; and (ii) system identification models. For each category, a brief description of the control-oriented modeling strategies is given. In the control field, three relevant aspects are considered: (i) significance of AUV trajectory tracking control, (ii) control strategies; and (iii) control performance. For each aspect, the most important features are explained. Furthermore, in the aspect of control strategies, mathematical modeling study and physical experiment study are introduced in detail. Finally, with the aim of establishing the acceptability of the reported modeling and control techniques, as well as challenges that remain open, a discussion and a case study are presented. The literature review shows the development of new control-oriented models, the research in the estimation of unknown inputs, and the development of more innovative control strategies for AUV trajectory tracking systems are still open problems that must be addressed in the short term.
KW  - autonomous underwater vehicle
KW  - trajectory tracking
KW  - modeling
KW  - control strategies
DO  - 10.3390/jmse9091020
ER  -
TY  - EJOU
AU  - Ahmed, Shara
AU  - Nicholson, Catherine E.
AU  - Muto, Paul
AU  - Perry, Justin J.
AU  - Dean, John R.
TI  - The Use of an Unmanned Aerial Vehicle for Tree Phenotyping Studies
T2  - Separations

PY  - 2021
VL  - 8
IS  - 9
SN  - 2297-8739

AB  - A strip of 20th-century landscape woodland planted alongside a 17th to mid-18th century ancient and semi-natural woodland (ASNW) was investigated by applied aerial spectroscopy using an unmanned aerial vehicle (UAV) with a multispectral image camera (MSI). A simple classification approach of normalized difference spectral index (NDSI), derived using principal component analysis (PCA), enabled the identification of the non-native trees within the 20th-century boundary. The tree species within this boundary, classified by NDSI, were further segmented by the machine learning segmentation method of k-means clustering. This combined innovative approach has enabled the identification of multiple tree species in the 20th-century boundary. Phenotyping of trees at canopy level using the UAV with MSI, across 8052 m2, identified black pine (23%), Norway maple (19%), Scots pine (12%), and sycamore (19%) as well as native trees (oak and silver birch, 27%). This derived data was corroborated by field identification at ground-level, over an area of 6785 m2, that confirmed the presence of black pine (26%), Norway maple (30%), Scots pine (10%), and sycamore (14%) as well as other trees (oak and silver birch, 20%). The benefits of using a UAV, with an MSI camera, for monitoring tree boundaries next to a new housing development are demonstrated.
KW  - Unmanned aerial vehicles
KW  - ancient woodland
KW  - invasive species identification
KW  - normalized difference spectral index (NDSI)
KW  - k-means clustering
DO  - 10.3390/separations8090160
ER  -
TY  - EJOU
AU  - Benbouzid, Mohamed
AU  - Berghout, Tarek
AU  - Sarma, Nur
AU  - Djurović, Siniša
AU  - Wu, Yueqi
AU  - Ma, Xiandong
TI  - Intelligent Condition Monitoring of Wind Power Systems: State of the Art Review
T2  - Energies

PY  - 2021
VL  - 14
IS  - 18
SN  - 1996-1073

AB  - Modern wind turbines operate in continuously transient conditions, with varying speed, torque, and power based on the stochastic nature of the wind resource. This variability affects not only the operational performance of the wind power system, but can also affect its integrity under service conditions. Condition monitoring continues to play an important role in achieving reliable and economic operation of wind turbines. This paper reviews the current advances in wind turbine condition monitoring, ranging from conventional condition monitoring and signal processing tools to machine-learning-based condition monitoring and usage of big data mining for predictive maintenance. A systematic review is presented of signal-based and data-driven modeling methodologies using intelligent and machine learning approaches, with the view to providing a critical evaluation of the recent developments in this area, and their applications in diagnosis, prognosis, health assessment, and predictive maintenance of wind turbines and farms.
KW  - wind turbines
KW  - condition monitoring
KW  - diagnosis
KW  - prognosis
KW  - machine learning
KW  - data mining
KW  - health management
KW  - operations and maintenance
DO  - 10.3390/en14185967
ER  -
TY  - EJOU
AU  - Zhang, He
AU  - Bauters, Marijn
AU  - Boeckx, Pascal
AU  - Van Oost, Kristof
TI  - Mapping Canopy Heights in Dense Tropical Forests Using Low-Cost UAV-Derived Photogrammetric Point Clouds and Machine Learning Approaches
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 18
SN  - 2072-4292

AB  - Tropical forests are a key component of the global carbon cycle and climate change mitigation. Field- or LiDAR-based approaches enable reliable measurements of the structure and above-ground biomass (AGB) of tropical forests. Data derived from digital aerial photogrammetry (DAP) on the unmanned aerial vehicle (UAV) platform offer several advantages over field- and LiDAR-based approaches in terms of scale and efficiency, and DAP has been presented as a viable and economical alternative in boreal or deciduous forests. However, detecting with DAP the ground in dense tropical forests, which is required for the estimation of canopy height, is currently considered highly challenging. To address this issue, we present a generally applicable method that is based on machine learning methods to identify the forest floor in DAP-derived point clouds of dense tropical forests. We capitalize on the DAP-derived high-resolution vertical forest structure to inform ground detection. We conducted UAV-DAP surveys combined with field inventories in the tropical forest of the Congo Basin. Using airborne LiDAR (ALS) for ground truthing, we present a canopy height model (CHM) generation workflow that constitutes the detection, classification and interpolation of ground points using a combination of local minima filters, supervised machine learning algorithms and TIN densification for classifying ground points using spectral and geometrical features from the UAV-based 3D data. We demonstrate that our DAP-based method provides estimates of tree heights that are identical to LiDAR-based approaches (conservatively estimated NSE = 0.88, RMSE = 1.6 m). An external validation shows that our method is capable of providing accurate and precise estimates of tree heights and AGB in dense tropical forests (DAP vs. field inventories of old forest: r2 = 0.913, RMSE = 31.93 Mg ha−1). Overall, this study demonstrates that the application of cheap and easily deployable UAV-DAP platforms can be deployed without expert knowledge to generate biophysical information and advance the study and monitoring of dense tropical forests.
KW  - UAV
KW  - DAP
KW  - SfM
KW  - LiDAR
KW  - digital terrain model
KW  - tropical forest
KW  - biomass
DO  - 10.3390/rs13183777
ER  -
TY  - EJOU
AU  - Fraser, Benjamin T.
AU  - Congalton, Russell G.
TI  - A Comparison of Methods for Determining Forest Composition from High-Spatial-Resolution Remotely Sensed Imagery
T2  - Forests

PY  - 2021
VL  - 12
IS  - 9
SN  - 1999-4907

AB  - Remotely sensed imagery has been used to support forest ecology and management for decades. In modern times, the propagation of high-spatial-resolution image analysis techniques and automated workflows have further strengthened this synergy, leading to the inquiry into more complex, local-scale, ecosystem characteristics. To appropriately inform decisions in forestry ecology and management, the most reliable and efficient methods should be adopted. For this reason, our research compares visual interpretation to digital (automated) processing for forest plot composition and individual tree identification. During this investigation, we qualitatively and quantitatively evaluated the process of classifying species groups within complex, mixed-species forests in New England. This analysis included a comparison of three high-resolution remotely sensed imagery sources: Google Earth, National Agriculture Imagery Program (NAIP) imagery, and unmanned aerial system (UAS) imagery. We discovered that, although the level of detail afforded by the UAS imagery spatial resolution (3.02 cm average pixel size) improved the visual interpretation results (7.87–9.59%), the highest thematic accuracy was still only 54.44% for the generalized composition groups. Our qualitative analysis of the uncertainty for visually interpreting different composition classes revealed the persistence of mislabeled hardwood compositions (including an early successional class) and an inability to consistently differentiate between ‘pure’ and ‘mixed’ stands. The results of digitally classifying the same forest compositions produced a higher level of accuracy for both detecting individual trees (93.9%) and labeling them (59.62–70.48%) using machine learning algorithms including classification and regression trees, random forest, and support vector machines. These results indicate that digital, automated, classification produced an increase in overall accuracy of 16.04% over visual interpretation for generalized forest composition classes. Other studies, which incorporate multitemporal, multispectral, or data fusion approaches provide evidence for further widening this gap. Further refinement of the methods for individual tree detection, delineation, and classification should be developed for structurally and compositionally complex forests to supplement the critical deficiency in local-scale forest information around the world.
KW  - visual interpretation
KW  - forest composition
KW  - digital classification
KW  - unmanned aerial systems
KW  - unmanned aerial vehicles
KW  - precision forestry
KW  - random forests
KW  - support vector machines
DO  - 10.3390/f12091290
ER  -
TY  - EJOU
AU  - Barber, Nastassia
AU  - Alvarado, Ernesto
AU  - Kane, Van R.
AU  - Mell, William E.
AU  - Moskal, L. M.
TI  - Estimating Fuel Moisture in Grasslands Using UAV-Mounted Infrared and Visible Light Sensors
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 19
SN  - 1424-8220

AB  - Predicting wildfire behavior is a complex task that has historically relied on empirical models. Physics-based fire models could improve predictions and have broad applicability, but these models require more detailed inputs, including spatially explicit estimates of fuel characteristics. One of the most critical of these characteristics is fuel moisture. Obtaining moisture measurements with traditional destructive sampling techniques can be prohibitively time-consuming and extremely limited in spatial resolution. This study seeks to assess how effectively moisture in grasses can be estimated using reflectance in six wavelengths in the visible and infrared ranges. One hundred twenty 1 m-square field samples were collected in a western Washington grassland as well as overhead imagery in six wavelengths for the same area. Predictive models of vegetation moisture using existing vegetation indices and components from principal component analysis of the wavelengths were generated and compared. The best model, a linear model based on principal components and biomass, showed modest predictive power (r² = 0.45). This model performed better for the plots with both dominant grass species pooled than it did for each species individually. The presence of this correlation, especially given the limited moisture range of this study, suggests that further research using samples across the entire fire season could potentially produce effective models for estimating moisture in this type of ecosystem using unmanned aerial vehicles, even when more than one major species of grass is present. This approach would be a fast and flexible approach compared to traditional moisture measurements.
KW  - unmanned aerial vehicle
KW  - fuel moisture content
KW  - wildfire
KW  - grassland
DO  - 10.3390/s21196350
ER  -
TY  - EJOU
AU  - Sanders, John T.
AU  - Jones, Eric A. L.
AU  - Austin, Robert
AU  - Roberson, Gary T.
AU  - Richardson, Robert J.
AU  - Everman, Wesley J.
TI  - Remote Sensing for Palmer Amaranth (Amaranthus palmeri S. Wats.) Detection in Soybean (Glycine max (L.) Merr.)
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 10
SN  - 2073-4395

AB  - Field studies were conducted in 2016 and 2017 to determine if multispectral imagery collected from an unmanned aerial vehicle (UAV) equipped with a five-band sensor could successfully identify Palmer amaranth (Amaranthus palmeri) infestations of various densities growing among soybeans (Glycine max [L.] Merr.). The multispectral sensor captures imagery from five wavebands: 475 (blue), 560 (green), 668 (red), 840 (near infrared [NIR]), and 717 nm (red-edge). Image analysis was performed to examine the spectral properties of discrete Palmer amaranth and soybean plants at various weed densities using these wavebands. Additionally, imagery was subjected to supervised classification to evaluate the usefulness of classification as a tool to differentiate the two species in a field setting. Date was a significant factor influencing the spectral reflectance values of the Palmer amaranth densities. The effects of altitude on reflectance were less clear and were dependent on band and density being evaluated. The near infrared (NIR) waveband offered the best resolution in separating Palmer amaranth densities. Spectral separability in the other wavebands was less defined, although low weed densities were consistently able to be discriminated from high densities. Palmer amaranth and soybean were found to be spectrally distinct regardless of imaging date, weed density, or waveband. Soybean exhibited overall lower reflectance intensity than Palmer amaranth across all wavebands. The reflectance of both species within blue, green, red, and red-edge wavebands declined as the season progressed, while reflectance in NIR increased. Near infrared and red-edge wavebands were shown to be the most useful for species discrimination and maintained their utility at most weed densities. Palmer amaranth weed densities were found to be spectrally distinct from one another in all wavebands, with greatest distinction when using the red, NIR and red-edge wavebands. Supervised classification in a two-class system was consistently able to discriminate between Palmer amaranth and soybean with at least 80% overall accuracy. The incorporation of a weed density component into these classifications introduced an error of 65% or greater into these classifications. Reducing the number of classes in a supervised classification system could improve the accuracy of discriminating between Palmer amaranth and soybean.
KW  - remote sensing
KW  - weed management
KW  - species discrimination
KW  - UAV
KW  - multispectral
DO  - 10.3390/agronomy11101909
ER  -
TY  - EJOU
AU  - Serrano, João
AU  - Shahidian, Shakib
AU  - Paixão, Luis
AU  - Marques da Silva, José
AU  - Morais, Tiago
AU  - Teixeira, Ricardo
AU  - Domingos, Tiago
TI  - Spatiotemporal Patterns of Pasture Quality Based on NDVI Time-Series in Mediterranean Montado Ecosystem
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - The evolution of dryland pasture quality is closely related to the seasonal and inter-annual variability characteristic of the Mediterranean climate. This variability introduces great unpredictability in the dynamic management of animal grazing. The aim of this study is to evaluate the potential of two complementary tools (satellite images, Sentinel-2 and proximal optical sensor, OptRx) for the calculation of the normalized difference vegetation index (NDVI), to monitor in a timely manner indicators of pasture quality (moisture content, crude protein, and neutral detergent fiber). In two consecutive years (2018/2019 and 2019/2020) these tools were evaluated in six fields representative of dryland pastures in the Alentejo region, in Portugal. The results show a significant correlation between pasture quality degradation index (PQDI) and NDVI measured by remote sensing (R2 = 0.82) and measured by proximal optical sensor (R2 = 0.83). These technological tools can potentially make an important contribution to decision making and to the management of livestock production. The complementarity of these two approaches makes it possible to overcome the limitations of satellite images that result (i) from the interference of clouds (which occurs frequently throughout the pasture vegetative cycle) and (ii) from the interference of tree canopy, an important layer of the Montado ecosystem. This work opens perspectives to explore new solutions in the field of Precision Agriculture technologies based on spectral reflectance to respond to the challenges of economic and environmental sustainability of extensive livestock production systems.
KW  - pasture quality degradation
KW  - Montado
KW  - remote sensing
KW  - proximal sensing
KW  - cloud effect
DO  - 10.3390/rs13193820
ER  -
TY  - EJOU
AU  - Tian, Anhong
AU  - Fu, Chengbiao
AU  - Yau, Her-Terng
AU  - Su, Xiao-Yi
AU  - Xiong, Heigang
TI  - Soil Salinization Level Monitoring and Classifying by Mixed Chaotic Systems
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - Soil salinization process is a complex non-linear dynamic evolution. To classify a system with this type of non-linear characteristic, this study proposed a mixed master/slave chaotic system based on Chua’s circuit and a fractional-order Chen-Lee chaotic system to classify soil salinization level. The subject is the soil in Xinjiang with different levels of human interference. A fractional-order Chen-Lee chaotic system was constructed, and the spectral signal processed by the Chua’s non-linear circuit was substituted into the master/slave chaotic system. The chaotic dynamic errors with different fractional orders were calculated. The comparative analysis showed that 0.1-order has the largest chaotic dynamic error change, which produced two distinct and divergent results. Thus, this study converted the chaotic dynamic errors of fractional 0.1-order into chaotic attractors to build an extension matter-element model. Finally, we compared the soil salt contents (SSC) from the laboratory chemical analysis with the results of the extension theory classification. The comparison showed that the combination of fractional order mixed master/slave chaotic system and extension theory has high classification accuracy for soil salinization level. The results of this system match the result of the chemical analysis. The classification accuracy of the calibration set data was 100%, and the classification accuracy of the validation set data was 90%. This method is the first use of the mixed master/slave chaotic system in this field and can satisfy certain soil salinization monitoring needs as well as promote the application of the chaotic system in soil salinization monitoring.
KW  - soil salinization degree classification
KW  - Chua’s chaotic circuit
KW  - Chen-Lee master/slave chaotic system
KW  - mixed fractional-order chaotic system
KW  - soil hyperspectral
DO  - 10.3390/rs13193819
ER  -
TY  - EJOU
AU  - Wen, Xiang
AU  - Li, Xing
AU  - Zhang, Ce
AU  - Han, Wenquan
AU  - Li, Erzhu
AU  - Liu, Wei
AU  - Zhang, Lianpeng
TI  - ME-Net: A Multi-Scale Erosion Network for Crisp Building Edge Detection from Very High Resolution Remote Sensing Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - The detection of building edges from very high resolution (VHR) remote sensing imagery is essential to various geo-related applications, including surveying and mapping, urban management, etc. Recently, the rapid development of deep convolutional neural networks (DCNNs) has achieved remarkable progress in edge detection; however, there has always been the problem of edge thickness due to the large receptive field of DCNNs. In this paper, we proposed a multi-scale erosion network (ME-Net) for building edge detection to crisp the building edge through two innovative approaches: (1) embedding an erosion module (EM) in the network to crisp the edge and (2) adding the Dice coefficient and local cross entropy of edge neighbors into the loss function to increase its sensitivity to the receptive field. In addition, a new metric, Ene, to measure the crispness of the predicted building edge was proposed. The experiment results show that ME-Net not only detects the clearest and crispest building edges, but also achieves the best OA of 98.75%, 95.00% and 95.51% on three building edge datasets, and exceeds other edge detection networks 3.17% and 0.44% at least in strict F1-score and Ene. In a word, the proposed ME-Net is an effective and practical approach for detecting crisp building edges from VHR remote sensing imagery.
KW  - building edge detection
KW  - deep convolutional neural network
KW  - erosion module
KW  - very high resolution remote sensing imagery
DO  - 10.3390/rs13193826
ER  -
TY  - EJOU
AU  - Deng, Hongjie
AU  - Ergu, Daji
AU  - Liu, Fangyao
AU  - Ma, Bo
AU  - Cai, Ying
TI  - An Embeddable Algorithm for Automatic Garbage Detection Based on Complex Marine Environment
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 19
SN  - 1424-8220

AB  - With the continuous development of artificial intelligence, embedding object detection algorithms into autonomous underwater detectors for marine garbage cleanup has become an emerging application area. Considering the complexity of the marine environment and the low resolution of the images taken by underwater detectors, this paper proposes an improved algorithm based on Mask R-CNN, with the aim of achieving high accuracy marine garbage detection and instance segmentation. First, the idea of dilated convolution is introduced in the Feature Pyramid Network to enhance feature extraction ability for small objects. Secondly, the spatial-channel attention mechanism is used to make features learn adaptively. It can effectively focus attention on detection objects. Third, the re-scoring branch is added to improve the accuracy of instance segmentation by scoring the predicted masks based on the method of Generalized Intersection over Union. Finally, we train the proposed algorithm in this paper on the Transcan dataset, evaluating its effectiveness by various metrics and comparing it with existing algorithms. The experimental results show that compared to the baseline provided by the Transcan dataset, the algorithm in this paper improves the mAP indexes on the two tasks of garbage detection and instance segmentation by 9.6 and 5.0, respectively, which significantly improves the algorithm performance. Thus, it can be better applied in the marine environment and achieve high precision object detection and instance segmentation.
KW  - deep learning
KW  - object detection
KW  - instance segmentation
KW  - marine ecology
KW  - the attentional mechanism
KW  - dilated convolution
DO  - 10.3390/s21196391
ER  -
TY  - EJOU
AU  - Pérez-Adán, Darian
AU  - Fresnedo, Óscar
AU  - González-Coma, José P.
AU  - Castedo, Luis
TI  - Intelligent Reflective Surfaces for Wireless Networks: An Overview of Applications, Approached Issues, and Open Problems
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 19
SN  - 2079-9292

AB  - An intelligent reflective surface (IRS) is a novel and revolutionizing communication technology destined to enable the control of the radio environment. An IRS is a real-time controllable reflectarray with a massive number of low-cost passive elements which introduce a phase shift to the incoming signals from the sources before the propagation towards the destination. This technology introduces the notion of a smart propagation environment with the aim of improving the system performance. In this paper, we provide a comprehensive literature overview on IRS technology, including its basic concepts and reconfiguration, as well as its design aspects and applications for wireless communication systems. We also study the performance metrics and the setups considered in recent publications related to IRS and provide suggestions of future research lines based on still unexplored use cases in the state-of-the-art.
KW  - intelligent reflective surfaces
KW  - smart propagation environments
KW  - IRS-aided wireless communication systems
DO  - 10.3390/electronics10192345
ER  -
TY  - EJOU
AU  - Neupane, Krishna
AU  - Baysal-Gurel, Fulya
TI  - Automatic Identification and Monitoring of Plant Diseases Using Unmanned Aerial Vehicles: A Review
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - Disease diagnosis is one of the major tasks for increasing food production in agriculture. Although precision agriculture (PA) takes less time and provides a more precise application of agricultural activities, the detection of disease using an Unmanned Aerial System (UAS) is a challenging task. Several Unmanned Aerial Vehicles (UAVs) and sensors have been used for this purpose. The UAVs’ platforms and their peripherals have their own limitations in accurately diagnosing plant diseases. Several types of image processing software are available for vignetting and orthorectification. The training and validation of datasets are important characteristics of data analysis. Currently, different algorithms and architectures of machine learning models are used to classify and detect plant diseases. These models help in image segmentation and feature extractions to interpret results. Researchers also use the values of vegetative indices, such as Normalized Difference Vegetative Index (NDVI), Crop Water Stress Index (CWSI), etc., acquired from different multispectral and hyperspectral sensors to fit into the statistical models to deliver results. There are still various drifts in the automatic detection of plant diseases as imaging sensors are limited by their own spectral bandwidth, resolution, background noise of the image, etc. The future of crop health monitoring using UAVs should include a gimble consisting of multiple sensors, large datasets for training and validation, the development of site-specific irradiance systems, and so on. This review briefly highlights the advantages of automatic detection of plant diseases to the growers.
KW  - UAS
KW  - UAVs
KW  - plant disease detection
KW  - plant monitoring
KW  - convolutional neural networks (CNNs)
KW  - deep learning
KW  - machine learning
DO  - 10.3390/rs13193841
ER  -
TY  - EJOU
AU  - Czarnecki, Joby M. Prince
AU  - Samiappan, Sathishkumar
AU  - Zhou, Meilun
AU  - McCraine, Cary D.
AU  - Wasson, Louis L.
TI  - Real-Time Automated Classification of Sky Conditions Using Deep Learning and Edge Computing
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - The radiometric quality of remotely sensed imagery is crucial for precision agriculture applications because estimations of plant health rely on the underlying quality. Sky conditions, and specifically shadowing from clouds, are critical determinants in the quality of images that can be obtained from low-altitude sensing platforms. In this work, we first compare common deep learning approaches to classify sky conditions with regard to cloud shadows in agricultural fields using a visible spectrum camera. We then develop an artificial-intelligence-based edge computing system to fully automate the classification process. Training data consisting of 100 oblique angle images of the sky were provided to a convolutional neural network and two deep residual neural networks (ResNet18 and ResNet34) to facilitate learning two classes, namely (1) good image quality expected, and (2) degraded image quality expected. The expectation of quality stemmed from the sky condition (i.e., density, coverage, and thickness of clouds) present at the time of the image capture. These networks were tested using a set of 13,000 images. Our results demonstrated that ResNet18 and ResNet34 classifiers produced better classification accuracy when compared to a convolutional neural network classifier. The best overall accuracy was obtained by ResNet34, which was 92% accurate, with a Kappa statistic of 0.77. These results demonstrate a low-cost solution to quality control for future autonomous farming systems that will operate without human intervention and supervision.
KW  - autonomous systems
KW  - cloud detection
KW  - low-altitude remote sensing
KW  - ResNet
KW  - UAS image quality
DO  - 10.3390/rs13193859
ER  -
TY  - EJOU
AU  - Cogato, Alessia
AU  - Wu, Lihua
AU  - Jewan, Shaikh Y.
AU  - Meggio, Franco
AU  - Marinello, Francesco
AU  - Sozzi, Marco
AU  - Pagay, Vinay
TI  - Evaluating the Spectral and Physiological Responses of Grapevines (Vitis vinifera L.) to Heat and Water Stresses under Different Vineyard Cooling and Irrigation Strategies
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 10
SN  - 2073-4395

AB  - Heat stress (HS) and water stress (WS) pose severe threats to viticulture, and effective management solutions to counter their effects on grapevine performance must be examined. In this study, we evaluated the physiological and spectral responses of Vitis vinifera L. cv. Sauvignon blanc to individual (HS) and combined (HS + WS) stress under four different cooling and irrigation strategies. The treatments were: standard drip irrigation (SI), extra drip irrigation (SI+), extra sprinklers irrigation (SPRI), and sustained deficit irrigation (SDI; 50% of SI). Compared to the other treatments, in the early stages after the occurrence of HS, the vine water status of SPRI and SI+ improved, with high stomatal conductance (gs) (SPRI) and stem water potential (Ψstem; SPRI and SI+). All the physiological indicators measured were significantly lower after the end of HS in the SDI treatment. We also identified the spectral response of grapevine to HS and combined HS and WS (resulting from SDI). Consistent with the physiological analysis, the proximal spectral responses of leaves identified SPRI and SI+ as putative cooling strategies to minimize vine HS. The vines undergoing combined stress (SDI) showed greenness amelioration 10 days after stress, as revealed by the greenness vegetation indices (VIs), i.e., Green Index (GI), Normalized Difference Greenness Vegetation Index (NDGI), and Visible Atmospherically Resistant Index (VARI). However, their physiological recovery was not achieved within this time, as shown by the Simple Ratio Index (SRI), Transformed Chlorophyll Absorption Ratio Index (TCARI), and TCARI/Optimized Soil-Adjusted Vegetation Index (TCARI/OSAVI). A three-step band selection process allowed the identification of the spectral traits’ responsive to HS and combined stress, i.e., 1336–1340 nm, 1967–1971 nm, and 600–604 nm.
KW  - heat stress
KW  - drought stress
KW  - grapevine
KW  - vegetation indices
KW  - hyperspectral analysis
KW  - grapevine physiology
DO  - 10.3390/agronomy11101940
ER  -
TY  - EJOU
AU  - Sharma, Vinamra B.
AU  - Tewari, Saurabh
AU  - Biswas, Susham
AU  - Lohani, Bharat
AU  - Dwivedi, Umakant D.
AU  - Dwivedi, Deepak
AU  - Sharma, Ashutosh
AU  - Jung, Jae P.
TI  - Recent Advancements in AI-Enabled Smart Electronics Packaging for Structural Health Monitoring
T2  - Metals

PY  - 2021
VL  - 11
IS  - 10
SN  - 2075-4701

AB  - Real-time health monitoring of civil infrastructures is performed to maintain their structural integrity, sustainability, and serviceability for a longer time. With smart electronics and packaging technology, large amounts of complex monitoring data are generated, requiring sophisticated artificial intelligence (AI) techniques for their processing. With the advancement of technology, more complex AI models have been applied, from simple models to sophisticated deep learning (DL) models, for structural health monitoring (SHM). In this article, a comprehensive review is performed, primarily on the applications of AI models for SHM to maintain the sustainability of diverse civil infrastructures. Three smart data capturing methods of SHM, namely, camera-based, smartphone-based, and unmanned aerial vehicle (UAV)-based methods, are also discussed, having made the utilization of intelligent paradigms easier. UAV is found to be the most promising smart data acquisition technology, whereas convolution neural networks are the most impressive DL model reported for SHM. Furthermore, current challenges and future perspectives of AI-based SHM systems are also described separately. Moreover, the Internet of Things (IoT) and smart city concepts are explained to elaborate on the contributions of intelligent SHM systems. The integration of SHM with IoT and cloud-based computing is leading us towards the evolution of future smart cities.
KW  - electronics packaging
KW  - lead-free solders
KW  - structural health monitoring
KW  - civil infrastructure
KW  - damage detection
KW  - pipeline leakage detection
DO  - 10.3390/met11101537
ER  -
TY  - EJOU
AU  - Montgomery, Joshua
AU  - Mahoney, Craig
AU  - Brisco, Brian
AU  - Boychuk, Lyle
AU  - Cobbaert, Danielle
AU  - Hopkinson, Chris
TI  - Remote Sensing of Wetlands in the Prairie Pothole Region of North America
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - The Prairie Pothole Region (PPR) of North America is an extremely important habitat for a diverse range of wetland ecosystems that provide a wealth of socio-economic value. This paper describes the ecological characteristics and importance of PPR wetlands and the use of remote sensing for mapping and monitoring applications. While there are comprehensive reviews for wetland remote sensing in recent publications, there is no comprehensive review about the use of remote sensing in the PPR. First, the PPR is described, including the wetland classification systems that have been used, the water regimes that control the surface water and water levels, and the soil and vegetation characteristics of the region. The tools and techniques that have been used in the PPR for analyses of geospatial data for wetland applications are described. Field observations for ground truth data are critical for good validation and accuracy assessment of the many products that are produced. Wetland classification approaches are reviewed, including Decision Trees, Machine Learning, and object versus pixel-based approaches. A comprehensive description of the remote sensing systems and data that have been employed by various studies in the PPR is provided. A wide range of data can be used for various applications, including passive optical data like aerial photographs or satellite-based, Earth-observation data. Both airborne and spaceborne lidar studies are described. A detailed description of Synthetic Aperture RADAR (SAR) data and research are provided. The state of the art is the use of multi-source data to achieve higher accuracies and hybrid approaches. Digital Surface Models are also being incorporated in geospatial analyses to separate forest and shrub and emergent systems based on vegetation height. Remote sensing provides a cost-effective mechanism for mapping and monitoring PPR wetlands, especially with the logistical difficulties and cost of field-based methods. The wetland characteristics of the PPR dictate the need for high resolution in both time and space, which is increasingly possible with the numerous and increasing remote sensing systems available and the trend to open-source data and tools. The fusion of multi-source remote sensing data via state-of-the-art machine learning is recommended for wetland applications in the PPR. The use of such data promotes flexibility for sensor addition, subtraction, or substitution as a function of application needs and potential cost restrictions. This is important in the PPR because of the challenges related to the highly dynamic nature of this unique region.
KW  - prairie pothole region
KW  - wetland
KW  - remote sensing
KW  - monitoring
KW  - classification
KW  - ecology
DO  - 10.3390/rs13193878
ER  -
TY  - EJOU
AU  - Zhang, Tianxiang
AU  - Xu, Zhiyong
AU  - Su, Jinya
AU  - Yang, Zhifang
AU  - Liu, Cunjia
AU  - Chen, Wen-Hua
AU  - Li, Jiangyun
TI  - Ir-UNet: Irregular Segmentation U-Shape Network for Wheat Yellow Rust Detection by UAV Multispectral Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - Crop disease is widely considered as one of the most pressing challenges for food crops, and therefore an accurate crop disease detection algorithm is highly desirable for its sustainable management. The recent use of remote sensing and deep learning is drawing increasing research interests in wheat yellow rust disease detection. However, current solutions on yellow rust detection are generally addressed by RGB images and the basic semantic segmentation algorithms (e.g., UNet), which do not consider the irregular and blurred boundary problems of yellow rust area therein, restricting the disease segmentation performance. Therefore, this work aims to develop an automatic yellow rust disease detection algorithm to cope with these boundary problems. An improved algorithm entitled Ir-UNet by embedding irregular encoder module (IEM), irregular decoder module (IDM) and content-aware channel re-weight module (CCRM) is proposed and compared against the basic UNet while with various input features. The recently collected dataset by DJI M100 UAV equipped with RedEdge multispectral camera is used to evaluate the algorithm performance. Comparative results show that the Ir-UNet with five raw bands outperforms the basic UNet, achieving the highest overall accuracy (OA) score (97.13%) among various inputs. Moreover, the use of three selected bands, Red-NIR-RE, in the proposed Ir-UNet can obtain a comparable result (OA: 96.83%) while with fewer spectral bands and less computation load. It is anticipated that this study by seamlessly integrating the Ir-UNet network and UAV multispectral images can pave the way for automated yellow rust detection at farmland scales.
KW  - deep learning
KW  - Ir-UNet
KW  - crop disease detection
KW  - multispectral imagery
KW  - unmanned aerial vehicle (UAV)
DO  - 10.3390/rs13193892
ER  -
TY  - EJOU
AU  - Khan, Mohammad Z.
AU  - Alhazmi, Omar H.
AU  - Javed, Muhammad A.
AU  - Ghandorh, Hamza
AU  - Aloufi, Khalid S.
TI  - Reliable Internet of Things: Challenges and Future Trends
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 19
SN  - 2079-9292

AB  - The Internet of Things (IoT) is a vital component of many future industries. By intelligent integration of sensors, wireless communications, computing techniques, and data analytics, IoT can increase productivity and efficiency of industries. Reliability of data transmission is key to realize several applications offered by IoT. In this paper, we present an overview of future IoT applications, and their major communication requirements. We provide a brief survey of recent work in four major areas of reliable IoT including resource allocation, latency management, security, and reliability metrics. Finally, we highlight some of the important challenges for reliable IoT related to machine learning techniques, 6G communications and blockchain based security that need further investigation and discuss related future directions.
KW  - IoT
KW  - resource allocation
KW  - latency
KW  - security
KW  - metrics
DO  - 10.3390/electronics10192377
ER  -
TY  - EJOU
AU  - Nooralishahi, Parham
AU  - Ibarra-Castanedo, Clemente
AU  - Deane, Shakeb
AU  - López, Fernando
AU  - Pant, Shashank
AU  - Genest, Marc
AU  - Avdelidis, Nicolas P.
AU  - Maldague, Xavier P. V.
TI  - Drone-Based Non-Destructive Inspection of Industrial Sites: A Review and Case Studies
T2  - Drones

PY  - 2021
VL  - 5
IS  - 4
SN  - 2504-446X

AB  - Using aerial platforms for Non-Destructive Inspection (NDI) of large and complex structures is a growing field of interest in various industries. Infrastructures such as: buildings, bridges, oil and gas, etc. refineries require regular and extensive inspections. The inspection reports are used to plan and perform required maintenance, ensuring their structural health and the safety of the workers. However, performing these inspections can be challenging due to the size of the facility, the lack of easy access, the health risks for the inspectors, or several other reasons, which has convinced companies to invest more in drones as an alternative solution to overcome these challenges. The autonomous nature of drones can assist companies in reducing inspection time and cost. Moreover, the employment of drones can lower the number of required personnel for inspection and can increase personnel safety. Finally, drones can provide a safe and reliable solution for inspecting hard-to-reach or hazardous areas. Despite the recent developments in drone-based NDI to reliably detect defects, several limitations and challenges still need to be addressed. In this paper, a brief review of the history of unmanned aerial vehicles, along with a comprehensive review of studies focused on UAV-based NDI of industrial and commercial facilities, are provided. Moreover, the benefits of using drones in inspections as an alternative to conventional methods are discussed, along with the challenges and open problems of employing drones in industrial inspections, are explored. Finally, some of our case studies conducted in different industrial fields in the field of Non-Destructive Inspection are presented.
KW  - unmanned aerial vehicle
KW  - thermography
KW  - non-destructive testing (NDT)
KW  - aerial inspection
DO  - 10.3390/drones5040106
ER  -
TY  - EJOU
AU  - Li, Shuyang
AU  - Hu, Xiaohui
AU  - Du, Yongwen
TI  - Deep Reinforcement Learning for Computation Offloading and Resource Allocation in Unmanned-Aerial-Vehicle Assisted Edge Computing
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 19
SN  - 1424-8220

AB  - Computation offloading technology extends cloud computing to the edge of the access network close to users, bringing many benefits to terminal devices with limited battery and computational resources. Nevertheless, the existing computation offloading approaches are challenging to apply to specific scenarios, such as the dense distribution of end-users and the sparse distribution of network infrastructure. The technological revolution in the unmanned aerial vehicle (UAV) and chip industry has granted UAVs more computing resources and promoted the emergence of UAV-assisted mobile edge computing (MEC) technology, which could be applied to those scenarios. However, in the MEC system with multiple users and multiple servers, making reasonable offloading decisions and allocating system resources is still a severe challenge. This paper studies the offloading decision and resource allocation problem in the UAV-assisted MEC environment with multiple users and servers. To ensure the quality of service for end-users, we set the weighted total cost of delay, energy consumption, and the size of discarded tasks as our optimization objective. We further formulate the joint optimization problem as a Markov decision process and apply the soft actor–critic (SAC) deep reinforcement learning algorithm to optimize the offloading policy. Numerical simulation results show that the offloading policy optimized by our proposed SAC-based dynamic computing offloading (SACDCO) algorithm effectively reduces the delay, energy consumption, and size of discarded tasks for the UAV-assisted MEC system. Compared with the fixed local-UAV scheme in the specific simulation setting, our proposed approach reduces system delay and energy consumption by approximately 50% and 200%, respectively.
KW  - unmanned aerial vehicle
KW  - edge computing
KW  - computation offloading
KW  - resource allocation
KW  - soft actor–critic
DO  - 10.3390/s21196499
ER  -
TY  - EJOU
AU  - Ta, Na
AU  - Chang, Qingrui
AU  - Zhang, Youming
TI  - Estimation of Apple Tree Leaf Chlorophyll Content Based on Machine Learning Methods
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - Leaf chlorophyll content (LCC) is one of the most important factors affecting photosynthetic capacity and nitrogen status, both of which influence crop harvest. However, the development of rapid and nondestructive methods for leaf chlorophyll estimation is a topic of much interest. Hence, this study explored the use of the machine learning approach to enhance the estimation of leaf chlorophyll from spectral reflectance data. The objective of this study was to evaluate four different approaches for estimating the LCC of apple tree leaves at five growth stages (the 1st, 2nd, 3rd, 4th and 5th growth stages): (1) univariate linear regression (ULR); (2) multivariate linear regression (MLR); (3) support vector regression (SVR); and (4) random forest (RF) regression. Samples were collected from the leaves on the eastern, western, southern and northern sides of apple trees five times (1st, 2nd, 3rd, 4th and 5th growth stages) over three consecutive years (2016–2018), and experiments were conducted in 10–20-year-old apple tree orchards. Correlation analysis results showed that LCC and ST, LCC and vegetation indices (VIs), and LCC and three edge parameters (TEP) had high correlations with the first-order differential spectrum (FODS) (0.86), leaf chlorophyll index (LCI) (0.87), and (SDr − SDb)/ (SDr + SDb) (0.88) at the 3rd, 3rd, and 4th growth stages, respectively. The prediction models of different growth stages were relatively good. The MLR and SVR models in the LCC assessment of different growth stages only reached the highest R2 values of 0.79 and 0.82, and the lowest RMSEs were 2.27 and 2.02, respectively. However, the RF model evaluation was significantly better than above models. The R2 value was greater than 0.94 and RMSE was less than 1.37 at different growth stages. The prediction accuracy of the 1st growth stage (R2 = 0.96, RMSE = 0.95) was best with the RF model. This result could provide a theoretical basis for orchard management. In the future, more models based on machine learning techniques should be developed using the growth information and physiological parameters of orchards that provide technical support for intelligent orchard management.
KW  - leaf chlorophyll content
KW  - hyperspectral remote sensing
KW  - RF
KW  - SVR
DO  - 10.3390/rs13193902
ER  -
TY  - EJOU
AU  - Xia, Shuang
AU  - Zhang, Xiangyin
TI  - Constrained Path Planning for Unmanned Aerial Vehicle in 3D Terrain Using Modified Multi-Objective Particle Swarm Optimization
T2  - Actuators

PY  - 2021
VL  - 10
IS  - 10
SN  - 2076-0825

AB  - This paper considered the constrained unmanned aerial vehicle (UAV) path planning problem as the multi-objective optimization problem, in which both costs and constraints are treated as the objective functions. A novel multi-objective particle swarm optimization algorithm based on the Gaussian distribution and the Q-Learning technique (GMOPSO-QL) is proposed and applied to determine the feasible and optimal path for UAV. In GMOPSO-QL, the Gaussian distribution based updating operator is adopted to generate new particles, and the exploration and exploitation modes are introduced to enhance population diversity and convergence speed, respectively. Moreover, the Q-Learning based mode selection logic is introduced to balance the global search with the local search in the evolution process. Simulation results indicate that our proposed GMOPSO-QL can deal with the constrained UAV path planning problem and is superior to existing optimization algorithms in terms of efficiency and robustness.
KW  - 3D path planning
KW  - multi-objective particle swarm optimization
KW  - unmanned aerial vehicle
KW  - Q-Learning
DO  - 10.3390/act10100255
ER  -
TY  - EJOU
AU  - Saddik, Amine
AU  - Latif, Rachid
AU  - El Ouardi, Abdelhafid
TI  - Low-Power FPGA Architecture Based Monitoring Applications in Precision Agriculture
T2  - Journal of Low Power Electronics and Applications

PY  - 2021
VL  - 11
IS  - 4
SN  - 2079-9268

AB  - Today’s on-chip systems technology has grounded impressive advances in computing power and energy consumption. The choice of the right architecture depends on the application. In our case, we were studying vegetation monitoring algorithms in precision agriculture. This study presents a system based on a monitoring algorithm for agricultural fields, an electronic architecture based on a CPU-FPGA SoC system and the OpenCL parallel programming paradigm. We focused our study on our own dataset of agricultural fields to validate the results. The fields studied in our case are in the Guelmin-Oued noun region in the south of Morocco. These fields are divided into two areas, with a total surface of 3.44 Ha2 for the first field and 3.73 Ha2 for the second. The images were collected using a DJI-type unmanned aerial vehicle and an RGB camera. Performance evaluation showed that the system could process up to 86 fps versus 12 fps or 20 fps in C/C++ and OpenMP implementations, respectively. Software optimizations have increased the performance to 107 fps, which meets real-time constraints.
KW  - CPU-FPGA SoC
KW  - on-chip systems
KW  - embedded systems
KW  - precision agriculture
DO  - 10.3390/jlpea11040039
ER  -
TY  - EJOU
AU  - Zawadzka, Joanna
AU  - Truckell, Ian
AU  - Khouakhi, Abdou
AU  - Rivas Casado, Mónica
TI  - Detection of Flood Damage in Urban Residential Areas Using Object-Oriented UAV Image Analysis Coupled with Tree-Based Classifiers
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - Timely clearing-up interventions are essential for effective recovery of flood-damaged housing, however, time-consuming door-to-door inspections for insurance purposes need to take place before major repairs can be done to adequately assess the losses caused by flooding. With the increased probability of flooding, there is a heightened need for rapid flood damage assessment methods. High resolution imagery captured by unmanned aerial vehicles (UAVs) offers an opportunity for accelerating the time needed for inspections, either through visual interpretation or automated image classification. In this study, object-oriented image segmentation coupled with tree-based classifiers was implemented on a 10 cm resolution RGB orthoimage, captured over the English town of Cockermouth a week after a flood triggered by storm Desmond, to automatically detect debris associated with damages predominantly to residential housing. Random forests algorithm achieved a good level of overall accuracy of 74%, with debris being correctly classified at the rate of 58%, and performing well for small debris (67%) and skips (64%). The method was successful at depicting brightly-colored debris, however, was prone to misclassifications with brightly-colored vehicles. Consequently, in the current stage, the methodology could be used to facilitate visual interpretation of UAV images. Methods to improve accuracy have been identified and discussed.
KW  - urban flood damage
KW  - UAV
KW  - object-oriented image analysis
DO  - 10.3390/rs13193913
ER  -
TY  - EJOU
AU  - Korchagin, Sergey A.
AU  - Gataullin, Sergey T.
AU  - Osipov, Aleksey V.
AU  - Smirnov, Mikhail V.
AU  - Suvorov, Stanislav V.
AU  - Serdechnyi, Denis V.
AU  - Bublikov, Konstantin V.
TI  - Development of an Optimal Algorithm for Detecting Damaged and Diseased Potato Tubers Moving along a Conveyor Belt Using Computer Vision Systems
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 10
SN  - 2073-4395

AB  - The article discusses the problem of detecting sick or mechanically damaged potatoes using machine learning methods. We proposed an algorithm and developed a system for the rapid detection of damaged tubers. The system can be installed on a conveyor belt in a vegetable store, and it consists of a laptop computer and an action camera, synchronized with a flashlight system. The algorithm consists of two phases. The first phase uses the Viola-Jones algorithm, applied to the filtered action camera image, so it aims to detect separate potato tubers on the conveyor belt. The second phase is the application of a method that we choose based on video capturing conditions. To isolate potatoes infected with certain types of diseases (dry rot, for example), we use the Scale Invariant Feature Transform (SIFT)—Support Vector Machine (SVM) method. In case of inconsistent or weak lighting, the histogram of oriented gradients (HOG)—Bag-of-Visual-Words (BOVW)—neural network (BPNN) method is used. Otherwise, Otsu’s threshold binarization—a convolutional neural network (CNN) method is used. The first phase’s result depends on the conveyor’s speed, the density of tubers on the conveyor, and the accuracy of the video system. With the optimal setting, the result reaches 97%. The second phase’s outcome depends on the method and varies from 80% to 97%. When evaluating the performance of the system, it was found that it allows to detect and classify up to 100 tubers in one second, which significantly exceeds the performance of most similar systems.
KW  - neural networks
KW  - defects detection
KW  - crop
KW  - potato disease
KW  - potato classification
KW  - fast detection
KW  - machine learning
DO  - 10.3390/agronomy11101980
ER  -
TY  - EJOU
AU  - Lu, Qikai
AU  - Si, Wei
AU  - Wei, Lifei
AU  - Li, Zhongqiang
AU  - Xia, Zhihong
AU  - Ye, Song
AU  - Xia, Yu
TI  - Retrieval of Water Quality from UAV-Borne Hyperspectral Imagery: A Comparative Study of Machine Learning Algorithms
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - The rapidly increasing world population and human activities accelerate the crisis of the limited freshwater resources. Water quality must be monitored for the sustainability of freshwater resources. Unmanned aerial vehicle (UAV)-borne hyperspectral data can capture fine features of water bodies, which have been widely used for monitoring water quality. In this study, nine machine learning algorithms are systematically evaluated for the inversion of water quality parameters including chlorophyll-a (Chl-a) and suspended solids (SS) with UAV-borne hyperspectral data. In comparing the experimental results of the machine learning model on the water quality parameters, we can observe that the prediction performance of the Catboost regression (CBR) model is the best. However, the prediction performances of the Multi-layer Perceptron regression (MLPR) and Elastic net (EN) models are very unsatisfactory, indicating that the MLPR and EN models are not suitable for the inversion of water quality parameters. In addition, the water quality distribution map is generated, which can be used to identify polluted areas of water bodies.
KW  - water quality parameters inversion
KW  - machine learning
KW  - UAV-borne hyperspectral data
KW  - water quality mapping
DO  - 10.3390/rs13193928
ER  -
TY  - EJOU
AU  - Su, Xin
AU  - Shao, Weiwei
AU  - Liu, Jiahong
AU  - Jiang, Yunzhong
AU  - Wang, Kaibo
TI  - Dynamic Assessment of the Impact of Flood Disaster on Economy and Population under Extreme Rainstorm Events
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - In the context of climate change and rapid urbanization, flood disaster loss caused by extreme rainstorm events is becoming more and more serious. An accurate assessment of flood disaster loss has become a key issue. In this study, extreme rainstorm scenarios with 50- and 100-year return periods based on the Chicago rain pattern were designed. The dynamic change process of flood disaster loss was obtained by using a 1D–2D coupled model, Hazard Rating (HR) method, machine learning, and ArcPy script. The results show that under extreme rainstorm events, the direct economic loss and affected population account for about 3% of the total GDP and 16% of the total population, respectively, and built-up land is the main disaster area. In addition, the initial time and the peak time of flood disaster loss increases with an increasing flood hazard degree and decreases with the increase in the return period. The total loss increases with the increase in the return period, and the unit loss decreases with the increase in the return period. Compared with a static assessment, a dynamic assessment can better reveal the development law of flood disaster loss, which has great significance for flood risk management and the mitigation of flood disaster loss.
KW  - extreme rainstorm
KW  - flood disaster loss
KW  - dynamic assessment
KW  - POIs
KW  - machine learning
DO  - 10.3390/rs13193924
ER  -
TY  - EJOU
AU  - Berghout, Tarek
AU  - Benbouzid, Mohamed
AU  - Bentrcia, Toufik
AU  - Ma, Xiandong
AU  - Djurović, Siniša
AU  - Mouss, Leïla-Hayet
TI  - Machine Learning-Based Condition Monitoring for PV Systems: State of the Art and Future Prospects
T2  - Energies

PY  - 2021
VL  - 14
IS  - 19
SN  - 1996-1073

AB  - To ensure the continuity of electric power generation for photovoltaic systems, condition monitoring frameworks are subject to major enhancements. The continuous uniform delivery of electric power depends entirely on a well-designed condition maintenance program. A just-in-time task to deal with several naturally occurring faults can be correctly undertaken via the cooperation of effective detection, diagnosis, and prognostic analyses. Therefore, the present review first outlines different failure modes to which all photovoltaic systems are subjected, in addition to the essential integrated detection methods and technologies. Then, data-driven paradigms, and their contribution to solving this prediction problem, are also explored. Accordingly, this review primarily investigates the different learning architectures used (i.e., ordinary, hybrid, and ensemble) in relation to their learning frameworks (i.e., traditional and deep learning). It also discusses the extension of machine learning to knowledge-driven approaches, including generative models such as adversarial networks and transfer learning. Finally, this review provides insights into different works to highlight various operating conditions and different numbers and types of failures, and provides links to some publicly available datasets in the field. The clear organization of the abundant information on this subject may result in rigorous guidelines for the trends adopted in the future.
KW  - photovoltaic systems
KW  - machine learning
KW  - deep learning
KW  - condition monitoring
KW  - faults diagnosis
KW  - fault detection
KW  - open source datasets
DO  - 10.3390/en14196316
ER  -
TY  - EJOU
AU  - Xue, Wei
AU  - Jeong, Seungtaek
AU  - Ko, Jonghan
AU  - Yeom, Jong-Min
TI  - Contribution of Biophysical Factors to Regional Variations of Evapotranspiration and Seasonal Cooling Effects in Paddy Rice in South Korea
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - Previous studies have observed seasonal cooling effects in paddy rice as compared to temperate forest through enhanced evapotranspiration (ET) in Northeast Asia, while rare studies have revealed biophysical factors responsible for spatial variations of ET and its cooling effects. In this study, we adopted a data fusion method that integrated MODIS 8-day surface reflectance products, gridded daily climate data of ground surface, and a remote sensing pixel-based Penman-Monteith ET model (i.e., the RS–PM model) to quantify ET patterns of paddy rice in South Korea from 2011 to 2014. Results indicated that the regional variations of the rice-growing season ET (RGS-ET, the sum of daily ET from the season onset of rapid canopy expansion (SoS) to the end of the rice-growing season (EGS)) were primarily influenced by phenological factors (i.e., the length of growing period-LGP), followed by growing season mean climatic factors (i.e., vapor pressure deficit-VPD, and air temperature). For regional variations of the paddy field ET (PF-ET, the sum of daily ET from the field flooding and transplanting date detected by satellite observations (FFTDsat) to SoS, and to EGS), the extents were substantially reduced, only accounting for 54% of the RGS-ET variations. The FFTDsat and SoS were considered critical for the reduced PF-ET variations. In comparison to the temperate forest, changes in monthly ground surface air temperature (Ts) in paddy fields showed the V-shaped seasonal pattern with significant cooling effects found in late spring and early summer, primarily due to a large decline in daytime Ts that exceeded the nighttime warming. Bringing FFTDsat towards late spring and early summer was identified as vital field management practices, causing significant declines in daytime Ts due to enhanced ET. Results highlighted climate-warming mitigation by paddy fields due to early flooding practices.
KW  - cooling effects
KW  - evapotranspiration
KW  - numerical simulation
KW  - paddy rice
KW  - phenology
KW  - remote sensing
KW  - water management
DO  - 10.3390/rs13193992
ER  -
TY  - EJOU
AU  - Shashikant, Veena
AU  - Mohamed Shariff, Abdul R.
AU  - Wayayok, Aimrun
AU  - Kamal, Md R.
AU  - Lee, Yang P.
AU  - Takeuchi, Wataru
TI  - Vegetation Effects on Soil Moisture Retrieval from Water Cloud Model Using PALSAR-2 for Oil Palm Trees
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - In oil palm crop, soil fertility is less important than the physical soil characteristics. It is important to have a balance and sufficient soil moisture to sustain high yields in oil palm plantations. However, conventional methods of soil moisture determination are laborious and time-consuming with limited coverage and accuracy. In this research, we evaluated synthetic aperture radar (SAR) and in-situ observations at an oil palm plantation to determine SAR signal sensitivity to oil palm crop by means of water cloud model (WCM) inversion for retrieving soil moisture from L-band HH and HV polarized data. The effects of vegetation on backscattering coefficients were evaluated by comparing Leaf Area Index (LAI), Leaf Water Area Index (LWAI) and Normalized Plant Water Content (NPWC). The results showed that HV polarization effectively simulated backscatter coefficient as compared to HH polarization where the best fit was obtained by taking the LAI as a vegetation descriptor. The HV polarization with the LAI indicator was able to retrieve soil moisture content with an accuracy of at least 80%.
KW  - SAR
KW  - backscattering
KW  - soil moisture content
KW  - LAI
KW  - HH and HV polarization
DO  - 10.3390/rs13204023
ER  -
TY  - EJOU
AU  - Zhao, Jianghong
AU  - Wang, Yinrui
AU  - Cao, Yuee
AU  - Guo, Ming
AU  - Huang, Xianfeng
AU  - Zhang, Ruiju
AU  - Dou, Xintong
AU  - Niu, Xinyu
AU  - Cui, Yuanyuan
AU  - Wang, Jun
TI  - The Fusion Strategy of 2D and 3D Information Based on Deep Learning: A Review
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - Recently, researchers have realized a number of achievements involving deep-learning-based neural networks for the tasks of segmentation and detection based on 2D images, 3D point clouds, etc. Using 2D and 3D information fusion for the advantages of compensation and accuracy improvement has become a hot research topic. However, there are no critical reviews focusing on the fusion strategies of 2D and 3D information integration based on various data for segmentation and detection, which are the basic tasks of computer vision. To boost the development of this research domain, the existing representative fusion strategies are collected, introduced, categorized, and summarized in this paper. In addition, the general structures of different kinds of fusion strategies were firstly abstracted and categorized, which may inspire researchers. Moreover, according to the methods included in this paper, the 2D information and 3D information of different methods come from various kinds of data. Furthermore, suitable datasets are introduced and comparatively summarized to support the relative research. Last but not least, we put forward some open challenges and promising directions for future research.
KW  - fusion strategy
KW  - deep learning
KW  - segmentation
KW  - detection
DO  - 10.3390/rs13204029
ER  -
TY  - EJOU
AU  - Mirmazloumi, S. M.
AU  - Moghimi, Armin
AU  - Ranjgar, Babak
AU  - Mohseni, Farzane
AU  - Ghorbanian, Arsalan
AU  - Ahmadi, Seyed A.
AU  - Amani, Meisam
AU  - Brisco, Brian
TI  - Status and Trends of Wetland Studies in Canada Using Remote Sensing Technology with a Focus on Wetland Classification: A Bibliographic Analysis
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - A large portion of Canada is covered by wetlands; mapping and monitoring them is of great importance for various applications. In this regard, Remote Sensing (RS) technology has been widely employed for wetland studies in Canada over the past 45 years. This study evaluates meta-data to investigate the status and trends of wetland studies in Canada using RS technology by reviewing the scientific papers published between 1976 and the end of 2020 (300 papers in total). Initially, a meta-analysis was conducted to analyze the status of RS-based wetland studies in terms of the wetland classification systems, methods, classes, RS data usage, publication details (e.g., authors, keywords, citations, and publications time), geographic information, and level of classification accuracies. The deep systematic review of 128 peer-reviewed articles illustrated the rising trend in using multi-source RS datasets along with advanced machine learning algorithms for wetland mapping in Canada. It was also observed that most of the studies were implemented over the province of Ontario. Pixel-based supervised classifiers were the most popular wetland classification algorithms. This review summarizes different RS systems and methodologies for wetland mapping in Canada to outline how RS has been utilized for the generation of wetland inventories. The results of this review paper provide the current state-of-the-art methods and datasets for wetland studies in Canada and will provide direction for future wetland mapping research.
KW  - Canada
KW  - classification
KW  - remote sensing
KW  - wetland
DO  - 10.3390/rs13204025
ER  -
TY  - EJOU
AU  - Yu, Run
AU  - Luo, Youqing
AU  - Li, Haonan
AU  - Yang, Liyuan
AU  - Huang, Huaguo
AU  - Yu, Linfeng
AU  - Ren, Lili
TI  - Three-Dimensional Convolutional Neural Network Model for Early Detection of Pine Wilt Disease Using UAV-Based Hyperspectral Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - As one of the most devastating disasters to pine forests, pine wilt disease (PWD) has caused tremendous ecological and economic losses in China. An effective way to prevent large-scale PWD outbreaks is to detect and remove the damaged pine trees at the early stage of PWD infection. However, early infected pine trees do not show obvious changes in morphology or color in the visible wavelength range, making early detection of PWD tricky. Unmanned aerial vehicle (UAV)-based hyperspectral imagery (HI) has great potential for early detection of PWD. However, the commonly used methods, such as the two-dimensional convolutional neural network (2D-CNN), fail to simultaneously extract and fully utilize the spatial and spectral information, whereas the three-dimensional convolutional neural network (3D-CNN) is able to collect this information from raw hyperspectral data. In this paper, we applied the residual block to 3D-CNN and constructed a 3D-Res CNN model, the performance of which was then compared with that of 3D-CNN, 2D-CNN, and 2D-Res CNN in identifying PWD-infected pine trees from the hyperspectral images. The 3D-Res CNN model outperformed the other models, achieving an overall accuracy (OA) of 88.11% and an accuracy of 72.86% for detecting early infected pine trees (EIPs). Using only 20% of the training samples, the OA and EIP accuracy of 3D-Res CNN can still achieve 81.06% and 51.97%, which is superior to the state-of-the-art method in the early detection of PWD based on hyperspectral images. Collectively, 3D-Res CNN was more accurate and effective in early detection of PWD. In conclusion, 3D-Res CNN is proposed for early detection of PWD in this paper, making the prediction and control of PWD more accurate and effective. This model can also be applied to detect pine trees damaged by other diseases or insect pests in the forest.
KW  - pine wilt disease
KW  - early detection
KW  - UAV-based hyperspectral imagery
KW  - 3D-CNN
KW  - 3D-Res CNN
DO  - 10.3390/rs13204065
ER  -
TY  - EJOU
AU  - Liu, Hong
AU  - Yu, Tao
AU  - Hu, Bingliang
AU  - Hou, Xingsong
AU  - Zhang, Zhoufeng
AU  - Liu, Xiao
AU  - Liu, Jiacheng
AU  - Wang, Xueji
AU  - Zhong, Jingjing
AU  - Tan, Zhengxuan
AU  - Xia, Shaoxia
AU  - Qian, Bao
TI  - UAV-Borne Hyperspectral Imaging Remote Sensing System Based on Acousto-Optic Tunable Filter for Water Quality Monitoring
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - Unmanned aerial vehicle (UAV) hyperspectral remote sensing technologies have unique advantages in high-precision quantitative analysis of non-contact water surface source concentration. Improving the accuracy of non-point source detection is a difficult engineering problem. To facilitate water surface remote sensing, imaging, and spectral analysis activities, a UAV-based hyperspectral imaging remote sensing system was designed. Its prototype was built, and laboratory calibration and a joint air–ground water quality monitoring activity were performed. The hyperspectral imaging remote sensing system of UAV comprised a light and small UAV platform, spectral scanning hyperspectral imager, and data acquisition and control unit. The spectral principle of the hyperspectral imager is based on the new high-performance acousto-optic tunable (AOTF) technology. During laboratory calibration, the spectral calibration of the imaging spectrometer and image preprocessing in data acquisition were completed. In the UAV air–ground joint experiment, combined with the typical water bodies of the Yangtze River mainstream, the Three Gorges demonstration area, and the Poyang Lake demonstration area, the hyperspectral data cubes of the corresponding water areas were obtained, and geometric registration was completed. Thus, a large field-of-view mosaic and water radiation calibration were realized. A chlorophyl-a (Chl-a) sensor was used to test the actual water control points, and 11 traditional Chl-a sensitive spectrum selection algorithms were analyzed and compared. A random forest algorithm was used to establish a prediction model of water surface spectral reflectance and water quality parameter concentration. Compared with the back propagation neural network, partial least squares, and PSO-LSSVM algorithms, the accuracy of the RF algorithm in predicting Chl-a was significantly improved. The determination coefficient of the training samples was 0.84; root mean square error, 3.19 μg/L; and mean absolute percentage error, 5.46%. The established Chl-a inversion model was applied to UAV hyperspectral remote sensing images. The predicted Chl-a distribution agreed with the field observation results, indicating that the UAV-borne hyperspectral remote sensing water quality monitoring system based on AOTF is a promising remote sensing imaging spectral analysis tool for water.
KW  - hyperspectral imaging
KW  - acousto-optic tunable filter
KW  - UAV platform
KW  - remote sensing
KW  - water quality monitoring
DO  - 10.3390/rs13204069
ER  -
TY  - EJOU
AU  - Megat Mohamed Nazir, Megat N.
AU  - Terhem, Razak
AU  - Norhisham, Ahmad R.
AU  - Mohd Razali, Sheriza
AU  - Meder, Roger
TI  - Early Monitoring of Health Status of Plantation-Grown Eucalyptus pellita at Large Spatial Scale via Visible Spectrum Imaging of Canopy Foliage Using Unmanned Aerial Vehicles
T2  - Forests

PY  - 2021
VL  - 12
IS  - 10
SN  - 1999-4907

AB  - Eucalyptus is a diverse genus from which several species are often deployed for commercial industrial tree plantation due to their desirable wood properties for utilization in both solid wood and fiber products, as well as their growth and productivity in many environments. In this study, a method for monitoring the health status of a 22.78 ha Eucalyptus pellita plantation stand was developed using the red-green-blue channels captured using an unmanned aerial vehicle. The ortho-image was generated, and visual atmospheric resistance index (VARI) indices were developed. Herein, four classification levels of pest and disease were generated using the VARI-green algorithm. The range of normalized VARI-green indices was between −2.0 and 2.0. The results identified seven dead trees (VARI-green index −2 to 0), five trees that were severely infected (VARI-green index 0 to 0.05), 967 trees that were mildly infected (VARI-green index 0.06 to 0.16), and 10,090 trees that were considered healthy (VARI-green index 0.17 to 2.00). The VARI-green indices were verified by manual ground-truthing and by comparison with normalized difference vegetation index which showed a mean correlation of 0.73. This study has shown practical application of aerial survey of a large-scale operational area of industrial tree plantation via low-cost UAV and RGB camera, to analyze VARI-green images in the detection of pest and disease.
KW  - Eucalyptus
KW  - health status
KW  - VARI-green
KW  - aerial survey
KW  - pest
KW  - disease
DO  - 10.3390/f12101393
ER  -
TY  - EJOU
AU  - Gambardella, Carmine
AU  - Parente, Rosaria
AU  - Ciambrone, Alessandro
AU  - Casbarra, Marialaura
TI  - A Principal Components Analysis-Based Method for the Detection of Cannabis Plants Using Representation Data by Remote Sensing
T2  - Data

PY  - 2021
VL  - 6
IS  - 10
SN  - 2306-5729

AB  - Integrating the representation of the territory, through airborne remote sensing activities with hyperspectral and visible sensors, and managing complex data through dimensionality reduction for the identification of cannabis plantations, in Albania, is the focus of the research proposed by the multidisciplinary group of the Benecon University Consortium. In this study, principal components analysis (PCA) was used to remove redundant spectral information from multiband datasets. This makes it easier to identify the most prevalent spectral characteristics in most bands and those that are specific to only a few bands. The survey and airborne monitoring by hyperspectral sensors is carried out with an Itres CASI 1500 sensor owned by Benecon, characterized by a spectral range of 380–1050 nm and 288 configurable channels. The spectral configuration adopted for the research was developed specifically to maximize the spectral separability of cannabis. The ground resolution of the georeferenced cartographic data varies according to the flight planning, inserted in the aerial platform of an Italian Guardia di Finanza’s aircraft, in relation to the orography of the sites under investigation. The geodatabase, wherein the processing of hyperspectral and visible images converge, contains ancillary data such as digital aeronautical maps, digital terrain models, color orthophoto, topographic data and in any case a significant amount of data so that they can be processed synergistically. The goal is to create maps and predictive scenarios, through the application of the spectral angle mapper algorithm, of the cannabis plantations scattered throughout the area. The protocol consists of comparing the spectral data acquired with the CASI1500 airborne sensor and the spectral signature of the cannabis leaves that have been acquired in the laboratory with ASD Fieldspec PRO FR spectrometers. These scientific studies have demonstrated how it is possible to achieve ex ante control of the evolution of the phenomenon itself for monitoring the cultivation of cannabis plantations.
KW  - remote sensing
KW  - machine learning
KW  - big data
KW  - principal component analysis
KW  - cannabis plantations
KW  - drug trafficking control
DO  - 10.3390/data6100108
ER  -
TY  - EJOU
AU  - Han, Jiejie
AU  - Zhao, Xi
AU  - Zhang, Hao
AU  - Liu, Yu
TI  - Analyzing the Spatial Heterogeneity of the Built Environment and Its Impact on the Urban Thermal Environment—Case Study of Downtown Shanghai
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 20
SN  - 2071-1050

AB  - Ongoing urban expansion has accelerated the explosive growth of urban populations and has led to a dramatic increase in the impervious surface area within urban areas. This, in turn, has exacerbated the surface heat island effect within cities. However, the importance of the surface heat island effect within urban areas, scilicet the intra-SUHI effect, has attracted less concern. The aim of this study was to quantitatively explore the relationship between the spatial heterogeneity of a built environment and the intra-urban surface heat island (intra-SUHI) effect using the thermally sharpened land surface temperature (LST) and high-resolution land-use classification products. The results show that at the land parcel scale, the parcel-based relative intensity of intra-SUHI should be attributed to the land parcels featured with differential land developmental intensity. Furthermore, the partial least squares regression (PLSR) modeling quantified the relative importance of the spatial heterogeneity indices of the built environment that exhibit a negative contribution to decreasing the parcel-based intra-SUHI effect or a positive contribution to increasing the intra-SUHI effect. Finally, based on the findings of this study, some practical countermeasures towards mitigating the adverse intra-SUHI effect and improving urban climatic adaption are discussed.
KW  - built-up environment
KW  - spatial heterogeneity
KW  - urban thermal environment
KW  - blue–green space
KW  - land use pattern
DO  - 10.3390/su132011302
ER  -
TY  - EJOU
AU  - Ndlovu, Helen S.
AU  - Odindi, John
AU  - Sibanda, Mbulisi
AU  - Mutanga, Onisimo
AU  - Clulow, Alistair
AU  - Chimonyo, Vimbayi G. P.
AU  - Mabhaudhi, Tafadzwanashe
TI  - A Comparative Estimation of Maize Leaf Water Content Using Machine Learning Techniques and Unmanned Aerial Vehicle (UAV)-Based Proximal and Remotely Sensed Data
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - Determining maize water content variability is necessary for crop monitoring and in developing early warning systems to optimise agricultural production in smallholder farms. However, spatially explicit information on maize water content, particularly in Southern Africa, remains elementary due to the shortage of efficient and affordable primary sources of suitable spatial data at a local scale. Unmanned Aerial Vehicles (UAVs), equipped with light-weight multispectral sensors, provide spatially explicit, near-real-time information for determining the maize crop water status at farm scale. Therefore, this study evaluated the utility of UAV-derived multispectral imagery and machine learning techniques in estimating maize leaf water indicators: equivalent water thickness (EWT), fuel moisture content (FMC), and specific leaf area (SLA). The results illustrated that both NIR and red-edge derived spectral variables were critical in characterising the maize water indicators on smallholder farms. Furthermore, the best models for estimating EWT, FMC, and SLA were derived from the random forest regression (RFR) algorithm with an rRMSE of 3.13%, 1%, and 3.48%, respectively. Additionally, EWT and FMC yielded the highest predictive performance and were the most optimal indicators of maize leaf water content. The findings are critical towards developing a robust and spatially explicit monitoring framework of maize water status and serve as a proxy of crop health and the overall productivity of smallholder maize farms.
KW  - precision agriculture
KW  - maize monitoring
KW  - UAV applications
KW  - smallholder farming
KW  - machine learning
DO  - 10.3390/rs13204091
ER  -
TY  - EJOU
AU  - Mohidem, Nur A.
AU  - Che’Ya, Nik N.
AU  - Juraimi, Abdul S.
AU  - Fazlil Ilahi, Wan F.
AU  - Mohd Roslim, Muhammad H.
AU  - Sulaiman, Nursyazyla
AU  - Saberioon, Mohammadmehdi
AU  - Mohd Noor, Nisfariza
TI  - How Can Unmanned Aerial Vehicles Be Used for Detecting Weeds in Agricultural Fields?
T2  - Agriculture

PY  - 2021
VL  - 11
IS  - 10
SN  - 2077-0472

AB  - Weeds are among the most harmful abiotic factors in agriculture, triggering significant yield loss worldwide. Remote sensing can detect and map the presence of weeds in various spectral, spatial, and temporal resolutions. This review aims to show the current and future trends of UAV applications in weed detection in the crop field. This study systematically searched the original articles published from 1 January 2016 to 18 June 2021 in the databases of Scopus, ScienceDirect, Commonwealth Agricultural Bureaux (CAB) Direct, and Web of Science (WoS) using Boolean string: “weed” AND “Unmanned Aerial Vehicle” OR “UAV” OR “drone”. Out of the papers identified, 144 eligible studies did meet our inclusion criteria and were evaluated. Most of the studies (i.e., 27.42%) on weed detection were carried out during the seedling stage of the growing cycle for the crop. Most of the weed images were captured using red, green, and blue (RGB) camera, i.e., 48.28% and main classification algorithm was machine learning techniques, i.e., 47.90%. This review initially highlighted articles from the literature that includes the crops’ typical phenology stage, reference data, type of sensor/camera, classification methods, and current UAV applications in detecting and mapping weed for different types of crop. This study then provides an overview of the advantages and disadvantages of each sensor and algorithm and tries to identify research gaps by providing a brief outlook at the potential areas of research concerning the benefit of this technology in agricultural industries. Integrated weed management, coupled with UAV application improves weed monitoring in a more efficient and environmentally-friendly way. Overall, this review demonstrates the scientific information required to achieve sustainable weed management, so as to implement UAV platform in the real agricultural contexts.
KW  - precision agriculture
KW  - unmanned aerial vehicle
KW  - weed
DO  - 10.3390/agriculture11101004
ER  -
TY  - EJOU
AU  - Rabiei, Saman
AU  - Jalilvand, Ehsan
AU  - Tajrishy, Massoud
TI  - A Method to Estimate Surface Soil Moisture and Map the Irrigated Cropland Area Using Sentinel-1 and Sentinel-2 Data
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 20
SN  - 2071-1050

AB  - Considering variations in surface soil moisture (SSM) is essential in improving crop yield and irrigation scheduling. Today, most remotely sensed soil moisture products have difficulties in resolving irrigation signals at the plot scale. This study aims to use Sentinel-1 radar backscatter and Sentinel-2 multispectral imagery to estimate SSM at high spatial (10 m) and temporal resolution (at least 5 days) over an agricultural domain. Three supervised machine learning algorithms, multilayer perceptron (MLP), a convolutional neural network (CNN), and linear regression models, were trained to estimate changes in SSM based on the variation in surface reflectance and backscatter over five different crops. Results showed that CNN is the best algorithm as it understands spatial relations and better represents two-dimensional images. Estimated values for SSM were in agreement with in-situ measurements regardless of the crop type, with RMSE=0.0292&nbsp;(cm3/cm3) and R2=0.92 for the Sentinel-2 derived SSM and RMSE=0.0317&nbsp;(cm3/cm3) and R2=0.84 for the Sentinel-1 soil moisture data. Moreover, a time series of estimated SSM based on Sentinel-1 (SSM-S1), Sentinel-2 (SSM-S2), and SSM derived from SMAP-Sentinel1 was compared. The developed SSM data showed a significantly higher mean SSM state over irrigated agriculture relative to the rainfed cropland area during the irrigation season. The multiple comparisons (fisher LSD) were tested and found that these two groups are different (pvalue=0.035 in 95% confidence interval). Therefore, by employing the maximum likelihood classification on the SSM data, we managed to map the irrigated agriculture. The overall accuracy of this unsupervised classification is 77%, with a kappa coefficient of 65%.
KW  - soil moisture
KW  - Sentinel-1
KW  - Sentinel-2
KW  - irrigation mapping
KW  - change detection
KW  - supervised learning
KW  - machine learning
DO  - 10.3390/su132011355
ER  -
TY  - EJOU
AU  - Wu, Meiyi
AU  - Zhang, Anmin
AU  - Gao, Miao
AU  - Zhang, Jiali
TI  - Ship Motion Planning for MASS Based on a Multi-Objective Optimization HA* Algorithm in Complex Navigation Conditions
T2  - Journal of Marine Science and Engineering

PY  - 2021
VL  - 9
IS  - 10
SN  - 2077-1312

AB  - Ship motion planning constitutes the most critical part in the autonomous navigation systems of marine autonomous surface ships (MASS). Weather and ocean conditions can significantly affect their navigation, but there are relatively few studies on the influence of wind and current on motion planning. This study investigates the motion planning problem for USV, wherein the goal is to obtain an optimal path under the interference of the navigation environment (wind and current), and control the USV in order to avoid obstacles and arrive at its destination without collision. In this process, the influences of search efficiency, navigation safety and energy consumption on motion planning are taken into consideration. Firstly, the navigation environment is constructed by integrating information, including the electronic navigational chart, wind and current field. Based on the environmental interference factors, the three-degree-of-freedom kinematic model of USVs is created, and the multi-objective optimization and complex constraints are reasonably expressed to establish the corresponding optimization model. A multi-objective optimization algorithm based on HA* is proposed after considering the constraints of motion and dynamic and optimization objectives. Simulation verifies the effectiveness of the algorithm, where an efficient, safe and economical path is obtained and is more in line with the needs of practical application.
KW  - motion planning
KW  - MASS
KW  - multi-objective optimization
KW  - complex navigation conditions
DO  - 10.3390/jmse9101126
ER  -
TY  - EJOU
AU  - Guo, Xuzhan
AU  - Liu, Qingwang
AU  - Sharma, Ram P.
AU  - Chen, Qiao
AU  - Ye, Qiaolin
AU  - Tang, Shouzheng
AU  - Fu, Liyong
TI  - Tree Recognition on the Plantation Using UAV Images with Ultrahigh Spatial Resolution in a Complex Environment
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - The survival rate of seedlings is a decisive factor of afforestation assessment. Generally, ground checking is more accurate than any other methods. However, the survival rate of seedlings can be higher in the growing season, and this can be estimated in a larger area at a relatively lower cost by extracting the tree crown from the unmanned aerial vehicle (UAV) images, which provides an opportunity for monitoring afforestation in an extensive area. At present, studies on extracting individual tree crowns under the complex ground vegetation conditions are limited. Based on the afforestation images obtained by airborne consumer-grade cameras in central China, this study proposes a method of extracting and fusing multiple radii morphological features to obtain the potential crown. A random forest (RF) was used to identify the regions extracted from the images, and then the recognized crown regions were fused selectively according to the distance. A low-cost individual crown recognition framework was constructed for rapid checking of planted trees. The method was tested in two afforestation areas of 5950 m2 and 5840 m2, with a population of 2418 trees (Koelreuteria) in total. Due to the complex terrain of the sample plot, high weed coverage, the crown width of trees, and spacing of saplings vary greatly, which increases both the difficulty and complexity of crown extraction. Nevertheless, recall and F-score of the proposed method reached 93.29%, 91.22%, and 92.24% precisions, respectively, and 2212 trees were correctly recognized and located. The results show that the proposed method is robust to the change of brightness and to splitting up of a multi-directional tree crown, and is an automatic solution for afforestation verification.
KW  - individual trees crown
KW  - multi-radius extraction
KW  - chromatic mapping
KW  - feature extraction
KW  - complex environment
KW  - spectral index
DO  - 10.3390/rs13204122
ER  -
TY  - EJOU
AU  - Hollenbeck, Derek
AU  - Zulevic, Demitrius
AU  - Chen, Yangquan
TI  - Advanced Leak Detection and Quantification of Methane Emissions Using sUAS
T2  - Drones

PY  - 2021
VL  - 5
IS  - 4
SN  - 2504-446X

AB  - Detecting and quantifying methane emissions is gaining an increasingly vital role in mitigating emissions for the oil and gas industry through early detection and repair and will aide our understanding of how emissions in natural ecosystems are playing a role in the global carbon cycle and its impact on the climate. Traditional methods of measuring and quantifying emissions utilize chamber methods, bagging individual equipment, or require the release of a tracer gas. Advanced leak detection techniques have been developed over the past few years, utilizing technologies, such as optical gas imaging, mobile surveyors equipped with sensitive cavity ring down spectroscopy (CRDS), and manned aircraft and satellite approaches. More recently, sUAS-based approaches have been developed to provide, in some ways, cheaper alternatives that also offer sensing advantages to traditional methods, including not being constrained to roadways and being able to access class G airspace (0–400 ft) where manned aviation cannot travel. This work looks at reviewing methods of quantifying methane emissions that can be, or are, carried out using small unmanned aircraft systems (sUAS) as well as traditional methods to provide a clear comparison for future practitioners. This includes the current limitations, capabilities, assumptions, and survey details. The suggested technique for LDAQ depends on the desired accuracy and is a function of the survey time and survey distance. Based on the complexity and precision, the most promising sUAS methods are the near-field Gaussian plume inversion (NGI) and the vertical flux plane (VFP), which have comparable accuracy to those found in conventional state-of-the-art methods.
KW  - advanced leak detection
KW  - advanced leak quantification
KW  - remote sensing
KW  - source estimation
KW  - environmental monitoring
KW  - landfill
KW  - natural gas
DO  - 10.3390/drones5040117
ER  -
TY  - EJOU
AU  - Bao, Wenxia
AU  - Ren, Yangxun
AU  - Wang, Nian
AU  - Hu, Gensheng
AU  - Yang, Xianjun
TI  - Detection of Abnormal Vibration Dampers on Transmission Lines in UAV Remote Sensing Images with PMA-YOLO
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - The accurate detection and timely replacement of abnormal vibration dampers on transmission lines are critical for the safe and stable operation of power systems. Recently, unmanned aerial vehicles (UAVs) have become widely used to inspect transmission lines. In this paper, we constructed a data set of abnormal vibration dampers (DAVDs) on transmission lines in images obtained by UAVs. There are four types of vibration dampers in this data set, and each vibration damper may be rusty, defective, or normal. The challenges in the detection of abnormal vibration dampers on transmission lines in the images captured by UAVs were as following: the images had a high resolution as well as the objects of vibration dampers were relatively small and sparsely distributed, and the backgrounds of cross stage partial networks of the images were complex due to the fact that the transmission lines were erected in a variety of outdoor environments. Existing methods of ground-based object detection significantly reduced the accuracy when dealing with complex backgrounds and small objects of abnormal vibration dampers detection. To address these issues, we proposed an end-to-end parallel mixed attention You Only Look Once (PMA-YOLO) network to improve the detection performance for abnormal vibration dampers. The parallel mixed attention (PMA) module was introduced and integrated into the YOLOv4 network. This module combines a channel attention block and a spatial attention block, and the convolution results of the input feature maps in parallel, allowing the network to pay more attention to critical regions of abnormal vibration dampers in complex background images. Meanwhile, in view of the problem that abnormal vibration dampers are prone to missing detections, we analyzed the scale and ratio of the ground truth boxes and used the K-means algorithm to re-cluster new anchors for abnormal vibration dampers in images. In addition, we introduced a multi-stage transfer learning strategy to improve the efficiency of the original training method and prevent overfitting by the network. The experimental results showed that the mAP@0.5 for PMA-YOLO in the detection of abnormal vibration dampers reached 93.8% on the test set of DAVD, 3.5% higher than that of YOLOv4. When the multi-stage transfer learning strategy was used, the mAP@0.5 was improved by a further 0.2%.
KW  - objective detection
KW  - vibration dampers
KW  - UAV remote sensing images
KW  - transmission lines
KW  - YOLOv4
KW  - attention mechanism
KW  - transfer learning
DO  - 10.3390/rs13204134
ER  -
TY  - EJOU
AU  - Zhou, Xuan
AU  - Ke, Ruimin
AU  - Yang, Hao
AU  - Liu, Chenxi
TI  - When Intelligent Transportation Systems Sensing Meets Edge Computing: Vision and Challenges
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 20
SN  - 2076-3417

AB  - The widespread use of mobile devices and sensors has motivated data-driven applications that can leverage the power of big data to benefit many aspects of our daily life, such as health, transportation, economy, and environment. Under the context of smart city, intelligent transportation systems (ITS), as a main building block of modern cities, and edge computing (EC), as an emerging computing service that targets addressing the limitations of cloud computing, have attracted increasing attention in the research community in recent years. It is well believed that the application of EC in ITS will have considerable benefits to transportation systems regarding efficiency, safety, and sustainability. Despite the growing trend in ITS and EC research, a big gap in the existing literature is identified: the intersection between these two promising directions has been far from well explored. In this paper, we focus on a critical part of ITS, i.e., sensing, and conducting a review on the recent advances in ITS sensing and EC applications in this field. The key challenges in ITS sensing and future directions with the integration of edge computing are discussed.
KW  - intelligent transportation systems
KW  - sensing technology
KW  - edge computing
KW  - traffic data
DO  - 10.3390/app11209680
ER  -
TY  - EJOU
AU  - Ahmad, Uzair
AU  - Alvino, Arturo
AU  - Marino, Stefano
TI  - A Review of Crop Water Stress Assessment Using Remote Sensing
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - Currently, the world is facing high competition and market risks in improving yield, crop illness, and crop water stress. This could potentially be addressed by technological advancements in the form of precision systems, improvements in production, and through ensuring the sustainability of development. In this context, remote-sensing systems are fully equipped to address the complex and technical assessment of crop production, security, and crop water stress in an easy and efficient way. They provide simple and timely solutions for a diverse set of ecological zones. This critical review highlights novel methods for evaluating crop water stress and its correlation with certain measurable parameters, investigated using remote-sensing systems. Through an examination of previous literature, technologies, and data, we review the application of remote-sensing systems in the analysis of crop water stress. Initially, the study presents the relationship of relative water content (RWC) with equivalent water thickness (EWT) and soil moisture crop water stress. Evapotranspiration and sun-induced chlorophyll fluorescence are then analyzed in relation to crop water stress using remote sensing. Finally, the study presents various remote-sensing technologies used to detect crop water stress, including optical sensing systems, thermometric sensing systems, land-surface temperature-sensing systems, multispectral (spaceborne and airborne) sensing systems, hyperspectral sensing systems, and the LiDAR sensing system. The study also presents the future prospects of remote-sensing systems in analyzing crop water stress and how they could be further improved.
KW  - crop water stress
KW  - hyperspectral
KW  - LiDAR
KW  - multispectral
KW  - optical sensing
KW  - remote sensing
KW  - sentinel-1
KW  - soil moisture
KW  - thermometric sensing
DO  - 10.3390/rs13204155
ER  -
TY  - EJOU
AU  - Muhadi, Nur A.
AU  - Abdullah, Ahmad F.
AU  - Bejo, Siti K.
AU  - Mahadi, Muhammad R.
AU  - Mijic, Ana
TI  - Deep Learning Semantic Segmentation for Water Level Estimation Using Surveillance Camera
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 20
SN  - 2076-3417

AB  - The interest in visual-based surveillance systems, especially in natural disaster applications, such as flood detection and monitoring, has increased due to the blooming of surveillance technology. In this work, semantic segmentation based on convolutional neural networks (CNN) was proposed to identify water regions from the surveillance images. This work presented two well-established deep learning algorithms, DeepLabv3+ and SegNet networks, and evaluated their performances using several evaluation metrics. Overall, both networks attained high accuracy when compared to the measurement data but the DeepLabv3+ network performed better than the SegNet network, achieving over 90% for overall accuracy and IoU metrics, and around 80% for boundary F1 score (BF score), respectively. When predicting new images using both trained networks, the results show that both networks successfully distinguished water regions from the background but the outputs from DeepLabv3+ were more accurate than the results from the SegNet network. Therefore, the DeepLabv3+ network was used for practical application using a set of images captured at five consecutive days in the study area. The segmentation result and water level markers extracted from light detection and ranging (LiDAR) data were overlaid to estimate river water levels and observe the water fluctuation. River water levels were predicted based on the elevation from the predefined markers. The proposed water level framework was evaluated according to Spearman’s rank-order correlation coefficient. The correlation coefficient was 0.91, which indicates a strong relationship between the estimated water level and observed water level. Based on these findings, it can be concluded that the proposed approach has high potential as an alternative monitoring system that offers water region information and water level estimation for flood management and related activities.
KW  - flood detection
KW  - deep learning
KW  - water level estimation
KW  - water segmentation
KW  - CCTV
KW  - CNN
DO  - 10.3390/app11209691
ER  -
TY  - EJOU
AU  - Fotouhi, Sakineh
AU  - Khayatzadeh, Saber
AU  - Pui, Wei X.
AU  - Damghani, Mahdi
AU  - Bodaghi, Mahdi
AU  - Fotouhi, Mohamad
TI  - Detection of Barely Visible Impact Damage in Polymeric Laminated Composites Using a Biomimetic Tactile Whisker
T2  - Polymers

PY  - 2021
VL  - 13
IS  - 20
SN  - 2073-4360

AB  - This is a novel investigation on the possibility of detecting barely visible impact damage (BVID) in composite materials by whisking across the surface via tactile whisker sensors that resemble rats’ whiskers. A series of drop tower low-velocity impact tests were performed on quasi-isotropic composite plates. The plates were made from unidirectional T800 carbon/MTM49-3 epoxy prepregs with the stacking sequence of [45/0/90/−45]4S. Investigating the specimens’ surface by the naked eye does not reveal any significant damage, rather than a small dent on the surface, with no tangible difference in the different impact energy levels. Ultrasonic C-scan observations showed the existence of BVID in all the impact energy levels, with an increasing trend in the damage size by increasing the impact energy level. The collected data from whisker sensors were analyzed using the support vector machine classifier, based on their vibrational properties, to identify the impacted region and classify the impact severity. It was observed that after training for 13 whisker contacts, the BVID severity can be classified with an accuracy of 100%. This is offering a new BVID detection technique, with a high potential for automation and high reliability that can be used as an alternative or combined with available inspection systems.
KW  - composite materials
KW  - damage detection
KW  - low velocity impact
KW  - whisker
KW  - ultrasonic
DO  - 10.3390/polym13203587
ER  -
TY  - EJOU
AU  - Huang, Zhaoyang
AU  - Wang, Feng
AU  - You, Hongjian
AU  - Hu, Yuxin
TI  - STC-Det: A Slender Target Detector Combining Shadow and Target Information in Optical Satellite Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - Object detection has made great progress. However, due to the unique imaging method of optical satellite remote sensing, the detection of slender targets is still insufficient. Specifically, the perspective of optical satellites is small, and the characteristics of slender targets are severely lost during imaging, resulting in insufficient detection task information; at the same time, the appearance of slender targets in the image is greatly affected by the satellite perspective, which is likely to cause insufficient generalization capabilities of conventional detection models. In response to these two points, we have made some improvements. First, in this paper, we introduce the shadow as auxiliary information to complement the trunk features of the target lost in imaging. Second, to reduce the impact of satellite perspective on imaging, in this paper, we use the characteristic that shadow information is not affected by satellite perspective to design STC-Det. STC-Det treats the shadow and the target as two different types of targets and uses the shadow information to assist the detection, reducing the impact of the satellite perspective on detection. Among them, in order to improve the performance of STC-Det, we propose an automatic matching method (AMM) of shadow and target and a feature fusion method (FFM). Finally, this paper proposes a new method to calculate the heatmaps of detectors, which verifies the effectiveness of the proposed network in a visual way. Experiments show that when the satellite perspective is variable, the precision of STC-Det is increased by 1.7%, and when the satellite perspective is small, the precision of STC-Det is increased by 5.2%.
KW  - optical satellite image
KW  - shadow
KW  - slender targets
KW  - object detection
DO  - 10.3390/rs13204183
ER  -
TY  - EJOU
AU  - Scalici, Massimiliano
AU  - Perrone, Michela
AU  - Battisti, Jacopo
AU  - Benedini, Livia
AU  - Malavasi, Marco
TI  - First Perceptions of Hydroperiod Mapping and Assessment of Shallow Waters in Coastal Landscapes by Drone-Based Monitoring Activities: A Remote-Sensing and GIS Approach
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 20
SN  - 2076-3417

AB  - Beyond the importance of ponds for aquatic and terrestrial life, pond networks seem to be crucial to providing a vital spatial resource in response to global climate change for all migrating and spreading taxa. Additionally, ponds offer sustainable solutions to issues of concern in water management, such as nutrient retention, rainfall interception, or carbon sequestration. Although the ecological role of shallow waters seems clear, significant work must be performed to set future guidelines and actions towards their conservation. The main aims of the present study are to (i) georeference all small temporary wetlands within the Tyrrhenian central Italy coastal area, (ii) evaluate their hydroperiod, and (iii) calculate their surface size variability. We found 137 wetlands, 53 of which were temporary and contained listed habitats. Each wetland’s status was assessed in relation to land use and proximity to stressors (e.g., urban centres, railways, roads) while observing the relationship between pond occurrence, lithology, and permeability. Amongst the detected wetlands, we selected and monitored 21 temporary ponds (homogeneously distributed within the study area) for 12 months using images collected by the non-professional drone Parrot Bebop 2. All images were then acquired in ArcGIS to georeference all temporary ponds. The analysis confirmed that the majority of the surveyed ponds are in close proximity to roads and tracks, which might have significant impacts on the preservation of such fragile habitats. Moreover, despite the wide variability of hydroperiod duration, the greater part of the pools fill with water in autumn and dry in summer, in alignment with the Mediterranean climate. This preliminary study allowed for the creation of the first temporary ponds’ database, which is useful for monitoring their status in central Italy and planning further studies to assess eventual detrimental effects caused by human-mediated activities.
KW  - environmental assessment
KW  - freshwater ecosystems’ conservation
KW  - Mediterranean wetlands
KW  - unmanned aerial vehicles (UAVs)
DO  - 10.3390/app11209773
ER  -
TY  - EJOU
AU  - Koay, Hong V.
AU  - Chuah, Joon H.
AU  - Chow, Chee-Onn
AU  - Chang, Yang-Lang
AU  - Yong, Keh K.
TI  - YOLO-RTUAV: Towards Real-Time Vehicle Detection through Aerial Images with Low-Cost Edge Devices
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Object detection in aerial images has been an active research area thanks to the vast availability of unmanned aerial vehicles (UAVs). Along with the increase of computational power, deep learning algorithms are commonly used for object detection tasks. However, aerial images have large variations, and the object sizes are usually small, rendering lower detection accuracy. Besides, real-time inferencing on low-cost edge devices remains an open-ended question. In this work, we explored the usage of state-of-the-art deep learning object detection on low-cost edge hardware. We propose YOLO-RTUAV, an improved version of YOLOv4-Tiny, as the solution. We benchmarked our proposed models with various state-of-the-art models on the VAID and COWC datasets. Our proposed model can achieve higher mean average precision (mAP) and frames per second (FPS) than other state-of-the-art tiny YOLO models, especially on a low-cost edge device such as the Jetson Nano 2 GB. It was observed that the Jetson Nano 2 GB can achieve up to 12.8 FPS with a model size of only 5.5 MB.
KW  - object detection
KW  - deep learning
KW  - aerial imaging
KW  - real-time detection
DO  - 10.3390/rs13214196
ER  -
TY  - EJOU
AU  - Fassnacht, Steven R.
TI  - A Call for More Snow Sampling
T2  - Geosciences

PY  - 2021
VL  - 11
IS  - 11
SN  - 2076-3263

AB  - The snowpack is important for water resources, tourism, ecology, and the global energy budget. Over the past century, we have gone from point measurements of snow water equivalent (SWE) to estimate spring and summer runoff volumes, to remote sensing of various snowpack properties at continuously finer spatial and temporal resolutions, to various complexities of snowpack and hydrological modeling, to the current fusion of field data with remote sensing and modeling, all to improve our estimates of the snowpack and the subsequent runoff. However, we are still limited by the uncertainty induced by scaling from point field measurements to the area represented by remote sensing and modeling. This paper uses several examples of fine-resolution sampling to issue a call to snow hydrologists and other earth scientists to collect more data, or at least to thoroughly evaluate their sampling strategy for collecting ground-truth measurements. Recommendations are provided for different approaches to have more representative sampling, when at all possible, to collect at least a few more samples or data points.
KW  - scaling
KW  - snow hydrology
KW  - sampling strategies
DO  - 10.3390/geosciences11110435
ER  -
TY  - EJOU
AU  - Atli, İbrahim
AU  - Ozturk, Metin
AU  - Valastro, Gianluca C.
AU  - Asghar, Muhammad Z.
TI  - Multi-Objective UAV Positioning Mechanism for Sustainable Wireless Connectivity in Environments with Forbidden Flying Zones
T2  - Algorithms

PY  - 2021
VL  - 14
IS  - 11
SN  - 1999-4893

AB  - A communication system based on unmanned aerial vehicles (UAVs) is a viable alternative for meeting the coverage and capacity needs of future wireless networks. However, because of the limitations of UAV-enabled communications in terms of coverage, energy consumption, and flying laws, the number of studies focused on the sustainability element of UAV-assisted networking in the literature was limited thus far. We present a solution to this problem in this study; specifically, we design a Q-learning-based UAV placement strategy for long-term wireless connectivity while taking into account major constraints such as altitude regulations, nonflight zones, and transmit power. The goal is to determine the best location for the UAV base station (BS) while reducing energy consumption and increasing the number of users covered. Furthermore, a weighting method is devised, allowing energy usage and the number of users served to be prioritized based on network/battery circumstances. The suggested Q-learning-based solution is contrasted to the standard k-means clustering method, in which the UAV BS is positioned at the centroid location with the shortest cumulative distance between it and the users. The results demonstrate that the proposed solution outperforms the baseline k-means clustering-based method in terms of the number of users covered while achieving the desired minimization of the energy consumption.
KW  - sustainable wireless connectivity
KW  - energy saving
KW  - UAV
KW  - communication system
KW  - 5G
KW  - positioning
KW  - reinforcement learning
DO  - 10.3390/a14110302
ER  -
TY  - EJOU
AU  - Jia, Jianxin
AU  - Sun, Haibin
AU  - Jiang, Changhui
AU  - Karila, Kirsi
AU  - Karjalainen, Mika
AU  - Ahokas, Eero
AU  - Khoramshahi, Ehsan
AU  - Hu, Peilun
AU  - Chen, Chen
AU  - Xue, Tianru
AU  - Wang, Tinghuai
AU  - Chen, Yuwei
AU  - Hyyppä, Juha
TI  - Review on Active and Passive Remote Sensing Techniques for Road Extraction
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Digital maps of road networks are a vital part of digital cities and intelligent transportation. In this paper, we provide a comprehensive review on road extraction based on various remote sensing data sources, including high-resolution images, hyperspectral images, synthetic aperture radar images, and light detection and ranging. This review is divided into three parts. Part 1 provides an overview of the existing data acquisition techniques for road extraction, including data acquisition methods, typical sensors, application status, and prospects. Part 2 underlines the main road extraction methods based on four data sources. In this section, road extraction methods based on different data sources are described and analysed in detail. Part 3 presents the combined application of multisource data for road extraction. Evidently, different data acquisition techniques have unique advantages, and the combination of multiple sources can improve the accuracy of road extraction. The main aim of this review is to provide a comprehensive reference for research on existing road extraction technologies.
KW  - road extraction
KW  - high-resolution image
KW  - hyperspectral image
KW  - synthetic aperture radar (SAR)
KW  - light detection and ranging (LiDAR)
DO  - 10.3390/rs13214235
ER  -
TY  - EJOU
AU  - Alvites, Cesar
AU  - Santopuoli, Giovanni
AU  - Hollaus, Markus
AU  - Pfeifer, Norbert
AU  - Maesano, Mauro
AU  - Moresi, Federico V.
AU  - Marchetti, Marco
AU  - Lasserre, Bruno
TI  - Terrestrial Laser Scanning for Quantifying Timber Assortments from Standing Trees in a Mixed and Multi-Layered Mediterranean Forest
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Timber assortments are some of the most important goods provided by forests worldwide. To quantify the amount and type of timber assortment is strongly important for socio-economic purposes, but also for accurate assessment of the carbon stored in the forest ecosystems, regardless of their main function. Terrestrial laser scanning (TLS) became a promising tool for timber assortment assessment compared to the traditional surveys, allowing reconstructing the tree architecture directly and rapidly. This study aims to introduce an approach for timber assortment assessment using TLS data in a mixed and multi-layered Mediterranean forest. It consists of five steps: (1) pre-processing, (2) timber-leaf discrimination, (3) stem detection, (4) stem reconstruction, and (5) timber assortment assessment. We assume that stem form drives the stem reconstruction, and therefore, it influences the timber assortment assessment. Results reveal that the timber-leaf discrimination accuracy is 0.98 through the Random Forests algorithm. The overall detection rate for all trees is 84.4%, and all trees with a diameter at breast height larger than 0.30 m are correctly identified. Results highlight that the main factors hindering stem reconstruction are the presence of defects outside the trunk, trees poorly covered by points, and the stem form. We expect that the proposed approach is a starting point for valorising the timber resources from unmanaged/managed forests, e.g., abandoned forests. Further studies to calibrate its performance under different forest stand conditions are furtherly required.
KW  - timber assortment
KW  - roundwood
KW  - mixed-species
KW  - point cloud
KW  - stem modelling
DO  - 10.3390/rs13214265
ER  -
TY  - EJOU
AU  - Yu, Jin-Woo
AU  - Yoon, Young-Woong
AU  - Baek, Won-Kyung
AU  - Jung, Hyung-Sup
TI  - Forest Vertical Structure Mapping Using Two-Seasonal Optic Images and LiDAR DSM Acquired from UAV Platform through Random Forest, XGBoost, and Support Vector Machine Approaches
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Research on the forest structure classification is essential, as it plays an important role in assessing the vitality and diversity of vegetation. However, classifying forest structure involves in situ surveying, which requires considerable time and money, and cannot be conducted directly in some instances; also, the update cycle of the classification data is very late. To overcome these drawbacks, feasibility studies on mapping the forest vertical structure from aerial images using machine learning techniques were conducted. In this study, we investigated (1) the performance improvement of the forest structure classification, using a high-resolution LiDAR-derived digital surface model (DSM) acquired from an unmanned aerial vehicle (UAV) platform and (2) the performance comparison of results obtained from the single-seasonal and two-seasonal data, using random forest (RF), extreme gradient boosting (XGBoost), and support vector machine (SVM). For the performance comparison, the UAV optic and LiDAR data were divided into three cases: (1) only used autumn data, (2) only used winter data, and (3) used both autumn and winter data. From the results, the best model was XGBoost, and the F1 scores achieved using this method were approximately 0.92 in the autumn and winter cases. A remarkable improvement was achieved when both two-seasonal images were used. The F1 score improved by 35.3% from 0.68 to 0.92. This implies that (1) the seasonal variation in the forest vertical structure can be more important than the spatial resolution, and (2) the classification performance achieved from the two-seasonal UAV optic images and LiDAR-derived DSMs can reach 0.9 with the application of an optimal machine learning approach.
KW  - forest vertical structure
KW  - multiseason
KW  - machine learning
KW  - classification
DO  - 10.3390/rs13214282
ER  -
TY  - EJOU
AU  - El-Askary, Hesham
AU  - Fawzy, Amr
AU  - Thomas, Rejoice
AU  - Li, Wenzhao
AU  - LaHaye, Nicholas
AU  - Linstead, Erik
AU  - Piechota, Thomas
AU  - Struppa, Daniele
AU  - Sayed, Mohamed A.
TI  - Assessing the Vertical Displacement of the Grand Ethiopian Renaissance Dam during Its Filling Using DInSAR Technology and Its Potential Acute Consequences on the Downstream Countries
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - The Grand Ethiopian Renaissance Dam (GERD), formerly known as the Millennium Dam, is currently under construction and has been filling at a fast rate without sufficient known analysis on possible impacts on the body of the structure. The filling of GERD not only has an impact on the Blue Nile Basin hydrology, water storage and flow but also poses massive risks in case of collapse. Rosaries Dam located in Sudan at only 116 km downstream of GERD, along with the 20 million Sudanese benefiting from that dam, would be seriously threatened in case of the collapse of GERD. In this study, through the analysis of Sentinal-1 satellite imagery, we show concerning deformation patterns associated with different sections of the GERD’s Main Dam (structure RCC Dam type) and the Saddle Dam (Embankment Dam type). We processed 109 descending mode scenes from Sentinel-1 SAR imagery, from December 2016 to July 2021, using the Differential Synthetic Aperture Radar Interferometry technique to demonstrate the deformation trends of both—the GERD’s Main and Saddle Dams. The time series generated from the analysis clearly indicates different displacement trends at various sections of the GERD as well as the Saddle Dam. Results of the multi-temporal data analysis on and around the project area show inconsistent subsidence at the extremities of the GERD Main Dam, especially the west side of the dam where we recorded varying displacements in the range of 10 mm to 90 mm at the crest of the dam. We conducted the current analysis after masking the images with a coherence value of 0.9 and hence, the subsequent results are extremely reliable and accurate. Further decomposition of the subsiding rate has revealed higher vertical displacement over the west side of the GERD’s Main Dam as compared to the east side. The local geological structures consisting of weak zones under the GERD’s accompanying Saddle Dam adds further instability to its structure. We identified seven critical nodes on the Saddle Dam that match the tectonic faults lying underneath it, and which display a varying degree of vertical displacements. In fact, the nodes located next to each other displayed varying displacement trends: one or more nodes displayed subsidence since 2017 while the other node in the same section displayed uplift. The geological weak zones underneath and the weight of the Saddle Dam itself may somewhat explain this inconsistency and the non-uniform vertical displacements. For the most affected cells, we observed a total displacement value of ~90 mm during the whole study period (~20 mm/year) for the Main Dam while the value of the total displacement for the Saddle dam is ~380 mm during the same period (~85 mm/year). Analysis through CoastSat tool also suggested a non-uniformity in trends of surface water-edge at the two extremities of the Main Dam.
KW  - Grand Ethiopian Renaissance Dam
KW  - Main and Saddle Dams
KW  - ground displacement
KW  - Sentinel-1
KW  - dam filling
KW  - geological structures
DO  - 10.3390/rs13214287
ER  -
TY  - EJOU
AU  - Zhao, Genping
AU  - Zhang, Weiguang
AU  - Peng, Yeping
AU  - Wu, Heng
AU  - Wang, Zhuowei
AU  - Cheng, Lianglun
TI  - PEMCNet: An Efficient Multi-Scale Point Feature Fusion Network for 3D LiDAR Point Cloud Classification
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Point cloud classification plays a significant role in Light Detection and Ranging (LiDAR) applications. However, most available multi-scale feature learning networks for large-scale 3D LiDAR point cloud classification tasks are time-consuming. In this paper, an efficient deep neural architecture denoted as Point Expanded Multi-scale Convolutional Network (PEMCNet) is developed to accurately classify the 3D LiDAR point cloud. Different from traditional networks for point cloud processing, PEMCNet includes successive Point Expanded Grouping (PEG) units and Absolute and Relative Spatial Embedding (ARSE) units for representative point feature learning. The PEG unit enables us to progressively increase the receptive field for each observed point and aggregate the feature of a point cloud at different scales but without increasing computation. The ARSE unit following the PEG unit furthermore realizes representative encoding of points relationship, which effectively preserves the geometric details between points. We evaluate our method on both public datasets (the Urban Semantic 3D (US3D) dataset and Semantic3D benchmark dataset) and our new collected Unmanned Aerial Vehicle (UAV) based LiDAR point cloud data of the campus of Guangdong University of Technology. In comparison with four available state-of-the-art methods, our methods ranked first place regarding both efficiency and accuracy. It was observed on the public datasets that with a 2% increase in classification accuracy, over 26% improvement of efficiency was achieved at the same time compared to the second efficient method. Its potential value is also tested on the newly collected point cloud data with over 91% of classification accuracy and 154 ms of processing time.
KW  - LiDAR
KW  - point cloud
KW  - classification
KW  - deep learning
DO  - 10.3390/rs13214312
ER  -
TY  - EJOU
AU  - Hu, Kai
AU  - Chen, Xu
AU  - Xia, Qingfeng
AU  - Jin, Junlan
AU  - Weng, Liguo
TI  - A Control Algorithm for Sea&ndash;Air Cooperative Observation Tasks Based on a Data-Driven Algorithm
T2  - Journal of Marine Science and Engineering

PY  - 2021
VL  - 9
IS  - 11
SN  - 2077-1312

AB  - There is tremendous demand for marine environmental observation, which requires the development of a multi-agent cooperative observation algorithm to guide Unmanned Surface Vehicles (USVs) and Unmanned Aerial Vehicles (UAVs) to observe isotherm data of the mesoscale vortex. The task include two steps: firstly, USVs search out the isotherm, navigate independently along the isotherm, and collect marine data; secondly, a UAV takes off, and in its one round trip, the UAV and USVs jointly perform the task of the UAV reading the observation data from USVs. In this paper, aiming at the first problem of the USV following the isotherm in an unknown environment, a data-driven Deep Deterministic Policy Gradient (DDPG) control algorithm is designed that allows USVs to navigate independently along isotherms in unknown environments. In addition, a hybrid cooperative control algorithm based on a multi-agent DDPG is adopted to solve the second problem, which enables USVs and a UAV to complete data reading tasks with the shortest flight distance of the UAV. The experimental simulation results show that the trained system can complete this tas, with good stability and accuracy.
KW  - sea and air observation
KW  - multi-agent collaboration
KW  - data-driven
KW  - deep reinforcement learning
DO  - 10.3390/jmse9111189
ER  -
TY  - EJOU
AU  - Lai, Joon-Keat
AU  - Lin, Wen-Shin
TI  - Assessment of the Rice Panicle Initiation by Using NDVI-Based Vegetation Indexes
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 21
SN  - 2076-3417

AB  - The assessment of rice panicle initiation is crucial for the management of nitrogen fertilizer application that affects yield and quality of grain. The occurrence of panicle initiation could be determined via either green ring, internode-elongation, or a 1–2 mm panicle, and was observed through manual dissection. The quadratic polynomial regression model was used to construct the model of the trend of normalized difference vegetation index-based vegetation indexes (NDVI-based VIs) between pre-tillering and panicle differentiation stages. The slope of the quadratic polynomial regression model tended to be alleviated in the period in which the panicle initiation stage should occur. The results indicated that the trend of the NDVI-based VIs was correlated with panicle initiation. NDVI-based VIs could be a useful indicator to remotely assess panicle initiation.
KW  - hyperspectral
KW  - proximal sensing
KW  - panicle initiation
KW  - normalized difference vegetation index (NDVI)
KW  - green ring
KW  - internode-elongation
DO  - 10.3390/app112110076
ER  -
TY  - EJOU
AU  - Xiang, Xuanchen
AU  - Foo, Simon
AU  - Zang, Huanyu
TI  - Recent Advances in Deep Reinforcement Learning Applications for Solving Partially Observable Markov Decision Processes (POMDP) Problems Part 2—Applications in Transportation, Industries, Communications and Networking and More Topics
T2  - Machine Learning and Knowledge Extraction

PY  - 2021
VL  - 3
IS  - 4
SN  - 2504-4990

AB  - The two-part series of papers provides a survey on recent advances in Deep Reinforcement Learning (DRL) for solving partially observable Markov decision processes (POMDP) problems. Reinforcement Learning (RL) is an approach to simulate the human’s natural learning process, whose key is to let the agent learn by interacting with the stochastic environment. The fact that the agent has limited access to the information of the environment enables AI to be applied efficiently in most fields that require self-learning. It’s essential to have an organized investigation—we can make good comparisons and choose the best structures or algorithms when applying DRL in various applications. The first part of the overview introduces Markov Decision Processes (MDP) problems and Reinforcement Learning and applications of DRL for solving POMDP problems in games, robotics, and natural language processing. In part two, we continue to introduce applications in transportation, industries, communications and networking, etc. and discuss the limitations of DRL.
KW  - reinforcement learning
KW  - deep reinforcement learning
KW  - Markov decision process
KW  - partially observable markov decision process
DO  - 10.3390/make3040043
ER  -
TY  - EJOU
AU  - Rominger, Kody R.
AU  - Meyer, Susan E.
TI  - Drones, Deep Learning, and Endangered Plants: A Method for Population-Level Census Using Image Analysis
T2  - Drones

PY  - 2021
VL  - 5
IS  - 4
SN  - 2504-446X

AB  - A census of endangered plant populations is critical to determining their size, spatial distribution, and geographical extent. Traditional, on-the-ground methods for collecting census data are labor-intensive, time-consuming, and expensive. Use of drone imagery coupled with application of rapidly advancing deep learning technology could greatly reduce the effort and cost of collecting and analyzing population-level data across relatively large areas. We used a customization of the YOLOv5 object detection model to identify and count individual dwarf bear poppy (Arctomecon humilis) plants in drone imagery obtained at 40 m altitude. We compared human-based and model-based detection at 40 m on n = 11 test plots for two areas that differed in image quality. The model out-performed human visual poppy detection for precision and recall, and was 1100× faster at inference/evaluation on the test plots. Model inference precision was 0.83, and recall was 0.74, while human evaluation resulted in precision of 0.67, and recall of 0.71. Both model and human performance were better in the area with higher-quality imagery, suggesting that image quality is a primary factor limiting model performance. Evaluation of drone-based census imagery from the 255 ha Webb Hill population with our customized YOLOv5 model was completed in &lt;3 h and provided a reasonable estimate of population size (7414 poppies) with minimal investment of on-the-ground resources.
KW  - AI (artificial intelligence)
KW  - Arctomecon humilis
KW  - census
KW  - drone
KW  - dwarf bear poppy
KW  - endangered plant species
KW  - UAS (unmanned aerial system)
KW  - YOLOv5
DO  - 10.3390/drones5040126
ER  -
TY  - EJOU
AU  - Schulze-Brüninghoff, Damian
AU  - Wachendorf, Michael
AU  - Astor, Thomas
TI  - Potentials and Limitations of WorldView-3 Data for the Detection of Invasive Lupinus polyphyllus Lindl. in Semi-Natural Grasslands
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Semi-natural grasslands contribute highly to biodiversity and other ecosystem services, but they are at risk by the spread of invasive plant species, which alter their habitat structure. Large area grassland monitoring can be a powerful tool to manage invaded ecosystems. Therefore, WorldView-3 multispectral sensor data was utilized to train multiple machine learning algorithms in an automatic machine learning workflow called ‘H2O AutoML’ to detect L. polyphyllus in a nature protection grassland ecosystem. Different degree of L. polyphyllus cover was collected on 3 × 3 m2 reference plots, and multispectral bands, indices, and texture features were used in a feature selection process to identify the most promising classification model and machine learning algorithm based on mean per class error, log loss, and AUC metrics. The best performance was achieved with a binary classification of lupin-free vs. fully invaded 3 × 3 m2 plot classification with a set of 7 features out of 763. The findings reveal that L. polyphyllus detection from WorldView-3 sensor data is limited to large dominant spots and not recommendable for lower plant coverage, especially single plant detection. Further research is needed to clarify if different phenological stages of L. polyphyllus as well as time series increase classification performance.
KW  - invasive species
KW  - WorldView-3
KW  - grassland
KW  - machine learning
KW  - feature selection
DO  - 10.3390/rs13214333
ER  -
TY  - EJOU
AU  - Khan, Rabia M.
AU  - Salehi, Bahram
AU  - Mahdianpari, Masoud
AU  - Mohammadimanesh, Fariba
AU  - Mountrakis, Giorgos
AU  - Quackenbush, Lindi J.
TI  - A Meta-Analysis on Harmful Algal Bloom (HAB) Detection and Monitoring: A Remote Sensing Perspective
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Algae serves as a food source for a wide range of aquatic species; however, a high concentration of inorganic nutrients under favorable conditions can result in the development of harmful algal blooms (HABs). Many studies have addressed HAB detection and monitoring; however, no global scale meta-analysis has specifically explored remote sensing-based HAB monitoring. Therefore, this manuscript elucidates and visualizes spatiotemporal trends in HAB detection and monitoring using remote sensing methods and discusses future insights through a meta-analysis of 420 journal articles. The results indicate an increase in the quantity of published articles which have facilitated the analysis of sensors, software, and HAB proxy estimation methods. The comparison across multiple studies highlighted the need for a standardized reporting method for HAB proxy estimation. Research gaps include: (1) atmospheric correction methods, particularly for turbid waters, (2) the use of analytical-based models, (3) the application of machine learning algorithms, (4) the generation of harmonized virtual constellation and data fusion for increased spatial and temporal resolutions, and (5) the use of cloud-computing platforms for large scale HAB detection and monitoring. The planned hyperspectral satellites will aid in filling these gaps to some extent. Overall, this review provides a snapshot of spatiotemporal trends in HAB monitoring to assist in decision making for future studies.
KW  - harmful algal blooms (HABs)
KW  - meta-analysis
KW  - phytoplankton
KW  - remote sensing
KW  - water quality
DO  - 10.3390/rs13214347
ER  -
TY  - EJOU
AU  - Aguilar, Fernando J.
AU  - Nemmaoui, Abderrahim
AU  - Aguilar, Manuel A.
AU  - Peñalver, Alberto
TI  - Building Tree Allometry Relationships Based on TLS Point Clouds and Machine Learning Regression
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 21
SN  - 2076-3417

AB  - Most of the allometric models used to estimate tree aboveground biomass rely on tree diameter at breast height (DBH). However, it is difficult to measure DBH from airborne remote sensors, and is common to draw upon traditional least squares linear regression models to relate DBH with dendrometric variables measured from airborne sensors, such as tree height (H) and crown diameter (CD). This study explores the usefulness of ensemble-type supervised machine learning regression algorithms, such as random forest regression (RFR), categorical boosting (CatBoost), gradient boosting (GBoost), or AdaBoost regression (AdaBoost), as an alternative to linear regression (LR) for modelling the allometric relationships DBH = Φ(H) and DBH = Ψ(H, CD). The original dataset was made up of 2272 teak trees (Tectona grandis Linn. F.) belonging to three different plantations located in Ecuador. All teak trees were digitally reconstructed from terrestrial laser scanning point clouds. The results showed that allometric models involving both H and CD to estimate DBH performed better than those based solely on H. Furthermore, boosting machine learning regression algorithms (CatBoost and GBoost) outperformed RFR (bagging) and LR (traditional linear regression) models, both in terms of goodness-of-fit (R2) and stability (variations in training and testing samples).
KW  - terrestrial laser scanning
KW  - allometric models
KW  - machine learning regression
KW  - teak plantations
KW  - forest inventory
DO  - 10.3390/app112110139
ER  -
TY  - EJOU
AU  - Raza, Wamiq
AU  - Osman, Anas
AU  - Ferrini, Francesco
AU  - Natale, Francesco D.
TI  - Energy-Efficient Inference on the Edge Exploiting TinyML Capabilities for UAVs
T2  - Drones

PY  - 2021
VL  - 5
IS  - 4
SN  - 2504-446X

AB  - In recent years, the proliferation of unmanned aerial vehicles (UAVs) has increased dramatically. UAVs can accomplish complex or dangerous tasks in a reliable and cost-effective way but are still limited by power consumption problems, which pose serious constraints on the flight duration and completion of energy-demanding tasks. The possibility of providing UAVs with advanced decision-making capabilities in an energy-effective way would be extremely beneficial. In this paper, we propose a practical solution to this problem that exploits deep learning on the edge. The developed system integrates an OpenMV microcontroller into a DJI Tello Micro Aerial Vehicle (MAV). The microcontroller hosts a set of machine learning-enabled inference tools that cooperate to control the navigation of the drone and complete a given mission objective. The goal of this approach is to leverage the new opportunistic features of TinyML through OpenMV including offline inference, low latency, energy efficiency, and data security. The approach is successfully validated on a practical application consisting of the onboard detection of people wearing protection masks in a crowded environment.
KW  - UAVs
KW  - energy efficiency
KW  - TinyML
KW  - microcontrollers
KW  - machine learning
KW  - deep learning
KW  - edge computing
DO  - 10.3390/drones5040127
ER  -
TY  - EJOU
AU  - Gopi, Sudheesh P.
AU  - Magarini, Maurizio
AU  - Alsamhi, Saeed H.
AU  - Shvetsov, Alexey V.
TI  - Machine Learning-Assisted Adaptive Modulation for Optimized Drone-User Communication in B5G
T2  - Drones

PY  - 2021
VL  - 5
IS  - 4
SN  - 2504-446X

AB  - The fundamental issue for Beyond fifth Generation (B5G) is providing a pervasive connection to heterogeneous and various devices in smart environments. Therefore, Drones play a vital role in the B5G, allowing for wireless broadcast and high-speed communications. In addition, the drone offers several advantages compared to fixed terrestrial communications, including flexible deployment, robust Line of Sight (LoS) connections, and more design degrees of freedom due to controlled mobility. Drones can provide reliable and high data rate connectivity to users irrespective of their location. However, atmospheric disturbances impact the signal quality between drones and users and degrade the system performance. Considering practical implementation, the location of drones makes the drone–user communication susceptible to several environmental disturbances. In this paper, we evaluate the performance of drone-user connectivity during atmospheric disturbances. Further, a Machine Learning (ML)-assisted algorithm is proposed to adapt to a modulation technique that offers optimal performance during atmospheric disturbances. The results show that, with the algorithm, the system switches to a lower order modulation scheme during higher rain rate and provides reliable communication with optimized data rate and error performance.
KW  - drone
KW  - adaptive modulation
KW  - K-means clustering
KW  - B5G
KW  - machine learning
DO  - 10.3390/drones5040128
ER  -
TY  - EJOU
AU  - Csákvári, Edina
AU  - Halassy, Melinda
AU  - Enyedi, Attila
AU  - Gyulai, Ferenc
AU  - Berke, József
TI  - Is Einkorn Wheat (Triticum monococcum L.) a Better Choice than Winter Wheat (Triticum aestivum L.)? Wheat Quality Estimation for Sustainable Agriculture Using Vision-Based Digital Image Analysis
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 21
SN  - 2071-1050

AB  - Einkorn wheat (Triticum monococcum L. ssp. monococcum) plays an increasingly important role in agriculture, promoted by organic farming. Although the number of comparative studies about modern and ancient types of wheats is increasing, there are still some knowledge gaps about the nutritional and health benefit differences between ancient and modern bread wheats. The aim of the present study was to compare ancient, traditional and modern wheat cultivars—including a field study and a laboratory stress experiment using vision-based digital image analysis—and to assess the feasibility of imaging techniques. Our study shows that modern winter wheat had better yield and grain quality compared to einkorn wheats, but the latter were not far behind; thus the cultivation of various species could provide a diverse and sustainable agriculture which contributes to higher agrobiodiversity. The results also demonstrate that digital image analysis could be a viable alternate method for the real-time estimation of aboveground biomass and for predicting yield and grain quality parameters. Digital area outperformed other digital variables in biomass prediction in relation to drought stress, but height and Feret’s diameter better correlated with yield and grain quality parameters. Based on these results we suggest that the combination of various vision-based methods could improve the performance estimation of modern and ancient types of wheat in a non-destructive and real-time manner.
KW  - agrobiodiversity
KW  - ecological farming
KW  - einkorn
KW  - winter wheat
KW  - RGB image
KW  - digital image processing
KW  - aboveground biomass
DO  - 10.3390/su132112005
ER  -
TY  - EJOU
AU  - Lan, Yubin
AU  - Huang, Kanghua
AU  - Yang, Chang
AU  - Lei, Luocheng
AU  - Ye, Jiahang
AU  - Zhang, Jianling
AU  - Zeng, Wen
AU  - Zhang, Yali
AU  - Deng, Jizhong
TI  - Real-Time Identification of Rice Weeds by UAV Low-Altitude Remote Sensing Based on Improved Semantic Segmentation Model
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Real-time analysis of UAV low-altitude remote sensing images at airborne terminals facilitates the timely monitoring of weeds in the farmland. Aiming at the real-time identification of rice weeds by UAV low-altitude remote sensing, two improved identification models, MobileNetV2-UNet and FFB-BiSeNetV2, were proposed based on the semantic segmentation models U-Net and BiSeNetV2, respectively. The MobileNetV2-UNet model focuses on reducing the amount of calculation of the original model parameters, and the FFB-BiSeNetV2 model focuses on improving the segmentation accuracy of the original model. In this study, we first tested and compared the segmentation accuracy and operating efficiency of the models before and after the improvement on the computer platform, and then transplanted the improved models to the embedded hardware platform Jetson AGX Xavier, and used TensorRT to optimize the model structure to improve the inference speed. Finally, the real-time segmentation effect of the two improved models on rice weeds was further verified through the collected low-altitude remote sensing video data. The results show that on the computer platform, the MobileNetV2-UNet model reduced the amount of network parameters, model size, and floating point calculations by 89.12%, 86.16%, and 92.6%, and the inference speed also increased by 2.77 times, when compared with the U-Net model. The FFB-BiSeNetV2 model improved the segmentation accuracy compared with the BiSeNetV2 model and achieved the highest pixel accuracy and mean Intersection over Union ratio of 93.09% and 80.28%. On the embedded hardware platform, the optimized MobileNetV2-UNet model and FFB-BiSeNetV2 model inferred 45.05 FPS and 40.16 FPS for a single image under the weight accuracy of FP16, respectively, both meeting the performance requirements of real-time identification. The two methods proposed in this study realize the real-time identification of rice weeds under low-altitude remote sensing by UAV, which provide a reference for the subsequent integrated operation of plant protection drones in real-time rice weed identification and precision spraying.
KW  - low-altitude remote sensing
KW  - semantic segmentation model
KW  - real-time
KW  - rice weeds
KW  - target spraying
DO  - 10.3390/rs13214370
ER  -
TY  - EJOU
AU  - Stolle, Lorena
AU  - Corte, Ana P.
AU  - Sanquetta, Carlos R.
AU  - Behling, Alexandre
AU  - Hentz, Ângela M.
AU  - Eisfeld, Rozane D.
TI  - Predicting Stand Volume by Number of Trees Automatically Detected in UAV Images: An Alternative Method for Forest Inventory
T2  - Forests

PY  - 2021
VL  - 12
IS  - 11
SN  - 1999-4907

AB  - In this study, we estimate the forest stock volume by multiplying the number of trees detected remotely by the estimated mean individual volume of the population (individual approach). A comparison was made with the conventional inventory method (area approach), which included 100 simulations of a simple random sampling process and a Bootstrap resampling. The study area included three stands: stand 1, 16-year-old pine; stand 2, 7-year-old pine; and stand 3, 5-year-old eucalyptus. A census was carried out in each stand for the variables diameter and total height. Individual volume was estimated by a ratio estimator, and the sum of all volumes was considered as the total parametric volume. The area approach presented parametric values within the confidence interval for 91%, 94%, and 98% of the simulations for the three stands, respectively. The mean relative errors for the area approach were −3.5% for stand 1, 0.3% for stand 2, and −0.9% for stand 3. The errors in stands 1 and 3 were associated with the spatial distribution of the volume. The individual approach proved to be efficient for all stands, and their respective parametric values were within the confidence interval. The relative errors were 1% for stand 1, −0.7% for stand 2, and 1.8% for stand 3. For stand 1 and 3, this approach yielded better results than the mean values obtained by the area approach simulations (Bootstrap resampling). Future research should evaluate other remote sources of data and other forest conditions.
KW  - RPA (remotely piloted aircraft)
KW  - CHM (canopy height model)
KW  - tree detection
DO  - 10.3390/f12111508
ER  -
TY  - EJOU
AU  - Marinoudi, Vasso
AU  - Lampridi, Maria
AU  - Kateris, Dimitrios
AU  - Pearson, Simon
AU  - Sørensen, Claus G.
AU  - Bochtis, Dionysis
TI  - The Future of Agricultural Jobs in View of Robotization
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 21
SN  - 2071-1050

AB  - Robotics and computerization have drastically changed the agricultural production sector and thus moved it into a new automation era. Robots have historically been used for carrying out routine tasks that require physical strength, accuracy, and repeatability, whereas humans are used to engage with more value-added tasks that need reasoning and decision-making skills. On the other hand, robots are also increasingly exploited in several non-routine tasks that require cognitive skills. This technological evolution will create a fundamental and an unavoidable transformation of the agricultural occupations landscape with a high social and economic impact in terms of jobs creation and jobs destruction. To that effect, the aim of the present work is two-fold: (a) to map agricultural occupations in terms of their cognitive/manual and routine/non-routine characteristics and (b) to assess the susceptibility of each agricultural occupation to robotization. Seventeen (17) agricultural occupations were reviewed in relation to the characteristics of each individual task they entail and mapped onto a two-dimensional space representing the manual versus cognitive nature and the routine versus non-routine nature of an occupation. Subsequently, the potential for robotization was investigated, again concerning each task individually, and resulted in a weighted average potential adoption rate for each one of the agricultural occupations. It can be concluded that most of the occupations entail manual tasks that need to be performed in a standardised manner. Considering also that almost 81% of the agricultural work force is involved with these activities, it turns out that there is strong evidence for possible robotization of 70% of the agricultural domain, which, in turn, could affect 56% of the total annual budget dedicated to agricultural occupations. The presented work silhouettes the expected transformation of occupational landscape in agricultural production as an effort for a subsequent identification of social threats in terms of unemployment and job and wages polarization, among others, but also of opportunities in terms of emerged skills and training requirements for a social sustainable development of agricultural domain.
KW  - agricultural robots
KW  - tasks automatization
KW  - occupations classification
KW  - human-robot substitution
KW  - human-robot complementarity
DO  - 10.3390/su132112109
ER  -
TY  - EJOU
AU  - Filippi, Margaux
AU  - Hanlon, Regina
AU  - Rypina, Irina I.
AU  - Hodges, Benjamin A.
AU  - Peacock, Thomas
AU  - Schmale, David G.
TI  - Tracking a Surrogate Hazardous Agent (Rhodamine Dye) in a Coastal Ocean Environment Using In Situ Measurements and Concentration Estimates Derived from Drone Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - New tools and technology are needed to track hazardous agents such as oil and red tides in our oceans. Rhodamine dye (a surrogate hazardous agent) was released into the Atlantic ocean in August 2018, and experiments were conducted to track the movement of the dye near the water surface within three hours following the release. A DrOne Water Sampling SystEm (DOWSE), consisting of a 3D-printed sampling device tethered to a drone, was used to collect 26 water samples at different locations around the dye plume. Rhodamine concentrations were measured from the drone water samples using a fluorometer and ranged from 1 to 93 ppb. Dye images were taken during the drone-sampling of surface water containing dye and at about 10 m above the sampling point. These images were post-processed to estimate dye concentrations across the sampling domain. A comparison of calibrated heat maps showed that the altitude images yielded dye distributions that were qualitatively similar to those from images taken near the ocean surface. Moreover, the association between red ratios and dye concentrations yielded trendlines explaining up to 67% of the variation. Drones may be used to detect, track and assist in mitigating hazardous agents in the future.
KW  - UAS
KW  - drone
KW  - fluorescent dye
KW  - rhodamine
KW  - transport
KW  - hazardous agents
KW  - plume
KW  - unmanned systems
DO  - 10.3390/rs13214415
ER  -
TY  - EJOU
AU  - Jang, Keunyoung
AU  - Kim, Jong-Woo
AU  - Ju, Ki-Beom
AU  - An, Yun-Kyu
TI  - Infrastructure BIM Platform for Lifecycle Management
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 21
SN  - 2076-3417

AB  - Recently, the application of the BIM technique to infrastructure lifecycle management has increased rapidly to improve the efficiency of infrastructure management systems. Research on the lifecycle management of infrastructure, from planning and design to construction and management, has been carried out. Therefore, a systematic review of the literature on recent research is performed to analyze the current state of the BIM technique. State-of-the-art techniques for infrastructure lifecycle management, such as unmanned robots, sensors and processing techniques, artificial intelligence, etc., are also reviewed. An infrastructure BIM platform framework composed of BIM and state-of-the-art techniques is then proposed. The proposed platform is a web-based platform that contains quantity, schedule (4D), and cost (5D) construction management, and the monitoring systems enable collaboration with stakeholders in a Common Data Environment (CDE). The lifecycle management methodology, after infrastructure construction, is then completed and is developed using state-of-the-art techniques using unmanned robots, scan-to-BIM, and deep learning networks, etc. It is confirmed that collaboration with stakeholders in the CDE in construction management is possible using an infrastructure BIM platform. Moreover, lifecycle management of infrastructure is possible by systematic management, such as time history analysis, damage growth prediction, decision of repair and demolition, etc., using a regular inspection database based on an infrastructure BIM platform.
KW  - Building Information Modeling (BIM)
KW  - infrastructure life cycle management
KW  - Unmanned Aerial Vehicle (UAV)
KW  - scan-to-BIM
KW  - deep learning
KW  - Common Data Environmental (CDE)
DO  - 10.3390/app112110310
ER  -
TY  - EJOU
AU  - Bizjak, Marko
AU  - Žalik, Borut
AU  - Lukač, Niko
TI  - Parameter-Free Half-Spaces Based 3D Building Reconstruction Using Ground and Segmented Building Points from Airborne LiDAR Data with 2D Outlines
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - This paper aims to automatically reconstruct 3D building models on a large scale using a new approach on the basis of half-spaces, while making no assumptions about the building layout and keeping the number of input parameters to a minimum. The proposed algorithm is performed in two stages. First, the airborne LiDAR data and buildings’ outlines are preprocessed to generate buildings’ base models and the corresponding half-spaces. In the second stage, the half-spaces are analysed and used for shaping the final 3D building model using 3D Boolean operations. In experiments, the proposed algorithm was applied on a large scale, and its’ performance was inspected on a city level and on a single building level. Accurate reconstruction of buildings with various layouts were demonstrated and limitations were identified for large-scale applications. Finally, the proposed algorithm was validated on an ISPRS benchmark dataset, where a RMSE of 1.31 m and completeness of 98.9% were obtained.
KW  - building model
KW  - reconstruction
KW  - half-space
KW  - LiDAR data
KW  - urban scale
DO  - 10.3390/rs13214430
ER  -
TY  - EJOU
AU  - Farhadi, Hadi
AU  - Najafzadeh, Mohammad
TI  - Flood Risk Mapping by Remote Sensing Data and Random Forest Technique
T2  - Water

PY  - 2021
VL  - 13
IS  - 21
SN  - 2073-4441

AB  - Detecting effective parameters in flood occurrence is one of the most important issues that has drawn more attention in recent years. Remote Sensing (RS) and Geographical Information System (GIS) are two efficient ways to spatially predict Flood Risk Mapping (FRM). In this study, a web-based platform called the Google Earth Engine (GEE) (Google Company, Mountain View, CA, USA) was used to obtain flood risk indices for the Galikesh River basin, Northern Iran. With the aid of Landsat 8 satellite imagery and the Shuttle Radar Topography Mission (SRTM) Digital Elevation Model (DEM), 11 risk indices (Elevation (El), Slope (Sl), Slope Aspect (SA), Land Use (LU), Normalized Difference Vegetation Index (NDVI), Normalized Difference Water Index (NDWI), Topographic Wetness Index (TWI), River Distance (RD), Waterway and River Density (WRD), Soil Texture (ST]), and Maximum One-Day Precipitation (M1DP)) were provided. In the next step, all of these indices were imported into ArcMap 10.8 (Esri, West Redlands, CA, USA) software for index normalization and to better visualize the graphical output. Afterward, an intelligent learning machine (Random Forest (RF)), which is a robust data mining technique, was used to compute the importance degree of each index and to obtain the flood hazard map. According to the results, the indices of WRD, RD, M1DP, and El accounted for about 68.27 percent of the total flood risk. Among these indices, the WRD index containing about 23.8 percent of the total risk has the greatest impact on floods. According to FRM mapping, about 21 and 18 percent of the total areas stood at the higher and highest risk areas, respectively.
KW  - Remote Sensing
KW  - Google Earth Engine
KW  - Random Forest
KW  - Flood Risk Mapping
DO  - 10.3390/w13213115
ER  -
TY  - EJOU
AU  - Duarte-Vidal, Luz
AU  - Herrera, Rodrigo F.
AU  - Atencio, Edison
AU  - Muñoz-La Rivera, Felipe
TI  - Interoperability of Digital Tools for the Monitoring and Control of Construction Projects
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 21
SN  - 2076-3417

AB  - Monitoring the progress on a construction site during the construction phase is crucial. An inadequate understanding of the project status can lead to mistakes and inappropriate actions, causing delays and increased costs. Monitoring and controlling projects via digital tools would reduce the risk of error and enable timely corrective actions. Although there is currently a wide range of technologies for these purposes, these technologies and interoperability between them are still limited. Because of this, it is important to know the possibilities of integration and interoperability regarding their implementation. This article presents a bibliographic synthesis and interpretation of 30 nonconventional digital tools for monitoring progress in terms of field data capture technologies (FDCT) and communication and collaborative technologies (CT) that are responsible for information processing and management. This research aims to perform an integration and interoperability analysis of technologies to demonstrate their potential for monitoring and controlling construction projects during the execution phase. A network analysis was conducted, and the results suggest that the triad formed by building information modeling (BIM), unmanned aerial vehicles (UAVs) and photogrammetry is an effective tool; the use of this set extends not only to monitoring and control, but also to all phases of a project.
KW  - monitoring progress
KW  - construction phase
KW  - automated monitoring
KW  - digital tools
KW  - as-built
KW  - as-planned
DO  - 10.3390/app112110370
ER  -
TY  - EJOU
AU  - Nazeri, Behrokh
AU  - Crawford, Melba
TI  - Detection of Outliers in LiDAR Data Acquired by Multiple Platforms over Sorghum and Maize
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - High-resolution point cloud data acquired with a laser scanner from any platform contain random noise and outliers. Therefore, outlier detection in LiDAR data is often necessary prior to analysis. Applications in agriculture are particularly challenging, as there is typically no prior knowledge of the statistical distribution of points, plant complexity, and local point densities, which are crop-dependent. The goals of this study were first to investigate approaches to minimize the impact of outliers on LiDAR acquired over agricultural row crops, and specifically for sorghum and maize breeding experiments, by an unmanned aerial vehicle (UAV) and a wheel-based ground platform; second, to evaluate the impact of existing outliers in the datasets on leaf area index (LAI) prediction using LiDAR data. Two methods were investigated to detect and remove the outliers from the plant datasets. The first was based on surface fitting to noisy point cloud data via normal and curvature estimation in a local neighborhood. The second utilized the PointCleanNet deep learning framework. Both methods were applied to individual plants and field-based datasets. To evaluate the method, an F-score was calculated for synthetic data in the controlled conditions, and LAI, the variable being predicted, was computed both before and after outlier removal for both scenarios. Results indicate that the deep learning method for outlier detection is more robust than the geometric approach to changes in point densities, level of noise, and shapes. The prediction of LAI was also improved for the wheel-based vehicle data based on the coefficient of determination (R2) and the root mean squared error (RMSE) of the residuals before and after the removal of outliers.
KW  - outlier removal
KW  - remote sensing
KW  - LiDAR
KW  - leaf area index
KW  - deep learning
DO  - 10.3390/rs13214445
ER  -
TY  - EJOU
AU  - Rokhafrouz, Mohammad
AU  - Latifi, Hooman
AU  - Abkar, Ali A.
AU  - Wojciechowski, Tomasz
AU  - Czechlowski, Mirosław
AU  - Naieni, Ali S.
AU  - Maghsoudi, Yasser
AU  - Niedbała, Gniewko
TI  - Simplified and Hybrid Remote Sensing-Based Delineation of Management Zones for Nitrogen Variable Rate Application in Wheat
T2  - Agriculture

PY  - 2021
VL  - 11
IS  - 11
SN  - 2077-0472

AB  - Enhancing digital and precision agriculture is currently inevitable to overcome the economic and environmental challenges of the agriculture in the 21st century. The purpose of this study was to generate and compare management zones (MZ) based on the Sentinel-2 satellite data for variable rate application of mineral nitrogen in wheat production, calculated using different remote sensing (RS)-based models under varied soil, yield and crop data availability. Three models were applied, including (1) a modified “RS- and threshold-based clustering”, (2) a “hybrid-based, unsupervised clustering”, in which data from different sources were combined for MZ delineation, and (3) a “RS-based, unsupervised clustering”. Various data processing methods including machine learning were used in the model development. Statistical tests such as the Paired Sample T-test, Kruskal–Wallis H-test and Wilcoxon signed-rank test were applied to evaluate the final delineated MZ maps. Additionally, a procedure for improving models based on information about phenological phases and the occurrence of agricultural drought was implemented. The results showed that information on agronomy and climate enables improving and optimizing MZ delineation. The integration of prior knowledge on new climate conditions (drought) in image selection was tested for effective use of the models. Lack of this information led to the infeasibility of obtaining optimal results. Models that solely rely on remote sensing information are comparatively less expensive than hybrid models. Additionally, remote sensing-based models enable delineating MZ for fertilizer recommendations that are temporally closer to fertilization times.
KW  - precision agriculture
KW  - management zones
KW  - remote sensing
KW  - Sentinel-2
KW  - clustering
KW  - winter wheat
KW  - drought
KW  - digital agriculture
DO  - 10.3390/agriculture11111104
ER  -
TY  - EJOU
AU  - Yang, Mingxin
AU  - Gao, Peng
AU  - Zhou, Ping
AU  - Xie, Jiaxing
AU  - Sun, Daozong
AU  - Han, Xiongzhe
AU  - Wang, Weixing
TI  - Simulating Canopy Temperature Using a Random Forest Model to Calculate the Crop Water Stress Index of Chinese Brassica
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 11
SN  - 2073-4395

AB  - The determination of crop water status has positive effects on the Chinese Brassica industry and irrigation decisions. Drought can decrease the production of Chinese Brassica, whereas over-irrigation can waste water. It is desirable to schedule irrigation when the crop suffers from water stress. In this study, a random forest model was developed using sample data derived from meteorological measurements including air temperature (Ta), relative humidity (RH), wind speed (WS), and photosynthetic active radiation (Par) to predict the lower baseline (Twet) and upper baseline (Tdry) canopy temperatures for Chinese Brassica from 27 November to 31 December 2020 (E1) and from 25 May to 20 June 2021 (E2). Crop water stress index (CWSI) values were determined based on the predicted canopy temperature and used to assess the crop water status. The study demonstrated the viability of using a random forest model to forecast Twet and Tdry. The coefficients of determination (R2) in E1 were 0.90 and 0.88 for development and 0.80 and 0.77 for validation, respectively. The R2 values in E2 were 0.91 and 0.89 for development and 0.83 and 0.80 for validation, respectively. Our results reveal that the measured and predicted CWSI values had similar R2 values related to stomatal conductance (~0.5 in E1, ~0.6 in E2), whereas the CWSI showed a poor correlation with transpiration rate (~0.25 in E1, ~0.2 in E2). Finally, the methodology used to calculate the daily CWSI for Chinese Brassica in this study showed that both Twet and Tdry, which require frequent measuring and design experiment due to the trial site and condition changes, have the potential to simulate environmental parameters and can therefore be applied to conveniently calculate the CWSI.
KW  - Chinese Brassica
KW  - canopy temperature
KW  - crop water stress index
KW  - stomatal conductance
KW  - random forest
DO  - 10.3390/agronomy11112244
ER  -
TY  - EJOU
AU  - Nababan, Bisman
AU  - Mastu, La O.
AU  - Idris, Nurul H.
AU  - Panjaitan, James P.
TI  - Shallow-Water Benthic Habitat Mapping Using Drone with Object Based Image Analyses
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Spatial information on benthic habitats in Wangiwangi island waters, Wakatobi District, Indonesia was very limited in recent years. However, this area is one of the marine tourism destinations and one of the Indonesia’s triangle coral reef regions with a very complex coral reef ecosystem. The drone technology that has rapidly developed in this decade, can be used to map benthic habitats in this area. This study aimed to map shallow-water benthic habitats using drone technology in the region of Wangiwangi island waters, Wakatobi District, Indonesia. The field data were collected using a 50 × 50 cm squared transect of 434 observation points in March–April 2017. The DJI Phantom 3 Pro drone with a spatial resolution of 5.2 × 5.2 cm was used to acquire aerial photographs. Image classifications were processed using object-based image analysis (OBIA) method with contextual editing classification at level 1 (reef level) with 200 segmentation scale and several segmentation scales at level 2 (benthic habitat). For level 2 classification, we found that the best algorithm to map benthic habitat was the support vector machine (SVM) algorithm with a segmentation scale of 50. Based on field observations, we produced 12 and 9 benthic habitat classes. Using the OBIA method with a segmentation value of 50 and the SVM algorithm, we obtained the overall accuracy of 77.4% and 81.1% for 12 and 9 object classes, respectively. This result improved overall accuracy up to 17% in mapping benthic habitats using Sentinel-2 satellite data within the similar region, similar classes, and similar method of classification analyses.
KW  - drone
KW  - mapping
KW  - benthic habitat
KW  - OBIA
KW  - SVM
KW  - Wakatobi
DO  - 10.3390/rs13214452
ER  -
TY  - EJOU
AU  - Eischeid, Isabell
AU  - Soininen, Eeva M.
AU  - Assmann, Jakob J.
AU  - Ims, Rolf A.
AU  - Madsen, Jesper
AU  - Pedersen, Åshild Ø.
AU  - Pirotti, Francesco
AU  - Yoccoz, Nigel G.
AU  - Ravolainen, Virve T.
TI  - Disturbance Mapping in Arctic Tundra Improved by a Planning Workflow for Drone Studies: Advancing Tools for Future Ecosystem Monitoring
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - The Arctic is under great pressure due to climate change. Drones are increasingly used as a tool in ecology and may be especially valuable in rapidly changing and remote landscapes, as can be found in the Arctic. For effective applications of drones, decisions of both ecological and technical character are needed. Here, we provide our method planning workflow for generating ground-cover maps with drones for ecological monitoring purposes. The workflow includes the selection of variables, layer resolutions, ground-cover classes and the development and validation of models. We implemented this workflow in a case study of the Arctic tundra to develop vegetation maps, including disturbed vegetation, at three study sites in Svalbard. For each site, we generated a high-resolution map of tundra vegetation using supervised random forest (RF) classifiers based on four spectral bands, the normalized difference vegetation index (NDVI) and three types of terrain variables—all derived from drone imagery. Our classifiers distinguished up to 15 different ground-cover classes, including two classes that identify vegetation state changes due to disturbance caused by herbivory (i.e., goose grubbing) and winter damage (i.e., ‘rain-on-snow’ and thaw-freeze). Areas classified as goose grubbing or winter damage had lower NDVI values than their undisturbed counterparts. The predictive ability of site-specific RF models was good (macro-F1 scores between 83% and 85%), but the area of the grubbing class was overestimated in parts of the moss tundra. A direct transfer of the models between study sites was not possible (macro-F1 scores under 50%). We show that drone image analysis can be an asset for studying future vegetation state changes on local scales in Arctic tundra ecosystems and encourage ecologists to use our tailored workflow to integrate drone mapping into long-term monitoring programs.
KW  - classifier
KW  - disturbance
KW  - drone
KW  - ecological monitoring
KW  - GLCM
KW  - herbivore
KW  - random forest
KW  - Svalbard
KW  - winter climate effect
KW  - grubbing
DO  - 10.3390/rs13214466
ER  -
TY  - EJOU
AU  - Wang, Yanjun
AU  - Li, Shaochun
AU  - Lin, Yunhao
AU  - Wang, Mengjie
TI  - Lightweight Deep Neural Network Method for Water Body Extraction from High-Resolution Remote Sensing Images with Multisensors
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 21
SN  - 1424-8220

AB  - Rapid and accurate extraction of water bodies from high-spatial-resolution remote sensing images is of great value for water resource management, water quality monitoring and natural disaster emergency response. For traditional water body extraction methods, it is difficult to select image texture and features, the shadows of buildings and other ground objects are in the same spectrum as water bodies, the existing deep convolutional neural network is difficult to train, the consumption of computing resources is large, and the methods cannot meet real-time requirements. In this paper, a water body extraction method based on lightweight MobileNetV2 is proposed and applied to multisensor high-resolution remote sensing images, such as GF-2, WorldView-2 and UAV orthoimages. This method was validated in two typical complex geographical scenes: water bodies for farmland irrigation, which have a broken shape and long and narrow area and are surrounded by many buildings in towns and villages; and water bodies in mountainous areas, which have undulating topography, vegetation coverage and mountain shadows all over. The results were compared with those of the support vector machine, random forest and U-Net models and also verified by generalization tests and the influence of spatial resolution changes. First, the results show that the F1-score and Kappa coefficients of the MobileNetV2 model extracting water bodies from three different high-resolution images were 0.75 and 0.72 for GF-2, 0.86 and 0.85 for Worldview-2 and 0.98 and 0.98 for UAV, respectively, which are higher than those of traditional machine learning models and U-Net. Second, the training time, number of parameters and calculation amount of the MobileNetV2 model were much lower than those of the U-Net model, which greatly improves the water body extraction efficiency. Third, in other more complex surface areas, the MobileNetV2 model still maintained relatively high accuracy of water body extraction. Finally, we tested the effects of multisensor models and found that training with lower and higher spatial resolution images combined can be beneficial, but that using just lower resolution imagery is ineffective. This study provides a reference for the efficient automation of water body classification and extraction under complex geographical environment conditions and can be extended to water resource investigation, management and planning.
KW  - water body extraction
KW  - multisensor high-resolution image
KW  - lightweight deep neural network
KW  - MobileNetv2
KW  - deep learning
DO  - 10.3390/s21217397
ER  -
TY  - EJOU
AU  - Kim, Bubryur
AU  - Choi, Se-Woon
AU  - Hu, Gang
AU  - Lee, Dong-Eun
AU  - Serfa Juan, Ronnie O.
TI  - Multivariate Analysis of Concrete Image Using Thermography and Edge Detection
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 21
SN  - 1424-8220

AB  - With the growing demand for structural health monitoring system applications, data imaging is an ideal method for performing regular routine maintenance inspections. Image analysis can provide invaluable information about the health conditions of a structure’s existing infrastructure by recording and analyzing exterior damages. Therefore, it is desirable to have an automated approach that reports defects on images reliably and robustly. This paper presents a multivariate analysis approach for images, specifically for assessing substantial damage (such as cracks). The image analysis provides graph representations that are related to the image, such as the histogram. In addition, image-processing techniques such as grayscale are also implemented, which enhance the object’s information present in the image. In addition, this study uses image segmentation and a neural network, for transforming an image to analyze it more easily and as a classifier, respectively. Initially, each concrete structure image is preprocessed to highlight the crack. A neural network is used to calculate and categorize the visual characteristics of each region, and it shows an accuracy for classification of 98%. Experimental results show that thermal image extraction yields better histogram and cumulative distribution function features. The system can promote the development of various thermal image applications, such as nonphysical visual recognition and fault detection analysis.
KW  - crack analysis
KW  - concrete
KW  - cumulative distribution function
KW  - edge detection
KW  - Sobel edge detection
DO  - 10.3390/s21217396
ER  -
TY  - EJOU
AU  - Wu, Li-Ya
AU  - Weng, Sung-Shun
TI  - Ensemble Learning Models for Food Safety Risk Prediction
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 21
SN  - 2071-1050

AB  - Ensemble learning was adopted to design risk prediction models with the aim of improving border inspection methods for food imported into Taiwan. Specifically, we constructed a set of prediction models to enhance the hit rate of non-conforming products, thus strengthening the border control of food products to safeguard public health. Using five algorithms, we developed models to provide recommendations for the risk assessment of each imported food batch. The models were evaluated by constructing a confusion matrix to calculate predictive performance indicators, including the positive prediction value (PPV), recall, harmonic mean of PPV and recall (F1 score), and area under the curve. Our results showed that ensemble learning achieved better and more stable prediction results than any single algorithm. When the results of comparable data periods were examined, the non-conformity hit rate was found to increase significantly after online implementation of the ensemble learning models, indicating that ensemble learning was effective at risk prediction. In addition to enhancing the inspection hit rate of non-conforming food, the results of this study can serve as a reference for the improvement of existing random inspection methods, thus strengthening capabilities in food risk management.
KW  - food safety
KW  - risk prediction
KW  - border control
KW  - ensemble learning
KW  - machine learning
KW  - bagging
DO  - 10.3390/su132112291
ER  -
TY  - EJOU
AU  - Fil, Pavel P.
AU  - Yurova, Alla Y.
AU  - Dobrokhotov, Alexey
AU  - Kozlov, Daniil
TI  - Estimation of Infiltration Volumes and Rates in Seasonally Water-Filled Topographic Depressions Based on Remote-Sensing Time Series
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 21
SN  - 1424-8220

AB  - In semi-arid ecoregions of temperate zones, focused snowmelt water infiltration in topographic depressions is a key, but imperfectly understood, groundwater recharge mechanism. Routine monitoring is precluded by the abundance of depressions. We have used remote-sensing data to construct mass balances and estimate volumes of temporary ponds in the Tambov area of Russia. First, small water bodies were automatically recognized in each of a time series of high-resolution Planet Labs images taken in April and May 2021 by object-oriented supervised classification. A training set of water pixels defined in one of the latest images using a small unmanned aerial vehicle enabled high-confidence predictions of water pixels in the earlier images (Cohen’s Κ = 0.99). A digital elevation model was used to estimate the ponds’ water volumes, which decreased with time following a negative exponential equation. The power of the exponent did not systematically depend on the pond size. With adjustment for estimates of daily Penman evaporation, function-based interpolation of the water bodies’ areas and volumes allowed calculation of daily infiltration into the depression beds. The infiltration was maximal (5–40 mm/day) at onset of spring and decreased with time during the study period. Use of the spatially variable infiltration rates improved steady-state shallow groundwater simulations.
KW  - closed depressions
KW  - temporary water bodies
KW  - remote sensing
KW  - infiltration
DO  - 10.3390/s21217403
ER  -
TY  - EJOU
AU  - Traore, Adama
AU  - Ata-Ul-Karim, Syed T.
AU  - Duan, Aiwang
AU  - Soothar, Mukesh K.
AU  - Traore, Seydou
AU  - Zhao, Ben
TI  - Predicting Equivalent Water Thickness in Wheat Using UAV Mounted Multispectral Sensor through Deep Learning Techniques
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - The equivalent water thickness (EWT) is an important biophysical indicator of water status in crops. The effective monitoring of EWT in wheat under different nitrogen and water treatments is important for irrigation management in precision agriculture. This study aimed to investigate the performances of machine learning (ML) algorithms in retrieving wheat EWT. For this purpose, a rain shelter experiment (Exp. 1) with four irrigation quantities (0, 120, 240, 360 mm) and two nitrogen levels (75 and 255 kg N/ha), and field experiments (Exps. 2–3) with the same irrigation and rainfall water levels (360 mm) but different nitrogen levels (varying from 75 to 255 kg N/ha) were conducted in the North China Plain. The canopy reflectance was measured for all plots at 30 m using an unmanned aerial vehicle (UAV)-mounted multispectral camera. Destructive sampling was conducted immediately after the UAV flights to measure total fresh and dry weight. Deep Neural Network (DNN) is a special type of neural network, which has shown performance in regression analysis is compared with other machine learning (ML) models. A feature selection (FS) algorithm named the decision tree (DT) was used as the automatic relevance determination method to obtain the relative relevance of 5 out of 67 vegetation indices (Vis), which were used for estimating EWT. The selected VIs were used to estimate EWT using multiple linear regression (MLR), deep neural network multilayer perceptron (DNN-MLP), artificial neural networks multilayer perceptron (ANN-MLP), boosted tree regression (BRT), and support vector machines (SVMs). The results show that the DNN-MLP with R2 = 0.934, NSE = 0.933, RMSE = 0.028 g/cm2, and MAE of 0.017 g/cm2 outperformed other ML algorithms (ANN-MPL, BRT, and SVM- Polynomial) owing to its high capacity for estimating EWT as compared to other ML methods. Our findings support the conclusion that ML can potentially be applied in combination with VIs for retrieving EWT. Despite the complexity of the ML models, the EWT map should help farmers by improving the real-time irrigation efficiency of wheat by quantifying field water content and addressing variability.
KW  - equivalent water thickness
KW  - UAV
KW  - deep learning
KW  - vegetation indices
KW  - multispectral images
DO  - 10.3390/rs13214476
ER  -
TY  - EJOU
AU  - Rakhmatuiln, Ildar
AU  - Kamilaris, Andreas
AU  - Andreasen, Christian
TI  - Deep Neural Networks to Detect Weeds from Crops in Agricultural Environments in Real-Time: A Review
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Automation, including machine learning technologies, are becoming increasingly crucial in agriculture to increase productivity. Machine vision is one of the most popular parts of machine learning and has been widely used where advanced automation and control have been required. The trend has shifted from classical image processing and machine learning techniques to modern artificial intelligence (AI) and deep learning (DL) methods. Based on large training datasets and pre-trained models, DL-based methods have proven to be more accurate than previous traditional techniques. Machine vision has wide applications in agriculture, including the detection of weeds and pests in crops. Variation in lighting conditions, failures to transfer learning, and object occlusion constitute key challenges in this domain. Recently, DL has gained much attention due to its advantages in object detection, classification, and feature extraction. DL algorithms can automatically extract information from large amounts of data used to model complex problems and is, therefore, suitable for detecting and classifying weeds and crops. We present a systematic review of AI-based systems to detect weeds, emphasizing recent trends in DL. Various DL methods are discussed to clarify their overall potential, usefulness, and performance. This study indicates that several limitations obstruct the widespread adoption of AI/DL in commercial applications. Recommendations for overcoming these challenges are summarized.
KW  - deep learning in agriculture
KW  - precision agriculture
KW  - weed detection
KW  - robotic weed control
KW  - machine vision for weed control
DO  - 10.3390/rs13214486
ER  -
TY  - EJOU
AU  - Chancia, Robert
AU  - Bates, Terry
AU  - Vanden Heuvel, Justine
AU  - van Aardt, Jan
TI  - Assessing Grapevine Nutrient Status from Unmanned Aerial System (UAS) Hyperspectral Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - This study aimed to identify the optimal sets of spectral bands for monitoring multiple grapevine nutrients in vineyards. We used spectral data spanning 400–2500 nm and leaf samples from 100 Concord grapevine canopies, lab-analyzed for six key nutrient values, to select the optimal bands for the nutrient regression models. The canopy spectral data were obtained with unmanned aerial systems (UAS), using push-broom imaging spectrometers (hyperspectral sensors). The novel use of UAS-based hyperspectral imagery to assess the grapevine nutrient status fills the gap between in situ spectral sampling and UAS-based multispectral imaging, avoiding their inherent trade-offs between spatial and spectral resolution. We found that an ensemble feature ranking method, utilizing six different machine learning feature selection methods, produced similar regression results as the standard PLSR feature selection and regression while generally selecting fewer wavelengths. We identified a set of biochemically consistent bands (606, 641, and 1494 nm) to predict the nitrogen content with an RMSE of 0.17% (using leave-one-out cross-validation) in samples with nitrogen contents ranging between 2.4 and 3.6%. Further studying is needed to confirm the relevance and consistency of the wavelengths selected for each nutrient model, but ensemble feature selection showed promise in identifying stable sets of wavelengths for assessing grapevine nutrient contents from canopy spectra.
KW  - imaging spectroscopy
KW  - unmanned aerial systems
KW  - vineyard
KW  - nutrients
DO  - 10.3390/rs13214489
ER  -
TY  - EJOU
AU  - Georgiou, Nikos
AU  - Dimas, Xenophon
AU  - Papatheodorou, George
TI  - Integrated Methodological Approach for the Documentation of Marine Priority Habitats and Submerged Antiquities: Examples from the Saronic Gulf, Greece
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 21
SN  - 2071-1050

AB  - The rising human activities and resource exploitation have increased pressure in the coastal zone and the marine environment, risking the very existence of Marine Priority Habitats (MPH) and Underwater Cultural Heritage (UCH). The delimitation of these two priority areas in a time- and cost-effective way is essential for the sustainable management and exploitation of sea resources and natural-cultural heritage preservation. We propose an Integrated Methodological Approach for the Detection and Mapping of MPH and UCH. To achieve this, we used a downscale methodological approach of increasing spatial resolution based on three main methodological axes: (i) desk-based research, (ii) marine geophysics/seafloor classification, and (iii) in-depth visual inspection/3D mapping. This methodological scheme was implemented at the Saronic Gulf and focused on Aegina island. The methodology proposed, which combines existing and new techniques, proved successful in detecting and mapping the MPH and UCH in detail, while it compiled the information necessary for the establishment of Marine Spatial Planning (MSP) maps. Finally, the MSP map constructed for the Saronic Gulf demonstrated the lack of holistic coastal zone management plans due to impacts on UCH linked to anthropogenic intervention and the sparsity of marine habitats owing to marine pollution.
KW  - marine geophysics
KW  - marine spatial planning
KW  - Aegina
KW  - Salamis
KW  - seafloor classification
KW  - 3D seismic profiles
KW  - photogrammetry
KW  - Posidonia oceanica
KW  - downscaling
DO  - 10.3390/su132112327
ER  -
TY  - EJOU
AU  - He, Yixin
AU  - Wang, Dawei
AU  - Huang, Fanghui
AU  - Zhang, Yufei
AU  - Zhang, Ruonan
AU  - Yan, Xiaohong
TI  - A RFID-Integrated Framework for Tag Anti-Collision in UAV-Aided VANETs
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 22
SN  - 2072-4292

AB  - In this paper, we investigate tags in anti-collision applications of radio frequency identification (RFID) technology in unmanned aerial vehicle (UAV)-aided vehicular ad hoc networks (VANETs). The integration of RFID technology in UAV-aided VANETs can provide reliable traffic-related services for vehicles. However, multiple tags’ simultaneous responses to a reader mounted on a UAV, denoted as tag collision, gravely affect the correct tag detection on each vehicle. Therefore, in order to decrease the collision probability and improve the throughput, we propose a multi-frequency tag identification method. In the proposed scheme, we devise a tag grouping method based on adaptive power control to make the reader dynamically match the optimal frame length. Based on the above matching results, we introduce a tag estimation method using the optimal weight to improve the accuracy of tag estimation. We theoretically analyze the closed-form expression of the security outage probability expression. Finally, our simulation results demonstrate that the proposed tag anti-collision scheme achieved significant performance superiority in terms of the throughput and identification time slots.
KW  - radio frequency identification (RFID)
KW  - tag anti-collision
KW  - unmanned aerial vehicle (UAV)
KW  - vehicular ad hoc networks (VANETs)
DO  - 10.3390/rs13224500
ER  -
TY  - EJOU
AU  - Zhao, Wenlong
AU  - Meng, Zhijun
AU  - Wang, Kaipeng
AU  - Zhang, Jiahui
AU  - Lu, Shaoze
TI  - Hierarchical Active Tracking Control for UAVs via Deep Reinforcement Learning
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 22
SN  - 2076-3417

AB  - Active tracking control is essential for UAVs to perform autonomous operations in GPS-denied environments. In the active tracking task, UAVs take high-dimensional raw images as input and execute motor actions to actively follow the dynamic target. Most research focuses on three-stage methods, which entail perception first, followed by high-level decision-making based on extracted spatial information of the dynamic target, and then UAV movement control, using a low-level dynamic controller. Perception methods based on deep neural networks are powerful but require considerable effort for manual ground truth labeling. Instead, we unify the perception and decision-making stages using a high-level controller and then leverage deep reinforcement learning to learn the mapping from raw images to the high-level action commands in the V-REP-based environment, where simulation data are infinite and inexpensive. This end-to-end method also has the advantages of a small parameter size and reduced effort requirements for parameter turning in the decision-making stage. The high-level controller, which has a novel architecture, explicitly encodes the spatial and temporal features of the dynamic target. Auxiliary segmentation and motion-in-depth losses are introduced to generate denser training signals for the high-level controller’s fast and stable training. The high-level controller and a conventional low-level PID controller constitute our hierarchical active tracking control framework for the UAVs’ active tracking task. Simulation experiments show that our controller trained with several augmentation techniques sufficiently generalizes dynamic targets with random appearances and velocities, and achieves significantly better performance, compared with three-stage methods.
KW  - unmanned aerial vehicle
KW  - deep reinforcement learning
KW  - visual active tracking
DO  - 10.3390/app112210595
ER  -
TY  - EJOU
AU  - Hu, Aihua
AU  - Deng, Zhongliang
AU  - Yang, Hui
AU  - Zhang, Yao
AU  - Gao, Yuhui
AU  - Zhao, Di
TI  - An Optimal Geometry Configuration Algorithm of Hybrid Semi-Passive Location System Based on Mayfly Optimization Algorithm
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 22
SN  - 1424-8220

AB  - In view of the demand of location awareness in a special complex environment, for an unmanned aerial vehicle (UAV) airborne multi base-station semi-passive positioning system, the hybrid positioning solutions and optimized site layout in the positioning system can effectively improve the positioning accuracy for a specific region. In this paper, the geometric dilution of precision (GDOP) formula of a time difference of arrival (TDOA) and angles of arrival (AOA) hybrid location algorithm is deduced. Mayfly optimization algorithm (MOA) which is a new swarm intelligence optimization algorithm is introduced, and a method to find the optimal station of the UAV airborne multiple base station’s semi-passive positioning system using MOA is proposed. The simulation and analysis of the optimization of the different number of base stations, compared with other station layout methods, such as particle swarm optimization (PSO), genetic algorithm (GA), and artificial bee colony (ABC) algorithm. MOA is less likely to fall into local optimum, and the error of regional target positioning is reduced. By simulating the deployment of four base stations and five base stations in various situations, MOA can achieve a better deployment effect. The dynamic station configuration capability of the multi-station semi-passive positioning system has been improved with the UAV.
KW  - optimal geometry configuration
KW  - semi-passive location
KW  - GDOP
KW  - MOA
KW  - TDOA&AOA
KW  - UAV
DO  - 10.3390/s21227484
ER  -
TY  - EJOU
AU  - Jaalama, Kaisa
AU  - Kauhanen, Heikki
AU  - Keitaanniemi, Aino
AU  - Rantanen, Toni
AU  - Virtanen, Juho-Pekka
AU  - Julin, Arttu
AU  - Vaaja, Matti
AU  - Ingman, Matias
AU  - Ahlavuo, Marika
AU  - Hyyppä, Hannu
TI  - 3D Point Cloud Data in Conveying Information for Local Green Factor Assessment
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 11
SN  - 2220-9964

AB  - The importance of ensuring the adequacy of urban ecosystem services and green infrastructure has been widely highlighted in multidisciplinary research. Meanwhile, the consolidation of cities has been a dominant trend in urban development and has led to the development and implementation of the green factor tool in cities such as Berlin, Melbourne, and Helsinki. In this study, elements of the green factor tool were monitored with laser-scanned and photogrammetrically derived point cloud datasets encompassing a yard in Espoo, Finland. The results show that with the support of 3D point clouds, it is possible to support the monitoring of the local green infrastructure, including elements of smaller size in green areas and yards. However, point clouds generated by distinct means have differing abilities in conveying information on green elements, and canopy covers, for example, might hinder these abilities. Additionally, some green factor elements are more promising for 3D measurement-based monitoring than others, such as those with clear geometrical form. The results encourage the involvement of 3D measuring technologies for monitoring local urban green infrastructure (UGI), also of small scale.
KW  - point cloud
KW  - green factor
KW  - urban green infrastructure
KW  - laser scanning
KW  - photogrammetry
DO  - 10.3390/ijgi10110762
ER  -
TY  - EJOU
AU  - Jensen, Signe M.
AU  - Akhter, Muhammad J.
AU  - Azim, Saiful
AU  - Rasmussen, Jesper
TI  - The Predictive Power of Regression Models to Determine Grass Weed Infestations in Cereals Based on Drone Imagery—Statistical and Practical Aspects
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 11
SN  - 2073-4395

AB  - Site-specific weed management (SSWM) may reduce herbicide use by identifying weed patches and weed-free areas. However, one major constraint is robust weed detection algorithms that are able to predict weed infestations outside of the training data. This study investigates the predictive power of regression models trained on drone imagery that are used within fields to predict infestations of annual grass weeds in the late growth stages of cereals. The main objective was to identify the optimum sampling strategy for training regression models based on aerial RGB images. The study showed that training based on sampling from the whole range of weed infestations or the extreme values in the field provided better prediction accuracy than random sampling. Prediction models based on vegetation indices (VIs) offered a useful alternative to a more complex random forest machine-learning algorithm. For binary decision-making, linear regression utilizing weed density information resulted in higher accuracy than a logistic regression approach that only relied on information regarding the presence/absence of weeds. Across six fields, the average balanced accuracy based on linear regression was in the range of 75–83%, with the highest accuracy found when the sampling was from the extreme values in the field, and with the lowest accuracy found for random sampling. For future work on training weed prediction models, choosing training sets covering the entire sample space is recommended in favor of random sampling.
KW  - prediction models
KW  - validation
KW  - weed detection
KW  - weed monitoring
KW  - vegetation indices
KW  - precision agriculture
KW  - site-specific weed management (SSWM)
KW  - UAV imagery
DO  - 10.3390/agronomy11112277
ER  -
TY  - EJOU
AU  - Sadgrove, Edmund J.
AU  - Falzon, Greg
AU  - Miron, David
AU  - Lamb, David W.
TI  - The Segmented Colour Feature Extreme Learning Machine: Applications in Agricultural Robotics
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 11
SN  - 2073-4395

AB  - This study presents the Segmented Colour Feature Extreme Learning Machine (SCF-ELM). The SCF-ELM is inspired by the Extreme Learning Machine (ELM) which is known for its rapid training and inference times. The ELM is therefore an ideal candidate for an ensemble learning algorithm. The Colour Feature Extreme Learning Machine (CF-ELM) is used in this study due to its additional ability to extract colour image features. The SCF-ELM is an ensemble learner that utilizes feature mapping via k-means clustering, a decision matrix and majority voting. It has been evaluated on a range of challenging agricultural object classification scenarios including weed, livestock and machinery detection. SCF-ELM model performance results were excellent both in terms of detection, 90 to 99% accuracy, and also inference times, around 0.01(s) per image. The SCF-ELM was able to compete or improve upon established algorithms in its class, indicating its potential for remote computing applications in agriculture.
KW  - agricultural robotics
KW  - computer vision
KW  - drone
KW  - stationary camera trap
KW  - ensemble
KW  - extreme learning machine
KW  - feature mapping
KW  - object classification
DO  - 10.3390/agronomy11112290
ER  -
TY  - EJOU
AU  - Hassan, Syed-Ali
AU  - Rahim, Tariq
AU  - Shin, Soo-Young
TI  - An Improved Deep Convolutional Neural Network-Based Autonomous Road Inspection Scheme Using Unmanned Aerial Vehicles
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 22
SN  - 2079-9292

AB  - Recent advancements in the field of machine learning (ML) provide opportunity to conduct research on autonomous devices for a variety of applications. Intelligent decision-making is a critical task for self-driving systems. An attempt is made in this study to use a deep learning (DL) approach for the early detection of road cracks, potholes, and the yellow lane. The accuracy is not sufficient after training with the default model. To enhance accuracy, a convolutional neural network (CNN) model with 13 convolutional layers, a softmax layer as an output layer, and two fully connected layers (FCN) are constructed. In order to achieve the deeper propagation and to prevent saturation in the training phase, mish activation is employed in the first 12 layers with a rectified linear unit (ReLU) activation function. The upgraded CNN model performs better than the default CNN model in terms of accuracy. For the varied situation, a revised and enriched dataset for road cracks, potholes, and the yellow lane is created. The yellow lane is detected and tracked in order to move the unmanned aerial vehicle (UAV) autonomously by following yellow lane. After identifying a yellow lane, the UAV performs autonomous navigation while concurrently detecting road cracks and potholes using the robot operating system within the UAV. The performance model is benchmarked using performance measures, such as accuracy, sensitivity, F1-score, F2-score, and dice-coefficient, which demonstrate that the suggested technique produces better outcomes.
KW  - autonomous navigation
KW  - autonomous road inspection
KW  - computer vision
KW  - drone
KW  - robots
KW  - neural network
KW  - UAV
DO  - 10.3390/electronics10222764
ER  -
TY  - EJOU
AU  - Rosle, Rhushalshafira
AU  - Che’Ya, Nik N.
AU  - Ang, Yuhao
AU  - Rahmat, Fariq
AU  - Wayayok, Aimrun
AU  - Berahim, Zulkarami
AU  - Fazlil Ilahi, Wan F.
AU  - Ismail, Mohd R.
AU  - Omar, Mohamad H.
TI  - Weed Detection in Rice Fields Using Remote Sensing Technique: A Review
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 22
SN  - 2076-3417

AB  - This paper reviewed the weed problems in agriculture and how remote sensing techniques can detect weeds in rice fields. The comparison of weed detection between traditional practices and automated detection using remote sensing platforms is discussed. The ideal stage for controlling weeds in rice fields was highlighted, and the types of weeds usually found in paddy fields were listed. This paper will discuss weed detection using remote sensing techniques, and algorithms commonly used to differentiate them from crops are deliberated. However, weed detection in rice fields using remote sensing platforms is still in its early stages; weed detection in other crops is also discussed. Results show that machine learning (ML) and deep learning (DL) remote sensing techniques have successfully produced a high accuracy map for detecting weeds in crops using RS platforms. Therefore, this technology positively impacts weed management in many aspects, especially in terms of the economic perspective. The implementation of this technology into agricultural development could be extended further.
KW  - invasive plants
KW  - precision agriculture
KW  - remote sensing
KW  - rice farming
KW  - site-specific weed management
DO  - 10.3390/app112210701
ER  -
TY  - EJOU
AU  - Gonzalez-Aguirre, Juan A.
AU  - Osorio-Oliveros, Ricardo
AU  - Rodríguez-Hernández, Karen L.
AU  - Lizárraga-Iturralde, Javier
AU  - Morales Menendez, Rubén
AU  - Ramírez-Mendoza, Ricardo A.
AU  - Ramírez-Moreno, Mauricio A.
AU  - Lozoya-Santos, Jorge D.
TI  - Service Robots: Trends and Technology
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 22
SN  - 2076-3417

AB  - The 2021 sales volume in the market of service robots is attractive. Expert reports from the International Federation of Robotics confirm 27 billion USD in total market share. Moreover, the number of new startups with the denomination of service robots nowadays constitutes 29% of the total amount of robotic companies recorded in the United States. Those data, among other similar figures, remark the need for formal development in the service robots area, including knowledge transfer and literature reviews. Furthermore, the COVID-19 spread accelerated business units and some research groups to invest time and effort into the field of service robotics. Therefore, this research work intends to contribute to the formalization of service robots as an area of robotics, presenting a systematic review of scientific literature. First, a definition of service robots according to fundamental ontology is provided, followed by a detailed review covering technological applications; state-of-the-art, commercial technology; and application cases indexed on the consulted databases.
KW  - robotics
KW  - service robots
KW  - human–robot interaction
KW  - healthcare robots
KW  - robot-as-a-service
KW  - smart cities
KW  - AGV
KW  - AMR
DO  - 10.3390/app112210702
ER  -
TY  - EJOU
AU  - Luo, Lili
AU  - Chang, Qingrui
AU  - Wang, Qi
AU  - Huang, Yong
TI  - Identification and Severity Monitoring of Maize Dwarf Mosaic Virus Infection Based on Hyperspectral Measurements
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 22
SN  - 2072-4292

AB  - Prompt monitoring of maize dwarf mosaic virus (MDMV) is critical for the prevention and control of disease and to ensure high crop yield and quality. Here, we first analyzed the spectral differences between MDMV-infected red leaves and healthy leaves and constructed a sensitive index (SI) for measurements. Next, based on the characteristic bands (Rλ) associated with leaf anthocyanins (Anth), we determined vegetation indices (VIs) commonly used in plant physiological and biochemical parameter inversion and established a vegetation index (VIc) by utilizing the combination of two arbitrary bands following the construction principles of NDVI, DVI, RVI, and SAVI. Furthermore, we developed classification models based on linear discriminant analysis (LDA) and support vector machine (SVM) in order to distinguish the red leaves from healthy leaves. Finally, we performed UR, MLR, PLSR, PCR, and SVM simulations on Anth based on Rλ, VIs, VIc, and Rλ + VIs + VIc and indirectly estimated the severity of MDMV infection based on the relationship between the reflection spectra and Anth. Distinct from those of the normal leaves, the spectra of red leaves showed strong reflectance characteristics at 640 nm, and SI increased with increasing Anth. Moreover, the accuracy of the two VIc-based classification models was 100%, which is significantly higher than that of the VIs and Rλ-based models. Among the Anth regression models, the accuracy of the MLR model based on Rλ + VIs + VIc was the highest (R2c = 0.85; R2v = 0.74). The developed models could accurately identify MDMV and estimate the severity of its infection, laying the theoretical foundation for large-scale remote sensing-based monitoring of this virus in the future.
KW  - plant disease
KW  - band selection
KW  - machine learning
KW  - anthocyanin
KW  - hyperspectral reflectance
KW  - linear discriminant analysis
KW  - precision crop protection
DO  - 10.3390/rs13224560
ER  -
TY  - EJOU
AU  - Lei, Shuhan
AU  - Luo, Jianbiao
AU  - Tao, Xiaojun
AU  - Qiu, Zixuan
TI  - Remote Sensing Detecting of Yellow Leaf Disease of Arecanut Based on UAV Multisource Sensors
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 22
SN  - 2072-4292

AB  - Unmanned aerial vehicle (UAV) remote sensing technology can be used for fast and efficient monitoring of plant diseases and pests, but these techniques are qualitative expressions of plant diseases. However, the yellow leaf disease of arecanut in Hainan Province is similar to a plague, with an incidence rate of up to 90% in severely affected areas, and a qualitative expression is not conducive to the assessment of its severity and yield. Additionally, there exists a clear correlation between the damage caused by plant diseases and pests and the change in the living vegetation volume (LVV). However, the correlation between the severity of the yellow leaf disease of arecanut and LVV must be demonstrated through research. Therefore, this study aims to apply the multispectral data obtained by the UAV along with the high-resolution UAV remote sensing images to obtain five vegetation indexes such as the normalized difference vegetation index (NDVI), optimized soil adjusted vegetation index (OSAVI), leaf chlorophyll index (LCI), green normalized difference vegetation index (GNDVI), and normalized difference red edge (NDRE) index, and establish five algorithm models such as the back-propagation neural network (BPNN), decision tree, naïve Bayes, support vector machine (SVM), and k-nearest-neighbor classification to determine the severity of the yellow leaf disease of arecanut, which is expressed by the proportion of the yellowing area of a single areca crown (in percentage). The traditional qualitative expression of this disease is transformed into the quantitative expression of the yellow leaf disease of arecanut per plant. The results demonstrate that the classification accuracy of the test set of the BPNN algorithm and SVM algorithm is the highest, at 86.57% and 86.30%, respectively. Additionally, the UAV structure from motion technology is used to measure the LVV of a single areca tree and establish a model of the correlation between the LVV and the severity of the yellow leaf disease of arecanut. The results show that the relative root mean square error is between 34.763% and 39.324%. This study presents the novel quantitative expression of the severity of the yellow leaf disease of arecanut, along with the correlation between the LVV of areca and the severity of the yellow leaf disease of arecanut. Significant development is expected in the degree of integration of multispectral software and hardware, observation accuracy, and ease of use of UAVs owing to the rapid progress of spectral sensing technology and the image processing and analysis algorithms.
KW  - yellow leaf disease of arecanut
KW  - unmanned aerial vehicle
KW  - machine learning
KW  - multisource data fusion
KW  - remote sensing quantitative monitoring
DO  - 10.3390/rs13224562
ER  -
TY  - EJOU
AU  - Song, Huan
AU  - Hu, Yongguang
AU  - Lu, Yongzong
AU  - Wang, Jizhang
AU  - Pan, Qingmin
AU  - Li, Pingping
TI  - A Review of Methods and Techniques for Detecting Frost on Plant Surfaces
T2  - Agriculture

PY  - 2021
VL  - 11
IS  - 11
SN  - 2077-0472

AB  - Severe frost usually has adverse impacts on agricultural production, resulting in crop freeze injury, poor crop yield, and crop quality reduction. Timely and accurate detection of frost plays an important role in cold damage warnings, prevention, and control. Current frost detection methods mostly use physical properties such as light, electricity, and heat, or the judge and quantify using environmental factors such as temperature and wind speed. However, it is difficult to detect and accurately identify the frosting phenomenon in real time during field trials because of the complex environment, different plant types, and interference by many factors during observation. To provide an overview of the analytical tools for scientists, researchers, and product developers, a review and comparative analysis of the available literature on frost mechanisms, correlations, and characteristics are presented in this study. First, the mechanisms of the frost formation process, frost level, and the significance of detection, are introduced. Then, the methods and techniques used to measure frost on plant surfaces are synthetically classified and further compared. Moreover, the key points and difficulties are summarized and discussed. Finally, some constructive methods of frost detection are proposed to improve the frost detection process.
KW  - plant
KW  - leaf surface
KW  - frost
KW  - frost characteristics
KW  - detection
DO  - 10.3390/agriculture11111142
ER  -
TY  - EJOU
AU  - Zhou, Xiaoteng
AU  - Liu, Chun
AU  - Akbar, Akram
AU  - Xue, Yun
AU  - Zhou, Yuan
TI  - Spectral and Spatial Feature Integrated Ensemble Learning Method for Grading Urban River Network Water Quality
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 22
SN  - 2072-4292

AB  - Urban river networks have the characteristics of medium and micro scales, complex water quality, rapid change, and time–space incoherence. Aiming to monitor the water quality accurately, it is necessary to extract suitable features and establish a universal inversion model for key water quality parameters. In this paper, we describe a spectral- and spatial-feature-integrated ensemble learning method for urban river network water quality grading. We proposed an in situ sampling method for urban river networks. Factor and correlation analyses were applied to extract the spectral features. Moreover, we analyzed the maximum allowed bandwidth for feature bands. We demonstrated that spatial features can improve the accuracy of water quality grading using kernel canonical correlation analysis (KCCA). Based on the spectral and spatial features, an ensemble learning model was established for total phosphorus (TP) and ammonia nitrogen (NH3-N). Both models were evaluated by means of fivefold validation. Furthermore, we proposed an unmanned aerial vehicle (UAV)-borne water quality multispectral remote sensing application process for urban river networks. Based on the process, we tested the model in practice. The experiment confirmed that our model can improve the grading accuracy by 30% compared to other machine learning models that use only spectral features. Our research can extend the application field of water quality remote sensing to complex urban river networks.
KW  - ensemble learning
KW  - feature extraction
KW  - UAV-borne remote sensing
KW  - urban river network
KW  - water quality grading
DO  - 10.3390/rs13224591
ER  -
TY  - EJOU
AU  - Eide, Austin
AU  - Koparan, Cengiz
AU  - Zhang, Yu
AU  - Ostlie, Michael
AU  - Howatt, Kirk
AU  - Sun, Xin
TI  - UAV-Assisted Thermal Infrared and Multispectral Imaging of Weed Canopies for Glyphosate Resistance Detection
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 22
SN  - 2072-4292

AB  - The foundation of contemporary weed management practices in many parts of the world is glyphosate. However, dependency on the effectiveness of herbicide practices has led to overuse through continuous growth of crops resistant to a single mode of action. In order to provide a cost-effective weed management strategy that does not promote glyphosate-resistant weed biotypes, differences between resistant and susceptible biotypes have to be identified accurately in the field conditions. Unmanned Aerial Vehicle (UAV)-assisted thermal and multispectral remote sensing has potential for detecting biophysical characteristics of weed biotypes during the growing season, which includes distinguishing glyphosate-susceptible and glyphosate-resistant weed populations based on canopy temperature and deep learning driven weed identification algorithms. The objective of this study was to identify herbicide resistance after glyphosate application in true field conditions by analyzing the UAV-acquired thermal and multispectral response of kochia, waterhemp, redroot pigweed, and common ragweed. The data were processed in ArcGIS for raster classification as well as spectral comparison of glyphosate-resistant and glyphosate-susceptible weeds. The classification accuracy between the sensors and classification methods of maximum likelihood, random trees, and Support Vector Machine (SVM) were compared. The random trees classifier performed the best at 4 days after application (DAA) for kochia with 62.9% accuracy. The maximum likelihood classifier provided the highest performing result out of all classification methods with an accuracy of 75.2%. A commendable classification was made at 8 DAA where the random trees classifier attained an accuracy of 87.2%. However, thermal reflectance measurements as a predictor for glyphosate resistance within weed populations in field condition was unreliable due to its susceptibility to environmental conditions. Normalized Difference Vegetation Index (NDVI) and a composite reflectance of 842 nm, 705 nm, and 740 nm wavelength managed to provide better classification results than thermal in most cases.
KW  - weed identification
KW  - glyphosate
KW  - thermal image
KW  - multispectral image
KW  - UAV
DO  - 10.3390/rs13224606
ER  -
TY  - EJOU
AU  - Pan, Baihong
AU  - Zheng, Yi
AU  - Shen, Ruoque
AU  - Ye, Tao
AU  - Zhao, Wenzhi
AU  - Dong, Jie
AU  - Ma, Hanqing
AU  - Yuan, Wenping
TI  - High Resolution Distribution Dataset of Double-Season Paddy Rice in China
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 22
SN  - 2072-4292

AB  - Although China is the largest producer of rice, accounting for about 25% of global production, there are no high-resolution maps of paddy rice covering the entire country. Using time-weighted dynamic time warping (TWDTW), this study developed a pixel- and phenology-based method to identify planting areas of double-season paddy rice in China, by comparing temporal variations of synthetic aperture radar (SAR) signals of unknown pixels to those of known double-season paddy rice fields. We conducted a comprehensive evaluation of the method’s performance at pixel and regional scales. Based on 145,210 field surveyed samples from 2018 to 2020, the producer’s and user’s accuracy are 88.49% and 87.02%, respectively. Compared to county-level statistical data from 2016 to 2019, the relative mean absolute errors are 34.11%. This study produced distribution maps of double-season rice at 10 m spatial resolution from 2016 to 2020 over nine provinces in South China, which account for more than 99% of the planting areas of double-season paddy rice of China. The maps are expected to contribute to timely monitoring and evaluating rice growth and yield.
KW  - early rice
KW  - late rice
KW  - double-season rice
KW  - time-weighted dynamic time warping
KW  - synthetic aperture radar
KW  - planting area
KW  - remote sensing
DO  - 10.3390/rs13224609
ER  -
TY  - EJOU
AU  - Moussaid, Abdellatif
AU  - Fkihi, Sanaa E.
AU  - Zennayi, Yahya
TI  - Tree Crowns Segmentation and Classification in Overlapping Orchards Based on Satellite Images and Unsupervised Learning Algorithms
T2  - Journal of Imaging

PY  - 2021
VL  - 7
IS  - 11
SN  - 2313-433X

AB  - Smart agriculture is a new concept that combines agriculture and new technologies to improve the yield’s quality and quantity as well as facilitate many tasks for farmers in managing orchards. An essential factor in smart agriculture is tree crown segmentation, which helps farmers automatically monitor their orchards and get information about each tree. However, one of the main problems, in this case, is when the trees are close to each other, which means that it would be difficult for the algorithm to delineate the crowns correctly. This paper used satellite images and machine learning algorithms to segment and classify trees in overlapping orchards. The data used are images from the Moroccan Mohammed VI satellite, and the study region is the OUARGHA citrus orchard located in Morocco. Our approach starts by segmenting the rows inside the parcel and finding all the trees there, getting their canopies, and classifying them by size. In general, the model inputs the parcel’s image and other field measurements to classify the trees into three classes: missing/weak, normal, or big. Finally, the results are visualized in a map containing all the trees with their classes. For the results, we obtained a score of 0.93 F-measure in rows segmentation. Additionally, several field comparisons were performed to validate the classification, dozens of trees were compared and the results were very good. This paper aims to help farmers to quickly and automatically classify trees by crown size, even if there are overlapping orchards, in order to easily monitor each tree’s health and understand the tree’s distribution in the field.
KW  - tree canopy segmentation
KW  - tree canopy classification
KW  - unsupervised learning
KW  - satellite images
KW  - remote sensing
DO  - 10.3390/jimaging7110241
ER  -
TY  - EJOU
AU  - Hashim, Wahidah
AU  - Eng, Lim S.
AU  - Alkawsi, Gamal
AU  - Ismail, Rozita
AU  - Alkahtani, Ammar A.
AU  - Dzulkifly, Sumayyah
AU  - Baashar, Yahia
AU  - Hussain, Azham
TI  - A Hybrid Vegetation Detection Framework: Integrating Vegetation Indices and Convolutional Neural Network
T2  - Symmetry

PY  - 2021
VL  - 13
IS  - 11
SN  - 2073-8994

AB  - Vegetation inspection and monitoring is a time-consuming task. In the era of industrial revolution 4.0 (IR 4.0), unmanned aerial vehicles (UAV), commercially known as drones, are in demand, being adopted for vegetation inspection and monitoring activities. However, most off-the-shelf drones are least favoured by vegetation maintenance departments for on-site inspection due to limited spectral bands camera restricting advanced vegetation analysis. Most of these drones are normally equipped with a normal red, green, and blue (RGB) camera. Additional spectral bands are found to produce more accurate analysis during vegetation inspection, but at the cost of advanced camera functionalities, such as multispectral camera. Vegetation indices (VI) is a technique to maximize detection sensitivity related to vegetation characteristics while minimizing other factors which are not categorised otherwise. The emergence of machine learning has slowly influenced the existing vegetation analysis technique in order to improve detection accuracy. This study focuses on exploring VI techniques in identifying vegetation objects. The selected VIs investigated are Visible Atmospheric Resistant Index (VARI), Green Leaf Index (GLI), and Vegetation Index Green (VIgreen). The chosen machine learning technique is You Only Look Once (YOLO), which is a clever convolutional neural network (CNN) offering object detection in real time. The CNN model has a symmetrical structure along the direction of the tensor flow. Several series of data collection have been conducted at identified locations to obtain aerial images. The proposed hybrid methods were tested on captured aerial images to observe vegetation detection performance. Segmentation in image analysis is a process to divide the targeted pixels for further detection testing. Based on our findings, more than 70% of the vegetation objects in the images were accurately detected, which reduces the misdetection issue faced by previous VI techniques. On the other hand, hybrid segmentation methods perform best with the combination of VARI and YOLO at 84% detection accuracy.
KW  - vegetation detection
KW  - vegetation indices
KW  - convolutional neural network
KW  - hybrid method
DO  - 10.3390/sym13112190
ER  -

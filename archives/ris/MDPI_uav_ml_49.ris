TY  - EJOU
AU  - Hassanein, Mohamed
AU  - Lari, Zahra
AU  - El-Sheimy, Naser
TI  - A New Vegetation Segmentation Approach for Cropped Fields Based on Threshold Detection from Hue Histograms
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 4
SN  - 1424-8220

AB  - Over the last decade, the use of unmanned aerial vehicle (UAV) technology has evolved significantly in different applications as it provides a special platform capable of combining the benefits of terrestrial and aerial remote sensing. Therefore, such technology has been established as an important source of data collection for different precision agriculture (PA) applications such as crop health monitoring and weed management. Generally, these PA applications depend on performing a vegetation segmentation process as an initial step, which aims to detect the vegetation objects in collected agriculture fields&rsquo; images. The main result of the vegetation segmentation process is a binary image, where vegetations are presented in white color and the remaining objects are presented in black. Such process could easily be performed using different vegetation indexes derived from multispectral imagery. Recently, to expand the use of UAV imagery systems for PA applications, it was important to reduce the cost of such systems through using low-cost RGB cameras Thus, developing vegetation segmentation techniques for RGB images is a challenging problem. The proposed paper introduces a new vegetation segmentation methodology for low-cost UAV RGB images, which depends on using Hue color channel. The proposed methodology follows the assumption that the colors in any agriculture field image can be distributed into vegetation and non-vegetations colors. Therefore, four main steps are developed to detect five different threshold values using the hue histogram of the RGB image, these thresholds are capable to discriminate the dominant color, either vegetation or non-vegetation, within the agriculture field image. The achieved results for implementing the proposed methodology showed its ability to generate accurate and stable vegetation segmentation performance with mean accuracy equal to 87.29% and standard deviation as 12.5%.
KW  - vegetation segmentation
KW  - threshold detection
KW  - hue histogram
KW  - UAV
KW  - precision agriculture
DO  - 10.3390/s18041253
ER  -
TY  - EJOU
AU  - Zhang, Yongjun
AU  - Wang, Xiang
AU  - Xie, Xunwei
AU  - Li, Yansheng
TI  - Salient Object Detection via Recursive Sparse Representation
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 4
SN  - 2072-4292

AB  - Object-level saliency detection is an attractive research field which is useful for many content-based computer vision and remote-sensing tasks. This paper introduces an efficient unsupervised approach to salient object detection from the perspective of recursive sparse representation. The reconstruction error determined by foreground and background dictionaries other than common local and global contrasts is used as the saliency indication, by which the shortcomings of the object integrity can be effectively improved. The proposed method consists of the following four steps: (1) regional feature extraction; (2) background and foreground dictionaries extraction according to the initial saliency map and image boundary constraints; (3) sparse representation and saliency measurement; and (4) recursive processing with a current saliency map updating the initial saliency map in step 2 and repeating step 3. This paper also presents the experimental results of the proposed method compared with seven state-of-the-art saliency detection methods using three benchmark datasets, as well as some satellite and unmanned aerial vehicle remote-sensing images, which confirmed that the proposed method was more effective than current methods and could achieve more favorable performance in the detection of multiple objects as well as maintaining the integrity of the object area.
KW  - salient object detection
KW  - sparse representation
KW  - reconstruction error
KW  - recursive processing
DO  - 10.3390/rs10040652
ER  -
TY  - EJOU
AU  - Krylov, Vladimir A.
AU  - Kenny, Eamonn
AU  - Dahyot, Rozenn
TI  - Automatic Discovery and Geotagging of Objects from Street View Imagery
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 5
SN  - 2072-4292

AB  - Many applications, such as autonomous navigation, urban planning, and asset monitoring, rely on the availability of accurate information about objects and their geolocations. In this paper, we propose the automatic detection and computation of the coordinates of recurring stationary objects of interest using street view imagery. Our processing pipeline relies on two fully convolutional neural networks: the first segments objects in the images, while the second estimates their distance from the camera. To geolocate all the detected objects coherently we propose a novel custom Markov random field model to estimate the objects&rsquo; geolocation. The novelty of the resulting pipeline is the combined use of monocular depth estimation and triangulation to enable automatic mapping of complex scenes with the simultaneous presence of multiple, visually similar objects of interest. We validate experimentally the effectiveness of our approach on two object classes: traffic lights and telegraph poles. The experiments report high object recall rates and position precision of approximately 2 m, which is approaching the precision of single-frequency GPS receivers.
KW  - object geolocation
KW  - object mapping
KW  - street view imagery
KW  - Markov random fields
KW  - traffic lights
KW  - telecom assets
KW  - GPS estimation
DO  - 10.3390/rs10050661
ER  -
TY  - EJOU
AU  - Zhao, Xiaoyang
AU  - Zhang, Jian
AU  - Yang, Chenghai
AU  - Song, Huaibo
AU  - Shi, Yeyin
AU  - Zhou, Xingen
AU  - Zhang, Dongyan
AU  - Zhang, Guozhong
TI  - Registration for Optical Multimodal Remote Sensing Images Based on FAST Detection, Window Selection, and Histogram Specification
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 5
SN  - 2072-4292

AB  - In recent years, digital frame cameras have been increasingly used for remote sensing applications. However, it is always a challenge to align or register images captured with different cameras or different imaging sensor units. In this research, a novel registration method was proposed. Coarse registration was first applied to approximately align the sensed and reference images. Window selection was then used to reduce the search space and a histogram specification was applied to optimize the grayscale similarity between the images. After comparisons with other commonly-used detectors, the fast corner detector, FAST (Features from Accelerated Segment Test), was selected to extract the feature points. The matching point pairs were then detected between the images, the outliers were eliminated, and geometric transformation was performed. The appropriate window size was searched and set to one-tenth of the image width. The images that were acquired by a two-camera system, a camera with five imaging sensors, and a camera with replaceable filters mounted on a manned aircraft, an unmanned aerial vehicle, and a ground-based platform, respectively, were used to evaluate the performance of the proposed method. The image analysis results showed that, through the appropriate window selection and histogram specification, the number of correctly matched point pairs had increased by 11.30 times, and that the correct matching rate had increased by 36%, compared with the results based on FAST alone. The root mean square error (RMSE) in the x and y directions was generally within 0.5 pixels. In comparison with the binary robust invariant scalable keypoints (BRISK), curvature scale space (CSS), Harris, speed up robust features (SURF), and commercial software ERDAS and ENVI, this method resulted in larger numbers of correct matching pairs and smaller, more consistent RMSE. Furthermore, it was not necessary to choose any tie control points manually before registration. The results from this study indicate that the proposed method can be effective for registering optical multimodal remote sensing images that have been captured with different imaging sensors.
KW  - optical multimodal images
KW  - registration
KW  - FAST
KW  - window selection
KW  - histogram specification
DO  - 10.3390/rs10050663
ER  -
TY  - EJOU
AU  - De Simone, Marco C.
AU  - Rivera, Zandra B.
AU  - Guida, Domenico
TI  - Obstacle Avoidance System for Unmanned Ground Vehicles by Using Ultrasonic Sensors
T2  - Machines

PY  - 2018
VL  - 6
IS  - 2
SN  - 2075-1702

AB  - Artificial intelligence is the ability of a computer to perform the functions and reasoning typical of the human mind. In its purely informatic aspect, it includes the theory and techniques for the development of algorithms that allow machines to show an intelligent ability and/or perform an intelligent activity, at least in specific areas. In particular, there are automatic learning algorithms based on the same mechanisms that are thought to be the basis of all the cognitive processes developed by the human brain. Such a powerful tool has already started to produce a new class of self-driving vehicles. With the projections of population growth that will increase until the year 2100 up to 11.2 billion, research on innovating agricultural techniques must be continued. In order to improve the efficiency regarding precision agriculture, the use of autonomous agricultural machines must become an important issue. For this reason, it was decided to test the use of the &ldquo;Neural Network Toolbox&rdquo; tool already present in MATLAB to design an artificial neural network with supervised learning suitable for classification and pattern recognition by using data collected by an ultrasonic sensor. The idea is to use such a protocol to retrofit kits for agricultural machines already present on the market.
KW  - object recognition
KW  - neural network
KW  - unmanned vehicle
KW  - MATLAB
KW  - ultrasonic sensors
DO  - 10.3390/machines6020018
ER  -
TY  - EJOU
AU  - Chen, Xi
AU  - Kopsaftopoulos, Fotis
AU  - Wu, Qi
AU  - Ren, He
AU  - Chang, Fu-Kuo
TI  - Flight State Identification of a Self-Sensing Wing via an Improved Feature Selection Method and Machine Learning Approaches
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 5
SN  - 1424-8220

AB  - In this work, a data-driven approach for identifying the flight state of a self-sensing wing structure with an embedded multi-functional sensing network is proposed. The flight state is characterized by the structural vibration signals recorded from a series of wind tunnel experiments under varying angles of attack and airspeeds. A large feature pool is created by extracting potential features from the signals covering the time domain, the frequency domain as well as the information domain. Special emphasis is given to feature selection in which a novel filter method is developed based on the combination of a modified distance evaluation algorithm and a variance inflation factor. Machine learning algorithms are then employed to establish the mapping relationship from the feature space to the practical state space. Results from two case studies demonstrate the high identification accuracy and the effectiveness of the model complexity reduction via the proposed method, thus providing new perspectives of self-awareness towards the next generation of intelligent air vehicles.
KW  - self-sensing wing
KW  - feature extraction
KW  - feature selection
KW  - flight state identification
KW  - machine learning
DO  - 10.3390/s18051379
ER  -
TY  - EJOU
AU  - Aadil, Farhan
AU  - Raza, Ali
AU  - Khan, Muhammad F.
AU  - Maqsood, Muazzam
AU  - Mehmood, Irfan
AU  - Rho, Seungmin
TI  - Energy Aware Cluster-Based Routing in Flying Ad-Hoc Networks
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 5
SN  - 1424-8220

AB  - Flying ad-hoc networks (FANETs) are a very vibrant research area nowadays. They have many military and civil applications. Limited battery energy and the high mobility of micro unmanned aerial vehicles (UAVs) represent their two main problems, i.e., short flight time and inefficient routing. In this paper, we try to address both of these problems by means of efficient clustering. First, we adjust the transmission power of the UAVs by anticipating their operational requirements. Optimal transmission range will have minimum packet loss ratio (PLR) and better link quality, which ultimately save the energy consumed during communication. Second, we use a variant of the K-Means Density clustering algorithm for selection of cluster heads. Optimal cluster heads enhance the cluster lifetime and reduce the routing overhead. The proposed model outperforms the state of the art artificial intelligence techniques such as Ant Colony Optimization-based clustering algorithm and Grey Wolf Optimization-based clustering algorithm. The performance of the proposed algorithm is evaluated in term of number of clusters, cluster building time, cluster lifetime and energy consumption.
KW  - FANET
KW  - routing
KW  - clustering
KW  - transmission range optimization
KW  - energy optimization
DO  - 10.3390/s18051413
ER  -
TY  - EJOU
AU  - Moy de Vitry, Matthew
AU  - Schindler, Konrad
AU  - Rieckermann, Jörg
AU  - Leitão, João P.
TI  - Sewer Inlet Localization in UAV Image Clouds: Improving Performance with Multiview Detection
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 5
SN  - 2072-4292

AB  - Sewer and drainage infrastructure are often not as well catalogued as they should be, considering the immense investment they represent. In this work, we present a fully automatic framework for localizing sewer inlets from image clouds captured from an unmanned aerial vehicle (UAV). The framework exploits the high image overlap of UAV imaging surveys with a multiview approach to improve detection performance. The framework uses a Viola–Jones classifier trained to detect sewer inlets in aerial images with a ground sampling distance of 3–3.5 cm/pixel. The detections are then projected into three-dimensional space where they are clustered and reclassified to discard false positives. The method is evaluated by cross-validating results from an image cloud of 252 UAV images captured over a 0.57-km2 study area with 228 sewer inlets. Compared to an equivalent single-view detector, the multiview approach improves both recall and precision, increasing average precision from 0.65 to 0.73. The source code and case study data are publicly available for reuse.
KW  - infrastructure mapping
KW  - multiview
KW  - object detection
KW  - unmanned aerial vehicle
KW  - urban drainage
KW  - asset management
DO  - 10.3390/rs10050706
ER  -
TY  - EJOU
AU  - Kamminga, Jacob
AU  - Ayele, Eyuel
AU  - Meratnia, Nirvana
AU  - Havinga, Paul
TI  - Poaching Detection Technologies—A Survey
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 5
SN  - 1424-8220

AB  - Between 1960 and 1990, 95% of the black rhino population in the world was killed. In South Africa, a rhino was killed every 8 h for its horn throughout 2016. Wild animals, rhinos and elephants, in particular, are facing an ever increasing poaching crisis. In this paper, we review poaching detection technologies that aim to save endangered species from extinction. We present requirements for effective poacher detection and identify research challenges through the survey. We describe poaching detection technologies in four domains: perimeter based, ground based, aerial based, and animal tagging based technologies. Moreover, we discuss the different types of sensor technologies that are used in intruder detection systems such as: radar, magnetic, acoustic, optic, infrared and thermal, radio frequency, motion, seismic, chemical, and animal sentinels. The ultimate long-term solution for the poaching crisis is to remove the drivers of demand by educating people in demanding countries and raising awareness of the poaching crisis. Until prevention of poaching takes effect, there will be a continuous urgent need for new (combined) approaches that take up the research challenges and provide better protection against poaching in wildlife areas.
KW  - anti-poaching
KW  - conservation
KW  - surveillance
KW  - intruder detetection
DO  - 10.3390/s18051474
ER  -
TY  - EJOU
AU  - Mohammed, Hani M.
AU  - El-Sheimy, Naser
TI  - A Descriptor-less Well-Distributed Feature Matching Method Using Geometrical Constraints and Template Matching
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 5
SN  - 2072-4292

AB  - The problem of feature matching comprises detection, description, and the preliminary matching of features. Commonly, these steps are followed by Random Sample Consensus (RANSAC) or one of its variants in order to filter the matches and find a correct model, which is usually the fundamental matrix. Unfortunately, this scheme may encounter some problems, such as mismatches of some of the features, which can be rejected later by RANSAC. Hence, important features might be discarded permanently. Another issue facing the matching scheme, especially in three-dimensional (3D) reconstruction, is the degeneracy of the fundamental matrix. In such a case, RANSAC tends to select matches that are concentrated over a particular area of the images and rejects other correct matches. This leads to a fundamental matrix that differs from the correct one, which can be obtained using the camera parameters. In this paper, these problems are tackled by providing a descriptor-less method for matching features. The proposed method utilises the geometric as well as the radiometric properties of the image pair. Starting with an initial set of roughly matched features, we can compute the homography and the fundamental matrix. These two entities are then used to find other corresponding features. Then, template matching is used to enhance the predicted locations of the correspondences. The method is a tradeoff between the number and distribution of matches, and the matching accuracy. Moreover, the number of outliers is usually small, which encourages the use of least squares to estimate the fundamental matrix, instead of RANSAC. As a result, the problem of degeneracy is targeted at the matching level, rather than at the RANSAC level. The method was tested on images taken by unmanned aerial vehicles (UAVs), with a focus on applications of 3D reconstruction, and on images taken by the camera of a smartphone for an indoor environment. The results emphasise that the proposed method is more deterministic rather than probabilistic and is also robust to the difference in orientation and scale. It also achieves a higher number of accurate and well-distributed matches compared with state-of-the-art methods.
KW  - feature matching
KW  - homography
KW  - fundamental matrix
KW  - epipolar geometry
KW  - template matching
KW  - normalised cross-correlation
DO  - 10.3390/rs10050747
ER  -
TY  - EJOU
AU  - Su, Xichao
AU  - Wu, Yu
AU  - Song, Jingyu
AU  - Yuan, Peilong
TI  - A Fuzzy Path Selection Strategy for Aircraft Landing on a Carrier
T2  - Applied Sciences

PY  - 2018
VL  - 8
IS  - 5
SN  - 2076-3417

AB  - Landing is one of the most dangerous tasks in all the operations on an aircraft carrier, and the landing safety is very important to the pilot and the flight deck operation. Nowadays, the landing safety of carrier aircraft is improved by designing an automatic landing controller and by training the pilot to increase his/her control ability. However, the importance of choosing the landing path has not been investigated thus far. In this paper, the problem of landing path selection for an aircraft carrier is studied as there are several candidates corresponding to different situations. A fuzzy path selection strategy is proposed to solve the problem considering the fuzziness of environmental information and human judgment, and the goal is to provide the pilot with a more reasonable decision. The strategy is in view of the idea of Fuzzy Multi-attribute Group Decision Making (FMAGDM), which has been widely used in industry. Firstly, the background of the landing path selection is given. Then, the factors influencing the decision making are abstracted to build the conceptual model. A TOPSIS-based group decision-making method is developed to denote the preference of each decision maker for each alternative route, and the optimal landing path under the current environment is determined taking into account the knowledge and the weight of both the pilot and the landing console operator (LCO). Experimental studies under different setups, i.e., different environments, are carried out. The results demonstrate that the proposed path selection strategy is validated in different environments, and the optimal landing paths corresponding to different environments can be determined.
KW  - landing
KW  - aircraft carrier
KW  - landing path
KW  - fuzziness
KW  - fuzzy multi-attribute group decision making
DO  - 10.3390/app8050779
ER  -
TY  - EJOU
AU  - Lee, Junghee
AU  - Im, Jungho
AU  - Kim, Kyungmin
AU  - Quackenbush, Lindi J.
TI  - Machine Learning Approaches for Estimating Forest Stand Height Using Plot-Based Observations and Airborne LiDAR Data
T2  - Forests

PY  - 2018
VL  - 9
IS  - 5
SN  - 1999-4907

AB  - Effective sustainable forest management for broad areas needs consistent country-wide forest inventory data. A stand-level inventory is appropriate as a minimum unit for local and regional forest management. South Korea currently produces a forest type map that contains only four categorical parameters. Stand height is a crucial forest attribute for understanding forest ecosystems that is currently missing and should be included in future forest type maps. Estimation of forest stand height is challenging in South Korea because stands exist in small and irregular patches on highly rugged terrain. In this study, we proposed stand height estimation models suitable for rugged terrain with highly mixed tree species. An arithmetic mean height was used as a target variable. Plot-level height estimation models were first developed using 20 descriptive statistics from airborne Light Detection and Ranging (LiDAR) data and three machine learning approaches—support vector regression (SVR), modified regression trees (RT) and random forest (RF). Two schemes (i.e., central plot-based (Scheme 1) and stand-based (Scheme 2)) for expanding from the plot level to the stand level were then investigated. The results showed varied performance metrics (i.e., coefficient of determination, root mean square error, and mean bias) by model for forest height estimation at the plot level. There was no statistically significant difference among the three mean plot height models (i.e., SVR, RT and RF) in terms of estimated heights and bias (p-values &gt; 0.05). The stand-level validation based on all tree measurements for three selected stands produced varied results by scheme and machine learning used. It implies that additional reference data should be used for a more thorough stand-level validation to identify statistically robust approaches in the future. Nonetheless, the research findings from this study can be used as a guide for estimating stand heights for forests in rugged terrain and with complex composition of tree species.
KW  - forest stand height
KW  - plot-level to stand-level expansion methods
KW  - airborne LiDAR
KW  - machine learning
DO  - 10.3390/f9050268
ER  -
TY  - EJOU
AU  - Viljanen, Niko
AU  - Honkavaara, Eija
AU  - Näsi, Roope
AU  - Hakala, Teemu
AU  - Niemeläinen, Oiva
AU  - Kaivosoja, Jere
TI  - A Novel Machine Learning Method for Estimating Biomass of Grass Swards Using a Photogrammetric Canopy Height Model, Images and Vegetation Indices Captured by a Drone
T2  - Agriculture

PY  - 2018
VL  - 8
IS  - 5
SN  - 2077-0472

AB  - Silage is the main feed in milk and ruminant meat production in Northern Europe. Novel drone-based remote sensing technology could be utilized in many phases of silage production, but advanced methods of utilizing these data are still developing. Grass swards are harvested three times in season, and fertilizer is applied similarly three times—once for each harvest when aiming at maximum yields. Timely information of the yield is thus necessary several times in a season for making decisions on harvesting time and rate of fertilizer application. Our objective was to develop and assess a novel machine learning technique for the estimation of canopy height and biomass of grass swards utilizing multispectral photogrammetric camera data. Variation in the studied crop stand was generated using six different nitrogen fertilizer levels and four harvesting dates. The sward was a timothy-meadow fescue mixture dominated by timothy. We extracted various features from the remote sensing data by combining an ultra-high resolution photogrammetric canopy height model (CHM) with a pixel size of 1.0 cm and red, green, blue (RGB) and near-infrared range intensity values and different vegetation indices (VI) extracted from orthophoto mosaics. We compared the performance of multiple linear regression (MLR) and a Random Forest estimator (RF) with different combinations of the CHM, RGB and VI features. The best estimation results with both methods were obtained by combining CHM and VI features and all three feature classes (CHM, RGB and VI features). Both estimators provided equally accurate results. The Pearson correlation coefficients (PCC) and Root Mean Square Errors (RMSEs) of the estimations were at best 0.98 and 0.34 t/ha (12.70%), respectively, for the dry matter yield (DMY) and 0.98 and 1.22 t/ha (11.05%), respectively, for the fresh yield (FY) estimations. Our assessment of the sensitivity of the method with respect to different development stages and different amounts of biomass showed that the use of the machine learning technique that integrated multiple features improved the results in comparison to the simple linear regressions. These results were extremely promising, showing that the proposed multispectral photogrammetric approach can provide accurate biomass estimates of grass swards, and could be developed as a low-cost tool for practical farming applications.
KW  - photogrammetry
KW  - drone
KW  - unmanned aerial vehicle
KW  - digital surface model
KW  - canopy height model
KW  - grass sward
KW  - biomass
KW  - machine learning
KW  - Random Forest
KW  - multiple linear regression
DO  - 10.3390/agriculture8050070
ER  -
TY  - EJOU
AU  - Li, Dan
AU  - Gu, Xingfa
AU  - Pang, Yong
AU  - Chen, Bowei
AU  - Liu, Luxia
TI  - Estimation of Forest Aboveground Biomass and Leaf Area Index Based on Digital Aerial Photograph Data in Northeast China
T2  - Forests

PY  - 2018
VL  - 9
IS  - 5
SN  - 1999-4907

AB  - Forest aboveground biomass (AGB) and leaf area index (LAI) are two important parameters for evaluating forest growth and health. It is of great significance to estimate AGB and LAI accurately using remote sensing technology. Considering the temporal resolution and data acquisition costs, digital aerial photographs (DAPs) from a digital camera mounted on an unmanned aerial vehicle or light, small aircraft have been widely used in forest inventory. In this study, the aerial photograph data was acquired on 5 and 9 June, 2017 by a Hasselblad60 digital camera of the CAF-LiCHy system in a Y-5 aircraft in the Mengjiagang forest farm of Northeast China, and the digital orthophoto mosaic (DOM) and photogrammetric point cloud (PPC) were generated from an aerial overlap photograph. Forest red-green-blue (RGB) vegetation indices and textural factors were extracted from the DOM. Forest vertical structure features and canopy cover were extracted from normalized PPC. Regression analysis was carried out considering only DOM data, only PPC data, and a combination of both. A recursive feature elimination (RFE) method using a random forest was used for variable selection. Four different machine-learning (ML) algorithms (random forest, k-nearest neighbor, Cubist and supporting vector machine) were used to build regression models. Experimental results showed that PPC data alone could estimate AGB, and DOM data alone could estimate LAI with relatively high accuracy. The combination of features from DOM and PPC data was the most effective, in all the experiments considered, for the estimation of AGB and LAI. The results showed that the height and coverage variables of PPC, texture mean value, and the visible differential vegetation index (VDVI) of the DOM are significantly related to the estimated AGB (R2 = 0.73, RMSE = 20 t/ha). The results also showed that the canopy cover of PPC and green red ratio index (GRRI) of DOM are the most strongly related to the estimated LAI, and the height and coverage variables of PPC, the texture mean value and visible atmospherically resistant index (VARI), and the VDVI of DOM followed (R2 = 0.79, RMSE = 0.48).
KW  - digital aerial photograph
KW  - aboveground biomass
KW  - leaf area index
KW  - photogrammetric point cloud
KW  - recursive feature elimination
KW  - machine-learning
DO  - 10.3390/f9050275
ER  -
TY  - EJOU
AU  - Joalland, Samuel
AU  - Screpanti, Claudio
AU  - Varella, Hubert V.
AU  - Reuther, Marie
AU  - Schwind, Mareike
AU  - Lang, Christian
AU  - Walter, Achim
AU  - Liebisch, Frank
TI  - Aerial and Ground Based Sensing of Tolerance to Beet Cyst Nematode in Sugar Beet
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 5
SN  - 2072-4292

AB  - The rapid development of image-based phenotyping methods based on ground-operating devices or unmanned aerial vehicles (UAV) has increased our ability to evaluate traits of interest for crop breeding in the field. A field site infested with beet cyst nematode (BCN) and planted with four nematode susceptible cultivars and five tolerant cultivars was investigated at different times during the growing season. We compared the ability of spectral, hyperspectral, canopy height- and temperature information derived from handheld and UAV-borne sensors to discriminate susceptible and tolerant cultivars and to predict the final sugar beet yield. Spectral indices (SIs) related to chlorophyll, nitrogen or water allowed differentiating nematode susceptible and tolerant cultivars (cultivar type) from the same genetic background (breeder). Discrimination between the cultivar types was easier at advanced stages when the nematode pressure was stronger and the plants and canopies further developed. The canopy height (CH) allowed differentiating cultivar type as well but was much more efficient from the UAV compared to manual field assessment. Canopy temperatures also allowed ranking cultivars according to their nematode tolerance level. Combinations of SIs in multivariate analysis and decision trees improved differentiation of cultivar type and classification of genetic background. Thereby, SIs and canopy temperature proved to be suitable proxies for sugar yield prediction. The spectral information derived from handheld and the UAV-borne sensor did not match perfectly, but both analysis procedures allowed for discrimination between susceptible and tolerant cultivars. This was possible due to successful detection of traits related to BCN tolerance like chlorophyll, nitrogen and water content, which were reduced in cultivars with a low tolerance to BCN. The high correlation between SIs and final sugar beet yield makes the UAV hyperspectral imaging approach very suitable to improve farming practice via maps of yield potential or diseases. Moreover, the study shows the high potential of multi- sensor and parameter combinations for plant phenotyping purposes, in particular for data from UAV-borne sensors that allow for standardized and automated high-throughput data extraction procedures.
KW  - hyperspectral images
KW  - spectrometry
KW  - canopy height
KW  - thermography
KW  - UAV
KW  - Heterodera schachtii
KW  - root
KW  - field
DO  - 10.3390/rs10050787
ER  -
TY  - EJOU
AU  - Moeckel, Thomas
AU  - Dayananda, Supriya
AU  - Nidamanuri, Rama R.
AU  - Nautiyal, Sunil
AU  - Hanumaiah, Nagaraju
AU  - Buerkert, Andreas
AU  - Wachendorf, Michael
TI  - Estimation of Vegetable Crop Parameter by Multi-temporal UAV-Borne Images
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 5
SN  - 2072-4292

AB  - 3D point cloud analysis of imagery collected by unmanned aerial vehicles (UAV) has been shown to be a valuable tool for estimation of crop phenotypic traits, such as plant height, in several species. Spatial information about these phenotypic traits can be used to derive information about other important crop characteristics, like fresh biomass yield, which could not be derived directly from the point clouds. Previous approaches have often only considered single date measurements using a single point cloud derived metric for the respective trait. Furthermore, most of the studies focused on plant species with a homogenous canopy surface. The aim of this study was to assess the applicability of UAV imagery for capturing crop height information of three vegetables (crops eggplant, tomato, and cabbage) with a complex vegetation canopy surface during a complete crop growth cycle to infer biomass. Additionally, the effect of crop development stage on the relationship between estimated crop height and field measured crop height was examined. Our study was conducted in an experimental layout at the University of Agricultural Science in Bengaluru, India. For all the crops, the crop height and the biomass was measured at five dates during one crop growth cycle between February and May 2017 (average crop height was 42.5, 35.5, and 16.0 cm for eggplant, tomato, and cabbage). Using a structure from motion approach, a 3D point cloud was created for each crop and sampling date. In total, 14 crop height metrics were extracted from the point clouds. Machine learning methods were used to create prediction models for vegetable crop height. The study demonstrates that the monitoring of crop height using an UAV during an entire growing period results in detailed and precise estimates of crop height and biomass for all three crops (R2 ranging from 0.87 to 0.97, bias ranging from &minus;0.66 to 0.45 cm). The effect of crop development stage on the predicted crop height was found to be substantial (e.g., median deviation increased from 1% to 20% for eggplant) influencing the strength and consistency of the relationship between point cloud metrics and crop height estimates and, thus, should be further investigated. Altogether the results of the study demonstrate that point cloud generated from UAV-based RGB imagery can be used to effectively measure vegetable crop biomass in larger areas (relative error = 17.6%, 19.7%, and 15.2% for eggplant, tomato, and cabbage, respectively) with a similar accuracy as biomass prediction models based on measured crop height (relative error = 21.6, 18.8, and 15.2 for eggplant, tomato, and cabbage).
KW  - point clouds
KW  - biomass
KW  - crop height
KW  - machine learning
KW  - unmanned aerial vehicles
KW  - multi-spectral
DO  - 10.3390/rs10050805
ER  -
TY  - EJOU
AU  - Silveira, Eduarda M. O.
AU  - Bueno, Inácio T.
AU  - Acerbi-Junior, Fausto W.
AU  - Mello, José M.
AU  - Scolforo, José Roberto S.
AU  - Wulder, Michael A.
TI  - Using Spatial Features to Reduce the Impact of Seasonality for Detecting Tropical Forest Changes from Landsat Time Series
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 6
SN  - 2072-4292

AB  - In forested areas that experience strong seasonality and are undergoing rapid land cover conversion (e.g., Brazilian savannas), the accuracy of remote sensing change detection is affected by seasonal changes that are erroneously classified as having changed. To improve the quality and consistency of regionally important forest change maps, we aim to separate process related change (for example, spectral variability due to phenology) from changes related to deforestations or fires. Seasonal models are typically used to account for seasonality, but fitting a model is difficult when there are insufficient data points in the time series. In this research, we utilize remotely sensed data and related spectral trends and the spatial context at the object level to evaluate the performance of geostatistical features to reduce the impact of seasonality from the NDVI (Normalized Difference Vegetation Index) of Landsat time series. The study area is the S&atilde;o Rom&atilde;o municipality, totaling 2440 km2, and is part of the Brazilian savannas biome. We first create image objects via multiresolution segmentation, basing the objects on the characteristics found in the first image (2003) of the 13-year time series. We intersected the objects with the NDVI images in order to extract semivariogram indices, the RVF (Ratio Variance&mdash;First lag) and AFM (Area First lag&mdash;First Maximum), and spectral information (average and standard deviation of NDVI values) to generate the time series from these features and to derive Spatio-Temporal Metrics (change and trend) to train a Random Forest (RF) algorithm. The NDVI spatial variability, captured by the AFM semivariogram index time series produced the best result, reaching 96.53% of the overall accuracy (OA) to separate no-change from forest change, while the greatest inter-class confusion occurred using the average of the NDVI values time series (OA = 63.72%). The spatial context approach we presented is a novel approach for the detection of forest change events that are subject to seasonality (and possible miss-classification of change) and mitigating the effects of forest phenology without the need for specific de-seasoning models.
KW  - remote sensing
KW  - geostatistical
KW  - semivariogram
KW  - change detection
KW  - NDVI
KW  - forest phenology
KW  - savannas
DO  - 10.3390/rs10060808
ER  -
TY  - EJOU
AU  - Liu, Xiaofei
AU  - Yang, Tao
AU  - Li, Jing
TI  - Real-Time Ground Vehicle Detection in Aerial Infrared Imagery Based on Convolutional Neural Network
T2  - Electronics

PY  - 2018
VL  - 7
IS  - 6
SN  - 2079-9292

AB  - An infrared sensor is a commonly used imaging device. Unmanned aerial vehicles, the most promising moving platform, each play a vital role in their own field, respectively. However, the two devices are seldom combined in automatic ground vehicle detection tasks. Therefore, how to make full use of them&mdash;especially in ground vehicle detection based on aerial imagery&ndash;has aroused wide academic concern. However, due to the aerial imagery&rsquo;s low-resolution and the vehicle detection&rsquo;s complexity, how to extract remarkable features and handle pose variations, view changes as well as surrounding radiation remains a challenge. In fact, these typical abstract features extracted by convolutional neural networks are more recognizable than the engineering features, and those complex conditions involved can be learned and memorized before. In this paper, a novel approach towards ground vehicle detection in aerial infrared images based on a convolutional neural network is proposed. The UAV and the infrared sensor used in this application are firstly introduced. Then, a novel aerial moving platform is built and an aerial infrared vehicle dataset is unprecedentedly constructed. We publicly release this dataset (NPU_CS_UAV_IR_DATA), which can be used for the following research in this field. Next, an end-to-end convolutional neural network is built. With large amounts of recognized features being iteratively learned, a real-time ground vehicle model is constructed. It has the unique ability to detect both the stationary vehicles and moving vehicles in real urban environments. We evaluate the proposed algorithm on some low&ndash;resolution aerial infrared images. Experiments on the NPU_CS_UAV_IR_DATA dataset demonstrate that the proposed method is effective and efficient to recognize the ground vehicles. Moreover it can accomplish the task in real-time while achieving superior performances in leak and false alarm ratio.
KW  - aerial infrared imagery
KW  - real-time ground vehicle detection
KW  - convolutional neural network
KW  - unmanned aerial vehicle
DO  - 10.3390/electronics7060078
ER  -
TY  - EJOU
AU  - Nguyen, Phong H.
AU  - Arsalan, Muhammad
AU  - Koo, Ja H.
AU  - Naqvi, Rizwan A.
AU  - Truong, Noi Q.
AU  - Park, Kang R.
TI  - LightDenseYOLO: A Fast and Accurate Marker Tracker for Autonomous UAV Landing by Visible Light Camera Sensor on Drone
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 6
SN  - 1424-8220

AB  - Autonomous landing of an unmanned aerial vehicle or a drone is a challenging problem for the robotics research community. Previous researchers have attempted to solve this problem by combining multiple sensors such as global positioning system (GPS) receivers, inertial measurement unit, and multiple camera systems. Although these approaches successfully estimate an unmanned aerial vehicle location during landing, many calibration processes are required to achieve good detection accuracy. In addition, cases where drones operate in heterogeneous areas with no GPS signal should be considered. To overcome these problems, we determined how to safely land a drone in a GPS-denied environment using our remote-marker-based tracking algorithm based on a single visible-light-camera sensor. Instead of using hand-crafted features, our algorithm includes a convolutional neural network named lightDenseYOLO to extract trained features from an input image to predict a marker&rsquo;s location by visible light camera sensor on drone. Experimental results show that our method significantly outperforms state-of-the-art object trackers both using and not using convolutional neural network in terms of both accuracy and processing time.
KW  - unmanned aerial vehicle
KW  - autonomous landing
KW  - real-time marker detection
KW  - lightDenseYOLO
KW  - visible light camera sensor on drone
DO  - 10.3390/s18061703
ER  -
TY  - EJOU
AU  - Zhu, Jiasong
AU  - Sun, Ke
AU  - Jia, Sen
AU  - Lin, Weidong
AU  - Hou, Xianxu
AU  - Liu, Bozhi
AU  - Qiu, Guoping
TI  - Bidirectional Long Short-Term Memory Network for Vehicle Behavior Recognition
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 6
SN  - 2072-4292

AB  - Vehicle behavior recognition is an attractive research field which is useful for many computer vision and intelligent traffic analysis tasks. This paper presents an all-in-one behavior recognition framework for moving vehicles based on the latest deep learning techniques. Unlike traditional traffic analysis methods which rely on low-resolution videos captured by road cameras, we capture 4K (    3840 × 2178    ) traffic videos at a busy road intersection of a modern megacity by flying a unmanned aerial vehicle (UAV) during the rush hours. We then manually annotate locations and types of road vehicles. The proposed method consists of the following three steps: (1) vehicle detection and type recognition based on deep neural networks; (2) vehicle tracking by data association and vehicle trajectory modeling; (3) vehicle behavior recognition by nearest neighbor search and by bidirectional long short-term memory network, respectively. This paper also presents experimental results of the proposed framework in comparison with state-of-the-art approaches on the 4K testing traffic video, which demonstrated the effectiveness and superiority of the proposed method.
KW  - unmanned aerial vehicles (UAVs)
KW  - deep neural networks
KW  - vehicle detection
KW  - vehicle tracking
KW  - behavior recognition
KW  - long short-term memory
DO  - 10.3390/rs10060887
ER  -
TY  - EJOU
AU  - Zecha, Christoph W.
AU  - Peteinatos, Gerassimos G.
AU  - Link, Johanna
AU  - Claupein, Wilhelm
TI  - Utilisation of Ground and Airborne Optical Sensors for Nitrogen Level Identification and Yield Prediction in Wheat
T2  - Agriculture

PY  - 2018
VL  - 8
IS  - 6
SN  - 2077-0472

AB  - A healthy crop growth ensures a good biomass development for optimal yield amounts and qualities. This can only be achieved with sufficient knowledge about field conditions. In this study we investigated the performance of optical sensors in large field trails, to predict yield and biomass characteristics. This publication investigated how information fusion can support farming decisions. We present the results of four site-year studies with one fluorescence sensor and two spectrometers mounted on a ground sensor platform, and one spectrometer built into a fixed-wing unmanned aerial vehicle (UAV). The measurements have been carried out in three winter wheat fields (Triticum aestivum L.) with different Nitrogen (N) levels. The sensor raw data have been processed and converted to features (indices and ratios) that correlate with field information and biological parameters. The aerial spectrometer indices showed correlations with the ground truth data only for site-year 2. FERARI (Fluorescence Excitation Ratio Anthocyanin Relative Index) and SFR (Simple Fluorescence Ratio) from the Multiplex&reg; Research fluorometer (MP) in 2012 showed significant correlations with yield (Adj. r     2    &le; 0.63), and the NDVI (Normalised Difference Vegetation Index) and OSAVI (Optimized Soil-Adjusted Vegetation Index) of the FieldSpec HandHeld sensor (FS) even higher correlations with an Adj. r     2    &le; 0.67. Concerning the available N (N     avail    ), the REIP (Red-Edge Inflection Point) and CropSpec indices from the FS sensor had a high correlation (Adj. r     2    &le; 0.86), while the MP ratio SFR was slightly lower (Adj. r     2    &le; 0.67). Concerning the biomass weight, the REIP and SAVI indices had an Adj. r     2    &le; 0.78, and the FERARI and SFR ratios an Adj. r     2    &le; 0.85. The indices of the HandySpec Field     &reg;    spectrometer gave a lower significance level than the FS sensor, and lower correlations (Adj. r     2    &le; 0.64) over all field measurements. The features of MP and FS sensor have been used to create a feature fusion model. A developed linear model for site-year 4 has been used for evaluating the rest of the data sets. The used model did not correlate on a significant de novo level but by changing only one parameter, it resulted in a significant correlation. The data analysis reveals that by increasing mixed features from different sensors in a model, the higher and more robust the r     2    values became. New advanced algorithms, in combination with existent map overlay approaches, have the potential of complete and weighted decision fusion, to ensure the maximum yield for each specific field condition.
KW  - precision farming
KW  - sensor fusion
KW  - remote sensing
KW  - fluorescence
KW  - reflectance
KW  - spectrometry
KW  - nitrogen fertilisation
KW  - wheat
KW  - yield
DO  - 10.3390/agriculture8060079
ER  -
TY  - EJOU
AU  - Kim, In-Ho
AU  - Jeon, Haemin
AU  - Baek, Seung-Chan
AU  - Hong, Won-Hwa
AU  - Jung, Hyung-Jo
TI  - Application of Crack Identification Techniques for an Aging Concrete Bridge Inspection Using an Unmanned Aerial Vehicle
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 6
SN  - 1424-8220

AB  - Bridge inspection using unmanned aerial vehicles (UAV) with high performance vision sensors has received considerable attention due to its safety and reliability. As bridges become obsolete, the number of bridges that need to be inspected increases, and they require much maintenance cost. Therefore, a bridge inspection method based on UAV with vision sensors is proposed as one of the promising strategies to maintain bridges. In this paper, a crack identification method by using a commercial UAV with a high resolution vision sensor is investigated in an aging concrete bridge. First, a point cloud-based background model is generated in the preliminary flight. Then, cracks on the structural surface are detected with the deep learning algorithm, and their thickness and length are calculated. In the deep learning method, region with convolutional neural networks (R-CNN)-based transfer learning is applied. As a result, a new network for the 384 collected crack images of 256 &times; 256 pixel resolution is generated from the pre-trained network. A field test is conducted to verify the proposed approach, and the experimental results proved that the UAV-based bridge inspection is effective at identifying and quantifying the cracks on the structures.
KW  - crack identification
KW  - deep learning
KW  - unmanned aerial vehicle (UAV)
KW  - computer vision
KW  - spatial information
DO  - 10.3390/s18061881
ER  -
TY  - EJOU
AU  - Mattupalli, Chakradhar
AU  - Moffet, Corey A.
AU  - Shah, Kushendra N.
AU  - Young, Carolyn A.
TI  - Supervised Classification of RGB Aerial Imagery to Evaluate the Impact of a Root Rot Disease
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 6
SN  - 2072-4292

AB  - Aerial imaging provides a landscape view of crop fields that can be utilized to monitor plant diseases. Phymatotrichopsis root rot (PRR) is a serious root rot disease affecting several dicotyledonous hosts, including the perennial forage crop alfalfa. PRR disease causes stand loss by spreading as circular to irregular diseased areas that increase over time, but disease progression in alfalfa fields is poorly understood. The objectives of this study were to develop a workflow to produce PRR disease maps from sets of high-resolution red, green and blue (RGB) images acquired from two different platforms and to assess the feasibility of using these PRR disease maps to monitor disease progression in alfalfa fields. Aerial RGB images, two from unmanned aircraft systems (UAS) and four images from a manned aircraft platform were acquired at different time points during the 2014&ndash;2015 growing seasons from a center-pivot irrigated, PRR-infested alfalfa field near Burneyville, OK. Supervised classification of images acquired from both platforms were performed using three spectral signatures: image-specific, UAS-platform-specific and manned-aircraft platform-specific. Our results showed that the UAS-platform-specific spectral signature was most efficient for classifying images acquired with the UAS, with accuracy ranging from 90 to 96%. In contrast, manned-aircraft-acquired images classified using image-specific spectral signatures yielded 95 to 100% accuracy. The effect of hue, saturation and value color space transformations (HSV and Hrot60SV) on classification accuracy was determined, but the accuracy estimates showed no improvement in their efficiency compared to the RGB color space. Finally, the data showed that the classification of the bare ground increased by 74% during the study period, indicating the extent of alfalfa stand loss caused by PRR disease. Thus, this study showed the utility of high-resolution RGB aerial images for monitoring PRR disease spread in alfalfa.
KW  - cotton root rot
KW  - soil-borne fungus
KW  - disease monitoring
KW  - Phymatotrichopsis omnivora
DO  - 10.3390/rs10060917
ER  -
TY  - EJOU
AU  - Khan, Zohaib
AU  - Chopin, Joshua
AU  - Cai, Jinhai
AU  - Eichi, Vahid-Rahimi
AU  - Haefele, Stephan
AU  - Miklavcic, Stanley J.
TI  - Quantitative Estimation of Wheat Phenotyping Traits Using Ground and Aerial Imagery
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 6
SN  - 2072-4292

AB  - This study evaluates an aerial and ground imaging platform for assessment of canopy development in a wheat field. The dependence of two canopy traits, height and vigour, on fertilizer treatment was observed in a field trial comprised of ten varieties of spring wheat. A custom-built mobile ground platform (MGP) and an unmanned aerial vehicle (UAV) were deployed at the experimental site for standard red, green and blue (RGB) image collection on five occasions. Meanwhile, reference field measurements of canopy height and vigour were manually recorded during the growing season. Canopy level estimates of height and vigour for each variety and treatment were computed by image analysis. The agreement between estimates from each platform and reference measurements was statistically analysed. Estimates of canopy height derived from MGP imagery were more accurate (RMSE = 3.95 cm, R2 = 0.94) than estimates derived from UAV imagery (RMSE = 6.64 cm, R2 = 0.85). In contrast, vigour was better estimated using the UAV imagery (RMSE = 0.057, R2 = 0.57), compared to MGP imagery (RMSE = 0.063, R2 = 0.42), albeit with a significant fixed and proportional bias. The ability of the platforms to capture differential development of traits as a function of fertilizer treatment was also investigated. Both imaging methodologies observed a higher median canopy height of treated plots compared with untreated plots throughout the season, and a greater median vigour of treated plots compared with untreated plots exhibited in the early growth stages. While the UAV imaging provides a high-throughput method for canopy-level trait determination, the MGP imaging captures subtle canopy structures, potentially useful for fine-grained analyses of plants.
KW  - unmanned aerial vehicle
KW  - mobile ground platform
KW  - canopy traits
KW  - canopy imaging
KW  - field phenotyping
KW  - wheat
KW  - height
KW  - vigour
DO  - 10.3390/rs10060950
ER  -
TY  - EJOU
AU  - Wang, Dong
AU  - Fang, Shenghui
AU  - Yang, Zhenzhong
AU  - Wang, Lin
AU  - Tang, Wenchao
AU  - Li, Yucui
AU  - Tong, Chunyan
TI  - A Regional Mapping Method for Oilseed Rape Based on HSV Transformation and Spectral Features
T2  - ISPRS International Journal of Geo-Information

PY  - 2018
VL  - 7
IS  - 6
SN  - 2220-9964

AB  - This study proposed a colorimetric transformation and spectral features-based oilseed rape extraction algorithm (CSRA) to map oilseed rape at the provincial scale as a first step towards country-scale coverage. Using a stepwise analysis strategy, our method gradually separates vegetation from non-vegetation, crop from non-crop, and oilseed rape from winter wheat. The wide-field view (WFV) images from Chinese Gaofen satellite no. 1 (GF-1) at six continuous flowering stages in Wuxue City, Hubei Province, China are used to extract the unique characteristics of oilseed rape during the flowering period and predict the parameter of the CSRA method. The oilseed rape maps of Hubei Province from 2014 to 2017 are obtained automatically based on the CSRA method using GF-1 WFV images. As a result, the CSRA-derived provincial oilseed rape maps achieved at least 85% overall accuracy of spatial consistency when comparing with local reference oilseed rape maps and lower than 20% absolute error of provincial planting areas when comparing with agricultural census data. The robustness of the CSRA method is also tested on other satellite images including one panchromatic and multispectral image from GF-2 and two RapidEye images. Moreover, the comparison between the CSRA and other previous methods is discussed using the six GF-1 WFV images of Wuxue City, showing the proposed method has better mapping accuracy than other tested methods. These results highlight the potential of our method for accurate extraction and regional mapping capacity for oilseed rape.
KW  - regional mapping
KW  - oilseed rape
KW  - flowering period
KW  - phenology difference
KW  - HSV transformation
KW  - stepwise analysis
KW  - Gaofen satellite imagery
DO  - 10.3390/ijgi7060224
ER  -
TY  - EJOU
AU  - Zalakeviciute, Rasa
AU  - López-Villada, Jesús
AU  - Rybarczyk, Yves
TI  - Contrasted Effects of Relative Humidity and Precipitation on Urban PM2.5 Pollution in High Elevation Urban Areas
T2  - Sustainability

PY  - 2018
VL  - 10
IS  - 6
SN  - 2071-1050

AB  - Levels of urban pollution can be influenced largely by meteorological conditions and the topography of the area. The impact of the relative humidity (RH) on the daily average PM2.5 concentrations was studied at several sites in a mid-size South American city at a high elevation over the period of nine years. In this work, we show that there is a positive correlation between daily average urban PM2.5 concentrations and the RH in traffic-busy central areas, and a negative correlation in the outskirts of the city in more industrial areas. While in the traffic sites strong events of precipitation (&ge;9 mm) played a major role in PM2.5 pollution removal, in the city outskirts, the PM2.5 concentrations decreased with increasing RH independently of rain accumulation. Increasing PM2.5 concentrations are to be expected in any highly motorized city where there is high RH and a lack of strong precipitation, especially in rapidly growing and developing countries with high motorization due to poor fuel quality. Finally, two models, based on a logistic regression algorithm, are proposed to describe the effect of rain and RH on PM2.5, when the source of pollution is traffic-based vs. industry-based.
KW  - relative humidity
KW  - precipitation
KW  - combustion efficiency
KW  - urban PM2.5
DO  - 10.3390/su10062064
ER  -
TY  - EJOU
AU  - Parsons, Mark
AU  - Bratanov, Dmitry
AU  - Gaston, Kevin J.
AU  - Gonzalez, Felipe
TI  - UAVs, Hyperspectral Remote Sensing, and Machine Learning Revolutionizing Reef Monitoring
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 7
SN  - 1424-8220

AB  - Recent advances in unmanned aerial system (UAS) sensed imagery, sensor quality/size, and geospatial image processing can enable UASs to rapidly and continually monitor coral reefs, to determine the type of coral and signs of coral bleaching. This paper describes an unmanned aerial vehicle (UAV) remote sensing methodology to increase the efficiency and accuracy of existing surveillance practices. The methodology uses a UAV integrated with advanced digital hyperspectral, ultra HD colour (RGB) sensors, and machine learning algorithms. This paper describes the combination of airborne RGB and hyperspectral imagery with in-water survey data of several types in-water survey of coral under diverse levels of bleaching. The paper also describes the technology used, the sensors, the UAS, the flight operations, the processing workflow of the datasets, the methods for combining multiple airborne and in-water datasets, and finally presents relevant results of material classification. The development of the methodology for the collection and analysis of airborne hyperspectral and RGB imagery would provide coral reef researchers, other scientists, and UAV practitioners with reliable data collection protocols and faster processing techniques to achieve remote sensing objectives.
KW  - in-water survey
KW  - UAS
KW  - hyperspectral camera
KW  - machine learning
KW  - image segmentation
KW  - support vector machines (SVM)
KW  - drones
DO  - 10.3390/s18072026
ER  -
TY  - EJOU
AU  - Rivas, Alberto
AU  - Chamoso, Pablo
AU  - González-Briones, Alfonso
AU  - Corchado, Juan M.
TI  - Detection of Cattle Using Drones and Convolutional Neural Networks
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 7
SN  - 1424-8220

AB  - Multirotor drones have been one of the most important technological advances of the last decade. Their mechanics are simple compared to other types of drones and their possibilities in flight are greater. For example, they can take-off vertically. Their capabilities have therefore brought progress to many professional activities. Moreover, advances in computing and telecommunications have also broadened the range of activities in which drones may be used. Currently, artificial intelligence and information analysis are the main areas of research in the field of computing. The case study presented in this article employed artificial intelligence techniques in the analysis of information captured by drones. More specifically, the camera installed in the drone took images which were later analyzed using Convolutional Neural Networks (CNNs) to identify the objects captured in the images. In this research, a CNN was trained to detect cattle, however the same training process could be followed to develop a CNN for the detection of any other object. This article describes the design of the platform for real-time analysis of information and its performance in the detection of cattle.
KW  - cattle detection
KW  - convolutional neural network
KW  - multirotor
KW  - drone
KW  - Unmanned Aerial Vehicle
DO  - 10.3390/s18072048
ER  -
TY  - EJOU
AU  - Guerra, Edmundo
AU  - Munguía, Rodrigo
AU  - Grau, Antoni
TI  - UAV Visual and Laser Sensors Fusion for Detection and Positioning in Industrial Applications
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 7
SN  - 1424-8220

AB  - This work presents a solution to localize Unmanned Autonomous Vehicles with respect to pipes and other cylindrical elements found in inspection and maintenance tasks both in industrial and civilian infrastructures. The proposed system exploits the different features of vision and laser based sensors, combining them to obtain accurate positioning of the robot with respect to the cylindrical structures. A probabilistic (RANSAC-based) procedure is used to segment possible cylinders found in the laser scans, and this is used as a seed to accurately determine the robot position through a computer vision system. The priors obtained from the laser scan registration help to solve the problem of determining the apparent contour of the cylinders. In turn this apparent contour is used in a degenerate quadratic conic estimation, enabling to visually estimate the pose of the cylinder.
KW  - Unmanned Autonomous Vehicle
KW  - pose determination
KW  - LiDAR registration
KW  - apparent contour
DO  - 10.3390/s18072071
ER  -
TY  - EJOU
AU  - Adege, Abebe B.
AU  - Lin, Hsin-Piao
AU  - Tarekegn, Getaneh B.
AU  - Jeng, Shiann-Shiun
TI  - Applying Deep Neural Network (DNN) for Robust Indoor Localization in Multi-Building Environment
T2  - Applied Sciences

PY  - 2018
VL  - 8
IS  - 7
SN  - 2076-3417

AB  - In the Internet of Things (IoT) era, indoor localization plays a vital role in academia and industry. Wi-Fi is a promising scheme for indoor localization as it is easy and free of charge, even for private networks. However, Wi-Fi has signal fluctuation problems because of dynamic changes of environments and shadowing effects. In this paper, we propose to use a deep neural network (DNN) to achieve accurate localization in Wi-Fi environments. In the localization process, we primarily construct a database having all reachable received signal strengths (RSSs), and basic service set identifiers (BSSIDs). Secondly, we fill the missed RSS values using regression, and then apply linear discriminant analysis (LDA) to reduce features. Thirdly, the 5-BSSIDs having the strongest RSS values are appended with reduced RSS vector. Finally, a DNN is applied for localizing Wi-Fi users. The proposed system is evaluated in the classification and regression schemes using the python programming language. The results show that 99.15% of the localization accuracy is correctly classified. Moreover, the coordinate-based localization provides 50%, 75%, and 93.10% accuracies for errors less than 0.50 m, 0.75 m, and 0.90 m respectively. The proposed method is compared with other algorithms, and our method provides motivated results. The simulation results also show that the proposed method can robustly localize Wi-Fi users in hierarchical and complex wireless environments.
KW  - deep neural network
KW  - Internet of Things
KW  - linear discriminant analysis
KW  - Wi-Fi based indoor localization
DO  - 10.3390/app8071062
ER  -
TY  - EJOU
AU  - Huang, Huasheng
AU  - Lan, Yubin
AU  - Deng, Jizhong
AU  - Yang, Aqing
AU  - Deng, Xiaoling
AU  - Zhang, Lei
AU  - Wen, Sheng
TI  - A Semantic Labeling Approach for Accurate Weed Mapping of High Resolution UAV Imagery
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 7
SN  - 1424-8220

AB  - Weed control is necessary in rice cultivation, but the excessive use of herbicide treatments has led to serious agronomic and environmental problems. Suitable site-specific weed management (SSWM) is a solution to address this problem while maintaining the rice production quality and quantity. In the context of SSWM, an accurate weed distribution map is needed to provide decision support information for herbicide treatment. UAV remote sensing offers an efficient and effective platform to monitor weeds thanks to its high spatial resolution. In this work, UAV imagery was captured in a rice field located in South China. A semantic labeling approach was adopted to generate the weed distribution maps of the UAV imagery. An ImageNet pre-trained CNN with residual framework was adapted in a fully convolutional form, and transferred to our dataset by fine-tuning. Atrous convolution was applied to extend the field of view of convolutional filters; the performance of multi-scale processing was evaluated; and a fully connected conditional random field (CRF) was applied after the CNN to further refine the spatial details. Finally, our approach was compared with the pixel-based-SVM and the classical FCN-8s. Experimental results demonstrated that our approach achieved the best performance in terms of accuracy. Especially for the detection of small weed patches in the imagery, our approach significantly outperformed other methods. The mean intersection over union (mean IU), overall accuracy, and Kappa coefficient of our method were 0.7751, 0.9445, and 0.9128, respectively. The experiments showed that our approach has high potential in accurate weed mapping of UAV imagery.
KW  - UAV
KW  - remote sensing
KW  - weed mapping
KW  - Deep Fully Convolutional Network
KW  - semantic labeling
DO  - 10.3390/s18072113
ER  -
TY  - EJOU
AU  - Buscombe, Daniel
AU  - Ritchie, Andrew C.
TI  - Landscape Classification with Deep Neural Networks
T2  - Geosciences

PY  - 2018
VL  - 8
IS  - 7
SN  - 2076-3263

AB  - The application of deep learning, specifically deep convolutional neural networks (DCNNs), to the classification of remotely-sensed imagery of natural landscapes has the potential to greatly assist in the analysis and interpretation of geomorphic processes. However, the general usefulness of deep learning applied to conventional photographic imagery at a landscape scale is, at yet, largely unproven. If DCNN-based image classification is to gain wider application and acceptance within the geoscience community, demonstrable successes need to be coupled with accessible tools to retrain deep neural networks to discriminate landforms and land uses in landscape imagery. Here, we present an efficient approach to train/apply DCNNs with/on sets of photographic images, using a powerful graphical method called a conditional random field (CRF), to generate DCNN training and testing data using minimal manual supervision. We apply the method to several sets of images of natural landscapes, acquired from satellites, aircraft, unmanned aerial vehicles, and fixed camera installations. We synthesize our findings to examine the general effectiveness of transfer learning to landscape-scale image classification. Finally, we show how DCNN predictions on small regions of images might be used in conjunction with a CRF for highly accurate pixel-level classification of images.
KW  - image classification
KW  - image segmentation
KW  - land use
KW  - land cover
KW  - landforms
KW  - deep learning
KW  - machine learning
KW  - unmanned aerial systems
KW  - aerial imagery
KW  - remote sensing
DO  - 10.3390/geosciences8070244
ER  -
TY  - EJOU
AU  - Ismail, Adiel
AU  - Bagula, Bigomokero A.
AU  - Tuyishimire, Emmanuel
TI  - Internet-Of-Things in Motion: A UAV Coalition Model for Remote Sensing in Smart Cities
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 7
SN  - 1424-8220

AB  - Unmanned aerial vehicles (UAVs) or drones are increasingly used in cities to provide service tasks that are too dangerous, expensive or difficult for human beings. Drones are also used in cases where a task can be performed more economically and or more efficiently than if done by humans. These include remote sensing tasks where drones can be required to form coalitions by pooling their resources to meet the service requirements at different locations of interest in a city. During such coalition formation, finding the shortest path from a source to a location of interest is key to efficient service delivery. For fixed-wing UAVs, Dubins curves can be applied to find the shortest flight path. When a UAV flies to a location of interest, the angle or orientation of the UAV upon its arrival is often not important. In such a case, a simplified version of the Dubins curve consisting of two instead of three parts can be used. This paper proposes a novel model for UAV coalition and an algorithm derived from basic geometry that generates a path derived from the original Dubins curve for application in remote sensing missions of fixed-wing UAVs. The algorithm is tested by incorporating it into three cooperative coalition formation algorithms. The performance of the model is evaluated by varying the number of types of resources and the sensor ranges of the UAVs to reveal the relevance and practicality of the proposed model.
KW  - smart cities
KW  - Internet-of-Things
KW  - multi-drone task allocation
KW  - unmanned aerial vehicles
KW  - path planning
KW  - Dubins curves
KW  - particle swarm optimization
DO  - 10.3390/s18072184
ER  -
TY  - EJOU
AU  - Näsi, Roope
AU  - Viljanen, Niko
AU  - Kaivosoja, Jere
AU  - Alhonoja, Katja
AU  - Hakala, Teemu
AU  - Markelin, Lauri
AU  - Honkavaara, Eija
TI  - Estimating Biomass and Nitrogen Amount of Barley and Grass Using UAV and Aircraft Based Spectral and Photogrammetric 3D Features
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 7
SN  - 2072-4292

AB  - The timely estimation of crop biomass and nitrogen content is a crucial step in various tasks in precision agriculture, for example in fertilization optimization. Remote sensing using drones and aircrafts offers a feasible tool to carry out this task. Our objective was to develop and assess a methodology for crop biomass and nitrogen estimation, integrating spectral and 3D features that can be extracted using airborne miniaturized multispectral, hyperspectral and colour (RGB) cameras. We used the Random Forest (RF) as the estimator, and in addition Simple Linear Regression (SLR) was used to validate the consistency of the RF results. The method was assessed with empirical datasets captured of a barley field and a grass silage trial site using a hyperspectral camera based on the Fabry-P&eacute;rot interferometer (FPI) and a regular RGB camera onboard a drone and an aircraft. Agricultural reference measurements included fresh yield (FY), dry matter yield (DMY) and amount of nitrogen. In DMY estimation of barley, the Pearson Correlation Coefficient (PCC) and the normalized Root Mean Square Error (RMSE%) were at best 0.95% and 33.2%, respectively; and in the grass DMY estimation, the best results were 0.79% and 1.9%, respectively. In the nitrogen amount estimations of barley, the PCC and RMSE% were at best 0.97% and 21.6%, respectively. In the biomass estimation, the best results were obtained when integrating hyperspectral and 3D features, but the integration of RGB images and 3D features also provided results that were almost as good. In nitrogen content estimation, the hyperspectral camera gave the best results. We concluded that the integration of spectral and high spatial resolution 3D features and radiometric calibration was necessary to optimize the accuracy.
KW  - hyperspectral
KW  - photogrammetry
KW  - UAV
KW  - drone
KW  - machine learning
KW  - random forest
KW  - regression
KW  - precision agriculture
KW  - biomass
KW  - nitrogen
DO  - 10.3390/rs10071082
ER  -
TY  - EJOU
AU  - Bachmann, Daniel
AU  - Weichert, Frank
AU  - Rinkenauer, Gerhard
TI  - Review of Three-Dimensional Human-Computer Interaction with Focus on the Leap Motion Controller
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 7
SN  - 1424-8220

AB  - Modern hardware and software development has led to an evolution of user interfaces from command-line to natural user interfaces for virtual immersive environments. Gestures imitating real-world interaction tasks increasingly replace classical two-dimensional interfaces based on Windows/Icons/Menus/Pointers (WIMP) or touch metaphors. Thus, the purpose of this paper is to survey the state-of-the-art Human-Computer Interaction (HCI) techniques with a focus on the special field of three-dimensional interaction. This includes an overview of currently available interaction devices, their applications of usage and underlying methods for gesture design and recognition. Focus is on interfaces based on the Leap Motion Controller (LMC) and corresponding methods of gesture design and recognition. Further, a review of evaluation methods for the proposed natural user interfaces is given.
KW  - human-computer interaction
KW  - contact-free input devices
KW  - three-dimensional interaction
KW  - natural user interfaces
KW  - leap motion controller
DO  - 10.3390/s18072194
ER  -
TY  - EJOU
AU  - Aasen, Helge
AU  - Honkavaara, Eija
AU  - Lucieer, Arko
AU  - Zarco-Tejada, Pablo J.
TI  - Quantitative Remote Sensing at Ultra-High Resolution with UAV Spectroscopy: A Review of Sensor Technology, Measurement Procedures, and Data Correction Workflows
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 7
SN  - 2072-4292

AB  - In the last 10 years, development in robotics, computer vision, and sensor technology has provided new spectral remote sensing tools to capture unprecedented ultra-high spatial and high spectral resolution with unmanned aerial vehicles (UAVs). This development has led to a revolution in geospatial data collection in which not only few specialist data providers collect and deliver remotely sensed data, but a whole diverse community is potentially able to gather geospatial data that fit their needs. However, the diversification of sensing systems and user applications challenges the common application of good practice procedures that ensure the quality of the data. This challenge can only be met by establishing and communicating common procedures that have had demonstrated success in scientific experiments and operational demonstrations. In this review, we evaluate the state-of-the-art methods in UAV spectral remote sensing and discuss sensor technology, measurement procedures, geometric processing, and radiometric calibration based on the literature and more than a decade of experimentation. We follow the &lsquo;journey&rsquo; of the reflected energy from the particle in the environment to its representation as a pixel in a 2D or 2.5D map, or 3D spectral point cloud. Additionally, we reflect on the current revolution in remote sensing, and identify trends, potential opportunities, and limitations.
KW  - imaging spectroscopy
KW  - spectral
KW  - unmanned aerial vehicles
KW  - unmanned aerial systems (UAS)
KW  - Remotely Piloted Aircraft Systems (RPAS)
KW  - drone
KW  - calibration
KW  - hyperspectral
KW  - multispectral
KW  - low-altitude
KW  - remote sensing
KW  - sensors
KW  - 2D imager
KW  - pushbroom
KW  - snapshot
KW  - spectroradiometers
DO  - 10.3390/rs10071091
ER  -
TY  - EJOU
AU  - Petrellis, Nikos
TI  - A Review of Image Processing Techniques Common in Human and Plant Disease Diagnosis
T2  - Symmetry

PY  - 2018
VL  - 10
IS  - 7
SN  - 2073-8994

AB  - Image processing has been extensively used in various (human, animal, plant) disease diagnosis approaches, assisting experts to select the right treatment. It has been applied to both images captured from cameras of visible light and from equipment that captures information in invisible wavelengths (magnetic/ultrasonic sensors, microscopes, etc.). In most of the referenced diagnosis applications, the image is enhanced by various filtering methods and segmentation follows isolating the regions of interest. Classification of the input image is performed at the final stage. The disease diagnosis approaches based on these steps and the common methods are described. The features extracted from a plant/skin disease diagnosis framework developed by the author are used here to demonstrate various techniques adopted in the literature. The various metrics along with the available experimental conditions and results presented in the referenced approaches are also discussed. The accuracy achieved in the diagnosis methods that are based on image processing is often higher than 90%. The motivation for this review is to highlight the most common and efficient methods that have been employed in various disease diagnosis approaches and suggest how they can be used in similar or different applications.
KW  - image processing
KW  - disease diagnosis
KW  - plant disease
KW  - segmentation
KW  - classification
KW  - image filtering
DO  - 10.3390/sym10070270
ER  -
TY  - EJOU
AU  - Chen, Shiyu
AU  - Yuan, Xiuxiao
AU  - Yuan, Wei
AU  - Niu, Jiqiang
AU  - Xu, Feng
AU  - Zhang, Yong
TI  - Matching Multi-Sensor Remote Sensing Images via an Affinity Tensor
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 7
SN  - 2072-4292

AB  - Matching multi-sensor remote sensing images is still a challenging task due to textural changes and non-linear intensity differences. In this paper, a novel matching method is proposed for multi-sensor remote sensing images. To establish feature correspondences, an affinity tensor is used to integrate geometric and radiometric information. The matching process consists of three steps. First, features from an accelerated segment test are extracted from both source and target images, and two complete graphs are constructed with their nodes representing these features. Then, the geometric and radiometric similarities of the feature points are represented by the three-order affinity tensor, and the initial feature correspondences are established by tensor power iteration. Finally, a tensor-based mismatch detection process is conducted to purify the initial matched points. The robustness and capability of the proposed method are tested with a variety of remote sensing images such as Ziyuan-3 backward, Ziyuan-3 nadir, Gaofen-1, Gaofen-2, unmanned aerial vehicle platform, and Jilin-1. The experiments show that the average matching recall is greater than 0.5, which outperforms state-of-the-art multi-sensor image-matching algorithms such as SIFT, SURF, NG-SIFT, OR-SIFT and GOM-SIFT.
KW  - image matching
KW  - multi-sensor remote sensing image
KW  - graph theory
KW  - affinity tensor
KW  - matching blunder detection
DO  - 10.3390/rs10071104
ER  -
TY  - EJOU
AU  - De Oliveira, Diulhio C.
AU  - Wehrmeister, Marco A.
TI  - Using Deep Learning and Low-Cost RGB and Thermal Cameras to Detect Pedestrians in Aerial Images Captured by Multirotor UAV
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 7
SN  - 1424-8220

AB  - The use of Unmanned Aerial Vehicles (UAV) has been increasing over the last few years in many sorts of applications due mainly to the decreasing cost of this technology. One can see the use of the UAV in several civilian applications such as surveillance and search and rescue. Automatic detection of pedestrians in aerial images is a challenging task. The computing vision system must deal with many sources of variability in the aerial images captured with the UAV, e.g., low-resolution images of pedestrians, images captured at distinct angles due to the degrees of freedom that a UAV can move, the camera platform possibly experiencing some instability while the UAV flies, among others. In this work, we created and evaluated different implementations of Pattern Recognition Systems (PRS) aiming at the automatic detection of pedestrians in aerial images captured with multirotor UAV. The main goal is to assess the feasibility and suitability of distinct PRS implementations running on top of low-cost computing platforms, e.g., single-board computers such as the Raspberry Pi or regular laptops without a GPU. For that, we used four machine learning techniques in the feature extraction and classification steps, namely Haar cascade, LBP cascade, HOG + SVM and Convolutional Neural Networks (CNN). In order to improve the system performance (especially the processing time) and also to decrease the rate of false alarms, we applied the Saliency Map (SM) and Thermal Image Processing (TIP) within the segmentation and detection steps of the PRS. The classification results show the CNN to be the best technique with 99.7% accuracy, followed by HOG + SVM with 92.3%. In situations of partial occlusion, the CNN showed 71.1% sensitivity, which can be considered a good result in comparison with the current state-of-the-art, since part of the original image data is missing. As demonstrated in the experiments, by combining TIP with CNN, the PRS can process more than two frames per second (fps), whereas the PRS that combines TIP with HOG + SVM was able to process 100 fps. It is important to mention that our experiments show that a trade-off analysis must be performed during the design of a pedestrian detection PRS. The faster implementations lead to a decrease in the PRS accuracy. For instance, by using HOG + SVM with TIP, the PRS presented the best performance results, but the obtained accuracy was 35 percentage points lower than the CNN. The obtained results indicate that the best detection technique (i.e., the CNN) requires more computational resources to decrease the PRS computation time. Therefore, this work shows and discusses the pros/cons of each technique and trade-off situations, and hence, one can use such an analysis to improve and tailor the design of a PRS to detect pedestrians in aerial images.
KW  - pedestrian detection
KW  - aerial images
KW  - Unmanned Aerial Vehicle (UAV)
KW  - thermal camera
KW  - deep learning
KW  - convolutional neural network
KW  - pattern recognition system
KW  - performance assessment
DO  - 10.3390/s18072244
ER  -
TY  - EJOU
AU  - Xiang, Xuezhi
AU  - Lv, Ning
AU  - Guo, Xinli
AU  - Wang, Shuai
AU  - El Saddik, Abdulmotaleb
TI  - Engineering Vehicles Detection Based on Modified Faster R-CNN for Power Grid Surveillance
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 7
SN  - 1424-8220

AB  - Engineering vehicles intrusion detection is a key problem for the security of power grid operation, which can warn of the regional invasion and prevent external damage from architectural construction. In this paper, we propose an intelligent surveillance method based on the framework of Faster R-CNN for locating and identifying the invading engineering vehicles. In our detection task, the type of the objects is varied and the monitoring scene is large and complex. In order to solve these challenging problems, we modify the network structure of the object detection model by adjusting the position of the ROI pooling layer. The convolutional layer is added to the feature classification part to improve the accuracy of the detection model. We verify that increasing the depth of the feature classification part is effective for detecting engineering vehicles in realistic transmission lines corridors. We also collect plenty of scene images taken from the monitor site and label the objects to create a fine-tuned dataset. We train the modified deep detection model based on the technology of transfer learning and conduct training and test on the newly labeled dataset. Experimental results show that the proposed intelligent surveillance method can detect engineering vehicles with high accuracy and a low false alarm rate, which can be used for the early warning of power grid surveillance.
KW  - power grid surveillance
KW  - external damage
KW  - engineering vehicles
KW  - faster R-CNN
KW  - transfer learning
DO  - 10.3390/s18072258
ER  -
TY  - EJOU
AU  - Lausch, Angela
AU  - Borg, Erik
AU  - Bumberger, Jan
AU  - Dietrich, Peter
AU  - Heurich, Marco
AU  - Huth, Andreas
AU  - Jung, András
AU  - Klenke, Reinhard
AU  - Knapp, Sonja
AU  - Mollenhauer, Hannes
AU  - Paasche, Hendrik
AU  - Paulheim, Heiko
AU  - Pause, Marion
AU  - Schweitzer, Christian
AU  - Schmulius, Christiane
AU  - Settele, Josef
AU  - Skidmore, Andrew K.
AU  - Wegmann, Martin
AU  - Zacharias, Steffen
AU  - Kirsten, Toralf
AU  - Schaepman, Michael E.
TI  - Understanding Forest Health with Remote Sensing, Part III: Requirements for a Scalable Multi-Source Forest Health Monitoring Network Based on Data Science Approaches
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 7
SN  - 2072-4292

AB  - Forest ecosystems fulfill a whole host of ecosystem functions that are essential for life on our planet. However, an unprecedented level of anthropogenic influences is reducing the resilience and stability of our forest ecosystems as well as their ecosystem functions. The relationships between drivers, stress, and ecosystem functions in forest ecosystems are complex, multi-faceted, and often non-linear, and yet forest managers, decision makers, and politicians need to be able to make rapid decisions that are data-driven and based on short and long-term monitoring information, complex modeling, and analysis approaches. A huge number of long-standing and standardized forest health inventory approaches already exist, and are increasingly integrating remote-sensing based monitoring approaches. Unfortunately, these approaches in monitoring, data storage, analysis, prognosis, and assessment still do not satisfy the future requirements of information and digital knowledge processing of the 21st century. Therefore, this paper discusses and presents in detail five sets of requirements, including their relevance, necessity, and the possible solutions that would be necessary for establishing a feasible multi-source forest health monitoring network for the 21st century. Namely, these requirements are: (1) understanding the effects of multiple stressors on forest health; (2) using remote sensing (RS) approaches to monitor forest health; (3) coupling different monitoring approaches; (4) using data science as a bridge between complex and multidimensional big forest health (FH) data; and (5) a future multi-source forest health monitoring network. It became apparent that no existing monitoring approach, technique, model, or platform is sufficient on its own to monitor, model, forecast, or assess forest health and its resilience. In order to advance the development of a multi-source forest health monitoring network, we argue that in order to gain a better understanding of forest health in our complex world, it would be conducive to implement the concepts of data science with the components: (i) digitalization; (ii) standardization with metadata management after the FAIR (Findability, Accessibility, Interoperability, and Reusability) principles; (iii) Semantic Web; (iv) proof, trust, and uncertainties; (v) tools for data science analysis; and (vi) easy tools for scientists, data managers, and stakeholders for decision-making support.
KW  - forest health
KW  - in situ forest monitoring
KW  - remote sensing
KW  - data science
KW  - digitalization
KW  - big data
KW  - semantic web
KW  - linked open data
KW  - FAIR
KW  - multi-source forest health monitoring network
DO  - 10.3390/rs10071120
ER  -
TY  - EJOU
AU  - Lee, Ki-Baek
AU  - Kim, Young-Joo
AU  - Hong, Young-Dae
TI  - Real-Time Swarm Search Method for Real-World Quadcopter Drones
T2  - Applied Sciences

PY  - 2018
VL  - 8
IS  - 7
SN  - 2076-3417

AB  - This paper proposes a novel search method for a swarm of quadcopter drones. In the proposed method, inspired by the phenomena of swarms in nature, drones effectively look for the search target by investigating the evidence from the surroundings and communicating with each other. The position update mechanism is implemented using the particle swarm optimization algorithm as the swarm intelligence (a well-known swarm-based optimization algorithm), as well as a dynamic model for the drones to take the real-world environment into account. In addition, the mechanism is processed in real-time along with the movements of the drones. The effectiveness of the proposed method was verified through repeated test simulations, including a benchmark function optimization and air pollutant search problems. The results show that the proposed method is highly practical, accurate, and robust.
KW  - unmanned aerial vehicle
KW  - swarm intelligence
KW  - particle swarm optimization
KW  - search algorithm
DO  - 10.3390/app8071169
ER  -
TY  - EJOU
AU  - Feduck, Corey
AU  - McDermid, Gregory J.
AU  - Castilla, Guillermo
TI  - Detection of Coniferous Seedlings in UAV Imagery
T2  - Forests

PY  - 2018
VL  - 9
IS  - 7
SN  - 1999-4907

AB  - Rapid assessment of forest regeneration using unmanned aerial vehicles (UAVs) is likely to decrease the cost of establishment surveys in a variety of resource industries. This research tests the feasibility of using UAVs to rapidly identify coniferous seedlings in replanted forest-harvest areas in Alberta, Canada. In developing our protocols, we gave special consideration to creating a workflow that could perform in an operational context, avoiding comprehensive wall-to-wall surveys and complex photogrammetric processing in favor of an efficient sampling-based approach, consumer-grade cameras, and straightforward image handling. Using simple spectral decision rules from a red, green, and blue (RGB) camera, we documented a seedling detection rate of 75.8 % (n = 149), on the basis of independent test data. While moderate imbalances between the omission and commission errors suggest that our workflow has a tendency to underestimate the seedling density in a harvest block, the plot-level associations with ground surveys were very high (Pearson&rsquo;s r = 0.98; n = 14). Our results were promising enough to suggest that UAVs can be used to detect coniferous seedlings in an operational capacity with standard RGB cameras alone, although our workflow relies on seasonal leaf-off windows where seedlings are visible and spectrally distinct from their surroundings. In addition, the differential errors between the pine seedlings and spruce seedlings suggest that operational workflows could benefit from multiple decision rules designed to handle diversity in species and other sources of spectral variability.
KW  - unmanned aerial vehicles
KW  - seedling detection
KW  - forest regeneration
KW  - reforestation
KW  - establishment survey
KW  - machine learning
KW  - multispectral classification
DO  - 10.3390/f9070432
ER  -
TY  - EJOU
AU  - Yue, Jibo
AU  - Feng, Haikuan
AU  - Jin, Xiuliang
AU  - Yuan, Huanhuan
AU  - Li, Zhenhai
AU  - Zhou, Chengquan
AU  - Yang, Guijun
AU  - Tian, Qingjiu
TI  - A Comparison of Crop Parameters Estimation Using Images from UAV-Mounted Snapshot Hyperspectral Sensor and High-Definition Digital Camera
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 7
SN  - 2072-4292

AB  - Timely and accurate estimates of crop parameters are crucial for agriculture management. Unmanned aerial vehicles (UAVs) carrying sophisticated cameras are very pertinent for this work because they can obtain remote-sensing images with higher temporal, spatial, and ground resolution than satellites. In this study, we evaluated (i) the performance of crop parameters estimates using a near-surface spectroscopy (350~2500 nm, 3 nm at 700 nm, 8.5 nm at 1400 nm, 6.5 nm at 2100 nm), a UAV-mounted snapshot hyperspectral sensor (450~950 nm, 8 nm at 532 nm) and a high-definition digital camera (Visible, R, G, B); (ii) the crop surface models (CSMs), RGB-based vegetation indices (VIs), hyperspectral-based VIs, and methods combined therefrom to make multi-temporal estimates of crop parameters and to map the parameters. The estimated leaf area index (LAI) and above-ground biomass (AGB) are obtained by using linear and exponential equations, random forest (RF) regression, and partial least squares regression (PLSR) to combine the UAV based spectral VIs and crop heights (from the CSMs). The results show that: (i) spectral VIs correlate strongly with LAI and AGB over single growing stages when crop height correlates positively with AGB over multiple growth stages; (ii) the correlation between the VIs multiplying crop height and AGB is greater than that between a single VI and crop height; (iii) the AGB estimate from the UAV-mounted snapshot hyperspectral sensor and high-definition digital camera is similar to the results from the ground spectrometer when using the combined methods (i.e., using VIs multiplying crop height, RF and PLSR to combine VIs and crop heights); and (iv) the spectral performance of the sensors is crucial in LAI estimates (the wheat LAI cannot be accurately estimated over multiple growing stages when using only crop height). The LAI estimates ranked from best to worst are ground spectrometer, UAV snapshot hyperspectral sensor, and UAV high-definition digital camera.
KW  - crop surface model
KW  - crop height
KW  - aboveground biomass
KW  - LAI
KW  - random forest regression
KW  - partial least squares regression
DO  - 10.3390/rs10071138
ER  -
TY  - EJOU
AU  - Gopalakrishnan, Kasthurirangan
TI  - Deep Learning in Data-Driven Pavement Image Analysis and Automated Distress Detection: A Review
T2  - Data

PY  - 2018
VL  - 3
IS  - 3
SN  - 2306-5729

AB  - Deep learning, more specifically deep convolutional neural networks, is fast becoming a popular choice for computer vision-based automated pavement distress detection. While pavement image analysis has been extensively researched over the past three decades or so, recent ground-breaking achievements of deep learning algorithms in the areas of machine translation, speech recognition, and computer vision has sparked interest in the application of deep learning to automated detection of distresses in pavement images. This paper provides a narrative review of recently published studies in this field, highlighting the current achievements and challenges. A comparison of the deep learning software frameworks, network architecture, hyper-parameters employed by each study, and crack detection performance is provided, which is expected to provide a good foundation for driving further research on this important topic in the context of smart pavement or asset management systems. The review concludes with potential avenues for future research; especially in the application of deep learning to not only detect, but also characterize the type, extent, and severity of distresses from 2D and 3D pavement images.
KW  - pavement cracking
KW  - pavement management
KW  - pavement imaging
KW  - 3D image
KW  - deep learning
KW  - TensorFlow
KW  - deep convolutional neural networks
DO  - 10.3390/data3030028
ER  -
TY  - EJOU
AU  - Chabot, Dominique
AU  - Dillon, Christopher
AU  - Shemrock, Adam
AU  - Weissflog, Nicholas
AU  - Sager, Eric P. S.
TI  - An Object-Based Image Analysis Workflow for Monitoring Shallow-Water Aquatic Vegetation in Multispectral Drone Imagery
T2  - ISPRS International Journal of Geo-Information

PY  - 2018
VL  - 7
IS  - 8
SN  - 2220-9964

AB  - High-resolution drone aerial surveys combined with object-based image analysis are transforming our capacity to monitor and manage aquatic vegetation in an era of invasive species. To better exploit the potential of these technologies, there is a need to develop more efficient and accessible analysis workflows and focus more efforts on the distinct challenge of mapping submerged vegetation. We present a straightforward workflow developed to monitor emergent and submerged invasive water soldier (Stratiotes aloides) in shallow waters of the Trent-Severn Waterway in Ontario, Canada. The main elements of the workflow are: (1) collection of radiometrically calibrated multispectral imagery including a near-infrared band; (2) multistage segmentation of the imagery involving an initial separation of above-water from submerged features; and (3) automated classification of features with a supervised machine-learning classifier. The approach yielded excellent classification accuracy for emergent features (overall accuracy = 92%; kappa = 88%; water soldier producer&rsquo;s accuracy = 92%; user&rsquo;s accuracy = 91%) and good accuracy for submerged features (overall accuracy = 84%; kappa = 75%; water soldier producer&rsquo;s accuracy = 71%; user&rsquo;s accuracy = 84%). The workflow employs off-the-shelf graphical software tools requiring no programming or coding, and could therefore be used by anyone with basic GIS and image analysis skills for a potentially wide variety of aquatic vegetation monitoring operations.
KW  - environmental monitoring
KW  - freshwater ecosystems
KW  - OBIA
KW  - random forests
KW  - remote sensing
KW  - rivers
KW  - unmanned aircraft
KW  - UAS
KW  - UAV
KW  - wetlands
DO  - 10.3390/ijgi7080294
ER  -
TY  - EJOU
AU  - Fu, Shu
AU  - Zhao, Lian
AU  - Su, Zhou
AU  - Jian, Xin
TI  - UAV Based Relay for Wireless Sensor Networks in 5G Systems
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 8
SN  - 1424-8220

AB  - Relay is one of the most significant issues in smart industrial wireless sensor networks (WSN) due to the low transmitting power of sensors. By relay, the signals of sensors can be concentrated at the relay and further transmitted to the base station for decreasing energy consumption in the system. In the past decades, the relay in WSN is generally one super sensor with large transmitting power. However, the placement of the super sensor is static, which leads to the instability of performance in WSN under the time-varying wireless environment. Fortunately, unmanned aerial vehicles (UAV) can provide an effective leverage to improve the environment-adaptation in WSN compared to the static relay in WSN. In this paper, we employ UAV as the relay in WSN, which can move in three-dimensional space to possess a better position to minimize the system power consumption. We use a simple case study to demonstrate the effectiveness of UAV in WSN. Extended simulations are also given to verify the preferable performance of the UAV based relay in WSN.
KW  - wireless sensor networks
KW  - unmanned aerial vehicle
KW  - relay
KW  - power consumption
DO  - 10.3390/s18082413
ER  -
TY  - EJOU
AU  - Wierzbicki, Damian
TI  - Multi-Camera Imaging System for UAV Photogrammetry
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 8
SN  - 1424-8220

AB  - In the last few years, it has been possible to observe a considerable increase in the use of unmanned aerial vehicles (UAV) equipped with compact digital cameras for environment mapping. The next stage in the development of photogrammetry from low altitudes was the development of the imagery data from UAV oblique images. Imagery data was obtained from side-facing directions. As in professional photogrammetric systems, it is possible to record footprints of tree crowns and other forms of the natural environment. The use of a multi-camera system will significantly reduce one of the main UAV photogrammetry limitations (especially in the case of multirotor UAV) which is a reduction of the ground coverage area, while increasing the number of images, increasing the number of flight lines, and reducing the surface imaged during one flight. The approach proposed in this paper is based on using several head cameras to enhance the imaging geometry during one flight of UAV for mapping. As part of the research work, a multi-camera system consisting of several cameras was designed to increase the total Field of View (FOV). Thanks to this, it will be possible to increase the ground coverage area and to acquire image data effectively. The acquired images will be mosaicked in order to limit the total number of images for the mapped area. As part of the research, a set of cameras was calibrated to determine the interior orientation parameters (IOPs). Next, the method of image alignment using the feature image matching algorithms was presented. In the proposed approach, the images are combined in such a way that the final image has a joint centre of projections of component images. The experimental results showed that the proposed solution was reliable and accurate for the mapping purpose. The paper also presents the effectiveness of existing transformation models for images with a large coverage subjected to initial geometric correction due to the influence of distortion.
KW  - UAV applications
KW  - unmanned aerial systems (UAS)
KW  - photogrammetry
KW  - image matching
KW  - image mosaicking
KW  - multi-camera images
DO  - 10.3390/s18082433
ER  -
TY  - EJOU
AU  - Zhou, Jianmin
AU  - Zhang, Shan
AU  - Yang, Hua
AU  - Xiao, Zhiqiang
AU  - Gao, Feng
TI  - The Retrieval of 30-m Resolution LAI from Landsat Data by Combining MODIS Products
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 8
SN  - 2072-4292

AB  - Leaf area index (LAI) is a critical vegetation structural parameter in biogeochemical and biophysical ecosystems. High-resolution LAI products play an essential role in regional studies. Empirical methods, which normally use field measurements as their training samples and have been identified as the most commonly used approaches to retrieve structural parameters of vegetation from high-resolution remote-sensing data, are limited by the quality of training samples. Few efforts have been made to generate training samples from existing global LAI products. In this study, two methods (a homogeneous and pure pixel filter method (method A) and a pixel unmixing method (method B)) were developed to extract training samples from moderate-resolution imaging spectroradiometer (MODIS) surface reflectance and LAI products, and a support vector regression (SVR) algorithm trained by the samples was used to retrieve the high-resolution LAI from Landsat data at Baoding, situated in the Hebei Province in China, and Des Moines, situated in Iowa, United States. For the homogeneous and pure pixel filter method, two different sets of training samples were designed. One was composed of upscaled Landsat reflectance at the 500-m resolution and MODIS LAI products (dataset A1); the other was composed of MODIS reflectance and LAI products (dataset A2). With them, two inversion models were developed using SVR. For the pixel unmixing method, the training samples (dataset B) were extracted from unmixed MODIS surface reflectance and LAI products at 30-m resolution, and the third inversion model was obtained with them. LAI inversion results showed that good agreement with field measurements was achieved using these three inversion models. The R2 (coefficient of determination) value and the root mean square error (RMSE) value were computed to assess the results. For all tests, the R2 values are higher than 0.74 and RMSE values are less than 0.73. These tests showed that three models for the two methods combined with MODIS products can retrieve 30-m resolution LAI from Landsat data. The results of the pixel unmixing method was slightly better than that of the homogeneous and pure pixel filter method.
KW  - leaf area index
KW  - MODIS products
KW  - Landsat
KW  - high resolution
KW  - homogeneous and pure pixel filter
KW  - pixel unmixing
DO  - 10.3390/rs10081187
ER  -
TY  - EJOU
AU  - Feng, Chen-Chieh
AU  - Guo, Zhou
TI  - Automating Parameter Learning for Classifying Terrestrial LiDAR Point Cloud Using 2D Land Cover Maps
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 8
SN  - 2072-4292

AB  - The automating classification of point clouds capturing urban scenes is critical for supporting applications that demand three-dimensional (3D) models. Achieving this goal, however, is met with challenges because of the varying densities of the point clouds and the complexity of the 3D data. In order to increase the level of automation in the point cloud classification, this study proposes a segment-based parameter learning method that incorporates a two-dimensional (2D) land cover map, in which a strategy of fusing the 2D land cover map and the 3D points is first adopted to create labelled samples, and a formalized procedure is then implemented to automatically learn the following parameters of point cloud classification: the optimal scale of the neighborhood for segmentation, optimal feature set, and the training classifier. It comprises four main steps, namely: (1) point cloud segmentation; (2) sample selection; (3) optimal feature set selection; and (4) point cloud classification. Three datasets containing the point cloud data were used in this study to validate the efficiency of the proposed method. The first two datasets cover two areas of the National University of Singapore (NUS) campus while the third dataset is a widely used benchmark point cloud dataset of Oakland, Pennsylvania. The classification parameters were learned from the first dataset consisting of a terrestrial laser-scanning data and a 2D land cover map, and were subsequently used to classify both of the NUS datasets. The evaluation of the classification results showed overall accuracies of 94.07% and 91.13%, respectively, indicating that the transition of the knowledge learned from one dataset to another was satisfactory. The classification of the Oakland dataset achieved an overall accuracy of 97.08%, which further verified the transferability of the proposed approach. An experiment of the point-based classification was also conducted on the first dataset and the result was compared to that of the segment-based classification. The evaluation revealed that the overall accuracy of the segment-based classification is indeed higher than that of the point-based classification, demonstrating the advantage of the segment-based approaches.
KW  - point cloud classification
KW  - 2D map
KW  - segment-based
KW  - neighborhood scale
KW  - sample selection
DO  - 10.3390/rs10081192
ER  -
TY  - EJOU
AU  - Zhang, Weixing
AU  - Witharana, Chandi
AU  - Li, Weidong
AU  - Zhang, Chuanrong
AU  - Li, Xiaojiang
AU  - Parent, Jason
TI  - Using Deep Learning to Identify Utility Poles with Crossarms and Estimate Their Locations from Google Street View Images
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 8
SN  - 1424-8220

AB  - Traditional methods of detecting and mapping utility poles are inefficient and costly because of the demand for visual interpretation with quality data sources or intense field inspection. The advent of deep learning for object detection provides an opportunity for detecting utility poles from side-view optical images. In this study, we proposed using a deep learning-based method for automatically mapping roadside utility poles with crossarms (UPCs) from Google Street View (GSV) images. The method combines the state-of-the-art DL object detection algorithm (i.e., the RetinaNet object detection algorithm) and a modified brute-force-based line-of-bearing (LOB, a LOB stands for the ray towards the location of the target [UPC at here] from the original location of the sensor [GSV mobile platform]) measurement method to estimate the locations of detected roadside UPCs from GSV. Experimental results indicate that: (1) both the average precision (AP) and the overall accuracy (OA) are around 0.78 when the intersection-over-union (IoU) threshold is greater than 0.3, based on the testing of 500 GSV images with a total number of 937 objects; and (2) around 2.6%, 47%, and 79% of estimated locations of utility poles are within 1 m, 5 m, and 10 m buffer zones, respectively, around the referenced locations of utility poles. In general, this study indicates that even in a complex background, most utility poles can be detected with the use of DL, and the LOB measurement method can estimate the locations of most UPCs.
KW  - deep learning
KW  - utility pole
KW  - infrastructure mapping
KW  - Google Street View
KW  - line-of-bearing measurement
KW  - object detection
DO  - 10.3390/s18082484
ER  -
TY  - EJOU
AU  - Dash, Jonathan P.
AU  - Pearse, Grant D.
AU  - Watt, Michael S.
TI  - UAV Multispectral Imagery Can Complement Satellite Data for Monitoring Forest Health
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 8
SN  - 2072-4292

AB  - The development of methods that can accurately detect physiological stress in forest trees caused by biotic or abiotic factors is vital for ensuring productive forest systems that can meet the demands of the Earth&rsquo;s population. The emergence of new sensors and platforms presents opportunities to augment traditional practices by combining remotely-sensed data products to provide enhanced information on forest condition. We tested the sensitivity of multispectral imagery collected from time-series unmanned aerial vehicle (UAV) and satellite imagery to detect herbicide-induced stress in a carefully controlled experiment carried out in a mature Pinus radiata D. Don plantation. The results revealed that both data sources were sensitive to physiological stress in the study trees. The UAV data were more sensitive to changes at a finer spatial resolution and could detect stress down to the level of individual trees. The satellite data tested could only detect physiological stress in clusters of four or more trees. Resampling the UAV imagery to the same spatial resolution as the satellite imagery revealed that the differences in sensitivity were not solely the result of spatial resolution. Instead, vegetation indices suited to the sensor characteristics of each platform were required to optimise the detection of physiological stress from each data source. Our results define both the spatial detection threshold and the optimum vegetation indices required to implement monitoring of this forest type. A comparison between time-series datasets of different spectral indices showed that the two sensors are compatible and can be used to deliver an enhanced method for monitoring physiological stress in forest trees at various scales. We found that the higher resolution UAV imagery was more sensitive to fine-scale instances of herbicide induced physiological stress than the RapidEye imagery. Although less sensitive to smaller phenomena the satellite imagery was found to be very useful for observing trends in physiological stress over larger areas.
KW  - tree health
KW  - precision forestry
KW  - sensor fusion
KW  - RPAS
KW  - drone
KW  - RapidEye
KW  - plantation forest
KW  - radiata pine
KW  - forest management
KW  - forest productivity
DO  - 10.3390/rs10081216
ER  -
TY  - EJOU
AU  - Yang, Jian
AU  - Wang, Xin
AU  - Bauer, Peter
TI  - Line and V-Shape Formation Based Distributed Processing for Robotic Swarms
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 8
SN  - 1424-8220

AB  - Efficient distributed processing is vital for collaborative searching tasks of robotic swarm systems. Typically, those systems are decentralized, and the members have only limited communication and processing capacities. What is illustrated in this paper is a distributed processing paradigm for robotic swarms moving in a line or v-shape formation. The introduced concept is capable of exploits the line and v-shape formations for 2-D filtering and processing algorithms based on a modified multi-dimensional Roesser model. The communication is only between nearest adjacent members with a simple state variable. As an example, we applied a salient region detection algorithm to the proposed framework. The simulation results indicate the designed paradigm can detect salient regions by using a moving line or v-shape formation in a scanning way. The requirement of communication and processing capability in this framework is minimal, making it a good candidate for collaborative exploration of formatted robotic swarms.
KW  - swarm robotics
KW  - sensor networks
KW  - pattern formation
KW  - distributed processing
KW  - collaborative exploration
DO  - 10.3390/s18082543
ER  -
TY  - EJOU
AU  - Zhao, Qi
AU  - Zhang, Boxue
AU  - Lyu, Shuchang
AU  - Zhang, Hong
AU  - Sun, Daniel
AU  - Li, Guoqiang
AU  - Feng, Wenquan
TI  - A CNN-SIFT Hybrid Pedestrian Navigation Method Based on First-Person Vision
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 8
SN  - 2072-4292

AB  - The emergence of new wearable technologies, such as action cameras and smart glasses, has driven the use of the first-person perspective in computer applications. This field is now attracting the attention and investment of researchers aiming to develop methods to process first-person vision (FPV) video. The current approaches present particular combinations of different image features and quantitative methods to accomplish specific objectives, such as object detection, activity recognition, user&ndash;machine interaction, etc. FPV-based navigation is necessary in some special areas, where Global Position System (GPS) or other radio-wave strength methods are blocked, and is especially helpful for visually impaired people. In this paper, we propose a hybrid structure with a convolutional neural network (CNN) and local image features to achieve FPV pedestrian navigation. A novel end-to-end trainable global pooling operator, called AlphaMEX, has been designed to improve the scene classification accuracy of CNNs. A scale-invariant feature transform (SIFT)-based tracking algorithm is employed for movement estimation and trajectory tracking of the person through each frame of FPV images. Experimental results demonstrate the effectiveness of the proposed method. The top-1 error rate of the proposed AlphaMEX-ResNet outperforms the original ResNet (k = 12) by 1.7% on the ImageNet dataset. The CNN-SIFT hybrid pedestrian navigation system reaches 0.57 m average absolute error, which is an adequate accuracy for pedestrian navigation. Both positions and movements can be well estimated by the proposed pedestrian navigation algorithm with a single wearable camera.
KW  - navigation
KW  - first-person vision
KW  - CNN
KW  - SIFT
KW  - movement estimation
DO  - 10.3390/rs10081229
ER  -
TY  - EJOU
AU  - Fu, Zhitao
AU  - Qin, Qianqing
AU  - Luo, Bin
AU  - Sun, Hong
AU  - Wu, Chun
TI  - HOMPC: A Local Feature Descriptor Based on the Combination of Magnitude and Phase Congruency Information for Multi-Sensor Remote Sensing Images
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 8
SN  - 2072-4292

AB  - Local region description of multi-sensor images remains a challenging task in remote sensing image analysis and applications due to the non-linear radiation variations between images. This paper presents a novel descriptor based on the combination of the magnitude and phase congruency information of local regions to capture the common features of images with non-linear radiation changes. We first propose oriented phase congruency maps (PCMs) and oriented magnitude binary maps (MBMs) using the multi-oriented phase congruency and magnitude information of log-Gabor filters. The two feature vectors are then quickly constructed based on the convolved PCMs and MBMs. Finally, a dense descriptor named the histograms of oriented magnitude and phase congruency (HOMPC) is developed by combining the histograms of oriented phase congruency (HPC) and the histograms of oriented magnitude (HOM) to capture the structure and shape properties of local regions. HOMPC was evaluated with three datasets composed of multi-sensor remote sensing images obtained from unmanned ground vehicle, unmanned aerial vehicle, and satellite platforms. The descriptor performance was evaluated by recall, precision, F1-measure, and area under the precision-recall curve. The experimental results showed the advantages of the HOM and HPC combination and confirmed that HOMPC is far superior to the current state-of-the-art local feature descriptors.
KW  - multi-sensor images
KW  - log-Gabor filters
KW  - non-linear radiation variations
KW  - local feature descriptor
KW  - phase congruency and magnitude
DO  - 10.3390/rs10081234
ER  -
TY  - EJOU
AU  - Matsumoto, Hironori
AU  - Young, Adam P.
TI  - Automated Cobble Mapping of a Mixed Sand-Cobble Beach Using a Mobile LiDAR System
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 8
SN  - 2072-4292

AB  - Cobbles (64&ndash;256 mm) are found on beaches throughout the world, influence beach morphology, and can provide shoreline stability. Detailed, frequent, and spatially large-scale quantitative cobble observations at beaches are vital toward a better understanding of sand-cobble beach systems. This study used a truck-mounted mobile terrestrial LiDAR system and a raster-based classification approach to map cobbles automatically. Rasters of LiDAR intensity, intensity deviation, topographic roughness, and slope were utilized for cobble classification. Four machine learning techniques including maximum likelihood, decision tree, support vector machine, and k-nearest neighbors were tested on five raster resolutions ranging from 5&ndash;50 cm. The cobble mapping capability varied depending on pixel size, classification technique, surface cobble density, and beach setting. The best performer was a maximum likelihood classification using 20 cm raster resolution. Compared to manual mapping at 15 control sites (size ranging from a few to several hundred square meters), automated mapping errors were &lt;12% (best fit line). This method mapped the spatial location of dense cobble regions more accurately compared to sparse and moderate density cobble areas. The method was applied to a ~40 km section of coast in southern California, and successfully generated temporal and spatial cobble distributions consistent with previous observations.
KW  - cobble
KW  - mobile terrestrial LiDAR
KW  - raster classification
KW  - machine learning
KW  - beach
DO  - 10.3390/rs10081253
ER  -
TY  - EJOU
AU  - Rocha, Alby D.
AU  - Groen, Thomas A.
AU  - Skidmore, Andrew K.
AU  - Darvishzadeh, Roshanak
AU  - Willemen, Louise
TI  - Machine Learning Using Hyperspectral Data Inaccurately Predicts Plant Traits Under Spatial Dependency
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 8
SN  - 2072-4292

AB  - Spectral, temporal and spatial dimensions are difficult to model together when predicting in situ plant traits from remote sensing data. Therefore, machine learning algorithms solely based on spectral dimensions are often used as predictors, even when there is a strong effect of spatial or temporal autocorrelation in the data. A significant reduction in prediction accuracy is expected when algorithms are trained using a sequence in space or time that is unlikely to be observed again. The ensuing inability to generalise creates a necessity for ground-truth data for every new area or period, provoking the propagation of &ldquo;single-use&rdquo; models. This study assesses the impact of spatial autocorrelation on the generalisation of plant trait models predicted with hyperspectral data. Leaf Area Index (LAI) data generated at increasing levels of spatial dependency are used to simulate hyperspectral data using Radiative Transfer Models. Machine learning regressions to predict LAI at different levels of spatial dependency are then tuned (determining the optimum model complexity) using cross-validation as well as the NOIS method. The results show that cross-validated prediction accuracy tends to be overestimated when spatial structures present in the training data are fitted (or learned) by the model.
KW  - remote sensing
KW  - radiative transfer models
KW  - spatial autocorrelation
KW  - data simulation
KW  - model accuracy
DO  - 10.3390/rs10081263
ER  -
TY  - EJOU
AU  - Fu, Xiaowei
AU  - Wang, Hui
AU  - Li, Bin
AU  - Gao, Xiaoguang
TI  - An Efficient Sampling-Based Algorithms Using Active Learning and Manifold Learning for Multiple Unmanned Aerial Vehicle Task Allocation under Uncertainty
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 8
SN  - 1424-8220

AB  - This paper presents a sampling-based approximation for multiple unmanned aerial vehicle (UAV) task allocation under uncertainty. Our goal is to reduce the amount of calculations and improve the accuracy of the algorithm. For this purpose, Gaussian process regression models are constructed from an uncertainty parameter and task reward sample set, and this training set is iteratively refined by active learning and manifold learning. Firstly, a manifold learning method is used to screen samples, and a sparse graph is constructed to represent the distribution of all samples through a small number of samples. Then, multi-points sampling is introduced into the active learning method to obtain the training set from the sparse graph quickly and efficiently. This proposed hybrid sampling strategy could select a limited number of representative samples to construct the training set. Simulation analyses demonstrate that our sampling-based algorithm can effectively get a high-precision evaluation model of the impact of uncertain parameters on task reward.
KW  - uncertainty
KW  - multi-UAVs
KW  - task allocation
KW  - active learning
KW  - manifold learning
DO  - 10.3390/s18082645
ER  -
TY  - EJOU
AU  - Liakos, Konstantinos G.
AU  - Busato, Patrizia
AU  - Moshou, Dimitrios
AU  - Pearson, Simon
AU  - Bochtis, Dionysis
TI  - Machine Learning in Agriculture: A Review
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 8
SN  - 1424-8220

AB  - Machine learning has emerged with big data technologies and high-performance computing to create new opportunities for data intensive science in the multi-disciplinary agri-technologies domain. In this paper, we present a comprehensive review of research dedicated to applications of machine learning in agricultural production systems. The works analyzed were categorized in (a) crop management, including applications on yield prediction, disease detection, weed detection crop quality, and species recognition; (b) livestock management, including applications on animal welfare and livestock production; (c) water management; and (d) soil management. The filtering and classification of the presented articles demonstrate how agriculture will benefit from machine learning technologies. By applying machine learning to sensor data, farm management systems are evolving into real time artificial intelligence enabled programs that provide rich recommendations and insights for farmer decision support and action.
KW  - crop management
KW  - water management
KW  - soil management
KW  - livestock management
KW  - artificial intelligence
KW  - planning
KW  - precision agriculture
DO  - 10.3390/s18082674
ER  -
TY  - EJOU
AU  - Pei, Zhaoyi
AU  - Piao, Songhao
AU  - Souidi, Mohammed E.
AU  - Qadir, Muhammad Z.
AU  - Li, Guo
TI  - SLAM for Humanoid Multi-Robot Active Cooperation Based on Relative Observation
T2  - Sustainability

PY  - 2018
VL  - 10
IS  - 8
SN  - 2071-1050

AB  - The simultaneous localization and mapping (SLAM) of robot in the complex environment is a fundamental research topic for service robots. This paper presents a new humanoid multi-robot SLAM mechanism that allows robots to collaborate and localize each other in their own SLAM process. Each robot has two switchable modes: independent mode and collaborative mode. Each robot can respond to the requests of other robots and participate in chained localization of the target robot under the leadership of the organiser. We aslo discuss how to find the solution of optimal strategy for chained localization. This mechanism can improve the performance of bundle adjustment at the global level, especially when the image features are few or the results of closed loop are not ideal. The simulation results show that this method has a great effect on improving the accuracy of multi-robot localization and the efficiency of 3D mapping.
KW  - SLAM
KW  - multi-robot system (MRS)
KW  - humanoid robot
KW  - cooperative localization
DO  - 10.3390/su10082946
ER  -
TY  - EJOU
AU  - Liu, Qingsheng
AU  - Huang, Chong
AU  - Liu, Gaohuan
AU  - Yu, Bowei
TI  - Comparison of CBERS-04, GF-1, and GF-2 Satellite Panchromatic Images for Mapping Quasi-Circular Vegetation Patches in the Yellow River Delta, China
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 8
SN  - 1424-8220

AB  - Vegetation in arid and semi-arid regions frequently exists in patches, which can be effectively mapped by remote sensing. However, not all satellite images are suitable to detect the decametric-scale vegetation patches because of low spatial resolution. This study compared the capability of the first Gaofen Satellite (GF-1), the second Gaofen Satellite (GF-2), and China-Brazil Earth Resource Satellite 4 (CBERS-04) panchromatic images for mapping quasi-circular vegetation patches (QVPs) with K-Means (KM) and object-based example-based feature extraction with support vector machine classification (OEFE) in the Yellow River Delta, China. Both approaches provide relatively high classification accuracy with GF-2. For all five images, the root mean square errors (RMSEs) for area, perimeter, and perimeter/area ratio were smaller using the KM than the OEFE, indicating that the results from the KM are more similar to ground truth. Although the mapped results of the QVPs from finer-spatial resolution images appeared more accurate, accuracy improvement in terms of QVP area, perimeter, and perimeter/area ratio was limited, and most of the QVPs detected only by finer-spatial resolution imagery had a more than 40% difference with the actual QVPs in these three parameters. Compared with the KM approach, the OEFE approach performed better for vegetation patch shape description. Coupling the CBERS-04 with the OEFE approach could suitably map the QVPs (overall accuracy 75.3%). This is important for ecological protection managers concerned about cost-effectiveness between image spatial resolution and mapping the QVPs.
KW  - vegetation patch
KW  - CBERS-04
KW  - GF-1
KW  - GF-2
KW  - K-Means
KW  - example-based feature extraction
DO  - 10.3390/s18082733
ER  -
TY  - EJOU
AU  - Hidayat, Sarip
AU  - MATSUOKA, Masayuki
AU  - Baja, Sumbangan
AU  - Rampisela, Dorothea A.
TI  - Object-Based Image Analysis for Sago Palm Classification: The Most Important Features from High-Resolution Satellite Imagery
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 8
SN  - 2072-4292

AB  - Sago palm (Metroxylon sagu) is a palm tree species originating in Indonesia. In the future, this starch-producing tree will play an important role in food security and biodiversity. Local governments have begun to emphasize the sustainable development of sago palm plantations; therefore, they require near-real-time geospatial information on palm stands. We developed a semi-automated classification scheme for mapping sago palm using machine learning within an object-based image analysis framework with Pleiades-1A imagery. In addition to spectral information, arithmetic, geometric, and textural features were employed to enhance the classification accuracy. Recursive feature elimination was applied to samples to rank the importance of 26 input features. A support vector machine (SVM) was used to perform classifications and resulted in the highest overall accuracy of 85.00% after inclusion of the eight most important features, including three spectral features, three arithmetic features, and two textural features. The SVM classifier showed normal fitting up to the eighth most important feature. According to the McNemar test results, using the top seven to 14 features provided a better classification accuracy. The significance of this research is the revelation of the most important features in recognizing sago palm among other similar tree species.
KW  - sago palm
KW  - OBIA
KW  - machine learning
KW  - textural features
KW  - image segmentation
KW  - feature selection
KW  - classification
DO  - 10.3390/rs10081319
ER  -
TY  - EJOU
AU  - Hu, Jie
AU  - Wu, Zhongli
AU  - Qin, Xiongzhen
AU  - Geng, Huangzheng
AU  - Gao, Zhangbin
TI  - An Extended Kalman Filter and Back Propagation Neural Network Algorithm Positioning Method Based on Anti-lock Brake Sensor and Global Navigation Satellite System Information
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 9
SN  - 1424-8220

AB  - Telematics box (T-Box) chip-level Global Navigation Satellite System (GNSS) receiver modules usually suffer from GNSS information failure or noise in urban environments. In order to resolve this issue, this paper presents a real-time positioning method for Extended Kalman Filter (EKF) and Back Propagation Neural Network (BPNN) algorithms based on Antilock Brake System (ABS) sensor and GNSS information. Experiments were performed using an assembly in the vehicle with a T-Box. The T-Box firstly use automotive kinematical Pre-EKF to fuse the four wheel speed, yaw rate and steering wheel angle data from the ABS sensor to obtain a more accurate vehicle speed and heading angle velocity. In order to reduce the noise of the GNSS information, After-EKF fusion vehicle speed, heading angle velocity and GNSS data were used and low-noise positioning data were obtained. The heading angle speed error is extracted as target and part of low-noise positioning data were used as input for training a BPNN model. When the positioning is invalid, the well-trained BPNN corrected heading angle velocity output and vehicle speed add the synthesized relative displacement to the previous absolute position to realize a new position. With the data of high-precision real-time kinematic differential positioning equipment as the reference, the use of the dual EKF can reduce the noise range of GNSS information and concentrate good-positioning signals of the road within 5 m (i.e. the positioning status is valid). When the GNSS information was shielded (making the positioning status invalid), and the previous data was regarded as a training sample, it is found that the vehicle achieved 15 minutes position without GNSS information on the recycling line. The results indicated this new position method can reduce the vehicle positioning noise when GNSS information is valid and determine the position during long periods of invalid GNSS information.
KW  - ABS sensor
KW  - neural network
KW  - EKF
KW  - GNSS
KW  - T-Box
DO  - 10.3390/s18092753
ER  -
TY  - EJOU
AU  - Xie, Fuding
AU  - Li, Fangfei
AU  - Lei, Cunkuan
AU  - Ke, Lina
TI  - Representative Band Selection for Hyperspectral Image Classification
T2  - ISPRS International Journal of Geo-Information

PY  - 2018
VL  - 7
IS  - 9
SN  - 2220-9964

AB  - The high dimensionality of hyperspectral images (HSIs) brings great difficulty for their later data processing. Band selection, as a commonly used dimension reduction technique, is the selection of optimal band combinations from the original bands, while attempting to remove the redundancy between bands and maintain a good classification ability. In this study, a novel hybrid filter-wrapper band selection method is proposed by a three-step strategy, i.e., band subset decomposition, band selection and band optimization. Based on the information gain (IG) and the spectral curve of the hyperspectral dataset, the band subset decomposition technique is improved, and a random selection strategy is suggested. The implementation of the first two steps addresses the problem of reducing inter-band redundancy. An optimization strategy based on a gray wolf optimizer (GWO) ensures that the selected band combination has a good classification ability. The classification performance of the selected band combination is verified on the Indian Pines, Pavia University and Salinas hyperspectral datasets with the aid of support vector machine (SVM) with a five-fold cross-validation. By comparing the proposed IG-GWO method with five state-of-the-art band selection approaches, the superiority of the proposed method for HSIs classification is experimentally demonstrated on three well-known hyperspectral datasets.
KW  - hyperspectral image classification
KW  - band selection
KW  - information gain
KW  - band subset decomposition
KW  - gray wolf optimizer
DO  - 10.3390/ijgi7090338
ER  -
TY  - EJOU
AU  - Tamouridou, Afroditi A.
AU  - Pantazi, Xanthoula E.
AU  - Alexandridis, Thomas
AU  - Lagopodi, Anastasia
AU  - Kontouris, Giorgos
AU  - Moshou, Dimitrios
TI  - Spectral Identification of Disease in Weeds Using Multilayer Perceptron with Automatic Relevance Determination
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 9
SN  - 1424-8220

AB  - Microbotryum silybum, a smut fungus, is studied as an agent for the biological control of Silybum marianum (milk thistle) weed. Confirmation of the systemic infection is essential in order to assess the effectiveness of the biological control application and assist decision-making. Nonetheless, in situ diagnosis is challenging. The presently demonstrated research illustrates the identification process of systemically infected S. marianum plants by means of field spectroscopy and the multilayer perceptron/automatic relevance determination (MLP-ARD) network. Leaf spectral signatures were obtained from both healthy and infected S. marianum plants using a portable visible and near-infrared spectrometer (310&ndash;1100 nm). The MLP-ARD algorithm was applied for the recognition of the infected S. marianum plants. Pre-processed spectral signatures served as input features. The spectra pre-processing consisted of normalization, and second derivative and principal component extraction. MLP-ARD reached a high overall accuracy (90.32%) in the identification process. The research results establish the capacity of MLP-ARD to precisely identify systemically infected S. marianum weeds during their vegetative growth stage.
KW  - plant pathology
KW  - MLP-ARD
KW  - disease detection
KW  - artificial intelligence
KW  - precision agriculture
DO  - 10.3390/s18092770
ER  -
TY  - EJOU
AU  - Kung, Chien-Chun
TI  - Study on Consulting Air Combat Simulation of Cluster UAV Based on Mixed Parallel Computing Framework of Graphics Processing Unit
T2  - Electronics

PY  - 2018
VL  - 7
IS  - 9
SN  - 2079-9292

AB  - This paper combines matrix game theory with negotiating theory and uses U-solution to study the framework of the consulting air combat of UAV cluster. The processes to determine the optimal strategy in this paper follow three points: first, the UAV cluster are grouped into fleets; second, the best paring for the joint operations of the fleet member with the enemy fleet members are calculated; thirdly, consultations within the fleet are conducted to discuss the problems of optimal tactic, roles of main/assistance, and situational assessment within the fleet. In order to improve the computing efficiency of the framework, this article explores the use of the NVIDIA graphics processor programmed through MATLAB mixed C++/CUDA toolkit to accelerate the calculations of equations of motion of unmanned aerial vehicles, the prediction of superiority values and U values, computations of consultation, the evaluation of situational assessment and the optimal strategies. The effectiveness evaluation of GPGPU and CPU can be observed by the simulation results. When the number of team air combat is small, the CPU alone has better efficiency; however, when the number of air combat clusters exceeds 6 to 6, the architecture presented in this article can provide higher performance improvements and run faster than optimized CPU-only code.
KW  - GPGPU
KW  - MATLAB/CUDA
KW  - matrix game
KW  - consulting air combat
KW  - UAV cluster
KW  - maneuver decision-making
DO  - 10.3390/electronics7090160
ER  -
TY  - EJOU
AU  - Ju, Chanyoung
AU  - Son, Hyoung I.
TI  - Multiple UAV Systems for Agricultural Applications: Control, Implementation, and Evaluation
T2  - Electronics

PY  - 2018
VL  - 7
IS  - 9
SN  - 2079-9292

AB  - The introduction of multiple unmanned aerial vehicle (UAV) systems into agriculture causes an increase in work efficiency and a decrease in operator fatigue. However, systems that are commonly used in agriculture perform tasks using a single UAV with a centralized controller. In this study, we develop a multi-UAV system for agriculture using the distributed swarm control algorithm and evaluate the performance of the system. The performance of the proposed agricultural multi-UAV system is quantitatively evaluated and analyzed through four experimental cases: single UAV with autonomous control, multiple UAVs with autonomous control, single UAV with remote control, and multiple UAVs with remote control. Moreover, the performance of each system was analyzed through seven performance metrics: total time, setup time, flight time, battery consumption, inaccuracy of land, haptic control effort, and coverage ratio. Experimental results indicate that the performance of the multi-UAV system is significantly superior to the single-UAV system.
KW  - agricultural UAV
KW  - multi-UAV system
KW  - distributed swarm control
KW  - performance evaluation
KW  - remote sensing
DO  - 10.3390/electronics7090162
ER  -
TY  - EJOU
AU  - Alvarez, Laura V.
AU  - Moreno, Hernan A.
AU  - Segales, Antonio R.
AU  - Pham, Tri G.
AU  - Pillar-Little, Elizabeth A.
AU  - Chilson, Phillip B.
TI  - Merging Unmanned Aerial Systems (UAS) Imagery and Echo Soundings with an Adaptive Sampling Technique for Bathymetric Surveys
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 9
SN  - 2072-4292

AB  - Bathymetric surveying to gather information about depths and underwater terrain is increasingly important to the sciences of hydrology and geomorphology. Submerged terrain change detection, water level, and reservoir storage monitoring demand extensive bathymetric data. Despite often being scarce or unavailable, this information is fundamental to hydrodynamic modeling for imposing boundary conditions and building computational domains. In this manuscript, a novel, low-cost, rapid, and accurate method is developed to measure submerged topography, as an alternative to conventional approaches that require significant economic investments and human power. The method integrates two types of Unmanned Aerial Systems (UAS) sampling techniques. The first couples a small UAS (sUAS) to an echosounder attached to a miniaturized boat for surveying submerged topography in deeper water within the range of accuracy. The second uses Structure from Motion (SfM) photogrammetry to cover shallower water areas no detected by the echosounder where the bed is visible from the sUAS. The refraction of light passing through air&ndash;water interface is considered for improving the bathymetric results. A zonal adaptive sampling algorithm is developed and applied to the echosounder data to densify measurements where the standard deviation of clustered points is high. This method is tested at a small reservoir in the U.S. southern plains. Ground Control Points (GCPs) and checkpoints surveyed with a total station are used for properly georeferencing of the SfM photogrammetry and assessment of the UAS imagery accuracy. An independent validation procedure providing a number of skill and error metrics is conducted using ground-truth data collected with a leveling rod at co-located reservoir points. Assessment of the results shows a strong correlation between the echosounder, SfM measurements and the field observations. The final product is a hybrid bathymetric survey resulting from the merging of SfM photogrammetry and echosoundings within an adaptive sampling framework.
KW  - unmanned aerial systems
KW  - bathymetry
KW  - adaptive sampling
KW  - structure from motion
KW  - echo sounding
KW  - geomorphology
KW  - hydrology
KW  - reservoirs
DO  - 10.3390/rs10091362
ER  -
TY  - EJOU
AU  - Kirsch, Moritz
AU  - Lorenz, Sandra
AU  - Zimmermann, Robert
AU  - Tusa, Laura
AU  - Möckel, Robert
AU  - Hödl, Philip
AU  - Booysen, René
AU  - Khodadadzadeh, Mahdi
AU  - Gloaguen, Richard
TI  - Integration of Terrestrial and Drone-Borne Hyperspectral and Photogrammetric Sensing Methods for Exploration Mapping and Mining Monitoring
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 9
SN  - 2072-4292

AB  - Mapping lithology and geological structures accurately remains a challenge in difficult terrain or in active mining areas. We demonstrate that the integration of terrestrial and drone-borne multi-sensor remote sensing techniques significantly improves the reliability, safety, and efficiency of geological activities during exploration and mining monitoring. We describe an integrated workflow to produce a geometrically and spectrally accurate combination of a Structure-from-Motion Multi-View Stereo point cloud and hyperspectral data cubes in the visible to near-infrared (VNIR) and short-wave infrared (SWIR), as well as long-wave infrared (LWIR) ranges acquired by terrestrial and drone-borne imaging sensors. Vertical outcrops in a quarry in the Freiberg mining district, Saxony (Germany), featuring sulfide-rich hydrothermal zones in a granitoid host, are used to showcase the versatility of our approach. The image data are processed using spectroscopic and machine learning algorithms to generate meaningful 2.5D (i.e., surface) maps that are available to geologists on the ground just shortly after data acquisition. We validate the remote sensing data with thin section analysis and laboratory X-ray diffraction, as well as point spectroscopic data. The combination of ground- and drone-based photogrammetric and hyperspectral VNIR, SWIR, and LWIR imaging allows for safer and more efficient ground surveys, as well as a better, statistically sound sampling strategy for further structural, geochemical, and petrological investigations.
KW  - hyperspectral imaging
KW  - Structure-from-Motion (SfM)
KW  - mineral mapping
KW  - virtual outcrops
KW  - geology
KW  - hydrothermal
KW  - UAV
KW  - long-wave infrared
DO  - 10.3390/rs10091366
ER  -
TY  - EJOU
AU  - Tahsin, Subrina
AU  - Medeiros, Stephen C.
AU  - Singh, Arvind
TI  - Assessing the Resilience of Coastal Wetlands to Extreme Hydrologic Events Using Vegetation Indices: A Review
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 9
SN  - 2072-4292

AB  - Coastal wetlands (CWs) offer numerous imperative functions that support a diverse array of life forms that are poorly adapted for other environments and provide an economic base for human communities. Unfortunately, CWs have been experiencing significant threats due to meteorological and climatic fluctuations as well as anthropogenic impacts. The wetlands and marshes in Apalachicola Bay, Florida have endured the impacts of several extreme hydrologic events (EHEs) over the past few decades. These extreme hydrologic events include drought, hurricane, heavy precipitation and fluvial flooding. Remote sensing has been used and continues to demonstrate promise for acquiring spatial and temporal information about CWs thereby making it easier to track and quantify long term changes driven by EHEs. These wetland ecosystems are also adversely impacted by increased human activities such as wetland conversion to agricultural, aquaculture, industrial or residential use; construction of dikes along the shoreline; and sprawl of built areas. In this paper, we review previous works on coastal wetland resilience to EHEs. We synthesize these concepts in the context of remote sensing as the primary assessment tool with focus on derived vegetation indices to monitor CWs at regional and global scales.
KW  - coastal wetlands
KW  - remote sensing
KW  - Normalized Difference Vegetation Index
KW  - extreme hydrologic events
KW  - resilience
DO  - 10.3390/rs10091390
ER  -
TY  - EJOU
AU  - Ullah, Fahim
AU  - Sepasgozar, Samad M. E.
AU  - Wang, Changxin
TI  - A Systematic Review of Smart Real Estate Technology: Drivers of, and Barriers to, the Use of Digital Disruptive Technologies and Online Platforms
T2  - Sustainability

PY  - 2018
VL  - 10
IS  - 9
SN  - 2071-1050

AB  - Real estate needs to improve its adoption of disruptive technologies to move from traditional to smart real estate (SRE). This study reviews the adoption of disruptive technologies in real estate. It covers the applications of nine such technologies, hereby referred to as the Big9. These are: drones, the internet of things (IoT), clouds, software as a service (SaaS), big data, 3D scanning, wearable technologies, virtual and augmented realities (VR and AR), and artificial intelligence (AI) and robotics. The Big9 are examined in terms of their application to real estate and how they can furnish consumers with the kind of information that can avert regrets. The review is based on 213 published articles. The compiled results show the state of each technology&rsquo;s practice and usage in real estate. This review also surveys dissemination mechanisms, including smartphone technology, websites and social media-based online platforms, as well as the core components of SRE: sustainability, innovative technology and user centredness. It identifies four key real estate stakeholders&mdash;consumers, agents and associations, government and regulatory authorities, and complementary industries&mdash;and their needs, such as buying or selling property, profits, taxes, business and/or other factors. Interactions between these stakeholders are highlighted, and the specific needs that various technologies address are tabulated in the form of a what, who and how analysis to highlight the impact that the technologies have on key stakeholders. Finally, stakeholder needs as identified in the previous steps are matched theoretically with six extensions of the traditionally accepted technology adoption model (TAM), paving the way for a smoother transition to technology-based benefits for consumers. The findings pertinent to the Big9 technologies in the form of opportunities, potential losses and exploitation levels (OPLEL) analyses highlight the potential utilisation of each technology for addressing consumers&rsquo; needs and minimizing their regrets. Additionally, the tabulated findings in the form of what, how and who links the Big9 technologies to core consumers&rsquo; needs and provides a list of resources needed to ensure proper information dissemination to the stakeholders. Such high-quality information can bridge the gap between real estate consumers and other stakeholders and raise the state of the industry to a level where its consumers have fewer or no regrets. The study, being the first to explore real estate technologies, is limited by the number of research publications on the SRE technologies that has been compensated through incorporation of online reports.
KW  - smart real estate (SRE)
KW  - smart real estate management (SREM)
KW  - real estate technologies
KW  - Big9 disruptive technologies
KW  - online technology dissemination platforms
KW  - technology adoption
KW  - decision regrets
DO  - 10.3390/su10093142
ER  -
TY  - EJOU
AU  - Al-Ruzouq, Rami
AU  - Shanableh, Abdallah
AU  - Barakat A. Gibril, Mohamed
AU  - AL-Mansoori, Saeed
TI  - Image Segmentation Parameter Selection and Ant Colony Optimization for Date Palm Tree Detection and Mapping from Very-High-Spatial-Resolution Aerial Imagery
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 9
SN  - 2072-4292

AB  - Accurate mapping of date palm trees is essential for their sustainable management, yield estimation, and environmental studies. In this study, we integrated geographic object-based image analysis, class-specific accuracy measures, fractional factorial design, metaheuristic feature-selection technique, and rule-based classification to detect and map date palm trees from very-high-spatial-resolution (VHSR) aerial images of two study areas. First, multiresolution segmentation was optimized through the synergy of the F1-score accuracy measure and the robust Taguchi design. Second, ant colony optimization (ACO) was adopted to select the most significant features. Out of 31 features, only 12 significant color invariants and textural features were selected. Third, based on the selected features, the rule-based classification with the aid of a decision tree algorithm was applied to extract date palm trees. The proposed methodology was developed on a subset of the first study area, and ultimately applied to the second study area to investigate its efficiency and transferability. To evaluate the proposed classification scheme, various supervised object-based algorithms, namely random forest (RF), support vector machine (SVM), and k-nearest neighbor (k-NN), were applied to the first study area. The result of image segmentation optimization demonstrated that segmentation optimization based on an integrated F1-score class-specific accuracy measure and Taguchi statistical design showed improvement compared with objective function, along with the Taguchi design. Moreover, the result of the feature selection by ACO outperformed, with almost 88% overall accuracy, several feature-selection techniques, such as chi-square, correlation-based feature selection, gain ratio, information gain, support vector machine, and principal component analysis. The integrated framework for palm tree detection outperformed RF, SVM, and k-NN classification algorithms with an overall accuracy of 91.88% and 87.03%, date palm class-specific accuracies of 0.91 and 0.89, and kappa coefficients of 0.90 and 0.85 for the first and second study areas, respectively. The proposed integrated methodology demonstrated a highly efficient and promising tool to detect and map date palm trees from VHSR aerial images.
KW  - object-based classification
KW  - very-high-resolution aerial imagery
KW  - image segmentation optimization
KW  - feature selection
KW  - ant colony optimization
KW  - date palm tree
DO  - 10.3390/rs10091413
ER  -
TY  - EJOU
AU  - Sa, Inkyu
AU  - Popović, Marija
AU  - Khanna, Raghav
AU  - Chen, Zetao
AU  - Lottes, Philipp
AU  - Liebisch, Frank
AU  - Nieto, Juan
AU  - Stachniss, Cyrill
AU  - Walter, Achim
AU  - Siegwart, Roland
TI  - WeedMap: A Large-Scale Semantic Weed Mapping Framework Using Aerial Multispectral Imaging and Deep Neural Network for Precision Farming
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 9
SN  - 2072-4292

AB  - The ability to automatically monitor agricultural fields is an important capability in precision farming, enabling steps towards more sustainable agriculture. Precise, high-resolution monitoring is a key prerequisite for targeted intervention and the selective application of agro-chemicals. The main goal of this paper is developing a novel crop/weed segmentation and mapping framework that processes multispectral images obtained from an unmanned aerial vehicle (UAV) using a deep neural network (DNN). Most studies on crop/weed semantic segmentation only consider single images for processing and classification. Images taken by UAVs often cover only a few hundred square meters with either color only or color and near-infrared (NIR) channels. Although a map can be generated by processing single segmented images incrementally, this requires additional complex information fusion techniques which struggle to handle high fidelity maps due to their computational costs and problems in ensuring global consistency. Moreover, computing a single large and accurate vegetation map (e.g., crop/weed) using a DNN is non-trivial due to difficulties arising from: (1) limited ground sample distances (GSDs) in high-altitude datasets, (2) sacrificed resolution resulting from downsampling high-fidelity images, and (3) multispectral image alignment. To address these issues, we adopt a stand sliding window approach that operates on only small portions of multispectral orthomosaic maps (tiles), which are channel-wise aligned and calibrated radiometrically across the entire map. We define the tile size to be the same as that of the DNN input to avoid resolution loss. Compared to our baseline model (i.e., SegNet with 3 channel RGB (red, green, and blue) inputs) yielding an area under the curve (AUC) of [background=0.607, crop=0.681, weed=0.576], our proposed model with 9 input channels achieves [0.839, 0.863, 0.782]. Additionally, we provide an extensive analysis of 20 trained models, both qualitatively and quantitatively, in order to evaluate the effects of varying input channels and tunable network hyperparameters. Furthermore, we release a large sugar beet/weed aerial dataset with expertly guided annotations for further research in the fields of remote sensing, precision agriculture, and agricultural robotics.
KW  - precision farming
KW  - weed management
KW  - multispectral imaging
KW  - semantic segmentation
KW  - deep neural network
KW  - unmanned aerial vehicle
KW  - remote sensing
DO  - 10.3390/rs10091423
ER  -
TY  - EJOU
AU  - Kose, Utku
TI  - An Ant-Lion Optimizer-Trained Artificial Neural Network System for Chaotic Electroencephalogram (EEG) Prediction
T2  - Applied Sciences

PY  - 2018
VL  - 8
IS  - 9
SN  - 2076-3417

AB  - The prediction of future events based on available time series measurements is a relevant research area specifically for healthcare, such as prognostics and assessments of intervention applications. A measure of brain dynamics, electroencephalogram time series, are routinely analyzed to obtain information about current, as well as future, mental states, and to detect and diagnose diseases or environmental factors. Due to their chaotic nature, electroencephalogram time series require specialized techniques for effective prediction. The objective of this study was to introduce a hybrid system developed by artificial intelligence techniques to deal with electroencephalogram time series. Both artificial neural networks and the ant-lion optimizer, which is a recent intelligent optimization technique, were employed to comprehend the related system and perform some prediction applications over electroencephalogram time series. According to the obtained findings, the system can successfully predict the future states of target time series and it even outperforms some other hybrid artificial neural network-based systems and alternative time series prediction approaches from the literature.
KW  - artificial neural networks
KW  - ant-lion optimizer
KW  - time series prediction
KW  - electroencephalogram
KW  - healthcare
KW  - chaotic time series
KW  - artificial intelligence
DO  - 10.3390/app8091613
ER  -
TY  - EJOU
AU  - Zhong, Cheng
AU  - Wang, Cuizhen
AU  - Li, Hui
AU  - Chen, Wenlong
AU  - Hou, Yong
TI  - Mapping Inter-Annual Land Cover Variations Automatically Based on a Novel Sample Transfer Method
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 9
SN  - 2072-4292

AB  - Most land cover mapping methods require the collection of ground reference data at the time when the remotely sensed data are acquired. Due to the high cost of repetitive collection of reference data, however, it limits the production of annual land cover maps to a short time span. In order to reduce the mapping cost and to improve the timeliness, an object-based sample transfer (OBST) method was presented in this study. The object-based analysis with strict constrains in area, shape and index values is expected to reduce the accident errors in selecting and transferring samples. The presented method was tested and compared with same-year mapping (SY), cross-year mapping (CY) and multi-index automatic classification (MI). For the study years of 2001&ndash;2016, both the overall accuracies (above 90%) and detailed accuracy indicators of the presented method were very close to the SY accuracy and higher than accuracies of CY and MI. With the presented method, the times-series land cover map of Guangzhou, China were derived and analyzed. The results reveal that the city has undergone rapid urban expansion and the pressure on natural resources and environment has increased. These results indicate the proposed method could save considerable cost and time for mapping the spatial-temporal changes of urban development. This suggests great potential for future applications as more satellite observations have become available all over the globe.
KW  - land cover
KW  - remote sensing
KW  - automatic classification
KW  - sample transfer
KW  - object-based analysis
DO  - 10.3390/rs10091457
ER  -
TY  - EJOU
AU  - Cui, Zhaoyu
AU  - Kerekes, John P.
TI  - Potential of Red Edge Spectral Bands in Future Landsat Satellites on Agroecosystem Canopy Green Leaf Area Index Retrieval
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 9
SN  - 2072-4292

AB  - Vegetation biophysical parameter retrieval is an important earth remote sensing system application. In this paper, we studied the potential impact of the addition of new spectral bands in the red edge region in future Landsat satellites on agroecosystem canopy green leaf area index (LAI) retrieval. The test data were simulated from SPARC &lsquo;03 field campaign HyMap hyperspectral data. Three retrieval approaches were tested: empirical regression based on vegetation index, physical model-based look-up-table (LUT) inversion, and machine learning. The results of all three approaches showed that a potential new spectral band located between the Landsat-8 Operational Land Imager (OLI) red and NIR bands slightly improved the agroecosystem green LAI retrieval accuracy (R2 of 0.787 vs. 0.810 for vegetation index approach, 0.806 vs. 0.828 for LUT inversion approach, and 0.925 vs. 0.933 for machine learning approach). The results of this work are consistent with the conclusions from previous research on the value of Sentinel-2 red edge bands for agricultural green LAI retrieval.
KW  - Landsat
KW  - red edge band
KW  - leaf area index
KW  - vegetation indices
KW  - look-up-table inversion
DO  - 10.3390/rs10091458
ER  -
TY  - EJOU
AU  - Xu, Yongyang
AU  - Xie, Zhong
AU  - Feng, Yaxing
AU  - Chen, Zhanlong
TI  - Road Extraction from High-Resolution Remote Sensing Imagery Using Deep Learning
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 9
SN  - 2072-4292

AB  - The road network plays an important role in the modern traffic system; as development occurs, the road structure changes frequently. Owing to the advancements in the field of high-resolution remote sensing, and the success of semantic segmentation success using deep learning in computer version, extracting the road network from high-resolution remote sensing imagery is becoming increasingly popular, and has become a new tool to update the geospatial database. Considering that the training dataset of the deep convolutional neural network will be clipped to a fixed size, which lead to the roads run through each sample, and that different kinds of road types have different widths, this work provides a segmentation model that was designed based on densely connected convolutional networks (DenseNet) and introduces the local and global attention units. The aim of this work is to propose a novel road extraction method that can efficiently extract the road network from remote sensing imagery with local and global information. A dataset from Google Earth was used to validate the method, and experiments showed that the proposed deep convolutional neural network can extract the road network accurately and effectively. This method also achieves a harmonic mean of precision and recall higher than other machine learning and deep learning methods.
KW  - road network extraction
KW  - deep learning
KW  - pyramid attention
KW  - global attention
KW  - high resolution
DO  - 10.3390/rs10091461
ER  -
TY  - EJOU
AU  - Wan, Liang
AU  - Li, Yijian
AU  - Cen, Haiyan
AU  - Zhu, Jiangpeng
AU  - Yin, Wenxin
AU  - Wu, Weikang
AU  - Zhu, Hongyan
AU  - Sun, Dawei
AU  - Zhou, Weijun
AU  - He, Yong
TI  - Combining UAV-Based Vegetation Indices and Image Classification to Estimate Flower Number in Oilseed Rape
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 9
SN  - 2072-4292

AB  - Remote estimation of flower number in oilseed rape under different nitrogen (N) treatments is imperative in precision agriculture and field remote sensing, which can help to predict the yield of oilseed rape. In this study, an unmanned aerial vehicle (UAV) equipped with Red Green Blue (RGB) and multispectral cameras was used to acquire a series of field images at the flowering stage, and the flower number was manually counted as a reference. Images of the rape field were first classified using K-means method based on Commission Internationale de l&rsquo;&Eacute;clairage (CIE) L*a*b* space, and the result showed that classified flower coverage area (FCA) possessed a high correlation with the flower number (r2 = 0.89). The relationships between ten commonly used vegetation indices (VIs) extracted from UAV-based RGB and multispectral images and the flower number were investigated, and the VIs of Normalized Green Red Difference Index (NGRDI), Red Green Ratio Index (RGRI) and Modified Green Red Vegetation Index (MGRVI) exhibited the highest correlation to the flower number with the absolute correlation coefficient (r) of 0.91. Random forest (RF) model was developed to predict the flower number, and a good performance was achieved with all UAV variables (r2 = 0.93 and RMSEP = 16.18), while the optimal subset regression (OSR) model was further proposed to simplify the RF model, and a better result with r2 = 0.95 and RMSEP = 14.13 was obtained with the variable combination of RGRI, normalized difference spectral index (NDSI (944, 758)) and FCA. Our findings suggest that combining VIs and image classification from UAV-based RGB and multispectral images possesses the potential of estimating flower number in oilseed rape.
KW  - unmanned aerial vehicle (UAV)
KW  - RGB and multispectral camera
KW  - flower number
KW  - oilseed rape
KW  - vegetation indices
KW  - image classification
DO  - 10.3390/rs10091484
ER  -
TY  - EJOU
AU  - Xavier, Shereen S.
AU  - Coffin, Alisa W.
AU  - Olson, Dawn M.
AU  - Schmidt, Jason M.
TI  - Remotely Estimating Beneficial Arthropod Populations: Implications of a Low-Cost Small Unmanned Aerial System
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 9
SN  - 2072-4292

AB  - Studies show that agricultural land requires investment in the habitat management of non-cropped areas to support healthy beneficial arthropods and the ecosystem services they provide. In a previous small plot study, we manually counted blooms over the season, and found that plots providing greater numbers of flowers supported significantly higher pollinator populations over that of spontaneous weed plots. Here, we examined the potential of deploying an inexpensive small unmanned aerial vehicle (UAV) as a tool to remotely estimate floral resources and corresponding pollinator populations. Data were collected from previously established native wildflower plots in 19 locations on the University of Georgia experimental farms in South Georgia, USA. A UAV equipped with a lightweight digital camera was deployed to capture images of the flowers during the months of June and September 2017. Supervised image classification using a geographic information system (GIS) was carried out on the acquired images, and classified images were used to evaluate the floral area. The floral area obtained from the images positively correlated with the floral counts gathered from the quadrat samples. Furthermore, the floral area derived from imagery significantly predicted pollinator populations, with a positive correlation indicating that plots with greater area of blooming flowers contained higher numbers of pollinators.
KW  - UAV floral detection
KW  - image classification
KW  - floral provisioning
KW  - habitat management
KW  - pollinators
KW  - agricultural buffers
KW  - floral area
KW  - long term agroecosystem research (LTAR)
DO  - 10.3390/rs10091485
ER  -
TY  - EJOU
AU  - Palace, Michael
AU  - Herrick, Christina
AU  - DelGreco, Jessica
AU  - Finnell, Daniel
AU  - Garnello, Anthony J.
AU  - McCalley, Carmody
AU  - McArthur, Kellen
AU  - Sullivan, Franklin
AU  - Varner, Ruth K.
TI  - Determining Subarctic Peatland Vegetation Using an Unmanned Aerial System (UAS)
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 9
SN  - 2072-4292

AB  - Rising global temperatures tied to increases in greenhouse gas emissions are impacting high latitude regions, leading to changes in vegetation composition and feedbacks to climate through increased methane (CH4) emissions. In subarctic peatlands, permafrost collapse has led to shifts in vegetation species on landscape scales with high spatial heterogeneity. Our goal was to provide a baseline for vegetation distribution related to permafrost collapse and changes in biogeochemical processes. We collected unmanned aerial system (UAS) imagery at Stordalen Mire, Abisko, Sweden to classify vegetation cover types. A series of digital image processing routines were used to generate texture attributes within the image for the purpose of characterizing vegetative cover types. An artificial neural network (ANN) was developed to classify the image. The ANN used all texture variables and color bands (three spectral bands and six metrics) to generate a probability map for each of the eight cover classes. We used the highest probability for a class at each pixel to designate the cover type in the final map. Our overall misclassification rate was 32%, while omission and commission error by class ranged from 0% to 50%. We found that within our area of interest, cover classes most indicative of underlying permafrost (hummock and tall shrub) comprised 43.9% percent of the landscape. Our effort showed the capability of an ANN applied to UAS high-resolution imagery to develop a classification that focuses on vegetation types associated with permafrost status and therefore potentially changes in greenhouse gas exchange. We also used a method to examine the multiple probabilities representing cover class prediction at the pixel level to examine model confusion. UAS image collection can be inexpensive and a repeatable avenue to determine vegetation change at high latitudes, which can further be used to estimate and scale corresponding changes in CH4 emissions.
KW  - unmanned aerial system (UAS)
KW  - artificial neural network
KW  - mire vegetation
KW  - Stordalen
KW  - tundra
KW  - drone
KW  - classification
DO  - 10.3390/rs10091498
ER  -
TY  - EJOU
AU  - Chen, Lin
AU  - Ren, Chunying
AU  - Zhang, Bai
AU  - Wang, Zongming
AU  - Xi, Yanbiao
TI  - Estimation of Forest Above-Ground Biomass by Geographically Weighted Regression and Machine Learning with Sentinel Imagery
T2  - Forests

PY  - 2018
VL  - 9
IS  - 10
SN  - 1999-4907

AB  - Accurate forest above-ground biomass (AGB) is crucial for sustaining forest management and mitigating climate change to support REDD+ (reducing emissions from deforestation and forest degradation, plus the sustainable management of forests, and the conservation and enhancement of forest carbon stocks) processes. Recently launched Sentinel imagery offers a new opportunity for forest AGB mapping and monitoring. In this study, texture characteristics and backscatter coefficients of Sentinel-1, in addition to multispectral bands, vegetation indices, and biophysical variables of Sentinal-2, based on 56 measured AGB samples in the center of the Changbai Mountains, China, were used to develop biomass prediction models through geographically weighted regression (GWR) and machine learning (ML) algorithms, such as the artificial neural network (ANN), support vector machine for regression (SVR), and random forest (RF). The results showed that texture characteristics and vegetation biophysical variables were the most important predictors. SVR was the best method for predicting and mapping the patterns of AGB in the study site with limited samples, whose mean error, mean absolute error, root mean square error, and correlation coefficient were 4 &times; 10&minus;3, 0.07, 0.08 Mg&middot;ha&minus;1, and 1, respectively. Predicted values of AGB from four models ranged from 11.80 to 324.12 Mg&middot;ha&minus;1, and those for broadleaved deciduous forests were the most accurate, while those for AGB above 160 Mg&middot;ha&minus;1 were the least accurate. The study demonstrated encouraging results in forest AGB mapping of the normal vegetated area using the freely accessible and high-resolution Sentinel imagery, based on ML techniques.
KW  - sentinel imagery
KW  - above-ground biomass
KW  - predictive mapping
KW  - machine learning
KW  - geographically weighted regression
DO  - 10.3390/f9100582
ER  -
TY  - EJOU
AU  - Theron, Andre
AU  - Engelbrecht, Jeanine
TI  - The Role of Earth Observation, with a Focus on SAR Interferometry, for Sinkhole Hazard Assessment
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 10
SN  - 2072-4292

AB  - Sinkholes are global phenomena with significant consequences on the natural- and built environment. Significant efforts have been devoted to the assessment of sinkhole hazards to predict the spatial and temporal occurrence of future sinkholes as well as to detect small-scale deformation prior to collapse. Sinkhole hazard maps are created by considering the distribution of past sinkholes in conjunction with their geomorphic features, controlling conditions and triggering mechanisms. Quantitative risk assessment then involves the statistical analysis of sinkhole events in relation to these conditions with the aim of identifying high risk areas. Remote sensing techniques contribute to the field of sinkhole hazard assessment by providing tools for the population of sinkhole inventories and lend themselves to the monitoring of precursory deformation prior to sinkhole development. In this paper, we outline the background to sinkhole formation and sinkhole hazard assessment. We provide a review of earth observation techniques, both for the compilation of sinkhole inventories as well as the monitoring of precursors to sinkhole development. We discuss the advantages and limitations of these approaches and conclude by highlighting the potential role of radar interferometry in the early detection of sinkhole-induced instability resulting in a potential decrease in the risk to human lives and infrastructure by enabling proactive remediation.
KW  - sinkholes
KW  - geohazard
KW  - inventory
KW  - monitoring
KW  - prediction
KW  - SAR interferometry
DO  - 10.3390/rs10101506
ER  -
TY  - EJOU
AU  - Duarte-Carvajalino, Julio M.
AU  - Alzate, Diego F.
AU  - Ramirez, Andrés A.
AU  - Santa-Sepulveda, Juan D.
AU  - Fajardo-Rojas, Alexandra E.
AU  - Soto-Suárez, Mauricio
TI  - Evaluating Late Blight Severity in Potato Crops Using Unmanned Aerial Vehicles and Machine Learning Algorithms
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 10
SN  - 2072-4292

AB  - This work presents quantitative prediction of severity of the disease caused by Phytophthora infestans in potato crops using machine learning algorithms such as multilayer perceptron, deep learning convolutional neural networks, support vector regression, and random forests. The machine learning algorithms are trained using datasets extracted from multispectral data captured at the canopy level with an unmanned aerial vehicle, carrying an inexpensive digital camera. The results indicate that deep learning convolutional neural networks, random forests and multilayer perceptron using band differences can predict the level of Phytophthora infestans affectation on potato crops with acceptable accuracy.
KW  - UAV
KW  - remote sensing
KW  - Phytophthora infestans
KW  - multispectral
KW  - neural networks
KW  - deep learning
DO  - 10.3390/rs10101513
ER  -
TY  - EJOU
AU  - Pflanz, Michael
AU  - Nordmeyer, Henning
AU  - Schirrmann, Michael
TI  - Weed Mapping with UAS Imagery and a Bag of Visual Words Based Image Classifier
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 10
SN  - 2072-4292

AB  - Weed detection with aerial images is a great challenge to generate field maps for site-specific plant protection application. The requirements might be met with low altitude flights of unmanned aerial vehicles (UAV), to provide adequate ground resolutions for differentiating even single weeds accurately. The following study proposed and tested an image classifier based on a Bag of Visual Words (BoVW) framework for mapping weed species, using a small unmanned aircraft system (UAS) with a commercial camera on board, at low flying altitudes. The image classifier was trained with support vector machines after building a visual dictionary of local features from many collected UAS images. A window-based processing of the models was used for mapping the weed occurrences in the UAS imagery. The UAS flight campaign was carried out over a weed infested wheat field, and images were acquired between a 1 and 6 m flight altitude. From the UAS images, 25,452 weed plants were annotated on species level, along with wheat and soil as background classes for training and validation of the models. The results showed that the BoVW model allowed the discrimination of single plants with high accuracy for Matricaria recutita L. (88.60%), Papaver rhoeas L. (89.08%), Viola arvensis M. (87.93%), and winter wheat (94.09%), within the generated maps. Regarding site specific weed control, the classified UAS images would enable the selection of the right herbicide based on the distribution of the predicted weed species.
KW  - low altitude UAS flights
KW  - weed mapping
KW  - bag of visual words
KW  - object based image classification
DO  - 10.3390/rs10101530
ER  -
TY  - EJOU
AU  - Ma, Lingfei
AU  - Li, Ying
AU  - Li, Jonathan
AU  - Wang, Cheng
AU  - Wang, Ruisheng
AU  - Chapman, Michael A.
TI  - Mobile Laser Scanned Point-Clouds for Road Object Detection and Extraction: A Review
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 10
SN  - 2072-4292

AB  - The mobile laser scanning (MLS) technique has attracted considerable attention for providing high-density, high-accuracy, unstructured, three-dimensional (3D) geo-referenced point-cloud coverage of the road environment. Recently, there has been an increasing number of applications of MLS in the detection and extraction of urban objects. This paper presents a systematic review of existing MLS related literature. This paper consists of three parts. Part 1 presents a brief overview of the state-of-the-art commercial MLS systems. Part 2 provides a detailed analysis of on-road and off-road information inventory methods, including the detection and extraction of on-road objects (e.g., road surface, road markings, driving lines, and road crack) and off-road objects (e.g., pole-like objects and power lines). Part 3 presents a refined integrated analysis of challenges and future trends. Our review shows that MLS technology is well proven in urban object detection and extraction, since the improvement of hardware and software accelerate the efficiency and accuracy of data collection and processing. When compared to other review papers focusing on MLS applications, we review the state-of-the-art road object detection and extraction methods using MLS data and discuss their performance and applicability. The main contribution of this review demonstrates that the MLS systems are suitable for supporting road asset inventory, ITS-related applications, high-definition maps, and other highly accurate localization services.
KW  - mobile laser scanning (MLS)
KW  - point cloud
KW  - road surface
KW  - road marking
KW  - driving line
KW  - road crack
KW  - traffic sign
KW  - street light
KW  - tree
KW  - power line
KW  - deep learning
DO  - 10.3390/rs10101531
ER  -
TY  - EJOU
AU  - Thomson, Eleanor R.
AU  - Malhi, Yadvinder
AU  - Bartholomeus, Harm
AU  - Oliveras, Imma
AU  - Gvozdevaite, Agne
AU  - Peprah, Theresa
AU  - Suomalainen, Juha
AU  - Quansah, John
AU  - Seidu, John
AU  - Adonteng, Christian
AU  - Abraham, Andrew J.
AU  - Herold, Martin
AU  - Adu-Bredu, Stephen
AU  - Doughty, Christopher E.
TI  - Mapping the Leaf Economic Spectrum across West African Tropical Forests Using UAV-Acquired Hyperspectral Imagery
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 10
SN  - 2072-4292

AB  - The leaf economic spectrum (LES) describes a set of universal trade-offs between leaf mass per area (LMA), leaf nitrogen (N), leaf phosphorus (P) and leaf photosynthesis that influence patterns of primary productivity and nutrient cycling. Many questions regarding vegetation-climate feedbacks can be addressed with a better understanding of LES traits and their controls. Remote sensing offers enormous potential for generating large-scale LES trait data. Yet so far, canopy studies have been limited to imaging spectrometers onboard aircraft, which are rare, expensive to deploy and lack fine-scale resolution. In this study, we measured VNIR (visible-near infrared (400&ndash;1050 nm)) reflectance of individual sun and shade leaves in 7 one-ha tropical forest plots located along a 1200&ndash;2000 mm precipitation gradient in West Africa. We collected hyperspectral imaging data from 3 of the 7 plots, using an octocopter-based unmanned aerial vehicle (UAV), mounted with a hyperspectral mapping system (450&ndash;950 nm, 9 nm FWHM). Using partial least squares regression (PLSR), we found that the spectra of individual sun leaves demonstrated significant (p &lt; 0.01) correlations with LMA and leaf chemical traits: r2 = 0.42 (LMA), r2 = 0.43 (N), r2 = 0.21 (P), r2 = 0.20 (leaf potassium (K)), r2 = 0.23 (leaf calcium (Ca)) and r2 = 0.14 (leaf magnesium (Mg)). Shade leaf spectra displayed stronger relationships with all leaf traits. At the airborne level, four of the six leaf traits demonstrated weak (p &lt; 0.10) correlations with the UAV-collected spectra of 58 tree crowns: r2 = 0.25 (LMA), r2 = 0.22 (N), r2 = 0.22 (P), and r2 = 0.25 (Ca). From the airborne imaging data, we used LMA, N and P values to map the LES across the three plots, revealing precipitation and substrate as co-dominant drivers of trait distributions and relationships. Positive N-P correlations and LMA-P anticorrelations followed typical LES theory, but we found no classic trade-offs between LMA and N. Overall, this study demonstrates the application of UAVs to generating LES information and advancing the study and monitoring tropical forest functional diversity.
KW  - leaf traits
KW  - leaf economic spectrum
KW  - UAV
KW  - hyperspectral
KW  - spectroscopy
KW  - tropical forest
KW  - PLSR
KW  - Ghana
KW  - West Africa
DO  - 10.3390/rs10101532
ER  -
TY  - EJOU
AU  - Luo, Lei
AU  - Wang, Xinyuan
AU  - Guo, Huadong
AU  - Lasaponara, Rosa
AU  - Shi, Pilong
AU  - Bachagha, Nabil
AU  - Li, Li
AU  - Yao, Ya
AU  - Masini, Nicola
AU  - Chen, Fulong
AU  - Ji, Wei
AU  - Cao, Hui
AU  - Li, Chao
AU  - Hu, Ningke
TI  - Google Earth as a Powerful Tool for Archaeological and Cultural Heritage Applications: A Review
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 10
SN  - 2072-4292

AB  - Google Earth (GE), a large Earth-observation data-based geographical information computer application, is an intuitive three-dimensional virtual globe. It enables archaeologists around the world to communicate and share their multisource data and research findings. Different from traditional geographical information systems (GIS), GE is free and easy to use in data collection, exploration, and visualization. In the past decade, many peer-reviewed articles on the use of GE in the archaeological cultural heritage (ACH) research field have been published. Most of these concern specific ACH investigations with a wide spatial coverage. GE can often be used to survey and document ACH so that both skilled archaeologists and the public can more easily and intuitively understand the results. Based on geographical tools and multi-temporal very high-resolution (VHR) satellite imagery, GE has been shown to provide spatio-temporal change information that has a bearing on the physical, environmental, and geographical character of ACH. In this review, in order to discuss the huge potential of GE, a comprehensive review of GE and its applications to ACH in the published scientific literature is first presented; case studies in five main research fields demonstrating how GE can be deployed as a key tool for studying ACH are then described. The selected case studies illustrate how GE can be used effectively to investigate ACH at multiple scales, discover new archaeological sites in remote regions, monitor historical sites, and assess damage in areas of conflict, and promote virtual tourism. These examples form the basis for highlighting current trends in remote sensing archaeology based on the GE platform, which could provide access to a low-cost and easy-to-use tool for communicating and sharing ACH geospatial data more effectively to the general public in the era of Digital Earth. Finally, a discussion of the merits and limitations of GE is presented along with conclusions and remaining challenges.
KW  - Google Earth (GE)
KW  - archaeological
KW  - cultural heritage
KW  - remote sensing
KW  - Keyhole Markup Language
KW  - very high-resolution (VHR)
KW  - virtual
DO  - 10.3390/rs10101558
ER  -
TY  - EJOU
AU  - Otsu, Kaori
AU  - Pla, Magda
AU  - Vayreda, Jordi
AU  - Brotons, Lluís
TI  - Calibrating the Severity of Forest Defoliation by Pine Processionary Moth with Landsat and UAV Imagery
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 10
SN  - 1424-8220

AB  - The pine processionary moth (Thaumetopoea pityocampa Dennis and Schiff.), one of the major defoliating insects in Mediterranean forests, has become an increasing threat to the forest health of the region over the past two decades. After a recent outbreak of T. pityocampa in Catalonia, Spain, we attempted to estimate the damage severity by capturing the maximum defoliation period over winter between pre-outbreak and post-outbreak images. The difference in vegetation index (dVI) derived from Landsat 8 was used as the change detection indicator and was further calibrated with Unmanned Aerial Vehicle (UAV) imagery. Regression models between predicted dVIs and observed defoliation degrees by UAV were compared among five selected dVIs for the coefficient of determination. Our results found the highest R-squared value (0.815) using Moisture Stress Index (MSI), with an overall accuracy of 72%, as a promising approach for estimating the severity of defoliation in affected areas where ground-truth data is limited. We concluded with the high potential of using UAVs as an alternative method to obtain ground-truth data for cost-effectively monitoring forest health. In future studies, combining UAV images with satellite data may be considered to validate model predictions of the forest condition for developing ecosystem service tools.
KW  - forest defoliation
KW  - Thaumetopoea pityocampa
KW  - vegetation index
KW  - unmanned aerial vehicle (UAV)
KW  - change detection
DO  - 10.3390/s18103278
ER  -
TY  - EJOU
AU  - Han, Xiaoliang
AU  - Lv, Peiyi
AU  - Zhao, Sen
AU  - Sun, Yan
AU  - Yan, Shiyu
AU  - Wang, Minghao
AU  - Han, Xiaona
AU  - Wang, Xiuru
TI  - The Effect of the Gully Land Consolidation Project on Soil Erosion and Crop Production on a Typical Watershed in the Loess Plateau
T2  - Land

PY  - 2018
VL  - 7
IS  - 4
SN  - 2073-445X

AB  - The Gully Land Consolidation Project (GLCP) was launched to create more arable land by excavating soil from the slopes on both sides of gullies, combined with simultaneous comprehensive gully prevention and control measures. The purpose of the GLCP is to increase crop production and reduce soil erosion to achieve ecological and agricultural sustainability. In this study, we assess the effects of the GLCP on soil erosion and crop production by studying the BaoChengGou Watershed in the Loess Plateau, primarily by means of high spatial-resolution satellite images (taken by the GF-1 and ZY-3 satellites) combined with the InVEST model and field investigations. Sloping cropland, sparse forestland, and natural grassland are the main land use types in the study area. After implementing the GLCP, consolidated land in the cropland increased by 7.35%, an increase that has come largely at the expense of grassland and forestland. The GLCP has markedly reduced soil erosion in the BaoChengGou Watershed, especially in the sense that soil erosion intensity was also reduced significantly in the project region on the whole, despite intensifying in certain places, such as excavated slopes; furthermore, it has improved crop yields in the study area by 10.9%. Comprehensive measurement shows the GLCP to be scientific, reasonable, and clearly efficacious. This study presents findings regarding the positive significance of the GLCP in promoting ecological and agricultural sustainability in the Loess Plateau.
KW  - Gully Land Consolidation Project (GLCP)
KW  - soil erosion
KW  - crop production
KW  - sustainable development
KW  - high spatial resolution satellite
KW  - InVEST
KW  - Loess Plateau
DO  - 10.3390/land7040113
ER  -
TY  - EJOU
AU  - Tayara, Hilal
AU  - Chong, Kil T.
TI  - Object Detection in Very High-Resolution Aerial Images Using One-Stage Densely Connected Feature Pyramid Network
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 10
SN  - 1424-8220

AB  - Object detection in very high-resolution (VHR) aerial images is an essential step for a wide range of applications such as military applications, urban planning, and environmental management. Still, it is a challenging task due to the different scales and appearances of the objects. On the other hand, object detection task in VHR aerial images has improved remarkably in recent years due to the achieved advances in convolution neural networks (CNN). Most of the proposed methods depend on a two-stage approach, namely: a region proposal stage and a classification stage such as Faster R-CNN. Even though two-stage approaches outperform the traditional methods, their optimization is not easy and they are not suitable for real-time applications. In this paper, a uniform one-stage model for object detection in VHR aerial images has been proposed. In order to tackle the challenge of different scales, a densely connected feature pyramid network has been proposed by which high-level multi-scale semantic feature maps with high-quality information are prepared for object detection. This work has been evaluated on two publicly available datasets and outperformed the current state-of-the-art results on both in terms of mean average precision (mAP) and computation time.
KW  - Aerial images
KW  - convolution neural network (CNN)
KW  - deep learning
KW  - feature pyramid network
KW  - focal loss
KW  - object detection
DO  - 10.3390/s18103341
ER  -
TY  - EJOU
AU  - Zhao, Qingxia
AU  - Wang, Fei
AU  - Zhao, Jun
AU  - Zhou, Jingjing
AU  - Yu, Shichuan
AU  - Zhao, Zhong
TI  - Estimating Forest Canopy Cover in Black Locust (Robinia pseudoacacia L.) Plantations on the Loess Plateau Using Random Forest
T2  - Forests

PY  - 2018
VL  - 9
IS  - 10
SN  - 1999-4907

AB  - The forest canopy is the medium for energy and mass exchange between forest ecosystems and the atmosphere. Remote sensing techniques are more efficient and appropriate for estimating forest canopy cover (CC) than traditional methods, especially at large scales. In this study, we evaluated the CC of black locust plantations on the Loess Plateau using random forest (RF) regression models. The models were established using the relationships between digital hemispherical photograph (DHP) field data and variables that were calculated from satellite images. Three types of variables were calculated from the satellite data: spectral variables calculated from a multispectral image, textural variables calculated from a panchromatic image (Tpan) with a 15 &times; 15 window size, and textural variables calculated from spectral variables (TB+VIs) with a 9 &times; 9 window size. We compared different mtry and ntree values to find the most suitable parameters for the RF models. The results indicated that the RF model of spectral variables explained 57% (root mean square error (RMSE) = 0.06) of the variability in the field CC data. The soil-adjusted vegetation index (SAVI) and enhanced vegetation index (EVI) were more important than other spectral variables. The RF model of Tpan obtained higher accuracy (R2 = 0.69, RMSE = 0.05) than the spectral variables, and the grey level co-occurrence matrix-based texture measure&mdash;Correlation (COR) was the most important variable for Tpan. The most accurate model was obtained from the TB+VIs (R2 = 0.79, RMSE = 0.05), which combined spectral and textural information, thus providing a significant improvement in estimating CC. This model provided an effective approach for detecting the CC of black locust plantations on the Loess Plateau.
KW  - canopy cover (CC)
KW  - spectral
KW  - texture
KW  - digital hemispherical photograph (DHP)
KW  - random forest (RF)
KW  - gray level co-occurrence matrix (GLCM)
DO  - 10.3390/f9100623
ER  -
TY  - EJOU
AU  - Opromolla, Roberto
AU  - Fasano, Giancarmine
AU  - Accardo, Domenico
TI  - A Vision-Based Approach to UAV Detection and Tracking in Cooperative Applications
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 10
SN  - 1424-8220

AB  - This paper presents a visual-based approach that allows an Unmanned Aerial Vehicle (UAV) to detect and track a cooperative flying vehicle autonomously using a monocular camera. The algorithms are based on template matching and morphological filtering, thus being able to operate within a wide range of relative distances (i.e., from a few meters up to several tens of meters), while ensuring robustness against variations of illumination conditions, target scale and background. Furthermore, the image processing chain takes full advantage of navigation hints (i.e., relative positioning and own-ship attitude estimates) to improve the computational efficiency and optimize the trade-off between correct detections, false alarms and missed detections. Clearly, the required exchange of information is enabled by the cooperative nature of the formation through a reliable inter-vehicle data-link. Performance assessment is carried out by exploiting flight data collected during an ad hoc experimental campaign. The proposed approach is a key building block of cooperative architectures designed to improve UAV navigation performance either under nominal GNSS coverage or in GNSS-challenging environments.
KW  - unmanned aerial vehicles
KW  - visual detection
KW  - visual tracking
KW  - template matching
KW  - morphological filtering
KW  - cooperative UAV applications
KW  - autonomous navigation
DO  - 10.3390/s18103391
ER  -
TY  - EJOU
AU  - Helman, David
AU  - Bahat, Idan
AU  - Netzer, Yishai
AU  - Ben-Gal, Alon
AU  - Alchanatis, Victor
AU  - Peeters, Aviva
AU  - Cohen, Yafit
TI  - Using Time Series of High-Resolution Planet Satellite Images to Monitor Grapevine Stem Water Potential in Commercial Vineyards
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 10
SN  - 2072-4292

AB  - Spectral-based vegetation indices (VI) have been shown to be good proxies of grapevine stem water potential (&Psi;stem), assisting in irrigation decision-making for commercial vineyards. However, VI-&Psi;stem correlations are mostly reported at the leaf or canopy scales, using proximal canopy-based sensors or very-high-spatial resolution images derived from sensors mounted on small airplanes or drones. Here, for the first time, we take advantage of high-spatial resolution (3-m) near-daily images acquired from Planet&rsquo;s nano-satellite constellation to derive VI-&Psi;stem correlations at the vineyard scale. Weekly &Psi;stem was measured along the growing season of 2017 in six vines each in 81 commercial vineyards and in 60 pairs of grapevines in a 2.4 ha experimental vineyard in Israel. The Clip application programming interface (API), provided by Planet, and the Google Earth Engine platform were used to derive spatially continuous time series of four VIs&mdash;GNDVI, NDVI, EVI and SAVI&mdash;in the 82 vineyards. Results show that per-week multivariable linear models using variables extracted from VI time series successfully tracked spatial variations in &Psi;stem across the experimental vineyard (Pearson&rsquo;s-r = 0.45&ndash;0.84; N = 60). A simple linear regression model enabled monitoring seasonal changes in &Psi;stem along the growing season in the vineyard (r = 0.80&ndash;0.82). Planet VIs and seasonal &Psi;stem data from the 82 vineyards were used to derive a &lsquo;global&rsquo; model for in-season monitoring of &Psi;stem at the vineyard-level (r = 0.78; RMSE = 18.5%; N = 970). The &lsquo;global&rsquo; model, which requires only a few VI variables extracted from Planet images, may be used for real-time weekly assessment of &Psi;stem in Mediterranean vineyards, substantially improving the efficiency of conventional in-field monitoring efforts.
KW  - Google Earth Engine
KW  - grapevine
KW  - irrigation
KW  - Planet
KW  - time series
KW  - stem water potential
KW  - VI
KW  - vineyard
DO  - 10.3390/rs10101615
ER  -
TY  - EJOU
AU  - Chen, Hongyi
AU  - Zhang, Fan
AU  - Tang, Bo
AU  - Yin, Qiang
AU  - Sun, Xian
TI  - Slim and Efficient Neural Network Design for Resource-Constrained SAR Target Recognition
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 10
SN  - 2072-4292

AB  - Deep convolutional neural networks (CNN) have been recently applied to synthetic aperture radar (SAR) for automatic target recognition (ATR) and have achieved state-of-the-art results with significantly improved recognition performance. However, the training period of deep CNN is long, and the size of the network is huge, sometimes reaching hundreds of megabytes. These two factors of deep CNN hinders its practical implementation and deployment in real-time SAR platforms that are typically resource-constrained. To address this challenge, this paper presents three strategies of network compression and acceleration to decrease computing and memory resource dependencies while maintaining a competitive accuracy. First, we introduce a new weight-based network pruning and adaptive architecture squeezing method to reduce the network storage and the time of inference and training process, meanwhile maintain a balance between compression ratio and classification accuracy. Then we employ weight quantization and coding to compress the network storage space. Due to the fact that the amount of calculation is mainly reflected in the convolution layer, a fast approach for pruned convolutional layers is proposed to reduce the number of multiplication by exploiting the sparsity in the activation inputs and weights. Experimental results show that the convolutional neural networks for SAR-ATR can be compressed by     40 &times;     without loss of accuracy, and the number of multiplication can be reduced by     15 &times;    . Combining these strategies, we can easily load the network in resource-constrained platforms, speed up the inference process to get the results in real-time or even retrain a more suitable network with new image data in a specific situation.
KW  - deep learning
KW  - synthetic aperture radar (SAR)
KW  - automatic target recognition (ATR)
KW  - model compression
KW  - fast algorithm
DO  - 10.3390/rs10101618
ER  -
TY  - EJOU
AU  - Kim, Byunghyun
AU  - Cho, Soojin
TI  - Automated Vision-Based Detection of Cracks on Concrete Surfaces Using a Deep Learning Technique
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 10
SN  - 1424-8220

AB  - At present, a number of computer vision-based crack detection techniques have been developed to efficiently inspect and manage a large number of structures. However, these techniques have not replaced visual inspection, as they have been developed under near-ideal conditions and not in an on-site environment. This article proposes an automated detection technique for crack morphology on concrete surface under an on-site environment based on convolutional neural networks (CNNs). A well-known CNN, AlexNet is trained for crack detection with images scraped from the Internet. The training set is divided into five classes involving cracks, intact surfaces, two types of similar patterns of cracks, and plants. A comparative study evaluates the successfulness of the detailed surface categorization. A probability map is developed using a softmax layer value to add robustness to sliding window detection and a parametric study was carried out to determine its threshold. The applicability of the proposed method is evaluated on images taken from the field and real-time video frames taken using an unmanned aerial vehicle. The evaluation results confirm the high adoptability of the proposed method for crack inspection in an on-site environment.
KW  - crack
KW  - deep learning
KW  - convolutional neural networks
KW  - AlexNet
KW  - unmanned aerial vehicle
DO  - 10.3390/s18103452
ER  -
TY  - EJOU
AU  - Fang, Tao
AU  - Tian, Hua
AU  - Zhang, Xiaobo
AU  - Chen, Xueqiang
AU  - Shao, Xinhong
AU  - Zhang, Yuli
TI  - Context-Aware Caching Distribution and UAV Deployment: A Game-Theoretic Approach
T2  - Applied Sciences

PY  - 2018
VL  - 8
IS  - 10
SN  - 2076-3417

AB  - This paper investigates the problem of the optimal arrangement for both unmanned aerial vehicles&rsquo; (UAVs&rsquo;) caching contents and service locations in UAV-assisted networks based on the context awareness, which considers the influence between users and environment. In the existing work, users within the coverage of UAVs are considered to be served perfectly, which ignores the communication probability caused by line-of-sight (LOS) and non-line-of-sight (NLOS) links. However, the links are related to the deployment of UAVs. Moreover, the transmission overhead should be taken into account. To balance the tradeoff between these two factors, we design the ratio of users&rsquo; probability and transmission overhead as the performance measure mechanism to evaluate the performance of UAV-assisted networks. Then, we formulate the objective for maximizing the performance of UAV-assisted networks as a UAV-assisted caching game. It is proved that the game is an exact potential game with the performance of UAV-assisted networks serving as the potential function. Next, we propose a log-linear caching algorithm (LCA) to achieve the Nash equilibrium (NE). Finally, related simulation results reflect the great performance of the proposed algorithm.
KW  - context-aware
KW  - UAV-assisted networks
KW  - communication probability
KW  - cache content
KW  - potential game
DO  - 10.3390/app8101959
ER  -
TY  - EJOU
AU  - Martin, François-Marie
AU  - Müllerová, Jana
AU  - Borgniet, Laurent
AU  - Dommanget, Fanny
AU  - Breton, Vincent
AU  - Evette, André
TI  - Using Single- and Multi-Date UAV and Satellite Imagery to Accurately Monitor Invasive Knotweed Species
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 10
SN  - 2072-4292

AB  - Understanding the spatial dynamics of invasive alien plants is a growing concern for many scientists and land managers hoping to effectively tackle invasions or mitigate their impacts. Consequently, there is an urgent need for the development of efficient tools for large scale mapping of invasive plant populations and the monitoring of colonization fronts. Remote sensing using very high resolution satellite and Unmanned Aerial Vehicle (UAV) imagery is increasingly considered for such purposes. Here, we assessed the potential of several single- and multi-date indices derived from satellite and UAV imagery (i.e., UAV-generated Canopy Height Models—CHMs; and Bi-Temporal Band Ratios—BTBRs) for the detection and mapping of the highly problematic Asian knotweeds (Fallopia japonica; Fallopia × bohemica) in two different landscapes (i.e., open vs. highly heterogeneous areas). The idea was to develop a simple classification procedure using the Random Forest classifier in eCognition, usable in various contexts and requiring little training to be used by non-experts. We also rationalized errors of omission by applying simple “buffer” boundaries around knotweed predictions to know if heterogeneity across multi-date images could lead to unfairly harsh accuracy assessment and, therefore, ill-advised decisions. Although our “crisp” satellite results were rather average, our UAV classifications achieved high detection accuracies. Multi-date spectral indices and CHMs consistently improved classification results of both datasets. To the best of our knowledge, it was the first time that UAV-generated CHMs were used to map invasive plants and their use substantially facilitated knotweed detection in heterogeneous vegetation contexts. Additionally, the “buffer” boundary results showed detection rates often exceeding 90–95% for both satellite and UAV images, suggesting that classical accuracy assessments were overly conservative. Considering these results, it seems that knotweed can be satisfactorily mapped and monitored via remote sensing with moderate time and money investment but that the choice of the most appropriate method will depend on the landscape context and the spatial scale of the invaded area.
KW  - Fallopia spp. (Reynoutria spp.)
KW  - invasive plant management
KW  - applied remote sensing
KW  - spatial dynamics monitoring
KW  - Unmanned Aerial Vehicle (UAV)
KW  - very high resolution satellite imagery
DO  - 10.3390/rs10101662
ER  -
TY  - EJOU
AU  - Mozgeris, Gintautas
AU  - Juodkienė, Vytautė
AU  - Jonikavičius, Donatas
AU  - Straigytė, Lina
AU  - Gadal, Sébastien
AU  - Ouerghemmi, Walid
TI  - Ultra-Light Aircraft-Based Hyperspectral and Colour-Infrared Imaging to Identify Deciduous Tree Species in an Urban Environment
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 10
SN  - 2072-4292

AB  - One may consider the application of remote sensing as a trade-off between the imaging platforms, sensors, and data gathering and processing techniques. This study addresses the potential of hyperspectral imaging using ultra-light aircraft for vegetation species mapping in an urban environment, exploring both the engineering and scientific aspects related to imaging platform design and image classification methods. An imaging system based on simultaneous use of Rikola frame format hyperspectral and Nikon D800E adopted colour infrared cameras installed onboard a Bekas X32 manned ultra-light aircraft is introduced. Two test imaging flight missions were conducted in July of 2015 and September of 2016 over a 4000 ha area in Kaunas City, Lithuania. Sixteen and 64 spectral bands in 2015 and 2016, respectively, in a spectral range of 500&ndash;900 nm were recorded with colour infrared images. Three research questions were explored assessing the identification of six deciduous tree species: (1) Pre-treatment of spectral features for classification, (2) testing five conventional machine learning classifiers, and (3) fusion of hyperspectral and colour infrared images. Classification performance was assessed by applying leave-one-out cross-validation at the individual crown level and using as a reference at least 100 field inventoried trees for each species. The best-performing classification algorithm&mdash;multilayer perceptron, using all spectral properties extracted from the hyperspectral images&mdash;resulted in a moderate classification accuracy. The overall classification accuracy was 63%, Cohen&rsquo;s Kappa was 0.54, and the species-specific classification accuracies were in the range of 51&ndash;72%. Hyperspectral images resulted in significantly better tree species classification ability than the colour infrared images and simultaneous use of spectral properties extracted from hyperspectral and colour infrared images improved slightly the accuracy over the 2015 image. Even though classifications using hyperspectral data cubes of 64 bands resulted in relatively larger accuracies than with 16 bands, classification error matrices were not statistically different. Alternative imaging platforms (like an unmanned aerial vehicle and a Cessna 172 aircraft) and settings of the flights were discussed using simulated imaging projects assuming the same study area and field of application. Ultra-light aircraft-based hyperspectral and colour-infrared imaging was considered to be a technically and economically sound solution for urban green space inventories to facilitate tree mapping, characterization, and monitoring.
KW  - hyperspectral
KW  - colour infrared
KW  - ultra-light aircraft
KW  - urban trees
KW  - classification
DO  - 10.3390/rs10101668
ER  -
TY  - EJOU
AU  - Tu, Yu-Hsuan
AU  - Phinn, Stuart
AU  - Johansen, Kasper
AU  - Robson, Andrew
TI  - Assessing Radiometric Correction Approaches for Multi-Spectral UAS Imagery for Horticultural Applications
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 11
SN  - 2072-4292

AB  - Multi-spectral imagery captured from unmanned aerial systems (UAS) is becoming increasingly popular for the improved monitoring and managing of various horticultural crops. However, for UAS-based data to be used as an industry standard for assessing tree structure and condition as well as production parameters, it is imperative that the appropriate data collection and pre-processing protocols are established to enable multi-temporal comparison. There are several UAS-based radiometric correction methods commonly used for precision agricultural purposes. However, their relative accuracies have not been assessed for data acquired in complex horticultural environments. This study assessed the variations in estimated surface reflectance values of different radiometric corrections applied to multi-spectral UAS imagery acquired in both avocado and banana orchards. We found that inaccurate calibration panel measurements, inaccurate signal-to-reflectance conversion, and high variation in geometry between illumination, surface, and sensor viewing produced significant radiometric variations in at-surface reflectance estimates. Potential solutions to address these limitations included appropriate panel deployment, site-specific sensor calibration, and appropriate bidirectional reflectance distribution function (BRDF) correction. Future UAS-based horticultural crop monitoring can benefit from the proposed solutions to radiometric corrections to ensure they are using comparable image-based maps of multi-temporal biophysical properties.
KW  - unmanned aerial system
KW  - multi-spectral imagery
KW  - radiometric correction
KW  - bidirectional reflectance distribution function
KW  - horticulture
DO  - 10.3390/rs10111684
ER  -
TY  - EJOU
AU  - Muñoz, Paul
AU  - Orellana-Alvear, Johanna
AU  - Willems, Patrick
AU  - Célleri, Rolando
TI  - Flash-Flood Forecasting in an Andean Mountain Catchment—Development of a Step-Wise Methodology Based on the Random Forest Algorithm
T2  - Water

PY  - 2018
VL  - 10
IS  - 11
SN  - 2073-4441

AB  - Flash-flood forecasting has emerged worldwide due to the catastrophic socio-economic impacts this hazard might cause and the expected increase of its frequency in the future. In mountain catchments, precipitation-runoff forecasts are limited by the intrinsic complexity of the processes involved, particularly its high rainfall variability. While process-based models are hard to implement, there is a potential to use the random forest algorithm due to its simplicity, robustness and capacity to deal with complex data structures. Here a step-wise methodology is proposed to derive parsimonious models accounting for both hydrological functioning of the catchment (e.g., input data, representation of antecedent moisture conditions) and random forest procedures (e.g., sensitivity analyses, dimension reduction, optimal input composition). The methodology was applied to develop short-term prediction models of varying time duration (4, 8, 12, 18 and 24 h) for a catchment representative of the Ecuadorian Andes. Results show that the derived parsimonious models can reach validation efficiencies (Nash-Sutcliffe coefficient) from 0.761 (4-h) to 0.384 (24-h) for optimal inputs composed only by features accounting for 80% of the model&rsquo;s outcome variance. Improvement in the prediction of extreme peak flows was demonstrated (extreme value analysis) by including precipitation information in contrast to the use of pure autoregressive models.
KW  - flash-flood
KW  - precipitation-runoff
KW  - forecasting
KW  - lag analysis
KW  - random forest
KW  - machine learning
DO  - 10.3390/w10111519
ER  -
TY  - EJOU
AU  - Padró, Joan-Cristian
AU  - Muñoz, Francisco-Javier
AU  - Ávila, Luis Á.
AU  - Pesquer, Lluís
AU  - Pons, Xavier
TI  - Radiometric Correction of Landsat-8 and Sentinel-2A Scenes Using Drone Imagery in Synergy with Field Spectroradiometry
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 11
SN  - 2072-4292

AB  - The main objective of this research is to apply unmanned aerial system (UAS) data in synergy with field spectroradiometry for the accurate radiometric correction of Landsat-8 (L8) and Sentinel-2 (S2) imagery. The central hypothesis is that imagery acquired with multispectral UAS sensors that are well calibrated with highly accurate field measurements can fill in the scale gap between satellite imagery and conventional in situ measurements; this can be possible by sampling a larger area, including difficult-to-access land covers, in less time while simultaneously providing good radiometric quality. With this aim and by using near-coincident L8 and S2 imagery, we applied an upscaling workflow, whereby: (a) UAS-acquired multispectral data was empirically fitted to the reflectance of field measurements, with an extensive set of radiometric references distributed across the spectral domain; (b) drone data was resampled to satellite grids for comparison with the radiometrically corrected L8 and S2 official products (6S-LaSRC and Sen2Cor-SNAP, respectively) and the CorRad-MiraMon algorithm using pseudo-invariant areas, such as reflectance references (PIA-MiraMon), to examine their overall accuracy; (c) then, a subset of UAS data was used as reflectance references, in combination with the CorRad-MiraMon algorithm (UAS-MiraMon), to radiometrically correct the matching bands of UAS, L8, and S2; and (d) radiometrically corrected L8 and S2 scenes obtained with UAS-MiraMon were intercompared (intersensor coherence). In the first upscaling step, the results showed a good correlation between the field spectroradiometric measurements and the drone data in all evaluated bands (R2 &gt; 0.946). In the second upscaling step, drone data indicated good agreement (estimated from root mean square error, RMSE) with the satellite official products in visible (VIS) bands (RMSEVIS &lt; 2.484%), but yielded poor results in the near-infrared (NIR) band (RMSENIR &gt; 6.688% was not very good due to spectral sensor response differences). In the third step, UAS-MiraMon indicated better agreement (RMSEVIS &lt; 2.018%) than the other satellite radiometric correction methods in visible bands (6S-LaSRC (RMSE &lt; 2.680%), Sen2Cor-SNAP (RMSE &lt; 2.192%), and PIA-MiraMon (RMSE &lt; 3.130%), but did not achieve sufficient results in the NIR band (RMSENIR &lt; 7.530%); this also occurred with all other methods. In the intercomparison step, the UAS-MiraMon method achieved an excellent intersensor (L8-S2) coherence (RMSEVIS &lt; 1%). The UAS-sampled area involved 51 L8 (30 m) pixels, 143 S2 (20 m) pixels, and 517 S2 (10 m) pixels. The drone time needed to cover this area was only 10 min, including areas that were difficult to access. The systematic sampling of the study area was achieved with a pixel size of 6 cm, and the raster nature of the sampling allowed for an easy but rigorous resampling of UAS data to the different satellite grids. These advances improve human capacities for conventional field spectroradiometry samplings. However, our study also shows that field spectroradiometry is the backbone that supports the full upscaling workflow. In conclusion, the synergy between field spectroradiometry, UAS sensors, and Landsat-like satellite data can be a useful tool for accurate radiometric corrections used in local environmental studies or the monitoring of protected areas around the world.
KW  - radiometric correction
KW  - Landsat-8
KW  - OLI
KW  - Sentinel-2
KW  - MSI
KW  - UAS
KW  - MicaSense RedEdge
KW  - field spectroradiometry
KW  - upscaling
DO  - 10.3390/rs10111687
ER  -
TY  - EJOU
AU  - Bah, M D.
AU  - Hafiane, Adel
AU  - Canals, Raphael
TI  - Deep Learning with Unsupervised Data Labeling for Weed Detection in Line Crops in UAV Images
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 11
SN  - 2072-4292

AB  - In recent years, weeds have been responsible for most agricultural yield losses. To deal with this threat, farmers resort to spraying the fields uniformly with herbicides. This method not only requires huge quantities of herbicides but impacts the environment and human health. One way to reduce the cost and environmental impact is to allocate the right doses of herbicide to the right place and at the right time (precision agriculture). Nowadays, unmanned aerial vehicles (UAVs) are becoming an interesting acquisition system for weed localization and management due to their ability to obtain images of the entire agricultural field with a very high spatial resolution and at a low cost. However, despite significant advances in UAV acquisition systems, the automatic detection of weeds remains a challenging problem because of their strong similarity to the crops. Recently, a deep learning approach has shown impressive results in different complex classification problems. However, this approach needs a certain amount of training data, and creating large agricultural datasets with pixel-level annotations by an expert is an extremely time-consuming task. In this paper, we propose a novel fully automatic learning method using convolutional neuronal networks (CNNs) with an unsupervised training dataset collection for weed detection from UAV images. The proposed method comprises three main phases. First, we automatically detect the crop rows and use them to identify the inter-row weeds. In the second phase, inter-row weeds are used to constitute the training dataset. Finally, we perform CNNs on this dataset to build a model able to detect the crop and the weeds in the images. The results obtained are comparable to those of traditional supervised training data labeling, with differences in accuracy of 1.5% in the spinach field and 6% in the bean field.
KW  - weed detection
KW  - deep learning
KW  - unmanned aerial vehicle
KW  - image processing
KW  - precision agriculture
KW  - crop line detection
DO  - 10.3390/rs10111690
ER  -
TY  - EJOU
AU  - Nomura, Keiko
AU  - Mitchard, Edward T. A.
TI  - More Than Meets the Eye: Using Sentinel-2 to Map Small Plantations in Complex Forest Landscapes
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 11
SN  - 2072-4292

AB  - Many tropical forest landscapes are now complex mosaics of intact forests, recovering forests, tree crops, agroforestry, pasture, and crops. The small patch size of each land cover type contributes to making them difficult to separate using satellite remote sensing data. We used Sentinel-2 data to conduct supervised classifications covering seven classes, including oil palm, rubber, and betel nut plantations in Southern Myanmar, based on an extensive training dataset derived from expert interpretation of WorldView-3 and UAV data. We used a Random Forest classifier with all 13 Sentinel-2 bands, as well as vegetation and texture indices, over an area of 13,330 ha. The median overall accuracy of 1000 iterations was &gt;95% (95.5%&ndash;96.0%) against independent test data, even though the tree crop classes appear visually very similar at a 20 m resolution. We conclude that the Sentinel-2 data, which are freely available with very frequent (five day) revisits, are able to differentiate these similar tree crop types. We suspect that this is due to the large number of spectral bands in Sentinel-2 data, indicating great potential for the wider application of Sentinel-2 data for the classification of small land parcels without needing to resort to object-based classification of higher resolution data.
KW  - classification
KW  - UAV
KW  - WorldView
KW  - Sentinel-2
KW  - palm oil
KW  - Random Forest
KW  - Myanmar
KW  - Google Earth Engine
KW  - rubber
KW  - betel nut
DO  - 10.3390/rs10111693
ER  -
TY  - EJOU
AU  - Bouaddi, Sahar
AU  - Fernández-García, Aránzazu
AU  - Sansom, Chris
AU  - Sarasua, Jon A.
AU  - Wolfertstetter, Fabian
AU  - Bouzekri, Hicham
AU  - Sutter, Florian
AU  - Azpitarte, Itiziar
TI  - A Review of Conventional and Innovative- Sustainable Methods for Cleaning Reflectors in Concentrating Solar Power Plants
T2  - Sustainability

PY  - 2018
VL  - 10
IS  - 11
SN  - 2071-1050

AB  - The severe soiling of reflectors deployed in arid and semi arid locations decreases their reflectance and drives down the yield of the concentrating solar power (CSP) plants. To alleviate this issue, various sets of methods are available. The operation and maintenance (O&amp;M) staff should opt for sustainable cleaning methods that are safe and environmentally friendly. To restore high reflectance, the cleaning vehicles of CSP plants must adapt to the constraints of each technology and to the layout of reflectors in the solar field. Water based methods are currently the most commonly used in CSP plants but they are not sustainable due to water scarcity and high soiling rates. The recovery and reuse of washing water can compensate for these methods and make them a more reasonable option for mediterranean and desert environments. Dry methods, on the other hand, are gaining more attraction as they are more suitable for desert regions. Some of these methods rely on ultrasonic wave or vibration for detaching the dust bonding from the reflectors surface, while other methods, known as preventive methods, focus on reducing the soiling by modifying the reflectors surface and incorporating self cleaning features using special coatings. Since the CSP plants operators aim to achieve the highest profit by minimizing the cost of cleaning while maintaining a high reflectance, optimizing the cleaning parameters and strategies is of great interest. This work presents the conventional water-based methods that are currently used in CSP plants in addition to sustainable alternative methods for dust removal and soiling prevention. Also, the cleaning effectiveness, the environmental impacts and the economic aspects of each technology are discussed.
KW  - sustainable cleaning
KW  - CSP reflectors
KW  - soiling
KW  - dust removal
KW  - mirror washing
DO  - 10.3390/su10113937
ER  -
TY  - EJOU
AU  - Akcay, Ozgun
AU  - Avsar, Emin O.
AU  - Inalpulat, Melis
AU  - Genc, Levent
AU  - Cam, Ahmet
TI  - Assessment of Segmentation Parameters for Object-Based Land Cover Classification Using Color-Infrared Imagery
T2  - ISPRS International Journal of Geo-Information

PY  - 2018
VL  - 7
IS  - 11
SN  - 2220-9964

AB  - Using object-based image analysis (OBIA) techniques for land use-land cover classification (LULC) has become an area of interest due to the availability of high-resolution data and segmentation methods. Multi-resolution segmentation in particular, statistically seen as the most used algorithm, is able to produce non-identical segmentations depending on the required parameters. The total effect of segmentation parameters on the classification accuracy of high-resolution imagery is still an open question, though some studies were implemented to define the optimum segmentation parameters. However, recent studies have not properly considered the parameters and their consequences on LULC accuracy. The main objective of this study is to assess OBIA segmentation and classification accuracy according to the segmentation parameters using different overlap ratios during image object sampling for a predetermined scale. With this aim, we analyzed and compared (a) high-resolution color-infrared aerial images of a newly-developed urban area including different land use types; (b) combinations of multi-resolution segmentation with different shape, color, compactness, bands, and band-weights; and (c) accuracies of classifications based on varied segmentations. The results of various parameters in the study showed an explicit correlation between segmentation accuracies and classification accuracies. The effect of changes in segmentation parameters using different sample selection methods for five main LULC types was studied. Specifically, moderate shape and compactness values provided more consistency than lower and higher values; also, band weighting demonstrated substantial results due to the chosen bands. Differences in the variable importance of the classifications and changes in LULC maps were also explained.
KW  - segmentation
KW  - object-based classification
KW  - orthophoto
KW  - land cover
KW  - high resolution imagery
KW  - infrared
KW  - accuracy
DO  - 10.3390/ijgi7110424
ER  -
TY  - EJOU
AU  - Zhang, Pengbin
AU  - Ke, Yinghai
AU  - Zhang, Zhenxin
AU  - Wang, Mingli
AU  - Li, Peng
AU  - Zhang, Shuangyue
TI  - Urban Land Use and Land Cover Classification Using Novel Deep Learning Models Based on High Spatial Resolution Satellite Imagery
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 11
SN  - 1424-8220

AB  - Urban land cover and land use mapping plays an important role in urban planning and management. In this paper, novel multi-scale deep learning models, namely ASPP-Unet and ResASPP-Unet are proposed for urban land cover classification based on very high resolution (VHR) satellite imagery. The proposed ASPP-Unet model consists of a contracting path which extracts the high-level features, and an expansive path, which up-samples the features to create a high-resolution output. The atrous spatial pyramid pooling (ASPP) technique is utilized in the bottom layer in order to incorporate multi-scale deep features into a discriminative feature. The ResASPP-Unet model further improves the architecture by replacing each layer with residual unit. The models were trained and tested based on WorldView-2 (WV2) and WorldView-3 (WV3) imageries over the city of Beijing. Model parameters including layer depth and the number of initial feature maps (IFMs) as well as the input image bands were evaluated in terms of their impact on the model performances. It is shown that the ResASPP-Unet model with 11 layers and 64 IFMs based on 8-band WV2 imagery produced the highest classification accuracy (87.1% for WV2 imagery and 84.0% for WV3 imagery). The ASPP-Unet model with the same parameter setting produced slightly lower accuracy, with overall accuracy of 85.2% for WV2 imagery and 83.2% for WV3 imagery. Overall, the proposed models outperformed the state-of-the-art models, e.g., U-Net, convolutional neural network (CNN) and Support Vector Machine (SVM) model over both WV2 and WV3 images, and yielded robust and efficient urban land cover classification results.
KW  - urban land cover classification
KW  - high spatial resolution satellite imagery
KW  - deep learning
KW  - U-Net
KW  - CNN
DO  - 10.3390/s18113717
ER  -
TY  - EJOU
AU  - Kuffer, Monika
AU  - Wang, Jiong
AU  - Nagenborg, Michael
AU  - Pfeffer, Karin
AU  - Kohli, Divyani
AU  - Sliuzas, Richard
AU  - Persello, Claudio
TI  - The Scope of Earth-Observation to Improve the Consistency of the SDG Slum Indicator
T2  - ISPRS International Journal of Geo-Information

PY  - 2018
VL  - 7
IS  - 11
SN  - 2220-9964

AB  - The continuous increase in deprived living conditions in many cities of the Global South contradicts efforts to make cities inclusive, safe, resilient, and sustainable places. Using examples of Asian, African, and Latin American cities, this study shows the scope and limits of earth observation (EO)-based mapping of deprived living conditions in support of providing consistent global information for the SDG indicator 11.1.1 “proportion of urban population living in slums, informal settlements or inadequate housing”. At the technical level, we compare several EO-based methods and imagery for mapping deprived living conditions, discussing their ability to map such areas including differences in terms of accuracy and performance at the city scale. At the operational level, we compare available municipal maps showing identified deprived areas with the spatial extent of morphological mapped areas of deprived living conditions (using EO) at the city scale, discussing the reasons for inconsistencies between municipal and EO-based maps. We provide an outlook on how EO-based mapping of deprived living conditions could contribute to a global spatial information base to support targeting of deprived living conditions in support of the SDG Goal 11.1.1 indicator, when uncertainties and ethical considerations on data provision are well addressed.
KW  - deprived living conditions
KW  - slum
KW  - informal settlement
KW  - inadequate housing
KW  - Sustainable Development Goals (SDGs)
KW  - remote sensing
KW  - global urban data
KW  - uncertainties
KW  - geo-ethics
DO  - 10.3390/ijgi7110428
ER  -
TY  - EJOU
AU  - Yuan, Wenan
AU  - Li, Jiating
AU  - Bhatta, Madhav
AU  - Shi, Yeyin
AU  - Baenziger, P. S.
AU  - Ge, Yufeng
TI  - Wheat Height Estimation Using LiDAR in Comparison to Ultrasonic Sensor and UAS
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 11
SN  - 1424-8220

AB  - As one of the key crop traits, plant height is traditionally evaluated manually, which can be slow, laborious and prone to error. Rapid development of remote and proximal sensing technologies in recent years allows plant height to be estimated in more objective and efficient fashions, while research regarding direct comparisons between different height measurement methods seems to be lagging. In this study, a ground-based multi-sensor phenotyping system equipped with ultrasonic sensors and light detection and ranging (LiDAR) was developed. Canopy heights of 100 wheat plots were estimated five times during a season by the ground phenotyping system and an unmanned aircraft system (UAS), and the results were compared to manual measurements. Overall, LiDAR provided the best results, with a root-mean-square error (RMSE) of 0.05 m and an R2 of 0.97. UAS obtained reasonable results with an RMSE of 0.09 m and an R2 of 0.91. Ultrasonic sensors did not perform well due to our static measurement style. In conclusion, we suggest LiDAR and UAS are reliable alternative methods for wheat height evaluation.
KW  - crop
KW  - plant breeding
KW  - phenotyping
KW  - proximal sensing
KW  - remote sensing
DO  - 10.3390/s18113731
ER  -
TY  - EJOU
AU  - Valentino, Rico
AU  - Jung, Woo-Sung
AU  - Ko, Young-Bae
TI  - A Design and Simulation of the Opportunistic Computation Offloading with Learning-Based Prediction for Unmanned Aerial Vehicle (UAV) Clustering Networks
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 11
SN  - 1424-8220

AB  - Drones have recently become extremely popular, especially in military and civilian applications. Examples of drone utilization include reconnaissance, surveillance, and packet delivery. As time has passed, drones’ tasks have become larger and more complex. As a result, swarms or clusters of drones are preferred, because they offer more coverage, flexibility, and reliability. However, drone systems have limited computing power and energy resources, which means that sometimes it is difficult for drones to finish their tasks on schedule. A solution to this is required so that drone clusters can complete their work faster. One possible solution is an offloading scheme between drone clusters. In this study, we propose an opportunistic computational offloading system, which allows for a drone cluster with a high intensity task to borrow computing resources opportunistically from other nearby drone clusters. We design an artificial neural network-based response time prediction module for deciding whether it is faster to finish tasks by offloading them to other drone clusters. The offloading scheme is conducted only if the predicted offloading response time is smaller than the local computing time. Through simulation results, we show that our proposed scheme can decrease the response time of drone clusters through an opportunistic offloading process.
KW  - drone cluster
KW  - computation offloading
KW  - neural network
KW  - wireless communication
DO  - 10.3390/s18113751
ER  -
TY  - EJOU
AU  - Cui, Jun-hui
AU  - Wei, Rui-xuan
AU  - Liu, Zong-cheng
AU  - Zhou, Kai
TI  - UAV Motion Strategies in Uncertain Dynamic Environments: A Path Planning Method Based on Q-Learning Strategy
T2  - Applied Sciences

PY  - 2018
VL  - 8
IS  - 11
SN  - 2076-3417

AB  - A solution framework for UAV motion strategies in uncertain dynamic environments is constructed in this paper. Considering that the motion states of UAV might be influenced by some dynamic uncertainties, such as control strategies, flight environments, and any other bursting-out threats, we model the uncertain factors that might cause such influences to the path planning of the UAV, unified as an unobservable part of the system and take the acceleration together with the bank angle of the UAV as a control variable. Meanwhile, the cost function is chosen based on the tracking error, then the control instructions and flight path for UAV can be achieved. Then, the cost function can be optimized through Q-learning, and the best UAV action sequence for conflict avoidance under the moving threat environment can be obtained. According to Bellman&rsquo;s optimization principle, the optimal action strategies can be obtained from the current confidence level. The method in this paper is more in line with the actual UAV path planning, since the generation of the path planning strategy at each moment takes into account the influence of the UAV control strategy on its motion at the next moment. The simulation results show that all the planning paths that are created according to the solution framework proposed in this paper have a very high tracking accuracy, and this method has a much shorter processing time as well as a shorter path it can create.
KW  - unmanned aerial vehicle
KW  - path planning
KW  - Q-Learning strategy
KW  - observational error
DO  - 10.3390/app8112169
ER  -
TY  - EJOU
AU  - Tsiropoulou, Eirini E.
AU  - Kousis, George
AU  - Thanou, Athina
AU  - Lykourentzou, Ioanna
AU  - Papavassiliou, Symeon
TI  - Quality of Experience in Cyber-Physical Social Systems Based on Reinforcement Learning and Game Theory
T2  - Future Internet

PY  - 2018
VL  - 10
IS  - 11
SN  - 1999-5903

AB  - This paper addresses the problem of museum visitors&rsquo; Quality of Experience (QoE) optimization by viewing and treating the museum environment as a cyber-physical social system. To achieve this goal, we harness visitors&rsquo; internal ability to intelligently sense their environment and make choices that improve their QoE in terms of which the museum touring option is the best for them and how much time to spend on their visit. We model the museum setting as a distributed non-cooperative game where visitors selfishly maximize their own QoE. In this setting, we formulate the problem of Recommendation Selection and Visiting Time Management (RSVTM) and propose a two-stage distributed algorithm based on game theory and reinforcement learning, which learns from visitor behavior to make on-the-fly recommendation selections that maximize visitor QoE. The proposed framework enables autonomic visitor-centric management in a personalized manner and enables visitors themselves to decide on the best visiting strategies. Experimental results evaluating the performance of the proposed RSVTM algorithm under realistic simulation conditions indicate the high operational effectiveness and superior performance when compared to other recommendation approaches. Our results constitute a practical alternative for museums and exhibition spaces meant to enhance visitor QoE in a flexible, efficient, and cost-effective manner.
KW  - quality of experience
KW  - congestion
KW  - reinforcement learning
KW  - time management
KW  - game theory
KW  - personalization and recommendation
DO  - 10.3390/fi10110108
ER  -
TY  - EJOU
AU  - Hashemi-Beni, Leila
AU  - Jones, Jeffery
AU  - Thompson, Gary
AU  - Johnson, Curt
AU  - Gebrehiwot, Asmamaw
TI  - Challenges and Opportunities for UAV-Based Digital Elevation Model Generation for Flood-Risk Management: A Case of Princeville, North Carolina
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 11
SN  - 1424-8220

AB  - Among the different types of natural disasters, floods are the most devastating, widespread, and frequent. Floods account for approximately 30% of the total loss caused by natural disasters. Accurate flood-risk mapping is critical in reducing such damages by correctly predicting the extent of a flood when coupled with rain and stage gage data, supporting emergency-response planning, developing land use plans and regulations with regard to the construction of structures and infrastructures, and providing damage assessment in both spatial and temporal measurements. The reliability and accuracy of such flood assessment maps is dependent on the quality of the digital elevation model (DEM) in flood conditions. This study investigates the quality of an Unmanned Aerial Vehicle (UAV)-based DEM for spatial flood assessment mapping and evaluating the extent of a flood event in Princeville, North Carolina during Hurricane Matthew. The challenges and problems of on-demand DEM production during a flooding event were discussed. An accuracy analysis was performed by comparing the water surface extracted from the UAV-derived DEM with the water surface/stage obtained using the nearby US Geologic Survey (USGS) stream gauge station and LiDAR data.
KW  - UAV
KW  - 3D flood mapping
KW  - remote sensing
KW  - digital elevation model
KW  - 3D modeling
DO  - 10.3390/s18113843
ER  -
TY  - EJOU
AU  - Zisi, Theodota
AU  - Alexandridis, Thomas K.
AU  - Kaplanis, Spyridon
AU  - Navrozidis, Ioannis
AU  - Tamouridou, Afroditi-Alexandra
AU  - Lagopodi, Anastasia
AU  - Moshou, Dimitrios
AU  - Polychronos, Vasilios
TI  - Incorporating Surface Elevation Information in UAV Multispectral Images for Mapping Weed Patches
T2  - Journal of Imaging

PY  - 2018
VL  - 4
IS  - 11
SN  - 2313-433X

AB  - Accurate mapping of weed distribution within a field is a first step towards effective weed management. The aim of this work was to improve the mapping of milk thistle (Silybum marianum) weed patches through unmanned aerial vehicle (UAV) images using auxiliary layers of information, such as spatial texture and estimated vegetation height from the UAV digital surface model. UAV multispectral images acquired in the visible and near-infrared parts of the spectrum were used as the main source of data, together with texture that was estimated for the image bands using a local variance filter. The digital surface model was created from structure from motion algorithms using the UAV image stereopairs. From this layer, the terrain elevation was estimated using a focal minimum filter followed by a low-pass filter. The plant height was computed by subtracting the terrain elevation from the digital surface model. Three classification algorithms (maximum likelihood, minimum distance and an object-based image classifier) were used to identify S. marianum from other vegetation using various combinations of inputs: image bands, texture and plant height. The resulting weed distribution maps were evaluated for their accuracy using field-surveyed data. Both texture and plant height have helped improve the accuracy of classification of S. marianum weed, increasing the overall accuracy of classification from 70% to 87% in 2015, and from 82% to 95% in 2016. Thus, as texture is easier to compute than plant height from a digital surface model, it may be preferable to be used in future weed mapping applications.
KW  - milk thistle
KW  - precision farming
KW  - digital surface model
KW  - plant height
KW  - texture
KW  - Sf structure from motion
DO  - 10.3390/jimaging4110132
ER  -
TY  - EJOU
AU  - Zhou, Zhenjin
AU  - Ma, Lei
AU  - Fu, Tengyu
AU  - Zhang, Ge
AU  - Yao, Mengru
AU  - Li, Manchun
TI  - Change Detection in Coral Reef Environment Using High-Resolution Images: Comparison of Object-Based and Pixel-Based Paradigms
T2  - ISPRS International Journal of Geo-Information

PY  - 2018
VL  - 7
IS  - 11
SN  - 2220-9964

AB  - Despite increases in the spatial resolution of satellite imagery prompting interest in object-based image analysis, few studies have used object-based methods for monitoring changes in coral reefs. This study proposes a high accuracy object-based change detection (OBCD) method intended for coral reef environment, which uses QuickBird and WorldView-2 images. The proposed methodological framework includes image fusion, multi-temporal image segmentation, image differencing, random forests models, and object-area-based accuracy assessment. For validation, we applied the method to images of four coral reef study sites in the South China Sea. We compared the proposed OBCD method with a conventional pixel-based change detection (PBCD) method by implementing both methods under the same conditions. The average overall accuracy of OBCD exceeded 90%, which was approximately 20% higher than PBCD. The OBCD method was free from salt-and-pepper effects and was less prone to images misregistration in terms of change detection accuracy and mapping results. The object-area-based accuracy assessment reached a higher overall accuracy and per-class accuracy than the object-number-based and pixel-number-based accuracy assessment.
KW  - coral reef
KW  - change detection
KW  - very high resolution
KW  - object-based method
KW  - random forests
DO  - 10.3390/ijgi7110441
ER  -
TY  - EJOU
AU  - Wu, Zhe
AU  - Zhang, Qiang
AU  - Wang, Lixin
AU  - Cheng, Lifeng
AU  - Zhou, Jingbo
TI  - Early Fault Detection Method for Rotating Machinery Based on Harmonic-Assisted Multivariate Empirical Mode Decomposition and Transfer Entropy
T2  - Entropy

PY  - 2018
VL  - 20
IS  - 11
SN  - 1099-4300

AB  - It is a difficult task to analyze the coupling characteristics of rotating machinery fault signals under the influence of complex and nonlinear interference signals. This difficulty is due to the strong noise background of rotating machinery fault feature extraction and weaknesses, such as modal mixing problems, in the existing Ensemble Empirical Mode Decomposition (EEMD) time&ndash;frequency analysis methods. To quantitatively study the nonlinear synchronous coupling characteristics and information transfer characteristics of rotating machinery fault signals between different frequency scales under the influence of complex and nonlinear interference signals, a new nonlinear signal processing method&mdash;the harmonic assisted multivariate empirical mode decomposition method (HA-MEMD)&mdash;is proposed in this paper. By adding additional high-frequency harmonic-assisted channels and reducing them, the decomposing precision of the Intrinsic Mode Function (IMF) can be effectively improved, and the phenomenon of mode aliasing can be mitigated. Analysis results of the simulated signals prove the effectiveness of this method. By combining HA-MEMD with the transfer entropy algorithm and introducing signal processing of the rotating machinery, a fault detection method of rotating machinery based on high-frequency harmonic-assisted multivariate empirical mode decomposition-transfer entropy (HA-MEMD-TE) was established. The main features of the mechanical transmission system were extracted by the high-frequency harmonic-assisted multivariate empirical mode decomposition method, and the signal, after noise reduction, was used for the transfer entropy calculation. The evaluation index of the rotating machinery state based on HA-MEMD-TE was established to quantitatively describe the degree of nonlinear coupling between signals to effectively evaluate and diagnose the operating state of the mechanical system. By adding noise to different signal-to-noise ratios, the fault detection ability of HA-MEMD-TE method in the background of strong noise is investigated, which proves that the method has strong reliability and robustness. In this paper, transfer entropy is applied to the fault diagnosis field of rotating machinery, which provides a new effective method for early fault diagnosis and performance degradation-state recognition of rotating machinery, and leads to relevant research conclusions.
KW  - HA-MEMD
KW  - rotating machinery
KW  - transfer entropy
KW  - fault diagnosis
DO  - 10.3390/e20110873
ER  -
TY  - EJOU
AU  - Galatas, Athanasios
AU  - Hassanin, Hany
AU  - Zweiri, Yahya
AU  - Seneviratne, Lakmal
TI  - Additive Manufactured Sandwich Composite/ABS Parts for Unmanned Aerial Vehicle Applications
T2  - Polymers

PY  - 2018
VL  - 10
IS  - 11
SN  - 2073-4360

AB  - Fused deposition modelling (FDM) is one of most popular 3D printing techniques of thermoplastic polymers. Nonetheless, the poor mechanical strength of FDM parts restricts the use of this technology in functional parts of many applications such as unmanned aerial vehicles (UAVs) where lightweight, high strength, and stiffness are required. In the present paper, the fabrication process of low-density acrylonitrile butadiene styrenecarbon (ABS) with carbon fibre reinforced polymer (CFRP) sandwich layers for UAV structure is proposed to improve the poor mechanical strength and elastic modulus of printed ABS. The composite sandwich structures retains FDM advantages for rapid making of complex geometries, while only requires simple post-processing steps to improve the mechanical properties. Artificial neural network (ANN) was used to investigate the influence of the core density and number of CFRP layers on the mechanical properties. The results showed an improvement of specific strength and elastic modulus with increasing the number of CFRP. The specific strength of the samples improved from 20 to 145 KN&middot;m/kg while the Young&rsquo;s modulus increased from 0.63 to 10.1 GPa when laminating the samples with CFRP layers. On the other hand, the core density had no significant effect on both specific strength and elastic modulus. A case study was undertaken by applying the CFRP/ABS/CFRP sandwich structure using the proposed method to manufacture improved dual-tilting clamps of a quadcopter UAV.
KW  - FDM
KW  - composite
KW  - sandwich structure
KW  - CFRP
KW  - neural network
KW  - UAV
DO  - 10.3390/polym10111262
ER  -
TY  - EJOU
AU  - Michez, Adrien
AU  - Bauwens, Sébastien
AU  - Brostaux, Yves
AU  - Hiel, Marie-Pierre
AU  - Garré, Sarah
AU  - Lejeune, Philippe
AU  - Dumont, Benjamin
TI  - How Far Can Consumer-Grade UAV RGB Imagery Describe Crop Production? A 3D and Multitemporal Modeling Approach Applied to Zea mays
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 11
SN  - 2072-4292

AB  - In recent decades, remote sensing has increasingly been used to estimate the spatio-temporal evolution of crop biophysical parameters such as the above-ground biomass (AGB). On a local scale, the advent of unmanned aerial vehicles (UAVs) seems to be a promising trade-off between satellite/airborne and terrestrial remote sensing. This study aims to evaluate the potential of a low-cost UAV RGB solution to predict the final AGB of Zea mays. Besides evaluating the interest of 3D data and multitemporality, our study aims to answer operational questions such as when one should plan a combination of two UAV flights for AGB modeling. In this case, study, final AGB prediction model performance reached 0.55 (R-square) using only UAV information and 0.8 (R-square) when combining UAV information from a single flight with a single-field AGB measurement. The adding of UAV height information to the model improves the quality of the AGB prediction. Performing two flights provides almost systematically an improvement in AGB prediction ability in comparison to most single flights. Our study provides clear insight about how we can counter the low spectral resolution of consumer-grade RGB cameras using height information and multitemporality. Our results highlight the importance of the height information which can be derived from UAV data on one hand, and on the other hand, the lower relative importance of RGB spectral information.
KW  - unmanned aerial vehicles
KW  - unmanned aerial systems
KW  - drone
KW  - above-ground biomass
KW  - RGB imagery
KW  - photogrammetry
KW  - Zea mays
DO  - 10.3390/rs10111798
ER  -
TY  - EJOU
AU  - Boonpook, Wuttichai
AU  - Tan, Yumin
AU  - Ye, Yinghua
AU  - Torteeka, Peerapong
AU  - Torsri, Kritanai
AU  - Dong, Shengxian
TI  - A Deep Learning Approach on Building Detection from Unmanned Aerial Vehicle-Based Images in Riverbank Monitoring
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 11
SN  - 1424-8220

AB  - Buildings along riverbanks are likely to be affected by rising water levels, therefore the acquisition of accurate building information has great importance not only for riverbank environmental protection but also for dealing with emergency cases like flooding. UAV-based photographs are flexible and cloud-free compared to satellite images and can provide very high-resolution images up to centimeter level, while there exist great challenges in quickly and accurately detecting and extracting building from UAV images because there are usually too many details and distortions on UAV images. In this paper, a deep learning (DL)-based approach is proposed for more accurately extracting building information, in which the network architecture, SegNet, is used in the semantic segmentation after the network training on a completely labeled UAV image dataset covering multi-dimension urban settlement appearances along a riverbank area in Chongqing. The experiment results show that an excellent performance has been obtained in the detection of buildings from untrained locations with an average overall accuracy more than 90%. To verify the generality and advantage of the proposed method, the procedure is further evaluated by training and testing with another two open standard datasets which have a variety of building patterns and styles, and the final overall accuracies of building extraction are more than 93% and 95%, respectively.
KW  - building extraction
KW  - UAV dataset
KW  - deep learning
KW  - river bank monitoring
DO  - 10.3390/s18113921
ER  -
TY  - EJOU
AU  - Mishra, Niti B.
AU  - Mainali, Kumar P.
AU  - Shrestha, Bharat B.
AU  - Radenz, Jackson
AU  - Karki, Debendra
TI  - Species-Level Vegetation Mapping in a Himalayan Treeline Ecotone Using Unmanned Aerial System (UAS) Imagery
T2  - ISPRS International Journal of Geo-Information

PY  - 2018
VL  - 7
IS  - 11
SN  - 2220-9964

AB  - Understanding ecological patterns and response to climate change requires unbiased data on species distribution. This can be challenging, especially in biodiverse but extreme environments like the Himalaya. This study presents the results of the first ever application of Unmanned Aerial Systems (UAS) imagery for species-level mapping of vegetation in the Himalaya following a hierarchical Geographic Object Based Image Analysis (GEOBIA) method. The first level of classification separated green vegetated objects from the rest with overall accuracy of 95%. At the second level, seven cover types were identified (including four woody vegetation species). For this, the suitability of various spectral, shape and textural features were tested for classifying them using an ensemble decision tree algorithm. Spectral features alone yielded ~70% accuracy (kappa 0.66) whereas adding textural and shape features marginally improved the accuracy (73%) but at the cost of a substantial increase in processing time. Contrast in plant morphological traits was the key to distinguishing nearby stands as different species. Hence, broad-leaved versus fine needle leaved vegetation were mapped more accurately than structurally similar classes such as Rhododendron anthopogon versus non-photosynthetic vegetation. Results highlight the potential and limitations of the suggested UAS-GEOBIA approach for detailed mapping of plant communities and suggests future research directions.
KW  - species mapping
KW  - Unmanned Aerial Systems
KW  - hierarchical GEOBIA
KW  - Himalaya
KW  - treeline ecotone
KW  - random forest
KW  - Langtang National Park
DO  - 10.3390/ijgi7110445
ER  -
TY  - EJOU
AU  - Zhang, Yihong
AU  - Yang, Yijin
AU  - Zhou, Wuneng
AU  - Shi, Lifeng
AU  - Li, Demin
TI  - Motion-Aware Correlation Filters for Online Visual Tracking
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 11
SN  - 1424-8220

AB  - The discriminative correlation filters-based methods struggle deal with the problem of fast motion and heavy occlusion, the problem can severely degrade the performance of trackers, ultimately leading to tracking failures. In this paper, a novel Motion-Aware Correlation Filters (MACF) framework is proposed for online visual object tracking, where a motion-aware strategy based on joint instantaneous motion estimation Kalman filters is integrated into the Discriminative Correlation Filters (DCFs). The proposed motion-aware strategy is used to predict the possible region and scale of the target in the current frame by utilizing the previous estimated 3D motion information. Obviously, this strategy can prevent model drift caused by fast motion. On the base of the predicted region and scale, the MACF detects the position and scale of the target by using the DCFs-based method in the current frame. Furthermore, an adaptive model updating strategy is proposed to address the problem of corrupted models caused by occlusions, where the learning rate is determined by the confidence of the response map. The extensive experiments on popular Object Tracking Benchmark OTB-100, OTB-50 and unmanned aerial vehicles (UAV) video have demonstrated that the proposed MACF tracker performs better than most of the state-of-the-art trackers and achieves a high real-time performance. In addition, the proposed approach can be integrated easily and flexibly into other visual tracking algorithms.
KW  - visual tracking
KW  - correlation filters
KW  - motion-aware
KW  - adaptive update strategy
KW  - confidence response map
DO  - 10.3390/s18113937
ER  -
TY  - EJOU
AU  - Lagkas, Thomas
AU  - Argyriou, Vasileios
AU  - Bibi, Stamatia
AU  - Sarigiannidis, Panagiotis
TI  - UAV IoT Framework Views and Challenges: Towards Protecting Drones as “Things”
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 11
SN  - 1424-8220

AB  - Unmanned aerial vehicles (UAVs) have enormous potential in enabling new applications in various areas, ranging from military, security, medicine, and surveillance to traffic-monitoring applications. Lately, there has been heavy investment in the development of UAVs and multi-UAVs systems that can collaborate and complete missions more efficiently and economically. Emerging technologies such as 4G/5G networks have significant potential on UAVs equipped with cameras, sensors, and GPS receivers in delivering Internet of Things (IoT) services from great heights, creating an airborne domain of the IoT. However, there are many issues to be resolved before the effective use of UAVs can be made, including security, privacy, and management. As such, in this paper we review new UAV application areas enabled by the IoT and 5G technologies, analyze the sensor requirements, and overview solutions for fleet management over aerial-networking, privacy, and security challenges. Finally, we propose a framework that supports and enables these technologies on UAVs. The introduced framework provisions a holistic IoT architecture that enables the protection of UAVs as “flying” things in a collaborative networked environment.
KW  - security
KW  - privacy
KW  - drones
KW  - IoT
KW  - UAV
DO  - 10.3390/s18114015
ER  -
TY  - EJOU
AU  - Csillik, Ovidiu
AU  - Cherbini, John
AU  - Johnson, Robert
AU  - Lyons, Andy
AU  - Kelly, Maggi
TI  - Identification of Citrus Trees from Unmanned Aerial Vehicle Imagery Using Convolutional Neural Networks
T2  - Drones

PY  - 2018
VL  - 2
IS  - 4
SN  - 2504-446X

AB  - Remote sensing is important to precision agriculture and the spatial resolution provided by Unmanned Aerial Vehicles (UAVs) is revolutionizing precision agriculture workflows for measurement crop condition and yields over the growing season, for identifying and monitoring weeds and other applications. Monitoring of individual trees for growth, fruit production and pest and disease occurrence remains a high research priority and the delineation of each tree using automated means as an alternative to manual delineation would be useful for long-term farm management. In this paper, we detected citrus and other crop trees from UAV images using a simple convolutional neural network (CNN) algorithm, followed by a classification refinement using superpixels derived from a Simple Linear Iterative Clustering (SLIC) algorithm. The workflow performed well in a relatively complex agricultural environment (multiple targets, multiple size trees and ages, etc.) achieving high accuracy (overall accuracy = 96.24%, Precision (positive predictive value) = 94.59%, Recall (sensitivity) = 97.94%). To our knowledge, this is the first time a CNN has been used with UAV multi-spectral imagery to focus on citrus trees. More of these individual cases are needed to develop standard automated workflows to help agricultural managers better incorporate large volumes of high resolution UAV imagery into agricultural management operations.
KW  - CNN
KW  - deep learning
KW  - superpixels
KW  - precision agriculture
KW  - UAS
KW  - feature extraction
KW  - citrus
KW  - tree identification
DO  - 10.3390/drones2040039
ER  -
TY  - EJOU
AU  - White, Raechel A.
AU  - Bomber, Michael
AU  - Hupy, Joseph P.
AU  - Shortridge, Ashton
TI  - UAS-GEOBIA Approach to Sapling Identification in Jack Pine Barrens after Fire
T2  - Drones

PY  - 2018
VL  - 2
IS  - 4
SN  - 2504-446X

AB  - Jack pine (pinus banksiana) forests are unique ecosystems controlled by wildfire. Understanding the traits of revegetation after wildfire is important for sustainable forest management, as these forests not only provide economic resources, but also are home to specialized species, like the Kirtland Warbler (Setophaga kirtlandii). Individual tree detection of jack pine saplings after fire events can provide information about an environment&rsquo;s recovery. Traditional satellite and manned aerial sensors lack the flexibility and spatial resolution required for identifying saplings in early post-fire analysis. Here we evaluated the use of unmanned aerial systems and geographic object-based image analysis for jack pine sapling identification in a region burned during the 2012 Duck Lake Fire in the Upper Peninsula of Michigan. Results of this study indicate that sapling identification accuracies can top 90%, and that accuracy improves with the inclusion of red and near infrared spectral bands. Results also indicated that late season imagery performed best when discriminating between young (&lt;5 years) jack pines and herbaceous ground cover in these environments.
KW  - UAV
KW  - jack pine
KW  - succession
KW  - forest disturbance
KW  - fire
DO  - 10.3390/drones2040040
ER  -
TY  - EJOU
AU  - Rahman, Muhammad M.
AU  - Robson, Andrew
AU  - Bristow, Mila
TI  - Exploring the Potential of High Resolution WorldView-3 Imagery for Estimating Yield of Mango
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - Pre-harvest yield estimation of mango fruit is important for the optimization of inputs and other resources on the farm. Current industry practice of visual counting the fruit on a small number of trees for yield forecasting can be highly inaccurate due to the spatial variability, especially if the trees selected do not represent the entire crop. Therefore, this study evaluated the potential of high resolution WorldView-3 (WV3) satellite imagery to estimate yield of mango by integrating both geometric (tree crown area) and optical (spectral vegetation indices) data using artificial neural network (ANN) model. WV3 images were acquired in 2016&ndash;2017 and 2017&ndash;2018 growing seasons at the early fruit stage from three orchards in Acacia Hills region, Northern Territory, Australia. Stratified sampling technique (SST) was applied to select 18 trees from each orchard and subsequently ground truthed for yield (kg&middot;tree&minus;1) and fruit number per tree. For each sampled tree, spectral reflectance data and tree crown area (TCA) was extracted from WV3 imagery. The TCA was identified as the most important predictor of both fruit yield (kg&middot;tree&minus;1) and fruit number, followed by NDVI red-edge band when all trees from three orchards in two growing seasons were combined. The results of all sampled trees from three orchards in two growing seasons using ANN model produced a strong correlation (R2 = 0.70 and 0.68 for total fruit yield (kg&middot;tree&minus;1) and fruit number respectively), which suggest that the model can be obtained to predict yield on a regional level. On orchard level also the ANN model produced a high correlation when both growing seasons were combined. However, the model developed in one season could not be applied in another season due to the influence of seasonal variation and canopy condition. Using the relationship derived from the measured yield parameters against combined VIs and TCA data, the total fruit yield (t&middot;ha&minus;1) and fruit number were estimated for each orchard, produced 7% under estimation to less than 1% over estimation. The accuracy of the findings showed the potential of WV3 imagery to better predict the yield parameters than the current practice across the mango industry as well as to quantify lost yield as a result of delayed harvest.
KW  - WorldView-3 (WV3)
KW  - Mango (Mangifera indica)
KW  - tree crown area
KW  - yield prediction
DO  - 10.3390/rs10121866
ER  -
TY  - EJOU
AU  - Han, Xiongzhe
AU  - Thomasson, J. Alex
AU  - Bagnall, G. Cody
AU  - Pugh, N. Ace
AU  - Horne, David W.
AU  - Rooney, William L.
AU  - Jung, Jinha
AU  - Chang, Anjin
AU  - Malambo, Lonesome
AU  - Popescu, Sorin C.
AU  - Gates, Ian T.
AU  - Cope, Dale A.
TI  - Measurement and Calibration of Plant-Height from Fixed-Wing UAV Images
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 12
SN  - 1424-8220

AB  - Continuing population growth will result in increasing global demand for food and fiber for the foreseeable future. During the growing season, variability in the height of crops provides important information on plant health, growth, and response to environmental effects. This paper indicates the feasibility of using structure from motion (SfM) on images collected from 120 m above ground level (AGL) with a fixed-wing unmanned aerial vehicle (UAV) to estimate sorghum plant height with reasonable accuracy on a relatively large farm field. Correlations between UAV-based estimates and ground truth were strong on all dates (R2 &gt; 0.80) but are clearly better on some dates than others. Furthermore, a new method for improving UAV-based plant height estimates with multi-level ground control points (GCPs) was found to lower the root mean square error (RMSE) by about 20%. These results indicate that GCP-based height calibration has a potential for future application where accuracy is particularly important. Lastly, the image blur appeared to have a significant impact on the accuracy of plant height estimation. A strong correlation (R2 = 0.85) was observed between image quality and plant height RMSE and the influence of wind was a challenge in obtaining high-quality plant height data. A strong relationship (R2 = 0.99) existed between wind speed and image blurriness.
KW  - fixed-wing UAV
KW  - sorghum plant height
KW  - structure from motion
KW  - multi-level GCPs
KW  - GCP-based height calibration
KW  - image blurriness
KW  - wind speed
DO  - 10.3390/s18124092
ER  -
TY  - EJOU
AU  - Aragon, Bruno
AU  - Houborg, Rasmus
AU  - Tu, Kevin
AU  - Fisher, Joshua B.
AU  - McCabe, Matthew
TI  - CubeSats Enable High Spatiotemporal Retrievals of Crop-Water Use for Precision Agriculture
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - Remote sensing based estimation of evapotranspiration (ET) provides a direct accounting of the crop water use. However, the use of satellite data has generally required that a compromise between spatial and temporal resolution is made, i.e., one could obtain low spatial resolution data regularly, or high spatial resolution occasionally. As a consequence, this spatiotemporal trade-off has tended to limit the impact of remote sensing for precision agricultural applications. With the recent emergence of constellations of small CubeSat-based satellite systems, these constraints are rapidly being removed, such that daily 3 m resolution optical data are now a reality for earth observation. Such advances provide an opportunity to develop new earth system monitoring and assessment tools. In this manuscript we evaluate the capacity of CubeSats to advance the estimation of ET via application of the Priestley-Taylor Jet Propulsion Laboratory (PT-JPL) retrieval model. To take advantage of the high-spatiotemporal resolution afforded by these systems, we have integrated a CubeSat derived leaf area index as a forcing variable into PT-JPL, as well as modified key biophysical model parameters. We evaluate model performance over an irrigated farmland in Saudi Arabia using observations from an eddy covariance tower. Crop water use retrievals were also compared against measured irrigation from an in-line flow meter installed within a center-pivot system. To leverage the high spatial resolution of the CubeSat imagery, PT-JPL retrievals were integrated over the source area of the eddy covariance footprint, to allow an equivalent intercomparison. Apart from offering new precision agricultural insights into farm operations and management, the 3 m resolution ET retrievals were shown to explain 86% of the observed variability and provide a relative RMSE of 32.9% for irrigated maize, comparable to previously reported satellite-based retrievals. An observed underestimation was diagnosed as a possible misrepresentation of the local surface moisture status, highlighting the challenge of high-resolution modeling applications for precision agriculture and informing future research directions.
KW  - CubeSats
KW  - evapotranspiration
KW  - PT-JPL
KW  - remote sensing
KW  - Saudi Arabia
KW  - high-resolution
KW  - precision agriculture
DO  - 10.3390/rs10121867
ER  -
TY  - EJOU
AU  - Morales, Giorgio
AU  - Kemper, Guillermo
AU  - Sevillano, Grace
AU  - Arteaga, Daniel
AU  - Ortega, Ivan
AU  - Telles, Joel
TI  - Automatic Segmentation of Mauritia flexuosa in Unmanned Aerial Vehicle (UAV) Imagery Using Deep Learning
T2  - Forests

PY  - 2018
VL  - 9
IS  - 12
SN  - 1999-4907

AB  - One of the most important ecosystems in the Amazon rainforest is the Mauritia flexuosa swamp or “aguajal”. However, deforestation of its dominant species, the Mauritia flexuosa palm, also known as “aguaje”, is a common issue, and conservation is poorly monitored because of the difficult access to these swamps. The contribution of this paper is twofold: the presentation of a dataset called MauFlex, and the proposal of a segmentation and measurement method for areas covered in Mauritia flexuosa palms using high-resolution aerial images acquired by UAVs. The method performs a semantic segmentation of Mauritia flexuosa using an end-to-end trainable Convolutional Neural Network (CNN) based on the Deeplab v3+ architecture. Images were acquired under different environment and light conditions using three different RGB cameras. The MauFlex dataset was created from these images and it consists of 25,248 image patches of     512 × 512     pixels and their respective ground truth masks. The results over the test set achieved an accuracy of 98.143%, specificity of 96.599%, and sensitivity of 95.556%. It is shown that our method is able not only to detect full-grown isolated Mauritia flexuosa palms, but also young palms or palms partially covered by other types of vegetation.
KW  - Mauritia flexuosa
KW  - semantic segmentation
KW  - end-to-end learning
KW  - convolutional neural network
KW  - forest inventory
DO  - 10.3390/f9120736
ER  -
TY  - EJOU
AU  - Sarron, Julien
AU  - Malézieux, Éric
AU  - Sané, Cheikh A.
AU  - Faye, Émile
TI  - Mango Yield Mapping at the Orchard Scale Based on Tree Structure and Land Cover Assessed by UAV
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - In the value chain, yields are key information for both growers and other stakeholders in market supply and exports. However, orchard yields are often still based on an extrapolation of tree production which is visually assessed on a limited number of trees; a tedious and inaccurate task that gives no yield information at a finer scale than the orchard plot. In this work, we propose a method to accurately map individual tree production at the orchard scale by developing a trade-off methodology between mechanistic yield modelling and extensive fruit counting using machine vision systems. A methodological toolbox was developed and tested to estimate and map tree species, structure, and yields in mango orchards of various cropping systems (from monocultivar to plurispecific orchards) in the Niayes region, West Senegal. Tree structure parameters (height, crown area and volume), species, and mango cultivars were measured using unmanned aerial vehicle (UAV) photogrammetry and geographic, object-based image analysis. This procedure reached an average overall accuracy of 0.89 for classifying tree species and mango cultivars. Tree structure parameters combined with a fruit load index, which takes into account year and management effects, were implemented in predictive production models of three mango cultivars. Models reached satisfying accuracies with R2 greater than 0.77 and RMSE% ranging from 20% to 29% when evaluated with the measured production of 60 validation trees. In 2017, this methodology was applied to 15 orchards overflown by UAV, and estimated yields were compared to those measured by the growers for six of them, showing the proper efficiency of our technology. The proposed method achieved the breakthrough of rapidly and precisely mapping mango yields without detecting fruits from ground imagery, but rather, by linking yields with tree structural parameters. Such a tool will provide growers with accurate yield estimations at the orchard scale, and will permit them to study the parameters that drive yield heterogeneity within and between orchards.
KW  - unmanned aerial vehicle
KW  - mango orchard
KW  - yield estimation
KW  - fruit detection
KW  - tree architecture
KW  - random forest
KW  - GEOBIA
KW  - structure-from-motion
DO  - 10.3390/rs10121900
ER  -
TY  - EJOU
AU  - Pádua, Luís
AU  - Marques, Pedro
AU  - Hruška, Jonáš
AU  - Adão, Telmo
AU  - Peres, Emanuel
AU  - Morais, Raul
AU  - Sousa, Joaquim J.
TI  - Multi-Temporal Vineyard Monitoring through UAV-Based RGB Imagery
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - This study aimed to characterize vineyard vegetation thorough multi-temporal monitoring using a commercial low-cost rotary-wing unmanned aerial vehicle (UAV) equipped with a consumer-grade red/green/blue (RGB) sensor. Ground-truth data and UAV-based imagery were acquired on nine distinct dates, covering the most significant vegetative growing cycle until harvesting season, over two selected vineyard plots. The acquired UAV-based imagery underwent photogrammetric processing resulting, per flight, in an orthophoto mosaic, used for vegetation estimation. Digital elevation models were used to compute crop surface models. By filtering vegetation within a given height-range, it was possible to separate grapevine vegetation from other vegetation present in a specific vineyard plot, enabling the estimation of grapevine area and volume. The results showed high accuracy in grapevine detection (94.40%) and low error in grapevine volume estimation (root mean square error of 0.13 m and correlation coefficient of 0.78 for height estimation). The accuracy assessment showed that the proposed method based on UAV-based RGB imagery is effective and has potential to become an operational technique. The proposed method also allows the estimation of grapevine areas that can potentially benefit from canopy management operations.
KW  - unmanned aerial vehicles
KW  - precision viticulture
KW  - multi-temporal analysis
KW  - crop surface models
DO  - 10.3390/rs10121907
ER  -
TY  - EJOU
AU  - Griffith, David C.
AU  - Hay, Geoffrey J.
TI  - Integrating GEOBIA, Machine Learning, and Volunteered Geographic Information to Map Vegetation over Rooftops
T2  - ISPRS International Journal of Geo-Information

PY  - 2018
VL  - 7
IS  - 12
SN  - 2220-9964

AB  - The objective of this study is to evaluate operational methods for creating a particular type of urban vegetation map—one focused on vegetation over rooftops (VOR), specifically trees that extend over urban residential buildings. A key constraint was the use of passive remote sensing data only. To achieve this, we (1) conduct a review of the urban remote sensing vegetation classification literature, and we then (2) discuss methods to derive a detailed map of VOR for a study area in Calgary, Alberta, Canada from a late season, high-resolution airborne orthomosaic based on an integration of Geographic Object-Based Image Analysis (GEOBIA), pre-classification filtering of image-objects using Volunteered Geographic Information (VGI), and a machine learning classifier. Pre-classification filtering lowered the computational burden of classification by reducing the number of input objects by 14%. Accuracy assessment results show that, despite the presence of senescing vegetation with low vegetation index values and deep shadows, classification using a small number of image-object spectral attributes as classification features (n = 9) had similar overall accuracy (88.5%) to a much more complex classification (91.8%) comprising a comprehensive set of spectral, texture, and spatial attributes as classification features (n = 86). This research provides an example of the very specific questions answerable about precise urban locations using a combination of high-resolution passive imagery and freely available VGI data. It highlights the benefits of pre-classification filtering and the judicious selection of features from image-object attributes to reduce processing load without sacrificing classification accuracy.
KW  - GEOBIA
KW  - vegetation over rooftops
KW  - machine learning
DO  - 10.3390/ijgi7120462
ER  -
TY  - EJOU
AU  - Fu, Kun
AU  - Li, Yang
AU  - Sun, Hao
AU  - Yang, Xue
AU  - Xu, Guangluan
AU  - Li, Yuting
AU  - Sun, Xian
TI  - A Ship Rotation Detection Model in Remote Sensing Images Based on Feature Fusion Pyramid Network and Deep Reinforcement Learning
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - Ship detection plays an important role in automatic remote sensing image interpretation. The scale difference, large aspect ratio of ship, complex remote sensing image background and ship dense parking scene make the detection task difficult. To handle the challenging problems above, we propose a ship rotation detection model based on a Feature Fusion Pyramid Network and deep reinforcement learning (FFPN-RL) in this paper. The detection network can efficiently generate the inclined rectangular box for ship. First, we propose the Feature Fusion Pyramid Network (FFPN) that strengthens the reuse of different scales features, and FFPN can extract the low level location and high level semantic information that has an important impact on multi-scale ship detection and precise location of dense parking ships. Second, in order to get accurate ship angle information, we apply deep reinforcement learning to the inclined ship detection task for the first time. In addition, we put forward prior policy guidance and a long-term training method to train an angle prediction agent constructed through a dueling structure Q network, which is able to iteratively and accurately obtain the ship angle. In addition, we design soft rotation non-maximum suppression to reduce the missed ship detection while suppressing the redundant detection boxes. We carry out detailed experiments on the remote sensing ship image dataset, and the experiments validate that our FFPN-RL ship detection model has efficient detection performance.
KW  - ship detection
KW  - deep reinforcement learning
KW  - convolution neural network
KW  - feature map fusion
DO  - 10.3390/rs10121922
ER  -
TY  - EJOU
AU  - Wang, Bing
AU  - Jia, Kun
AU  - Liang, Shunlin
AU  - Xie, Xianhong
AU  - Wei, Xiangqin
AU  - Zhao, Xiang
AU  - Yao, Yunjun
AU  - Zhang, Xiaotong
TI  - Assessment of Sentinel-2 MSI Spectral Band Reflectances for Estimating Fractional Vegetation Cover
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - Fractional vegetation cover (FVC) is an essential parameter for characterizing the land surface vegetation conditions and plays an important role in earth surface process simulations and global change studies. The Sentinel-2 missions carrying multi-spectral instrument (MSI) sensors with 13 multispectral bands are potentially useful for estimating FVC. However, the performance of these bands for FVC estimation is unclear. Therefore, the objective of this study was to assess the performance of Sentinel-2 MSI spectral band reflectances on FVC estimation. The samples, including the Sentinel-2 MSI canopy reflectances and corresponding FVC values, were simulated using the PROSPECT + SAIL radiative transfer model under different conditions, and random forest regression (RFR) method was then used to develop FVC estimation models and assess the performance of various band reflectances for FVC estimation. These models were finally evaluated using field survey data. The results indicate that the three most important bands of Sentinel-2 MSI data for FVC estimation are band 4 (Red), band 12 (SWIR2) and band 8a (NIR2). FVC estimation using these bands has a comparable accuracy (root mean square error (RMSE) = 0.085) with that using all bands (RMSE = 0.090). The results also demonstrate that band 12 had a better performance for FVC estimation than the green band (RMSE = 0.097). However, the newly added red-edge bands, with low scores in the RFR model, have little significance for improving FVC estimation accuracy compared with the Red, NIR2 and SWIR2 bands.
KW  - Sentinel-2 satellites
KW  - fractional vegetation cover
KW  - variable selection
KW  - random forest regression
DO  - 10.3390/rs10121927
ER  -
TY  - EJOU
AU  - Wu, Hao
AU  - Pang, Bo
AU  - Dai, Dahai
AU  - Wu, Jiani
AU  - Wang, Xuesong
TI  - Unmanned Aerial Vehicle Recognition Based on Clustering by Fast Search and Find of Density Peaks (CFSFDP) with Polarimetric Decomposition
T2  - Electronics

PY  - 2018
VL  - 7
IS  - 12
SN  - 2079-9292

AB  - Unmanned aerial vehicles (UAV) have become vital targets in civilian and military fields. However, the polarization characteristics are rarely studied. This paper studies the polarization property of UAVs via the fusion of three polarimetric decomposition methods. A novel algorithm is presented to classify and recognize UAVs automatically which includes a clustering method proposed in &ldquo;Science&rdquo;, one of the top journals in academia. Firstly, the selection of the imaging algorithm ensures the quality of the radar images. Secondly, local geometrical structures of UAVs can be extracted based on Pauli, Krogager, and Cameron polarimetric decomposition. Finally, the proposed algorithm with clustering by fast search and find of density peaks (CFSFDP) has been demonstrated to be better than the original methods under the various noise conditions with the fusion of three polarimetric decomposition methods.
KW  - unmanned aerial vehicle
KW  - clustering methods
KW  - man-made targets
KW  - synthetic aperture radar (SAR)
KW  - inverse synthetic aperture radar (ISAR)
KW  - polarimetric decomposition
DO  - 10.3390/electronics7120364
ER  -
TY  - EJOU
AU  - Liu, Mingyue
AU  - Mao, Dehua
AU  - Wang, Zongming
AU  - Li, Lin
AU  - Man, Weidong
AU  - Jia, Mingming
AU  - Ren, Chunying
AU  - Zhang, Yuanzhi
TI  - Rapid Invasion of Spartina alterniflora in the Coastal Zone of Mainland China: New Observations from Landsat OLI Images
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - Plant invasion imposes significant threats to biodiversity and ecosystem function. Thus, monitoring the spatial pattern of invasive plants is vital for effective ecosystem management. Spartina alterniflora (S. alterniflora) has been one of the most prevalent invasive plants along the China coast, and its spread has had severe ecological consequences. Here, we provide new observation from Landsat operational land imager (OLI) images. Specifically, 43 Landsat-8 OLI images from 2014 to 2016, a combination of object-based image analysis (OBIA) and support vector machine (SVM) methods, and field surveys covering the whole coast were used to construct an up-to-date dataset for 2015 and investigate the spatial variability of S. alterniflora in the coastal zone of mainland China. The classification results achieved good estimation, with a kappa coefficient of 0.86 and 96% overall accuracy. Our results revealed that there was approximately 545.80 km2 of S. alterniflora distributed in the coastal zone of mainland China in 2015, from Hebei to Guangxi provinces. Nearly 92% of the total area of S. alterniflora was distributed within four provinces: Jiangsu, Shanghai, Zhejiang, and Fujian. Seven national nature reserves invaded by S. alterniflora encompassed approximately one-third (174.35 km2) of the total area of S. alterniflora over mainland China. The Yancheng National Nature Reserve exhibited the largest area of S. alterniflora (115.62 km2) among the reserves. Given the rapid and extensive expansion of S. alterniflora in the 40 years since its introduction and its various ecological effects, geospatially varied responding decisions are needed to promote sustainable coastal ecosystems.
KW  - invasive plants
KW  - Spartina alterniflora
KW  - CAS S. alterniflora
KW  - object-based image analysis
KW  - Landsat OLI
DO  - 10.3390/rs10121933
ER  -
TY  - EJOU
AU  - Castillejo-González, Isabel L.
TI  - Mapping of Olive Trees Using Pansharpened QuickBird Images: An Evaluation of Pixel- and Object-Based Analyses
T2  - Agronomy

PY  - 2018
VL  - 8
IS  - 12
SN  - 2073-4395

AB  - This study sought to verify whether remote sensing offers the ability to efficiently delineate olive tree canopies using QuickBird (QB) satellite imagery. This paper compares four classification algorithms performed in pixel- and object-based analyses. To increase the spectral and spatial resolution of the standard QB image, three different pansharpened images were obtained based on variations in the weight of the red and near infrared bands. The results showed slight differences between classifiers. Maximum Likelihood algorithm yielded the highest results in pixel-based classifications with an average overall accuracy (OA) of 94.2%. In object-based analyses, Maximum Likelihood and Decision Tree classifiers offered the highest precisions with average OA of 95.3% and 96.6%, respectively. Between pixel- and object-based analyses no clear difference was observed, showing an increase of average OA values of approximately 1% for all classifiers except Decision Tree, which improved up to 4.5%. The alteration of the weight of different bands in the pansharpen process exhibited satisfactory results with a general performance improvement of up to 9% and 11% in pixel- and object-based analyses, respectively. Thus, object-based analyses with the DT algorithm and the pansharpened imagery with the near-infrared band altered would be highly recommended to obtain accurate maps for site-specific management.
KW  - Á Trous algorithm
KW  - conservation agriculture
KW  - crop inventory
KW  - remote sensing
KW  - spectral-weight variations in fused images
DO  - 10.3390/agronomy8120288
ER  -
TY  - EJOU
AU  - Wan Mohd Jaafar, Wan S.
AU  - Woodhouse, Iain H.
AU  - Silva, Carlos A.
AU  - Omar, Hamdan
AU  - Abdul Maulud, Khairul N.
AU  - Hudak, Andrew T.
AU  - Klauberg, Carine
AU  - Cardil, Adrián
AU  - Mohan, Midhun
TI  - Improving Individual Tree Crown Delineation and Attributes Estimation of Tropical Forests Using Airborne LiDAR Data
T2  - Forests

PY  - 2018
VL  - 9
IS  - 12
SN  - 1999-4907

AB  - Individual tree crown (ITC) segmentation is an approach to isolate individual tree from the background vegetation and delineate precisely the crown boundaries for forest management and inventory purposes. ITC detection and delineation have been commonly generated from canopy height model (CHM) derived from light detection and ranging (LiDAR) data. Existing ITC segmentation methods, however, are limited in their efficiency for characterizing closed canopies, especially in tropical forests, due to the overlapping structure and irregular shape of tree crowns. Furthermore, the potential of 3-dimensional (3D) LiDAR data is not fully realized by existing CHM-based methods. Thus, the aim of this study was to develop an efficient framework for ITC segmentation in tropical forests using LiDAR-derived CHM and 3D point cloud data in order to accurately estimate tree attributes such as the tree height, mean crown width and aboveground biomass (AGB). The proposed framework entails five major steps: (1) automatically identifying dominant tree crowns by implementing semi-variogram statistics and morphological analysis; (2) generating initial tree segments using a watershed algorithm based on mathematical morphology; (3) identifying &ldquo;problematic&rdquo; segments based on predetermined set of rules; (4) tuning the problematic segments using a modified distance-based algorithm (DBA); and (5) segmenting and counting the number of individual trees based on the 3D LiDAR point clouds within each of the identified segment. This approach was developed in a way such that the 3D LiDAR points were only examined on problematic segments identified for further evaluations. 209 reference trees with diameter at breast height (DBH) &ge; 10 cm were selected in the field in two study areas in order to validate ITC detection and delineation results of the proposed framework. We computed tree crown metrics (e.g., maximum crown height and mean crown width) to estimate aboveground biomass (AGB) at tree level using previously published allometric equations. Accuracy assessment was performed to calculate percentage of correctly detected trees, omission and commission errors. Our method correctly identified individual tree crowns with detection accuracy exceeding 80 percent at both forest sites. Also, our results showed high agreement (R2 &gt; 0.64) in terms of AGB estimates using 3D LiDAR metrics and variables measured in the field, for both sites. The findings from our study demonstrate the efficacy of the proposed framework in delineating tree crowns, even in high canopy density areas such as tropical rainforests, where, usually the traditional algorithms are limited in their performances. Moreover, the high tree delineation accuracy in the two study areas emphasizes the potential robustness and transferability of our approach to other densely forested areas across the globe.
KW  - tropical forest
KW  - individual tree crown (ITC)
KW  - LiDAR
KW  - 3D LiDAR point cloud
KW  - canopy height model (CHM)
KW  - mathematical morphology
KW  - watershed
KW  - aboveground biomass (AGB)
DO  - 10.3390/f9120759
ER  -
TY  - EJOU
AU  - Levitan, Nathaniel
AU  - Gross, Barry
TI  - Utilizing Collocated Crop Growth Model Simulations to Train Agronomic Satellite Retrieval Algorithms
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - Due to its worldwide coverage and high revisit time, satellite-based remote sensing provides the ability to monitor in-season crop state variables and yields globally. In this study, we presented a novel approach to training agronomic satellite retrieval algorithms by utilizing collocated crop growth model simulations and solar-reflective satellite measurements. Specifically, we showed that bidirectional long short-term memory networks (BLSTMs) can be trained to predict the in-season state variables and yields of Agricultural Production Systems sIMulator (APSIM) maize crop growth model simulations from collocated Moderate Resolution Imaging Spectroradiometer (MODIS) 500-m satellite measurements over the United States Corn Belt at a regional scale. We evaluated the performance of the BLSTMs through both k-fold cross validation and comparison to regional scale ground-truth yields and phenology. Using k-fold cross validation, we showed that three distinct in-season maize state variables (leaf area index, aboveground biomass, and specific leaf area) can be retrieved with cross-validated R2 values ranging from 0.4 to 0.8 for significant portions of the season. Several other plant, soil, and phenological in-season state variables were also evaluated in the study for their retrievability via k-fold cross validation. In addition, by comparing to survey-based United State Department of Agriculture (USDA) ground truth data, we showed that the BLSTMs are able to predict actual county-level yields with R2 values between 0.45 and 0.6 and actual state-level phenological dates (emergence, silking, and maturity) with R2 values between 0.75 and 0.85. We believe that a potential application of this methodology is to develop satellite products to monitor in-season field-scale crop growth on a global scale by reproducing the methodology with field-scale crop growth model simulations (utilizing farmer-recorded field-scale agromanagement data) and collocated high-resolution satellite data (fused with moderate-resolution satellite data).
KW  - crop growth models
KW  - MODIS
KW  - BLSTMs
DO  - 10.3390/rs10121968
ER  -
TY  - EJOU
AU  - Chen, Chien-Ying
AU  - Hasan, Monowar
AU  - Mohan, Sibin
TI  - Securing Real-Time Internet-of-Things
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 12
SN  - 1424-8220

AB  - Modern embedded and cyber-physical systems are ubiquitous. Many critical cyber-physical systems have real-time requirements (e.g., avionics, automobiles, power grids, manufacturing systems, industrial control systems, etc.). Recent developments and new functionality require real-time embedded devices to be connected to the Internet. This gives rise to the real-time Internet-of-things (RT-IoT) that promises a better user experience through stronger connectivity and efficient use of next-generation embedded devices. However, RT-IoT are also increasingly becoming targets for cyber-attacks, which is exacerbated by this increased connectivity. This paper gives an introduction to RT-IoT systems, an outlook of current approaches and possible research challenges towards secure RT-IoT frameworks.
KW  - security
KW  - real-time systems
KW  - Internet-of-things
KW  - survey
DO  - 10.3390/s18124356
ER  -
TY  - EJOU
AU  - Lou, Yidong
AU  - Zhang, Tian
AU  - Tang, Jian
AU  - Song, Weiwei
AU  - Zhang, Yi
AU  - Chen, Liang
TI  - A Fast Algorithm for Rail Extraction Using Mobile Laser Scanning Data
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - Railroads companies conduct regular inspections of their tracks to maintain and update the geographic data for railway management. Traditional railroad inspection methods, such as onsite inspections and semi-automated analysis of imagery and video data, are time consuming and ineffective. This study presents an automated effective method to detect tracks on the basis of their physical shape, geometrical properties, and reflection intensity feature. This study aims to investigate the feasibility of fast extraction of railroad using onboard Velodyne puck data collected by mobile laser scanning (MLS) system. Results show that the proposed method can be executed rapidly on an i5 computer with at least 10 Hz. The MLS system used in this study comprises a Velodyne puck/onboard GNSS receiver/inertial measurement unit. The range accuracy of Velodyne puck equipment is 2 cm, which fulfills the need of precise mapping. Notably, positioning STD is lower than 4 cm in most areas. Experiments are also undertaken to evaluate the timing of the proposed method. Experimental results indicate that the proposed method can extract 3D tracks in real-time and correctly recognize pairs of tracks. Accuracy, precision, and sensitivity of total test area are 99.68%, 97.55%, and 66.55%, respectively. Results suggest that in a multi-track area, close collaboration between MLS platforms mounted on several trains is required.
KW  - rail road
KW  - scanning lines
KW  - track extraction
KW  - fast recognition
KW  - mobile laser scanning (MLS)
DO  - 10.3390/rs10121998
ER  -
TY  - EJOU
AU  - Tauro, Flavia
AU  - Tosi, Fabio
AU  - Mattoccia, Stefano
AU  - Toth, Elena
AU  - Piscopia, Rodolfo
AU  - Grimaldi, Salvatore
TI  - Optical Tracking Velocimetry (OTV): Leveraging Optical Flow and Trajectory-Based Filtering for Surface Streamflow Observations
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - Nonintrusive image-based methods have the potential to advance hydrological streamflow observations by providing spatially distributed data at high temporal resolution. Due to their simplicity, correlation-based approaches have until recent been preferred to alternative image-based approaches, such as optical flow, for camera-based surface flow velocity estimate. In this work, we introduce a novel optical flow scheme, optical tracking velocimetry (OTV), that entails automated feature detection, tracking through the differential sparse Lucas-Kanade algorithm, and then a posteriori filtering to retain only realistic trajectories that pertain to the transit of actual objects in the field of view. The method requires minimal input on the flow direction and camera orientation. Tested on two image data sets collected in diverse natural conditions, the approach proved suitable for rapid and accurate surface flow velocity estimations. Five different feature detectors were compared and the features from accelerated segment test (FAST) resulted in the best balance between the number of features identified and successfully tracked as well as computational efficiency. OTV was relatively insensitive to reduced image resolution but was impacted by acquisition frequencies lower than 7&ndash;8 Hz. Compared to traditional correlation-based techniques, OTV was less affected by noise and surface seeding. In addition, the scheme is foreseen to be applicable to real-time gauge-cam implementations.
KW  - optical tracking velocimetry (OTV)
KW  - streamflow
KW  - optical flow
KW  - Lucas-Kanade
KW  - FAST
KW  - feature detection
KW  - feature tracking
KW  - particle tracking velocimetry
KW  - large scale particle image velocimetry
KW  - gauge-cam
DO  - 10.3390/rs10122010
ER  -
TY  - EJOU
AU  - Zhang, Yao
AU  - Qin, Qiming
AU  - Ren, Huazhong
AU  - Sun, Yuanheng
AU  - Li, Minzan
AU  - Zhang, Tianyuan
AU  - Ren, Shilong
TI  - Optimal Hyperspectral Characteristics Determination for Winter Wheat Yield Prediction
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - Crop growth in different periods influences the final yield. This study started from the agronomic mechanism of yield formation and aimed to extract useful spectral characteristics in different phenological phases, which could directly describe the final yield and dynamic contributions of different phases to the yield formation. Hyperspectral information of the winter wheat canopy was acquired during three important phases (jointing stage, heading stage, and grain-filling stage). An enhanced 2D correlation spectral analysis method modified by mutual information was proposed to identify the sensitive wavebands. The selected wavebands performed well with good mechanism interpretation and close correlation with important crop growth parameters and main physiological activities related to yield formation. The quantitative contribution proportions of plant growth in three phases to the final yield were estimated by determining the coefficients of partial least square models based on full spectral information. They were then used as single-phase weight factors to merge the selected wavebands. The support vector machine model based on the weighted spectral dataset performed well in yield prediction with satisfactory accuracy and robustness. This result would provide rapid and accurate guidance for agricultural production and would be valuable for the processing of hyperspectral remote sensing data.
KW  - hyperspectral
KW  - winter wheat
KW  - yield
KW  - mutual information
KW  - 2D correlation spectra
DO  - 10.3390/rs10122015
ER  -
TY  - EJOU
AU  - Lu, Chunyan
AU  - Liu, Jinfu
AU  - Jia, Mingming
AU  - Liu, Mingyue
AU  - Man, Weidong
AU  - Fu, Weiwei
AU  - Zhong, Lianxiu
AU  - Lin, Xiaoqing
AU  - Su, Ying
AU  - Gao, Yibin
TI  - Dynamic Analysis of Mangrove Forests Based on an Optimal Segmentation Scale Model and Multi-Seasonal Images in Quanzhou Bay, China
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - Mangrove forests are important coastal ecosystems and are crucial for the equilibrium of the global carbon cycle. Monitoring and mapping of mangrove forests are essential for framing knowledge-based conservation policies and funding decisions by governments and managers. The purpose of this study was to monitor mangrove forest dynamics in the Quanzhou Bay Estuary Wetland Nature Reserve. To achieve this goal, we compared and analyzed the spectral discrimination among mangrove forests, mudflats and Spartina using multi-seasonal Landsat images from 1990, 1997, 2005, 2010, and 2017. We identified the spatio-temporal distribution of mangrove forests by combining an optimal segmentation scale model based on object-oriented classification, decision tree and visual interpretation. In addition, mangrove forest dynamics were determined by combining the annual land change area, centroid migration and overlay analysis. The results showed that there were advantages in the approaches used in this study for monitoring mangrove forests. From 1990 to 2017, the extent of mangrove forests increased by 2.48 km2, which was mostly converted from mudflats and Spartina. Environmental threats including climate change and sea-level rise, aquaculture development and Spartina invasion, pose potential and direct threats to the existence and expansion of mangrove forests. However, the implementation of reforestation projects and Spartina control plays a substantial role in the expansion of mangrove forests. It has been demonstrated that conservation activities can be beneficial for the restoration and succession of mangrove forests. This study provides an example of how the application of an optimal segmentation scale model and multi-seasonal images to mangrove forest monitoring can facilitate government policies that ensure the effective protection of mangrove forests.
KW  - mangrove forests
KW  - object-oriented classification
KW  - optimal segmentation scale model
KW  - multi-seasonal image
KW  - Quanzhou Bay
KW  - remote sensing dynamic monitoring
DO  - 10.3390/rs10122020
ER  -
TY  - EJOU
AU  - Zheng, Hengbiao
AU  - Li, Wei
AU  - Jiang, Jiale
AU  - Liu, Yong
AU  - Cheng, Tao
AU  - Tian, Yongchao
AU  - Zhu, Yan
AU  - Cao, Weixing
AU  - Zhang, Yu
AU  - Yao, Xia
TI  - A Comparative Assessment of Different Modeling Algorithms for Estimating Leaf Nitrogen Content in Winter Wheat Using Multispectral Images from an Unmanned Aerial Vehicle
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - Unmanned aerial vehicle (UAV)-based remote sensing (RS) possesses the significant advantage of being able to efficiently collect images for precision agricultural applications. Although numerous methods have been proposed to monitor crop nitrogen (N) status in recent decades, just how to utilize an appropriate modeling algorithm to estimate crop leaf N content (LNC) remains poorly understood, especially based on UAV multispectral imagery. A comparative assessment of different modeling algorithms (i.e., simple and non-parametric modeling algorithms alongside the physical model retrieval method) for winter wheat LNC estimation is presented in this study. Experiments were conducted over two consecutive years and involved different winter wheat varieties, N rates, and planting densities. A five-band multispectral camera (i.e., 490 nm, 550 nm, 671 nm, 700 nm, and 800 nm) was mounted on a UAV to acquire canopy images across five critical growth stages. The results of this study showed that the best-performing vegetation index (VI) was the modified renormalized difference VI (RDVI), which had a determination coefficient (R2) of 0.73 and a root mean square error (RMSE) of 0.38. This method was also characterized by a high processing speed (0.03 s) for model calibration and validation. Among the 13 non-parametric modeling algorithms evaluated here, the random forest (RF) approach performed best, characterized by R2 and RMSE values of 0.79 and 0.33, respectively. This method also had the advantage of full optical spectrum utilization and enabled flexible, non-linear fitting with a fast processing speed (2.3 s). Compared to the other two methods assessed here, the use of a look up table (LUT)-based radiative transfer model (RTM) remained challenging with regard to LNC estimation because of low prediction accuracy (i.e., an R2 value of 0.62 and an RMSE value of 0.46) and slow processing speed. The RF approach is a fast and accurate technique for N estimation based on UAV multispectral imagery.
KW  - UAV
KW  - multispectral imagery
KW  - LNC
KW  - vegetation index
KW  - non-parametric regression
KW  - radiative transfer model
DO  - 10.3390/rs10122026
ER  -
TY  - EJOU
AU  - Li, Jiaojiao
AU  - Xi, Bobo
AU  - Du, Qian
AU  - Song, Rui
AU  - Li, Yunsong
AU  - Ren, Guangbo
TI  - Deep Kernel Extreme-Learning Machine for the Spectral–Spatial Classification of Hyperspectral Imagery
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - Extreme-learning machines (ELM) have attracted significant attention in hyperspectral image classification due to their extremely fast and simple training structure. However, their shallow architecture may not be capable of further improving classification accuracy. Recently, deep-learning-based algorithms have focused on deep feature extraction. In this paper, a deep neural network-based kernel extreme-learning machine (KELM) is proposed. Furthermore, an excellent spatial guided filter with first-principal component (GFFPC) is also proposed for spatial feature enhancement. Consequently, a new classification framework derived from the deep KELM network and GFFPC is presented to generate deep spectral and spatial features. Experimental results demonstrate that the proposed framework outperforms some state-of-the-art algorithms with very low cost, which can be used for real-time processes.
KW  - hyperspectral classification
KW  - deep layer
KW  - kernel-based ELM
KW  - spectral and spatial features
DO  - 10.3390/rs10122036
ER  -
TY  - EJOU
AU  - Cao, Jingjing
AU  - Liu, Kai
AU  - Liu, Lin
AU  - Zhu, Yuanhui
AU  - Li, Jun
AU  - He, Zhi
TI  - Identifying Mangrove Species Using Field Close-Range Snapshot Hyperspectral Imaging and Machine-Learning Techniques
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - Investigating mangrove species composition is a basic and important topic in wetland management and conservation. This study aims to explore the potential of close-range hyperspectral imaging with a snapshot hyperspectral sensor for identifying mangrove species under field conditions. Specifically, we assessed the data pre-processing and transformation, waveband selection and machine-learning techniques to develop an optimal classification scheme for eight mangrove species in Qi&rsquo;ao Island of Zhuhai, Guangdong, China. After data pre-processing and transformation, five spectral datasets, which included the reflectance spectra R and its first-order derivative d(R), the logarithm of the reflectance spectra log(R) and its first-order derivative d[log(R)], and hyperspectral vegetation indices (VIs), were used as the input data for each classifier. Consequently, three waveband selection methods, including the stepwise discriminant analysis (SDA), correlation-based feature selection (CFS), and successive projections algorithm (SPA) were used to reduce dimensionality and select the effective wavebands for identifying mangrove species. Furthermore, we evaluated the performance of mangrove species classification using four classifiers, including linear discriminant analysis (LDA), k-nearest neighbor (KNN), random forest (RF), and support vector machine (SVM). Application of the four considered classifiers on the reflectance spectra of all wavebands yielded overall classification accuracies of the eight mangrove species higher than 80%, with SVM having the highest accuracy of 93.54% (Kappa = 0.9256). Using the selected wavebands derived from SPA, the accuracy of SVM reached 93.13% (Kappa = 0.9208). The addition of hyperspectral VIs and d[log(R)] spectral datasets further improves the accuracies to 93.54% (Kappa = 0.9253) and 96.46% (Kappa = 0.9591), respectively. These results suggest that it is highly effective to apply field close-range snapshot hyperspectral images and machine-learning classifiers to classify mangrove species.
KW  - mangrove species classification
KW  - close-range hyperspectral imaging
KW  - field hyperspectral measurement
KW  - waveband selection
KW  - machine learning
DO  - 10.3390/rs10122047
ER  -
TY  - EJOU
AU  - Cao, Feng
AU  - Liu, Fei
AU  - Guo, Han
AU  - Kong, Wenwen
AU  - Zhang, Chu
AU  - He, Yong
TI  - Fast Detection of Sclerotinia Sclerotiorum on Oilseed Rape Leaves Using Low-Altitude Remote Sensing Technology
T2  - Sensors

PY  - 2018
VL  - 18
IS  - 12
SN  - 1424-8220

AB  - Sclerotinia sclerotiorum, one of the major diseases infecting oilseed rape leaves, has seriously affected crop yield and quality. In this study, an indoor unmanned aerial vehicle (UAV) low-altitude remote sensing simulation platform was built for disease detection. Thermal, multispectral and RGB images were acquired before and after being artificially inoculated with Sclerotinia sclerotiorum on oilseed rape leaves. New image registration and fusion methods based on scale-invariant feature transform (SIFT) were presented to construct a fused database using multi-model images. The changes of temperature distribution in different sections of infected areas were analyzed by processing thermal images, the maximum temperature difference (MTD) on a single leaf reached 1.7 degrees Celsius 24 h after infection. Four machine learning models were established using thermal images and fused images respectively, including support vector machine (SVM), random forest (RF), K-nearest neighbor (KNN) and na&iuml;ve Bayes (NB). The results demonstrated that the classification accuracy was improved by 11.3% after image fusion, and the SVM model obtained a classification accuracy of 90.0% on the task of classifying disease severity. The overall results indicated the UAV low-altitude remote sensing simulation platform equipped with multi-sensors could be used to early detect Sclerotinia sclerotiorum on oilseed rape leaves.
KW  - Sclerotinia sclerotiorum
KW  - oilseed rape
KW  - multispectral technology
KW  - thermal imaging technology
KW  - image fusion
KW  - machine learning
DO  - 10.3390/s18124464
ER  -
TY  - EJOU
AU  - Jozaghi, Ali
AU  - Alizadeh, Babak
AU  - Hatami, Mohsen
AU  - Flood, Ian
AU  - Khorrami, Mohammad
AU  - Khodaei, Nastaran
AU  - Ghasemi Tousi, Erfan
TI  - A Comparative Study of the AHP and TOPSIS Techniques for Dam Site Selection Using GIS: A Case Study of Sistan and Baluchestan Province, Iran
T2  - Geosciences

PY  - 2018
VL  - 8
IS  - 12
SN  - 2076-3263

AB  - The application of multiple criteria decision-making (MCDM) techniques in real-life problems has increased in recent years. The need to build advanced decision models with higher capabilities that can support decision-making in a broad spectrum of applications, promotes the integration of MCDM techniques with applicable systems, including artificial intelligence, and Geographic Information Systems (GIS). The Analytic Hierarchy Process (AHP) and Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) are among the most widely adopted MCDM techniques capable of resolving water resources challenges. A critical problem associated with water resource management is dam site selection. This paper presents a comparative analysis of TOPSIS and AHP in the context of decision-making using GIS for dam site selection. The comparison was made based on geographic and water quality criteria. The geographical criteria are geology, land use, sediment, erosion, slope, groundwater, and discharge. The water quality criteria include Soluble Sodium Percentage, Total Dissolved Solid, Potential of Hydrogen, and Electrical Conductivity of water. A ratio estimation procedure was used to determine the weights of these criteria. Both methods were applied for selection of optimal sites for dams in the Sistan and Baluchestan province, Iran. The results show that the TOPSIS method is better suited to the problem of dam site selection for this study area. Actual locations of dams constructed in the area were used to verify the results of both methods.
KW  - dam site selection
KW  - water resources
KW  - MCDM
KW  - topographical conditions
KW  - morphological conditions
KW  - TOPSIS
KW  - AHP
KW  - Geographic Information System
KW  - Sistan and Baluchestan
DO  - 10.3390/geosciences8120494
ER  -
TY  - EJOU
AU  - Zhao, Caidan
AU  - Chen, Caiyun
AU  - He, Zeping
AU  - Wu, Zhiqiang
TI  - Application of Auxiliary Classifier Wasserstein Generative Adversarial Networks in Wireless Signal Classification of Illegal Unmanned Aerial Vehicles
T2  - Applied Sciences

PY  - 2018
VL  - 8
IS  - 12
SN  - 2076-3417

AB  - Recently, many studies have reported on image synthesis based on Generative Adversarial Networks (GAN). However, the use of GAN does not provide much attention on the signal classification problem. In the context of using wireless signals to classify illegal Unmanned Aerial Vehicles (UAVs), this paper explores the feasibility of using GAN to improve the training datasets and obtain a better classification model, thereby improving the accuracy of classification. First, we use the generative model of GAN to generate a large datasets, which does not need manual annotation. At the same time, the discriminative model of GAN is improved to classify the types of signals based on the loss function of the discriminative model. Finally, this model can be used to the outdoor environment and obtain a real-time illegal UAVs signal classification system. Our experiments confirmed that the improvements on the Auxiliary Classifier Generative Adversarial Networks (AC-GANs) by limited datasets achieve excellent results. The recognition rate can reach more than 95% in the indoor environment, and this method is also applicable in the outdoor environment. Moreover, based on the theory of Wasserstein GANs (WGAN) and AC-GANs, a more robust Auxiliary Classifier Wasserstein GANs (AC-WGANs) model is obtained, which is suitable for multi-class UAVs. Through the combination of AC-WGANs and Universal Software Radio Peripheral (USRP) B210 software defined radio (SDR) platform, a real-time UAVs signal classification system is also implemented.
KW  - GAN
KW  - AC-WGANs
KW  - wireless signals
KW  - classify model
KW  - USRP
DO  - 10.3390/app8122664
ER  -
TY  - EJOU
AU  - Guo, Hao
AU  - Wei, Guo
AU  - An, Jubai
TI  - Dark Spot Detection in SAR Images of Oil Spill Using Segnet
T2  - Applied Sciences

PY  - 2018
VL  - 8
IS  - 12
SN  - 2076-3417

AB  - Damping Bragg scattering from the ocean surface is the basic underlying principle of synthetic aperture radar (SAR) oil slick detection, and they produce dark spots on SAR images. Dark spot detection is the first step in oil spill detection, which affects the accuracy of oil spill detection. However, some natural phenomena (such as waves, ocean currents, and low wind belts, as well as human factors) may change the backscatter intensity on the surface of the sea, resulting in uneven intensity, high noise, and blurred boundaries of oil slicks or lookalikes. In this paper, Segnet is used as a semantic segmentation model to detect dark spots in oil spill areas. The proposed method is applied to a data set of 4200 from five original SAR images of an oil spill. The effectiveness of the method is demonstrated through the comparison with fully convolutional networks (FCN), an initiator of semantic segmentation models, and some other segmentation methods. It is here observed that the proposed method can not only accurately identify the dark spots in SAR images, but also show a higher robustness under high noise and fuzzy boundary conditions.
KW  - image segmentation
KW  - deep learning
KW  - synthetic aperture radar (SAR)
KW  - oil slicks
KW  - segnet
DO  - 10.3390/app8122670
ER  -
TY  - EJOU
AU  - Huang, Lingcao
AU  - Liu, Lin
AU  - Jiang, Liming
AU  - Zhang, Tingjun
TI  - Automatic Mapping of Thermokarst Landforms from Remote Sensing Images Using Deep Learning: A Case Study in the Northeastern Tibetan Plateau
T2  - Remote Sensing

PY  - 2018
VL  - 10
IS  - 12
SN  - 2072-4292

AB  - Thawing of ice-rich permafrost causes thermokarst landforms on the ground surface. Obtaining the distribution of thermokarst landforms is a prerequisite for understanding permafrost degradation and carbon exchange at local and regional scales. However, because of their diverse types and characteristics, it is challenging to map thermokarst landforms from remote sensing images. We conducted a case study towards automatically mapping a type of thermokarst landforms (i.e., thermo-erosion gullies) in a local area in the northeastern Tibetan Plateau from high-resolution images by the use of deep learning. In particular, we applied the DeepLab algorithm (based on Convolutional Neural Networks) to a 0.15-m-resolution Digital Orthophoto Map (created using aerial photographs taken by an Unmanned Aerial Vehicle). Here, we document the detailed processing flow with key steps including preparing training data, fine-tuning, inference, and post-processing. Validating against the field measurements and manual digitizing results, we obtained an F1 score of 0.74 (precision is 0.59 and recall is 1.0), showing that the proposed method can effectively map small and irregular thermokarst landforms. It is potentially viable to apply the designed method to mapping diverse thermokarst landforms in a larger area where high-resolution images and training data are available.
KW  - DeepLab
KW  - permafrost degradation
KW  - semantic segmentation
KW  - thermokarst landforms
KW  - thermo-erosion gullies
KW  - Tibetan Plateau
KW  - Unmanned Aerial Vehicle Images
DO  - 10.3390/rs10122067
ER  -
TY  - EJOU
AU  - Rançon, Florian
AU  - Bombrun, Lionel
AU  - Keresztes, Barna
AU  - Germain, Christian
TI  - Comparison of SIFT Encoded and Deep Learning Features for the Classification and Detection of Esca Disease in Bordeaux Vineyards
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 1
SN  - 2072-4292

AB  - Grapevine wood fungal diseases such as esca are among the biggest threats in vineyards nowadays. The lack of very efficient preventive (best results using commercial products report 20% efficiency) and curative means induces huge economic losses. The study presented in this paper is centered around the in-field detection of foliar esca symptoms during summer, exhibiting a typical &ldquo;striped&rdquo; pattern. Indeed, in-field disease detection has shown great potential for commercial applications and has been successfully used for other agricultural needs such as yield estimation. Differentiation with foliar symptoms caused by other diseases or abiotic stresses was also considered. Two vineyards from the Bordeaux region (France, Aquitaine) were chosen as the basis for the experiment. Pictures of diseased and healthy vine plants were acquired during summer 2017 and labeled at the leaf scale, resulting in a patch database of around 6000 images (224 &times; 224 pixels) divided into red cultivar and white cultivar samples. Then, we tackled the classification part of the problem comparing state-of-the-art SIFT encoding and pre-trained deep learning feature extractors for the classification of database patches. In the best case, 91% overall accuracy was obtained using deep features extracted from MobileNet network trained on ImageNet database, demonstrating the efficiency of simple transfer learning approaches without the need to design an ad-hoc specific feature extractor. The third part aimed at disease detection (using bounding boxes) within full plant images. For this purpose, we integrated the deep learning base network within a &ldquo;one-step&rdquo; detection network (RetinaNet), allowing us to perform detection queries in real time (approximately six frames per second on GPU). Recall/Precision (RP) and Average Precision (AP) metrics then allowed us to evaluate the performance of the network on a 91-image (plants) validation database. Overall, 90% precision for a 40% recall was obtained while best esca AP was about 70%. Good correlation between annotated and detected symptomatic surface per plant was also obtained, meaning slightly symptomatic plants can be efficiently separated from severely attacked plants.
KW  - proximal sensing
KW  - disease detection
KW  - grapevine trunk disease
KW  - esca
KW  - SIFT
KW  - deep learning
DO  - 10.3390/rs11010001
ER  -
TY  - EJOU
AU  - Wang, Kepu
AU  - Wang, Tiejun
AU  - Liu, Xuehua
TI  - A Review: Individual Tree Species Classification Using Integrated Airborne LiDAR and Optical Imagery with a Focus on the Urban Environment
T2  - Forests

PY  - 2019
VL  - 10
IS  - 1
SN  - 1999-4907

AB  - With the significant progress of urbanization, cities and towns are suffering from air pollution, heat island effects, and other environmental problems. Urban vegetation, especially trees, plays a significant role in solving these ecological problems. To maximize services provided by vegetation, urban tree species should be properly selected and optimally arranged. Therefore, accurate classification of tree species in urban environments has become a major issue. In this paper, we reviewed the potential of light detection and ranging (LiDAR) data to improve the accuracy of urban tree species classification. In detail, we reviewed the studies using LiDAR data in urban tree species mapping, especially studies where LiDAR data was fused with optical imagery, through classification accuracy comparison, general workflow extraction, and discussion and summarizing of the specific contribution of LiDAR. It is concluded that combining LiDAR data in urban tree species identification could achieve better classification accuracy than using either dataset individually, and that such improvements are mainly due to finer segmentation, shadowing effect reduction, and refinement of classification rules based on LiDAR. Furthermore, some suggestions are given to improve the classification accuracy on a finer and larger species level, while also aiming to maintain classification costs.
KW  - LiDAR
KW  - optical imagery
KW  - tree species classification
KW  - urban forests
DO  - 10.3390/f10010001
ER  -
TY  - EJOU
AU  - Chen, Yuyun
AU  - Li, Longwei
AU  - Lu, Dengsheng
AU  - Li, Dengqiu
TI  - Exploring Bamboo Forest Aboveground Biomass Estimation Using Sentinel-2 Data
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 1
SN  - 2072-4292

AB  - Bamboo forests, due to rapid growth and short harvest rotation, play an important role in carbon cycling and local economic development. Accurate estimation of bamboo forest aboveground biomass (AGB) has garnered increasing attention during the past two decades. However, remote sensing-based AGB estimation for bamboo forests is challenging due to poor understanding of the mechanisms between bamboo forest growth characteristics and remote sensing data. The objective of this research is to examine the remote sensing characteristics of on-year and off-year bamboo forests at different dates and their AGB estimation performance. This research used multiple Sentinel-2 data to explore AGB estimation of bamboo forests in Zhejiang Province, China, by taking into account the unique characteristics of on-year and off-year bamboo forest growth features. Combining field survey data and Sentinel-2 spectral responses (spectral bands and vegetation indices) and textural images, random forest was used to identify key variables for AGB estimation. The results show that (1) the on-year and off-year bamboo forests have considerably different spectral signatures, especially in the wavelengths between red edge 2 and near-infrared wavelength (NIR2) (740&ndash;865 nm), making it possible to separate on-year and off-year bamboo forests; (2) on-year bamboo forests have similar spectral signatures although AGB increases from as small as 40 Mgha&minus;1 to as high as 90 Mgha&minus;1, implying that optical sensor data cannot effectively model on-year bamboo AGB; (3) off-year bamboo AGB has significant relationships with red and shortwave infrared (SWIR) spectral bands in the April image and with red edge 2 in the July image, but the AGB saturation problem yields poor estimation accuracy; (4) stratification considerably improved off-year bamboo AGB estimation but not on-year, non-stratification using the April image is recommended; and (5) Sentinel-2 data cannot solve the bamboo AGB data saturation problem when AGB is greater than 70 Mgha&minus;1, similar to other optical sensor data such as Landsat. More research should be conducted in the future to integrate multiple sources&mdash;remotely sensed data (e.g., lidar, optical sensor data) and ancillary data (e.g., soil, topography)&mdash;into AGB modeling to improve the estimation. The use of very high spatial resolution images that can effectively extract tree density information may improve bamboo AGB estimation and yield new insights.
KW  - bamboo forests
KW  - on-year and off-year
KW  - aboveground biomass
KW  - random forest
KW  - Sentinel-2
DO  - 10.3390/rs11010007
ER  -
TY  - EJOU
AU  - Wang, Yuhao
AU  - Liang, Binxiu
AU  - Ding, Meng
AU  - Li, Jiangyun
TI  - Dense Semantic Labeling with Atrous Spatial Pyramid Pooling and Decoder for High-Resolution Remote Sensing Imagery
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 1
SN  - 2072-4292

AB  - Dense semantic labeling is significant in high-resolution remote sensing imagery research and it has been widely used in land-use analysis and environment protection. With the recent success of fully convolutional networks (FCN), various types of network architectures have largely improved performance. Among them, atrous spatial pyramid pooling (ASPP) and encoder-decoder are two successful ones. The former structure is able to extract multi-scale contextual information and multiple effective field-of-view, while the latter structure can recover the spatial information to obtain sharper object boundaries. In this study, we propose a more efficient fully convolutional network by combining the advantages from both structures. Our model utilizes the deep residual network (ResNet) followed by ASPP as the encoder and combines two scales of high-level features with corresponding low-level features as the decoder at the upsampling stage. We further develop a multi-scale loss function to enhance the learning procedure. In the postprocessing, a novel superpixel-based dense conditional random field is employed to refine the predictions. We evaluate the proposed method on the Potsdam and Vaihingen datasets and the experimental results demonstrate that our method performs better than other machine learning or deep learning methods. Compared with the state-of-the-art DeepLab_v3+ our model gains 0.4% and 0.6% improvements in overall accuracy on these two datasets respectively.
KW  - remote sensing imagery
KW  - dense semantic labeling
KW  - fully convolutional networks
KW  - atrous spatial pyramid pooling
KW  - encoder-decoder
KW  - superpixel-based DenseCRF
DO  - 10.3390/rs11010020
ER  -
TY  - EJOU
AU  - Mahdianpari, Masoud
AU  - Salehi, Bahram
AU  - Mohammadimanesh, Fariba
AU  - Homayouni, Saeid
AU  - Gill, Eric
TI  - The First Wetland Inventory Map of Newfoundland at a Spatial Resolution of 10 m Using Sentinel-1 and Sentinel-2 Data on the Google Earth Engine Cloud Computing Platform
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 1
SN  - 2072-4292

AB  - Wetlands are one of the most important ecosystems that provide a desirable habitat for a great variety of flora and fauna. Wetland mapping and modeling using Earth Observation (EO) data are essential for natural resource management at both regional and national levels. However, accurate wetland mapping is challenging, especially on a large scale, given their heterogeneous and fragmented landscape, as well as the spectral similarity of differing wetland classes. Currently, precise, consistent, and comprehensive wetland inventories on a national- or provincial-scale are lacking globally, with most studies focused on the generation of local-scale maps from limited remote sensing data. Leveraging the Google Earth Engine (GEE) computational power and the availability of high spatial resolution remote sensing data collected by Copernicus Sentinels, this study introduces the first detailed, provincial-scale wetland inventory map of one of the richest Canadian provinces in terms of wetland extent. In particular, multi-year summer Synthetic Aperture Radar (SAR) Sentinel-1 and optical Sentinel-2 data composites were used to identify the spatial distribution of five wetland and three non-wetland classes on the Island of Newfoundland, covering an approximate area of 106,000 km2. The classification results were evaluated using both pixel-based and object-based random forest (RF) classifications implemented on the GEE platform. The results revealed the superiority of the object-based approach relative to the pixel-based classification for wetland mapping. Although the classification using multi-year optical data was more accurate compared to that of SAR, the inclusion of both types of data significantly improved the classification accuracies of wetland classes. In particular, an overall accuracy of 88.37% and a Kappa coefficient of 0.85 were achieved with the multi-year summer SAR/optical composite using an object-based RF classification, wherein all wetland and non-wetland classes were correctly identified with accuracies beyond 70% and 90%, respectively. The results suggest a paradigm-shift from standard static products and approaches toward generating more dynamic, on-demand, large-scale wetland coverage maps through advanced cloud computing resources that simplify access to and processing of the “Geo Big Data.” In addition, the resulting ever-demanding inventory map of Newfoundland is of great interest to and can be used by many stakeholders, including federal and provincial governments, municipalities, NGOs, and environmental consultants to name a few.
KW  - wetland
KW  - Google Earth Engine
KW  - Sentinel-1
KW  - Sentinel-2
KW  - random forest
KW  - cloud computing
KW  - geo-big data
DO  - 10.3390/rs11010043
ER  -
TY  - EJOU
AU  - Moskalenko, Viacheslav
AU  - Moskalenko, Alona
AU  - Korobov, Artem
AU  - Semashko, Viktor
TI  - The Model and Training Algorithm of Compact Drone Autonomous Visual Navigation System
T2  - Data

PY  - 2019
VL  - 4
IS  - 1
SN  - 2306-5729

AB  - Trainable visual navigation systems based on deep learning demonstrate potential for robustness of onboard camera parameters and challenging environment. However, a deep model requires substantial computational resources and large labelled training sets for successful training. Implementation of the autonomous navigation and training-based fast adaptation to the new environment for a compact drone is a complicated task. The article describes an original model and training algorithms adapted to the limited volume of labelled training set and constrained computational resource. This model consists of a convolutional neural network for visual feature extraction, extreme-learning machine for estimating the position displacement and boosted information-extreme classifier for obstacle prediction. To perform unsupervised training of the convolution filters with a growing sparse-coding neural gas algorithm, supervised learning algorithms to construct the decision rules with simulated annealing search algorithm used for finetuning are proposed. The use of complex criterion for parameter optimization of the feature extractor model is considered. The resulting approach performs better trajectory reconstruction than the well-known ORB-SLAM. In particular, for sequence 7 from the KITTI dataset, the translation error is reduced by nearly 65.6% under the frame rate 10 frame per second. Besides, testing on the independent TUM sequence shot outdoors produces a translation error not exceeding 6% and a rotation error not exceeding 3.68 degrees per 100 m. Testing was carried out on the Raspberry Pi 3+ single-board computer.
KW  - navigation
KW  - visual odometry
KW  - convolutional neural network
KW  - neural gas
KW  - information criterion
KW  - extreme learning
DO  - 10.3390/data4010004
ER  -
TY  - EJOU
AU  - Heinzel, Johannes
AU  - Ginzler, Christian
TI  - A Single-Tree Processing Framework Using Terrestrial Laser Scanning Data for Detecting Forest Regeneration
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 1
SN  - 2072-4292

AB  - Direct assessment of forest regeneration from remote sensing data is a previously little-explored problem. This is due to several factors which complicate object detection of small trees in the understory. Most existing studies are based on airborne laser scanning (ALS) data, which often has insufficient point densities in the understory forest layers. The present study uses plot-based terrestrial laser scanning (TLS) and the survey design was similar to traditional forest inventory practices. Furthermore, a framework of methods was developed to solve the difficulties of detecting understory trees for quantifying regeneration in temperate montane forest. Regeneration is of special importance in our montane study area, since large parts are declared as protection forest against alpine natural hazards. Close to nature forest structures were tackled by separating 3D tree stem detection from overall tree segmentation. In support, techniques from 3D mathematical morphology, Hough transformation and state-of-the-art machine learning were applied. The methodical framework consisted of four major steps. These were the extraction of the tree stems, the estimation of the stem diameters at breast height (DBH), the image segmentation into individual trees and finally, the separation of two groups of regeneration. All methods were fully automated and utilized volumetric 3D image information which was derived from the original point cloud. The total amount of regeneration was split into established regeneration, consisting of trees with a height &gt; 130 cm in combination with a DBH &lt; 12 cm and unestablished regeneration, consisting of trees with a height &lt; 130 cm. Validation was carried out against field-based expert estimates of percentage ground cover, differentiating seven classes that were similar to those used by forest inventory. The mean absolute error (MAE) of our method for established regeneration was 1.11 classes and for unestablished regeneration only 0.27 classes. Considering the metrical distances between the class centres, the MAE amounted 8.08% for established regeneration and 2.23% for unestablished regeneration.
KW  - understory
KW  - tree stems
KW  - DBH
KW  - forestry
KW  - TLS
KW  - 3D image segmentation
KW  - tree detection
DO  - 10.3390/rs11010060
ER  -
TY  - EJOU
AU  - Fraser, Benjamin T.
AU  - Congalton, Russell G.
TI  - Evaluating the Effectiveness of Unmanned Aerial Systems (UAS) for Collecting Thematic Map Accuracy Assessment Reference Data in New England Forests
T2  - Forests

PY  - 2019
VL  - 10
IS  - 1
SN  - 1999-4907

AB  - Thematic mapping provides today&rsquo;s analysts with an essential geospatial science tool for conveying spatial information. The advancement of remote sensing and computer science technologies has provided classification methods for mapping at both pixel-based and object-based analysis, for increasingly complex environments. These thematic maps then serve as vital resources for a variety of research and management needs. However, to properly use the resulting thematic map as a decision-making support tool, an assessment of map accuracy must be performed. The methods for assessing thematic accuracy have coalesced into a site-specific multivariate analysis of error, measuring uncertainty in relation to an established reality known as reference data. Ensuring statistical validity, access and time constraints, and immense costs limit the collection of reference data in many projects. Therefore, this research proposes evaluating the feasibility of adopting the low-cost, flexible, high-resolution sensor-capable Unmanned Aerial Systems (UAS, UAV, or Drone) platform for collecting reference data to use in thematic map accuracy assessments for complex environments. This pilot study analyzed 377.57 ha of New England forests, over six University of New Hampshire woodland properties, to compare the similarity between UAS-derived orthomosaic samples and ground-based continuous forest inventory (CFI) plot classifications of deciduous, mixed, and coniferous forest cover types. Using an eBee Plus fixed-wing UAS, 9173 images were acquired and used to create six comprehensive orthomosaics. Agreement between our UAS orthomosaics and ground-based sampling forest compositions reached 71.43% for pixel-based classification and 85.71% for object-based classification reference data methods. Despite several documented sources of uncertainty or error, this research demonstrated that UAS are capable of highly efficient and effective thematic map accuracy assessment reference data collection. As UAS hardware, software, and implementation policies continue to evolve, the potential to meet the challenges of accurate and timely reference data collection will only increase.
KW  - Unmanned Aerial Systems (UAS)
KW  - structure from motion (SfM)
KW  - Unmanned Aerial Vehicles (UAV)
KW  - Photogrammetry
KW  - Thematic Mapping
KW  - Accuracy Assessment
KW  - Reference Data
KW  - Forest Sampling
KW  - Remote Sensing
DO  - 10.3390/f10010024
ER  -
TY  - EJOU
AU  - Navarro, José A.
AU  - Algeet, Nur
AU  - Fernández-Landa, Alfredo
AU  - Esteban, Jessica
AU  - Rodríguez-Noriega, Pablo
AU  - Guillén-Climent, María L.
TI  - Integration of UAV, Sentinel-1, and Sentinel-2 Data for Mangrove Plantation Aboveground Biomass Monitoring in Senegal
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 1
SN  - 2072-4292

AB  - Due to the increasing importance of mangroves in climate change mitigation projects, more accurate and cost-effective aboveground biomass (AGB) monitoring methods are required. However, field measurements of AGB may be a challenge because of their remote location and the difficulty to walk in these areas. This study is based on the Livelihoods Fund Oceanium project that monitors 10,000 ha of mangrove plantations. In a first step, the possibility of replacing traditional field measurements of sample plots in a young mangrove plantation by a semiautomatic processing of UAV-based photogrammetric point clouds was assessed. In a second step, Sentinel-1 radar and Sentinel-2 optical imagery were used as auxiliary information to estimate AGB and its variance for the entire study area under a model-assisted framework. AGB was measured using UAV imagery in a total of 95 sample plots. UAV plot data was used in combination with non-parametric support vector regression (SVR) models for the estimation of the study area AGB using model-assisted estimators. Purely UAV-based AGB estimates and their associated standard error (SE) were compared with model-assisted estimates using (1) Sentinel-1, (2) Sentinel-2, and (3) a combination of Sentinel-1 and Sentinel-2 data as auxiliary information. The validation of the UAV-based individual tree height and crown diameter measurements showed a root mean square error (RMSE) of 0.21 m and 0.32 m, respectively. Relative efficiency of the three model-assisted scenarios ranged between 1.61 and 2.15. Although all SVR models improved the efficiency of the monitoring over UAV-based estimates, the best results were achieved when a combination of Sentinel-1 and Sentinel-2 data was used. Results indicated that the methodology used in this research can provide accurate and cost-effective estimates of AGB in young mangrove plantations.
KW  - digital aerial photogrammetry
KW  - SAR
KW  - model-assisted
KW  - biomass estimation
KW  - Copernicus
KW  - unmanned aerial vehicles
DO  - 10.3390/rs11010077
ER  -
TY  - EJOU
AU  - Melville, Bethany
AU  - Lucieer, Arko
AU  - Aryal, Jagannath
TI  - Classification of Lowland Native Grassland Communities Using Hyperspectral Unmanned Aircraft System (UAS) Imagery in the Tasmanian Midlands
T2  - Drones

PY  - 2019
VL  - 3
IS  - 1
SN  - 2504-446X

AB  - This paper presents the results of a study undertaken to classify lowland native grassland communities in the Tasmanian Midlands region. Data was collected using the 20 band hyperspectral snapshot PhotonFocus sensor mounted on an unmanned aerial vehicle. The spectral range of the sensor is 600 to 875 nm. Four vegetation classes were identified for analysis including Themeda triandra grassland, Wilsonia rotundifolia, Danthonia/Poa grassland, and Acacia dealbata. In addition to the hyperspectral UAS dataset, a Digital Surface Model (DSM) was derived using a structure-from-motion (SfM). Classification was undertaken using an object-based Random Forest (RF) classification model. Variable importance measures from the training model indicated that the DSM was the most significant variable. Key spectral variables included bands two (620.9 nm), four (651.1 nm), and 11 (763.2 nm) from the hyperspectral UAS imagery. Classification validation was performed using both the reference segments and the two transects. For the reference object validation, mean accuracies were between 70% and 72%. Classification accuracies based on the validation transects achieved a maximum overall classification accuracy of 93.
KW  - hyperspectral
KW  - UAS
KW  - native grassland
KW  - random forest
DO  - 10.3390/drones3010005
ER  -
TY  - EJOU
AU  - Hernandez-Santin, Lorna
AU  - Rudge, Mitchel L.
AU  - Bartolo, Renee E.
AU  - Erskine, Peter D.
TI  - Identifying Species and Monitoring Understorey from UAS-Derived Data: A Literature Review and Future Directions
T2  - Drones

PY  - 2019
VL  - 3
IS  - 1
SN  - 2504-446X

AB  - Understorey vegetation plays an important role in many ecosystems, yet identifying and monitoring understorey vegetation through remote sensing has proved a challenge for researchers and land managers because understorey plants tend to be small, spatially and spectrally similar, and are often blocked by the overstorey. The emergence of Unmanned Aerial Systems (UAS) is revolutionising how vegetation is measured, and may allow us to measure understorey species where traditional remote sensing previously could not. The goal of this paper was to review current literature and assess the current capability of UAS to identify and monitor understorey vegetation. From the literature, we focused on the technical attributes that limit the ability to monitor understorey vegetation&mdash;specifically (1) spatial resolution, (2) spectral sensitivity, (3) spatial extent, and (4) temporal frequency at which a sensor acquires data. We found that UAS have provided improved levels of spatial resolution, with authors reporting successful classifications of understorey vegetation at resolutions of between 3 mm and 200 mm. Species discrimination can be achieved by targeting flights to correspond with phenological events to allow the detection of species-specific differences. We provide recommendations as to how UAS attributes can be tailored to help identify and monitor understorey species.
KW  - UAV
KW  - drone
KW  - sub-canopy
KW  - understory
KW  - vegetation
KW  - remote sensing
KW  - spatial resolution
KW  - spectral sensitivity
KW  - spatial extent
KW  - temporal frequency
DO  - 10.3390/drones3010009
ER  -
TY  - EJOU
AU  - Jiménez López, Jesús
AU  - Mulero-Pázmány, Margarita
TI  - Drones for Conservation in Protected Areas: Present and Future
T2  - Drones

PY  - 2019
VL  - 3
IS  - 1
SN  - 2504-446X

AB  - Park managers call for cost-effective and innovative solutions to handle a wide variety of environmental problems that threaten biodiversity in protected areas. Recently, drones have been called upon to revolutionize conservation and hold great potential to evolve and raise better-informed decisions to assist management. Despite great expectations, the benefits that drones could bring to foster effectiveness remain fundamentally unexplored. To address this gap, we performed a literature review about the use of drones in conservation. We selected a total of 256 studies, of which 99 were carried out in protected areas. We classified the studies in five distinct areas of applications: “wildlife monitoring and management”; “ecosystem monitoring”; “law enforcement”; “ecotourism”; and “environmental management and disaster response”. We also identified specific gaps and challenges that would allow for the expansion of critical research or monitoring. Our results support the evidence that drones hold merits to serve conservation actions and reinforce effective management, but multidisciplinary research must resolve the operational and analytical shortcomings that undermine the prospects for drones integration in protected areas.
KW  - protected areas
KW  - drones
KW  - RPAS
KW  - conservation
KW  - effective management
KW  - biodiversity threats
DO  - 10.3390/drones3010010
ER  -
TY  - EJOU
AU  - Shiu, Yi-Shiang
AU  - Chuang, Yung-Chung
TI  - Yield Estimation of Paddy Rice Based on Satellite Imagery: Comparison of Global and Local Regression Models
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 2
SN  - 2072-4292

AB  - Precisely estimating the yield of paddy rice is crucial for national food security and development evaluation. Rice yield estimation based on satellite imagery is usually performed with global regression models; however, estimation errors may occur because the spatial variation is not considered. Therefore, this study proposed an approach estimating paddy rice yield based on global and local regression models. In our study area, the overall per-field data might not available because it took lots of time and manpower as well as resources. Therefore, we gathered and accumulated 26 to 63 ground survey sample fields, accounting for about 0.05% of the total cultivated areas, as the training samples for our regression models. To demonstrate whether the spatial autocorrelation or spatial heterogeneity exists and dominates the estimation, global models including the ordinary least squares (OLS), support vector regression (SVR), and the local model geographically weighted regression (GWR) were used to build the yield estimation models. We obtained the representative independent variables, including 4 original bands, 11 vegetation indices, and 32 texture indices, from SPOT-7 multispectral satellite imagery. To determine the optimal variable combination, feature selection based on the Pearson correlation was used for all of the regression models. The case study in Central Taiwan rendered that the error rate was between 0.06% and 13.22%. Through feature selection, the GWR model&rsquo;s performance was more relatively stable than the OLS model and nonlinear SVR model for yield estimation. Where the GWR model considers the spatial autocorrelation and spatial heterogeneity of the relationships between the yield and the independent variables, the OLS and nonlinear SVR models lack this feature; this led to the rice yield estimation of GWR in this study be more stable than those of the other two models.
KW  - yield estimation
KW  - geographically weighted regression
KW  - support vector regression
KW  - vegetation indices
KW  - grey-level co-occurrence matrix
DO  - 10.3390/rs11020111
ER  -
TY  - EJOU
AU  - Yang, Shengying
AU  - Qin, Huibin
AU  - Liang, Xiaolin
AU  - Gulliver, Thomas A.
TI  - An Improved Unauthorized Unmanned Aerial Vehicle Detection Algorithm Using Radiofrequency-Based Statistical Fingerprint Analysis
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 2
SN  - 1424-8220

AB  - Unmanned aerial vehicles (UAVs) are now readily available worldwide and users can easily fly them remotely using smart controllers. This has created the problem of keeping unauthorized UAVs away from private or sensitive areas where they can be a personal or public threat. This paper proposes an improved radio frequency (RF)-based method to detect UAVs. The clutter (interference) is eliminated using a background filtering method. Then singular value decomposition (SVD) and average filtering are used to reduce the noise and improve the signal to noise ratio (SNR). Spectrum accumulation (SA) and statistical fingerprint analysis (SFA) are employed to provide two frequency estimates. These estimates are used to determine if a UAV is present in the detection environment. The data size is reduced using a region of interest (ROI), and this improves the system efficiency and improves azimuth estimation accuracy. Detection results are obtained using real UAV RF signals obtained experimentally which show that the proposed method is more effective than other well-known detection algorithms. The recognition rate with this method is close to 100% within a distance of 2.4 km and greater than 90% within a distance of 3 km. Further, multiple UAVs can be detected accurately using the proposed method.
KW  - spectrum sensing
KW  - radio frequency (RF)
KW  - singular value decomposition (SVD)
KW  - spectrum accumulation (SA)
KW  - statistical fingerprint analysis (SFA)
DO  - 10.3390/s19020274
ER  -
TY  - EJOU
AU  - Shin, Beomju
AU  - Park, Minhuck
AU  - Jeon, Sanghoon
AU  - So, Hyoungmin
AU  - Kim, Gapjin
AU  - Kee, Changdon
TI  - Spoofing Attack Results Determination in Code Domain Using a Spoofing Process Equation
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 2
SN  - 1424-8220

AB  - When a user receiver is tracking an authentic signal, a spoofing signal can be transmitted to the user antenna. The question is under what conditions does the tracking point of the receiver move from the authentic signal to the spoofing signal? In this study, we develop a spoofing process equation (SPE) that can be used to calculate the tracking point of the delay lock loop (DLL) at regular chip intervals for the entire spoofing process. The condition for a successful spoofing signal is analyzed using the SPE. To derive the SPE, parameters, such as the signal strength, sweep velocity, loop filter order, and DLL bandwidth are considered. The success or failure of a spoofing attack is determined for a specific spoofing signal using the SPE. In addition, a correlation between each parameter for a successful spoofing attack could be obtained through the SPE. The simulation results show that the SPE performance is largely consistent with that of general DLL methods, even though the computational load of SPE is very low.
KW  - GNSS spoofing
KW  - GNSS receiver
KW  - delay lock loop
DO  - 10.3390/s19020293
ER  -
TY  - EJOU
AU  - Zhuo, Xiangyu
AU  - Fraundorfer, Friedrich
AU  - Kurz, Franz
AU  - Reinartz, Peter
TI  - Automatic Annotation of Airborne Images by Label Propagation Based on a Bayesian-CRF Model
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 2
SN  - 2072-4292

AB  - The tremendous advances in deep neural networks have demonstrated the superiority of deep learning techniques for applications such as object recognition or image classification. Nevertheless, deep learning-based methods usually require a large amount of training data, which mainly comes from manual annotation and is quite labor-intensive. In order to reduce the amount of manual work required for generating enough training data, we hereby propose to leverage existing labeled data to generate image annotations automatically. Specifically, the pixel labels are firstly transferred from one image modality to another image modality via geometric transformation to create initial image annotations, and then additional information (e.g., height measurements) is incorporated for Bayesian inference to update the labeling beliefs. Finally, the updated label assignments are optimized with a fully connected conditional random field (CRF), yielding refined labeling for all pixels in the image. The proposed approach is tested on two different scenarios, i.e., (1) label propagation from annotated aerial imagery to unmanned aerial vehicle (UAV) imagery and (2) label propagation from map database to aerial imagery. In each scenario, the refined image labels are used as pseudo-ground truth data for training a convolutional neural network (CNN). Results demonstrate that our model is able to produce accurate label assignments even around complex object boundaries; besides, the generated image labels can be effectively leveraged for training CNNs and achieve comparable classification accuracy as manual image annotations, more specifically, the per-class classification accuracy of the networks trained by the manual image annotations and the generated image labels have a difference within     &plusmn; 5 %    .
KW  - automatic image annotation
KW  - label propagation
KW  - Conditional Random Field (CRF)
KW  - Convolutional Neural Network (CNN)
DO  - 10.3390/rs11020145
ER  -
TY  - EJOU
AU  - Giernacki, Wojciech
AU  - Horla, Dariusz
AU  - Báča, Tomáš
AU  - Saska, Martin
TI  - Real-Time Model-Free Minimum-Seeking Autotuning Method for Unmanned Aerial Vehicle Controllers Based on Fibonacci-Search Algorithm
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 2
SN  - 1424-8220

AB  - The paper presents a novel autotuning approach for finding locally-best parameters of controllers on board of unmanned aerial vehicles (UAVs). The controller tuning is performed fully autonomously during flight on the basis of predefined ranges of controller parameters. Required controller properties may be simply interpreted by a cost function, which is involved in the optimization process. For example, the sum of absolute values of the tracking error samples or performance indices, including weighed functions of control signal samples, can be penalized to achieve very precise position control, if required. The proposed method relies on an optimization procedure using Fibonacci-search technique fitted into bootstrap sequences, enabling one to obtain a global minimizer for a unimodal cost function. The approach is characterized by low computational complexity and does not require any UAV dynamics model (just periodical measurements from basic onboard sensors) to obtain proper tuning of a controller. In addition to the theoretical background of the method, an experimental verification in real-world outdoor conditions is provided. The experiments have demonstrated a high robustness of the method to in-environment disturbances, such as wind, and its easy deployability.
KW  - UAV
KW  - auto-tuning
KW  - extremum-seeking control
KW  - iterative learning
KW  - optimization
DO  - 10.3390/s19020312
ER  -
TY  - EJOU
AU  - Gao, Pengbo
AU  - Zhang, Yan
AU  - Zhang, Linhuan
AU  - Noguchi, Ryozo
AU  - Ahamed, Tofael
TI  - Development of a Recognition System for Spraying Areas from Unmanned Aerial Vehicles Using a Machine Learning Approach
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 2
SN  - 1424-8220

AB  - Unmanned aerial vehicle (UAV)-based spraying systems have recently become important for the precision application of pesticides, using machine learning approaches. Therefore, the objective of this research was to develop a machine learning system that has the advantages of high computational speed and good accuracy for recognizing spray and non-spray areas for UAV-based sprayers. A machine learning system was developed by using the mutual subspace method (MSM) for images collected from a UAV. Two target lands: agricultural croplands and orchard areas, were considered in building two classifiers for distinguishing spray and non-spray areas. The field experiments were conducted in target areas to train and test the system by using a commercial UAV (DJI Phantom 3 Pro) with an onboard 4K camera. The images were collected from low (5 m) and high (15 m) altitudes for croplands and orchards, respectively. The recognition system was divided into offline and online systems. In the offline recognition system, 74.4% accuracy was obtained for the classifiers in recognizing spray and non-spray areas for croplands. In the case of orchards, the average classifier recognition accuracy of spray and non-spray areas was 77%. On the other hand, the online recognition system performance had an average accuracy of 65.1% for croplands, and 75.1% for orchards. The computational time for the online recognition system was minimal, with an average of 0.0031 s for classifier recognition. The developed machine learning system had an average recognition accuracy of 70%, which can be implemented in an autonomous UAV spray system for recognizing spray and non-spray areas for real-time applications.
KW  - precision agriculture
KW  - recognition system
KW  - image classifiers
KW  - machine learning system
KW  - mutual subspace method
DO  - 10.3390/s19020313
ER  -
TY  - EJOU
AU  - Li, Zhiqiang
AU  - Cheng, Chengqi
AU  - Kwan, Mei-Po
AU  - Tong, Xiaochong
AU  - Tian, Shaohong
TI  - Identifying Asphalt Pavement Distress Using UAV LiDAR Point Cloud Data and Random Forest Classification
T2  - ISPRS International Journal of Geo-Information

PY  - 2019
VL  - 8
IS  - 1
SN  - 2220-9964

AB  - Asphalt pavement ages and incurs various distresses due to natural and human factors. Thus, it is crucial to rapidly and accurately extract different types of pavement distress to effectively monitor road health status. In this study, we explored the feasibility of pavement distress identification using low-altitude unmanned aerial vehicle light detection and ranging (UAV LiDAR) and random forest classification (RFC) for a section of an asphalt road that is located in the suburb of Shihezi City in Xinjiang Province of China. After a spectral and spatial feature analysis of pavement distress, a total of 48 multidimensional and multiscale features were extracted based on the strength of the point cloud elevations and reflection intensities. Subsequently, we extracted the pavement distresses from the multifeature dataset by utilizing the RFC method. The overall accuracy of the distress identification was 92.3%, and the kappa coefficient was 0.902. When compared with the maximum likelihood classification (MLC) and support vector machine (SVM), the RFC had a higher accuracy, which confirms its robustness and applicability to multisample and high-dimensional data classification. Furthermore, the method achieved an overall accuracy of 95.86% with a validation dataset. This result indicates the validity and stability of our method, which highway maintenance agencies can use to evaluate road health conditions and implement maintenance.
KW  - UAV
KW  - LiDAR
KW  - asphalt pavement distresses
KW  - pavement health conditions
KW  - multiscale features
KW  - random forest classification
DO  - 10.3390/ijgi8010039
ER  -
TY  - EJOU
AU  - Xie, Zhuli
AU  - Chen, Yaoliang
AU  - Lu, Dengsheng
AU  - Li, Guiying
AU  - Chen, Erxue
TI  - Classification of Land Cover, Forest, and Tree Species Classes with ZiYuan-3 Multispectral and Stereo Data
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 2
SN  - 2072-4292

AB  - The global availability of high spatial resolution images makes mapping tree species distribution possible for better management of forest resources. Previous research mainly focused on mapping single tree species, but information about the spatial distribution of all kinds of trees, especially plantations, is often required. This research aims to identify suitable variables and algorithms for classifying land cover, forest, and tree species. Bi-temporal ZiYuan-3 multispectral and stereo images were used. Spectral responses and textures from multispectral imagery, canopy height features from bi-temporal stereo imagery, and slope and elevation from the stereo-derived digital surface model data were examined through comparative analysis of six classification algorithms including maximum likelihood classifier (MLC), k-nearest neighbor (kNN), decision tree (DT), random forest (RF), artificial neural network (ANN), and support vector machine (SVM). The results showed that use of multiple source data&mdash;spectral bands, vegetation indices, textures, and topographic factors&mdash;considerably improved land-cover and forest classification accuracies compared to spectral bands alone, which the highest overall accuracy of 84.5% for land cover classes was from the SVM, and, of 89.2% for forest classes, was from the MLC. The combination of leaf-on and leaf-off seasonal images further improved classification accuracies by 7.8% to 15.0% for land cover classes and by 6.0% to 11.8% for forest classes compared to single season spectral image. The combination of multiple source data also improved land cover classification by 3.7% to 15.5% and forest classification by 1.0% to 12.7% compared to the spectral image alone. MLC provided better land-cover and forest classification accuracies than machine learning algorithms when spectral data alone were used. However, some machine learning approaches such as RF and SVM provided better performance than MLC when multiple data sources were used. Further addition of canopy height features into multiple source data had no or limited effects in improving land-cover or forest classification, but improved classification accuracies of some tree species such as birch and Mongolia scotch pine. Considering tree species classification, Chinese pine, Mongolia scotch pine, red pine, aspen and elm, and other broadleaf trees as having classification accuracies of over 92%, and larch and birch have relatively low accuracies of 87.3% and 84.5%. However, these high classification accuracies are from different data sources and classification algorithms, and no one classification algorithm provided the best accuracy for all tree species classes. This research implies the same data source and the classification algorithm cannot provide the best classification results for different land cover classes. It is necessary to develop a comprehensive classification procedure using an expert-based approach or hierarchical-based classification approach that can employ specific data variables and algorithm for each tree species class.
KW  - tree species
KW  - classification
KW  - ZiYuan-3
KW  - stereo image
KW  - machine learning
DO  - 10.3390/rs11020164
ER  -
TY  - EJOU
AU  - Liu, Wei
AU  - Cheng, Dayu
AU  - Yin, Pengcheng
AU  - Yang, Mengyuan
AU  - Li, Erzhu
AU  - Xie, Meng
AU  - Zhang, Lianpeng
TI  - Small Manhole Cover Detection in Remote Sensing Imagery with Deep Convolutional Neural Networks
T2  - ISPRS International Journal of Geo-Information

PY  - 2019
VL  - 8
IS  - 1
SN  - 2220-9964

AB  - With the development of remote sensing technology and the advent of high-resolution images, obtaining data has become increasingly convenient. However, the acquisition of small manhole cover information still has shortcomings including low efficiency of manual surveying and high leakage rate. Recently, deep learning models, especially deep convolutional neural networks (DCNNs), have proven to be effective at object detection. However, several challenges limit the applications of DCNN in manhole cover object detection using remote sensing imagery: (1) Manhole cover objects often appear at different scales in remotely sensed images and DCNNs&rsquo; fixed receptive field cannot match the scale variability of such objects; (2) Manhole cover objects in large-scale remotely-sensed images are relatively small in size and densely packed, while DCNNs have poor localization performance when applied to such objects. To address these problems, we propose an effective method for detecting manhole cover objects in remotely-sensed images. First, we redesign the feature extractor by adopting the visual geometry group (VGG), which can increase the variety of receptive field size. Then, detection is performed using two sub-networks: a multi-scale output network (MON) for manhole cover object-like edge generation from several intermediate layers whose receptive fields match different object scales and a multi-level convolution matching network (M-CMN) for object detection based on fused feature maps, which combines several feature maps that enable small and densely packed manhole cover objects to produce a stronger response. The results show that our method is more accurate than existing methods at detecting manhole covers in remotely-sensed images.
KW  - manhole cover
KW  - remote sensing images
KW  - object detection
KW  - deep convolutional neural networks
DO  - 10.3390/ijgi8010049
ER  -
TY  - EJOU
AU  - Ghorbanzadeh, Omid
AU  - Blaschke, Thomas
AU  - Gholamnia, Khalil
AU  - Meena, Sansar R.
AU  - Tiede, Dirk
AU  - Aryal, Jagannath
TI  - Evaluation of Different Machine Learning Methods and Deep-Learning Convolutional Neural Networks for Landslide Detection
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 2
SN  - 2072-4292

AB  - There is a growing demand for detailed and accurate landslide maps and inventories around the globe, but particularly in hazard-prone regions such as the Himalayas. Most standard mapping methods require expert knowledge, supervision and fieldwork. In this study, we use optical data from the Rapid Eye satellite and topographic factors to analyze the potential of machine learning methods, i.e., artificial neural network (ANN), support vector machines (SVM) and random forest (RF), and different deep-learning convolution neural networks (CNNs) for landslide detection. We use two training zones and one test zone to independently evaluate the performance of different methods in the highly landslide-prone Rasuwa district in Nepal. Twenty different maps are created using ANN, SVM and RF and different CNN instantiations and are compared against the results of extensive fieldwork through a mean intersection-over-union (mIOU) and other common metrics. This accuracy assessment yields the best result of 78.26% mIOU for a small window size CNN, which uses spectral information only. The additional information from a 5 m digital elevation model helps to discriminate between human settlements and landslides but does not improve the overall classification accuracy. CNNs do not automatically outperform ANN, SVM and RF, although this is sometimes claimed. Rather, the performance of CNNs strongly depends on their design, i.e., layer depth, input window sizes and training strategies. Here, we conclude that the CNN method is still in its infancy as most researchers will either use predefined parameters in solutions like Google TensorFlow or will apply different settings in a trial-and-error manner. Nevertheless, deep-learning can improve landslide mapping in the future if the effects of the different designs are better understood, enough training samples exist, and the effects of augmentation strategies to artificially increase the number of existing samples are better understood.
KW  - deep-learning
KW  - convolution neural networks (CNNs)
KW  - artificial neural network
KW  - RapidEye
KW  - landslide mapping
KW  - mean intersection-over-union (mIOU)
DO  - 10.3390/rs11020196
ER  -
TY  - EJOU
AU  - Franceschini, Marston H.
AU  - Bartholomeus, Harm
AU  - van Apeldoorn, Dirk F.
AU  - Suomalainen, Juha
AU  - Kooistra, Lammert
TI  - Feasibility of Unmanned Aerial Vehicle Optical Imagery for Early Detection and Severity Assessment of Late Blight in Potato
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 3
SN  - 2072-4292

AB  - Assessment of disease incidence and severity at farm scale or in agronomic trials is frequently performed based on visual crop inspection, which is a labor intensive task prone to errors associated with its subjectivity. Therefore, alternative methods to relate disease incidence and severity with changes in crop traits are of great interest. Optical imagery in the visible and near-infrared (Vis-NIR) can potentially be used to detect changes in crop traits caused by pathogen development. Also, cameras on-board of Unmanned Aerial Vehicles (UAVs) have flexible data collection capabilities allowing adjustments considering the trade-off between data throughput and its resolution. However, studies focusing on the use of UAV imagery to describe changes in crop traits related to disease infection are still lacking. More specifically, evaluation of late blight (Phytophthora infestans) incidence in potato concerning early discrimination of different disease severity levels has not been extensively reported. In this article, the description of spectral changes related to the development of potato late blight under low disease severity levels is performed using sub-decimeter UAV optical imagery. The main objective was to evaluate the sensitivity of the data acquired regarding early changes in crop traits related to disease incidence. For that, UAV images were acquired on four dates during the growing season (from 37 to 78 days after planting), before and after late blight was detected in the field. The spectral variability observed in each date was summarized using Simplex Volume Maximization (SiVM), and its relationship with experimental treatments (different crop systems) and disease severity levels (evaluated by visual assessment) was determined based on pixel-wise log-likelihood ratio (LLR) calculation. Using this analytical framework it was possible to identify considerable spectral changes related to late blight incidence in different treatments and also to disease severity level as low as between 2.5 and 5.0% of affected leaf area. Comparison of disease incidence and spectral information acquired using UAV (with 4&ndash;5 cm of spatial resolution) and ground-based imagery (with 0.1&ndash;0.2 cm of spatial resolution) indicate that UAV data allowed identification of patterns comparable to those described by ground-based images, despite some differences concerning the distribution of affected areas detected within the sampling units and an attenuation in the signal measured. Finally, although aggregated information at sampling unit level provided discriminative potential for higher levels of disease development, focusing on spectral information related to disease occurrence increased the discriminative potential of the data acquired.
KW  - hyperspectral sensing
KW  - very high resolution imagery
KW  - disease assessment
KW  - crop monitoring
DO  - 10.3390/rs11030224
ER  -
TY  - EJOU
AU  - Pham, Tien D.
AU  - Yokoya, Naoto
AU  - Bui, Dieu T.
AU  - Yoshino, Kunihiko
AU  - Friess, Daniel A.
TI  - Remote Sensing Approaches for Monitoring Mangrove Species, Structure, and Biomass: Opportunities and Challenges
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 3
SN  - 2072-4292

AB  - The mangrove ecosystem plays a vital role in the global carbon cycle, by reducing greenhouse gas emissions and mitigating the impacts of climate change. However, mangroves have been lost worldwide, resulting in substantial carbon stock losses. Additionally, some aspects of the mangrove ecosystem remain poorly characterized compared to other forest ecosystems due to practical difficulties in measuring and monitoring mangrove biomass and their carbon stocks. Without a quantitative method for effectively monitoring biophysical parameters and carbon stocks in mangroves, robust policies and actions for sustainably conserving mangroves in the context of climate change mitigation and adaptation are more difficult. In this context, remote sensing provides an important tool for monitoring mangroves and identifying attributes such as species, biomass, and carbon stocks. A wide range of studies is based on optical imagery (aerial photography, multispectral, and hyperspectral) and synthetic aperture radar (SAR) data. Remote sensing approaches have been proven effective for mapping mangrove species, estimating their biomass, and assessing changes in their extent. This review provides an overview of the techniques that are currently being used to map various attributes of mangroves, summarizes the studies that have been undertaken since 2010 on a variety of remote sensing applications for monitoring mangroves, and addresses the limitations of these studies. We see several key future directions for the potential use of remote sensing techniques combined with machine learning techniques for mapping mangrove areas and species, and evaluating their biomass and carbon stocks.
KW  - mangrove species
KW  - mapping
KW  - biomass
KW  - blue carbon
KW  - machine learning
KW  - REDD+
DO  - 10.3390/rs11030230
ER  -
TY  - EJOU
AU  - Puliti, Stefano
AU  - Solberg, Svein
AU  - Granhus, Aksel
TI  - Use of UAV Photogrammetric Data for Estimation of Biophysical Properties in Forest Stands Under Regeneration
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 3
SN  - 2072-4292

AB  - The objective of this study was to assess the use of unmanned aerial vehicle (UAV) data for modelling tree density and canopy height in young boreal forests stands. The use of UAV data for such tasks can be beneficial thanks to the high resolution and reduction of the time spent in the field. This study included 29 forest stands, within which 580 clustered plots were measured in the field. An area-based approach was adopted to which random forest models were fitted using the plot data and the corresponding UAV data and then applied and validated at plot and stand level. The results were compared to those of models based on airborne laser scanning (ALS) data and those from a traditional field-assessment. The models based on UAV data showed the smallest stand-level     R M S E     values for mean height (0.56 m) and tree density (1175 trees ha&minus;1). The     R M S E     of the tree density using UAV data was 50% smaller than what was obtained using ALS data (2355 trees ha&minus;1). Overall, this study highlighted that the use of UAVs for the inventory of forest stands under regeneration can be beneficial both because of the high accuracy of the derived data analytics and the time saving compared to traditional field assessments.
KW  - unmanned aerial vehicle
KW  - forest inventory
KW  - stands under regeneration
KW  - tree density
KW  - airborne laser scanning
DO  - 10.3390/rs11030233
ER  -
TY  - EJOU
AU  - Tuyishimire, Emmanuel
AU  - Bagula, Antoine
AU  - Ismail, Adiel
TI  - Clustered Data Muling in the Internet of Things in Motion
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 3
SN  - 1424-8220

AB  - This paper considers a case where an Unmanned Aerial Vehicle (UAV) is used to monitor an area of interest. The UAV is assisted by a Sensor Network (SN), which is deployed in the area such as a smart city or smart village. The area being monitored has a reasonable size and hence may contain many sensors for efficient and accurate data collection. In this case, it would be expensive for one UAV to visit all the sensors; hence the need to partition the ground network into an optimum number of clusters with the objective of having the UAV visit only cluster heads (fewer sensors). In such a setting, the sensor readings (sensor data) would be sent to cluster heads where they are collected by the UAV upon its arrival. This paper proposes a clustering scheme that optimizes not only the sensor network energy usage, but also the energy used by the UAV to cover the area of interest. The computation of the number of optimal clusters in a dense and uniformly-distributed sensor network is proposed to complement the k-means clustering algorithm when used as a network engineering technique in hybrid UAV/terrestrial networks. Furthermore, for general networks, an efficient clustering model that caters for both orphan nodes and multi-layer optimization is proposed and analyzed through simulations using the city of Cape Town in South Africa as a smart city hybrid network engineering use-case.
KW  - clustering
KW  - hybrid network
KW  - UAV
DO  - 10.3390/s19030484
ER  -
TY  - EJOU
AU  - Rasti, Pejman
AU  - Ahmad, Ali
AU  - Samiei, Salma
AU  - Belin, Etienne
AU  - Rousseau, David
TI  - Supervised Image Classification by Scattering Transform with Application to Weed Detection in Culture Crops of High Density
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 3
SN  - 2072-4292

AB  - In this article, we assess the interest of the recently introduced multiscale scattering transform for texture classification applied for the first time in plant science. Scattering transform is shown to outperform monoscale approaches (gray-level co-occurrence matrix, local binary patterns) but also multiscale approaches (wavelet decomposition) which do not include combinatory steps. The regime in which scatter transform also outperforms a standard CNN architecture in terms of data-set size is evaluated (    10 4     instances). An approach on how to optimally design the scatter transform based on energy contrast is provided. This is illustrated on the hard and open problem of weed detection in culture crops of high density from the top view in intensity images. An annotated synthetic data-set available under the form of a data challenge and a simulator are proposed for reproducible science. Scatter transform only trained on synthetic data shows an accuracy of     85 %     when tested on real data.
KW  - weed detection
KW  - scatter transform
KW  - deep learning
KW  - machine-learning classification
KW  - annotation
KW  - synthetic data
KW  - local binary pattern
DO  - 10.3390/rs11030249
ER  -
TY  - EJOU
AU  - Grüner, Esther
AU  - Astor, Thomas
AU  - Wachendorf, Michael
TI  - Biomass Prediction of Heterogeneous Temperate Grasslands Using an SfM Approach Based on UAV Imaging
T2  - Agronomy

PY  - 2019
VL  - 9
IS  - 2
SN  - 2073-4395

AB  - An early and precise yield estimation in intensive managed grassland is mandatory for economic management decisions. RGB (red, green, blue) cameras attached on an unmanned aerial vehicle (UAV) represent a promising non-destructive technology for the assessment of crop traits especially in large and remote areas. Photogrammetric structure from motion (SfM) processing of the UAV-based images into point clouds can be used to generate 3D spatial information about the canopy height (CH). The aim of this study was the development of prediction models for dry matter yield (DMY) in temperate grassland based on CH data generated by UAV RGB imaging over a whole growing season including four cuts. The multi-temporal study compared the remote sensing technique with two conventional methods, i.e., destructive biomass sampling and ruler height measurements in two legume-grass mixtures with red clover (Trifolium pratense L.) and lucerne (Medicago sativa L.) in combination with Italian ryegrass (Lolium multiflorum Lam.). To cover the full range of legume contribution occurring in a practical grassland, pure stands of legumes and grasses contained in each mixture were also investigated. The results showed, that yield prediction by SfM-based UAV RGB imaging provided similar accuracies across all treatments (R2 = 0.59&ndash;0.81) as the ruler height measurements (R2 = 0.58&ndash;0.78). Furthermore, results of yield prediction by UAV RGB imaging demonstrated an improved robustness when an increased CH variability occurred due to extreme weather conditions. It became apparent that morphological characteristics of clover-based canopies (R2 = 0.75) allow a better remotely sensed prediction of total annual yield than for lucerne-grass mixtures (R2 = 0.64), and that these crop-specific models cannot be easily transferred to other grassland types.
KW  - grassland
KW  - yield prediction
KW  - canopy height
KW  - remote sensing
KW  - unmanned aerial vehicle
KW  - RGB imaging
KW  - structure from motion
DO  - 10.3390/agronomy9020054
ER  -
TY  - EJOU
AU  - Xu, Yi
AU  - Wang, Junjie
AU  - Xia, Anquan
AU  - Zhang, Kangyong
AU  - Dong, Xuanyan
AU  - Wu, Kaipeng
AU  - Wu, Guofeng
TI  - Continuous Wavelet Analysis of Leaf Reflectance Improves Classification Accuracy of Mangrove Species
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 3
SN  - 2072-4292

AB  - Due to continuous degradation of mangrove forests, the accurate monitoring of spatial distribution and species composition of mangroves is essential for restoration, conservation and management of coastal ecosystems. With leaf hyperspectral reflectance, this study aimed to explore the potential of continuous wavelet analysis (CWA) combined with different sample subset partition (stratified random sampling (STRAT), Kennard-Stone sampling algorithm (KS), and sample subset partition based on joint X-Y distances (SPXY)) and feature extraction methods (principal component analysis (PCA), successive projections algorithm (SPA), and vegetation index (VI)) in mangrove species classification. A total of 301 mangrove leaf samples with four species (Avicennia marina, Bruguiera gymnorrhiza, Kandelia obovate and Aegiceras corniculatum) were collected across six different regions. The smoothed reflectance (Smth) and first derivative reflectance (Der) spectra were subjected to CWA using different wavelet scales, and a total of 270 random forest classification models were established and compared. Among the 120 models with CWA of Smth, 88.3% of models increased the overall accuracy (OA) values with an improvement of 0.2&ndash;28.6% compared to the model with the Smth spectra; among the 120 models with CWA of Der, 25.8% of models increased the OA values with an improvement of 0.1&ndash;11.4% compared to the model with the Der spectra. The model with CWA of Der at the scale of 23 coupling with STRAT and SPA achieved the best classification result (OA = 98.0%), while the best model with Smth and Der alone had OA values of 86.3% and 93.0%, respectively. Moreover, the models using STRAT outperformed those using KS and SPXY, and the models using PCA and SPA had better performances than those using VIs. We have concluded that CWA with suitable scales holds great potential in improving the classification accuracy of mangrove species, and that STRAT combined with the PCA or SPA method is also recommended to improve classification performance. These results may lay the foundation for further studies with UAV-acquired or satellite hyperspectral data, and the encouraging performance of CWA for mangrove species classification can also be extended to other plant species.
KW  - mangrove
KW  - species classification
KW  - hyperspectral reflectance
KW  - continuous wavelet analysis
KW  - random forest
KW  - feature extraction
KW  - sample subset partition
DO  - 10.3390/rs11030254
ER  -
TY  - EJOU
AU  - Qing, Xinlin
AU  - Li, Wenzhuo
AU  - Wang, Yishou
AU  - Sun, Hu
TI  - Piezoelectric Transducer-Based Structural Health Monitoring for Aircraft Applications
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 3
SN  - 1424-8220

AB  - Structural health monitoring (SHM) is being widely evaluated by the aerospace industry as a method to improve the safety and reliability of aircraft structures and also reduce operational cost. Built-in sensor networks on an aircraft structure can provide crucial information regarding the condition, damage state and/or service environment of the structure. Among the various types of transducers used for SHM, piezoelectric materials are widely used because they can be employed as either actuators or sensors due to their piezoelectric effect and vice versa. This paper provides a brief overview of piezoelectric transducer-based SHM system technology developed for aircraft applications in the past two decades. The requirements for practical implementation and use of structural health monitoring systems in aircraft application are then introduced. State-of-the-art techniques for solving some practical issues, such as sensor network integration, scalability to large structures, reliability and effect of environmental conditions, robust damage detection and quantification are discussed. Development trend of SHM technology is also discussed.
KW  - structural health monitoring
KW  - piezoelectric transducer
KW  - sensor network
KW  - damage detection
KW  - aircraft
DO  - 10.3390/s19030545
ER  -
TY  - EJOU
AU  - Domingo, Darío
AU  - Alonso, Rafael
AU  - Lamelas, María T.
AU  - Montealegre, Antonio L.
AU  - Rodríguez, Francisco
AU  - de la Riva, Juan
TI  - Temporal Transferability of Pine Forest Attributes Modeling Using Low-Density Airborne Laser Scanning Data
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 3
SN  - 2072-4292

AB  - This study assesses model temporal transferability using airborne laser scanning (ALS) data acquired over two different dates. Seven forest attributes (i.e. stand density, basal area, squared mean diameter, dominant diameter, tree dominant height, timber volume, and total tree biomass) were estimated using an area-based approach in Mediterranean Aleppo pine forests. Low-density ALS data were acquired in 2011 and 2016 while 147 forest inventory plots were measured in 2013, 2014, and 2016. Single-tree growth models were used to generate concomitant field data for 2011 and 2016. A comparison of five selection techniques and five regression methods were performed to regress field observations against ALS metrics. The selection of the best regression models fitted for each stand attribute, and separately for both 2011 and 2016, was performed following an indirect approach. Model performance and temporal transferability were analyzed by extrapolating the best fitted models from 2011 to 2016 and inversely from 2016 to 2011 using the direct approach. Non-parametric support vector machine with radial kernel was the best regression method with average relative % root mean square error differences of 2.13% for 2011 models and 1.58% for 2016 ones.
KW  - model temporal transferability
KW  - ALS
KW  - forest inventory
KW  - backdating
KW  - Mediterranean forest
DO  - 10.3390/rs11030261
ER  -
TY  - EJOU
AU  - Xu, Ziyao
AU  - Lian, Jijian
AU  - Bin, Lingling
AU  - Hua, Kaixun
AU  - Xu, Kui
AU  - Chan, Hoi Y.
TI  - Water Price Prediction for Increasing Market Efficiency Using Random Forest Regression: A Case Study in the Western United States
T2  - Water

PY  - 2019
VL  - 11
IS  - 2
SN  - 2073-4441

AB  - The existence of water markets establishes water prices, promoting trading of water from low- to high-valued uses. However, market participants can face uncertainty when asking and offering prices because water rights are heterogeneous, resulting in inefficiency of the market. This paper proposes three random forest regression models (RFR) to predict water price in the western United States: a full variable set model and two reduced ones with optimal numbers of variables using a backward variable elimination (BVE) approach. Transactions of 12 semiarid states, from 1987 to 2009, and a dataset containing various predictors, were assembled. Multiple replications of k-fold cross-validation were applied to assess the model performance and their generalizability was tested on unused data. The importance of price influencing factors was then analyzed based on two plausible variable importance rankings. Results show that the RFR models have good predictive power for water price. They outperform a baseline model without leading to overfitting. Also, the higher degree of accuracy of the reduced models is insignificant, reflecting the robustness of RFR to including lower informative variables. This study suggests that, due to its ability to automatically learn from and make predictions on data, RFR-based models can aid water market participants in making more efficient decisions.
KW  - water market
KW  - water price prediction
KW  - market efficiency
KW  - random forest regression
KW  - machine learning
DO  - 10.3390/w11020228
ER  -
TY  - EJOU
AU  - Wu, Ruidong
AU  - Liu, Bing
AU  - Fu, Ping
AU  - Li, Junbao
AU  - Feng, Shou
TI  - An Accelerator Architecture of Changeable-Dimension Matrix Computing Method for SVM
T2  - Electronics

PY  - 2019
VL  - 8
IS  - 2
SN  - 2079-9292

AB  - Matrix multiplication is a critical time-consuming processing step in many machine learning applications. Due to the diversity of practical applications, the matrix dimensions are generally not fixed. However, most matrix calculation methods, based on field programmable gate array (FPGA) currently use fixed matrix dimensions, which limit the flexibility of machine learning algorithms in a FPGA. The bottleneck lies in the limited FPGA resources. Therefore, this paper proposes an accelerator architecture for matrix computing method with changeable dimensions. Multi-matrix synchronous calculation concept allows matrix data to be processed continuously, which improves the parallel computing characteristics of FPGA and optimizes the computational efficiency. This paper tests matrix multiplication using support vector machine (SVM) algorithm to verify the performance of proposed architecture on the ZYNQ platform. The experimental results show that, compared to the software processing method, the proposed architecture increases the performance by 21.18 times with 9947 dimensions. The dimension is changeable with a maximum value of 2,097,151, without changing hardware design. This method is also applicable to matrix multiplication processing with other machine learning algorithms.
KW  - changeable-dimension matrix computing
KW  - field programmable gate array (FPGA)
KW  - support vector machine (SVM)
KW  - ZYNQ
DO  - 10.3390/electronics8020143
ER  -
TY  - EJOU
AU  - Zhu, Qing
AU  - Zhang, Junxiao
AU  - Ding, Yulin
AU  - Liu, Mingwei
AU  - Li, Yun
AU  - Feng, Bin
AU  - Miao, Shuangxi
AU  - Yang, Weijun
AU  - He, Huagui
AU  - Zhu, Jun
TI  - Semantics-Constrained Advantageous Information Selection of Multimodal Spatiotemporal Data for Landslide Disaster Assessment
T2  - ISPRS International Journal of Geo-Information

PY  - 2019
VL  - 8
IS  - 2
SN  - 2220-9964

AB  - Although abundant spatiotemporal data are collected before and after landslides, the volume, variety, intercorrelation, and heterogeneity of multimodal data complicates disaster assessments, so it is challenging to select information from multimodal spatiotemporal data that is advantageous for credible and comprehensive disaster assessment. In disaster scenarios, multimodal data exhibit intrinsic relationships, and their interactions can greatly influence selection results. Previous data retrieval methods have mainly focused on candidate ranking while ignoring the generation and evaluation of candidate subsets. In this paper, a semantic-constrained data selection approach is proposed. First, multitype relationships are defined and reasoned through the heterogeneous information network. Then, relevance, redundancy, and complementarity are redefined to evaluate data sets in terms of semantic proximity and similarity. Finally, the approach is tested using Mao County (China) landslide data. The proposed method can automatically and effectively generate suitable datasets for certain tasks rather than simply ranking by similarity, and the selection results are compared with manual results to verify their effectiveness.
KW  - multimodal data
KW  - data retrieval
KW  - data selection
KW  - semantic proximity and similarity
DO  - 10.3390/ijgi8020068
ER  -
TY  - EJOU
AU  - Fu, Yongyong
AU  - Liu, Kunkun
AU  - Shen, Zhangquan
AU  - Deng, Jinsong
AU  - Gan, Muye
AU  - Liu, Xinguo
AU  - Lu, Dongming
AU  - Wang, Ke
TI  - Mapping Impervious Surfaces in Town–Rural Transition Belts Using China’s GF-2 Imagery and Object-Based Deep CNNs
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 3
SN  - 2072-4292

AB  - Impervious surfaces play an important role in urban planning and sustainable environmental management. High-spatial-resolution (HSR) images containing pure pixels have significant potential for the detailed delineation of land surfaces. However, due to high intraclass variability and low interclass distance, the mapping and monitoring of impervious surfaces in complex town&ndash;rural areas using HSR images remains a challenge. The fully convolutional network (FCN) model, a variant of convolution neural networks (CNNs), recently achieved state-of-the-art performance in HSR image classification applications. However, due to the inherent nature of FCN processing, it is challenging for an FCN to precisely capture the detailed information of classification targets. To solve this problem, we propose an object-based deep CNN framework that integrates object-based image analysis (OBIA) with deep CNNs to accurately extract and estimate impervious surfaces. Specifically, we also adopted two widely used transfer learning technologies to expedite the training of deep CNNs. Finally, we compare our approach with conventional OBIA classification and state-of-the-art FCN-based methods, such as FCN-8s and the U-Net methods. Both of these FCN-based methods are well designed for pixel-wise classification applications and have achieved great success. Our results show that the proposed approach effectively identified impervious surfaces, with 93.9% overall accuracy. Compared with the existing methods, i.e., OBIA, FCN-8s and U-Net methods, it shows that our method achieves obviously improvement in accuracy. Our findings also suggest that the classification performance of our proposed method is related to training strategy, indicating that significantly higher accuracy can be achieved through transfer learning by fine-tuning rather than feature extraction. Our approach for the automatic extraction and mapping of impervious surfaces also lays a solid foundation for intelligent monitoring and the management of land use and land cover.
KW  - transfer learning
KW  - remote sensing
KW  - deep learning
KW  - object-based image analysis (OBIA)
DO  - 10.3390/rs11030280
ER  -
TY  - EJOU
AU  - Gebremedhin, Alem
AU  - Badenhorst, Pieter E.
AU  - Wang, Junping
AU  - Spangenberg, German C.
AU  - Smith, Kevin F.
TI  - Prospects for Measurement of Dry Matter Yield in Forage Breeding Programs Using Sensor Technologies
T2  - Agronomy

PY  - 2019
VL  - 9
IS  - 2
SN  - 2073-4395

AB  - Increasing the yield of perennial forage crops remains a crucial factor underpinning the profitability of grazing industries, and therefore is a priority for breeding programs. Breeding for high dry matter yield (DMY) in forage crops is likely to be enhanced with the development of genomic selection (GS) strategies. However, realising the full potential of GS will require an increase in the amount of phenotypic data and the rate at which it is collected. Therefore, phenotyping remains a critical bottleneck in the implementation of GS in forage species. Assessments of DMY in forage crop breeding include visual scores, sample clipping and mowing of plots, which are often costly and time-consuming. New ground- and aerial-based platforms equipped with advanced sensors offer opportunities for fast, nondestructive and low-cost, high-throughput phenotyping (HTP) of plant growth, development and yield in a field environment. The workflow of image acquisition, processing and analysis are reviewed. The &ldquo;big data&rdquo; challenges, proposed storage and management techniques, development of advanced statistical tools and methods for incorporating the HTP into forage breeding systems are also reviewed. Initial results where these techniques have been applied to forages have been promising but further research and development is required to adapt them to forage breeding situations, particularly with respect to the management of large data sets and the integration of information from spaced plants to sward plots. However, realizing the potential of sensor technologies combined with GS leads to greater rates of genetic gain in forages.
KW  - forage dry matter yield
KW  - high-throughput phenotyping
KW  - automation
KW  - imaging and image analysis
DO  - 10.3390/agronomy9020065
ER  -
TY  - EJOU
AU  - Avgeris, Marios
AU  - Spatharakis, Dimitrios
AU  - Dechouniotis, Dimitrios
AU  - Kalatzis, Nikos
AU  - Roussaki, Ioanna
AU  - Papavassiliou, Symeon
TI  - Where There Is Fire There Is SMOKE: A Scalable Edge Computing Framework for Early Fire Detection
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 3
SN  - 1424-8220

AB  - A Cyber-Physical Social System (CPSS) tightly integrates computer systems with the physical world and human activities. In this article, a three-level CPSS for early fire detection is presented to assist public authorities to promptly identify and act on emergency situations. At the bottom level, the system&rsquo;s architecture involves IoT nodes enabled with sensing and forest monitoring capabilities. Additionally, in this level, the crowd sensing paradigm is exploited to aggregate environmental information collected by end user devices present in the area of interest. Since the IoT nodes suffer from limited computational energy resources, an Edge Computing Infrastructure, at the middle level, facilitates the offloaded data processing regarding possible fire incidents. At the top level, a decision-making service deployed on Cloud nodes integrates data from various sources, including users&rsquo; information on social media, and evaluates the situation criticality. In our work, a dynamic resource scaling mechanism for the Edge Computing Infrastructure is designed to address the demanding Quality of Service (QoS) requirements of this IoT-enabled time and mission critical application. The experimental results indicate that the vertical and horizontal scaling on the Edge Computing layer is beneficial for both the performance and the energy consumption of the IoT nodes.
KW  - IoT nodes
KW  - edge computing
KW  - control theory
KW  - resource scaling
KW  - social media
KW  - cyber-physical social system
KW  - fire detection
DO  - 10.3390/s19030639
ER  -
TY  - EJOU
AU  - Salamí, Esther
AU  - Gallardo, Antonia
AU  - Skorobogatov, Georgy
AU  - Barrado, Cristina
TI  - On-the-Fly Olive Tree Counting Using a UAS and Cloud Services
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 3
SN  - 2072-4292

AB  - Unmanned aerial systems (UAS) are becoming a common tool for aerial sensing applications. Nevertheless, sensed data need further processing before becoming useful information. This processing requires large computing power and time before delivery. In this paper, we present a parallel architecture that includes an unmanned aerial vehicle (UAV), a small embedded computer on board, a communication link to the Internet, and a cloud service with the aim to provide useful real-time information directly to the end-users. The potential of parallelism as a solution in remote sensing has not been addressed for a distributed architecture that includes the UAV processors. The architecture is demonstrated for a specific problem: the counting of olive trees in a crop field where the trees are regularly spaced from each other. During the flight, the embedded computer is able to process individual images on board the UAV and provide the total count. The tree counting algorithm obtains an     F 1     score of     99.09 %     for a sequence of ten images with 332 olive trees. The detected trees are geolocated and can be visualized on the Internet seconds after the take-off of the flight, with no further processing required. This is a use case to demonstrate near real-time results obtained from UAS usage. Other more complex UAS applications, such as tree inventories, search and rescue, fire detection, or stock breeding, can potentially benefit from this architecture and obtain faster outcomes, accessible while the UAV is still on flight.
KW  - UAS
KW  - UAV
KW  - image segmentation
KW  - tree counting
KW  - distributed services
KW  - cloud computing
DO  - 10.3390/rs11030316
ER  -
TY  - EJOU
AU  - Al-Kaff, Abdulla
AU  - Gómez-Silva, María J.
AU  - Moreno, Francisco M.
AU  - de la Escalera, Arturo
AU  - Armingol, José M.
TI  - An Appearance-Based Tracking Algorithm for Aerial Search and Rescue Purposes
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 3
SN  - 1424-8220

AB  - The automation of the Wilderness Search and Rescue (WiSAR) task aims for high levels of understanding of various scenery. In addition, working in unfriendly and complex environments may cause a time delay in the operation and consequently put human lives at stake. In order to address this problem, Unmanned Aerial Vehicles (UAVs), which provide potential support to the conventional methods, are used. These vehicles are provided with reliable human detection and tracking algorithms; in order to be able to find and track the bodies of the victims in complex environments, and a robust control system to maintain safe distances from the detected bodies. In this paper, a human detection based on the color and depth data captured from onboard sensors is proposed. Moreover, the proposal of computing data association from the skeleton pose and a visual appearance measurement allows the tracking of multiple people with invariance to the scale, translation and rotation of the point of view with respect to the target objects. The system has been validated with real and simulation experiments, and the obtained results show the ability to track multiple individuals even after long-term disappearances. Furthermore, the simulations present the robustness of the implemented reactive control system as a promising tool for assisting the pilot to perform approaching maneuvers in a safe and smooth manner.
KW  - multi-object tracking
KW  - UAV
KW  - rescue
KW  - reactive control
DO  - 10.3390/s19030652
ER  -
TY  - EJOU
AU  - Sagan, Vasit
AU  - Maimaitijiang, Maitiniyazi
AU  - Sidike, Paheding
AU  - Eblimit, Kevin
AU  - Peterson, Kyle T.
AU  - Hartling, Sean
AU  - Esposito, Flavio
AU  - Khanal, Kapil
AU  - Newcomb, Maria
AU  - Pauli, Duke
AU  - Ward, Rick
AU  - Fritschi, Felix
AU  - Shakoor, Nadia
AU  - Mockler, Todd
TI  - UAV-Based High Resolution Thermal Imaging for Vegetation Monitoring, and Plant Phenotyping Using ICI 8640 P, FLIR Vue Pro R 640, and thermoMap Cameras
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 3
SN  - 2072-4292

AB  - The growing popularity of Unmanned Aerial Vehicles (UAVs) in recent years, along with decreased cost and greater accessibility of both UAVs and thermal imaging sensors, has led to the widespread use of this technology, especially for precision agriculture and plant phenotyping. There are several thermal camera systems in the market that are available at a low cost. However, their efficacy and accuracy in various applications has not been tested. In this study, three commercially available UAV thermal cameras, including ICI 8640 P-series (Infrared Cameras Inc., USA), FLIR Vue Pro R 640 (FLIR Systems, USA), and thermoMap (senseFly, Switzerland) have been tested and evaluated for their potential for forest monitoring, vegetation stress detection, and plant phenotyping. Mounted on multi-rotor or fixed wing systems, these cameras were simultaneously flown over different experimental sites located in St. Louis, Missouri (forest environment), Columbia, Missouri (plant stress detection and phenotyping), and Maricopa, Arizona (high throughput phenotyping). Thermal imagery was calibrated using procedures that utilize a blackbody, handheld thermal spot imager, ground thermal targets, emissivity and atmospheric correction. A suite of statistical analyses, including analysis of variance (ANOVA), correlation analysis between camera temperature and plant biophysical and biochemical traits, and heritability were utilized in order to examine the sensitivity and utility of the cameras against selected plant phenotypic traits and in the detection of plant water stress. In addition, in reference to quantitative assessment of image quality from different thermal cameras, a non-reference image quality evaluator, which primarily measures image focus that is based on the spatial relationship of pixels in different scales, was developed. Our results show that (1) UAV-based thermal imaging is a viable tool in precision agriculture and (2) the three examined cameras are comparable in terms of their efficacy for plant phenotyping. Overall, accuracy, when compared against field measured ground temperature and estimating power of plant biophysical and biochemical traits, the ICI 8640 P-series performed better than the other two cameras, followed by FLIR Vue Pro R 640 and thermoMap cameras. Our results demonstrated that all three UAV thermal cameras provide useful temperature data for precision agriculture and plant phenotying, with ICI 8640 P-series presenting the best results among the three systems. Cost wise, FLIR Vue Pro R 640 is more affordable than the other two cameras, providing a less expensive option for a wide range of applications.
KW  - thermal imaging
KW  - ICI 8640 P-series
KW  - FLIR Vue Pro R 640
KW  - thermoMap
KW  - Unmanned Aerial Vehicles
KW  - vegetation monitoring
KW  - plant phenotyping
KW  - heritability analysis
DO  - 10.3390/rs11030330
ER  -
TY  - EJOU
AU  - Jayathunga, Sadeepa
AU  - Owari, Toshiaki
AU  - Tsuyuki, Satoshi
TI  - Digital Aerial Photogrammetry for Uneven-Aged Forest Management: Assessing the Potential to Reconstruct Canopy Structure and Estimate Living Biomass
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 3
SN  - 2072-4292

AB  - Scientifically robust yet economical and efficient methods are required to gather information about larger areas of uneven-aged forest resources, particularly at the landscape level, to reduce deforestation and forest degradation and to support the sustainable management of forest resources. In this study, we examined the potential of digital aerial photogrammetry (DAP) for assessing uneven-aged forest resources. Specifically, we tested the performance of biomass estimation by varying the conditions of several factors, e.g., image downscaling, vegetation metric extraction (point cloud- and canopy height model (CHM)-derived), modeling method ((simple linear regression (SLR), multiple linear regression (MLR), and random forest (RF)), and season (leaf-on and leaf-off). We built dense point clouds and CHMs using high-resolution aerial imagery collected in leaf-on and leaf-off conditions of an uneven-aged mixed conifer&ndash;broadleaf forest. DAP-derived vegetation metrics were then used to predict the dominant height and living biomass (total, conifer, and broadleaf) at the plot level. Our results demonstrated that image downscaling had a negative impact on the accuracy of the dominant height and biomass estimation in leaf-on conditions. In comparison to CHM-derived vegetation metrics, point cloud-derived metrics performed better in dominant height and biomass (total and conifer) estimations. Although the SLR (%RMSE = 21.1) and MLR (%RMSE = 18.1) modeling methods produced acceptable results for total biomass estimations, RF modeling significantly improved the plot-level total biomass estimation accuracy (%RMSE of 12.0 for leaf-on data). Overall, leaf-on DAP performed better in total biomass estimation compared to leaf-off DAP (%RMSE of 15.0 using RF modeling). Nevertheless, conifer biomass estimation accuracy improved when leaf-off data were used (from a %RMSE of 32.1 leaf-on to 23.8 leaf-off using RF modeling). Leaf-off DAP had a negative impact on the broadleaf biomass estimation (%RMSE &gt; 35% for SLR, MLR, and RF modeling). Our results demonstrated that the performance of forest biomass estimation for uneven-aged forests varied with statistical representations as well as data sources. Thus, it would be appropriate to explore different statistical approaches (e.g., parametric and nonparametric) and data sources (e.g., different image resolutions, vegetation metrics, and leaf-on and leaf-off data) to inform the interpretation of remotely sensed data for biomass estimation for uneven-aged forest resources.
KW  - unmanned aerial vehicle
KW  - mixed conifer–broadleaf forest
KW  - leaf-off imagery
DO  - 10.3390/rs11030338
ER  -
TY  - EJOU
AU  - Chen, Chaoyue
AU  - Gong, Weiguo
AU  - Chen, Yongliang
AU  - Li, Weihong
TI  - Object Detection in Remote Sensing Images Based on a Scene-Contextual Feature Pyramid Network
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 3
SN  - 2072-4292

AB  - Object detection has attracted increasing attention in the field of remote sensing image analysis. Complex backgrounds, vertical views, and variations in target kind and size in remote sensing images make object detection a challenging task. In this work, considering that the types of objects are often closely related to the scene in which they are located, we propose a convolutional neural network (CNN) by combining scene-contextual information for object detection. Specifically, we put forward the scene-contextual feature pyramid network (SCFPN), which aims to strengthen the relationship between the target and the scene and solve problems resulting from variations in target size. Additionally, to improve the capability of feature extraction, the network is constructed by repeating a building aggregated residual block. This block increases the receptive field, which can extract richer information for targets and achieve excellent performance with respect to small object detection. Moreover, to improve the proposed model performance, we use group normalization, which divides the channels into groups and computes the mean and variance for normalization within each group, to solve the limitation of the batch normalization. The proposed method is validated on a public and challenging dataset. The experimental results demonstrate that our proposed method outperforms other state-of-the-art object detection models.
KW  - convolutional neural network (CNN)
KW  - object detection
KW  - remote sensing images
KW  - scene-contextual feature pyramid network (SCFPN)
DO  - 10.3390/rs11030339
ER  -
TY  - EJOU
AU  - Cao, Lin
AU  - Liu, Hao
AU  - Fu, Xiaoyao
AU  - Zhang, Zhengnan
AU  - Shen, Xin
AU  - Ruan, Honghua
TI  - Comparison of UAV LiDAR and Digital Aerial Photogrammetry Point Clouds for Estimating Forest Structural Attributes in Subtropical Planted Forests
T2  - Forests

PY  - 2019
VL  - 10
IS  - 2
SN  - 1999-4907

AB  - Estimating forest structural attributes of planted forests plays a key role in managing forest resources, monitoring carbon stocks, and mitigating climate change. High-resolution and low-cost remote-sensing data are increasingly available to measure three-dimensional (3D) canopy structure and model forest structural attributes. In this study, we compared two suites of point cloud metrics and the accuracies of predictive models of forest structural attributes using unmanned aerial vehicle (UAV) light detection and ranging (LiDAR) and digital aerial photogrammetry (DAP) data, in a subtropical coastal planted forest of East China. A comparison between UAV-LiDAR and UAV-DAP metrics was performed across plots among different tree species, heights, and stem densities. The results showed that a higher similarity between the UAV-LiDAR and UAV-DAP metrics appeared in the dawn redwood plots with greater height and lower stem density. The comparison between the UAV-LiDAR and DAP metrics showed that the metrics of the upper percentiles (r for dawn redwood = 0.95&ndash;0.96, poplar = 0.94&ndash;0.95) showed a stronger correlation than the lower percentiles (r = 0.92&ndash;0.93, 0.90&ndash;0.92), whereas the metrics of upper canopy return density (r = 0.21&ndash;0.24, 0.14&ndash;0.15) showed a weaker correlation than those of lower canopy return density (r = 0.32&ndash;0.68, 0.31&ndash;0.52). The Weibull &alpha; parameter indicated a higher correlation (r = 0.70&ndash;0.72) than that of the Weibull &beta; parameter (r = 0.07&ndash;0.60) for both dawn redwood and poplar plots. The accuracies of UAV-LiDAR (adjusted (Adj)R2 = 0.58&ndash;0.91, relative root-mean-square error (rRMSE) = 9.03%&ndash;24.29%) predicted forest structural attributes were higher than UAV-DAP (Adj-R2 = 0.52&ndash;0.83, rRMSE = 12.20%&ndash;25.84%). In addition, by comparing the forest structural attributes between UAV-LiDAR and UAV-DAP predictive models, the greatest difference was found for volume (&Delta;Adj-R2 = 0.09, &Delta;rRMSE = 4.20%), whereas the lowest difference was for basal area (&Delta;Adj-R2 = 0.03, &Delta;rRMSE = 0.86%). This study proved that the UAV-DAP data are useful and comparable to LiDAR for forest inventory and sustainable forest management in planted forests, by providing accurate estimations of forest structural attributes.
KW  - unmanned aerial vehicle
KW  - LiDAR
KW  - digital aerial photogrammetry
KW  - forest structural attributes
KW  - planted forest
DO  - 10.3390/f10020145
ER  -
TY  - EJOU
AU  - Khan, Muhammad A.
AU  - Qureshi, Ijaz M.
AU  - Khanzada, Fahimullah
TI  - A Hybrid Communication Scheme for Efficient and Low-Cost Deployment of Future Flying Ad-Hoc Network (FANET)
T2  - Drones

PY  - 2019
VL  - 3
IS  - 1
SN  - 2504-446X

AB  - In recent years, FANET-related research and development has doubled, due to the increased demands of unmanned aerial vehicles (UAVs) in both military and civilian operations. Equipped with more capabilities and unique characteristics, FANET is able to play a vital role in mission-critical applications. However, these distinctive features enforce a series of guidelines to be considered for its efficient deployment. Particularly, the use of FANET for on-time data communication services presents demanding challenges in terms of energy efficiency and quality of service (QoS). Proper use of communication architecture and wireless technology will assist to solve these challenges. Therefore, in this paper, we review different communication architectures, including the existing wireless technologies, in order to provide seamless wireless connectivity. Based on the discussions, we conclude that a multi-layer UAV ad-hoc network is the most suitable architecture for networking a group of heterogeneous UAVs, while Bluetooth 5 (802.15.1) is the most favored option because of its low-cost, low power consumption, and longer transmission range for FANET. However, 802.15.1 has the limitation of a lower data rate as compared to Wi-Fi (802.11). Therefore, we propose a hybrid wireless communication scheme so as to utilize the features of the high data transmission rate of 802.11 and the low-power consumption of 802.15.1. The proposed scheme significantly reduces communication cost and improves the network performance in terms of throughput and delay. Further, simulation results using the Optimized Network Engineering Tool (OPNET) further support the effectiveness of our proposed scheme.
KW  - UAVs
KW  - FANET
KW  - drones
KW  - Bluetooth
KW  - Wi-Fi
KW  - communication architecture
KW  - wireless technologies
KW  - OPNET
DO  - 10.3390/drones3010016
ER  -
TY  - EJOU
AU  - Wang, Li
AU  - Chang, Qingrui
AU  - Li, Fenling
AU  - Yan, Lin
AU  - Huang, Yong
AU  - Wang, Qi
AU  - Luo, Lili
TI  - Effects of Growth Stage Development on Paddy Rice Leaf Area Index Prediction Models
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 3
SN  - 2072-4292

AB  - A in situ hyperspectral dataset containing multiple growth stages over multiple growing seasons was used to build paddy rice leaf area index (LAI) estimation models with a special focus on the effects of paddy rice growth stage development. The univariate regression method applied to the vegetation index (VI), the traditional multivariate calibration method of partial least squares regression (PLSR), and modern machine learning methods such as support vector regression (SVR), random forests (RF), and artificial neural networks (ANN) based on the original and first-derivative hyperspectral data were evaluated in this study for paddy rice LAI estimation. All the models were built on the whole growing season and on each separate vegetative, reproductive and ripening growth stage of paddy rice separately. To ensure a fair comparison, the models of the whole growing season were also validated on data for each separate growth stage of the standalone validation dataset. Moreover, the optimal band pairs for calculating narrowband difference vegetative index (DVI), normalized difference vegetation index (NDVI) and simple ratio vegetation index (SR) were determined for the whole growing season and for each separate growth stage separately. The results showed that for both the whole growing season and for each single growth stage, the red-edge and near-infrared band pairs are optimal for formulating the narrowband DVI, NDVI and SR. Among the four multivariate calibration methods, SVR and RF yielded more accurate results than the other two methods. The SVR and RF models built on first-derivative spectra provided more accurate results than the corresponding models on the original spectra for both whole growing season models and separate growth stage models. Comparing the prediction accuracy based on the whole growing season revealed that the RF and SVR models showed an advantage over the VI models. However, comparing the prediction accuracy based on each growth stage separately showed that the VI models provided more accurate results for the vegetative growth stages. The SVR and RF models provided more accurate results for the ripening growth stage. However, the whole growing season RF model on first-derivative spectra could provide reasonable accuracy for each single growth stage.
KW  - LAI
KW  - paddy rice
KW  - hyperspectral
KW  - machine learning
KW  - vegetation index
KW  - growth stage
DO  - 10.3390/rs11030361
ER  -
TY  - EJOU
AU  - Tabassum, Asma
AU  - Sabatini, Roberto
AU  - Gardi, Alessandro
TI  - Probabilistic Safety Assessment for UAS Separation Assurance and Collision Avoidance Systems
T2  - Aerospace

PY  - 2019
VL  - 6
IS  - 2
SN  - 2226-4310

AB  - The airworthiness certification of aerospace cyber-physical systems traditionally relies on the probabilistic safety assessment as a standard engineering methodology to quantify the potential risks associated with faults in system components. This paper presents and discusses the probabilistic safety assessment of detect and avoid (DAA) systems relying on multiple cooperative and non-cooperative tracking technologies to identify the risk of collision of unmanned aircraft systems (UAS) with other flight vehicles. In particular, fault tree analysis (FTA) is utilized to measure the overall system unavailability for each basic component failure. Considering the inter-dependencies of navigation and surveillance systems, the common cause failure (CCF)-beta model is applied to calculate the system risk associated with common failures. Additionally, an importance analysis is conducted to quantify the safety measures and identify the most significant component failures. Results indicate that the failure in traffic detection by cooperative surveillance systems contribute more to the overall DAA system functionality and that the probability of failure for ownship locatability in cooperative surveillance is greater than its traffic detection function. Although all the sensors individually yield 99.9% operational availability, the implementation of adequate multi-sensor DAA system relying on both cooperative and non-cooperative technologies is shown to be necessary to achieve the desired levels of safety in all possible encounters. These results strongly support the adoption of a unified analytical framework for cooperative/non-cooperative UAS DAA and elicits an evolution of the current certification framework to properly account for artificial intelligence and machine-learning based systems.
KW  - unmanned aircraft systems
KW  - sense and avoid
KW  - unified analytical framework
KW  - ADS-B
KW  - surveillance sensor
KW  - fault tree analysis
KW  - importance measure
DO  - 10.3390/aerospace6020019
ER  -
TY  - EJOU
AU  - Kwak, Geun-Ho
AU  - Park, No-Wook
TI  - Impact of Texture Information on Crop Classification with Machine Learning and UAV Images
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 4
SN  - 2076-3417

AB  - Unmanned aerial vehicle (UAV) images that can provide thematic information at much higher spatial and temporal resolutions than satellite images have great potential in crop classification. Due to the ultra-high spatial resolution of UAV images, spatial contextual information such as texture is often used for crop classification. From a data availability viewpoint, it is not always possible to acquire time-series UAV images due to limited accessibility to the study area. Thus, it is necessary to improve classification performance for situations when a single or minimum number of UAV images are available for crop classification. In this study, we investigate the potential of gray-level co-occurrence matrix (GLCM)-based texture information for crop classification with time-series UAV images and machine learning classifiers including random forest and support vector machine. In particular, the impact of combining texture and spectral information on the classification performance is evaluated for cases that use only one UAV image or multi-temporal images as input. A case study of crop classification in Anbandegi of Korea was conducted for the above comparisons. The best classification accuracy was achieved when multi-temporal UAV images which can fully account for the growth cycles of crops were combined with GLCM-based texture features. However, the impact of the utilization of texture information was not significant. In contrast, when one August UAV image was used for crop classification, the utilization of texture information significantly affected the classification performance. Classification using texture features extracted from GLCM with larger kernel size significantly improved classification accuracy, an improvement of 7.72%p in overall accuracy for the support vector machine classifier, compared with classification based solely on spectral information. These results indicate the usefulness of texture information for classification of ultra-high-spatial-resolution UAV images, particularly when acquisition of time-series UAV images is difficult and only one UAV image is used for crop classification.
KW  - unmanned aerial vehicle
KW  - texture
KW  - gray-level co-occurrence matrix
KW  - machine learning
KW  - crop
DO  - 10.3390/app9040643
ER  -
TY  - EJOU
AU  - Giernacki, Wojciech
TI  - Iterative Learning Method for In-Flight Auto-Tuning of UAV Controllers Based on Basic Sensory Information
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 4
SN  - 2076-3417

AB  - With an increasing number of multirotor unmanned aerial vehicles (UAVs), solutions supporting the improvement in their precision of operation and safety of autonomous flights are gaining importance. They are particularly crucial in transportation tasks, where control systems are required to provide a stable and controllable flight in various environmental conditions, especially after changing the total mass of the UAV (by adding extra load). In the paper, the problem of using only available basic sensory information for fast, locally best, iterative real-time auto-tuning of parameters of fixed-gain altitude controllers is considered. The machine learning method proposed for this purpose is based on a modified zero-order optimization algorithm (golden-search algorithm) and bootstrapping technique. It has been validated in numerous simulations and real-world experiments in terms of its effectiveness in such aspects as: the impact of environmental disturbances (wind gusts); flight with change in mass; and change of sensory information sources in the auto-tuning procedure. The main advantage of the proposed method is that for the trajectory primitives repeatedly followed by an UAV (for programmed controller gains), the method effectively minimizes the selected performance index (cost function). Such a performance index might, e.g., express indirect requirements about tracking quality and energy expenditure. In the paper, a comprehensive description of the method, as well as a wide discussion of the results obtained from experiments conducted in the AeroLab for a low-cost UAV (Bebop 2), are included. The results have confirmed high efficiency of the method at the expected, low computational complexity.
KW  - UAV
KW  - auto-tuning
KW  - machine learning
KW  - iterative learning
KW  - extremum-seeking
KW  - altitude controller
DO  - 10.3390/app9040648
ER  -
TY  - EJOU
AU  - Ancin-Murguzur, Francisco J.
AU  - Taff, Gregory
AU  - Davids, Corine
AU  - Tømmervik, Hans
AU  - Mølmann, Jørgen
AU  - Jørgensen, Marit
TI  - Yield Estimates by a Two-Step Approach Using Hyperspectral Methods in Grasslands at High Latitudes
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 4
SN  - 2072-4292

AB  - Ruminant fodder production in agricultural lands in latitudes above the Arctic Circle is constrained by short and hectic growing seasons with a 24-hour photoperiod and low growth temperatures. The use of remote sensing to measure crop production at high latitudes is hindered by intrinsic challenges, such as a low sun elevation angle and a coastal climate with high humidity, which influences the spectral signatures of the sampled vegetation. We used a portable spectrometer (ASD FieldSpec 3) to assess spectra of grass crops and found that when applying multivariate models to the hyperspectral datasets, results show significant predictability of yields (R2 &gt; 0.55, root mean squared error (RMSE) &lt; 180), even when captured under sub-optimal conditions. These results are consistent both in the full spectral range of the spectrometer (350&ndash;2500 nm) and in the 350&ndash;900 nm spectral range, which is a region more robust against air moisture. Sentinel-2A simulations resulted in moderately robust models that could be used in qualitative assessments of field productivity. In addition, simulation of the upcoming hyperspectral EnMap satellite bands showed its potential applicability to measure yields in northern latitudes both in the full spectral range of the satellite (420&ndash;2450 nm) with similar performance as the Sentinel-2A satellite and in the 420&ndash;900 nm range with a comparable reliability to the portable spectrometer. The combination of EnMap and Sentinel-2A to detect fields with low productivity and portable spectrometers to identify the fields or specific regions of fields with the lowest production can help optimize the management of fodder production in high latitudes.
KW  - remote sensing
KW  - partial least squares (PLS)
KW  - yield
KW  - crop
KW  - grass
KW  - EnMap
KW  - Arctic agriculture
DO  - 10.3390/rs11040400
ER  -
TY  - EJOU
AU  - Ampatzidis, Yiannis
AU  - Partel, Victor
TI  - UAV-Based High Throughput Phenotyping in Citrus Utilizing Multispectral Imaging and Artificial Intelligence
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 4
SN  - 2072-4292

AB  - Traditional plant breeding evaluation methods are time-consuming, labor-intensive, and costly. Accurate and rapid phenotypic trait data acquisition and analysis can improve genomic selection and accelerate cultivar development. In this work, a technique for data acquisition and image processing was developed utilizing small unmanned aerial vehicles (UAVs), multispectral imaging, and deep learning convolutional neural networks to evaluate phenotypic characteristics on citrus crops. This low-cost and automated high-throughput phenotyping technique utilizes artificial intelligence (AI) and machine learning (ML) to: (i) detect, count, and geolocate trees and tree gaps; (ii) categorize trees based on their canopy size; (iii) develop individual tree health indices; and (iv) evaluate citrus varieties and rootstocks. The proposed remote sensing technique was able to detect and count citrus trees in a grove of 4,931 trees, with precision and recall of 99.9% and 99.7%, respectively, estimate their canopy size with overall accuracy of 85.5%, and detect, count, and geolocate tree gaps with a precision and recall of 100% and 94.6%, respectively. This UAV-based technique provides a consistent, more direct, cost-effective, and rapid method to evaluate phenotypic characteristics of citrus varieties and rootstocks.
KW  - UAV
KW  - artificial intelligence
KW  - machine learning
KW  - smart agriculture
KW  - precision agriculture
KW  - neural networks
KW  - deep learning
DO  - 10.3390/rs11040410
ER  -

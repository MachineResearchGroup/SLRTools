TY  - EJOU
AU  - Zhuang, Jiedong
AU  - Dai, Ming
AU  - Chen, Xuruoyan
AU  - Zheng, Enhui
TI  - A Faster and More Effective Cross-View Matching Method of UAV and Satellite Images for UAV Geolocalization
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - Cross-view geolocalization matches the same target in different images from various views, such as views of unmanned aerial vehicles (UAVs) and satellites, which is a key technology for UAVs to autonomously locate and navigate without a positioning system (e.g., GPS and GNSS). The most challenging aspect in this area is the shifting of targets and nonuniform scales among different views. Published methods focus on extracting coarse features from parts of images, but neglect the relationship between different views, and the influence of scale and shifting. To bridge this gap, an effective network is proposed with well-designed structures, referred to as multiscale block attention (MSBA), based on a local pattern network. MSBA cuts images into several parts with different scales, among which self-attention is applied to make feature extraction more efficient. The features of different views are extracted by a multibranch structure, which was designed to make different branches learn from each other, leading to a more subtle relationship between views. The method was implemented with the newest UAV-based geolocalization dataset. Compared with the existing state-of-the-art (SOTA) method, MSBA accuracy improved by almost 10% when the inference time was equal to that of the SOTA method; when the accuracy of MSBA was the same as that of the SOTA method, inference time was shortened by 30%.
KW  - cross-view image matching
KW  - geolocalization
KW  - UAV image localization
KW  - deep neural network
DO  - 10.3390/rs13193979
ER  -
TY  - EJOU
AU  - Kim, Taeheon
AU  - Han, Youkyung
TI  - Integrated Preprocessing of Multitemporal Very-High-Resolution Satellite Images via Conjugate Points-Based Pseudo-Invariant Feature Extraction
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - Multitemporal very-high-resolution (VHR) satellite images are used as core data in the field of remote sensing because they express the topography and features of the region of interest in detail. However, geometric misalignment and radiometric dissimilarity occur when acquiring multitemporal VHR satellite images owing to external environmental factors, and these errors cause various inaccuracies, thereby hindering the effective use of multitemporal VHR satellite images. Such errors can be minimized by applying preprocessing methods such as image registration and relative radiometric normalization (RRN). However, as the data used in image registration and RRN differ, data consistency and computational efficiency are impaired, particularly when processing large amounts of data, such as a large volume of multitemporal VHR satellite images. To resolve these issues, we proposed an integrated preprocessing method by extracting pseudo-invariant features (PIFs), used for RRN, based on the conjugate points (CPs) extracted for image registration. To this end, the image registration was performed using CPs extracted using the speeded-up robust feature algorithm. Then, PIFs were extracted based on the CPs by removing vegetation areas followed by application of the region growing algorithm. Experiments were conducted on two sites constructed under different acquisition conditions to confirm the robustness of the proposed method. Various analyses based on visual and quantitative evaluation of the experimental results were performed from geometric and radiometric perspectives. The results evidence the successful integration of the image registration and RRN preprocessing steps by achieving a reasonable and stable performance.
KW  - multitemporal very-high-resolution satellite image
KW  - image registration
KW  - relative radiometric normalization
KW  - integrated preprocessing
KW  - pseudo invariant features
KW  - conjugate points
DO  - 10.3390/rs13193990
ER  -
TY  - EJOU
AU  - Magallón, Daniel A.
AU  - Castañeda, Carlos E.
AU  - Jurado, Francisco
AU  - Morfin, Onofre A.
TI  - Design of a Neural Super-Twisting Controller to Emulate a Flywheel Energy Storage System
T2  - Energies

PY  - 2021
VL  - 14
IS  - 19
SN  - 1996-1073

AB  - In this work, a neural super-twisting algorithm is applied to the design of a controller for a flywheel energy storage system (FESS) emulator. Emulation of the FESS is achieved through driving a Permanent Magnet Synchronous Machine (PMSM) coupled to a shaft to shaft DC-motor. The emulation of the FESS is carried out by controlling the velocity of the PMSM in the energy storage stag and then by controlling the DC-motor velocity in the energy feedback stage, where the plant’s states of both electrical machines are identified via a neural network. For the neural identification, a Recurrent Wavelet First-Order Neural Network (RWFONN) is proposed. For the design of the velocity controller, a super-twisting algorithm is applied by using a sliding surface as the argument; the latter is designed based on the states of the RWFONN, in combination with the block control linearization technique to the control of the angular velocity from both machines in their respective operation stage. The RWFONN is trained online using the filtered error algorithm. Closed-loop stability analysis is included when assuming boundedness of the synaptic weights. The results obtained from Matlab/Simulink validate the performance of the proposal in the control of an FESS.
KW  - wavelet neural network
KW  - block control form
KW  - filtered error algorithm
KW  - neural super-twisting control
KW  - flywheel energy storage system
DO  - 10.3390/en14196416
ER  -
TY  - EJOU
AU  - Zhao, Jianghong
AU  - Wang, Yinrui
AU  - Cao, Yuee
AU  - Guo, Ming
AU  - Huang, Xianfeng
AU  - Zhang, Ruiju
AU  - Dou, Xintong
AU  - Niu, Xinyu
AU  - Cui, Yuanyuan
AU  - Wang, Jun
TI  - The Fusion Strategy of 2D and 3D Information Based on Deep Learning: A Review
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - Recently, researchers have realized a number of achievements involving deep-learning-based neural networks for the tasks of segmentation and detection based on 2D images, 3D point clouds, etc. Using 2D and 3D information fusion for the advantages of compensation and accuracy improvement has become a hot research topic. However, there are no critical reviews focusing on the fusion strategies of 2D and 3D information integration based on various data for segmentation and detection, which are the basic tasks of computer vision. To boost the development of this research domain, the existing representative fusion strategies are collected, introduced, categorized, and summarized in this paper. In addition, the general structures of different kinds of fusion strategies were firstly abstracted and categorized, which may inspire researchers. Moreover, according to the methods included in this paper, the 2D information and 3D information of different methods come from various kinds of data. Furthermore, suitable datasets are introduced and comparatively summarized to support the relative research. Last but not least, we put forward some open challenges and promising directions for future research.
KW  - fusion strategy
KW  - deep learning
KW  - segmentation
KW  - detection
DO  - 10.3390/rs13204029
ER  -
TY  - EJOU
AU  - Khun, Kosal
AU  - Tremblay, Nicolas
AU  - Panneton, Bernard
AU  - Vigneault, Philippe
AU  - Lord, Etienne
AU  - Cavayas, François
AU  - Codjia, Claude
TI  - Use of Oblique RGB Imagery and Apparent Surface Area of Plants for Early Estimation of Above-Ground Corn Biomass
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - Estimating above-ground biomass in the context of fertilization management requires the monitoring of crops at early stages. Conventional remote sensing techniques make use of vegetation indices such as the normalized difference vegetation index (NDVI), but they do not exploit the high spatial resolution (ground sampling distance &lt; 5 mm) now achievable with the introduction of unmanned aerial vehicles (UAVs) in agriculture. The aim of this study was to compare image mosaics to single images for the estimation of corn biomass and the influence of viewing angles in this estimation. Nadir imagery was captured by a high spatial resolution camera mounted on a UAV to generate orthomosaics of corn plots at different growth stages (from V2 to V7). Nadir and oblique images (30° and 45° with respect to the vertical) were also acquired from a zip line platform and processed as single images. Image segmentation was performed using the difference color index Excess Green-Excess Red, allowing for the discrimination between vegetation and background pixels. The apparent surface area of plants was then extracted and compared to biomass measured in situ. An asymptotic total least squares regression was performed and showed a strong relationship between the apparent surface area of plants and both dry and fresh biomass. Mosaics tended to underestimate the apparent surface area in comparison to single images because of radiometric degradation. It is therefore conceivable to process only single images instead of investing time and effort in acquiring and processing data for orthomosaic generation. When comparing oblique photography, an angle of 30° yielded the best results in estimating corn biomass, with a low residual standard error of orthogonal distance (RSEOD = 0.031 for fresh biomass, RSEOD = 0.034 for dry biomass). Since oblique imagery provides more flexibility in data acquisition with fewer constraints on logistics, this approach might be an efficient way to monitor crop biomass at early stages.
KW  - Zea mays L.
KW  - corn
KW  - biomass
KW  - oblique imagery
KW  - precision agriculture
KW  - low-altitude remote sensing
KW  - UAV
KW  - drone
DO  - 10.3390/rs13204032
ER  -
TY  - EJOU
AU  - Mirmazloumi, S. M.
AU  - Moghimi, Armin
AU  - Ranjgar, Babak
AU  - Mohseni, Farzane
AU  - Ghorbanian, Arsalan
AU  - Ahmadi, Seyed A.
AU  - Amani, Meisam
AU  - Brisco, Brian
TI  - Status and Trends of Wetland Studies in Canada Using Remote Sensing Technology with a Focus on Wetland Classification: A Bibliographic Analysis
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - A large portion of Canada is covered by wetlands; mapping and monitoring them is of great importance for various applications. In this regard, Remote Sensing (RS) technology has been widely employed for wetland studies in Canada over the past 45 years. This study evaluates meta-data to investigate the status and trends of wetland studies in Canada using RS technology by reviewing the scientific papers published between 1976 and the end of 2020 (300 papers in total). Initially, a meta-analysis was conducted to analyze the status of RS-based wetland studies in terms of the wetland classification systems, methods, classes, RS data usage, publication details (e.g., authors, keywords, citations, and publications time), geographic information, and level of classification accuracies. The deep systematic review of 128 peer-reviewed articles illustrated the rising trend in using multi-source RS datasets along with advanced machine learning algorithms for wetland mapping in Canada. It was also observed that most of the studies were implemented over the province of Ontario. Pixel-based supervised classifiers were the most popular wetland classification algorithms. This review summarizes different RS systems and methodologies for wetland mapping in Canada to outline how RS has been utilized for the generation of wetland inventories. The results of this review paper provide the current state-of-the-art methods and datasets for wetland studies in Canada and will provide direction for future wetland mapping research.
KW  - Canada
KW  - classification
KW  - remote sensing
KW  - wetland
DO  - 10.3390/rs13204025
ER  -
TY  - EJOU
AU  - Yu, Run
AU  - Luo, Youqing
AU  - Li, Haonan
AU  - Yang, Liyuan
AU  - Huang, Huaguo
AU  - Yu, Linfeng
AU  - Ren, Lili
TI  - Three-Dimensional Convolutional Neural Network Model for Early Detection of Pine Wilt Disease Using UAV-Based Hyperspectral Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - As one of the most devastating disasters to pine forests, pine wilt disease (PWD) has caused tremendous ecological and economic losses in China. An effective way to prevent large-scale PWD outbreaks is to detect and remove the damaged pine trees at the early stage of PWD infection. However, early infected pine trees do not show obvious changes in morphology or color in the visible wavelength range, making early detection of PWD tricky. Unmanned aerial vehicle (UAV)-based hyperspectral imagery (HI) has great potential for early detection of PWD. However, the commonly used methods, such as the two-dimensional convolutional neural network (2D-CNN), fail to simultaneously extract and fully utilize the spatial and spectral information, whereas the three-dimensional convolutional neural network (3D-CNN) is able to collect this information from raw hyperspectral data. In this paper, we applied the residual block to 3D-CNN and constructed a 3D-Res CNN model, the performance of which was then compared with that of 3D-CNN, 2D-CNN, and 2D-Res CNN in identifying PWD-infected pine trees from the hyperspectral images. The 3D-Res CNN model outperformed the other models, achieving an overall accuracy (OA) of 88.11% and an accuracy of 72.86% for detecting early infected pine trees (EIPs). Using only 20% of the training samples, the OA and EIP accuracy of 3D-Res CNN can still achieve 81.06% and 51.97%, which is superior to the state-of-the-art method in the early detection of PWD based on hyperspectral images. Collectively, 3D-Res CNN was more accurate and effective in early detection of PWD. In conclusion, 3D-Res CNN is proposed for early detection of PWD in this paper, making the prediction and control of PWD more accurate and effective. This model can also be applied to detect pine trees damaged by other diseases or insect pests in the forest.
KW  - pine wilt disease
KW  - early detection
KW  - UAV-based hyperspectral imagery
KW  - 3D-CNN
KW  - 3D-Res CNN
DO  - 10.3390/rs13204065
ER  -
TY  - EJOU
AU  - Nguyen, Lanh V.
AU  - Phung, Manh D.
AU  - Ha, Quang P.
TI  - Iterative Learning Sliding Mode Control for UAV Trajectory Tracking
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 20
SN  - 2079-9292

AB  - This paper presents a novel iterative learning sliding mode controller (ILSMC) that can be applied to the trajectory tracking of quadrotor unmanned aerial vehicles (UAVs) subject to model uncertainties and external disturbances. Here, the proposed ILSMC is integrated in the outer loop of a controlled system. The control development, conducted in the discrete-time domain, does not require a priori information of the disturbance bound as with conventional SMC techniques. It only involves an equivalent control term for the desired dynamics in the closed loop and an iterative learning term to drive the system state toward the sliding surface to maintain robust performance. By learning from previous iterations, the ILSMC can yield very accurate tracking performance when a sliding mode is induced without control chattering. The design is then applied to the attitude control of a 3DR Solo UAV with a built-in PID controller. The simulation results and experimental validation with real-time data demonstrate the advantages of the proposed control scheme over existing techniques.
KW  - iterative learning
KW  - sliding mode control
KW  - unmanned arial vehicles
KW  - trajectory tracking
DO  - 10.3390/electronics10202474
ER  -
TY  - EJOU
AU  - Liu, Hong
AU  - Yu, Tao
AU  - Hu, Bingliang
AU  - Hou, Xingsong
AU  - Zhang, Zhoufeng
AU  - Liu, Xiao
AU  - Liu, Jiacheng
AU  - Wang, Xueji
AU  - Zhong, Jingjing
AU  - Tan, Zhengxuan
AU  - Xia, Shaoxia
AU  - Qian, Bao
TI  - UAV-Borne Hyperspectral Imaging Remote Sensing System Based on Acousto-Optic Tunable Filter for Water Quality Monitoring
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - Unmanned aerial vehicle (UAV) hyperspectral remote sensing technologies have unique advantages in high-precision quantitative analysis of non-contact water surface source concentration. Improving the accuracy of non-point source detection is a difficult engineering problem. To facilitate water surface remote sensing, imaging, and spectral analysis activities, a UAV-based hyperspectral imaging remote sensing system was designed. Its prototype was built, and laboratory calibration and a joint air–ground water quality monitoring activity were performed. The hyperspectral imaging remote sensing system of UAV comprised a light and small UAV platform, spectral scanning hyperspectral imager, and data acquisition and control unit. The spectral principle of the hyperspectral imager is based on the new high-performance acousto-optic tunable (AOTF) technology. During laboratory calibration, the spectral calibration of the imaging spectrometer and image preprocessing in data acquisition were completed. In the UAV air–ground joint experiment, combined with the typical water bodies of the Yangtze River mainstream, the Three Gorges demonstration area, and the Poyang Lake demonstration area, the hyperspectral data cubes of the corresponding water areas were obtained, and geometric registration was completed. Thus, a large field-of-view mosaic and water radiation calibration were realized. A chlorophyl-a (Chl-a) sensor was used to test the actual water control points, and 11 traditional Chl-a sensitive spectrum selection algorithms were analyzed and compared. A random forest algorithm was used to establish a prediction model of water surface spectral reflectance and water quality parameter concentration. Compared with the back propagation neural network, partial least squares, and PSO-LSSVM algorithms, the accuracy of the RF algorithm in predicting Chl-a was significantly improved. The determination coefficient of the training samples was 0.84; root mean square error, 3.19 μg/L; and mean absolute percentage error, 5.46%. The established Chl-a inversion model was applied to UAV hyperspectral remote sensing images. The predicted Chl-a distribution agreed with the field observation results, indicating that the UAV-borne hyperspectral remote sensing water quality monitoring system based on AOTF is a promising remote sensing imaging spectral analysis tool for water.
KW  - hyperspectral imaging
KW  - acousto-optic tunable filter
KW  - UAV platform
KW  - remote sensing
KW  - water quality monitoring
DO  - 10.3390/rs13204069
ER  -
TY  - EJOU
AU  - Yang, Baohua
AU  - Zhu, Yue
AU  - Zhou, Shuaijun
TI  - Accurate Wheat Lodging Extraction from Multi-Channel UAV Images Using a Lightweight Network Model
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 20
SN  - 1424-8220

AB  - The extraction of wheat lodging is of great significance to post-disaster agricultural production management, disaster assessment and insurance subsidies. At present, the recognition of lodging wheat in the actual complex field environment still has low accuracy and poor real-time performance. To overcome this gap, first, four-channel fusion images, including RGB and DSM (digital surface model), as well as RGB and ExG (excess green), were constructed based on the RGB image acquired from unmanned aerial vehicle (UAV). Second, a Mobile U-Net model that combined a lightweight neural network with a depthwise separable convolution and U-Net model was proposed. Finally, three data sets (RGB, RGB + DSM and RGB + ExG) were used to train, verify, test and evaluate the proposed model. The results of the experiment showed that the overall accuracy of lodging recognition based on RGB + DSM reached 88.99%, which is 11.8% higher than that of original RGB and 6.2% higher than that of RGB + ExG. In addition, our proposed model was superior to typical deep learning frameworks in terms of model parameters, processing speed and segmentation accuracy. The optimized Mobile U-Net model reached 9.49 million parameters, which was 27.3% and 33.3% faster than the FCN and U-Net models, respectively. Furthermore, for RGB + DSM wheat lodging extraction, the overall accuracy of Mobile U-Net was improved by 24.3% and 15.3% compared with FCN and U-Net, respectively. Therefore, the Mobile U-Net model using RGB + DSM could extract wheat lodging with higher accuracy, fewer parameters and stronger robustness.
KW  - UAV
KW  - wheat lodging
KW  - deep learning
KW  - lightweight
KW  - digital surface model (DSM)
DO  - 10.3390/s21206826
ER  -
TY  - EJOU
AU  - Mohidem, Nur A.
AU  - Che’Ya, Nik N.
AU  - Juraimi, Abdul S.
AU  - Fazlil Ilahi, Wan F.
AU  - Mohd Roslim, Muhammad H.
AU  - Sulaiman, Nursyazyla
AU  - Saberioon, Mohammadmehdi
AU  - Mohd Noor, Nisfariza
TI  - How Can Unmanned Aerial Vehicles Be Used for Detecting Weeds in Agricultural Fields?
T2  - Agriculture

PY  - 2021
VL  - 11
IS  - 10
SN  - 2077-0472

AB  - Weeds are among the most harmful abiotic factors in agriculture, triggering significant yield loss worldwide. Remote sensing can detect and map the presence of weeds in various spectral, spatial, and temporal resolutions. This review aims to show the current and future trends of UAV applications in weed detection in the crop field. This study systematically searched the original articles published from 1 January 2016 to 18 June 2021 in the databases of Scopus, ScienceDirect, Commonwealth Agricultural Bureaux (CAB) Direct, and Web of Science (WoS) using Boolean string: “weed” AND “Unmanned Aerial Vehicle” OR “UAV” OR “drone”. Out of the papers identified, 144 eligible studies did meet our inclusion criteria and were evaluated. Most of the studies (i.e., 27.42%) on weed detection were carried out during the seedling stage of the growing cycle for the crop. Most of the weed images were captured using red, green, and blue (RGB) camera, i.e., 48.28% and main classification algorithm was machine learning techniques, i.e., 47.90%. This review initially highlighted articles from the literature that includes the crops’ typical phenology stage, reference data, type of sensor/camera, classification methods, and current UAV applications in detecting and mapping weed for different types of crop. This study then provides an overview of the advantages and disadvantages of each sensor and algorithm and tries to identify research gaps by providing a brief outlook at the potential areas of research concerning the benefit of this technology in agricultural industries. Integrated weed management, coupled with UAV application improves weed monitoring in a more efficient and environmentally-friendly way. Overall, this review demonstrates the scientific information required to achieve sustainable weed management, so as to implement UAV platform in the real agricultural contexts.
KW  - precision agriculture
KW  - unmanned aerial vehicle
KW  - weed
DO  - 10.3390/agriculture11101004
ER  -
TY  - EJOU
AU  - Guo, Xuzhan
AU  - Liu, Qingwang
AU  - Sharma, Ram P.
AU  - Chen, Qiao
AU  - Ye, Qiaolin
AU  - Tang, Shouzheng
AU  - Fu, Liyong
TI  - Tree Recognition on the Plantation Using UAV Images with Ultrahigh Spatial Resolution in a Complex Environment
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - The survival rate of seedlings is a decisive factor of afforestation assessment. Generally, ground checking is more accurate than any other methods. However, the survival rate of seedlings can be higher in the growing season, and this can be estimated in a larger area at a relatively lower cost by extracting the tree crown from the unmanned aerial vehicle (UAV) images, which provides an opportunity for monitoring afforestation in an extensive area. At present, studies on extracting individual tree crowns under the complex ground vegetation conditions are limited. Based on the afforestation images obtained by airborne consumer-grade cameras in central China, this study proposes a method of extracting and fusing multiple radii morphological features to obtain the potential crown. A random forest (RF) was used to identify the regions extracted from the images, and then the recognized crown regions were fused selectively according to the distance. A low-cost individual crown recognition framework was constructed for rapid checking of planted trees. The method was tested in two afforestation areas of 5950 m2 and 5840 m2, with a population of 2418 trees (Koelreuteria) in total. Due to the complex terrain of the sample plot, high weed coverage, the crown width of trees, and spacing of saplings vary greatly, which increases both the difficulty and complexity of crown extraction. Nevertheless, recall and F-score of the proposed method reached 93.29%, 91.22%, and 92.24% precisions, respectively, and 2212 trees were correctly recognized and located. The results show that the proposed method is robust to the change of brightness and to splitting up of a multi-directional tree crown, and is an automatic solution for afforestation verification.
KW  - individual trees crown
KW  - multi-radius extraction
KW  - chromatic mapping
KW  - feature extraction
KW  - complex environment
KW  - spectral index
DO  - 10.3390/rs13204122
ER  -
TY  - EJOU
AU  - Bao, Wenxia
AU  - Ren, Yangxun
AU  - Wang, Nian
AU  - Hu, Gensheng
AU  - Yang, Xianjun
TI  - Detection of Abnormal Vibration Dampers on Transmission Lines in UAV Remote Sensing Images with PMA-YOLO
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - The accurate detection and timely replacement of abnormal vibration dampers on transmission lines are critical for the safe and stable operation of power systems. Recently, unmanned aerial vehicles (UAVs) have become widely used to inspect transmission lines. In this paper, we constructed a data set of abnormal vibration dampers (DAVDs) on transmission lines in images obtained by UAVs. There are four types of vibration dampers in this data set, and each vibration damper may be rusty, defective, or normal. The challenges in the detection of abnormal vibration dampers on transmission lines in the images captured by UAVs were as following: the images had a high resolution as well as the objects of vibration dampers were relatively small and sparsely distributed, and the backgrounds of cross stage partial networks of the images were complex due to the fact that the transmission lines were erected in a variety of outdoor environments. Existing methods of ground-based object detection significantly reduced the accuracy when dealing with complex backgrounds and small objects of abnormal vibration dampers detection. To address these issues, we proposed an end-to-end parallel mixed attention You Only Look Once (PMA-YOLO) network to improve the detection performance for abnormal vibration dampers. The parallel mixed attention (PMA) module was introduced and integrated into the YOLOv4 network. This module combines a channel attention block and a spatial attention block, and the convolution results of the input feature maps in parallel, allowing the network to pay more attention to critical regions of abnormal vibration dampers in complex background images. Meanwhile, in view of the problem that abnormal vibration dampers are prone to missing detections, we analyzed the scale and ratio of the ground truth boxes and used the K-means algorithm to re-cluster new anchors for abnormal vibration dampers in images. In addition, we introduced a multi-stage transfer learning strategy to improve the efficiency of the original training method and prevent overfitting by the network. The experimental results showed that the mAP@0.5 for PMA-YOLO in the detection of abnormal vibration dampers reached 93.8% on the test set of DAVD, 3.5% higher than that of YOLOv4. When the multi-stage transfer learning strategy was used, the mAP@0.5 was improved by a further 0.2%.
KW  - objective detection
KW  - vibration dampers
KW  - UAV remote sensing images
KW  - transmission lines
KW  - YOLOv4
KW  - attention mechanism
KW  - transfer learning
DO  - 10.3390/rs13204134
ER  -
TY  - EJOU
AU  - Zhou, Xuan
AU  - Ke, Ruimin
AU  - Yang, Hao
AU  - Liu, Chenxi
TI  - When Intelligent Transportation Systems Sensing Meets Edge Computing: Vision and Challenges
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 20
SN  - 2076-3417

AB  - The widespread use of mobile devices and sensors has motivated data-driven applications that can leverage the power of big data to benefit many aspects of our daily life, such as health, transportation, economy, and environment. Under the context of smart city, intelligent transportation systems (ITS), as a main building block of modern cities, and edge computing (EC), as an emerging computing service that targets addressing the limitations of cloud computing, have attracted increasing attention in the research community in recent years. It is well believed that the application of EC in ITS will have considerable benefits to transportation systems regarding efficiency, safety, and sustainability. Despite the growing trend in ITS and EC research, a big gap in the existing literature is identified: the intersection between these two promising directions has been far from well explored. In this paper, we focus on a critical part of ITS, i.e., sensing, and conducting a review on the recent advances in ITS sensing and EC applications in this field. The key challenges in ITS sensing and future directions with the integration of edge computing are discussed.
KW  - intelligent transportation systems
KW  - sensing technology
KW  - edge computing
KW  - traffic data
DO  - 10.3390/app11209680
ER  -
TY  - EJOU
AU  - Ahmad, Uzair
AU  - Alvino, Arturo
AU  - Marino, Stefano
TI  - A Review of Crop Water Stress Assessment Using Remote Sensing
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - Currently, the world is facing high competition and market risks in improving yield, crop illness, and crop water stress. This could potentially be addressed by technological advancements in the form of precision systems, improvements in production, and through ensuring the sustainability of development. In this context, remote-sensing systems are fully equipped to address the complex and technical assessment of crop production, security, and crop water stress in an easy and efficient way. They provide simple and timely solutions for a diverse set of ecological zones. This critical review highlights novel methods for evaluating crop water stress and its correlation with certain measurable parameters, investigated using remote-sensing systems. Through an examination of previous literature, technologies, and data, we review the application of remote-sensing systems in the analysis of crop water stress. Initially, the study presents the relationship of relative water content (RWC) with equivalent water thickness (EWT) and soil moisture crop water stress. Evapotranspiration and sun-induced chlorophyll fluorescence are then analyzed in relation to crop water stress using remote sensing. Finally, the study presents various remote-sensing technologies used to detect crop water stress, including optical sensing systems, thermometric sensing systems, land-surface temperature-sensing systems, multispectral (spaceborne and airborne) sensing systems, hyperspectral sensing systems, and the LiDAR sensing system. The study also presents the future prospects of remote-sensing systems in analyzing crop water stress and how they could be further improved.
KW  - crop water stress
KW  - hyperspectral
KW  - LiDAR
KW  - multispectral
KW  - optical sensing
KW  - remote sensing
KW  - sentinel-1
KW  - soil moisture
KW  - thermometric sensing
DO  - 10.3390/rs13204155
ER  -
TY  - EJOU
AU  - Muhadi, Nur A.
AU  - Abdullah, Ahmad F.
AU  - Bejo, Siti K.
AU  - Mahadi, Muhammad R.
AU  - Mijic, Ana
TI  - Deep Learning Semantic Segmentation for Water Level Estimation Using Surveillance Camera
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 20
SN  - 2076-3417

AB  - The interest in visual-based surveillance systems, especially in natural disaster applications, such as flood detection and monitoring, has increased due to the blooming of surveillance technology. In this work, semantic segmentation based on convolutional neural networks (CNN) was proposed to identify water regions from the surveillance images. This work presented two well-established deep learning algorithms, DeepLabv3+ and SegNet networks, and evaluated their performances using several evaluation metrics. Overall, both networks attained high accuracy when compared to the measurement data but the DeepLabv3+ network performed better than the SegNet network, achieving over 90% for overall accuracy and IoU metrics, and around 80% for boundary F1 score (BF score), respectively. When predicting new images using both trained networks, the results show that both networks successfully distinguished water regions from the background but the outputs from DeepLabv3+ were more accurate than the results from the SegNet network. Therefore, the DeepLabv3+ network was used for practical application using a set of images captured at five consecutive days in the study area. The segmentation result and water level markers extracted from light detection and ranging (LiDAR) data were overlaid to estimate river water levels and observe the water fluctuation. River water levels were predicted based on the elevation from the predefined markers. The proposed water level framework was evaluated according to Spearman’s rank-order correlation coefficient. The correlation coefficient was 0.91, which indicates a strong relationship between the estimated water level and observed water level. Based on these findings, it can be concluded that the proposed approach has high potential as an alternative monitoring system that offers water region information and water level estimation for flood management and related activities.
KW  - flood detection
KW  - deep learning
KW  - water level estimation
KW  - water segmentation
KW  - CCTV
KW  - CNN
DO  - 10.3390/app11209691
ER  -
TY  - EJOU
AU  - Nguyen, Tran X.
AU  - Rosser, Kent
AU  - Chahl, Javaan
TI  - A Review of Modern Thermal Imaging Sensor Technology and Applications for Autonomous Aerial Navigation
T2  - Journal of Imaging

PY  - 2021
VL  - 7
IS  - 10
SN  - 2313-433X

AB  - Limited navigation capabilities of many current robots and UAVs restricts their applications in GPS denied areas. Large aircraft with complex navigation systems rely on a variety of sensors including radio frequency aids and high performance inertial systems rendering them somewhat resistant to GPS denial. The rapid development of computer vision has seen cameras incorporated into small drones. Vision-based systems, consisting of one or more cameras, could arguably satisfy both size and weight constraints faced by UAVs. A new generation of thermal sensors is available that are lighter, smaller and widely available. Thermal sensors are a solution to enable navigation in difficult environments, including in low-light, dust or smoke. The purpose of this paper is to present a comprehensive literature review of thermal sensors integrated into navigation systems. Furthermore, the physics and characteristics of thermal sensors will also be presented to provide insight into challenges when integrating thermal sensors in place of conventional visual spectrum sensors.
KW  - review
KW  - UAVs
KW  - optical flow
KW  - simultaneous localization and mapping
KW  - SLAM
KW  - thermal imaging
KW  - LWIR
KW  - navigation
KW  - neural network
DO  - 10.3390/jimaging7100217
ER  -
TY  - EJOU
AU  - Koay, Hong V.
AU  - Chuah, Joon H.
AU  - Chow, Chee-Onn
AU  - Chang, Yang-Lang
AU  - Yong, Keh K.
TI  - YOLO-RTUAV: Towards Real-Time Vehicle Detection through Aerial Images with Low-Cost Edge Devices
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Object detection in aerial images has been an active research area thanks to the vast availability of unmanned aerial vehicles (UAVs). Along with the increase of computational power, deep learning algorithms are commonly used for object detection tasks. However, aerial images have large variations, and the object sizes are usually small, rendering lower detection accuracy. Besides, real-time inferencing on low-cost edge devices remains an open-ended question. In this work, we explored the usage of state-of-the-art deep learning object detection on low-cost edge hardware. We propose YOLO-RTUAV, an improved version of YOLOv4-Tiny, as the solution. We benchmarked our proposed models with various state-of-the-art models on the VAID and COWC datasets. Our proposed model can achieve higher mean average precision (mAP) and frames per second (FPS) than other state-of-the-art tiny YOLO models, especially on a low-cost edge device such as the Jetson Nano 2 GB. It was observed that the Jetson Nano 2 GB can achieve up to 12.8 FPS with a model size of only 5.5 MB.
KW  - object detection
KW  - deep learning
KW  - aerial imaging
KW  - real-time detection
DO  - 10.3390/rs13214196
ER  -
TY  - EJOU
AU  - Yermolaev, Oleg
AU  - Usmanov, Bulat
AU  - Gafurov, Artur
AU  - Poesen, Jean
AU  - Vedeneeva, Evgeniya
AU  - Lisetskii, Fedor
AU  - Nicu, Ionut C.
TI  - Assessment of Shoreline Transformation Rates and Landslide Monitoring on the Bank of Kuibyshev Reservoir (Russia) Using Multi-Source Data
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - This study focuses on the Kuibyshev reservoir (Volga River basin, Russia)—the largest in Eurasia and the third in the world by area (6150 km2). The objective of this paper is to quantitatively assess the dynamics of reservoir bank landslides and shoreline abrasion at active zones based on the integrated use of modern instrumental methods (i.e., terrestrial laser scanning—TLS, unmanned aerial vehicle—UAV, and a global navigation satellite system—GNSS) and GIS analysis of historical imagery. A methodology for the application of different methods of instrumental assessment of abrasion and landslide processes is developed. Different approaches are used to assess the intensity of landslide and abrasion processes: the specific volume and material loss index, the planar displacement of the bank scarp, and the planar-altitude analysis of displaced soil material based on the analysis of slope profiles. Historical shoreline position (1958, 1985, and 1987) was obtained from archival aerial photo data, whereas data for 1975, 1993, 2010, 2011, and 2012 were obtained from high-resolution satellite image interpretation. Field surveys of the geomorphic processes from 2002, 2003, 2005, 2006, 2014 were carried out using Trimble M3 and Trimble VX total stations; in 2012–2014 and 2019 TLS and UAV surveys were made, respectively. The monitoring of landslide processes showed that the rate of volumetric changes at Site 1 remained rather stable during the measurement period with net material losses of 0.03–0.04 m−3 m−2 yr−1. The most significant contribution to the average annual value of the material loss was snowmelt runoff. The landslide scarp retreat rate at Site 2 showed a steady decreasing trend, due to partial overgrowth of the landslide accumulation zone resulting in its relative stabilization. The average long-term landslide scarp retreat rate is—2.3 m yr−1. In 2019 earthworks for landscaping at this site have reduced the landslide intensity by more than 2.5 times to—0.84 m yr−1.
KW  - bank erosion
KW  - landslide
KW  - aerial and satellite images
KW  - historical maps
KW  - TLS
KW  - UAV
KW  - Volga
DO  - 10.3390/rs13214214
ER  -
TY  - EJOU
AU  - Jia, Jianxin
AU  - Sun, Haibin
AU  - Jiang, Changhui
AU  - Karila, Kirsi
AU  - Karjalainen, Mika
AU  - Ahokas, Eero
AU  - Khoramshahi, Ehsan
AU  - Hu, Peilun
AU  - Chen, Chen
AU  - Xue, Tianru
AU  - Wang, Tinghuai
AU  - Chen, Yuwei
AU  - Hyyppä, Juha
TI  - Review on Active and Passive Remote Sensing Techniques for Road Extraction
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Digital maps of road networks are a vital part of digital cities and intelligent transportation. In this paper, we provide a comprehensive review on road extraction based on various remote sensing data sources, including high-resolution images, hyperspectral images, synthetic aperture radar images, and light detection and ranging. This review is divided into three parts. Part 1 provides an overview of the existing data acquisition techniques for road extraction, including data acquisition methods, typical sensors, application status, and prospects. Part 2 underlines the main road extraction methods based on four data sources. In this section, road extraction methods based on different data sources are described and analysed in detail. Part 3 presents the combined application of multisource data for road extraction. Evidently, different data acquisition techniques have unique advantages, and the combination of multiple sources can improve the accuracy of road extraction. The main aim of this review is to provide a comprehensive reference for research on existing road extraction technologies.
KW  - road extraction
KW  - high-resolution image
KW  - hyperspectral image
KW  - synthetic aperture radar (SAR)
KW  - light detection and ranging (LiDAR)
DO  - 10.3390/rs13214235
ER  -
TY  - EJOU
AU  - Wang, Cynthia C.
AU  - Wang, Mudan
AU  - Sun, Jun
AU  - Mojtahedi, Mohammad
TI  - A Safety Warning Algorithm Based on Axis Aligned Bounding Box Method to Prevent Onsite Accidents of Mobile Construction Machineries
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 21
SN  - 1424-8220

AB  - Mobile construction machineries are accident-prone on a dynamic construction site, as the site environment is constantly changing and continuous safety monitoring by human beings is impossible. These accidents usually happen in the form of machinery overturning or collapsing into risk areas, including the foundation pit, slopes, or soft soil area. Therefore, preventing mobile construction machineries from entering risk areas is the key. However, currently, there is a lack of practical safety management techniques to achieve this. Utilizing a wireless sensor device to collect the location information of mobile construction machineries, this research develops a safety warning algorithm to prevent the machineries moving into risk area and reduces onsite overturning or collapsing accidents. A modified axis aligned bounding box method is proposed according to the movement patterns of mobile construction machineries, and the warning algorithm is developed based on the onsite safety management regulations. The algorithm is validated in a real case simulation when machinery enters the warning zone. The simulation results showed that the overall algorithm combining the location sensing technology and the modified bounding box method could detect risk and give warnings in a timely manner. This algorithm can be implemented for the safety monitoring of mobile construction machineries in daily onsite management.
KW  - construction machinery
KW  - accident prevention
KW  - axis aligned bounding box method
KW  - location sensing technology
KW  - safety warning algorithm
DO  - 10.3390/s21217075
ER  -
TY  - EJOU
AU  - Grimming, Robert
AU  - Leslie, Patrick
AU  - Burrell, Derek
AU  - Holst, Gerald
AU  - Davis, Brian
AU  - Driggers, Ronald
TI  - Refining Atmosphere Profiles for Aerial Target Detection Models
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 21
SN  - 1424-8220

AB  - Atmospheric path radiance in the infrared is an extremely important quantity in calculating system performance in certain infrared detection systems. For infrared search and track (IRST) system performance calculations, the path radiance competes with the target for precious detector well electrons. In addition, the radiance differential between the target and the path radiance defines the signal level that must be detected. Long-range, high-performance, offensive IRST system design depends on accurate path radiance predictions. In addition, in new applications such as drone detection where a dim unresolved target is embedded into a path radiance background, sensor design and performance are highly dependent on atmospheric path radiance. Being able to predict the performance of these systems under particular weather conditions and locations has long been an important topic. MODTRAN has been a critical tool in the analysis of systems and prediction of electro-optical system performance. The authors have used MODTRAN over many years for an average system performance using the typical “pull-down” conditions in the software. This article considers the level of refinement required for a custom MODTRAN atmosphere profile to satisfactorily model an infrared camera’s performance for a specific geographic location, date, and time. The average difference between a measured sky brightness temperature and a MODTRAN predicted value is less than 0.5 °C with sufficient atmosphere profile updates. The agreement between experimental results and MODTRAN predictions indicates the effectiveness of including updated atmospheric composition, radiosonde, and air quality data from readily available Internet sources to generate custom atmosphere profiles.
KW  - infrared detection
KW  - atmospheric radiation
KW  - path radiance
KW  - sky temperatures
DO  - 10.3390/s21217067
ER  -
TY  - EJOU
AU  - Zhao, Genping
AU  - Zhang, Weiguang
AU  - Peng, Yeping
AU  - Wu, Heng
AU  - Wang, Zhuowei
AU  - Cheng, Lianglun
TI  - PEMCNet: An Efficient Multi-Scale Point Feature Fusion Network for 3D LiDAR Point Cloud Classification
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Point cloud classification plays a significant role in Light Detection and Ranging (LiDAR) applications. However, most available multi-scale feature learning networks for large-scale 3D LiDAR point cloud classification tasks are time-consuming. In this paper, an efficient deep neural architecture denoted as Point Expanded Multi-scale Convolutional Network (PEMCNet) is developed to accurately classify the 3D LiDAR point cloud. Different from traditional networks for point cloud processing, PEMCNet includes successive Point Expanded Grouping (PEG) units and Absolute and Relative Spatial Embedding (ARSE) units for representative point feature learning. The PEG unit enables us to progressively increase the receptive field for each observed point and aggregate the feature of a point cloud at different scales but without increasing computation. The ARSE unit following the PEG unit furthermore realizes representative encoding of points relationship, which effectively preserves the geometric details between points. We evaluate our method on both public datasets (the Urban Semantic 3D (US3D) dataset and Semantic3D benchmark dataset) and our new collected Unmanned Aerial Vehicle (UAV) based LiDAR point cloud data of the campus of Guangdong University of Technology. In comparison with four available state-of-the-art methods, our methods ranked first place regarding both efficiency and accuracy. It was observed on the public datasets that with a 2% increase in classification accuracy, over 26% improvement of efficiency was achieved at the same time compared to the second efficient method. Its potential value is also tested on the newly collected point cloud data with over 91% of classification accuracy and 154 ms of processing time.
KW  - LiDAR
KW  - point cloud
KW  - classification
KW  - deep learning
DO  - 10.3390/rs13214312
ER  -
TY  - EJOU
AU  - Hu, Kai
AU  - Chen, Xu
AU  - Xia, Qingfeng
AU  - Jin, Junlan
AU  - Weng, Liguo
TI  - A Control Algorithm for Sea&ndash;Air Cooperative Observation Tasks Based on a Data-Driven Algorithm
T2  - Journal of Marine Science and Engineering

PY  - 2021
VL  - 9
IS  - 11
SN  - 2077-1312

AB  - There is tremendous demand for marine environmental observation, which requires the development of a multi-agent cooperative observation algorithm to guide Unmanned Surface Vehicles (USVs) and Unmanned Aerial Vehicles (UAVs) to observe isotherm data of the mesoscale vortex. The task include two steps: firstly, USVs search out the isotherm, navigate independently along the isotherm, and collect marine data; secondly, a UAV takes off, and in its one round trip, the UAV and USVs jointly perform the task of the UAV reading the observation data from USVs. In this paper, aiming at the first problem of the USV following the isotherm in an unknown environment, a data-driven Deep Deterministic Policy Gradient (DDPG) control algorithm is designed that allows USVs to navigate independently along isotherms in unknown environments. In addition, a hybrid cooperative control algorithm based on a multi-agent DDPG is adopted to solve the second problem, which enables USVs and a UAV to complete data reading tasks with the shortest flight distance of the UAV. The experimental simulation results show that the trained system can complete this tas, with good stability and accuracy.
KW  - sea and air observation
KW  - multi-agent collaboration
KW  - data-driven
KW  - deep reinforcement learning
DO  - 10.3390/jmse9111189
ER  -
TY  - EJOU
AU  - Xiang, Xuanchen
AU  - Foo, Simon
AU  - Zang, Huanyu
TI  - Recent Advances in Deep Reinforcement Learning Applications for Solving Partially Observable Markov Decision Processes (POMDP) Problems Part 2—Applications in Transportation, Industries, Communications and Networking and More Topics
T2  - Machine Learning and Knowledge Extraction

PY  - 2021
VL  - 3
IS  - 4
SN  - 2504-4990

AB  - The two-part series of papers provides a survey on recent advances in Deep Reinforcement Learning (DRL) for solving partially observable Markov decision processes (POMDP) problems. Reinforcement Learning (RL) is an approach to simulate the human’s natural learning process, whose key is to let the agent learn by interacting with the stochastic environment. The fact that the agent has limited access to the information of the environment enables AI to be applied efficiently in most fields that require self-learning. It’s essential to have an organized investigation—we can make good comparisons and choose the best structures or algorithms when applying DRL in various applications. The first part of the overview introduces Markov Decision Processes (MDP) problems and Reinforcement Learning and applications of DRL for solving POMDP problems in games, robotics, and natural language processing. In part two, we continue to introduce applications in transportation, industries, communications and networking, etc. and discuss the limitations of DRL.
KW  - reinforcement learning
KW  - deep reinforcement learning
KW  - Markov decision process
KW  - partially observable markov decision process
DO  - 10.3390/make3040043
ER  -
TY  - EJOU
AU  - Khan, Rabia M.
AU  - Salehi, Bahram
AU  - Mahdianpari, Masoud
AU  - Mohammadimanesh, Fariba
AU  - Mountrakis, Giorgos
AU  - Quackenbush, Lindi J.
TI  - A Meta-Analysis on Harmful Algal Bloom (HAB) Detection and Monitoring: A Remote Sensing Perspective
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Algae serves as a food source for a wide range of aquatic species; however, a high concentration of inorganic nutrients under favorable conditions can result in the development of harmful algal blooms (HABs). Many studies have addressed HAB detection and monitoring; however, no global scale meta-analysis has specifically explored remote sensing-based HAB monitoring. Therefore, this manuscript elucidates and visualizes spatiotemporal trends in HAB detection and monitoring using remote sensing methods and discusses future insights through a meta-analysis of 420 journal articles. The results indicate an increase in the quantity of published articles which have facilitated the analysis of sensors, software, and HAB proxy estimation methods. The comparison across multiple studies highlighted the need for a standardized reporting method for HAB proxy estimation. Research gaps include: (1) atmospheric correction methods, particularly for turbid waters, (2) the use of analytical-based models, (3) the application of machine learning algorithms, (4) the generation of harmonized virtual constellation and data fusion for increased spatial and temporal resolutions, and (5) the use of cloud-computing platforms for large scale HAB detection and monitoring. The planned hyperspectral satellites will aid in filling these gaps to some extent. Overall, this review provides a snapshot of spatiotemporal trends in HAB monitoring to assist in decision making for future studies.
KW  - harmful algal blooms (HABs)
KW  - meta-analysis
KW  - phytoplankton
KW  - remote sensing
KW  - water quality
DO  - 10.3390/rs13214347
ER  -
TY  - EJOU
AU  - Aguilar, Fernando J.
AU  - Nemmaoui, Abderrahim
AU  - Aguilar, Manuel A.
AU  - Peñalver, Alberto
TI  - Building Tree Allometry Relationships Based on TLS Point Clouds and Machine Learning Regression
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 21
SN  - 2076-3417

AB  - Most of the allometric models used to estimate tree aboveground biomass rely on tree diameter at breast height (DBH). However, it is difficult to measure DBH from airborne remote sensors, and is common to draw upon traditional least squares linear regression models to relate DBH with dendrometric variables measured from airborne sensors, such as tree height (H) and crown diameter (CD). This study explores the usefulness of ensemble-type supervised machine learning regression algorithms, such as random forest regression (RFR), categorical boosting (CatBoost), gradient boosting (GBoost), or AdaBoost regression (AdaBoost), as an alternative to linear regression (LR) for modelling the allometric relationships DBH = Φ(H) and DBH = Ψ(H, CD). The original dataset was made up of 2272 teak trees (Tectona grandis Linn. F.) belonging to three different plantations located in Ecuador. All teak trees were digitally reconstructed from terrestrial laser scanning point clouds. The results showed that allometric models involving both H and CD to estimate DBH performed better than those based solely on H. Furthermore, boosting machine learning regression algorithms (CatBoost and GBoost) outperformed RFR (bagging) and LR (traditional linear regression) models, both in terms of goodness-of-fit (R2) and stability (variations in training and testing samples).
KW  - terrestrial laser scanning
KW  - allometric models
KW  - machine learning regression
KW  - teak plantations
KW  - forest inventory
DO  - 10.3390/app112110139
ER  -
TY  - EJOU
AU  - Raza, Wamiq
AU  - Osman, Anas
AU  - Ferrini, Francesco
AU  - Natale, Francesco D.
TI  - Energy-Efficient Inference on the Edge Exploiting TinyML Capabilities for UAVs
T2  - Drones

PY  - 2021
VL  - 5
IS  - 4
SN  - 2504-446X

AB  - In recent years, the proliferation of unmanned aerial vehicles (UAVs) has increased dramatically. UAVs can accomplish complex or dangerous tasks in a reliable and cost-effective way but are still limited by power consumption problems, which pose serious constraints on the flight duration and completion of energy-demanding tasks. The possibility of providing UAVs with advanced decision-making capabilities in an energy-effective way would be extremely beneficial. In this paper, we propose a practical solution to this problem that exploits deep learning on the edge. The developed system integrates an OpenMV microcontroller into a DJI Tello Micro Aerial Vehicle (MAV). The microcontroller hosts a set of machine learning-enabled inference tools that cooperate to control the navigation of the drone and complete a given mission objective. The goal of this approach is to leverage the new opportunistic features of TinyML through OpenMV including offline inference, low latency, energy efficiency, and data security. The approach is successfully validated on a practical application consisting of the onboard detection of people wearing protection masks in a crowded environment.
KW  - UAVs
KW  - energy efficiency
KW  - TinyML
KW  - microcontrollers
KW  - machine learning
KW  - deep learning
KW  - edge computing
DO  - 10.3390/drones5040127
ER  -
TY  - EJOU
AU  - Lan, Yubin
AU  - Huang, Kanghua
AU  - Yang, Chang
AU  - Lei, Luocheng
AU  - Ye, Jiahang
AU  - Zhang, Jianling
AU  - Zeng, Wen
AU  - Zhang, Yali
AU  - Deng, Jizhong
TI  - Real-Time Identification of Rice Weeds by UAV Low-Altitude Remote Sensing Based on Improved Semantic Segmentation Model
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Real-time analysis of UAV low-altitude remote sensing images at airborne terminals facilitates the timely monitoring of weeds in the farmland. Aiming at the real-time identification of rice weeds by UAV low-altitude remote sensing, two improved identification models, MobileNetV2-UNet and FFB-BiSeNetV2, were proposed based on the semantic segmentation models U-Net and BiSeNetV2, respectively. The MobileNetV2-UNet model focuses on reducing the amount of calculation of the original model parameters, and the FFB-BiSeNetV2 model focuses on improving the segmentation accuracy of the original model. In this study, we first tested and compared the segmentation accuracy and operating efficiency of the models before and after the improvement on the computer platform, and then transplanted the improved models to the embedded hardware platform Jetson AGX Xavier, and used TensorRT to optimize the model structure to improve the inference speed. Finally, the real-time segmentation effect of the two improved models on rice weeds was further verified through the collected low-altitude remote sensing video data. The results show that on the computer platform, the MobileNetV2-UNet model reduced the amount of network parameters, model size, and floating point calculations by 89.12%, 86.16%, and 92.6%, and the inference speed also increased by 2.77 times, when compared with the U-Net model. The FFB-BiSeNetV2 model improved the segmentation accuracy compared with the BiSeNetV2 model and achieved the highest pixel accuracy and mean Intersection over Union ratio of 93.09% and 80.28%. On the embedded hardware platform, the optimized MobileNetV2-UNet model and FFB-BiSeNetV2 model inferred 45.05 FPS and 40.16 FPS for a single image under the weight accuracy of FP16, respectively, both meeting the performance requirements of real-time identification. The two methods proposed in this study realize the real-time identification of rice weeds under low-altitude remote sensing by UAV, which provide a reference for the subsequent integrated operation of plant protection drones in real-time rice weed identification and precision spraying.
KW  - low-altitude remote sensing
KW  - semantic segmentation model
KW  - real-time
KW  - rice weeds
KW  - target spraying
DO  - 10.3390/rs13214370
ER  -
TY  - EJOU
AU  - Sun, Long
AU  - Chen, Jie
AU  - Feng, Dazheng
AU  - Xing, Mengdao
TI  - Parallel Ensemble Deep Learning for Real-Time Remote Sensing Video Multi-Target Detection
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Unmanned aerial vehicle (UAV) is one of the main means of information warfare, such as in battlefield cruises, reconnaissance, and military strikes. Rapid detection and accurate recognition of key targets in UAV images are the basis of subsequent military tasks. The UAV image has characteristics of high resolution and small target size, and in practical application, the detection speed is often required to be fast. Existing algorithms are not able to achieve an effective trade-off between detection accuracy and speed. Therefore, this paper proposes a parallel ensemble deep learning framework for unmanned aerial vehicle video multi-target detection, which is a global and local joint detection strategy. It combines a deep learning target detection algorithm with template matching to make full use of image information. It also integrates multi-process and multi-threading mechanisms to speed up processing. Experiments show that the system has high detection accuracy for targets with focal lengths varying from one to ten times. At the same time, the real-time and stable display of detection results is realized by aiming at the moving UAV video image.
KW  - drone video
KW  - multi-target detection
KW  - multiple focal lengths
KW  - deep learning
KW  - template matching
DO  - 10.3390/rs13214377
ER  -
TY  - EJOU
AU  - Bielecki, Andrzej
AU  - Śmigielski, Piotr
TI  - Three-Dimensional Outdoor Analysis of Single Synthetic Building Structures by an Unmanned Flying Agent Using Monocular Vision
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 21
SN  - 1424-8220

AB  - An algorithm designed for analysis and understanding a 3D urban-type environment by an autonomous flying agent, equipped only with a monocular vision, is presented. The algorithm is hierarchical and is based on the structural representation of the analyzed scene. Firstly, the robot observes the scene from a high altitude to build a 2D representation of a single object and a graph representation of the 2D scene. The 3D representation of each object arises as a consequence of the robot’s actions, as a result of which it projects the object’s solid on different planes. The robot assigns the obtained representations to the corresponding vertex of the created graph. The algorithm was tested by using the embodied robot operating on the real scene. The tests showed that the robot equipped with the algorithm was able not only to localize the predefined object, but also to perform safe, collision-free maneuvers close to the structures in the scene.
KW  - autonomous flying agents
KW  - urban-type scene
KW  - 3D scene representation
KW  - scene analysis
DO  - 10.3390/s21217270
ER  -
TY  - EJOU
AU  - Marinoudi, Vasso
AU  - Lampridi, Maria
AU  - Kateris, Dimitrios
AU  - Pearson, Simon
AU  - Sørensen, Claus G.
AU  - Bochtis, Dionysis
TI  - The Future of Agricultural Jobs in View of Robotization
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 21
SN  - 2071-1050

AB  - Robotics and computerization have drastically changed the agricultural production sector and thus moved it into a new automation era. Robots have historically been used for carrying out routine tasks that require physical strength, accuracy, and repeatability, whereas humans are used to engage with more value-added tasks that need reasoning and decision-making skills. On the other hand, robots are also increasingly exploited in several non-routine tasks that require cognitive skills. This technological evolution will create a fundamental and an unavoidable transformation of the agricultural occupations landscape with a high social and economic impact in terms of jobs creation and jobs destruction. To that effect, the aim of the present work is two-fold: (a) to map agricultural occupations in terms of their cognitive/manual and routine/non-routine characteristics and (b) to assess the susceptibility of each agricultural occupation to robotization. Seventeen (17) agricultural occupations were reviewed in relation to the characteristics of each individual task they entail and mapped onto a two-dimensional space representing the manual versus cognitive nature and the routine versus non-routine nature of an occupation. Subsequently, the potential for robotization was investigated, again concerning each task individually, and resulted in a weighted average potential adoption rate for each one of the agricultural occupations. It can be concluded that most of the occupations entail manual tasks that need to be performed in a standardised manner. Considering also that almost 81% of the agricultural work force is involved with these activities, it turns out that there is strong evidence for possible robotization of 70% of the agricultural domain, which, in turn, could affect 56% of the total annual budget dedicated to agricultural occupations. The presented work silhouettes the expected transformation of occupational landscape in agricultural production as an effort for a subsequent identification of social threats in terms of unemployment and job and wages polarization, among others, but also of opportunities in terms of emerged skills and training requirements for a social sustainable development of agricultural domain.
KW  - agricultural robots
KW  - tasks automatization
KW  - occupations classification
KW  - human-robot substitution
KW  - human-robot complementarity
DO  - 10.3390/su132112109
ER  -
TY  - EJOU
AU  - Manin, Alexander A.
AU  - Sokolov, Sergey V.
AU  - Novikov, Arthur I.
AU  - Polyakova, Marianna V.
AU  - Demidov, Dmitriy N.
AU  - Novikova, Tatyana P.
TI  - Kalman Filter Adaptation to Disturbances of the Observer’s Parameters
T2  - Inventions

PY  - 2021
VL  - 6
IS  - 4
SN  - 2411-5134

AB  - Currently, one of the most effective algorithms for state estimation of stochastic systems is a Kalman filter. This filter provides an optimal root-mean-square error in state vector estimation only when the parameters of the dynamic system and its observer are precisely known. In real conditions, the observer’s parameters are often inaccurately known; moreover, they change randomly over time. This in turn leads to the divergence of the Kalman estimation process. The problem is currently being solved in a variety of ways. They include the use of interval observers, the use of an extended Kalman filter, the introduction of an additional evaluating observer by nonlinear programming methods, robust scaling of the observer’s transmission coefficient, etc. At the same time, it should be borne in mind that, firstly, all of the above ways are focused on application in specific technical systems and complexes, and secondly, they fundamentally do not allow estimating errors in determining the parameters of the observer themselves in order to compensate them for further improving the accuracy and stability of the filtration process of the state vector. To solve this problem, this paper proposes the use of accurate observations that are irregularly received in a complex measuring system (for example, navigation) for adaptive evaluation of the observer’s true parameters of the stochastic system state vector. The development of the proposed algorithm is based on the analytical dependence of the Kalman estimate variation on the observer’s parameters disturbances obtained using the mathematical apparatus for the study of perturbed multidimensional dynamical systems. The developed algorithm for observer’s parameters adaptive estimation makes it possible to significantly increase the accuracy and stability of the stochastic estimation process as a whole in the time intervals between accurate observations, which is illustrated by the corresponding numerical example.
KW  - complexing measurement system
KW  - disturbances
KW  - Kalman filter
KW  - measurement matrix
KW  - multidimensional dynamical systems
KW  - system state vector
KW  - unmanned vehicle
KW  - navigation
DO  - 10.3390/inventions6040080
ER  -
TY  - EJOU
AU  - Filippi, Margaux
AU  - Hanlon, Regina
AU  - Rypina, Irina I.
AU  - Hodges, Benjamin A.
AU  - Peacock, Thomas
AU  - Schmale, David G.
TI  - Tracking a Surrogate Hazardous Agent (Rhodamine Dye) in a Coastal Ocean Environment Using In Situ Measurements and Concentration Estimates Derived from Drone Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - New tools and technology are needed to track hazardous agents such as oil and red tides in our oceans. Rhodamine dye (a surrogate hazardous agent) was released into the Atlantic ocean in August 2018, and experiments were conducted to track the movement of the dye near the water surface within three hours following the release. A DrOne Water Sampling SystEm (DOWSE), consisting of a 3D-printed sampling device tethered to a drone, was used to collect 26 water samples at different locations around the dye plume. Rhodamine concentrations were measured from the drone water samples using a fluorometer and ranged from 1 to 93 ppb. Dye images were taken during the drone-sampling of surface water containing dye and at about 10 m above the sampling point. These images were post-processed to estimate dye concentrations across the sampling domain. A comparison of calibrated heat maps showed that the altitude images yielded dye distributions that were qualitatively similar to those from images taken near the ocean surface. Moreover, the association between red ratios and dye concentrations yielded trendlines explaining up to 67% of the variation. Drones may be used to detect, track and assist in mitigating hazardous agents in the future.
KW  - UAS
KW  - drone
KW  - fluorescent dye
KW  - rhodamine
KW  - transport
KW  - hazardous agents
KW  - plume
KW  - unmanned systems
DO  - 10.3390/rs13214415
ER  -
TY  - EJOU
AU  - Jang, Keunyoung
AU  - Kim, Jong-Woo
AU  - Ju, Ki-Beom
AU  - An, Yun-Kyu
TI  - Infrastructure BIM Platform for Lifecycle Management
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 21
SN  - 2076-3417

AB  - Recently, the application of the BIM technique to infrastructure lifecycle management has increased rapidly to improve the efficiency of infrastructure management systems. Research on the lifecycle management of infrastructure, from planning and design to construction and management, has been carried out. Therefore, a systematic review of the literature on recent research is performed to analyze the current state of the BIM technique. State-of-the-art techniques for infrastructure lifecycle management, such as unmanned robots, sensors and processing techniques, artificial intelligence, etc., are also reviewed. An infrastructure BIM platform framework composed of BIM and state-of-the-art techniques is then proposed. The proposed platform is a web-based platform that contains quantity, schedule (4D), and cost (5D) construction management, and the monitoring systems enable collaboration with stakeholders in a Common Data Environment (CDE). The lifecycle management methodology, after infrastructure construction, is then completed and is developed using state-of-the-art techniques using unmanned robots, scan-to-BIM, and deep learning networks, etc. It is confirmed that collaboration with stakeholders in the CDE in construction management is possible using an infrastructure BIM platform. Moreover, lifecycle management of infrastructure is possible by systematic management, such as time history analysis, damage growth prediction, decision of repair and demolition, etc., using a regular inspection database based on an infrastructure BIM platform.
KW  - Building Information Modeling (BIM)
KW  - infrastructure life cycle management
KW  - Unmanned Aerial Vehicle (UAV)
KW  - scan-to-BIM
KW  - deep learning
KW  - Common Data Environmental (CDE)
DO  - 10.3390/app112110310
ER  -
TY  - EJOU
AU  - Bizjak, Marko
AU  - Žalik, Borut
AU  - Lukač, Niko
TI  - Parameter-Free Half-Spaces Based 3D Building Reconstruction Using Ground and Segmented Building Points from Airborne LiDAR Data with 2D Outlines
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - This paper aims to automatically reconstruct 3D building models on a large scale using a new approach on the basis of half-spaces, while making no assumptions about the building layout and keeping the number of input parameters to a minimum. The proposed algorithm is performed in two stages. First, the airborne LiDAR data and buildings’ outlines are preprocessed to generate buildings’ base models and the corresponding half-spaces. In the second stage, the half-spaces are analysed and used for shaping the final 3D building model using 3D Boolean operations. In experiments, the proposed algorithm was applied on a large scale, and its’ performance was inspected on a city level and on a single building level. Accurate reconstruction of buildings with various layouts were demonstrated and limitations were identified for large-scale applications. Finally, the proposed algorithm was validated on an ISPRS benchmark dataset, where a RMSE of 1.31 m and completeness of 98.9% were obtained.
KW  - building model
KW  - reconstruction
KW  - half-space
KW  - LiDAR data
KW  - urban scale
DO  - 10.3390/rs13214430
ER  -
TY  - EJOU
AU  - Farhadi, Hadi
AU  - Najafzadeh, Mohammad
TI  - Flood Risk Mapping by Remote Sensing Data and Random Forest Technique
T2  - Water

PY  - 2021
VL  - 13
IS  - 21
SN  - 2073-4441

AB  - Detecting effective parameters in flood occurrence is one of the most important issues that has drawn more attention in recent years. Remote Sensing (RS) and Geographical Information System (GIS) are two efficient ways to spatially predict Flood Risk Mapping (FRM). In this study, a web-based platform called the Google Earth Engine (GEE) (Google Company, Mountain View, CA, USA) was used to obtain flood risk indices for the Galikesh River basin, Northern Iran. With the aid of Landsat 8 satellite imagery and the Shuttle Radar Topography Mission (SRTM) Digital Elevation Model (DEM), 11 risk indices (Elevation (El), Slope (Sl), Slope Aspect (SA), Land Use (LU), Normalized Difference Vegetation Index (NDVI), Normalized Difference Water Index (NDWI), Topographic Wetness Index (TWI), River Distance (RD), Waterway and River Density (WRD), Soil Texture (ST]), and Maximum One-Day Precipitation (M1DP)) were provided. In the next step, all of these indices were imported into ArcMap 10.8 (Esri, West Redlands, CA, USA) software for index normalization and to better visualize the graphical output. Afterward, an intelligent learning machine (Random Forest (RF)), which is a robust data mining technique, was used to compute the importance degree of each index and to obtain the flood hazard map. According to the results, the indices of WRD, RD, M1DP, and El accounted for about 68.27 percent of the total flood risk. Among these indices, the WRD index containing about 23.8 percent of the total risk has the greatest impact on floods. According to FRM mapping, about 21 and 18 percent of the total areas stood at the higher and highest risk areas, respectively.
KW  - Remote Sensing
KW  - Google Earth Engine
KW  - Random Forest
KW  - Flood Risk Mapping
DO  - 10.3390/w13213115
ER  -
TY  - EJOU
AU  - Duarte-Vidal, Luz
AU  - Herrera, Rodrigo F.
AU  - Atencio, Edison
AU  - Muñoz-La Rivera, Felipe
TI  - Interoperability of Digital Tools for the Monitoring and Control of Construction Projects
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 21
SN  - 2076-3417

AB  - Monitoring the progress on a construction site during the construction phase is crucial. An inadequate understanding of the project status can lead to mistakes and inappropriate actions, causing delays and increased costs. Monitoring and controlling projects via digital tools would reduce the risk of error and enable timely corrective actions. Although there is currently a wide range of technologies for these purposes, these technologies and interoperability between them are still limited. Because of this, it is important to know the possibilities of integration and interoperability regarding their implementation. This article presents a bibliographic synthesis and interpretation of 30 nonconventional digital tools for monitoring progress in terms of field data capture technologies (FDCT) and communication and collaborative technologies (CT) that are responsible for information processing and management. This research aims to perform an integration and interoperability analysis of technologies to demonstrate their potential for monitoring and controlling construction projects during the execution phase. A network analysis was conducted, and the results suggest that the triad formed by building information modeling (BIM), unmanned aerial vehicles (UAVs) and photogrammetry is an effective tool; the use of this set extends not only to monitoring and control, but also to all phases of a project.
KW  - monitoring progress
KW  - construction phase
KW  - automated monitoring
KW  - digital tools
KW  - as-built
KW  - as-planned
DO  - 10.3390/app112110370
ER  -
TY  - EJOU
AU  - Nazeri, Behrokh
AU  - Crawford, Melba
TI  - Detection of Outliers in LiDAR Data Acquired by Multiple Platforms over Sorghum and Maize
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - High-resolution point cloud data acquired with a laser scanner from any platform contain random noise and outliers. Therefore, outlier detection in LiDAR data is often necessary prior to analysis. Applications in agriculture are particularly challenging, as there is typically no prior knowledge of the statistical distribution of points, plant complexity, and local point densities, which are crop-dependent. The goals of this study were first to investigate approaches to minimize the impact of outliers on LiDAR acquired over agricultural row crops, and specifically for sorghum and maize breeding experiments, by an unmanned aerial vehicle (UAV) and a wheel-based ground platform; second, to evaluate the impact of existing outliers in the datasets on leaf area index (LAI) prediction using LiDAR data. Two methods were investigated to detect and remove the outliers from the plant datasets. The first was based on surface fitting to noisy point cloud data via normal and curvature estimation in a local neighborhood. The second utilized the PointCleanNet deep learning framework. Both methods were applied to individual plants and field-based datasets. To evaluate the method, an F-score was calculated for synthetic data in the controlled conditions, and LAI, the variable being predicted, was computed both before and after outlier removal for both scenarios. Results indicate that the deep learning method for outlier detection is more robust than the geometric approach to changes in point densities, level of noise, and shapes. The prediction of LAI was also improved for the wheel-based vehicle data based on the coefficient of determination (R2) and the root mean squared error (RMSE) of the residuals before and after the removal of outliers.
KW  - outlier removal
KW  - remote sensing
KW  - LiDAR
KW  - leaf area index
KW  - deep learning
DO  - 10.3390/rs13214445
ER  -
TY  - EJOU
AU  - Fu, Chengcai
AU  - Lu, Fengli
AU  - Zhang, Xiaoxiao
AU  - Zhang, Guoying
TI  - Joint Dedusting and Enhancement of Top-Coal Caving Face via Single-Channel Retinex-Based Method with Frequency Domain Prior Information
T2  - Symmetry

PY  - 2021
VL  - 13
IS  - 11
SN  - 2073-8994

AB  - Affected by the uneven concentration of coal dust and low illumination, most of the images captured in the top-coal caving face have low definition, high haze and serious noise. In order to improve the visual effect of underground images captured in the top-coal caving face, a novel single-channel Retinex dedusting algorithm with frequency domain prior information is proposed to solve the problem that Retinex defogging algorithm cannot effectively defog and denoise, simultaneously, while preserving image details. Our work is inspired by the simple and intuitive observation that the low frequency component of dust-free image will be amplified in the symmetrical spectrum after adding dusts. A single-channel multiscale Retinex algorithm with color restoration (MSRCR) in YIQ space is proposed to restore the foggy approximate component in wavelet domain. After that the multiscale convolution enhancement and fast non-local means (FNLM) filter are used to minimize noise of detail components while retaining sufficient details. Finally, a dust-free image is reconstructed to the spatial domain and the color is restored by white balance. By comparing with the state-of-the-art image dedusting and defogging algorithms, the experimental results have shown that the proposed algorithm has higher contrast and visibility in both subjective and objective analysis while retaining sufficient details.
KW  - top-coal caving face
KW  - image dedusting
KW  - frequency domain prior information
KW  - fast single-channel MSRCR
DO  - 10.3390/sym13112097
ER  -
TY  - EJOU
AU  - Rokhafrouz, Mohammad
AU  - Latifi, Hooman
AU  - Abkar, Ali A.
AU  - Wojciechowski, Tomasz
AU  - Czechlowski, Mirosław
AU  - Naieni, Ali S.
AU  - Maghsoudi, Yasser
AU  - Niedbała, Gniewko
TI  - Simplified and Hybrid Remote Sensing-Based Delineation of Management Zones for Nitrogen Variable Rate Application in Wheat
T2  - Agriculture

PY  - 2021
VL  - 11
IS  - 11
SN  - 2077-0472

AB  - Enhancing digital and precision agriculture is currently inevitable to overcome the economic and environmental challenges of the agriculture in the 21st century. The purpose of this study was to generate and compare management zones (MZ) based on the Sentinel-2 satellite data for variable rate application of mineral nitrogen in wheat production, calculated using different remote sensing (RS)-based models under varied soil, yield and crop data availability. Three models were applied, including (1) a modified “RS- and threshold-based clustering”, (2) a “hybrid-based, unsupervised clustering”, in which data from different sources were combined for MZ delineation, and (3) a “RS-based, unsupervised clustering”. Various data processing methods including machine learning were used in the model development. Statistical tests such as the Paired Sample T-test, Kruskal–Wallis H-test and Wilcoxon signed-rank test were applied to evaluate the final delineated MZ maps. Additionally, a procedure for improving models based on information about phenological phases and the occurrence of agricultural drought was implemented. The results showed that information on agronomy and climate enables improving and optimizing MZ delineation. The integration of prior knowledge on new climate conditions (drought) in image selection was tested for effective use of the models. Lack of this information led to the infeasibility of obtaining optimal results. Models that solely rely on remote sensing information are comparatively less expensive than hybrid models. Additionally, remote sensing-based models enable delineating MZ for fertilizer recommendations that are temporally closer to fertilization times.
KW  - precision agriculture
KW  - management zones
KW  - remote sensing
KW  - Sentinel-2
KW  - clustering
KW  - winter wheat
KW  - drought
KW  - digital agriculture
DO  - 10.3390/agriculture11111104
ER  -
TY  - EJOU
AU  - Yang, Mingxin
AU  - Gao, Peng
AU  - Zhou, Ping
AU  - Xie, Jiaxing
AU  - Sun, Daozong
AU  - Han, Xiongzhe
AU  - Wang, Weixing
TI  - Simulating Canopy Temperature Using a Random Forest Model to Calculate the Crop Water Stress Index of Chinese Brassica
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 11
SN  - 2073-4395

AB  - The determination of crop water status has positive effects on the Chinese Brassica industry and irrigation decisions. Drought can decrease the production of Chinese Brassica, whereas over-irrigation can waste water. It is desirable to schedule irrigation when the crop suffers from water stress. In this study, a random forest model was developed using sample data derived from meteorological measurements including air temperature (Ta), relative humidity (RH), wind speed (WS), and photosynthetic active radiation (Par) to predict the lower baseline (Twet) and upper baseline (Tdry) canopy temperatures for Chinese Brassica from 27 November to 31 December 2020 (E1) and from 25 May to 20 June 2021 (E2). Crop water stress index (CWSI) values were determined based on the predicted canopy temperature and used to assess the crop water status. The study demonstrated the viability of using a random forest model to forecast Twet and Tdry. The coefficients of determination (R2) in E1 were 0.90 and 0.88 for development and 0.80 and 0.77 for validation, respectively. The R2 values in E2 were 0.91 and 0.89 for development and 0.83 and 0.80 for validation, respectively. Our results reveal that the measured and predicted CWSI values had similar R2 values related to stomatal conductance (~0.5 in E1, ~0.6 in E2), whereas the CWSI showed a poor correlation with transpiration rate (~0.25 in E1, ~0.2 in E2). Finally, the methodology used to calculate the daily CWSI for Chinese Brassica in this study showed that both Twet and Tdry, which require frequent measuring and design experiment due to the trial site and condition changes, have the potential to simulate environmental parameters and can therefore be applied to conveniently calculate the CWSI.
KW  - Chinese Brassica
KW  - canopy temperature
KW  - crop water stress index
KW  - stomatal conductance
KW  - random forest
DO  - 10.3390/agronomy11112244
ER  -
TY  - EJOU
AU  - Wang, Yanjun
AU  - Li, Shaochun
AU  - Lin, Yunhao
AU  - Wang, Mengjie
TI  - Lightweight Deep Neural Network Method for Water Body Extraction from High-Resolution Remote Sensing Images with Multisensors
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 21
SN  - 1424-8220

AB  - Rapid and accurate extraction of water bodies from high-spatial-resolution remote sensing images is of great value for water resource management, water quality monitoring and natural disaster emergency response. For traditional water body extraction methods, it is difficult to select image texture and features, the shadows of buildings and other ground objects are in the same spectrum as water bodies, the existing deep convolutional neural network is difficult to train, the consumption of computing resources is large, and the methods cannot meet real-time requirements. In this paper, a water body extraction method based on lightweight MobileNetV2 is proposed and applied to multisensor high-resolution remote sensing images, such as GF-2, WorldView-2 and UAV orthoimages. This method was validated in two typical complex geographical scenes: water bodies for farmland irrigation, which have a broken shape and long and narrow area and are surrounded by many buildings in towns and villages; and water bodies in mountainous areas, which have undulating topography, vegetation coverage and mountain shadows all over. The results were compared with those of the support vector machine, random forest and U-Net models and also verified by generalization tests and the influence of spatial resolution changes. First, the results show that the F1-score and Kappa coefficients of the MobileNetV2 model extracting water bodies from three different high-resolution images were 0.75 and 0.72 for GF-2, 0.86 and 0.85 for Worldview-2 and 0.98 and 0.98 for UAV, respectively, which are higher than those of traditional machine learning models and U-Net. Second, the training time, number of parameters and calculation amount of the MobileNetV2 model were much lower than those of the U-Net model, which greatly improves the water body extraction efficiency. Third, in other more complex surface areas, the MobileNetV2 model still maintained relatively high accuracy of water body extraction. Finally, we tested the effects of multisensor models and found that training with lower and higher spatial resolution images combined can be beneficial, but that using just lower resolution imagery is ineffective. This study provides a reference for the efficient automation of water body classification and extraction under complex geographical environment conditions and can be extended to water resource investigation, management and planning.
KW  - water body extraction
KW  - multisensor high-resolution image
KW  - lightweight deep neural network
KW  - MobileNetv2
KW  - deep learning
DO  - 10.3390/s21217397
ER  -
TY  - EJOU
AU  - Kim, Bubryur
AU  - Choi, Se-Woon
AU  - Hu, Gang
AU  - Lee, Dong-Eun
AU  - Serfa Juan, Ronnie O.
TI  - Multivariate Analysis of Concrete Image Using Thermography and Edge Detection
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 21
SN  - 1424-8220

AB  - With the growing demand for structural health monitoring system applications, data imaging is an ideal method for performing regular routine maintenance inspections. Image analysis can provide invaluable information about the health conditions of a structure’s existing infrastructure by recording and analyzing exterior damages. Therefore, it is desirable to have an automated approach that reports defects on images reliably and robustly. This paper presents a multivariate analysis approach for images, specifically for assessing substantial damage (such as cracks). The image analysis provides graph representations that are related to the image, such as the histogram. In addition, image-processing techniques such as grayscale are also implemented, which enhance the object’s information present in the image. In addition, this study uses image segmentation and a neural network, for transforming an image to analyze it more easily and as a classifier, respectively. Initially, each concrete structure image is preprocessed to highlight the crack. A neural network is used to calculate and categorize the visual characteristics of each region, and it shows an accuracy for classification of 98%. Experimental results show that thermal image extraction yields better histogram and cumulative distribution function features. The system can promote the development of various thermal image applications, such as nonphysical visual recognition and fault detection analysis.
KW  - crack analysis
KW  - concrete
KW  - cumulative distribution function
KW  - edge detection
KW  - Sobel edge detection
DO  - 10.3390/s21217396
ER  -
TY  - EJOU
AU  - Wu, Li-Ya
AU  - Weng, Sung-Shun
TI  - Ensemble Learning Models for Food Safety Risk Prediction
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 21
SN  - 2071-1050

AB  - Ensemble learning was adopted to design risk prediction models with the aim of improving border inspection methods for food imported into Taiwan. Specifically, we constructed a set of prediction models to enhance the hit rate of non-conforming products, thus strengthening the border control of food products to safeguard public health. Using five algorithms, we developed models to provide recommendations for the risk assessment of each imported food batch. The models were evaluated by constructing a confusion matrix to calculate predictive performance indicators, including the positive prediction value (PPV), recall, harmonic mean of PPV and recall (F1 score), and area under the curve. Our results showed that ensemble learning achieved better and more stable prediction results than any single algorithm. When the results of comparable data periods were examined, the non-conformity hit rate was found to increase significantly after online implementation of the ensemble learning models, indicating that ensemble learning was effective at risk prediction. In addition to enhancing the inspection hit rate of non-conforming food, the results of this study can serve as a reference for the improvement of existing random inspection methods, thus strengthening capabilities in food risk management.
KW  - food safety
KW  - risk prediction
KW  - border control
KW  - ensemble learning
KW  - machine learning
KW  - bagging
DO  - 10.3390/su132112291
ER  -
TY  - EJOU
AU  - Traore, Adama
AU  - Ata-Ul-Karim, Syed T.
AU  - Duan, Aiwang
AU  - Soothar, Mukesh K.
AU  - Traore, Seydou
AU  - Zhao, Ben
TI  - Predicting Equivalent Water Thickness in Wheat Using UAV Mounted Multispectral Sensor through Deep Learning Techniques
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - The equivalent water thickness (EWT) is an important biophysical indicator of water status in crops. The effective monitoring of EWT in wheat under different nitrogen and water treatments is important for irrigation management in precision agriculture. This study aimed to investigate the performances of machine learning (ML) algorithms in retrieving wheat EWT. For this purpose, a rain shelter experiment (Exp. 1) with four irrigation quantities (0, 120, 240, 360 mm) and two nitrogen levels (75 and 255 kg N/ha), and field experiments (Exps. 2–3) with the same irrigation and rainfall water levels (360 mm) but different nitrogen levels (varying from 75 to 255 kg N/ha) were conducted in the North China Plain. The canopy reflectance was measured for all plots at 30 m using an unmanned aerial vehicle (UAV)-mounted multispectral camera. Destructive sampling was conducted immediately after the UAV flights to measure total fresh and dry weight. Deep Neural Network (DNN) is a special type of neural network, which has shown performance in regression analysis is compared with other machine learning (ML) models. A feature selection (FS) algorithm named the decision tree (DT) was used as the automatic relevance determination method to obtain the relative relevance of 5 out of 67 vegetation indices (Vis), which were used for estimating EWT. The selected VIs were used to estimate EWT using multiple linear regression (MLR), deep neural network multilayer perceptron (DNN-MLP), artificial neural networks multilayer perceptron (ANN-MLP), boosted tree regression (BRT), and support vector machines (SVMs). The results show that the DNN-MLP with R2 = 0.934, NSE = 0.933, RMSE = 0.028 g/cm2, and MAE of 0.017 g/cm2 outperformed other ML algorithms (ANN-MPL, BRT, and SVM- Polynomial) owing to its high capacity for estimating EWT as compared to other ML methods. Our findings support the conclusion that ML can potentially be applied in combination with VIs for retrieving EWT. Despite the complexity of the ML models, the EWT map should help farmers by improving the real-time irrigation efficiency of wheat by quantifying field water content and addressing variability.
KW  - equivalent water thickness
KW  - UAV
KW  - deep learning
KW  - vegetation indices
KW  - multispectral images
DO  - 10.3390/rs13214476
ER  -
TY  - EJOU
AU  - Zhao, Haoran
AU  - Yang, Wenjie
AU  - Zhu, Huibin
TI  - Unmanned Aerial Vehicles Rescue System Design and Traffic Model Planning
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 21
SN  - 2076-3417

AB  - Unmanned Aerial Vehicles (UAV) are widely used in disaster relief and road exploration in recent years. This paper mainly studied the emergency response of UAVs after disasters. The UAV response system is mainly suitable for the distribution of necessities and road exploration after geological disasters and tsunamis in coastal areas. By analyzing the problem and making reasonable assumptions, the optimization model was established with the traffic planning theory, and MATLAB software was used to program and solve the problem. An optimal scheduling scheme was presented to solve these problems. The normalization method was used to select a highly capable UAV. Taking the minimum volume of idle space buffer material as the objective function and taking into account the constraints, such as payload of unmanned aerial vehicle, a single objective programming model was established. The results are as follows: Each International Standards Organization (ISO) cargo container has five UAVs B, one UAV C, one UAV F and one UAV H. It provides 188 days of relief requirements with ISO cargo containers’ space utilization of 71.4%. The research shows that the UAV response system has the functions of necessities distribution and road exploration after disasters, and can be used to deal with the emergency response after disasters in coastal areas, and has a wide range of applicability.
KW  - transportation planning
KW  - optimal design
KW  - normalization method
KW  - single-target planning model
DO  - 10.3390/app112110481
ER  -
TY  - EJOU
AU  - Rakhmatuiln, Ildar
AU  - Kamilaris, Andreas
AU  - Andreasen, Christian
TI  - Deep Neural Networks to Detect Weeds from Crops in Agricultural Environments in Real-Time: A Review
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Automation, including machine learning technologies, are becoming increasingly crucial in agriculture to increase productivity. Machine vision is one of the most popular parts of machine learning and has been widely used where advanced automation and control have been required. The trend has shifted from classical image processing and machine learning techniques to modern artificial intelligence (AI) and deep learning (DL) methods. Based on large training datasets and pre-trained models, DL-based methods have proven to be more accurate than previous traditional techniques. Machine vision has wide applications in agriculture, including the detection of weeds and pests in crops. Variation in lighting conditions, failures to transfer learning, and object occlusion constitute key challenges in this domain. Recently, DL has gained much attention due to its advantages in object detection, classification, and feature extraction. DL algorithms can automatically extract information from large amounts of data used to model complex problems and is, therefore, suitable for detecting and classifying weeds and crops. We present a systematic review of AI-based systems to detect weeds, emphasizing recent trends in DL. Various DL methods are discussed to clarify their overall potential, usefulness, and performance. This study indicates that several limitations obstruct the widespread adoption of AI/DL in commercial applications. Recommendations for overcoming these challenges are summarized.
KW  - deep learning in agriculture
KW  - precision agriculture
KW  - weed detection
KW  - robotic weed control
KW  - machine vision for weed control
DO  - 10.3390/rs13214486
ER  -
TY  - EJOU
AU  - Sun, Biao
AU  - Gu, Zhou
AU  - Xiong, Tianyi
TI  - Event-Triggered Formation Tracking Control for Unmanned Aerial Vehicles Subjected to Deception Attacks
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 22
SN  - 2079-9292

AB  - This study investigates the time-varying formation tracking (TVFT) control problem for multiple unmanned aerial vehicle (multi-UAV) systems under deception attacks by utilizing an event-triggered mechanism (ETM). First, for the sake of alleviating the communication burden, an effective ETM is designed in this paper. Second, to deal with deception attacks in the communication network, a random deception attack model under the designed ETM is constructed. Finally, a novel formation tracking control scheme for multi-UAV systems under deception attack combining the ETM is proposed to achieve the expected TVFT. The stability analysis of the formation control system is given by using the Lyapunov stability theory and linear matrix inequality (LMI) technique. Simulations are conducted to verify the effectiveness of the proposed formation control scheme.
KW  - unmanned aerial vehicle (UAV)
KW  - formation tracking control
KW  - ETM
KW  - deception attacks
DO  - 10.3390/electronics10222736
ER  -
TY  - EJOU
AU  - Zhao, Wenlong
AU  - Meng, Zhijun
AU  - Wang, Kaipeng
AU  - Zhang, Jiahui
AU  - Lu, Shaoze
TI  - Hierarchical Active Tracking Control for UAVs via Deep Reinforcement Learning
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 22
SN  - 2076-3417

AB  - Active tracking control is essential for UAVs to perform autonomous operations in GPS-denied environments. In the active tracking task, UAVs take high-dimensional raw images as input and execute motor actions to actively follow the dynamic target. Most research focuses on three-stage methods, which entail perception first, followed by high-level decision-making based on extracted spatial information of the dynamic target, and then UAV movement control, using a low-level dynamic controller. Perception methods based on deep neural networks are powerful but require considerable effort for manual ground truth labeling. Instead, we unify the perception and decision-making stages using a high-level controller and then leverage deep reinforcement learning to learn the mapping from raw images to the high-level action commands in the V-REP-based environment, where simulation data are infinite and inexpensive. This end-to-end method also has the advantages of a small parameter size and reduced effort requirements for parameter turning in the decision-making stage. The high-level controller, which has a novel architecture, explicitly encodes the spatial and temporal features of the dynamic target. Auxiliary segmentation and motion-in-depth losses are introduced to generate denser training signals for the high-level controller’s fast and stable training. The high-level controller and a conventional low-level PID controller constitute our hierarchical active tracking control framework for the UAVs’ active tracking task. Simulation experiments show that our controller trained with several augmentation techniques sufficiently generalizes dynamic targets with random appearances and velocities, and achieves significantly better performance, compared with three-stage methods.
KW  - unmanned aerial vehicle
KW  - deep reinforcement learning
KW  - visual active tracking
DO  - 10.3390/app112210595
ER  -
TY  - EJOU
AU  - Hu, Aihua
AU  - Deng, Zhongliang
AU  - Yang, Hui
AU  - Zhang, Yao
AU  - Gao, Yuhui
AU  - Zhao, Di
TI  - An Optimal Geometry Configuration Algorithm of Hybrid Semi-Passive Location System Based on Mayfly Optimization Algorithm
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 22
SN  - 1424-8220

AB  - In view of the demand of location awareness in a special complex environment, for an unmanned aerial vehicle (UAV) airborne multi base-station semi-passive positioning system, the hybrid positioning solutions and optimized site layout in the positioning system can effectively improve the positioning accuracy for a specific region. In this paper, the geometric dilution of precision (GDOP) formula of a time difference of arrival (TDOA) and angles of arrival (AOA) hybrid location algorithm is deduced. Mayfly optimization algorithm (MOA) which is a new swarm intelligence optimization algorithm is introduced, and a method to find the optimal station of the UAV airborne multiple base station’s semi-passive positioning system using MOA is proposed. The simulation and analysis of the optimization of the different number of base stations, compared with other station layout methods, such as particle swarm optimization (PSO), genetic algorithm (GA), and artificial bee colony (ABC) algorithm. MOA is less likely to fall into local optimum, and the error of regional target positioning is reduced. By simulating the deployment of four base stations and five base stations in various situations, MOA can achieve a better deployment effect. The dynamic station configuration capability of the multi-station semi-passive positioning system has been improved with the UAV.
KW  - optimal geometry configuration
KW  - semi-passive location
KW  - GDOP
KW  - MOA
KW  - TDOA&AOA
KW  - UAV
DO  - 10.3390/s21227484
ER  -
TY  - EJOU
AU  - Atanassov, Krassimir T.
AU  - Vassilev, Peter
AU  - Atanassova, Vassia
AU  - Roeva, Olympia
AU  - Iliev, Rosen
AU  - Zoteva, Dafina
AU  - Bureva, Veselina
AU  - Mavrov, Deyan
AU  - Alexandrov, Alexander
TI  - Generalized Net Model of Forest Zone Monitoring by UAVs
T2  - Mathematics

PY  - 2021
VL  - 9
IS  - 22
SN  - 2227-7390

AB  - The paper presents a generalized net (GN) model of the process of terrain observation with the help of unmanned aerial vehicles (UAVs) for the prevention and rapid detection of wildfires. Using a GN, the process of monitoring a zone (through a UAV, which is further called a reconnaissance drone) and the localization of forest fires is described. For a more indepth study of the terrain, the reconnaissance drone needs to coordinate with a second UAV, called a specialized drone, so that video and sensory information is provided to the supervising fire command operational center. The proposed GN model was developed to assist in the decision-making process related to the coordination of the operation of both UAVs under dynamically changing terrain circumstances, such as those related to preventing or quickly containing wildfires. It describes the stages (transitions), logical determinants (transition predicate matrices), and directions of information flow (token characteristics) within the process of localization of fires using the pair of reconnaissance and specialized drones.
KW  - drone
KW  - unmanned aerial vehicle
KW  - unmanned aerial system
KW  - wildfire
KW  - forest fire
KW  - fire detection
KW  - fire prevention
KW  - generalized nets
KW  - mathematical modelling
DO  - 10.3390/math9222874
ER  -
TY  - EJOU
AU  - Sadgrove, Edmund J.
AU  - Falzon, Greg
AU  - Miron, David
AU  - Lamb, David W.
TI  - The Segmented Colour Feature Extreme Learning Machine: Applications in Agricultural Robotics
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 11
SN  - 2073-4395

AB  - This study presents the Segmented Colour Feature Extreme Learning Machine (SCF-ELM). The SCF-ELM is inspired by the Extreme Learning Machine (ELM) which is known for its rapid training and inference times. The ELM is therefore an ideal candidate for an ensemble learning algorithm. The Colour Feature Extreme Learning Machine (CF-ELM) is used in this study due to its additional ability to extract colour image features. The SCF-ELM is an ensemble learner that utilizes feature mapping via k-means clustering, a decision matrix and majority voting. It has been evaluated on a range of challenging agricultural object classification scenarios including weed, livestock and machinery detection. SCF-ELM model performance results were excellent both in terms of detection, 90 to 99% accuracy, and also inference times, around 0.01(s) per image. The SCF-ELM was able to compete or improve upon established algorithms in its class, indicating its potential for remote computing applications in agriculture.
KW  - agricultural robotics
KW  - computer vision
KW  - drone
KW  - stationary camera trap
KW  - ensemble
KW  - extreme learning machine
KW  - feature mapping
KW  - object classification
DO  - 10.3390/agronomy11112290
ER  -
TY  - EJOU
AU  - Hassan, Syed-Ali
AU  - Rahim, Tariq
AU  - Shin, Soo-Young
TI  - An Improved Deep Convolutional Neural Network-Based Autonomous Road Inspection Scheme Using Unmanned Aerial Vehicles
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 22
SN  - 2079-9292

AB  - Recent advancements in the field of machine learning (ML) provide opportunity to conduct research on autonomous devices for a variety of applications. Intelligent decision-making is a critical task for self-driving systems. An attempt is made in this study to use a deep learning (DL) approach for the early detection of road cracks, potholes, and the yellow lane. The accuracy is not sufficient after training with the default model. To enhance accuracy, a convolutional neural network (CNN) model with 13 convolutional layers, a softmax layer as an output layer, and two fully connected layers (FCN) are constructed. In order to achieve the deeper propagation and to prevent saturation in the training phase, mish activation is employed in the first 12 layers with a rectified linear unit (ReLU) activation function. The upgraded CNN model performs better than the default CNN model in terms of accuracy. For the varied situation, a revised and enriched dataset for road cracks, potholes, and the yellow lane is created. The yellow lane is detected and tracked in order to move the unmanned aerial vehicle (UAV) autonomously by following yellow lane. After identifying a yellow lane, the UAV performs autonomous navigation while concurrently detecting road cracks and potholes using the robot operating system within the UAV. The performance model is benchmarked using performance measures, such as accuracy, sensitivity, F1-score, F2-score, and dice-coefficient, which demonstrate that the suggested technique produces better outcomes.
KW  - autonomous navigation
KW  - autonomous road inspection
KW  - computer vision
KW  - drone
KW  - robots
KW  - neural network
KW  - UAV
DO  - 10.3390/electronics10222764
ER  -
TY  - EJOU
AU  - Rosle, Rhushalshafira
AU  - Che’Ya, Nik N.
AU  - Ang, Yuhao
AU  - Rahmat, Fariq
AU  - Wayayok, Aimrun
AU  - Berahim, Zulkarami
AU  - Fazlil Ilahi, Wan F.
AU  - Ismail, Mohd R.
AU  - Omar, Mohamad H.
TI  - Weed Detection in Rice Fields Using Remote Sensing Technique: A Review
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 22
SN  - 2076-3417

AB  - This paper reviewed the weed problems in agriculture and how remote sensing techniques can detect weeds in rice fields. The comparison of weed detection between traditional practices and automated detection using remote sensing platforms is discussed. The ideal stage for controlling weeds in rice fields was highlighted, and the types of weeds usually found in paddy fields were listed. This paper will discuss weed detection using remote sensing techniques, and algorithms commonly used to differentiate them from crops are deliberated. However, weed detection in rice fields using remote sensing platforms is still in its early stages; weed detection in other crops is also discussed. Results show that machine learning (ML) and deep learning (DL) remote sensing techniques have successfully produced a high accuracy map for detecting weeds in crops using RS platforms. Therefore, this technology positively impacts weed management in many aspects, especially in terms of the economic perspective. The implementation of this technology into agricultural development could be extended further.
KW  - invasive plants
KW  - precision agriculture
KW  - remote sensing
KW  - rice farming
KW  - site-specific weed management
DO  - 10.3390/app112210701
ER  -
TY  - EJOU
AU  - da Silva, José R.
AU  - Pacheco, Gefeson M.
TI  - An Extended Methodology for Sizing Solar Unmanned Aerial Vehicles: Theory and Development of a Python Framework for Design Assist
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 22
SN  - 1424-8220

AB  - There is a growing interest in using unmanned aerial vehicles (UAVs) in the most diverse application areas from agriculture to remote sensing, that determine the need to project and define mission profiles of the UAVs. In addition, solar photovoltaic energy increases the flight autonomy of this type of aircraft, forming the term Solar UAV. This study proposes an extended methodology for sizing Solar UAVs that take off from a runway. This methodology considers mission parameters such as operating location, altitude, flight speed, flight endurance, and payload to sizing the aircraft parameters, such as wingspan, area of embedded solar cells panels, runway length required for takeoff and landing, battery weight, and the total weight of the aircraft. Using the Python language, we developed a framework to apply the proposed methodology and assist in designing a Solar UAV. With this framework, it was possible to perform a sensitivity analysis of design parameters and constraints. Finally, we performed a simulation of a mission, checking the output parameters.
KW  - photovoltaic generators
KW  - solar cell
KW  - solar unmanned aerial vehicles
KW  - Python
KW  - aircraft design
DO  - 10.3390/s21227541
ER  -
TY  - EJOU
AU  - Lei, Shuhan
AU  - Luo, Jianbiao
AU  - Tao, Xiaojun
AU  - Qiu, Zixuan
TI  - Remote Sensing Detecting of Yellow Leaf Disease of Arecanut Based on UAV Multisource Sensors
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 22
SN  - 2072-4292

AB  - Unmanned aerial vehicle (UAV) remote sensing technology can be used for fast and efficient monitoring of plant diseases and pests, but these techniques are qualitative expressions of plant diseases. However, the yellow leaf disease of arecanut in Hainan Province is similar to a plague, with an incidence rate of up to 90% in severely affected areas, and a qualitative expression is not conducive to the assessment of its severity and yield. Additionally, there exists a clear correlation between the damage caused by plant diseases and pests and the change in the living vegetation volume (LVV). However, the correlation between the severity of the yellow leaf disease of arecanut and LVV must be demonstrated through research. Therefore, this study aims to apply the multispectral data obtained by the UAV along with the high-resolution UAV remote sensing images to obtain five vegetation indexes such as the normalized difference vegetation index (NDVI), optimized soil adjusted vegetation index (OSAVI), leaf chlorophyll index (LCI), green normalized difference vegetation index (GNDVI), and normalized difference red edge (NDRE) index, and establish five algorithm models such as the back-propagation neural network (BPNN), decision tree, naïve Bayes, support vector machine (SVM), and k-nearest-neighbor classification to determine the severity of the yellow leaf disease of arecanut, which is expressed by the proportion of the yellowing area of a single areca crown (in percentage). The traditional qualitative expression of this disease is transformed into the quantitative expression of the yellow leaf disease of arecanut per plant. The results demonstrate that the classification accuracy of the test set of the BPNN algorithm and SVM algorithm is the highest, at 86.57% and 86.30%, respectively. Additionally, the UAV structure from motion technology is used to measure the LVV of a single areca tree and establish a model of the correlation between the LVV and the severity of the yellow leaf disease of arecanut. The results show that the relative root mean square error is between 34.763% and 39.324%. This study presents the novel quantitative expression of the severity of the yellow leaf disease of arecanut, along with the correlation between the LVV of areca and the severity of the yellow leaf disease of arecanut. Significant development is expected in the degree of integration of multispectral software and hardware, observation accuracy, and ease of use of UAVs owing to the rapid progress of spectral sensing technology and the image processing and analysis algorithms.
KW  - yellow leaf disease of arecanut
KW  - unmanned aerial vehicle
KW  - machine learning
KW  - multisource data fusion
KW  - remote sensing quantitative monitoring
DO  - 10.3390/rs13224562
ER  -
TY  - EJOU
AU  - Song, Huan
AU  - Hu, Yongguang
AU  - Lu, Yongzong
AU  - Wang, Jizhang
AU  - Pan, Qingmin
AU  - Li, Pingping
TI  - A Review of Methods and Techniques for Detecting Frost on Plant Surfaces
T2  - Agriculture

PY  - 2021
VL  - 11
IS  - 11
SN  - 2077-0472

AB  - Severe frost usually has adverse impacts on agricultural production, resulting in crop freeze injury, poor crop yield, and crop quality reduction. Timely and accurate detection of frost plays an important role in cold damage warnings, prevention, and control. Current frost detection methods mostly use physical properties such as light, electricity, and heat, or the judge and quantify using environmental factors such as temperature and wind speed. However, it is difficult to detect and accurately identify the frosting phenomenon in real time during field trials because of the complex environment, different plant types, and interference by many factors during observation. To provide an overview of the analytical tools for scientists, researchers, and product developers, a review and comparative analysis of the available literature on frost mechanisms, correlations, and characteristics are presented in this study. First, the mechanisms of the frost formation process, frost level, and the significance of detection, are introduced. Then, the methods and techniques used to measure frost on plant surfaces are synthetically classified and further compared. Moreover, the key points and difficulties are summarized and discussed. Finally, some constructive methods of frost detection are proposed to improve the frost detection process.
KW  - plant
KW  - leaf surface
KW  - frost
KW  - frost characteristics
KW  - detection
DO  - 10.3390/agriculture11111142
ER  -
TY  - EJOU
AU  - Tashtoush, Yahya
AU  - Haj-Mahmoud, Israa
AU  - Darwish, Omar
AU  - Maabreh, Majdi
AU  - Alsinglawi, Belal
AU  - Elkhodr, Mahmoud
AU  - Alsaedi, Nasser
TI  - Enhancing Robots Navigation in Internet of Things Indoor Systems
T2  - Computers

PY  - 2021
VL  - 10
IS  - 11
SN  - 2073-431X

AB  - In this study, an effective local minima detection and definition algorithm is introduced for a mobile robot navigating through unknown static environments. Furthermore, five approaches are presented and compared with the popular approach wall-following to pull the robot out of the local minima enclosure namely; Random Virtual Target, Reflected Virtual Target, Global Path Backtracking, Half Path Backtracking, and Local Path Backtracking. The proposed approaches mainly depend on changing the target location temporarily to avoid the original target&rsquo;s attraction force effect on the robot. Moreover, to avoid getting trapped in the same location, a virtual obstacle is placed to cover the local minima enclosure. To include the most common shapes of deadlock situations, the proposed approaches were evaluated in four different environments; V-shaped, double U-shaped, C-shaped, and cluttered environments. The results reveal that the robot, using any of the proposed approaches, requires fewer steps to reach the destination, ranging from 59 to 73 m on average, as opposed to the wall-following strategy, which requires an average of 732 m. On average, the robot with a constant speed and reflected virtual target approach takes 103 s, whereas the identical robot with a wall-following approach takes 907 s to complete the tasks. Using a fuzzy-speed robot, the duration for the wall-following approach is greatly reduced to 507 s, while the reflected virtual target may only need up to 20% of that time. More results and detailed comparisons are embedded in the subsequent sections.
KW  - local minima
KW  - target switching
KW  - trap situation
KW  - mobile robot navigation
KW  - infinite loop
DO  - 10.3390/computers10110153
ER  -
TY  - EJOU
AU  - Moussaid, Abdellatif
AU  - Fkihi, Sanaa E.
AU  - Zennayi, Yahya
TI  - Tree Crowns Segmentation and Classification in Overlapping Orchards Based on Satellite Images and Unsupervised Learning Algorithms
T2  - Journal of Imaging

PY  - 2021
VL  - 7
IS  - 11
SN  - 2313-433X

AB  - Smart agriculture is a new concept that combines agriculture and new technologies to improve the yield’s quality and quantity as well as facilitate many tasks for farmers in managing orchards. An essential factor in smart agriculture is tree crown segmentation, which helps farmers automatically monitor their orchards and get information about each tree. However, one of the main problems, in this case, is when the trees are close to each other, which means that it would be difficult for the algorithm to delineate the crowns correctly. This paper used satellite images and machine learning algorithms to segment and classify trees in overlapping orchards. The data used are images from the Moroccan Mohammed VI satellite, and the study region is the OUARGHA citrus orchard located in Morocco. Our approach starts by segmenting the rows inside the parcel and finding all the trees there, getting their canopies, and classifying them by size. In general, the model inputs the parcel’s image and other field measurements to classify the trees into three classes: missing/weak, normal, or big. Finally, the results are visualized in a map containing all the trees with their classes. For the results, we obtained a score of 0.93 F-measure in rows segmentation. Additionally, several field comparisons were performed to validate the classification, dozens of trees were compared and the results were very good. This paper aims to help farmers to quickly and automatically classify trees by crown size, even if there are overlapping orchards, in order to easily monitor each tree’s health and understand the tree’s distribution in the field.
KW  - tree canopy segmentation
KW  - tree canopy classification
KW  - unsupervised learning
KW  - satellite images
KW  - remote sensing
DO  - 10.3390/jimaging7110241
ER  -
TY  - EJOU
AU  - Hashim, Wahidah
AU  - Eng, Lim S.
AU  - Alkawsi, Gamal
AU  - Ismail, Rozita
AU  - Alkahtani, Ammar A.
AU  - Dzulkifly, Sumayyah
AU  - Baashar, Yahia
AU  - Hussain, Azham
TI  - A Hybrid Vegetation Detection Framework: Integrating Vegetation Indices and Convolutional Neural Network
T2  - Symmetry

PY  - 2021
VL  - 13
IS  - 11
SN  - 2073-8994

AB  - Vegetation inspection and monitoring is a time-consuming task. In the era of industrial revolution 4.0 (IR 4.0), unmanned aerial vehicles (UAV), commercially known as drones, are in demand, being adopted for vegetation inspection and monitoring activities. However, most off-the-shelf drones are least favoured by vegetation maintenance departments for on-site inspection due to limited spectral bands camera restricting advanced vegetation analysis. Most of these drones are normally equipped with a normal red, green, and blue (RGB) camera. Additional spectral bands are found to produce more accurate analysis during vegetation inspection, but at the cost of advanced camera functionalities, such as multispectral camera. Vegetation indices (VI) is a technique to maximize detection sensitivity related to vegetation characteristics while minimizing other factors which are not categorised otherwise. The emergence of machine learning has slowly influenced the existing vegetation analysis technique in order to improve detection accuracy. This study focuses on exploring VI techniques in identifying vegetation objects. The selected VIs investigated are Visible Atmospheric Resistant Index (VARI), Green Leaf Index (GLI), and Vegetation Index Green (VIgreen). The chosen machine learning technique is You Only Look Once (YOLO), which is a clever convolutional neural network (CNN) offering object detection in real time. The CNN model has a symmetrical structure along the direction of the tensor flow. Several series of data collection have been conducted at identified locations to obtain aerial images. The proposed hybrid methods were tested on captured aerial images to observe vegetation detection performance. Segmentation in image analysis is a process to divide the targeted pixels for further detection testing. Based on our findings, more than 70% of the vegetation objects in the images were accurately detected, which reduces the misdetection issue faced by previous VI techniques. On the other hand, hybrid segmentation methods perform best with the combination of VARI and YOLO at 84% detection accuracy.
KW  - vegetation detection
KW  - vegetation indices
KW  - convolutional neural network
KW  - hybrid method
DO  - 10.3390/sym13112190
ER  -
TY  - EJOU
AU  - Zhang, Fei
AU  - Chan, Ngai W.
AU  - Liu, Changjiang
AU  - Wang, Xiaoping
AU  - Shi, Jingchao
AU  - Kung, Hsiang-Te
AU  - Li, Xinguo
AU  - Guo, Tao
AU  - Wang, Weiwei
AU  - Cao, Naixin
TI  - Water Quality Index (WQI) as a Potential Proxy for Remote Sensing Evaluation of Water Quality in Arid Areas
T2  - Water

PY  - 2021
VL  - 13
IS  - 22
SN  - 2073-4441

AB  - Water Resource Sustainability Management plays a vitally important role in ensuring sustainable development, especially in water-stressed arid regions throughout the world. In order to achieve sustainable development, it is necessary to study and monitor the water quality in the arid region of Central Asia, an area that is increasingly affected by climate change. In recent decades, the rapid deterioration of water quality in the Ebinur Lake basin in Xinjiang (China) has severely threatened sustainable economic development. This study selected the Ebinur Lake basin as the study target, with the purpose of revealing the response between the water quality index and water body reflectivity, and to describe the relationship between the water quality index and water reflectivity. The methodology employed remote sensing techniques that establish a water quality index monitoring model to monitor water quality. The results of our study include: (1) the Water Quality Index (WQI) that was used to evaluate the water environment in Ebinur Lake indicates a lower water quality of Ebinur Lake, with a WQI value as high as 4000; (2) an introduction of the spectral derivative method that realizes the extraction of spectral information from a water body to better mine the information of spectral data through remote sensing, and the results also prove that the spectral derivative method can improve the relationship between the water body spectral and WQI, whereby R2 is 0.6 at the most sensitive wavelengths; (3) the correlation between the spectral sensitivity index and WQI was greater than 0.6 at the significance level of 0.01 when multi-source spectral data were integrated with the spectral index (DI, RI and NDI) and fluorescence baseline; and (4) the distribution map of WQI in Ebinur Lake was obtained by the optimal model, which was constructed based on the third derivative data of Sentinel 2 data. We concluded that the water quality in the northwest of Ebinur Lake was the lowest in the region. In conclusion, we found that remote sensing techniques were highly effective and laid a foundation for water quality detection in arid areas.
KW  - Water Quality Index (WQI)
KW  - Ebinur Lake
KW  - remote sensing
DO  - 10.3390/w13223250
ER  -
TY  - EJOU
AU  - Ahmad, Muhammad I.
AU  - Ab. Rahim, Mohd H.
AU  - Nordin, Rosdiadee
AU  - Mohamed, Faizal
AU  - Abu-Samah, Asma’
AU  - Abdullah, Nor F.
TI  - Ionizing Radiation Monitoring Technology at the Verge of Internet of Things
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 22
SN  - 1424-8220

AB  - As nuclear technology evolves, and continues to be used in various fields since its discovery less than a century ago, radiation safety has become a major concern to humans and the environment. Radiation monitoring plays a significant role in preventive radiological nuclear detection in nuclear facilities, hospitals, or in any activities associated with radioactive materials by acting as a tool to measure the risk of being exposed to radiation while reaping its benefit. Apart from in occupational settings, radiation monitoring is required in emergency responses to radiation incidents as well as outdoor radiation zones. Several radiation sensors have been developed, ranging from as simple as a Geiger-Muller counter to bulkier radiation systems such as the High Purity Germanium detector, with different functionality for use in different settings, but the inability to provide real-time data makes radiation monitoring activities less effective. The deployment of manned vehicles equipped with these radiation sensors reduces the scope of radiation monitoring operations significantly, but the safety of radiation monitoring operators is still compromised. Recently, the Internet of Things (IoT) technology has been introduced to the world and offered solutions to these limitations. This review elucidates a systematic understanding of the fundamental usage of the Internet of Drones for radiation monitoring purposes. The extension of essential functional blocks in IoT can be expanded across radiation monitoring industries, presenting several emerging research opportunities and challenges. This article offers a comprehensive review of the evolutionary application of IoT technology in nuclear and radiation monitoring. Finally, the security of the nuclear industry is discussed.
KW  - radiation monitoring
KW  - remote monitoring
KW  - radiation sensor
KW  - radiation safety
KW  - Internet of Things
KW  - IoT
KW  - unmanned aerial vehicles
KW  - UAV
KW  - drone
DO  - 10.3390/s21227629
ER  -
TY  - EJOU
AU  - Koteleva, Natalia
AU  - Khokhlov, Sergei
AU  - Frenkel, Ilia
TI  - Digitalization in Open-Pit Mining: A New Approach in Monitoring and Control of Rock Fragmentation
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 22
SN  - 2076-3417

AB  - Mining enterprises are widely introducing digital technologies and automation is one of such tools. Granularity monitoring, namely, the size determination of rock mass pieces is a common operational component of the processes that extract minerals by open-pit mining. The article proposes an approach that, in addition to the lump size distribution, makes it possible to estimate the lump form distribution as well. To investigate the effectiveness of monitoring the form of blasted rock mass lumps, the authors conducted experiments in four stages related to the rock condition. They include geological occurrence, explosive crushing, trommelling, and mill crushing. The relationship between these stages is presented and the change in the lumps fragment form is traced. The present article proposes an informational and analytical model of the processes at mining enterprises, extracting minerals by open-pit mining, as well as an algorithm for determining the lumps form and obtaining their distribution in the rock mass.
KW  - digitalization
KW  - rock fragmentation
KW  - fragmentation
KW  - form
KW  - blasting
DO  - 10.3390/app112210848
ER  -
TY  - EJOU
AU  - Teodoro, Paulo E.
AU  - Teodoro, Larissa P.
AU  - Baio, Fábio H.
AU  - da Silva Junior, Carlos A.
AU  - dos Santos, Regimar G.
AU  - Ramos, Ana P.
AU  - Pinheiro, Mayara M.
AU  - Osco, Lucas P.
AU  - Gonçalves, Wesley N.
AU  - Carneiro, Alexsandro M.
AU  - Junior, José M.
AU  - Pistori, Hemerson
AU  - Shiratsuchi, Luciano S.
TI  - Predicting Days to Maturity, Plant Height, and Grain Yield in Soybean: A Machine and Deep Learning Approach Using Multispectral Data
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 22
SN  - 2072-4292

AB  - In soybean, there is a lack of research aiming to compare the performance of machine learning (ML) and deep learning (DL) methods to predict more than one agronomic variable, such as days to maturity (DM), plant height (PH), and grain yield (GY). As these variables are important to developing an overall precision farming model, we propose a machine learning approach to predict DM, PH, and GY for soybean cultivars based on multispectral bands. The field experiment considered 524 genotypes of soybeans in the 2017/2018 and 2018/2019 growing seasons and a multitemporal–multispectral dataset collected by embedded sensor in an unmanned aerial vehicle (UAV). We proposed a multilayer deep learning regression network, trained during 2000 epochs using an adaptive subgradient method, a random Gaussian initialization, and a 50% dropout in the first hidden layer for regularization. Three different scenarios, including only spectral bands, only vegetation indices, and spectral bands plus vegetation indices, were adopted to infer each variable (PH, DM, and GY). The DL model performance was compared against shallow learning methods such as random forest (RF), support vector machine (SVM), and linear regression (LR). The results indicate that our approach has the potential to predict soybean-related variables using multispectral bands only. Both DL and RF models presented a strong (r surpassing 0.77) prediction capacity for the PH variable, regardless of the adopted input variables group. Our results demonstrated that the DL model (r = 0.66) was superior to predict DM when the input variable was the spectral bands. For GY, all machine learning models evaluated presented similar performance (r ranging from 0.42 to 0.44) for each tested scenario. In conclusion, this study demonstrated an efficient approach to a computational solution capable of predicting multiple important soybean crop variables based on remote sensing data. Future research could benefit from the information presented here and be implemented in subsequent processes related to soybean cultivars or other types of agronomic crops.
KW  - precision agriculture
KW  - multispectral remote sensing data
KW  - shallow learner
KW  - deep neural network
DO  - 10.3390/rs13224632
ER  -
TY  - EJOU
AU  - Kim, In B.
AU  - Cho, Jun S.
AU  - Zi, Goang S.
AU  - Cho, Beom S.
AU  - Lee, Seon M.
AU  - Kim, Hyoung U.
TI  - Detection and Identification of Expansion Joint Gap of Road Bridges by Machine Learning Using Line-Scan Camera Images
T2  - Applied System Innovation

PY  - 2021
VL  - 4
IS  - 4
SN  - 2571-5577

AB  - Recently, the lack of expansion joint gaps on highway bridges in Korea has been increasing. In particular, with the increase in the number of days during the summer heatwave, the narrowing of the expansion joint gap causes symptoms such as expansion joint damage and pavement blow-up, which threaten traffic safety and structural safety. Therefore, in this study, we developed a machine vision (M/V)-technique-based inspection system that can monitor the expansion joint gap through image analysis while driving at high speed (100 km/h), replacing the current manual method that uses an inspector to inspect the expansion joint gap. To fix the error factors of image analysis that happened during the trial application, a machine learning method was used to improve the accuracy of measuring the gap between the expansion joint device. As a result, the expansion gap identification accuracy was improved by 27.5%, from 67.5% to 95.0%, and the use of the system reduces the survey time by more than 95%, from an average of approximately 1 h/bridge (existing manual inspection method) to approximately 3 min/bridge. We assume, in the future, maintenance practitioners can contribute to preventive maintenance that prepares countermeasures before problems occur.
KW  - bridge
KW  - expansion joint
KW  - joint gap
KW  - smart bridge maintenance equipment
KW  - sensor
KW  - structural health monitoring
KW  - line-scan camera
KW  - machine vision
KW  - machine learning
DO  - 10.3390/asi4040094
ER  -
TY  - EJOU
AU  - Lu, Bing
AU  - He, Yuhong
TI  - Assessing the Impacts of Species Composition on the Accuracy of Mapping Chlorophyll Content in Heterogeneous Ecosystems
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 22
SN  - 2072-4292

AB  - Chlorophyll is an essential vegetation pigment influencing plant photosynthesis rate and growth conditions. Remote sensing images have been widely used for mapping vegetation chlorophyll content in different ecosystems (e.g., farmlands, forests, grasslands, and wetlands) for evaluating vegetation growth status and productivity of these ecosystems. Compared to farmlands and forests that are more homogeneous in terms of species composition, grasslands and wetlands are more heterogeneous with highly mixed species (e.g., various grass, forb, and shrub species). Different species contribute differently to the ecosystem services, thus, monitoring species-specific chlorophyll content is critical for better understanding their growth status, evaluating ecosystem functions, and supporting ecosystem management (e.g., control invasive species). However, previous studies in mapping chlorophyll content in heterogeneous ecosystems have rarely estimated species-specific chlorophyll content, which was partially due to the limited spatial resolution of remote sensing images commonly used in the past few decades for recognizing different species. In addition, many previous studies have used one universal model built with data of all species for mapping chlorophyll of the entire study area, which did not fully consider the impacts of species composition on the accuracy of chlorophyll estimation (i.e., establishing species-specific chlorophyll estimation models may generate higher accuracy). In this study, helicopter-acquired high-spatial resolution hyperspectral images were acquired for species classification and species-specific chlorophyll content estimation. Four estimation models, including a universal linear regression (LR) model (i.e., built with data of all species), species-specific LR models (i.e., built with data of each species, respectively), a universal random forest regression (RFR) model, and species-specific RFR models, were compared to determine their performance in mapping chlorophyll and to evaluate the impacts of species composition. The results show that species-specific models performed better than the universal models, especially for species with fewer samples in the dataset. The best performed species-specific models were then used to generate species-specific chlorophyll content maps using the species classification results. Impacts of species composition on the retrieval of chlorophyll content were further assessed to support future chlorophyll mapping in heterogeneous ecosystems and ecosystem management.
KW  - vegetation chlorophyll content
KW  - remote sensing
KW  - heterogeneous ecosystems
KW  - species composition
KW  - hyperspectral
KW  - ecosystem monitoring
DO  - 10.3390/rs13224671
ER  -
TY  - EJOU
AU  - Deligiannakis, Georgios
AU  - Pallikarakis, Aggelos
AU  - Papanikolaou, Ioannis
AU  - Alexiou, Simoni
AU  - Reicherter, Klaus
TI  - Detecting and Monitoring Early Post-Fire Sliding Phenomena Using UAV&ndash;SfM Photogrammetry and t-LiDAR-Derived Point Clouds
T2  - Fire

PY  - 2021
VL  - 4
IS  - 4
SN  - 2571-6255

AB  - Soil changes, including landslides and erosion, are some of the most prominent post-fire effects in Mediterranean ecosystems. Landslide detection and monitoring play an essential role in mitigation measures. We tested two different methodologies in five burned sites with different characteristics in Central Greece. We compared Unmanned Aerial Vehicles (UAV)-derived high-resolution Digital Surface Models and point clouds with terrestrial Light Detection and Ranging (LiDAR)-derived point clouds to reveal new cracks and monitor scarps of pre-existing landslides. New cracks and scarps were revealed at two sites after the wildfire, measuring up to 27 m in length and up to 25 &plusmn; 5 cm in depth. Pre-existing scarps in both Kechries sites appeared to be active, with additional vertical displacements ranging from 5&ndash;15 &plusmn; 5 cm. In addition, the pre-existing landslide in Magoula expanded by 8%. Due to vegetation regrowth, no changes could be detected in the Agios Stefanos pre-existing landslide. This high-spatial-resolution mapping of slope deformations can be used as landslide precursor, assisting prevention measures. Considering the lack of vegetation after wildfires, UAV photogrammetry has great potential for tracing such early landslide indicators and is more efficient for accurately recording soil changes.
KW  - forest fires
KW  - landslides
KW  - vegetation regrowth
KW  - Terrestrial Laser Scanning—TLS
KW  - soil erosion
KW  - post-fire effects
KW  - Greece
DO  - 10.3390/fire4040087
ER  -
TY  - EJOU
AU  - Li, Xunmeng
AU  - Wang, Kai
AU  - Chen, Jianqu
AU  - Zhang, Shouyu
TI  - Allometric Growth of Sargassum fusiforme (Ochrophyta, Fucales) Organs in the Maturation Period Based on Biomass Analysis of Samples from Gouqi Island
T2  - Journal of Marine Science and Engineering

PY  - 2021
VL  - 9
IS  - 12
SN  - 2077-1312

AB  - Sargassum fusiforme is a seaweed species that plays an important role in the diverse communities of the flora and fauna of coastal food webs. Assessments of its biomass and energy allocation in addition to allometric organ growth have important ecological value for understanding the community structure, carbon storage, and resource assessment of seaweed beds during periods in which they thrive. In this study, the morphology of Sargassum fusiforme and the biomass of organs and total organisms in the maturation period were studied, and the allometric relationships for different organs of Sargassum fusiforme were analyzed using the standardized major axis (SMA). In the maturation period of Sargassum fusiforme, branch number, height &times; stem diameter were the prior independent variables, and the optimum biomass was y = 0.002x1.107 (R2 = 0.923). The biomass allocation ratio of blades was the highest (38.33%), followed by stems (32.90%) and receptacles (28.77%). The growth rates of the various organs were found to differ, and the rate of biomass increase for the blades and stems tended to converge. The rate of receptacle biomass growth of Sargassum fusiforme was the highest in the maturation period, and the rate of organ biomass increase was Wb &lt; Ws &lt; Wt &lt; Wr, which reflects the trade-off with energy allocation as a strategy used by Sargassum fusiforme.
KW  - intertidal zone
KW  - biomass
KW  - allometric growth
KW  - Sargassum fusiforme
KW  - maturation period
DO  - 10.3390/jmse9121320
ER  -
TY  - EJOU
AU  - Kakhani, Nafiseh
AU  - Mokhtarzade, Mehdi
AU  - Valadan Zoej, Mohammad J.
TI  - Deep Learning Spatial-Spectral Classification of Remote Sensing Images by Applying Morphology-Based Differential Extinction Profile (DEP)
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 23
SN  - 2079-9292

AB  - Since the technology of remote sensing has been improved recently, the spatial resolution of satellite images is getting finer. This enables us to precisely analyze the small complex objects in a scene through remote sensing images. Thus, the need to develop new, efficient algorithms like spatial-spectral classification methods is growing. One of the most successful approaches is based on extinction profile (EP), which can extract contextual information from remote sensing data. Moreover, deep learning classifiers have drawn attention in the remote sensing community in the past few years. Recent progress has shown the effectiveness of deep learning at solving different problems, particularly segmentation tasks. This paper proposes a novel approach based on a new concept, which is differential extinction profile (DEP). DEP makes it possible to have an input feature vector with both spectral and spatial information. The input vector is then fed into a proposed straightforward deep-learning-based classifier to produce a thematic map. The approach is carried out on two different urban datasets from Pleiades and World-View 2 satellites. In order to prove the capabilities of the suggested approach, we compare the final results to the results of other classification strategies with different input vectors and various types of common classifiers, such as support vector machine (SVM) and random forests (RF). It can be concluded that the proposed approach is significantly improved in terms of three kinds of criteria, which are overall accuracy, Kappa coefficient, and total disagreement.
KW  - extinction profile (EP)
KW  - deep learning
KW  - segmentation
KW  - spatial-spectral classification
KW  - remote sensing image
DO  - 10.3390/electronics10232893
ER  -
TY  - EJOU
AU  - Gawehn, Matthijs
AU  - de Vries, Sierd
AU  - Aarninkhof, Stefan
TI  - A Self-Adaptive Method for Mapping Coastal Bathymetry On-The-Fly from Wave Field Video
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 23
SN  - 2072-4292

AB  - Mapping coastal bathymetry from remote sensing becomes increasingly more attractive for the coastal community. It is facilitated by a rising availability of drone and satellite data, advances in data science, and an open-source mindset. Coastal bathymetry, but also wave directions, celerity and near-surface currents can simultaneously be derived from aerial video of a wave field. However, the required video processing is usually extensive, requires skilled supervision, and is tailored to a fieldsite. This study proposes a video-processing algorithm that resolves these issues. It automatically adapts to the video data and continuously returns mapping updates and thereby aims to make wave-based remote sensing more inclusive to the coastal community. The code architecture for the first time includes the dynamic mode decomposition (DMD) to reduce the data complexity of wavefield video. The DMD is paired with loss-functions to handle spectral noise and a novel spectral storage system and Kalman filter to achieve fast converging measurements. The algorithm is showcased for fieldsites in the USA, the UK, the Netherlands, and Australia. The performance with respect to mapping bathymetry was validated using ground truth data. It was demonstrated that merely 32 s of video footage is needed for a first mapping update with average depth errors of 0.9&ndash;2.6 m. These further reduced to 0.5&ndash;1.4 m as the videos continued and more mapping updates were returned. Simultaneously, coherent maps for wave direction and celerity were achieved as well as maps of local near-surface currents. The algorithm is capable of mapping the coastal parameters on-the-fly and thereby offers analysis of video feeds, such as from drones or operational camera installations. Hence, the innovative application of analysis techniques like the DMD enables both accurate and unprecedentedly fast coastal reconnaissance. The source code and data of this article are openly available.
KW  - remote sensing
KW  - coastal zone
KW  - bathymetry
KW  - depth inversion
KW  - waves
KW  - dynamic mode decomposition
KW  - on-the-fly
DO  - 10.3390/rs13234742
ER  -
TY  - EJOU
AU  - Appeltans, Simon
AU  - Apolo-Apolo, Orly E.
AU  - Rodríguez-Vázquez, Jaime N.
AU  - Pérez-Ruiz, Manuel
AU  - Pieters, Jan
AU  - Mouazen, Abdul M.
TI  - The Automation of Hyperspectral Training Library Construction: A Case Study for Wheat and Potato Crops
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 23
SN  - 2072-4292

AB  - The potential of hyperspectral measurements for early disease detection has been investigated by many experts over the last 5 years. One of the difficulties is obtaining enough data for training and building a hyperspectral training library. When the goal is to detect disease at a previsible stage, before the pathogen has manifested either its first symptoms or in the area surrounding the existing symptoms, it is impossible to objectively delineate the regions of interest containing the previsible pathogen growth from the areas without the pathogen growth. To overcome this, we propose an image labelling and segmentation algorithm that is able to (a) more objectively label the visible symptoms for the construction of a training library and (b) extend this labelling to the pre-visible symptoms. This algorithm is used to create hyperspectral training libraries for late blight disease (Phytophthora infestans) in potatoes and two types of leaf rust (Puccinia triticina and Puccinia striiformis) in wheat. The model training accuracies were compared between the automatic labelling algorithm and the classic visual delineation of regions of interest using a logistic regression machine learning approach. The modelling accuracies of the automatically labelled datasets were higher than those of the manually labelled ones for both potatoes and wheat, at 98.80% for P. infestans in potato, 97.69% for P. striiformis in soft wheat, and 96.66% for P. triticina in durum wheat.
KW  - hyperspectral
KW  - wheat
KW  - potato
KW  - machine learning
KW  - labelling
DO  - 10.3390/rs13234735
ER  -
TY  - EJOU
AU  - Hashim, Izrahayu C.
AU  - Shariff, Abdul R.
AU  - Bejo, Siti K.
AU  - Muharam, Farrah M.
AU  - Ahmad, Khairulmazmi
TI  - Classification of Non-Infected and Infected with Basal Stem Rot Disease Using Thermal Images and Imbalanced Data Approach
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 12
SN  - 2073-4395

AB  - Basal stem rot (BSR) disease occurs due to the most aggressive and threatening fungal attack of the oil palm plant known as Ganoderma boninense (G. boninense). BSR is a disease that has a significant impact on oil palm crops in Malaysia and Indonesia. Currently, the only sustainable strategy available is to extend the life of oil palm trees, as there is no effective treatment for BSR disease. This study used thermal imagery to identify the thermal features to classify non-infected and BSR-infected trees. The aims of this study were to (1) identify the potential temperature features and (2) examine the performance of machine learning (ML) classifiers (na&iuml;ve Bayes (NB), multilayer perceptron (MLP), and random forest (RF) to classify oil palm trees that are non-infected and BSR-infected. The sample size consisted of 55 uninfected trees and 37 infected trees. We used the imbalance data approaches such as random undersampling (RUS), random oversampling (ROS) and synthetic minority oversampling (SMOTE) in these classifications due to the different sample sizes. The study found that the Tmax feature is the most beneficial temperature characteristic for classifying non-infected or infected BSR trees. Meanwhile, the ROS approach improves the curve region (AUC) and PRC results compared to a single approach. The result showed that the temperature feature Tmax and combination feature TmaxTmin had a higher correct classification for the G. boninense non-infected and infected oil palm trees for the ROS-RF and had a robust success rate, classifying correctly 87.10% for non-infected and 100% for infected by G. boninense. In terms of model performance using the most significant variables, Tmax, the ROS-RF model had an excellent receiver operating characteristics (ROC) curve region (AUC) of 0.921, and the precision&ndash;recall curve (PRC) region gave a value of 0.902. Therefore, it can be concluded that the ROS-RF, using the Tmax, can be used to predict BSR disease with relatively high accuracy.
KW  - Ganoderma boninense
KW  - basal stem rot (BSR)
KW  - temperature
KW  - machine learning
KW  - classifier
KW  - imbalance approach
KW  - SMOTE
KW  - classification
DO  - 10.3390/agronomy11122373
ER  -
TY  - EJOU
AU  - Shirazy, Adel
AU  - Hezarkhani, Ardeshir
AU  - Timkin, Timofey
AU  - Shirazi, Aref
TI  - Investigation of Magneto-/Radio-Metric Behavior in Order to Identify an Estimator Model Using K-Means Clustering and Artificial Neural Network (ANN) (Iron Ore Deposit, Yazd, IRAN)
T2  - Minerals

PY  - 2021
VL  - 11
IS  - 12
SN  - 2075-163X

AB  - The study area is located near Toot village in the Yazd province of Iran, which is considered in terms of its iron mineralization potential. In this area, due to radioactivity, radiometric surveys were performed in a part of the area where magnetometric studies have also been performed. According to geological studies, the presence of magnetic anomalies can have a complex relationship with the intensity of radioactivity of radioactive elements. Using the K-means clustering method, the centers of the clusters were calculated with and without considering the coordinates of radiometric points. Finally, the behavior of the two variables of magnetic field strength and radioactivity of radioactive elements relative to each other was studied, and a mathematical relationship was presented to analyze the behavior of these two variables relative to each other. On the other hand, the increasing and then decreasing behavior of the intensity of the Earth&rsquo;s magnetic field relative to the intensity of radioactivity of radioactive elements shows that it is possible to generalize the results of magnetometric surveys to radiometry without radiometric re-sampling in this region and neighboring areas. For this purpose, using the general regression neural network and backpropagation neural network (BPNN) methods, radiometric data were estimated with very good accuracy. The general regression neural network (GRNN) method, with more precision in estimation, was used as a model for estimating the radiation intensity of radioactive elements in other neighboring areas.
KW  - radiometry
KW  - magnetometry
KW  - iron
KW  - k-means clustering method
KW  - artificial neural network
KW  - GRNN
KW  - BPNN
DO  - 10.3390/min11121304
ER  -
TY  - EJOU
AU  - Chen, Jianchang
AU  - Chen, Yiming
AU  - Liu, Zhengjun
TI  - Classification of Typical Tree Species in Laser Point Cloud Based on Deep Learning
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 23
SN  - 2072-4292

AB  - We propose the Point Cloud Tree Species Classification Network (PCTSCN) to overcome challenges in classifying tree species from laser data with deep learning methods. The network is mainly composed of two parts: a sampling component in the early stage and a feature extraction component in the later stage. We used geometric sampling to extract regions with local features from the tree contours since these tend to be species-specific. Then we used an improved Farthest Point Sampling method to extract the features from a global perspective. We input the intensity of the tree point cloud as a dimensional feature and spatial information into the neural network and mapped it to higher dimensions for feature extraction. We used the data obtained by Terrestrial Laser Scanning (TLS) and Unmanned Aerial Vehicle Laser Scanning (UAVLS) to conduct tree species classification experiments of white birch and larch. The experimental results showed that in both the TLS and UAVLS datasets, the input tree point cloud density and the highest feature dimensionality of the mapping had an impact on the classification accuracy of the tree species. When the single tree sample obtained by TLS consisted of 1024 points and the highest dimension of the network mapping was 512, the classification accuracy of the trained model reached 96%. For the individual tree samples obtained by UAVLS, which consisted of 2048 points and had the highest dimension of the network mapping of 1024, the classification accuracy of the trained model reached 92%. TLS data tree species classification accuracy of PCTSCN was improved by 2&ndash;9% compared with other models using the same point density, amount of data and highest feature dimension. The classification accuracy of tree species obtained by UAVLS was up to 8% higher. We propose PCTSCN to provide a new strategy for the intelligent classification of forest tree species.
KW  - deep learning
KW  - point cloud
KW  - forestry
KW  - tree species classification
DO  - 10.3390/rs13234750
ER  -
TY  - EJOU
AU  - Wang, Zhenhua
AU  - Zhang, Xinyue
AU  - Li, Jing
AU  - Luan, Kuifeng
TI  - A YOLO-Based Target Detection Model for Offshore Unmanned Aerial Vehicle Data
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 23
SN  - 2071-1050

AB  - Target detection in offshore unmanned aerial vehicle data is still a challenge due to the complex characteristics of targets, such as multi-sizes, alterable orientation, and complex backgrounds. Herein, a YOLO-based detection model (YOLO-D) was proposed for target detection in offshore unmanned aerial vehicle data. Based on the YOLOv3 network, the residual module was improved by establishing dense connections and adding a dual-attention mechanism (CBAM) to enhance the use of features and global information. Then, the loss function of the YOLO-D model was added to the weight coefficients to increase detection accuracy for small-size targets. Finally, the feature pyramid network (FPN) was replaced by the secondary recursive feature pyramid network to reduce the impacts of a complicated environment. Taking the car, boat, and deposit near the coastline as the targets, the proposed YOLO-D model was compared against other models, including the faster R-CNN, SSD, YOLOv3, and YOLOv5, to evaluate its detection performance. The results showed that the evaluation metrics of the YOLO-D model, including precision (Pr), recall (Re), average precision (AP), and the mean of average precision (mAP), had the highest values. The mAP of the YOLO-D model increased by 37.95%, 39.44%, 28.46%, and 5.08% compared to the faster R-CNN, SSD, YOLOv3, and YOLOv5, respectively. The AP of the car, boat, and deposit reached 96.24%, 93.70%, and 96.79% respectively. Moreover, the YOLO-D model had a higher detection accuracy than other models, especially in the detection of small-size targets. Collectively, the proposed YOLO-D model is a suitable model for target detection in offshore unmanned aerial vehicle data.
KW  - offshore monitoring
KW  - target detection
KW  - deep learning
KW  - YOLO
KW  - unmanned aerial vehicle
DO  - 10.3390/su132312980
ER  -
TY  - EJOU
AU  - Sekrecka, Aleksandra
TI  - Application of the XBoost Regressor for an A Priori Prediction of UAV Image Quality
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 23
SN  - 2072-4292

AB  - In general, the quality of imagery from Unmanned Aerial Vehicles (UAVs) is evaluated after the flight, and then a decision is made on the further value and use of the acquired data. In this paper, an a priori (preflight) image quality prediction methodology is proposed to estimate the preflight image quality and to avoid unfavourable flights, which is extremely important from a time and cost management point of view. The XBoost Regressor model and cross-validation were used for machine learning of the model and image quality prediction. The model was learned on a rich database of real-world images acquired from UAVs under conditions varying in both sensor type, UAV type, exposure parameters, weather, topography, and land cover. Radiometric quality indices (SNR, Entropy, PIQE, NIQE, BRISQUE, and NRPBM) were calculated for each image to train and test the model and to assess the accuracy of image quality prediction. Different variants of preflight parameter knowledge were considered in the study. The proposed methodology offers the possibility of predicting image quality with high accuracy. The correlation coefficient between the actual and predicted image quality, depending on the number of parameters known a priori, ranged from 0.90 to 0.96. The methodology was designed for data acquired from a UAV. Similar prediction accuracy is expected for other low-altitude or close-range photogrammetric data.
KW  - unmanned aerial vehicle
KW  - image quality
KW  - XBoost Regressor
KW  - machine learning
KW  - prediction
DO  - 10.3390/rs13234757
ER  -
TY  - EJOU
AU  - Singh, Simran
AU  - Kumbhar, Abhaykumar
AU  - Güvenç, İsmail
AU  - Sichitiu, Mihail L.
TI  - Intelligent Interference Management in UAV-Based HetNets
T2  - Telecom

PY  - 2021
VL  - 2
IS  - 4
SN  - 2673-4001

AB  - Unmanned aerial vehicles (UAVs) can play a key role in meeting certain demands of cellular networks. UAVs can be used not only as user equipment (UE) in cellular networks but also as mobile base stations (BSs) wherein they can either augment conventional BSs by adapting their position to serve the changing traffic and connectivity demands or temporarily replace BSs that are damaged due to natural disasters. The flexibility of UAVs allows them to provide coverage to UEs in hot-spots, at cell-edges, in coverage holes, or regions with scarce cellular infrastructure. In this work, we study how UAV locations and other cellular parameters may be optimized in such scenarios to maximize the spectral efficiency (SE) of the network. We compare the performance of machine learning (ML) techniques with conventional optimization approaches. We found that, on an average, a double deep Q learning approach can achieve 93.46% of the optimal median SE and 95.83% of the optimal mean SE. A simple greedy approach, which tunes the parameters of each BS and UAV independently, performed very well in all the cases that we tested. These computationally efficient approaches can be utilized to enhance the network performance in existing cellular networks.
KW  - artificial intelligence
KW  - double deep Q learning
KW  - FeICIC
KW  - HetNets
KW  - LTE-advanced
KW  - UAV
DO  - 10.3390/telecom2040027
ER  -
TY  - EJOU
AU  - Elmeseiry, Nourhan
AU  - Alshaer, Nancy
AU  - Ismail, Tawfik
TI  - A Detailed Survey and Future Directions of Unmanned Aerial Vehicles (UAVs) with Potential Applications
T2  - Aerospace

PY  - 2021
VL  - 8
IS  - 12
SN  - 2226-4310

AB  - Recently, unmanned aerial vehicles (UAVs), also known as drones, have gained widespread interest in civilian and military applications, which has led to the development of novel UAVs that can perform various operations. UAVs are aircraft that can fly without the need of a human pilot onboard, meaning they can fly either autonomously or be remotely piloted. They can be equipped with multiple sensors, including cameras, inertial measurement units (IMUs), LiDAR, and GPS, to collect and transmit data in real time. Due to the demand for UAVs in various applications such as precision agriculture, search and rescue, wireless communications, and surveillance, several types of UAVs have been invented with different specifications for their size, weight, range and endurance, engine type, and configuration. Because of this variety, the design process and analysis are based on the type of UAV, with the availability of several control techniques that could be used to improve the flight of the UAV in order to avoid obstacles and potential collisions, as well as find the shortest path to save the battery life with the support of optimization techniques. However, UAVs face several challenges in order to fly smoothly, including collision avoidance, battery life, and intruders. This review paper presents UAVs&rsquo; classification, control applications, and future directions in industry and research interest. For the design process, fabrication, and analysis, various control approaches are discussed in detail. Furthermore, the challenges for UAVs, including battery charging, collision avoidance, and security, are also presented and discussed.
KW  - UAV
KW  - drone
KW  - review
KW  - control
KW  - design
KW  - applications
KW  - future research trends
DO  - 10.3390/aerospace8120363
ER  -
TY  - EJOU
AU  - Amândio, Margarida
AU  - Parente, Manuel
AU  - Neves, José
AU  - Fonseca, Paulo
TI  - Integration of Smart Pavement Data with Decision Support Systems: A Systematic Review
T2  - Buildings

PY  - 2021
VL  - 11
IS  - 12
SN  - 2075-5309

AB  - Nowadays, pavement management systems (PMS) are mainly based on monitoring processes that have been established for a long time, and strongly depend on acquired experience. However, with the emergence of smart technologies, such as internet of things and artificial intelligence, PMS could be improved by applying these new smart technologies to their decision support systems, not just by updating their data collection methodologies, but also their data analysis tools. The application of these smart technologies to the field of pavement monitoring and condition evaluation will undoubtedly contribute to more efficient, less costly, safer, and environmentally friendly methodologies. Thus, the main drive of the present work is to provide insight for the development of future decision support systems for smart pavement management by conducting a systematic literature review of the developed works that apply smart technologies to this field. The conclusions drawn from the analysis allowed for the identification of a series of future direction recommendations for researchers. In fact, future PMS should tend to be capable of collecting and analyzing data at different levels, both externally at the surface or inside the pavement, as well as to detect and predict all types of functional and structural flaws and defects.
KW  - smart pavement
KW  - decision support systems
KW  - pavement management systems
KW  - smartphone
KW  - unmanned aerial vehicle (UAV)
KW  - self-powered sensors
KW  - image processing
KW  - artificial intelligence
DO  - 10.3390/buildings11120579
ER  -
TY  - EJOU
AU  - Lewicka, Oktawia
AU  - Specht, Mariusz
AU  - Stateczny, Andrzej
AU  - Specht, Cezary
AU  - Brčić, David
AU  - Jugović, Alen
AU  - Widźgowski, Szymon
AU  - Wiśniewska, Marta
TI  - Analysis of GNSS, Hydroacoustic and Optoelectronic Data Integration Methods Used in Hydrography
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 23
SN  - 1424-8220

AB  - The integration of geospatial data in hydrography, performed using different measurement systems, involves combining several study results to provide a comprehensive analysis. Each of the hydroacoustic and optoelectronic systems is characterised by a different spatial reference system and the method for technical implementation of the measurement. Therefore, the integration of hydrographic data requires that problems in selected fields of electronics, geodesy and physics (acoustics and optics) be solved. The aim of this review is to present selected fusion methods applying the data derived from Global Navigation Satellite System (GNSS), Real Time Kinematic (RTK) measurements, hydrographic surveys, a photogrammetric pass using unmanned vehicles and Terrestrial Laser Scanning (TLS) and compare their accuracy. An additional goal is the evalution of data integration methods according to the International Hydrographic Organization (IHO) S-44 standard. The publication is supplemented by implementation examples of the integration of geospatial data in the Geographic Information System (GIS). The methods described indicate the lack of a uniform methodology for data fusion due to differences in both the spatial reference systems and the techniques used. However, the integration of hydroacoustic and optoelectronic data allows for high accuracy geospatial data to be obtained. This is confirmed by the methods cited, in which the accuracy of integrated geospatial data was in the order of several centimetres.
KW  - data integration
KW  - Global Navigation Satellite System (GNSS)
KW  - hydroacoustic methods
KW  - optoelectronic methods
KW  - hydrographic surveys
DO  - 10.3390/s21237831
ER  -
TY  - EJOU
AU  - Fang, Lifa
AU  - Wu, Yanqiang
AU  - Li, Yuhua
AU  - Guo, Hongen
AU  - Zhang, Hua
AU  - Wang, Xiaoyu
AU  - Xi, Rui
AU  - Hou, Jialin
TI  - Using Channel and Network Layer Pruning Based on Deep Learning for Real-Time Detection of Ginger Images
T2  - Agriculture

PY  - 2021
VL  - 11
IS  - 12
SN  - 2077-0472

AB  - Consistent ginger shoot orientation helps to ensure consistent ginger emergence and meet shading requirements. YOLO v3 is used to recognize ginger images in response to the current ginger seeder&rsquo;s difficulty in meeting the above agronomic problems. However, it is not suitable for direct application on edge computing devices due to its high computational cost. To make the network more compact and to address the problems of low detection accuracy and long inference time, this study proposes an improved YOLO v3 model, in which some redundant channels and network layers are pruned to achieve real-time determination of ginger shoots and seeds. The test results showed that the pruned model reduced its model size by 87.2% and improved the detection speed by 85%. Meanwhile, its mean average precision (mAP) reached 98.0% for ginger shoots and seeds, only 0.1% lower than the model before pruning. Moreover, after deploying the model to the Jetson Nano, the test results showed that its mAP was 97.94%, the recognition accuracy could reach 96.7%, and detection speed could reach 20 frames&middot;s&minus;1. The results showed that the proposed method was feasible for real-time and accurate detection of ginger images, providing a solid foundation for automatic and accurate ginger seeding.
KW  - deep learning
KW  - object detection
KW  - network pruning
KW  - ginger shoots
KW  - ginger seeds
DO  - 10.3390/agriculture11121190
ER  -
TY  - EJOU
AU  - Abujayyab, Sohaib K. M.
AU  - Almotairi, Khaled H.
AU  - Alswaitti, Mohammed
AU  - Amr, Salem S. Abu
AU  - Alkarkhi, Abbas F. M.
AU  - Taşoğlu, Enes
AU  - Hussein, Ahmad M.
TI  - Effects of Meteorological Parameters on Surface Water Loss in Burdur Lake, Turkey over 34 Years Landsat Google Earth Engine Time-Series
T2  - Land

PY  - 2021
VL  - 10
IS  - 12
SN  - 2073-445X

AB  - The current work aims to examine the effect of meteorological parameters as well as the temporal variation on the Burdur Lake surface water body areas in Turkey. The data for the surface area of Burdur Lake was collected over 34 years between 1984 and 2019 by Google Earth Engine. The seasonal variation in the water bodies area was collected using our proposed extraction method and 570 Landsat images. The reduction in the total area of the lake was observed between 206.6 km2 in 1984 to 125.5 km2 in 2019. The vegetation cover and meteorological parameters collected that affect the observed variation of surface water bodies for the same area include precipitation, evapotranspiration, albedo, radiation, and temperature. The selected meteorological variables influence the reduction in lake area directly during various seasons. Correlations showed a strong positive or negative significant relationship between the reduction and the selected meteorological variables. A factor analysis provided three components that explain 82.15% of the total variation in the data. The data provide valuable references for decision makers to develop sustainable agriculture and industrial water use policies to preserve water resources as well as cope with potential climate changes.
KW  - surface water degradation
KW  - meteorological parameters
KW  - surface water mapping
KW  - spatial-temporal variation
KW  - satellite images
KW  - Normalized Difference Water Index (NDWI)
KW  - correlation
KW  - factor analysis
DO  - 10.3390/land10121301
ER  -
TY  - EJOU
AU  - Ojogbane, Sani S.
AU  - Mansor, Shattri
AU  - Kalantar, Bahareh
AU  - Khuzaimah, Zailani B.
AU  - Shafri, Helmi Z.
AU  - Ueda, Naonori
TI  - Automated Building Detection from Airborne LiDAR and Very High-Resolution Aerial Imagery with Deep Neural Network
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 23
SN  - 2072-4292

AB  - The detection of buildings in the city is essential in several geospatial domains and for decision-making regarding intelligence for city planning, tax collection, project management, revenue generation, and smart cities, among other areas. In the past, the classical approach used for building detection was by using the imagery and it entailed human&ndash;computer interaction, which was a daunting proposition. To tackle this task, a novel network based on an end-to-end deep learning framework is proposed to detect and classify buildings features. The proposed CNN has three parallel stream channels: the first is the high-resolution aerial imagery, while the second stream is the digital surface model (DSM). The third was fixed on extracting deep features using the fusion of channel one and channel two, respectively. Furthermore, the channel has eight group convolution blocks of 2D convolution with three max-pooling layers. The proposed model&rsquo;s efficiency and dependability were tested on three different categories of complex urban building structures in the study area. Then, morphological operations were applied to the extracted building footprints to increase the uniformity of the building boundaries and produce improved building perimeters. Thus, our approach bridges a significant gap in detecting building objects in diverse environments; the overall accuracy (OA) and kappa coefficient of the proposed method are greater than 80% and 0.605, respectively. The findings support the proposed framework and methodologies&rsquo; efficacy and effectiveness at extracting buildings from complex environments.
KW  - building classification
KW  - extraction
KW  - convolution neural networks (CNN)
KW  - LiDAR
KW  - high-resolution aerial imagery
DO  - 10.3390/rs13234803
ER  -
TY  - EJOU
AU  - Sott, Michele K.
AU  - Nascimento, Leandro D.
AU  - Foguesatto, Cristian R.
AU  - Furstenau, Leonardo B.
AU  - Faccin, Kadígia
AU  - Zawislak, Paulo A.
AU  - Mellado, Bruce
AU  - Kong, Jude D.
AU  - Bragazzi, Nicola L.
TI  - A Bibliometric Network Analysis of Recent Publications on Digital Agriculture to Depict Strategic Themes and Evolution Structure
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 23
SN  - 1424-8220

AB  - The agriculture sector is one of the backbones of many countries&rsquo; economies. Its processes have been changing to enable technology adoption to increase productivity, quality, and sustainable development. In this research, we present a scientific mapping of the adoption of precision techniques and breakthrough technologies in agriculture, so-called Digital Agriculture. To do this, we used 4694 documents from the Web of Science database to perform a Bibliometric Performance and Network Analysis of the literature using SciMAT software with the support of the PICOC protocol. Our findings presented 22 strategic themes related to Digital Agriculture, such as Internet of Things (IoT), Unmanned Aerial Vehicles (UAV) and Climate-smart Agriculture (CSA), among others. The thematic network structure of the nine most important clusters (motor themes) was presented and an in-depth discussion was performed. The thematic evolution map provides a broad perspective of how the field has evolved over time from 1994 to 2020. In addition, our results discuss the main challenges and opportunities for research and practice in the field of study. Our findings provide a comprehensive overview of the main themes related to Digital Agriculture. These results show the main subjects analyzed on this topic and provide a basis for insights for future research.
KW  - precision agriculture
KW  - agriculture 4.0
KW  - digital agriculture
KW  - smart farming
KW  - industry 4.0
KW  - sustainability
KW  - innovation
KW  - bibliometrics
KW  - science mapping
DO  - 10.3390/s21237889
ER  -
TY  - EJOU
AU  - Lo, Li-Yu
AU  - Yiu, Chi H.
AU  - Tang, Yu
AU  - Yang, An-Shik
AU  - Li, Boyang
AU  - Wen, Chih-Yung
TI  - Dynamic Object Tracking on Autonomous UAV System for Surveillance Applications
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 23
SN  - 1424-8220

AB  - The ever-burgeoning growth of autonomous unmanned aerial vehicles (UAVs) has demonstrated a promising platform for utilization in real-world applications. In particular, a UAV equipped with a vision system could be leveraged for surveillance applications. This paper proposes a learning-based UAV system for achieving autonomous surveillance, in which the UAV can be of assistance in autonomously detecting, tracking, and following a target object without human intervention. Specifically, we adopted the YOLOv4-Tiny algorithm for semantic object detection and then consolidated it with a 3D object pose estimation method and Kalman filter to enhance the perception performance. In addition, UAV path planning for a surveillance maneuver is integrated to complete the fully autonomous system. The perception module is assessed on a quadrotor UAV, while the whole system is validated through flight experiments. The experiment results verified the robustness, effectiveness, and reliability of the autonomous object tracking UAV system in performing surveillance tasks. The source code is released to the research community for future reference.
KW  - UAV
KW  - object detection
KW  - object tracking
KW  - deep learning
KW  - Kalman Filter
KW  - autonomous surveillance
DO  - 10.3390/s21237888
ER  -
TY  - EJOU
AU  - Gopi, Sudheesh P.
AU  - Magarini, Maurizio
TI  - Reinforcement Learning Aided UAV Base Station Location Optimization for Rate Maximization
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 23
SN  - 2079-9292

AB  - The application of unmanned aerial vehicles (UAV) as base station (BS) is gaining popularity. In this paper, we consider maximization of the overall data rate by intelligent deployment of UAV BS in the downlink of a cellular system. We investigate a reinforcement learning (RL)-aided approach to optimize the position of flying BSs mounted on board UAVs to support a macro BS (MBS). We propose an algorithm to avoid collision between multiple UAVs undergoing exploratory movements and to restrict UAV BSs movement within a predefined area. Q-learning technique is used to optimize UAV BS position, where the reward is equal to sum of user equipment (UE) data rates. We consider a framework where the UAV BSs carry out exploratory movements in the beginning and exploitary movements in later stages to maximize the overall data rate. Our results show that a cellular system with three UAV BSs and one MBS serving 72 UE reaches 69.2% of the best possible data rate, which is identified by brute force search. Finally, the RL algorithm is compared with a K-means algorithm to study the need of accurate UE locations. Our results show that the RL algorithm outperforms the K-means clustering algorithm when the measure of imperfection is higher. The proposed algorithm can be made use of by a practical MBS&ndash;UAV BSs&ndash;UEs system to provide protection to UAV BSs while maximizing data rate.
KW  - UAV BS
KW  - reinforcement learning
KW  - K-means clustering
DO  - 10.3390/electronics10232953
ER  -
TY  - EJOU
AU  - Georgopoulos, Nikos
AU  - Gitas, Ioannis Z.
AU  - Stefanidou, Alexandra
AU  - Korhonen, Lauri
AU  - Stavrakoudis, Dimitris
TI  - Estimation of Individual Tree Stem Biomass in an Uneven-Aged Structured Coniferous Forest Using Multispectral LiDAR Data
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 23
SN  - 2072-4292

AB  - Stem biomass is a fundamental component of the global carbon cycle that is essential for forest productivity estimation. Over the last few decades, Light Detection and Ranging (LiDAR) has proven to be a useful tool for accurate carbon stock and biomass estimation in various biomes. The aim of this study was to investigate the potential of multispectral LiDAR data for the reliable estimation of single-tree total and barkless stem biomass (TSB and BSB) in an uneven-aged structured forest with complex topography. Destructive and non-destructive field measurements were collected for a total of 67 dominant and co-dominant Abies borisii-regis trees located in a mountainous area in Greece. Subsequently, two allometric equations were constructed to enrich the reference data with non-destructively sampled trees. Five different regression algorithms were tested for single-tree BSB and TSB estimation using height (height percentiles and bicentiles, max and average height) and intensity (skewness, standard deviation and average intensity) LiDAR-derived metrics: Generalized Linear Models (GLMs), Gaussian Process (GP), Random Forest (RF), Support Vector Regression (SVR) and Extreme Gradient Boosting (XGBoost). The results showcased that the RF algorithm provided the best overall predictive performance in both BSB (i.e., RMSE = 175.76 kg and R2 = 0.78) and TSB (i.e., RMSE = 211.16 kg and R2 = 0.65) cases. Our work demonstrates that BSB can be estimated with moderate to high accuracy using all the tested algorithms, contrary to the TSB, where only three algorithms (RF, SVR and GP) can adequately provide accurate TSB predictions due to bark irregularities along the stems. Overall, the multispectral LiDAR data provide accurate stem biomass estimates, the general applicability of which should be further tested in different biomes and ecosystems.
KW  - stem biomass
KW  - multispectral LiDAR
KW  - remote sensing
KW  - regression analysis
DO  - 10.3390/rs13234827
ER  -
TY  - EJOU
AU  - Dirir, Ahmed
AU  - Ignatious, Henry
AU  - Elsayed, Hesham
AU  - Khan, Manzoor
AU  - Adib, Mohammed
AU  - Mahmoud, Anas
AU  - Al-Gunaid, Moatasem
TI  - An Advanced Deep Learning Approach for Multi-Object Counting in Urban Vehicular Environments
T2  - Future Internet

PY  - 2021
VL  - 13
IS  - 12
SN  - 1999-5903

AB  - Object counting is an active research area that gained more attention in the past few years. In smart cities, vehicle counting plays a crucial role in urban planning and management of the Intelligent Transportation Systems (ITS). Several approaches have been proposed in the literature to address this problem. However, the resulting detection accuracy is still not adequate. This paper proposes an efficient approach that uses deep learning concepts and correlation filters for multi-object counting and tracking. The performance of the proposed system is evaluated using a dataset consisting of 16 videos with different features to examine the impact of object density, image quality, angle of view, and speed of motion towards system accuracy. Performance evaluation exhibits promising results in normal traffic scenarios and adverse weather conditions. Moreover, the proposed approach outperforms the performance of two recent approaches from the literature.
KW  - object counting
KW  - object detection
KW  - multi-object tracking
KW  - deep learning
KW  - YOLO
KW  - correlation filters
DO  - 10.3390/fi13120306
ER  -
TY  - EJOU
AU  - de Carvalho, Osmar L.
AU  - de Moura, Rebeca D.
AU  - de Albuquerque, Anesmar O.
AU  - de Bem, Pablo P.
AU  - de Castro Pereira, Rubens
AU  - Weigang, Li
AU  - Borges, Dibio L.
AU  - Guimarães, Renato F.
AU  - Gomes, Roberto A.
AU  - de Carvalho Júnior, Osmar A.
TI  - Instance Segmentation for Governmental Inspection of Small Touristic Infrastructure in Beach Zones Using Multispectral High-Resolution WorldView-3 Imagery
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 12
SN  - 2220-9964

AB  - Misappropriation of public lands is an ongoing government concern. In Brazil, the beach zone is public property, but many private establishments use it for economic purposes, requiring constant inspection. Among the undue targets, the individual mapping of straw beach umbrellas (SBUs) attached to the sand is a great challenge due to their small size, high presence, and agglutinated appearance. This study aims to automatically detect and count SBUs on public beaches using high-resolution images and instance segmentation, obtaining pixel-wise semantic information and individual object detection. This study is the first instance segmentation application on coastal areas and the first using WorldView-3 (WV-3) images. We used the Mask-RCNN with some modifications: (a) multispectral input for the WorldView3 imagery (eight channels), (b) improved the sliding window algorithm for large image classification, and (c) comparison of different image resizing ratios to improve small object detection since the SBUs are small objects (&lt;322 pixels) even using high-resolution images (31 cm). The accuracy analysis used standard COCO metrics considering the original image and three scale ratios (2&times;, 4&times;, and 8&times; resolution increase). The average precision (AP) results increased proportionally to the image resolution: 30.49% (original image), 48.24% (2&times;), 53.45% (4&times;), and 58.11% (8&times;). The 8&times; model presented 94% AP50, classifying nearly all SBUs correctly. Moreover, the improved sliding window approach enables the classification of large areas providing automatic counting and estimating the size of the objects, proving to be effective for inspecting large coastal areas and providing insightful information for public managers. This remote sensing application impacts the inspection cost, tribute, and environmental conditions.
KW  - Mask-RCNN
KW  - multispectral
KW  - deep learning
KW  - object detection
DO  - 10.3390/ijgi10120813
ER  -
TY  - EJOU
AU  - Mahlberg, Justin A.
AU  - Cheng, Yi-Ting
AU  - Bullock, Darcy M.
AU  - Habib, Ayman
TI  - Leveraging LiDAR Intensity to Evaluate Roadway Pavement Markings
T2  - Future Transportation

PY  - 2021
VL  - 1
IS  - 3
SN  - 2673-7590

AB  - The United States has over 8.8 million lane miles nationwide, which require regular maintenance and evaluations of sign retroreflectivity, pavement markings, and other pavement information. Pavement markings convey crucial information to drivers as well as connected and autonomous vehicles for lane delineations. Current means of evaluation are by human inspection or semi-automated dedicated vehicles, which often capture one to two pavement lines at a time. Mobile LiDAR is also frequently used by agencies to map signs and infrastructure as well as assess pavement conditions and drainage profiles. This paper presents a case study where over 70 miles of US-52 and US-41 in Indiana were assessed, utilizing both a mobile retroreflectometer and a LiDAR mobile mapping system. Comparing the intensity data from LiDAR data and the retroreflective readings, there was a linear correlation for right edge pavement markings with an R2 of 0.87 and for the center skip line a linear correlation with an R2 of 0.63. The p-values were 0.000 and 0.000, respectively. Although there are no published standards for using LiDAR to evaluate pavement marking retroreflectivity, these results suggest that mobile LiDAR is a viable tool for network level monitoring of retroreflectivity.
KW  - LiDAR
KW  - retroreflectometer
KW  - mobile mapping systems
KW  - pavement markings
KW  - retroreflectivity
KW  - intensity profile
DO  - 10.3390/futuretransp1030039
ER  -
TY  - EJOU
AU  - Kartal, Serkan
AU  - Choudhary, Sunita
AU  - Masner, Jan
AU  - Kholová, Jana
AU  - Stočes, Michal
AU  - Gattu, Priyanka
AU  - Schwartz, Stefan
AU  - Kissel, Ewaut
TI  - Machine Learning-Based Plant Detection Algorithms to Automate Counting Tasks Using 3D Canopy Scans
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 23
SN  - 1424-8220

AB  - This study tested whether machine learning (ML) methods can effectively separate individual plants from complex 3D canopy laser scans as a prerequisite to analyzing particular plant features. For this, we scanned mung bean and chickpea crops with PlantEye (R) laser scanners. Firstly, we segmented the crop canopies from the background in 3D space using the Region Growing Segmentation algorithm. Then, Convolutional Neural Network (CNN) based ML algorithms were fine-tuned for plant counting. Application of the CNN-based (Convolutional Neural Network) processing architecture was possible only after we reduced the dimensionality of the data to 2D. This allowed for the identification of individual plants and their counting with an accuracy of 93.18% and 92.87% for mung bean and chickpea plants, respectively. These steps were connected to the phenotyping pipeline, which can now replace manual counting operations that are inefficient, costly, and error-prone. The use of CNN in this study was innovatively solved with dimensionality reduction, addition of height information as color, and consequent application of a 2D CNN-based approach. We found there to be a wide gap in the use of ML on 3D information. This gap will have to be addressed, especially for more complex plant feature extractions, which we intend to implement through further research.
KW  - 3D point clouds
KW  - plant detection
KW  - machine learning
KW  - computer vision
KW  - phenotyping
DO  - 10.3390/s21238022
ER  -
TY  - EJOU
AU  - Osman, Radwa A.
AU  - Saleh, Sherine N.
AU  - Saleh, Yasmine N. M.
AU  - Elagamy, Mazen N.
TI  - Enhancing the Reliability of Communication between Vehicle and Everything (V2X) Based on Deep Learning for Providing Efficient Road Traffic Information
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 23
SN  - 2076-3417

AB  - Developing efficient communication between vehicles and everything (V2X) is a challenging task, mainly due to the characteristics of vehicular networks, which include rapid topology changes, large-scale sizes, and frequent link disconnections. This article proposes a deep learning model to enhance V2X communication. Various channel conditions such as interference, channel noise, and path loss affect the communication between a vehicle (V) and everything (X). Thus, the proposed model aims to determine the required optimum interference power to enhance connectivity, comply with the quality of service (QoS) constraints, and improve the communication link reliability. The proposed model fulfills the best QoS in terms of four metrics, namely, achievable data rate (Rb), packet delivery ratio (PDR), packet loss rate (PLR), and average end-to-end delay (E2E). The factors to be considered are the distribution and density of vehicles, average length, and minimum safety distance between vehicles. A mathematical formulation of the optimum required interference power is presented to achieve the given objectives as a constrained optimization problem, and accordingly, the proposed deep learning model is trained. The obtained results show the ability of the proposed model to enhance the connectivity between V2X for improving road traffic information efficiency and increasing road traffic safety.
KW  - vehicle-to-everything
KW  - QoS
KW  - reliability
KW  - achievable data rate
KW  - deep learning
KW  - 1D-CNN
DO  - 10.3390/app112311382
ER  -
TY  - EJOU
AU  - Velasquez-Camacho, Luisa
AU  - Cardil, Adrián
AU  - Mohan, Midhun
AU  - Etxegarai, Maddi
AU  - Anzaldi, Gabriel
AU  - de-Miguel, Sergio
TI  - Remotely Sensed Tree Characterization in Urban Areas: A Review
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 23
SN  - 2072-4292

AB  - Urban trees and forests provide multiple ecosystem services (ES), including temperature regulation, carbon sequestration, and biodiversity. Interest in ES has increased amongst policymakers, scientists, and citizens given the extent and growth of urbanized areas globally. However, the methods and techniques used to properly assess biodiversity and ES provided by vegetation in urban environments, at large scales, are insufficient. Individual tree identification and characterization are some of the most critical issues used to evaluate urban biodiversity and ES, given the complex spatial distribution of vegetation in urban areas and the scarcity or complete lack of systematized urban tree inventories at large scales, e.g., at the regional or national levels. This often limits our knowledge on their contributions toward shaping biodiversity and ES in urban areas worldwide. This paper provides an analysis of the state-of-the-art studies and was carried out based on a systematic review of 48 scientific papers published during the last five years (2016&ndash;2020), related to urban tree and greenery characterization, remote sensing techniques for tree identification, processing methods, and data analysis to classify and segment trees. In particular, we focused on urban tree and forest characterization using remotely sensed data and identified frontiers in scientific knowledge that may be expanded with new developments in the near future. We found advantages and limitations associated with both data sources and processing methods, from which we drew recommendations for further development of tree inventory and characterization in urban forestry science. Finally, a critical discussion on the current state of the methods, as well as on the challenges and directions for future research, is presented.
KW  - tree detection
KW  - urban forest inventory
KW  - remote sensing
KW  - artificial intelligence
KW  - biodiversity
KW  - ecosystem services
DO  - 10.3390/rs13234889
ER  -
TY  - EJOU
AU  - Zhang, Xiaoning
AU  - Jiao, Ziti
AU  - Zhao, Changsen
AU  - Yin, Siyang
AU  - Cui, Lei
AU  - Dong, Yadong
AU  - Zhang, Hu
AU  - Guo, Jing
AU  - Xie, Rui
AU  - Li, Sijie
AU  - Zhu, Zidong
AU  - Tong, Yidong
TI  - Retrieval of Leaf Area Index by Linking the PROSAIL and Ross-Li BRDF Models Using MODIS BRDF Data
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 23
SN  - 2072-4292

AB  - Canopy structure parameters (e.g., leaf area index (LAI)) are key variables of most climate and ecology models. Currently, satellite-observed reflectances at a few viewing angles are often directly used for vegetation structure parameter retrieval; therefore, the information content of multi-angular observations that are sensitive to canopy structure in theory cannot be sufficiently considered. In this study, we proposed a novel method to retrieve LAI based on modelled multi-angular reflectances at sufficient sun-viewing geometries, by linking the PROSAIL model with a kernel-driven Ross-Li bi-directional reflectance function (BRDF) model using the MODIS BRDF parameter product. First, BRDF sensitivity to the PROSAIL input parameters was investigated to reduce the insensitive parameters. Then, MODIS BRDF parameters were used to model sufficient multi-angular reflectances. By comparing these reference MODIS reflectances with simulated PROSAIL reflectances within the range of the sensitive input parameters in the same geometries, the optimal vegetation parameters were determined by searching the minimum discrepancies between them. In addition, a significantly linear relationship between the average leaf angle (ALA) and the coefficient of the volumetric scattering kernel of the Ross-Li model in the near-infrared band was built, which can narrow the search scope of the ALA and accelerate the retrieval. In the validation, the proposed method attains a higher consistency (root mean square error (RMSE) = 1.13, bias = &minus;0.19, and relative RMSE (RRMSE) = 36.8%) with field-measured LAIs and 30-m LAI maps for crops than that obtained with the MODIS LAI product. The results indicate the vegetation inversion potential of sufficient multi-angular data and the ALA relationship, and this method presents promise for large-scale LAI estimation.
KW  - vegetation estimation
KW  - leaf area index (LAI)
KW  - average leaf angle (ALA)
KW  - bidirectional reflectance
KW  - kernel-driven Ross-Li model
DO  - 10.3390/rs13234911
ER  -
TY  - EJOU
AU  - Chung, Ming-An
AU  - Lin, Chia-Wei
AU  - Chang, Chih-Tsung
TI  - The Human&mdash;Unmanned Aerial Vehicle System Based on SSVEP&mdash;Brain Computer Interface
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 23
SN  - 2079-9292

AB  - The brain&ndash;computer interface (BCI) is a mechanism for extracting information from the brain, with this information used for various applications. This study proposes a method to control an unmanned aerial vehicle (UAV) flying through a BCI system using the steady-state visual evoked potential (SSVEP) approach. The UAV&rsquo;s screen emits three frequencies for visual stimulation: 15, 23, and 31 Hz for the UAV&rsquo;s left-turn, forward-flight, and right-turn functions. Due to the requirement of immediate response to the UAV flight, this paper proposes a method to improve the accuracy rate and reduce the time required to correct instruction errors in the resolution of brainwave signals received by UAVs. This study tested ten subjects and verified that the proposed method has a 10% improvement inaccuracy. While the traditional method can take 8 s to correct an error, the proposed method requires only 1 s, making it more suitable for practical applications in UAVs. Furthermore, such a BCI application for UAV systems can achieve the same experience of using the remote control for physically challenged patients.
KW  - brain–computer interface (BCI)
KW  - electroencephalography (EEG)
KW  - steady-state visual evoked potential (SSVEP)
KW  - fast Fourier transform (FFT)
KW  - unmanned aerial vehicle (UAV)
DO  - 10.3390/electronics10233025
ER  -
TY  - EJOU
AU  - Al-Okby, Mohammed F.
AU  - Neubert, Sebastian
AU  - Roddelkopf, Thomas
AU  - Thurow, Kerstin
TI  - Mobile Detection and Alarming Systems for Hazardous Gases and Volatile Chemicals in Laboratories and Industrial Locations
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 23
SN  - 1424-8220

AB  - The leakage of hazardous gases and chemical vapors is considered one of the dangerous accidents that can occur in laboratories, workshops, warehouses, and industrial sites that use or store these substances. The early detection and alarming of hazardous gases and volatile chemicals are significant to keep the safety conditions for the people and life forms who are work in and live around these places. In this paper, we investigate the available mobile detection and alarming systems for toxic, hazardous gases and volatile chemicals, especially in the laboratory environment. We included papers from January 2010 to August 2021 which may have the newest used sensors technologies and system components. We identified (236) papers from Clarivate Web of Science (WoS), IEEE, ACM Library, Scopus, and PubMed. Paper selection has been done based on a fast screening of the title and abstract, then a full-text reading was applied to filter the selected papers that resulted in (42) eligible papers. The main goal of this work is to discuss the available mobile hazardous gas detection and alarming systems based on several technical details such as the used gas detection technology (simple element, integrated, smart, etc.), sensor manufacturing technology (catalytic bead, MEMS, MOX, etc.) the sensor specifications (warm-up time, lifetime, response time, precision, etc.), processor type (microprocessor, microcontroller, PLC, etc.), and type of the used communication technology (Bluetooth/BLE, Wi-Fi/RF, ZigBee/XBee, LoRa, etc.). In this review, attention will be focused on the improvement of the detection and alarming system of hazardous gases with the latest invention in sensors, processors, communication, and battery technologies.
KW  - hazardous gases
KW  - toxic gases
KW  - gas sensor
KW  - safety system
KW  - volatile organic materials (VOCs)
KW  - alarming system
KW  - internet of things (IoT)
KW  - wireless sensor networks (WSNs)
DO  - 10.3390/s21238128
ER  -
TY  - EJOU
AU  - Yang, Pu
AU  - Wang, Zixin
AU  - Zhang, Zhiqing
AU  - Hu, Xukai
TI  - Sliding Mode Fault Tolerant Control for a Quadrotor with Varying Load and Actuator Fault
T2  - Actuators

PY  - 2021
VL  - 10
IS  - 12
SN  - 2076-0825

AB  - In this paper, an adaptive sliding mode fault-tolerant control scheme based on prescribed performance control and neural networks is developed for an Unmanned Aerial Vehicle (UAV) quadrotor carrying a load to deal with actuator faults. First, a nonsingular fast terminal sliding mode (NFTSM) control strategy is presented. In virtue of the proposed strategy, fast convergence and high robustness can be guaranteed without stimulating chattering. Secondly, to obtain correct fault magnitudes and compensate the failures actively, a radial basis function neural network-based fault estimation scheme is proposed. By combining the proposed fault estimation strategy and the NFTSM controller, an active fault-tolerant control algorithm is established. Then, the uncertainties caused by load variation are explicitly considered and compensated by the presented adaptive laws. Moreover, by synthesizing the proposed sliding mode control and prescribed performance control (PPC), an output error transformation is defined to deal with state constraints and provide better tracking performance. From the Lyapunov stability analysis, the overall system is proven to be uniformly asymptotically stable. Finally, numerical simulation based on a quadrotor helicopter is carried out to validate the effectiveness and superiority of the proposed algorithm.
KW  - quadrotor UAV
KW  - fault-tolerant control
KW  - sliding mode control
KW  - prescribed performance
DO  - 10.3390/act10120323
ER  -
TY  - EJOU
AU  - Hu, Shuang
AU  - Liu, Jin
AU  - Kang, Zhiwei
TI  - DeepLabV3+/Efficientnet Hybrid Network-Based Scene Area Judgment for the Mars Unmanned Vehicle System
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 23
SN  - 1424-8220

AB  - Due to the complexity and danger of Mars&rsquo;s environment, traditional Mars unmanned ground vehicles cannot efficiently perform Mars exploration missions. To solve this problem, the DeepLabV3+/Efficientnet hybrid network is proposed and applied to the scene area judgment for the Mars unmanned vehicle system. Firstly, DeepLabV3+ is used to extract the feature information of the Mars image due to its high accuracy. Then, the feature information is used as the input for Efficientnet, and the categories of scene areas are obtained, including safe area, report area, and dangerous area. Finally, according to three categories, the Mars unmanned vehicle system performs three operations: pass, report, and send. Experimental results show the effectiveness of the DeepLabV3+/Efficientnet hybrid network in the scene area judgment. Compared with the Efficientnet network, the accuracy of the DeepLabV3+/Efficientnet hybrid network is improved by approximately 18% and reaches 99.84%, which ensures the safety of the exploration mission for the Mars unmanned vehicle system.
KW  - hybrid neural network
KW  - UAV
KW  - feature extraction
KW  - scene area judgment
DO  - 10.3390/s21238136
ER  -
TY  - EJOU
AU  - Gao, Meijing
AU  - Bai, Yang
AU  - Li, Zhilong
AU  - Li, Shiyu
AU  - Zhang, Bozhi
AU  - Chang, Qiuyue
TI  - Real-Time Jellyfish Classification and Detection Based on Improved YOLOv3 Algorithm
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 23
SN  - 1424-8220

AB  - In recent years, jellyfish outbreaks have frequently occurred in offshore areas worldwide, posing a significant threat to the marine fishery, tourism, coastal industry, and personal safety. Effective monitoring of jellyfish is a vital method to solve the above problems. However, the optical detection method for jellyfish is still in the primary stage. Therefore, this paper studies a jellyfish detection method based on convolution neural network theory and digital image processing technology. This paper studies the underwater image preprocessing algorithm because the quality of underwater images directly affects the detection results. The results show that the image quality is better after applying the three algorithms namely prior defogging, adaptive histogram equalization, and multi-scale retinal enhancement, which is more conducive to detection. We establish a data set containing seven species of jellyfishes and fish. A total of 2141 images are included in the data set. The YOLOv3 algorithm is used to detect jellyfish, and its feature extraction network Darknet53 is optimized to ensure it is conducted in real-time. In addition, we introduce label smoothing and cosine annealing learning rate methods during the training process. The experimental results show that the improved algorithms improve the detection accuracy of jellyfish on the premise of ensuring the detection speed. This paper lays a foundation for the construction of an underwater jellyfish optical imaging real-time monitoring system.
KW  - jellyfish
KW  - convolutional neural network
KW  - image processing
KW  - YOLOv3
DO  - 10.3390/s21238160
ER  -
TY  - EJOU
AU  - Fan, Dongliang
AU  - Su, Xiaoyun
AU  - Weng, Bo
AU  - Wang, Tianshu
AU  - Yang, Feiyun
TI  - Research Progress on Remote Sensing Classification Methods for Farmland Vegetation
T2  - AgriEngineering

PY  - 2021
VL  - 3
IS  - 4
SN  - 2624-7402

AB  - Crop planting area and spatial distribution information have important practical significance for food security, global change, and sustainable agricultural development. How to efficiently and accurately identify crops in a timely manner by remote sensing in order to determine the crop planting area and its temporal&ndash;spatial dynamic change information is a core issue of monitoring crop growth and estimating regional crop yields. Based on hundreds of relevant documents from the past 25 years, in this paper, we summarize research progress in relation to farmland vegetation identification and classification by remote sensing. The classification and identification of farmland vegetation includes classification based on vegetation index, spectral bands, multi-source data fusion, artificial intelligence learning, and drone remote sensing. Representative studies of remote sensing methods are collated, the main content of each technology is summarized, and the advantages and disadvantages of each method are analyzed. Current problems related to crop remote sensing identification are then identified and future development directions are proposed.
KW  - agriculture
KW  - food security
KW  - remote sensing
KW  - farmland vegetation
KW  - identification
KW  - classification
DO  - 10.3390/agriengineering3040061
ER  -
TY  - EJOU
AU  - Kilwenge, Regina
AU  - Adewopo, Julius
AU  - Sun, Zhanli
AU  - Schut, Marc
TI  - UAV-Based Mapping of Banana Land Area for Village-Level Decision-Support in Rwanda
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 24
SN  - 2072-4292

AB  - Crop monitoring is crucial to understand crop production changes, agronomic practice decision-support, pests/diseases mitigation, and developing climate change adaptation strategies. Banana, an important staple food and cash crop in East Africa, is threatened by Banana Xanthomonas Wilt (BXW) disease. Yet, there is no up-to-date information about the spatial distribution and extent of banana lands, especially in Rwanda, where banana plays a key role in food security and livelihood. Therefore, delineation of banana-cultivated lands is important to prioritize resource allocation for optimal productivity. We mapped the spatial extent of smallholder banana farmlands by acquiring and processing high-resolution (25 cm/px) multispectral unmanned aerial vehicles (UAV) imageries, across four villages in Rwanda. Georeferenced ground-truth data on different land cover classes were combined with reflectance data and vegetation indices (NDVI, GNDVI, and EVI2) and compared using pixel-based supervised multi-classifiers (support vector models-SVM, classification and regression trees-CART, and random forest&ndash;RF), based on varying ground-truth data richness. Results show that RF consistently outperformed other classifiers regardless of data richness, with overall accuracy above 95%, producer&rsquo;s/user&rsquo;s accuracies above 92%, and kappa coefficient above 0.94. Estimated banana farmland areal coverage provides concrete baseline for extension-delivery efforts in terms of targeting banana farmers relative to their scale of production, and highlights opportunity to combine UAV-derived data with machine-learning methods for rapid landcover classification.
KW  - Rwanda
KW  - banana
KW  - machine learning
KW  - UAV
KW  - remote sensing
KW  - land cover mapping
KW  - precision agriculture
KW  - food security
KW  - BXW
DO  - 10.3390/rs13244985
ER  -
TY  - EJOU
AU  - Li, Zhipeng
AU  - Ding, Jie
AU  - Zhang, Heyu
AU  - Feng, Yiming
TI  - Classifying Individual Shrub Species in UAV Images&mdash;A Case Study of the Gobi Region of Northwest China
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 24
SN  - 2072-4292

AB  - Shrublands are the main vegetation component in the Gobi region and contribute considerably to its ecosystem. Accurately classifying individual shrub vegetation species to understand their spatial distributions and to effectively monitor species diversity in the Gobi ecosystem is essential. High-resolution remote sensing data create vegetation type inventories over large areas. However, high spectral similarity between shrublands and surrounding areas remains a challenge. In this study, we provide a case study that integrates object-based image analysis (OBIA) and the random forest (RF) model to classify shrubland species automatically. The Gobi region on the southern slope of the Tian Shan Mountains in Northwest China was analyzed using readily available unmanned aerial vehicle (UAV) RGB imagery (1.5 cm spatial resolution). Different spectral and texture index images were derived from UAV RGB images as variables for species classification. Principal component analysis (PCA) extracted features from different types of variable sets (original bands, original bands + spectral indices, and original bands + spectral indices + texture indices). We tested the ability of several non-parametric decision tree models and different types of variable sets to classify shrub species. Moreover, we analyzed three main shrubland areas comprising different shrub species and compared the prediction accuracies of the optimal model in combination with different types of variable sets. We found that the RF model could generate higher accuracy compared with the other two models. The best results were obtained using a combination of the optimal variable set and the RF model with an 88.63% overall accuracy and 0.82 kappa coefficient. Integrating OBIA and RF in the species classification process provides a promising method for automatic mapping of individual shrub species in the Gobi region and can reduce the workload of individual shrub species classification.
KW  - shrub species classification
KW  - unmanned aerial vehicle
KW  - RGB image
KW  - object-based image analysis
KW  - spectral indices
KW  - texture indices
DO  - 10.3390/rs13244995
ER  -
TY  - EJOU
AU  - He, Boyong
AU  - Li, Xianjiang
AU  - Huang, Bo
AU  - Gu, Enhui
AU  - Guo, Weijie
AU  - Wu, Liaoni
TI  - UnityShip: A Large-Scale Synthetic Dataset for Ship Recognition in Aerial Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 24
SN  - 2072-4292

AB  - As a data-driven approach, deep learning requires a large amount of annotated data for training to obtain a sufficiently accurate and generalized model, especially in the field of computer vision. However, when compared with generic object recognition datasets, aerial image datasets are more challenging to acquire and more expensive to label. Obtaining a large amount of high-quality aerial image data for object recognition and image understanding is an urgent problem. Existing studies show that synthetic data can effectively reduce the amount of training data required. Therefore, in this paper, we propose the first synthetic aerial image dataset for ship recognition, called UnityShip. This dataset contains over 100,000 synthetic images and 194,054 ship instances, including 79 different ship models in ten categories and six different large virtual scenes with different time periods, weather environments, and altitudes. The annotations include environmental information, instance-level horizontal bounding boxes, oriented bounding boxes, and the type and ID of each ship. This provides the basis for object detection, oriented object detection, fine-grained recognition, and scene recognition. To investigate the applications of UnityShip, the synthetic data were validated for model pre-training and data augmentation using three different object detection algorithms and six existing real-world ship detection datasets. Our experimental results show that for small-sized and medium-sized real-world datasets, the synthetic data achieve an improvement in model pre-training and data augmentation, showing the value and potential of synthetic data in aerial image recognition and understanding tasks.
KW  - deep learning
KW  - synthetic data
KW  - ship recognition
KW  - aerial imagery
DO  - 10.3390/rs13244999
ER  -
TY  - EJOU
AU  - Gardiner, Laura-Jayne
AU  - Krishna, Ritesh
TI  - Bluster or Lustre: Can AI Improve Crops and Plant Health?
T2  - Plants

PY  - 2021
VL  - 10
IS  - 12
SN  - 2223-7747

AB  - In a changing climate where future food security is a growing concern, researchers are exploring new methods and technologies in the effort to meet ambitious crop yield targets. The application of Artificial Intelligence (AI) including Machine Learning (ML) methods in this area has been proposed as a potential mechanism to support this. This review explores current research in the area to convey the state-of-the-art as to how AI/ML have been used to advance research, gain insights, and generally enable progress in this area. We address the question&mdash;Can AI improve crops and plant health? We further discriminate the bluster from the lustre by identifying the key challenges that AI has been shown to address, balanced with the potential issues with its usage, and the key requisites for its success. Overall, we hope to raise awareness and, as a result, promote usage, of AI related approaches where they can have appropriate impact to improve practices in agricultural and plant sciences.
KW  - AI
KW  - machine learning
KW  - crops
KW  - plant HEALTH
KW  - omics
KW  - disruptive technologies
DO  - 10.3390/plants10122707
ER  -
TY  - EJOU
AU  - Ma, Minfei
AU  - Liu, Jianhong
AU  - Liu, Mingxing
AU  - Zeng, Jingchao
AU  - Li, Yuanhui
TI  - Tree Species Classification Based on Sentinel-2 Imagery and Random Forest Classifier in the Eastern Regions of the Qilian Mountains
T2  - Forests

PY  - 2021
VL  - 12
IS  - 12
SN  - 1999-4907

AB  - Obtaining accurate forest coverage of tree species is an important basis for the rational use and protection of existing forest resources. However, most current studies have mainly focused on broad tree classification, such as coniferous vs. broadleaf tree species, and a refined tree classification with tree species information is urgently needed. Although airborne LiDAR data or unmanned aerial vehicle (UAV) images can be used to acquire tree information even at the single tree level, this method will encounter great difficulties when applied to a large area. Therefore, this study takes the eastern regions of the Qilian Mountains as an example to explore the possibility of tree species classification with satellite-derived images. We used Sentinel-2 images to classify the study area&rsquo;s major vegetation types, particularly four tree species, i.e., Sabina przewalskii (S.P.), Picea crassifolia (P.C.), Betula spp. (Betula), and Populus spp. (Populus). In addition to the spectral features, we also considered terrain and texture features in this classification. The results show that adding texture features can significantly increase the separation between tree species. The final classification result of all categories achieved an accuracy of 86.49% and a Kappa coefficient of 0.83. For trees, the classification accuracy was 90.31%, and their producer&rsquo;s accuracy (PA) and user&rsquo;s (UA) were all higher than 84.97%. We found that altitude, slope, and aspect all affected the spatial distribution of these four tree species in our study area. This study confirms the potential of Sentinel-2 images for the fine classification of tree species. Moreover, this can help monitor ecosystem biological diversity and provide references for inventory estimation.
KW  - Sentinel-2 image
KW  - random forest
KW  - tree species
KW  - vegetation classification
DO  - 10.3390/f12121736
ER  -
TY  - EJOU
AU  - Shinde, Swapnil S.
AU  - Tarchi, Daniele
TI  - Towards a Novel Air&ndash;Ground Intelligent Platform for Vehicular Networks: Technologies, Scenarios, and Challenges
T2  - Smart Cities

PY  - 2021
VL  - 4
IS  - 4
SN  - 2624-6511

AB  - Modern cities require a tighter integration with Information and Communication Technologies (ICT) for bringing new services to the citizens. The Smart City is the revolutionary paradigm aiming at integrating the ICT with the citizen life; among several urban services, transports are one of the most important in modern cities, introducing several challenges to the Smart City paradigm. In order to satisfy the stringent requirements of new vehicular applications and services, Edge Computing (EC) is one of the most promising technologies when integrated into the Vehicular Networks (VNs). EC-enabled VNs can facilitate new latency-critical and data-intensive applications and services. However, ground-based EC platforms (i.e., Road Side Units&mdash;RSUs, 5G Base Stations&mdash;5G BS) can only serve a reduced number of Vehicular Users (VUs), due to short coverage ranges and resource shortage. In the recent past, several new aerial platforms with integrated EC facilities have been deployed for achieving global connectivity. Such air-based EC platforms can complement the ground-based EC facilities for creating a futuristic VN able to deploy several new applications and services. The goal of this work is to explore the possibility of creating a novel joint air-ground EC platform within a VN architecture for helping VUs with new intelligent applications and services. By exploiting most modern technologies, with particular attention towards network softwarization, vehicular edge computing, and machine learning, we propose here three possible layered air-ground EC-enabled VN scenarios. For each of the discussed scenarios, a list of the possible challenges is considered, as well possible solutions allowing to overcome all or some of the considered challenges. A proper comparison is also done, through the use of tables, where all the proposed scenarios, and the proposed solutions, are discussed.
KW  - smart cities
KW  - vehicular networks
KW  - edge computing
KW  - machine learning
KW  - network softwarization
KW  - aerial platforms
DO  - 10.3390/smartcities4040078
ER  -
TY  - EJOU
AU  - Agapiou, Athos
AU  - Vionis, Athanasios
AU  - Papantoniou, Giorgos
TI  - Detection of Archaeological Surface Ceramics Using Deep Learning Image-Based Methods and Very High-Resolution UAV Imageries
T2  - Land

PY  - 2021
VL  - 10
IS  - 12
SN  - 2073-445X

AB  - Mapping surface ceramics through systematic pedestrian archaeological survey is considered a consistent method to recover the cultural biography of sites within a micro-region. Archaeologists nowadays conduct surface survey equipped with navigation devices counting, documenting, and collecting surface archaeological potsherds within a set of plotted grids. Recent advancements in unmanned aerial vehicles (UAVs) and image processing analysis can be utilised to support such surface archaeological investigations. In this study, we have implemented two different artificial intelligence image processing methods over two areas of interest near the present-day village of Kophinou in Cyprus, in the Xeros River valley. We have applied a random forest classifier through the Google Earth Engine big data cloud platform and a Single Shot Detector neural network in the ArcGIS Pro environment. For the first case study, the detection was based on red&ndash;green&ndash;blue (RGB) high-resolution orthophotos. In contrast, a multispectral camera covering both the visible and the near-infrared parts of the spectrum was used in the second area of investigation. The overall results indicate that such an approach can be used in the future as part of ongoing archaeological pedestrian surveys to detect scattered potsherds in areas of archaeological interest, even if pottery shares a very high spectral similarity with the surface.
KW  - potsherds
KW  - detection
KW  - pedestrian survey
KW  - remote sensing archaeology
KW  - single shot detector
KW  - artificial intelligence
KW  - random forest
KW  - Google Earth Engine
KW  - Cyprus
DO  - 10.3390/land10121365
ER  -
TY  - EJOU
AU  - Liu, Wenjian
AU  - Li, Yanjie
AU  - Liu, Jun
AU  - Jiang, Jingmin
TI  - Estimation of Plant Height and Aboveground Biomass of Toona sinensis under Drought Stress Using RGB-D Imaging
T2  - Forests

PY  - 2021
VL  - 12
IS  - 12
SN  - 1999-4907

AB  - Rapid and accurate plant growth and biomass estimation is essential for formulating and implementing targeted forest cultivation measures. In this study, RGB-D imaging technology was used to obtain the RGB and depth imaging data for a Toona sinensis seedling canopy to estimate plant growth and aboveground biomass (AGB). Three hundred T. sinensis seedlings from 20 varieties were planted under five different drought stress treatments. The U-Net model was applied first to achieve highly accurate segmentation of plants from complex backgrounds. Simple linear regression (SLR) was used for plant height prediction, and the other three models, including multivariate linear (ML), random forest (RF) and multilayer perceptron (MLP) regression, were applied to predict the AGB and compared for optimal model selection. The results showed that the SLR model yields promising and reliable results for the prediction of plant height, with R2 and RMSE values of 0.72 and 1.89 cm, respectively. All three regression methods perform well in the prediction of AGB estimation. MLP yields the highest accuracy in predicting dry and fresh aboveground biomass compared to the other two regression models, with R2 values of 0.77 and 0.83, respectively. The combination of Gray, Green minus red (GMR) and Excess green index (ExG) was identified as the key predictor by RReliefF for predicting dry AGB. GMR was the most important in predicting fresh AGB. This study demonstrated that the merits of RGB-D and machine learning models are effective phenotyping techniques for plant height and AGB prediction, and can be used to assist dynamic responses to drought stress for breeding selection.
KW  - RGB-D imaging
KW  - Toona sinensis seedling
KW  - aboveground biomass
KW  - plant height
KW  - machine learning
DO  - 10.3390/f12121747
ER  -
TY  - EJOU
AU  - Rakkolainen, Ismo
AU  - Farooq, Ahmed
AU  - Kangas, Jari
AU  - Hakulinen, Jaakko
AU  - Rantala, Jussi
AU  - Turunen, Markku
AU  - Raisamo, Roope
TI  - Technologies for Multimodal Interaction in Extended Reality&mdash;A Scoping Review
T2  - Multimodal Technologies and Interaction

PY  - 2021
VL  - 5
IS  - 12
SN  - 2414-4088

AB  - When designing extended reality (XR) applications, it is important to consider multimodal interaction techniques, which employ several human senses simultaneously. Multimodal interaction can transform how people communicate remotely, practice for tasks, entertain themselves, process information visualizations, and make decisions based on the provided information. This scoping review summarized recent advances in multimodal interaction technologies for head-mounted display-based (HMD) XR systems. Our purpose was to provide a succinct, yet clear, insightful, and structured overview of emerging, underused multimodal technologies beyond standard video and audio for XR interaction, and to find research gaps. The review aimed to help XR practitioners to apply multimodal interaction techniques and interaction researchers to direct future efforts towards relevant issues on multimodal XR. We conclude with our perspective on promising research avenues for multimodal interaction technologies.
KW  - multimodality
KW  - human-computer interaction
KW  - extended reality
KW  - augmented reality
KW  - virtual reality
KW  - mixed reality
DO  - 10.3390/mti5120081
ER  -
TY  - EJOU
AU  - Xu, Yaping
AU  - Shrestha, Vivek
AU  - Piasecki, Cristiano
AU  - Wolfe, Benjamin
AU  - Hamilton, Lance
AU  - Millwood, Reginald J.
AU  - Mazarei, Mitra
AU  - Stewart, Charles N.
TI  - Sustainability Trait Modeling of Field-Grown Switchgrass (Panicum virgatum) Using UAV-Based Imagery
T2  - Plants

PY  - 2021
VL  - 10
IS  - 12
SN  - 2223-7747

AB  - Unmanned aerial vehicles (UAVs) provide an intermediate scale of spatial and spectral data collection that yields increased accuracy and consistency in data collection for morphological and physiological traits than satellites and expanded flexibility and high-throughput compared to ground-based data collection. In this study, we used UAV-based remote sensing for automated phenotyping of field-grown switchgrass (Panicum virgatum), a leading bioenergy feedstock. Using vegetation indices calculated from a UAV-based multispectral camera, statistical models were developed for rust disease caused by Puccinia novopanici, leaf chlorophyll, nitrogen, and lignin contents. For the first time, UAV remote sensing technology was used to explore the potentials for multiple traits associated with sustainable production of switchgrass, and one statistical model was developed for each individual trait based on the statistical correlation between vegetation indices and the corresponding trait. Also, for the first time, lignin content was estimated in switchgrass shoots via UAV-based multispectral image analysis and statistical analysis. The UAV-based models were verified by ground-truthing via correlation analysis between the traits measured manually on the ground-based with UAV-based data. The normalized difference red edge (NDRE) vegetation index outperformed the normalized difference vegetation index (NDVI) for rust disease and nitrogen content, while NDVI performed better than NDRE for chlorophyll and lignin content. Overall, linear models were sufficient for rust disease and chlorophyll analysis, but for nitrogen and lignin contents, nonlinear models achieved better results. As the first comprehensive study to model switchgrass sustainability traits from UAV-based remote sensing, these results suggest that this methodology can be utilized for switchgrass high-throughput phenotyping in the field.
KW  - sustainability
KW  - switchgrass
KW  - rust disease
KW  - chlorophyll
KW  - nitrogen
KW  - lignin
KW  - UAV
KW  - high throughput modeling
DO  - 10.3390/plants10122726
ER  -
TY  - EJOU
AU  - Mousa, Mohammed A.
AU  - Yussof, Mustafasanie M.
AU  - Udi, Ufuoma J.
AU  - Nazri, Fadzli M.
AU  - Kamarudin, Mohd K.
AU  - Parke, Gerard A. R.
AU  - Assi, Lateef N.
AU  - Ghahari, Seyed A.
TI  - Application of Digital Image Correlation in Structural Health Monitoring of Bridge Infrastructures: A Review
T2  - Infrastructures

PY  - 2021
VL  - 6
IS  - 12
SN  - 2412-3811

AB  - A vision-based approach has been employed in Structural Health Monitoring (SHM) of bridge infrastructure. The approach has many advantages: non-contact, non-destructive, long-distance, high precision, immunity from electromagnetic interference, and multiple-target monitoring. This review aims to summarise the vision- and Digital Image Correlation (DIC)-based SHM methods for bridge infrastructure because of their strategic significance and security concerns. Four different bridge types were studied: concrete, suspension, masonry, and steel bridge. DIC applications in SHM have recently garnered attention in aiding to assess the bridges&rsquo; structural response mechanisms under loading. Different non-destructive diagnostics methods for SHM in civil infrastructure have been used; however, vision-based techniques like DIC were only developed over the last two decades, intending to facilitate damage detection in bridge systems with prompt and accurate data for efficient and sustainable operation of the bridge structure throughout its service life. Research works reviewed in this article demonstrated the DIC capability to detect damage such as cracks, spalling, and structural parameters such as deformation, strains, vibration, deflection, and rotation. In addition, the reviewed works indicated that the DIC as an efficient and reliable technique could provide sustainable monitoring solutions for different bridge infrastructures.
KW  - bridges
KW  - digital image correlation (DIC)
KW  - vision-based method
KW  - structural health monitoring (SHM)
DO  - 10.3390/infrastructures6120176
ER  -
TY  - EJOU
AU  - Zhu, Pengxing
AU  - Fang, Xi
TI  - Multi-UAV Cooperative Task Assignment Based on Half Random Q-Learning
T2  - Symmetry

PY  - 2021
VL  - 13
IS  - 12
SN  - 2073-8994

AB  - Unmanned aerial vehicle (UAV) clusters usually face problems such as complex environments, heterogeneous combat subjects, and realistic interference factors in the course of mission assignment. In order to reduce resource consumption and improve the task execution rate, it is very important to develop a reasonable allocation plan for the tasks. Therefore, this paper constructs a heterogeneous UAV multitask assignment model based on several realistic constraints and proposes an improved half-random Q-learning (HR Q-learning) algorithm. The algorithm is based on the Q-learning algorithm under reinforcement learning, and by changing the way the Q-learning algorithm selects the next action in the process of random exploration, the probability of obtaining an invalid action in the random case is reduced, and the exploration efficiency is improved, thus increasing the possibility of obtaining a better assignment scheme, this also ensures symmetry and synergy in the distribution process of the drones. Simulation experiments show that compared with Q-learning algorithm and other heuristic algorithms, HR Q-learning algorithm can improve the performance of task execution, including the ability to improve the rationality of task assignment, increasing the value of gains by 12.12%, this is equivalent to an average of one drone per mission saved, and higher success rate of task execution. This improvement provides a meaningful attempt for UAV task assignment.
KW  - task allocation
KW  - half-random Q-learning
KW  - UAV collaboration
KW  - random exploration
DO  - 10.3390/sym13122417
ER  -
TY  - EJOU
AU  - Khalid, Adnan
AU  - Jaffery, Mujtaba H.
AU  - Javed, Muhammad Y.
AU  - Yousaf, Adnan
AU  - Arshad, Jehangir
AU  - Ur Rehman, Ateeq
AU  - Haider, Aun
AU  - Althobaiti, Maha M.
AU  - Shafiq, Muhammad
AU  - Hamam, Habib
TI  - Performance Analysis of Mars-Powered Descent-Based Landing in a Constrained Optimization Control Framework
T2  - Energies

PY  - 2021
VL  - 14
IS  - 24
SN  - 1996-1073

AB  - It is imperative to find new places other than Earth for the survival of human beings. Mars could be the alternative to Earth in the future for us to live. In this context, many missions have been performed to examine the planet Mars. For such missions, planetary precision landing is a major challenge for the precise landing on Mars. Mars landing consists of different phases (hypersonic entry, parachute descent, terminal descent comprising gravity turn, and powered descent). However, the focus of this work is the powered descent phase of landing. Firstly, the main objective of this study is to minimize the landing error during the powered descend landing phase. The second objective involves constrained optimization in a predictive control framework for landing at non-cooperative sites. Different control algorithms like PID and LQR have been developed for the stated problem; however, the predictive control algorithm with constraint handling&rsquo;s ability has not been explored much. This research discusses the Model Predictive Control algorithm for the powered descent phase of landing. Model Predictive Control (MPC) considers input/output constraints in the calculation of the control law and thus it is very useful for the stated problem as shown in the results. The main novelty of this work is the implementation of Explicit MPC, which gives comparatively less computational time than MPC. A comparison is done among MPC variants in terms of feasibility, constraints handling, and computational time. Moreover, other conventional control algorithms like PID and LQR are compared with the proposed predictive algorithm. These control algorithms are implemented on quadrotor UAV (which emulates the dynamics of a planetary lander) to verify the feasibility through simulations in MATLAB.
KW  - Mars landing
KW  - explicit model predictive control
KW  - unmanned aerial vehicle (UAV)
KW  - powered descent
DO  - 10.3390/en14248493
ER  -
TY  - EJOU
AU  - Yang, Pu
AU  - Wen, Chenwan
AU  - Geng, Huilin
AU  - Liu, Peng
TI  - Intelligent Fault Diagnosis Method for Blade Damage of Quad-Rotor UAV Based on Stacked Pruning Sparse Denoising Autoencoder and Convolutional Neural Network
T2  - Machines

PY  - 2021
VL  - 9
IS  - 12
SN  - 2075-1702

AB  - This paper introduces a new intelligent fault diagnosis method based on stack pruning sparse denoising autoencoder and convolutional neural network (sPSDAE-CNN). This method processes the original input data by using a stack denoising autoencoder. Different from the traditional autoencoder, stack pruning sparse denoising autoencoder includes a fully connected autoencoding network, the features extracted from the front layer of the network are used for the operation of the subsequent layer, which means that some new connections will appear between the front and rear layers of the network, reduce the loss of information, and obtain more effective features. Firstly, a one-dimensional sliding window is introduced for data enhancement. In addition, transforming one-dimensional time-domain data into the two-dimensional gray image can further improve the deep learning (DL) ability of models. At the same time, pruning operation is introduced to improve the training efficiency and accuracy of the network. The convolutional neural network model with sPSDAE has a faster training speed, strong adaptability to noise interference signals, and can also suppress the over-fitting problem of the convolutional neural network to a certain extent. Actual experiments show that for the fault of unmanned aerial vehicle (UAV) blade damage, the sPSDAE-CNN model we use has better stability and reliable prediction accuracy than traditional convolutional neural networks. At the same time, For noise signals, better results can be obtained. The experimental results show that the sPSDAE-CNN model still has a good diagnostic accuracy rate in a high-noise environment. In the case of a signal-to-noise ratio of &minus;4, it still has an accuracy rate of 90%.
KW  - intelligent fault diagnosis
KW  - stacked pruning sparse denoising autoencoder
KW  - convolutional neural network
KW  - anti-noise
DO  - 10.3390/machines9120360
ER  -
TY  - EJOU
AU  - Kior, Anastasiia
AU  - Sukhov, Vladimir
AU  - Sukhova, Ekaterina
TI  - Application of Reflectance Indices for Remote Sensing of Plants and Revealing Actions of Stressors
T2  - Photonics

PY  - 2021
VL  - 8
IS  - 12
SN  - 2304-6732

AB  - Environmental conditions are very changeable; fluctuations in temperature, precipitation, illumination intensity, and other factors can decrease a plant productivity and crop. The remote sensing of plants under these conditions is the basis for the protection of plants and increases their survivability. This problem can be solved through measurements of plant reflectance and calculation of reflectance indices. Reflectance indices are related to the vegetation biomass, specific physiological processes, and biochemical compositions in plants; the indices can be used for both short-term and long-term plant monitoring. In our review, we considered the applications of reflectance indices in plant remote sensing. In Optical Methods and Platforms of Remote Sensing of Plants, we briefly discussed multi- and hyperspectral imaging, including descriptions of multispectral and hyperspectral cameras with different principles and their efficiency for the remote sensing of plants. In Main Reflectance Indices, we described the main reflectance indices, including vegetation, water, and pigment reflectance indices, as well as the photochemical reflectance index and its modifications. We focused on the relationships of leaf reflectance and reflectance indices to plant biomass, development, and physiological and biochemical characteristics. In Problems of Measurement and Analysis of Reflectance Indices, we discussed the methods of the correction of the reflectance indices that can be used for decreasing the influence of environmental conditions (mainly illumination, air, and soil) and plant characteristics (orientation of leaves, their thickness, and others) on their measurements and the analysis of the plant remote sensing. Additionally, the variability of plants was also considered as an important factor that influences the results of measurement and analysis.
KW  - remote sensing
KW  - multispectral imaging
KW  - hyperspectral imaging
KW  - vegetation reflectance indices
KW  - water reflectance indices
KW  - pigment reflectance indices
KW  - photochemical reflectance index
DO  - 10.3390/photonics8120582
ER  -
TY  - EJOU
AU  - Garbouge, Hadhami
AU  - Rasti, Pejman
AU  - Rousseau, David
TI  - Enhancing the Tracking of Seedling Growth Using RGB-Depth Fusion and Deep Learning
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 24
SN  - 1424-8220

AB  - The use of high-throughput phenotyping with imaging and machine learning to monitor seedling growth is a tough yet intriguing subject in plant research. This has been recently addressed with low-cost RGB imaging sensors and deep learning during day time. RGB-Depth imaging devices are also accessible at low-cost and this opens opportunities to extend the monitoring of seedling during days and nights. In this article, we investigate the added value to fuse RGB imaging with depth imaging for this task of seedling growth stage monitoring. We propose a deep learning architecture along with RGB-Depth fusion to categorize the three first stages of seedling growth. Results show an average performance improvement of 5% correct recognition rate by comparison with the sole use of RGB images during the day. The best performances are obtained with the early fusion of RGB and Depth. Also, Depth is shown to enable the detection of growth stage in the absence of the light.
KW  - deep learning
KW  - plant growth
KW  - CNN
KW  - RGB-Depth
KW  - image fusion
KW  - feature fusion
KW  - transformers
DO  - 10.3390/s21248425
ER  -
TY  - EJOU
AU  - Zhang, Xinyu
AU  - Yuan, Yaxin
AU  - Zhu, Zequn
AU  - Ma, Qingshan
AU  - Yu, Hongyan
AU  - Li, Meng
AU  - Ma, Jianhai
AU  - Yi, Shuhua
AU  - He, Xiongzhao
AU  - Sun, Yi
TI  - Predicting the Distribution of Oxytropis ochrocephala Bunge in the Source Region of the Yellow River (China) Based on UAV Sampling Data and Species Distribution Model
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 24
SN  - 2072-4292

AB  - Oxytropis ochrocephala Bunge is an herbaceous perennial poisonous weed. It severely affects the production of local animal husbandry and ecosystem stability in the source region of Yellow River (SRYR), China. To date, however, the spatiotemporal distribution of O. ochrocephala is still unclear, mainly due to lack of high-precision observation data and effective methods at a regional scale. In this study, an efficient sampling method, based on unmanned aerial vehicle (UAV), was proposed to supply basic sampling data for species distribution models (SDMs, BIOMOD in this study). A total of 3232 aerial photographs were obtained, from 2018 to 2020, in SRYR, and the potential and future distribution of O. ochrocephala were predicted by an ensemble model, consisting of six basic models of BIOMOD. The results showed that: (1) O. ochrocephala mainly distributed in the southwest, middle, and northeast of the SRYR, and the high suitable habitat of O. ochrocephala accounted for 3.19%; (2) annual precipitation and annual mean temperature were the two most important factors that affect the distribution of O. ochrocephala, with a cumulative importance of 60.45%; and (3) the distribution probability of O. ochrocephala tends to increase from now to the 2070s, while spatial distribution ranges will remain in the southwest, middle, and northeast of the SRYR. This study shows that UAVs can potentially be used to obtain the basic data for species distribution modeling; the results are both beneficial to establishing reasonable management practices and animal husbandry in alpine grassland systems.
KW  - poisonous weed
KW  - UAV
KW  - FragMAP
KW  - SDMs
KW  - BIOMOD
KW  - ensemble model
DO  - 10.3390/rs13245129
ER  -
TY  - EJOU
AU  - Pérez-González, Andrés
AU  - Benítez-Montoya, Nelson
AU  - Jaramillo-Duque, Álvaro
AU  - Cano-Quintero, Juan B.
TI  - Coverage Path Planning with Semantic Segmentation for UAV in PV Plants
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 24
SN  - 2076-3417

AB  - Solar energy is one of the most strategic energy sources for the world&rsquo;s economic development. This has caused the number of solar photovoltaic plants to increase around the world; consequently, they are installed in places where their access and manual inspection are arduous and risky tasks. Recently, the inspection of photovoltaic plants has been conducted with the use of unmanned aerial vehicles (UAV). Although the inspection with UAVs can be completed with a drone operator, where the UAV flight path is purely manual or utilizes a previously generated flight path through a ground control station (GCS). However, the path generated in the GCS has many restrictions that the operator must supply. Due to these restrictions, we present a novel way to develop a flight path automatically with coverage path planning (CPP) methods. Using a DL server to segment the region of interest (RoI) within each of the predefined PV plant images, three CPP methods were also considered and their performances were assessed with metrics. The UAV energy consumption performance in each of the CPP methods was assessed using two different UAVs and standard metrics. Six experiments were performed by varying the CPP width, and the consumption metrics were recorded in each experiment. According to the results, the most effective and efficient methods are the exact cellular decomposition boustrophedon and grid-based wavefront coverage, depending on the CPP width and the area of the PV plant. Finally, a relationship was established between the size of the photovoltaic plant area and the best UAV to perform the inspection with the appropriate CPP width. This could be an important result for low-cost inspection with UAVs, without high-resolution cameras on the UAV board, and in small plants.
KW  - deep learning (DL)
KW  - unmanned aerial vehicle (UAV)
KW  - photovoltaic (PV) plants
KW  - semantic segmentation
KW  - coverage path planning (CPP)
DO  - 10.3390/app112412093
ER  -
TY  - EJOU
AU  - Mohammadi, Roozbeh
AU  - Roncoli, Claudio
TI  - Towards Data-Driven Vehicle Estimation for Signalised Intersections in a Partially Connected Environment
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 24
SN  - 1424-8220

AB  - Connected vehicles (CVs) have the potential to collect and share information that, if appropriately processed, can be employed for advanced traffic control strategies, rendering infrastructure-based sensing obsolete. However, before we reach a fully connected environment, where all vehicles are CVs, we have to deal with the challenge of incomplete data. In this paper, we develop data-driven methods for the estimation of vehicles approaching a signalised intersection, based on the availability of partial information stemming from an unknown penetration rate of CVs. In particular, we build machine learning models with the aim of capturing the nonlinear relations between the inputs (CV data) and the output (number of non-connected vehicles), which are characterised by highly complex interactions and may be affected by a large number of factors. We show that, in order to train these models, we may use data that can be easily collected with modern technologies. Moreover, we demonstrate that, if the available real data is not deemed sufficient, training can be performed using synthetic data, produced via microscopic simulations calibrated with real data, without a significant loss of performance. Numerical experiments, where the estimation methods are tested using real vehicle data simulating the presence of various penetration rates of CVs, show very good performance of the estimators, making them promising candidates for applications in the near future.
KW  - traffic state estimation
KW  - connected vehicles
KW  - data-driven estimation
DO  - 10.3390/s21248477
ER  -
TY  - EJOU
AU  - Mongus, Domen
AU  - Brumen, Matej
AU  - Žlaus, Danijel
AU  - Kohek, Štefan
AU  - Tomažič, Roman
AU  - Kerin, Uroš
AU  - Kolmanič, Simon
TI  - A Complete Environmental Intelligence System for LiDAR-Based Vegetation Management in Power-Line Corridors
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 24
SN  - 2072-4292

AB  - This paper presents the first complete approach to achieving environmental intelligence support in the management of vegetation within electrical power transmission corridors. Contrary to the related studies that focused on the mapping of power lines, together with encroaching vegetation risk assessment, we realised predictive analytics with vegetation growth simulation. This was achieved by following the JDL/DFIG data fusion model for complementary feature extraction from Light Detection and Ranging (LiDAR) derived data products and auxiliary thematic maps that feed an ensemble regression model. The results indicate that improved vegetation growth prediction accuracy is obtained by segmenting training samples according to their contextual similarities that relate to their ecological niches. Furthermore, efficient situation assessment was then performed using a rasterised parametrically defined funnel-shaped volumetric filter. In this way, RMSE&asymp;1 m was measured when considering tree growth simulation, while a 0.37 m error was estimated in encroaching vegetation detection, demonstrating significant improvements over the field observations.
KW  - LiDAR
KW  - vegetation management
KW  - digital twin
KW  - power-lines
KW  - encroaching vegetation detection
KW  - three growth simulation
KW  - environmental intelligence
DO  - 10.3390/rs13245159
ER  -
TY  - EJOU
AU  - Etienne, Aaron
AU  - Ahmad, Aanis
AU  - Aggarwal, Varun
AU  - Saraswat, Dharmendra
TI  - Deep Learning-Based Object Detection System for Identifying Weeds Using UAS Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 24
SN  - 2072-4292

AB  - Current methods of broadcast herbicide application cause a negative environmental and economic impact. Computer vision methods, specifically those related to object detection, have been reported to aid in site-specific weed management procedures for targeted herbicide application within a field. However, a major challenge to developing a weed detection system is the requirement for a properly annotated database to differentiate between weeds and crops under field conditions. This research involved creating an annotated database of 374 red, green, and blue (RGB) color images organized into monocot and dicot weed classes. The images were acquired from corn and soybean research plots located in north-central Indiana using an unmanned aerial system (UAS) flown at 30 and 10 m heights above ground level (AGL). A total of 25,560 individual weed instances were manually annotated. The annotated database consisted of four different subsets (Training Image Sets 1&ndash;4) to train the You Only Look Once version 3 (YOLOv3) deep learning model for five separate experiments. The best results were observed with Training Image Set 4, consisting of images acquired at 10 m AGL. For monocot and dicot weeds, respectively, an average precision (AP) score of 91.48 % and 86.13% was observed at a 25% IoU threshold (AP @ T = 0.25), as well as 63.37% and 45.13% at a 50% IoU threshold (AP @ T = 0.5). This research has demonstrated a need to develop large, annotated weed databases to evaluate deep learning models for weed identification under field conditions. It also affirms the findings of other limited research studies utilizing object detection for weed identification under field conditions.
KW  - weed detection
KW  - artificial intelligence
KW  - machine learning
KW  - deep learning
KW  - object detection
KW  - UAS
DO  - 10.3390/rs13245182
ER  -
TY  - EJOU
AU  - Li, Changchun
AU  - Wang, Yilin
AU  - Ma, Chunyan
AU  - Chen, Weinan
AU  - Li, Yacong
AU  - Li, Jingbo
AU  - Ding, Fan
AU  - Xiao, Zhen
TI  - Improvement of Wheat Grain Yield Prediction Model Performance Based on Stacking Technique
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 24
SN  - 2076-3417

AB  - Crop growth and development is a dynamic and complex process, and the essence of yield formation is the continuous accumulation of photosynthetic products from multiple fertility stages. In this study, a new stacking method for integrating multiple growth stages information was proposed to improve the performance of the winter wheat grain yield (GY) prediction model. For this purpose, crop canopy hyperspectral reflectance and leaf area index (LAI) data were obtained at the jointing, flagging, anthesis and grain filling stages. In this case, 15 vegetation indices and LAI were used as input features of the elastic network to construct GY prediction models for single growth stage. Based on Stacking technique, the GY prediction results of four single growth stages were integrated to construct the ensemble learning framework. The results showed that vegetation indices coupled LAI could effectively overcome the spectral saturation phenomenon, the validated R2 of each growth stage was improved by 10%, 22.5%, 3.6% and 10%, respectively. The stacking method provided more stable information with higher prediction accuracy than the individual fertility results (R2 = 0.74), and the R2 of the model validation phase improved by 236%, 51%, 27.6%, and 12.1%, respectively. The study can provide a reference for GY prediction of other crops.
KW  - grain yield
KW  - hyperspectral vegetation index
KW  - leaf area index
KW  - elastic network
KW  - stacking technology
DO  - 10.3390/app112412164
ER  -
TY  - EJOU
AU  - Fuentes, Jose E.
AU  - Garcia, Cesar E.
AU  - Olaya, Robin A.
TI  - Estimation of the Setting and Infrastructure Criterion of the UI GreenMetric Ranking Using Unmanned Aerial Vehicles
T2  - Sustainability

PY  - 2022
VL  - 14
IS  - 1
SN  - 2071-1050

AB  - This study presents a methodology to estimate the seven indicators of the Setting and Infrastructure criterion of the UI GreenMetric World University Ranking based on three-dimensional data from a point cloud taken from an unmanned aerial vehicle (UAV). This study also estimated the potential aerial biomass, C and CO2, stored in the green spaces of a university campus using photogrammetric data analyzed in a Geographic Information System (GIS). The method was based on isolating classified point clouds using digital surface models (DSMs) and ground control points (GCPs) considering the canopy height model (CHM), the allometric equation (DBH, p, h), the biomass conversion factor, and carbon dioxide equivalents (CO2-e). The results confirmed that the national models for estimating the potential C reserves in natural forests are very close to reality and that the open space and green areas available to people on campus are adequate. The use of photogrammetric data facilitated the estimation of UI GreenMetric indicators from a highly detailed, low-cost three-dimensional model. The results of a case study revealed that the campus assimilates the CO2 emissions it produces and generates a surplus.
KW  - unmanned aerial vehicle
KW  - aboveground biomass
KW  - Geographic Information System
KW  - point cloud
KW  - digital surface model
KW  - UI GreenMetric
DO  - 10.3390/su14010046
ER  -
TY  - EJOU
AU  - Zhu, Zhongxian
AU  - Lyu, Hongguang
AU  - Zhang, Jundong
AU  - Yin, Yong
TI  - An Efficient Ship Automatic Collision Avoidance Method Based on Modified Artificial Potential Field
T2  - Journal of Marine Science and Engineering

PY  - 2022
VL  - 10
IS  - 1
SN  - 2077-1312

AB  - A novel collision avoidance (CA) algorithm was proposed based on the modified artificial potential field (APF) method, to construct a practical ship automatic CA system. Considering the constraints of both the International Regulations for Preventing Collisions at Sea (COLREGS) and the motion characteristics of the ship, the multi-ship CA algorithm was realized by modifying the repulsive force model in the APF method. Furthermore, the distance from the closest point of approach-time to the closest point of approach (DCPA-TCPA) criterion was selected as the unique adjustable parameter from the perspective of navigation practice. Collaborative CA experiments were designed and conducted to validate the proposed algorithm. The results of the experiments revealed that the actual DCPA and TCPA agree well with the parameter setup that keeps the ship at a safe distance from other ships in complex encountering situations. Consequently, the algorithm proposed in this study can achieve efficient automatic CA with minimal parameter settings. Moreover, the navigators can easily accept and comprehend the adjustable parameters, enabling the algorithm to satisfy the demand of the engineering applications.
KW  - artificial potential field
KW  - collision avoidance
KW  - maritime autonomous surface ships
KW  - path planning
DO  - 10.3390/jmse10010003
ER  -
TY  - EJOU
AU  - Cañas, José M.
AU  - Fernández-Conde, Jesús
AU  - Vega, Julio
AU  - Ordóñez, Juan
TI  - Reconfigurable Computing for Reactive Robotics Using Open-Source FPGAs
T2  - Electronics

PY  - 2022
VL  - 11
IS  - 1
SN  - 2079-9292

AB  - Reconfigurable computing provides a paradigm to create intelligent systems different from the classic software computing approach. Instead of using a processor with an instruction set, a full stack of middleware, and an application program running on top, the field-programmable gate arrays (FPGAs) integrate a cell set that can be configured in different ways. A few vendors have dominated this market with their proprietary tools, hardware devices, and boards, resulting in fragmented ecosystems with few standards and little interoperation. However, a new and complete toolchain for FPGAs with its associated open tools has recently emerged from the open-source community. Robotics is an expanding application field that may definitely benefit from this revolution, as fast speed and low power consumption are usual requirements. This paper hypothesizes that basic reactive robot behaviors may be easily designed following the reconfigurable computing approach and the state-of-the-art open FPGA toolchain. They provide new abstractions such as circuit blocks and wires for building intelligent robots. Visual programming and block libraries make such development painless and reliable. As experimental validation, two reactive behaviors have been created in a real robot involving common sensors, actuators, and in-between logic. They have been also implemented using classic software programming for comparison purposes. Results are discussed and show that the development of reactive robot behaviors using reconfigurable computing and open tools is feasible, also achieving a high degree of simplicity and reusability, and benefiting from FPGAs&rsquo; low power consumption and time-critical responsiveness.
KW  - robotics
KW  - reconfigurable computing
KW  - open-source FPGAs
DO  - 10.3390/electronics11010008
ER  -
TY  - EJOU
AU  - Christie, Anna I.
AU  - Colefax, Andrew P.
AU  - Cagnazzi, Daniele
TI  - Feasibility of Using Small UAVs to Derive Morphometric Measurements of Australian Snubfin (Orcaella heinsohni) and Humpback (Sousa sahulensis) Dolphins
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - Analysis of animal morphometrics can provide vital information regarding population dynamics, structure, and body condition of cetaceans. Unmanned aerial vehicles (UAVs) have become the primary tool to collect morphometric measurements on whales, whereas on free ranging small dolphins, have not yet been applied. This study assesses the feasibility of obtaining reliable body morphometrics from Australian snubfin (Orcaella heinsohni) and humpback dolphins (Sousa sahulensis) using images collected from UAVs. Specifically, using a dolphin replica of known size, we tested the effect of the altitude of the UAV and the position of the animal within the image frame on the accuracy of length estimates. Using linear mixed models, we further assessed the precision of the total length estimates of humpback and snubfin dolphins. The precision of length estimates on the replica increased by ~2% when images were sampled at 45&ndash;60 m compared with 15&ndash;30 m. However, the precision of total length estimates on dolphins was significantly influenced only by the degree of arch and edge certainty. Overall, we obtained total length estimates with a precision of ~3% and consistent with published data. This study demonstrates the reliability of using UAV based images to obtain morphometrics of small dolphin species, such as snubfin and humpback dolphins.
KW  - aerial imagery
KW  - inshore dolphins
KW  - morphometrics
KW  - photogrammetry
KW  - UAVs
DO  - 10.3390/rs14010021
ER  -
TY  - EJOU
AU  - Kumar, Arun
AU  - Sharma, Sharad
AU  - Singh, Aman
AU  - Alwadain, Ayed
AU  - Choi, Bong-Jun
AU  - Manual-Brenosa, Jose
AU  - Ortega-Mansilla, Arturo
AU  - Goyal, Nitin
TI  - Revolutionary Strategies Analysis and Proposed System for Future Infrastructure in Internet of Things
T2  - Sustainability

PY  - 2022
VL  - 14
IS  - 1
SN  - 2071-1050

AB  - The Internet of Things (IoT) has changed the worldwide network of people, smart devices, intelligent things, data, and information as an emergent technology. IoT development is still in its early stages, and numerous interrelated challenges must be addressed. IoT is the unifying idea of embedding everything. The Internet of Things offers a huge opportunity to improve the world&rsquo;s accessibility, integrity, availability, scalability, confidentiality, and interoperability. However, securing the Internet of Things is a difficult issue. The IoT aims to connect almost everything within the framework of a common infrastructure. This helps in controlling devices and, will allow device status to be updated everywhere and at any time. To develop technology via IoT, several critical scientific studies and inquiries have been carried out. However, many obstacles and problems remain to be tackled in order to reach IoT&rsquo;s maximum potential. These problems and concerns must be taken into consideration in different areas of the IoT, such as implementation in remote areas, threats to the system, development support, social and environmental impacts, etc. This paper reviews the current state of the art in different IoT architectures, with a focus on current technologies, applications, challenges, IoT protocols, and opportunities. As a result, a detailed taxonomy of IoT is presented here which includes interoperability, scalability, security and energy efficiency, among other things. Moreover, the significance of blockchains and big data as well as their analysis in relation to IoT, is discussed. This article aims to help readers and researchers understand the IoT and its applicability to the real world.
KW  - architecture
KW  - communication protocol
KW  - enabling technologies
KW  - interoperability
DO  - 10.3390/su14010071
ER  -
TY  - EJOU
AU  - Huang, Heqing
AU  - Huang, Tongbin
AU  - Li, Zhen
AU  - Lyu, Shilei
AU  - Hong, Tao
TI  - Design of Citrus Fruit Detection System Based on Mobile Platform and Edge Computer Device
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 1
SN  - 1424-8220

AB  - Citrus fruit detection can provide technical support for fine management and yield determination of citrus orchards. Accurate detection of citrus fruits in mountain orchards is challenging because of leaf occlusion and citrus fruit mutual occlusion of different fruits. This paper presents a citrus detection task that combines UAV data collection, AI embedded device, and target detection algorithm. The system used a small unmanned aerial vehicle equipped with a camera to take full-scale pictures of citrus trees; at the same time, we extended the state-of-the-art model target detection algorithm, added the attention mechanism and adaptive fusion feature method, improved the model&rsquo;s performance; to facilitate the deployment of the model, we used the pruning method to reduce the amount of model calculation and parameters. The improved target detection algorithm is ported to the edge computing end to detect the data collected by the unmanned aerial vehicle. The experiment was performed on the self-made citrus dataset, the detection accuracy was 93.32%, and the processing speed at the edge computing device was 180 ms/frame. This method is suitable for citrus detection tasks in the mountainous orchard environment, and it can help fruit growers to estimate their yield.
KW  - citrus detection
KW  - UAV
KW  - mobile operation platforms
KW  - edge computing devices
DO  - 10.3390/s22010059
ER  -
TY  - EJOU
AU  - Zuñiga-Peña, Nadia S.
AU  - Hernández-Romero, Norberto
AU  - Seck-Tuoh-Mora, Juan C.
AU  - Medina-Marin, Joselito
AU  - Barragan-Vite, Irving
TI  - Improving 3D Path Tracking of Unmanned Aerial Vehicles through Optimization of Compensated PD and PID Controllers
T2  - Applied Sciences

PY  - 2022
VL  - 12
IS  - 1
SN  - 2076-3417

AB  - The development of quadrotor unmanned aerial vehicles (QUAVs) is a growing field due to their wide range of applications. QUAVs are complex nonlinear systems with a chaotic nature that require a controller with extended dynamics. PD and PID controllers can be successfully applied when the parameters are accurate. However, this parameterization process is complicated and time-consuming; most of the time, parameters are chosen by trial and error without guaranteeing good performance. The originality of this work is to present a novel nonlinear mathematical model with aerodynamic moments and forces in the Newton&ndash;Euler formulation, and identify metaheuristic algorithms applied to parameter optimization of compensated PD and PID controls for tracking the trajectories of a QUAV. Eight metaheuristic algorithms (PSO, GWO, HGS, LSHADE, LSPACMA, MPA, SMA and WOA) are reported, and RMSE is used to measure each dynamic performance of the simulations. For the PD control, the best performance is obtained with the HGS algorithm with an RMSE = 0.037247252379126. For the PID control, the best performance is obtained with the HGS algorithm with an RMSE = 0.032594309723623. Trajectory tracking was successful for the QUAV by minimizing the error between the desired and actual dynamics.
KW  - quadrotor unmanned aerial vehicles
KW  - compensated PD controller
KW  - compensated PID controller
KW  - metaheuristics algorithms
KW  - Newton-Euler formulation
KW  - nonlinear system
KW  - parameterization
DO  - 10.3390/app12010099
ER  -
TY  - EJOU
AU  - He, Haiqing
AU  - Yu, Jing
AU  - Cheng, Penggen
AU  - Wang, Yuqian
AU  - Zhu, Yufeng
AU  - Lin, Taiqing
AU  - Dai, Guoqiang
TI  - Automatic, Multiview, Coplanar Extraction for CityGML Building Model Texture Mapping
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - Most 3D CityGML building models in street-view maps (e.g., Google, Baidu) lack texture information, which is generally used to reconstruct real-scene 3D models by photogrammetric techniques, such as unmanned aerial vehicle (UAV) mapping. However, due to its simplified building model and inaccurate location information, the commonly used photogrammetric method using a single data source cannot satisfy the requirement of texture mapping for the CityGML building model. Furthermore, a single data source usually suffers from several problems, such as object occlusion. We proposed a novel approach to achieve CityGML building model texture mapping by multiview coplanar extraction from UAV remotely sensed or terrestrial images to alleviate these problems. We utilized a deep convolutional neural network to filter out object occlusion (e.g., pedestrians, vehicles, and trees) and obtain building-texture distribution. Point-line-based features are extracted to characterize multiview coplanar textures in 2D space under the constraint of a homography matrix, and geometric topology is subsequently conducted to optimize the boundary of textures by using a strategy combining Hough-transform and iterative least-squares methods. Experimental results show that the proposed approach enables texture mapping for building fa&ccedil;ades to use 2D terrestrial images without the requirement of exterior orientation information; that is, different from the photogrammetric method, a collinear equation is not an essential part to capture texture information. In addition, the proposed approach can significantly eliminate blurred and distorted textures of building models, so it is suitable for automatic and rapid texture updates.
KW  - texture mapping
KW  - coplanar extraction
KW  - deep convolutional neural network
KW  - geometric topology
KW  - homography matrix
DO  - 10.3390/rs14010050
ER  -
TY  - EJOU
AU  - Gangadhar, Akshay
AU  - Manikandan, Murugaiah
AU  - Rajaram, Dushhyanth
AU  - Mavris, Dimitri
TI  - Conceptual Design and Feasibility Study of Winged Hybrid Airship
T2  - Aerospace

PY  - 2022
VL  - 9
IS  - 1
SN  - 2226-4310

AB  - In recent years, hybrid airships have been identified as promising alternatives for high altitude, long endurance missions. In this study, a design methodology to study the feasibility of a winged hybrid airship powered by solar energy is presented. The proposed methodology involves five disciplines of the airship, viz., geometry, aerodynamics, environment, energy and structures that have been coupled in order to develop an optimum design which incorporates the maximum advantages of the modules. A total of fourteen design variables have been finalized, which are required to carry out the sizing of the envelope, wing, and solar panel layout. The Particle Swarm Optimization (PSO) algorithm is implemented to carry out optimization of a user-defined fitness function for given user-defined operating conditions. The optimization study is subjected to general constraints of weight balance and energy balance. Optimal solutions have been obtained for two different configurations. These are&mdash;conventional airship and winged hybrid airship. The solutions have been obtained for four different days of the year, in order to analyse any potential benefits and pitfalls of the two configurations for the varying conditions over the course of one year. The results obtained are generally found to be in excellent agreement with the imposed constraints. The winged hybrid airship configuration was found to have offered no significant benefits in comparison to the conventional configuration. The analysis of the key parameters and data values readily supports this conclusion.
KW  - hybrid airship
KW  - dynastat
KW  - winged airship
KW  - stratospheric airship
KW  - solar powered
DO  - 10.3390/aerospace9010008
ER  -
TY  - EJOU
AU  - Kouhalvandi, Lida
AU  - Matekovits, Ladislau
AU  - Peter, Ildiko
TI  - Deep Learning Assisted Automatic Methodology for Implanted MIMO Antenna Designs on Large Ground Plane
T2  - Electronics

PY  - 2022
VL  - 11
IS  - 1
SN  - 2079-9292

AB  - This paper provides a novel methodology for designing implanted multiple-input and multiple-output (MIMO) antennas in the automatic fashion. The proposed optimization consists of two sequential phases for firstly configuring the geometry of an implanted MIMO antenna and then sizing the design parameters through the hierarchy top-down optimization (TDO) and regression deep neural network (DNN), respectively. It tackles the difficulty in constructing the structure of antennas and also provides optimal values for the determined variables, sufficiently. This methodology results in valid electromagnetic (EM)-verified post-layout generation that is ready-to-fabricate. The effectiveness of the proposed optimization-oriented method is verified by designing and optimizing the implanted MIMO antenna in the frequency band of 4.34&ndash;4.61 GHz and 5.86&ndash;6.64 GHz suitable for medical applications at the emerging wireless band. For our design, we employ the actual biological tissues as bone, liquid (%1 sodium chloride, %40 sugar in distilled water), and plexiglass surroundings with a bio-compatible substrate, as aluminium oxide on a large ground plane, that is suitable to be used in a particular biomedical applications involving smart implants.
KW  - automatic
KW  - biological tissues
KW  - deep neural network (DNN)
KW  - hierarchy top-down optimization (TDO)
KW  - implanted multiple-input and multiple-output (MIMO) antennas
KW  - long short-term memory (LSTM)
DO  - 10.3390/electronics11010047
ER  -
TY  - EJOU
AU  - Olayode, Isaac O.
AU  - Severino, Alessandro
AU  - Tartibu, Lagouge K.
AU  - Arena, Fabio
AU  - Cakici, Ziya
TI  - Performance Evaluation of a Hybrid PSO Enhanced ANFIS Model in Prediction of Traffic Flow of Vehicles on Freeways: Traffic Data Evidence from South Africa
T2  - Infrastructures

PY  - 2022
VL  - 7
IS  - 1
SN  - 2412-3811

AB  - In the last few years, there has been a significant rise in the number of private vehicles ownership, migration of people from rural areas to urban cities, and the rise in the number of under-maintained freeways; all these have added to the perennial problem of traffic congestion. Traffic flow prediction has been recognized as the solution in alleviating and reducing the problem of traffic congestion. In this research, we developed an adaptive neuro-fuzzy inference system trained by particle swarm optimization (ANFIS-PSO) by performing an evaluative performance of the model through traffic flow modelling of vehicles on five freeways (N1,N3,N12,N14&nbsp;and&nbsp;N17) using South Africa Transportation System as a case study. Six hundred and fifty (650) traffic data were collected using inductive loop detectors and video cameras from the five freeways. The traffic data used for developing these models comprises traffic volume, traffic density, speed of vehicles, time, and different types of vehicles. The traffic data were divided into 70% and 30% for the training and validation of the model. The model results show a positively correlated optimal performance between the inputs and the output with a regression value R2&nbsp; of 0.9978 and 0.9860 for the training and testing. The result of this research shows that the soft computing model ANFIS-PSO used in this research can model vehicular traffic flow on freeways. Furthermore, the evidence from this research suggests that the on-peak and off-peak hours are significant determinants of vehicular traffic flow on freeways. The modelling approach developed in this research will assist urban planners in developing practical ways to tackle traffic congestion and assist motorists and pedestrians in travel behaviour decision-making. Finally, the approach used in this study will assist transportation engineers in making constructive and safety dependent guidelines for drivers and pedestrians on freeways.
KW  - particle swarm optimization
KW  - adaptive neuro-fuzzy inference system
KW  - traffic flow
KW  - freeways
DO  - 10.3390/infrastructures7010002
ER  -
TY  - EJOU
AU  - Reder, Stefan
AU  - Mund, Jan-Peter
AU  - Albert, Nicole
AU  - Waßermann, Lilli
AU  - Miranda, Luis
TI  - Detection of Windthrown Tree Stems on UAV-Orthomosaics Using U-Net Convolutional Networks
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - The increasing number of severe storm events is threatening European forests. Besides the primary damages directly caused by storms, there are secondary damages such as bark beetle outbreaks and tertiary damages due to negative effects on the market. These subsequent damages can be minimized if a detailed overview of the affected area and the amount of damaged wood can be obtained quickly and included in the planning of clearance measures. The present work utilizes UAV-orthophotos and an adaptation of the U-Net architecture for the semantic segmentation and localization of windthrown stems. The network was pre-trained with generic datasets, randomly combining stems and background samples in a copy&ndash;paste augmentation, and afterwards trained with a specific dataset of a particular windthrow. The models pre-trained with generic datasets containing 10, 50 and 100 augmentations per annotated windthrown stems achieved F1-scores of 73.9% (S1Mod10), 74.3% (S1Mod50) and 75.6% (S1Mod100), outperforming the baseline model (F1-score 72.6%), which was not pre-trained. These results emphasize the applicability of the method to correctly identify windthrown trees and suggest the collection of training samples from other tree species and windthrow areas to improve the ability to generalize. Further enhancements of the network architecture are considered to improve the classification performance and to minimize the calculative costs.
KW  - natural disaster analysis
KW  - forest damage assessment
KW  - windthrow detection
KW  - deep learning
KW  - U-Net
KW  - UAV
KW  - semantic segmentation
DO  - 10.3390/rs14010075
ER  -
TY  - EJOU
AU  - Zhao, Xin
AU  - Liu, Rongjie
AU  - Ma, Yi
AU  - Xiao, Yanfang
AU  - Ding, Jing
AU  - Liu, Jianqiang
AU  - Wang, Quanbin
TI  - Red Tide Detection Method for HY&minus;1D Coastal Zone Imager Based on U&minus;Net Convolutional Neural Network
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - Existing red tide detection methods have mainly been developed for ocean color satellite data with low spatial resolution and high spectral resolution. Higher spatial resolution satellite images are required for red tides with fine scale and scattered distribution. However, red tide detection methods for ocean color satellite data cannot be directly applied to medium&ndash;high spatial resolution satellite data owing to the shortage of red tide responsive bands. Therefore, a new red tide detection method for medium&ndash;high spatial resolution satellite data is required. This study proposes the red tide detection U&minus;Net (RDU&minus;Net) model by considering the HY&minus;1D Coastal Zone Imager (HY&minus;1D CZI) as an example. RDU&minus;Net employs the channel attention model to derive the inter&minus;channel relationship of red tide information in order to reduce the influence of the marine environment on red tide detection. Moreover, the boundary and binary cross entropy (BBCE) loss function, which incorporates the boundary loss, is used to obtain clear and accurate red tide boundaries. In addition, a multi&minus;feature dataset including the HY&minus;1D CZI radiance and Normalized Difference Vegetation Index (NDVI) is employed to enhance the spectral difference between red tides and seawater and thus improve the accuracy of red tide detection. Experimental results show that RDU&minus;Net can detect red tides accurately without a precedent threshold. Precision and Recall of 87.47% and 86.62%, respectively, are achieved, while the F1&minus;score and Kappa are 0.87. Compared with the existing method, the F1&minus;score is improved by 0.07&ndash;0.21. Furthermore, the proposed method can detect red tides accurately even under interference from clouds and fog, and it shows good performance in the case of red tide edges and scattered distribution areas. Moreover, it shows good applicability and can be successfully applied to other satellite data with high spatial resolution and large bandwidth, such as GF&minus;1 Wide Field of View 2 (WFV2) images.
KW  - red tide detection
KW  - remote sensing
KW  - U−Net convolutional neural network
KW  - HY−1D CZI
DO  - 10.3390/rs14010088
ER  -
TY  - EJOU
AU  - Ponce, Juan M.
AU  - Aquino, Arturo
AU  - Tejada, Diego
AU  - Al-Hadithi, Basil M.
AU  - Andújar, José M.
TI  - A Methodology for the Automated Delineation of Crop Tree Crowns from UAV-Based Aerial Imagery by Means of Morphological Image Analysis
T2  - Agronomy

PY  - 2022
VL  - 12
IS  - 1
SN  - 2073-4395

AB  - The popularisation of aerial remote sensing using unmanned aerial vehicles (UAV), has boosted the capacities of agronomists and researchers to offer farmers valuable data regarding the status of their crops. This paper describes a methodology for the automated detection and individual delineation of tree crowns in aerial representations of crop fields by means of image processing and analysis techniques, providing accurate information about plant population and canopy coverage in intensive-farming orchards with a row-based plant arrangement. To that end, after pre-processing initial aerial captures by means of photogrammetry and morphological image analysis, a resulting binary representation of the land plot surveyed is treated at connected component-level in order to separate overlapping tree crown projections. Then, those components are morphologically transformed into a set of seeds with which tree crowns are finally delineated, establishing the boundaries between them when they appear overlapped. This solution was tested on images from three different orchards, achieving semantic segmentations in which more than 94% of tree canopy-belonging pixels were correctly classified, and more than 98% of trees were successfully detected when assessing the methodology capacities for estimating the overall plant population. According to these results, the methodology represents a promising tool for automating the inventorying of plants and estimating individual tree-canopy coverage in intensive tree-based orchards.
KW  - aerial imagery
KW  - canopy cover
KW  - morphological image analysis
KW  - crop tree
KW  - unmanned aerial vehicle (UAV)
DO  - 10.3390/agronomy12010043
ER  -
TY  - EJOU
AU  - Santos, Adão F.
AU  - Lacerda, Lorena N.
AU  - Rossi, Chiara
AU  - Moreno, Leticia de A.
AU  - Oliveira, Mailson F.
AU  - Pilon, Cristiane
AU  - Silva, Rouverson P.
AU  - Vellidis, George
TI  - Using UAV and Multispectral Images to Estimate Peanut Maturity Variability on Irrigated and Rainfed Fields Applying Linear Models and Artificial Neural Networks
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - Using UAV and multispectral images has contributed to identifying field variability and improving crop management through different data modeling methods. However, knowledge on application of these tools to manage peanut maturity variability is still lacking. Therefore, the objective of this study was to compare and validate linear and multiple linear regression with models using artificial neural networks (ANN) for estimating peanut maturity under irrigated and rainfed conditions. The models were trained (80% dataset) and tested (20% dataset) using results from the 2018 and 2019 growing seasons from irrigated and rainfed fields. In each field, plant reflectance was collected weekly from 90 days after planting using a UAV-mounted multispectral camera. Images were used to develop vegetation indices (VIs). Peanut pods were collected on the same dates as the UAV flights for maturity assessment using the peanut maturity index (PMI). The precision and accuracy of the linear models to estimate PMI using VIs were, in general, greater in irrigated fields with R2 &gt; 0.40 than in rainfed areas, which had a maximum R2 value of 0.21. Multiple linear regressions combining adjusted growing degree days (aGDD) and VIs resulted in decreased RMSE for both irrigated and rainfed conditions and increased R2 in irrigated areas. However, these models did not perform successfully in the test process. On the other hand, ANN models that included VIs and aGDD showed accuracy of R2 = 0.91 in irrigated areas, regardless of using Multilayer Perceptron (MLP; RMSE = 0.062) or Radial Basis Function (RBF; RMSE = 0.065), as well as low tendency (1:1 line). These results indicated that, regardless of the ANN architecture used to predict complex and non-linear variables, peanut maturity can be estimated accurately through models with multiple inputs using VIs and aGDD. Although the accuracy of the MLP or RBF models for irrigated and rainfed areas separately was high, the overall ANN models using both irrigated and rainfed areas can be used to predict peanut maturity with the same precision.
KW  - remote sensing
KW  - vegetation index
KW  - artificial intelligence
KW  - Arachis hypogaea L.
DO  - 10.3390/rs14010093
ER  -
TY  - EJOU
AU  - Li, Xin
AU  - Li, Tao
AU  - Chen, Ziqi
AU  - Zhang, Kaiwen
AU  - Xia, Runliang
TI  - Attentively Learning Edge Distributions for Semantic Segmentation of Remote Sensing Imagery
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - Semantic segmentation has been a fundamental task in interpreting remote sensing imagery (RSI) for various downstream applications. Due to the high intra-class variants and inter-class similarities, inflexibly transferring natural image-specific networks to RSI is inadvisable. To enhance the distinguishability of learnt representations, attention modules were developed and applied to RSI, resulting in satisfactory improvements. However, these designs capture contextual information by equally handling all the pixels regardless of whether they around edges. Therefore, blurry boundaries are generated, rising high uncertainties in classifying vast adjacent pixels. Hereby, we propose an edge distribution attention module (EDA) to highlight the edge distributions of leant feature maps in a self-attentive fashion. In this module, we first formulate and model column-wise and row-wise edge attention maps based on covariance matrix analysis. Furthermore, a hybrid attention module (HAM) that emphasizes the edge distributions and position-wise dependencies is devised combing with non-local block. Consequently, a conceptually end-to-end neural network, termed as EDENet, is proposed to integrate HAM hierarchically for the detailed strengthening of multi-level representations. EDENet implicitly learns representative and discriminative features, providing available and reasonable cues for dense prediction. The experimental results evaluated on ISPRS Vaihingen, Potsdam and DeepGlobe datasets show the efficacy and superiority to the state-of-the-art methods on overall accuracy (OA) and mean intersection over union (mIoU). In addition, the ablation study further validates the effects of EDA.
KW  - semantic segmentation
KW  - remote sensing imagery
KW  - covariance matrix analysis
KW  - edge distributions
KW  - end-to-end neural network
DO  - 10.3390/rs14010102
ER  -
TY  - EJOU
AU  - Zhang, Di
AU  - Pan, Feng
AU  - Diao, Qi
AU  - Feng, Xiaoxue
AU  - Li, Weixing
AU  - Wang, Jiacheng
TI  - Seeding Crop Detection Framework Using Prototypical Network Method in UAV Images
T2  - Agriculture

PY  - 2022
VL  - 12
IS  - 1
SN  - 2077-0472

AB  - With the development of unmanned aerial vehicle (UAV), obtaining high-resolution aerial images has become easier. Identifying and locating specific crops from aerial images is a valuable task. The location and quantity of crops are important for agricultural insurance businesses. In this paper, the problem of locating chili seedling crops in large-field UAV images is processed. Two problems are encountered in the location process: a small number of samples and objects in UAV images are similar on a small scale, which increases the location difficulty. A detection framework based on a prototypical network to detect crops in UAV aerial images is proposed. In particular, a method of subcategory slicing is applied to solve the problem, in which objects in aerial images have similarities at a smaller scale. The detection framework is divided into two parts: training and detection. In the training process, crop images are sliced into subcategories, and then these subcategory patch images and background category images are used to train the prototype network. In the detection process, a simple linear iterative clustering superpixel segmentation method is used to generate candidate regions in the UAV image. The location method uses a prototypical network to recognize nine patch images extracted simultaneously. To train and evaluate the proposed method, we construct an evaluation dataset by collecting the images of chilies in a seedling stage by an UAV. We achieve a location accuracy of 96.46%. This study proposes a seedling crop detection framework based on few-shot learning that does not require the use of labeled boxes. It reduces the workload of manual annotation and meets the location needs of seedling crops.
KW  - chili detection
KW  - prototypical network
KW  - small-scale similarity problem
KW  - unmanned aerial vehicle images
DO  - 10.3390/agriculture12010026
ER  -
TY  - EJOU
AU  - Besada, Juan A.
AU  - Campaña, Ivan
AU  - Carramiñana, David
AU  - Bergesio, Luca
AU  - de Miguel, Gonzalo
TI  - Review and Simulation of Counter-UAS Sensors for Unmanned Traffic Management
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 1
SN  - 1424-8220

AB  - Noncollaborative surveillance of airborne UAS (Unmanned Aerial System) is a key enabler to the safe integration of UAS within a UTM (Unmanned Traffic Management) ecosystem. Thus, a wide variety of new sensors (known as Counter-UAS sensors) are being developed to provide real-time UAS tracking, ranging from radar, RF analysis and image-based detection to even sound-based sensors. This paper aims to discuss the current state-of-the art technology in this wide variety of sensors (both academically and commercially) and to propose a set of simulation models for them. Thus, the review is focused on identifying the key parameters and processes that allow modeling their performance and operation, which reflect the variety of measurement processes. The resulting simulation models are designed to help evaluate how sensors&rsquo; performances affect UTM systems, and specifically the implications in their tracking and tactical services (i.e., tactical conflicts with uncontrolled drones). The simulation models cover probabilistic detection (i.e., false alarms and probability of detection) and measurement errors, considering equipment installation (i.e., monostatic vs. multistatic configurations, passive sensing, etc.). The models were integrated in a UTM simulation platform and simulation results are included in the paper for active radars, passive radars, and acoustic sensors.
KW  - counter-UAS sensors
KW  - unmanned traffic management
KW  - review
KW  - simulation models
DO  - 10.3390/s22010189
ER  -
TY  - EJOU
AU  - Yao, Xin
AU  - Shi, Xiaoran
AU  - Li, Yaxin
AU  - Wang, Li
AU  - Wang, Han
AU  - Ren, Shijie
AU  - Zhou, Feng
TI  - GMT-WGAN: An Adversarial Sample Expansion Method for Ground Moving Targets Classification
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - In the field of target classification, detecting a ground moving target that is easily covered in clutter has been a challenge. In addition, traditional feature extraction techniques and classification methods usually rely on strong subjective factors and prior knowledge, which affect their generalization capacity. Most existing deep-learning-based methods suffer from insufficient feature learning due to the lack of data samples, which makes it difficult for the training process to converge to a steady-state. To overcome these limitations, this paper proposes a Wasserstein generative adversarial network (WGAN) sample enhancement method for ground moving target classification (GMT-WGAN). First, the micro-Doppler characteristics of ground moving targets are analyzed. Next, a WGAN is constructed to generate effective time&ndash;frequency images of ground moving targets and thereby enrich the sample database used to train the classification network. Then, image quality evaluation indexes are introduced to evaluate the generated spectrogram samples, with an aim to verify the distribution similarity of generated and real samples. Afterward, by feeding augmented samples to the deep convolutional neural networks with good generalization capacity, the classification performance of the GMT-WGAN is improved. Finally, experiments conducted on different datasets validate the effectiveness and robustness of the proposed method.
KW  - ground moving target classification
KW  - Wasserstein generative adversarial network
KW  - deep convolutional neural network
KW  - image quality evaluation
DO  - 10.3390/rs14010123
ER  -
TY  - EJOU
AU  - Mesquita, Ricardo
AU  - Gaspar, Pedro D.
TI  - A Novel Path Planning Optimization Algorithm Based on Particle Swarm Optimization for UAVs for Bird Monitoring and Repelling
T2  - Processes

PY  - 2022
VL  - 10
IS  - 1
SN  - 2227-9717

AB  - Bird damage to fruit crops causes significant monetary losses to farmers annually. The application of traditional bird repelling methods such as bird cannons and tree netting become inefficient in the long run, requiring high maintenance and reducing mobility. Due to their versatility, Unmanned Aerial Vehicles (UAVs) can be beneficial to solve this problem. However, due to their low battery capacity that equals low flight duration, it is necessary to evolve path planning optimization. A novel path planning optimization algorithm of UAVs based on Particle Swarm Optimization (PSO) is presented in this paper. This path planning optimization algorithm aims to manage the drone&rsquo;s distance and flight time, applying optimization and randomness techniques to overcome the disadvantages of the traditional systems. The proposed algorithm&rsquo;s performance was tested in three study cases: two of them in simulation to test the variation of each parameter and one in the field to test the influence on battery management and height influence. All cases were tested in the three possible situations: same incidence rate, different rates, and different rates with no bird damage to fruit crops. The field tests were also essential to understand the algorithm&rsquo;s behavior of the path planning algorithm in the UAV, showing that there is less efficiency with fewer points of interest, but this does not correlate with the flight time. In addition, there is no association between the maximum horizontal speed and the flight time, which means that the function to calculate the total distance for path planning needs to be adjusted. Thus, the proposed algorithm presents promising results with an outstanding reduced average error in the total distance for the path planning obtained and low execution time, being suited for this and other applications.
KW  - bird damage to fruit crops
KW  - unmanned aerial vehicles
KW  - path planning
KW  - meta-heuristic
KW  - path planning optimization algorithm
DO  - 10.3390/pr10010062
ER  -
TY  - EJOU
AU  - Chen, Qi
AU  - Zhang, Yuanyi
AU  - Li, Xinyuan
AU  - Tao, Pengjie
TI  - Extracting Rectified Building Footprints from Traditional Orthophotos: A New Workflow
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 1
SN  - 1424-8220

AB  - Deep learning techniques such as convolutional neural networks have largely improved the performance of building segmentation from remote sensing images. However, the images for building segmentation are often in the form of traditional orthophotos, where the relief displacement would cause non-negligible misalignment between the roof outline and the footprint of a building; such misalignment poses considerable challenges for extracting accurate building footprints, especially for high-rise buildings. Aiming at alleviating this problem, a new workflow is proposed for generating rectified building footprints from traditional orthophotos. We first use the facade labels, which are prepared efficiently at low cost, along with the roof labels to train a semantic segmentation network. Then, the well-trained network, which employs the state-of-the-art version of EfficientNet as backbone, extracts the roof segments and the facade segments of buildings from the input image. Finally, after clustering the classified pixels into instance-level building objects and tracing out the roof outlines, an energy function is proposed to drive the roof outline to maximally align with the building footprint; thus, the rectified footprints can be generated. The experiments on the aerial orthophotos covering a high-density residential area in Shanghai demonstrate that the proposed workflow can generate obviously more accurate building footprints than the baseline methods, especially for high-rise buildings.
KW  - image segmentation
KW  - building footprint
KW  - aerial orthophoto
KW  - relief displacement
DO  - 10.3390/s22010207
ER  -
TY  - EJOU
AU  - Gromada, Krzysztof A.
AU  - Stecz, Wojciech M.
TI  - Designing a Reliable UAV Architecture Operating in a Real Environment
T2  - Applied Sciences

PY  - 2022
VL  - 12
IS  - 1
SN  - 2076-3417

AB  - The article presents a method of designing a selected unmanned aerial platform flight scenario based on the principles of designing a reliable (Unmanned Aerial Vehicle) UAV architecture operating in an environment in which other platforms operate. The models and results presented relate to the medium-range aerial platform, subject to certification under the principles set out in aviation regulations. These platforms are subject to the certification process requirements, but their restrictions are not as restrictive as in the case of manned platforms. Issues related to modeling scenarios implemented by the platform in flight are discussed. The article describes the importance of Functional Hazard Analysis (FHA) and Fault Trees Analysis (FTA) of elements included in the hardware and software architecture of the system. The models in Unified Modeling Language (UML) used by the authors in the project are described, supporting the design of a reliable architecture of flying platforms. Examples of the transformations from user requirements modeled in the form of Use Cases to platform operation models based on State Machines and then to the final UAV operation algorithms are shown. Principles of designing system test plans and designing individual test cases to verify the system&rsquo;s operation in emergencies in flight are discussed. Methods of integrating flight simulators with elements of the air platform in the form of Software-in-the-Loop (SIL) models based on selected algorithms for avoiding dangerous situations have been described. The presented results are based on a practical example of an algorithm for detecting an air collision situation of two platforms.
KW  - Unmanned Aerial Vehicle (UAV)
KW  - collision avoidance
KW  - safety procedures
KW  - reliable architecture
KW  - Unified Modeling Language (UML)
DO  - 10.3390/app12010294
ER  -
TY  - EJOU
AU  - Velusamy, Parthasarathy
AU  - Rajendran, Santhosh
AU  - Mahendran, Rakesh K.
AU  - Naseer, Salman
AU  - Shafiq, Muhammad
AU  - Choi, Jin-Ghoo
TI  - Unmanned Aerial Vehicles (UAV) in Precision Agriculture: Applications and Challenges
T2  - Energies

PY  - 2022
VL  - 15
IS  - 1
SN  - 1996-1073

AB  - Agriculture is the primary source of income in developing countries like India. Agriculture accounts for 17 percent of India&rsquo;s total GDP, with almost 60 percent of the people directly or indirectly employed. While researchers and planters focus on a variety of elements to boost productivity, crop loss due to disease is one of the most serious issues they confront. Crop growth monitoring and early detection of pest infestations are still a problem. With the expansion of cultivation to wider fields, manual intervention to monitor and diagnose insect and pest infestations is becoming increasingly difficult. Failure to apply on time fertilizers and pesticides results in more crop loss and so lower output. Farmers are putting in greater effort to conserve crops, but they are failing most of the time because they are unable to adequately monitor the crops when they are infected by pests and insects. Pest infestation is also difficult to predict because it is not evenly distributed. In the recent past, modern equipment, tools, and approaches have been used to replace manual involvement. Unmanned aerial vehicles serve a critical role in crop disease surveillance and early detection in this setting. This research attempts to give a review of the most successful techniques to have precision-based crop monitoring and pest management in agriculture fields utilizing unmanned aerial vehicles (UAVs) or unmanned aircraft. The researchers&rsquo; reports on the various types of UAVs and their applications to early detection of agricultural diseases are rigorously assessed and compared. This paper also discusses the deployment of aerial, satellite, and other remote sensing technologies for disease detection, as well as their Quality of Service (QoS).
KW  - UAV
KW  - crop monitoring
KW  - pest management
KW  - remote sensing
DO  - 10.3390/en15010217
ER  -
TY  - EJOU
AU  - Basan, Elena
AU  - Basan, Alexandr
AU  - Nekrasov, Alexey
AU  - Fidge, Colin
AU  - Sushkin, Nikita
AU  - Peskova, Olga
TI  - GPS-Spoofing Attack Detection Technology for UAVs Based on Kullback&ndash;Leibler Divergence
T2  - Drones

PY  - 2022
VL  - 6
IS  - 1
SN  - 2504-446X

AB  - Here, we developed a method for detecting cyber security attacks aimed at spoofing the Global Positioning System (GPS) signal of an Unmanned Aerial Vehicle (UAV). Most methods for detecting UAV anomalies indicative of an attack use machine learning or other such methods that compare normal behavior with abnormal behavior. Such approaches require large amounts of data and significant &ldquo;training&rdquo; time to prepare and implement the system. Instead, we consider a new approach based on other mathematical methods for detecting UAV anomalies without the need to first collect a large amount of data and describe normal behavior patterns. Doing so can simplify the process of creating an anomaly detection system, which can further facilitate easier implementation of intrusion detection systems in UAVs. This article presents issues related to ensuring the information security of UAVs. Development of the GPS spoofing detection method for UAVs is then described, based on a preliminary study that made it possible to form a mathematical apparatus for solving the problem. We then explain the necessary analysis of parameters and methods of data normalization, and the analysis of the Kullback&mdash;Leibler divergence measure needed to detect anomalies in UAV systems.
KW  - UAV
KW  - GPS
KW  - vulnerabilities
KW  - anomalies
KW  - spoofing
KW  - Kullback–Leibler divergence
KW  - cyber attacks
DO  - 10.3390/drones6010008
ER  -
TY  - EJOU
AU  - Akcay, Ozgun
AU  - Kinaci, Ahmet C.
AU  - Avsar, Emin O.
AU  - Aydar, Umut
TI  - Semantic Segmentation of High-Resolution Airborne Images with Dual-Stream DeepLabV3+
T2  - ISPRS International Journal of Geo-Information

PY  - 2022
VL  - 11
IS  - 1
SN  - 2220-9964

AB  - In geospatial applications such as urban planning and land use management, automatic detection and classification of earth objects are essential and primary subjects. When the significant semantic segmentation algorithms are considered, DeepLabV3+ stands out as a state-of-the-art CNN. Although the DeepLabV3+ model is capable of extracting multi-scale contextual information, there is still a need for multi-stream architectural approaches and different training approaches of the model that can leverage multi-modal geographic datasets. In this study, a new end-to-end dual-stream architecture that considers geospatial imagery was developed based on the DeepLabV3+ architecture. As a result, the spectral datasets other than RGB provided increments in semantic segmentation accuracies when they were used as additional channels to height information. Furthermore, both the given data augmentation and Tversky loss function which is sensitive to imbalanced data accomplished better overall accuracies. Also, it has been shown that the new dual-stream architecture using Potsdam and Vaihingen datasets produced 88.87% and 87.39% overall semantic segmentation accuracies, respectively. Eventually, it was seen that enhancement of the traditional significant semantic segmentation networks has a great potential to provide higher model performances, whereas the contribution of geospatial data as the second stream to RGB to segmentation was explicitly shown.
KW  - deep learning
KW  - semantic segmentation
KW  - photogrammetry
KW  - multi-spectral aerial imagery
KW  - digital surface model
KW  - vegetation index
KW  - land cover classification
DO  - 10.3390/ijgi11010023
ER  -
TY  - EJOU
AU  - Zhang, Xuan
AU  - Zhu, Chun
AU  - He, Manchao
AU  - Dong, Menglong
AU  - Zhang, Guangcheng
AU  - Zhang, Faming
TI  - Failure Mechanism and Long Short-Term Memory Neural Network Model for Landslide Risk Prediction
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - Rockslides along a stepped failure surface have characteristics of stepped deformation characteristic and it is difficult to predict the failure time. In this study, the deformation characteristics and disaster prediction model of the Fengning granite rockslide were analyzed based on field surveys and monitoring data. To evaluate the stability, the shear strength parameters of the sliding surface were determined based on the back-propagation neural network and three-dimensional discrete element numerical method. Through the correlation analysis of deformation monitoring results with rainfall and blasting, it is shown that the landslide was triggered by excavation, rainfall, and blasting vibrations. The landslide displacement prediction model was established by using long short-term memory neural network (LSTM) based on the monitoring data, and the prediction results are compared with those using the BP model, SVM model and ARMA model. Results show that the LSTM model has strong advantages and good reliability for the stepped landslide deformation with short-term influence, and the predicted LSTM values were very consistent with the measured values, with a correlation coefficient of 0.977. Combined with the distribution characteristics of joints, the damage influence scope of the landslide was simulated by three-dimensional discrete element, which provides decision-making basis for disaster warning after slope instability. The method proposed in this paper can provide references for early warning and treatment of geological disasters.
KW  - step moving rockslide
KW  - long short-term memory neural network
KW  - joint persistence ratio
KW  - deformation forecasting
KW  - hydrodynamic action
DO  - 10.3390/rs14010166
ER  -
TY  - EJOU
AU  - Piratelo, Paulo H.
AU  - de Azeredo, Rodrigo N.
AU  - Yamao, Eduardo M.
AU  - Bianchi Filho, Jose F.
AU  - Maidl, Gabriel
AU  - Lisboa, Felipe S.
AU  - de Jesus, Laercio P.
AU  - Penteado Neto, Renato D.
AU  - Coelho, Leandro D.
AU  - Leandro, Gideon V.
TI  - Blending Colored and Depth CNN Pipelines in an Ensemble Learning Classification Approach for Warehouse Application Using Synthetic and Real Data
T2  - Machines

PY  - 2022
VL  - 10
IS  - 1
SN  - 2075-1702

AB  - Electric companies face flow control and inventory obstacles such as reliability, outlays, and time-consuming tasks. Convolutional Neural Networks (CNNs) combined with computational vision approaches can process image classification in warehouse management applications to tackle this problem. This study uses synthetic and real images applied to CNNs to deal with classification of inventory items. The results are compared to seek the neural networks that better suit this application. The methodology consists of fine-tuning several CNNs on Red&ndash;Green&ndash;Blue (RBG) and Red&ndash;Green&ndash;Blue-Depth (RGB-D) synthetic and real datasets, using the best architecture of each domain in a blended ensemble approach. The proposed blended ensemble approach was not yet explored in such an application, using RGB and RGB-D data, from synthetic and real domains. The use of a synthetic dataset improved accuracy, precision, recall and f1-score in comparison with models trained only on the real domain. Moreover, the use of a blend of DenseNet and Resnet pipelines for colored and depth images proved to outperform accuracy, precision and f1-score performance indicators over single CNNs, achieving an accuracy measurement of 95.23%. The classification task is a real logistics engineering problem handled by computer vision and artificial intelligence, making full use of RGB and RGB-D images of synthetic and real domains, applied in an approach of blended CNN pipelines.
KW  - convolutional neural networks
KW  - warehouse management
KW  - image classification
KW  - ensemble learning
KW  - synthetic data
KW  - depth image
KW  - electrical maintenance
DO  - 10.3390/machines10010028
ER  -
TY  - EJOU
AU  - Li, Dengshan
AU  - Wang, Rujing
AU  - Chen, Peng
AU  - Xie, Chengjun
AU  - Zhou, Qiong
AU  - Jia, Xiufang
TI  - Visual Feature Learning on Video Object and Human Action Detection: A Systematic Review
T2  - Micromachines

PY  - 2022
VL  - 13
IS  - 1
SN  - 2072-666X

AB  - Video object and human action detection are applied in many fields, such as video surveillance, face recognition, etc. Video object detection includes object classification and object location within the frame. Human action recognition is the detection of human actions. Usually, video detection is more challenging than image detection, since video frames are often more blurry than images. Moreover, video detection often has other difficulties, such as video defocus, motion blur, part occlusion, etc. Nowadays, the video detection technology is able to implement real-time detection, or high-accurate detection of blurry video frames. In this paper, various video object and human action detection approaches are reviewed and discussed, many of them have performed state-of-the-art results. We mainly review and discuss the classic video detection methods with supervised learning. In addition, the frequently-used video object detection and human action recognition datasets are reviewed. Finally, a summarization of the video detection is represented, e.g., the video object and human action detection methods could be classified into frame-by-frame (frame-based) detection, extracting-key-frame detection and using-temporal-information detection; the methods of utilizing temporal information of adjacent video frames are mainly the optical flow method, Long Short-Term Memory and convolution among adjacent frames.
KW  - video object detection
KW  - human action recognition
KW  - deep learning
KW  - temporal information
KW  - optical flow
KW  - LSTM
KW  - video dataset
DO  - 10.3390/mi13010072
ER  -
TY  - EJOU
AU  - Carbonell-Rivera, Juan P.
AU  - Torralba, Jesús
AU  - Estornell, Javier
AU  - Ruiz, Luis Á.
AU  - Crespo-Peremarch, Pablo
TI  - Classification of Mediterranean Shrub Species from UAV Point Clouds
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - Modelling fire behaviour in forest fires is based on meteorological, topographical, and vegetation data, including species&rsquo; type. To accurately parameterise these models, an inventory of the area of analysis with the maximum spatial and temporal resolution is required. This study investigated the use of UAV-based digital aerial photogrammetry (UAV-DAP) point clouds to classify tree and shrub species in Mediterranean forests, and this information is key for the correct generation of wildfire models. In July 2020, two test sites located in the Natural Park of Sierra Calderona (eastern Spain) were analysed, registering 1036 vegetation individuals as reference data, corresponding to 11 shrub and one tree species. Meanwhile, photogrammetric flights were carried out over the test sites, using a UAV DJI Inspire 2 equipped with a Micasense RedEdge multispectral camera. Geometrical, spectral, and neighbour-based features were obtained from the resulting point cloud generated. Using these features, points belonging to tree and shrub species were classified using several machine learning methods, i.e., Decision Trees, Extra Trees, Gradient Boosting, Random Forest, and MultiLayer Perceptron. The best results were obtained using Gradient Boosting, with a mean cross-validation accuracy of 81.7% and 91.5% for test sites 1 and 2, respectively. Once the best classifier was selected, classified points were clustered based on their geometry and tested with evaluation data, and overall accuracies of 81.9% and 96.4% were obtained for test sites 1 and 2, respectively. Results showed that the use of UAV-DAP allows the classification of Mediterranean tree and shrub species. This technique opens a wide range of possibilities, including the identification of species as a first step for further extraction of structure and fuel variables as input for wildfire behaviour models.
KW  - Unmanned Aerial Vehicles (UAV)
KW  - Digital Aerial Photogrammetry (DAP)
KW  - machine learning
KW  - deep learning
KW  - point cloud labelling
KW  - Mediterranean forest
DO  - 10.3390/rs14010199
ER  -
TY  - EJOU
AU  - Lin, Qigen
AU  - Ci, Tianyu
AU  - Wang, Leibin
AU  - Mondal, Sanjit K.
AU  - Yin, Huaxiang
AU  - Wang, Ying
TI  - Transfer Learning for Improving Seismic Building Damage Assessment
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - The rapid assessment of building damage in earthquake-stricken areas is of paramount importance for emergency response. The development of remote sensing technology has aided in deriving reliable and precise building damage assessments of extensive areas following disasters. It is well documented that convolutional neural network methods have superior performance in earthquake building damage assessment compared with traditional machine learning methods. However, deep learning models require a large number of samples, and sufficient numbers of samples are usually not available in the newly earthquake-stricken areas rapidly enough. At the same time, the historical samples inevitably differ from the new earthquake-affected areas due to the discrepancy of regional building characteristics. For this purpose, this study proposes a data transfer algorithm for evaluating the impact of a single historical training sample on the model performance. Then, beneficial samples are selected to transfer knowledge from the historical data for facilitating the calibration of the new model. Four models are designed with two earthquake damage building datasets and the performance of the models is compared and evaluated. The results show that the data transfer algorithm proposed in this work improves the reliability of the building damage assessment model significantly by filtering samples from the historical data that are suitable for the new task. The performance of the model built based on the data transfer method on the test set of new earthquakes task is approximately 8% higher in overall accuracy compared with the model trained directly with the new earthquake samples when the training data for the new task is only 10% of the historical data and is operating under the objective of four classes of building damage. The proposed data transfer algorithm has effectively enhanced the precision of the seismic building damage assessment in a data-limited context. Thus, it could be applicable to the building damage assessment of new disasters.
KW  - building damage
KW  - transfer learning
KW  - earthquake
KW  - deep learning
KW  - convolutional neural networks
DO  - 10.3390/rs14010201
ER  -
TY  - EJOU
AU  - Kamarulzaman, Aisyah M.
AU  - Wan Mohd Jaafar, Wan S.
AU  - Abdul Maulud, Khairul N.
AU  - Saad, Siti N.
AU  - Omar, Hamdan
AU  - Mohan, Midhun
TI  - Integrated Segmentation Approach with Machine Learning Classifier in Detecting and Mapping Post Selective Logging Impacts Using UAV Imagery
T2  - Forests

PY  - 2022
VL  - 13
IS  - 1
SN  - 1999-4907

AB  - Selective logging can cause significant impacts on the residual stands, affecting biodiversity and leading to environmental changes. Proper monitoring and mapping of the impacts from logging activities, such as the stumps, felled logs, roads, skid trails, and forest canopy gaps, are crucial for sustainable forest management operations. The purpose of this study is to assess the indicators of selective logging impacts by detecting the individual stumps as the main indicators, evaluating the performance of classification methods to assess the impacts and identifying forest gaps from selective logging activities. The combination of forest inventory field plots and unmanned aerial vehicle (UAV) RGB and overlapped imaged were used in this study to assess these impacts. The study area is located in Ulu Jelai Forest Reserve in the central part of Peninsular Malaysia, covering an experimental study area of 48 ha. The study involved the integration of template matching (TM), object-based image analysis (OBIA), and machine learning classification&mdash;support vector machine (SVM) and artificial neural network (ANN). Forest features and tree stumps were classified, and the canopy height model was used for detecting forest canopy gaps in the post selective logging region. Stump detection using the integration of TM and OBIA produced an accuracy of 75.8% when compared with the ground data. Forest classification using SVM and ANN methods were adopted to extract other impacts from logging activities such as skid trails, felled logs, roads and forest canopy gaps. These methods provided an overall accuracy of 85% and kappa coefficient value of 0.74 when compared with conventional classifier. The logging operation also caused an 18.6% loss of canopy cover. The result derived from this study highlights the potential use of UAVs for efficient post logging impact analysis and can be used to complement conventional forest inventory practices.
KW  - selective logging impacts
KW  - UAV
KW  - object-based image analysis
KW  - machine learning
KW  - forest classification
DO  - 10.3390/f13010048
ER  -
TY  - EJOU
AU  - Li, Jiqiang
AU  - Zhang, Guoqing
AU  - Li, Bo
TI  - Robust Adaptive Neural Cooperative Control for the USV-UAV Based on the LVS-LVA Guidance Principle
T2  - Journal of Marine Science and Engineering

PY  - 2022
VL  - 10
IS  - 1
SN  - 2077-1312

AB  - Around the cooperative path-following control for the underactuated surface vessel (USV) and the unmanned aerial vehicle (UAV), a logic virtual ship-logic virtual aircraft (LVS-LVA) guidance principle is developed to generate the reference heading signals for the USV-UAV system by using the &ldquo;virtual ship&rdquo; and the &ldquo;virtual aircraft&rdquo;, which is critical to establish an effective correlation between the USV and the UAV. Taking the steerable variables (the main engine speed and the rudder angle of the USV, and the rotor angular velocities of the UAV) as the control input, a robust adaptive neural cooperative control algorithm was designed by employing the dynamic surface control (DSC), radial basic function neural networks (RBF-NNs) and the event-triggered technique. In the proposed algorithm, the reference roll angle and pitch angle for the UAV can be calculated from the position control loop by virtue of the nonlinear decouple technique. In addition, the system uncertainties were approximated through the RBF-NNs and the transmission burden from the controller to the actuators was reduced for merits of the event-triggered technique. Thus, the derived control law is superior in terms of the concise form, low transmission burden and robustness. Furthermore, the tracking errors of the USV-UAV cooperative control system can converge to a small compact set through adjusting the designed control parameters appropriately, and it can be also guaranteed that all the signals are the semi-global uniformly ultimately bounded (SGUUB). Finally, the effectiveness of the proposed algorithm has been verified via numerical simulations in the presence of the time-varying disturbances.
KW  - USV-UAV
KW  - event-triggered technique
KW  - dynamic surface control
KW  - path following
DO  - 10.3390/jmse10010051
ER  -
TY  - EJOU
AU  - Sharma, Mayuri
AU  - Nath, Keshab
AU  - Sharma, Rupam K.
AU  - Kumar, Chandan J.
AU  - Chaudhary, Ankit
TI  - Ensemble Averaging of Transfer Learning Models for Identification of Nutritional Deficiency in Rice Plant
T2  - Electronics

PY  - 2022
VL  - 11
IS  - 1
SN  - 2079-9292

AB  - Computer vision-based automation has become popular in detecting and monitoring plants&rsquo; nutrient deficiencies in recent times. The predictive model developed by various researchers were so designed that it can be used in an embedded system, keeping in mind the availability of computational resources. Nevertheless, the enormous popularity of smart phone technology has opened the door of opportunity to common farmers to have access to high computing resources. To facilitate smart phone users, this study proposes a framework of hosting high end systems in the cloud where processing can be done, and farmers can interact with the cloud-based system. With the availability of high computational power, many studies have been focused on applying convolutional Neural Networks-based Deep Learning (CNN-based DL) architectures, including Transfer learning (TL) models on agricultural research. Ensembling of various TL architectures has the potential to improve the performance of predictive models by a great extent. In this work, six TL architectures viz. InceptionV3, ResNet152V2, Xception, DenseNet201, InceptionResNetV2, and VGG19 are considered, and their various ensemble models are used to carry out the task of deficiency diagnosis in rice plants. Two publicly available datasets from Mendeley and Kaggle are used in this study. The ensemble-based architecture enhanced the highest classification accuracy to 100% from 99.17% in the Mendeley dataset, while for the Kaggle dataset; it was enhanced to 92% from 90%.
KW  - ML/DL methods
KW  - nutrient deficiency
KW  - ensemble learning
KW  - transfer learning
KW  - rice deficiency identification
DO  - 10.3390/electronics11010148
ER  -
TY  - EJOU
AU  - Niu, Xuerui
AU  - Zeng, Qiaolin
AU  - Luo, Xiaobo
AU  - Chen, Liangfu
TI  - FCAU-Net for the Semantic Segmentation of Fine-Resolution Remotely Sensed Images
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - The semantic segmentation of fine-resolution remotely sensed images is an urgent issue in satellite image processing. Solving this problem can help overcome various obstacles in urban planning, land cover classification, and environmental protection, paving the way for scene-level landscape pattern analysis and decision making. Encoder-decoder structures based on attention mechanisms have been frequently used for fine-resolution image segmentation. In this paper, we incorporate a coordinate attention (CA) mechanism, adopt an asymmetric convolution block (ACB), and design a refinement fusion block (RFB), forming a network named the fusion coordinate and asymmetry-based U-Net (FCAU-Net). Furthermore, we propose novel convolutional neural network (CNN) architecture to fully capture long-term dependencies and fine-grained details in fine-resolution remotely sensed imagery. This approach has the following advantages: (1) the CA mechanism embeds position information into a channel attention mechanism to enhance the feature representations produced by the network while effectively capturing position information and channel relationships; (2) the ACB enhances the feature representation ability of the standard convolution layer and captures and refines the feature information in each layer of the encoder; and (3) the RFB effectively integrates low-level spatial information and high-level abstract features to eliminate background noise when extracting feature information, reduces the fitting residuals of the fused features, and improves the ability of the network to capture information flows. Extensive experiments conducted on two public datasets (ZY-3 and DeepGlobe) demonstrate the effectiveness of the FCAU-Net. The proposed FCAU-Net transcends U-Net, Attention U-Net, the pyramid scene parsing network (PSPNet), DeepLab v3+, the multistage attention residual U-Net (MAResU-Net), MACU-Net, and the Transformer U-Net (TransUNet). Specifically, the FCAU-Net achieves a 97.97% (95.05%) pixel accuracy (PA), a 98.53% (91.27%) mean PA (mPA), a 95.17% (85.54%) mean intersection over union (mIoU), and a 96.07% (90.74%) frequency-weighted IoU (FWIoU) on the ZY-3 (DeepGlobe) dataset.
KW  - semantic segmentation
KW  - fine-resolution remotely sensed images
KW  - attention mechanism
KW  - asymmetric convolution block
KW  - refinement fusion block
DO  - 10.3390/rs14010215
ER  -
TY  - EJOU
AU  - Sun, Zhu
AU  - Guo, Xiangyu
AU  - Xu, Yang
AU  - Zhang, Songchao
AU  - Cheng, Xiaohui
AU  - Hu, Qiong
AU  - Wang, Wenxiang
AU  - Xue, Xinyu
TI  - Image Recognition of Male Oilseed Rape (Brassica napus) Plants Based on Convolutional Neural Network for UAAS Navigation Applications on Supplementary Pollination and Aerial Spraying
T2  - Agriculture

PY  - 2022
VL  - 12
IS  - 1
SN  - 2077-0472

AB  - To ensure the hybrid oilseed rape (OSR, Brassica napus) seed production, two important things are necessary, the stamen sterility on the female OSR plants and the effective pollen spread onto the pistil from the OSR male plants to the OSR female plants. The unmanned agricultural aerial system (UAAS) has developed rapidly in China. It has been used on supplementary pollination and aerial spraying during the hybrid OSR seed production. This study developed a new method to rapidly recognize the male OSR plants and extract the row center line for supporting the UAAS navigation. A male OSR plant recognition model was constructed based on the convolutional neural network (CNN). The sequence images of male OSR plants were extracted, the feature regions and points were obtained from the images through morphological and boundary process methods and horizontal segmentation, respectively. The male OSR plant image recognition accuracies of different CNN structures and segmentation sizes were discussed. The male OSR plant row center lines were fitted using the least-squares method (LSM) and Hough transform. The results showed that the segmentation algorithm could segment the male OSR plants from the complex background. The highest average recognition accuracy was 93.54%, and the minimum loss function value was 0.2059 with three convolutional layers, one fully connected layer, and a segmentation size of 40 pix &times; 40 pix. The LSM is better for center line fitting. The average recognition model accuracies of original input images were 98% and 94%, and the average root mean square errors (RMSE) of angle were 3.22&deg; and 1.36&deg; under cloudy day and sunny day lighting conditions, respectively. The results demonstrate the potential of using digital imaging technology to recognize the male OSR plant row for UAAS visual navigation on the applications of hybrid OSR supplementary pollination and aerial spraying, which would be a meaningful supplement in precision agriculture.
KW  - hybrid oilseed rape
KW  - male parent recognition
KW  - convolutional neural network
KW  - image processing
KW  - UAAS visual navigation
KW  - seed production
KW  - aerial spraying
DO  - 10.3390/agriculture12010062
ER  -
TY  - EJOU
AU  - Khan, Asim
AU  - Asim, Warda
AU  - Ulhaq, Anwaar
AU  - Robinson, Randall W.
TI  - A Multiview Semantic Vegetation Index for Robust Estimation of Urban Vegetation Cover
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 1
SN  - 2072-4292

AB  - Urban vegetation growth is vital for developing sustainable and liveable cities in the contemporary era since it directly helps people&rsquo;s health and well-being. Estimating vegetation cover and biomass is commonly done by calculating various vegetation indices for automated urban vegetation management and monitoring. However, most of these indices fail to capture robust estimation of vegetation cover due to their inherent focus on colour attributes with limited viewpoint and ignore seasonal changes. To solve this limitation, this article proposed a novel vegetation index called the Multiview Semantic Vegetation Index (MSVI), which is robust to color, viewpoint, and seasonal variations. Moreover, it can be applied directly to RGB images. This Multiview Semantic Vegetation Index (MSVI) is based on deep semantic segmentation and multiview field coverage and can be integrated into any vegetation management platform. This index has been tested on Google Street View (GSV) imagery of Wyndham City Council, Melbourne, Australia. The experiments and training achieved an overall pixel accuracy of 89.4% and 92.4% for FCN and U-Net, respectively. Thus, the MSVI can be a helpful instrument for analysing urban forestry and vegetation biomass since it provides an accurate and reliable objective method for assessing the plant cover at street level.
KW  - multiview semantic vegetation index
KW  - urban forestry
KW  - green view index (GVI)
KW  - semantic segmentation
KW  - urban vegetation
KW  - RGB vegetation index
DO  - 10.3390/rs14010228
ER  -
TY  - EJOU
AU  - Lerro, Angelo
AU  - Gili, Piero
AU  - Pisani, Marco
TI  - Verification in Relevant Environment of a Physics-Based Synthetic Sensor for Flow Angle Estimation
T2  - Electronics

PY  - 2022
VL  - 11
IS  - 1
SN  - 2079-9292

AB  - In the area of synthetic sensors for flow angle estimation, the present work aims to describe the verification in a relevant environment of a physics-based approach using a dedicated technological demonstrator. The flow angle synthetic solution is based on a model-free, or physics-based, scheme and, therefore, it is applicable to any flying body. The demonstrator also encompasses physical sensors that provide all the necessary inputs to the synthetic sensors to estimate the angle-of-attack and the angle-of-sideslip. The uncertainty budgets of the physical sensors are evaluated to corrupt the flight simulator data with the aim of reproducing a realistic scenario to verify the synthetic sensors. The proposed approach for the flow angle estimation is suitable for modern and future aircraft, such as drones and urban mobility air vehicles. The results presented in this work show that the proposed approach can be effective in relevant scenarios even though some limitations can arise.
KW  - air data system
KW  - flow angle
KW  - angle-of-attack
KW  - angle-of-sideslip
KW  - flight dynamics
KW  - flight testing
KW  - synthetic sensor
KW  - analytical redundancy
KW  - model-free
KW  - physics-based
DO  - 10.3390/electronics11010165
ER  -
TY  - EJOU
AU  - Narayana, Mannam V.
AU  - Jalihal, Devendra
AU  - Nagendra, S. M. Shiva
TI  - Establishing A Sustainable Low-Cost Air Quality Monitoring Setup: A Survey of the State-of-the-Art
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 1
SN  - 1424-8220

AB  - Low-cost sensors (LCS) are becoming popular for air quality monitoring (AQM). They promise high spatial and temporal resolutions at low-cost. In addition, citizen science applications such as personal exposure monitoring can be implemented effortlessly. However, the reliability of the data is questionable due to various error sources involved in the LCS measurement. Furthermore, sensor performance drift over time is another issue. Hence, the adoption of LCS by regulatory agencies is still evolving. Several studies have been conducted to improve the performance of low-cost sensors. This article summarizes the existing studies on the state-of-the-art of LCS for AQM. We conceptualize a step by step procedure to establish a sustainable AQM setup with LCS that can produce reliable data. The selection of sensors, calibration and evaluation, hardware setup, evaluation metrics and inferences, and end user-specific applications are various stages in the LCS-based AQM setup we propose. We present a critical analysis at every step of the AQM setup to obtain reliable data from the low-cost measurement. Finally, we conclude this study with future scope to improve the availability of air quality data.
KW  - air quality monitoring
KW  - low-cost sensors
KW  - calibration
KW  - evaluation metrics
KW  - citizen science applications
DO  - 10.3390/s22010394
ER  -
TY  - EJOU
AU  - Liu, Yicheng
AU  - Li, Zhipeng
AU  - Zhan, Bixiong
AU  - Han, Ju
AU  - Liu, Yan
TI  - A Super-Resolution Reconstruction Driven Helmet Detection Workflow
T2  - Applied Sciences

PY  - 2022
VL  - 12
IS  - 2
SN  - 2076-3417

AB  - The degrading of input images due to the engineering environment decreases the performance of helmet detection models so as to prevent their application in practice. To overcome this problem, we propose an end-to-end helmet monitoring system, which implements a super-resolution (SR) reconstruction driven helmet detection workflow to detect helmets for monitoring tasks. The monitoring system consists of two modules, the super-resolution reconstruction module and the detection module. The former implements the SR algorithm to produce high-resolution images, the latter performs the helmet detection. Validations are performed on both a public dataset as well as the realistic dataset obtained from a practical construction site. The results show that the proposed system achieves a promising performance and surpasses the competing methods. It will be a promising tool for construction monitoring and is easy to be extended to corresponding tasks.
KW  - helmet detection
KW  - super-resolution reconstruction
KW  - you only look once v5 (YOLOv5)
DO  - 10.3390/app12020545
ER  -
TY  - EJOU
AU  - Gao, Xin
AU  - Ram, Sundaresh
AU  - Philip, Rohit C.
AU  - Rodríguez, Jeffrey J.
AU  - Szep, Jeno
AU  - Shao, Sicong
AU  - Satam, Pratik
AU  - Pacheco, Jesús
AU  - Hariri, Salim
TI  - Selecting Post-Processing Schemes for Accurate Detection of Small Objects in Low-Resolution Wide-Area Aerial Imagery
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - In low-resolution wide-area aerial imagery, object detection algorithms are categorized as feature extraction and machine learning approaches, where the former often requires a post-processing scheme to reduce false detections and the latter demands multi-stage learning followed by post-processing. In this paper, we present an approach on how to select post-processing schemes for aerial object detection. We evaluated combinations of each of ten vehicle detection algorithms with any of seven post-processing schemes, where the best three schemes for each algorithm were determined using average F-score metric. The performance improvement is quantified using basic information retrieval metrics as well as the classification of events, activities and relationships (CLEAR) metrics. We also implemented a two-stage learning algorithm using a hundred-layer densely connected convolutional neural network for small object detection and evaluated its degree of improvement when combined with the various post-processing schemes. The highest average F-scores after post-processing are 0.902, 0.704 and 0.891 for the Tucson, Phoenix and online VEDAI datasets, respectively. The combined results prove that our enhanced three-stage post-processing scheme achieves a mean average precision (mAP) of 63.9% for feature extraction methods and 82.8% for the machine learning approach.
KW  - post-processing
KW  - vehicle detection
KW  - wide-area aerial imagery
KW  - segmentation
KW  - machine learning
DO  - 10.3390/rs14020255
ER  -
TY  - EJOU
AU  - Wang, Yuting
AU  - Wang, Shujian
AU  - Xu, Ming
TI  - Landscape Perception Identification and Classification Based on Electroencephalogram (EEG) Features
T2  - International Journal of Environmental Research and Public Health

PY  - 2022
VL  - 19
IS  - 2
SN  - 1660-4601

AB  - This paper puts forward a new method of landscape recognition and evaluation by using aerial video and EEG technology. In this study, seven typical landscape types (forest, wetland, grassland, desert, water, farmland, and city) were selected. Different electroencephalogram (EEG) signals were generated through different inner experiences and feelings felt by people watching video stimuli of the different landscape types. The electroencephalogram (EEG) features were extracted to obtain the mean amplitude spectrum (MAS), power spectrum density (PSD), differential entropy (DE), differential asymmetry (DASM), rational asymmetry (RASM), and differential caudality (DCAU) in the five frequency bands of delta, theta, alpha, beta, and gamma. According to electroencephalogram (EEG) features, four classifiers including the back propagation (BP) neural network, k-nearest neighbor classification (KNN), random forest (RF), and support vector machine (SVM) were used to classify the landscape types. The results showed that the support vector machine (SVM) classifier and the random forest (RF) classifier had the highest accuracy of landscape recognition, which reached 98.24% and 96.72%, respectively. Among the six classification features selected, the classification accuracy of MAS, PSD, and DE with frequency domain features were higher than those of the spatial domain features of DASM, RASM and DCAU. In different wave bands, the average classification accuracy of all subjects was 98.24% in the gamma band, 94.62% in the beta band, and 97.29% in the total band. This study identifies and classifies landscape perception based on multi-channel EEG signals, which provides a new idea and method for the quantification of human perception.
KW  - unmanned aerial vehicle (UAV)
KW  - electroencephalogram (EEG) features
KW  - landscape perception
KW  - machine learning
DO  - 10.3390/ijerph19020629
ER  -
TY  - EJOU
AU  - Lafiosca, Pasquale
AU  - Fan, Ip-Shing
AU  - Avdelidis, Nicolas P.
TI  - Automated Aircraft Dent Inspection via a Modified Fourier Transform Profilometry Algorithm
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 2
SN  - 1424-8220

AB  - The search for dents is a consistent part of the aircraft inspection workload. The engineer is required to find, measure, and report each dent over the aircraft skin. This process is not only hazardous, but also extremely subject to human factors and environmental conditions. This study discusses the feasibility of automated dent scanning via a single-shot triangular stereo Fourier transform algorithm, designed to be compatible with the use of an unmanned aerial vehicle. The original algorithm is modified introducing two main contributions. First, the automatic estimation of the pass-band filter removes the user interaction in the phase filtering process. Secondly, the employment of a virtual reference plane reduces unwrapping errors, leading to improved accuracy independently of the chosen unwrapping algorithm. Static experiments reached a mean absolute error of &sim;0.1&nbsp;mm at a distance of 60&nbsp;cm, while dynamic experiments showed &sim;0.3&nbsp;mm at a distance of 120&nbsp;cm. On average, the mean absolute error decreased by &sim;34%, proving the validity of the proposed single-shot 3D reconstruction algorithm and suggesting its applicability for future automated dent inspections.
KW  - airworthiness
KW  - fringe patterns
KW  - pinhole camera model
KW  - structured light
KW  - inspections
DO  - 10.3390/s22020433
ER  -
TY  - EJOU
AU  - Wang, Yanjun
AU  - Li, Shaochun
AU  - Teng, Fei
AU  - Lin, Yunhao
AU  - Wang, Mengjie
AU  - Cai, Hengfan
TI  - Improved Mask R-CNN for Rural Building Roof Type Recognition from UAV High-Resolution Images: A Case Study in Hunan Province, China
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - Accurate roof information of buildings can be obtained from UAV high-resolution images. The large-scale accurate recognition of roof types (such as gabled, flat, hipped, complex and mono-pitched roofs) of rural buildings is crucial for rural planning and construction. At present, most UAV high-resolution optical images only have red, green and blue (RGB) band information, which aggravates the problems of inter-class similarity and intra-class variability of image features. Furthermore, the different roof types of rural buildings are complex, spatially scattered, and easily covered by vegetation, which in turn leads to the low accuracy of roof type identification by existing methods. In response to the above problems, this paper proposes a method for identifying roof types of complex rural buildings based on visible high-resolution remote sensing images from UAVs. First, the fusion of deep learning networks with different visual features is investigated to analyze the effect of the different feature combinations of the visible difference vegetation index (VDVI) and Sobel edge detection features and UAV visible images on model recognition of rural building roof types. Secondly, an improved Mask R-CNN model is proposed to learn more complex features of different types of images of building roofs by using the ResNet152 feature extraction network with migration learning. After we obtained roof type recognition results in two test areas, we evaluated the accuracy of the results using the confusion matrix and obtained the following conclusions: (1) the model with RGB images incorporating Sobel edge detection features has the highest accuracy and enables the model to recognize more and more accurately the roof types of different morphological rural buildings, and the model recognition accuracy (Kappa coefficient (KC)) compared to that of RGB images is on average improved by 0.115; (2) compared with the original Mask R-CNN, U-Net, DeeplabV3 and PSPNet deep learning models, the improved Mask R-CNN model has the highest accuracy in recognizing the roof types of rural buildings, with F1-score, KC and OA averaging 0.777, 0.821 and 0.905, respectively. The method can obtain clear and accurate profiles and types of rural building roofs, and can be extended for green roof suitability evaluation, rooftop solar potential assessment, and other building roof surveys, management and planning.
KW  - UAV high-resolution optical image
KW  - roof type recognition
KW  - VDVI
KW  - Sobel
KW  - improved Mask R-CNN
KW  - deep learning
DO  - 10.3390/rs14020265
ER  -
TY  - EJOU
AU  - Wang, Yong
AU  - Zeng, Xiangqiang
AU  - Liao, Xiaohan
AU  - Zhuang, Dafang
TI  - B-FGC-Net: A Building Extraction Network from High Resolution Remote Sensing Imagery
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - Deep learning (DL) shows remarkable performance in extracting buildings from high resolution remote sensing images. However, how to improve the performance of DL based methods, especially the perception of spatial information, is worth further study. For this purpose, we proposed a building extraction network with feature highlighting, global awareness, and cross level information fusion (B-FGC-Net). The residual learning and spatial attention unit are introduced in the encoder of the B-FGC-Net, which simplifies the training of deep convolutional neural networks and highlights the spatial information representation of features. The global feature information awareness module is added to capture multiscale contextual information and integrate the global semantic information. The cross level feature recalibration module is used to bridge the semantic gap between low and high level features to complete the effective fusion of cross level information. The performance of the proposed method was tested on two public building datasets and compared with classical methods, such as UNet, LinkNet, and SegNet. Experimental results demonstrate that B-FGC-Net exhibits improved profitability of accurate extraction and information integration for both small and large scale buildings. The IoU scores of B-FGC-Net on WHU and INRIA Building datasets are 90.04% and 79.31%, respectively. B-FGC-Net is an effective and recommended method for extracting buildings from high resolution remote sensing images.
KW  - deep learning
KW  - building extraction
KW  - spatial attention
KW  - global information awareness
KW  - cross level information fusion
DO  - 10.3390/rs14020269
ER  -
TY  - EJOU
AU  - Anuar, Mohamed M.
AU  - Halin, Alfian A.
AU  - Perumal, Thinagaran
AU  - Kalantar, Bahareh
TI  - Aerial Imagery Paddy Seedlings Inspection Using Deep Learning
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - In recent years complex food security issues caused by climatic changes, limitations in human labour, and increasing production costs require a strategic approach in addressing problems. The emergence of artificial intelligence due to the capability of recent advances in computing architectures could become a new alternative to existing solutions. Deep learning algorithms in computer vision for image classification and object detection can facilitate the agriculture industry, especially in paddy cultivation, to alleviate human efforts in laborious, burdensome, and repetitive tasks. Optimal planting density is a crucial factor for paddy cultivation as it will influence the quality and quantity of production. There have been several studies involving planting density using computer vision and remote sensing approaches. While most of the studies have shown promising results, they have disadvantages and show room for improvement. One of the disadvantages is that the studies aim to detect and count all the paddy seedlings to determine planting density. The defective paddy seedlings&rsquo; locations are not pointed out to help farmers during the sowing process. In this work we aimed to explore several deep convolutional neural networks (DCNN) models to determine which one performs the best for defective paddy seedling detection using aerial imagery. Thus, we evaluated the accuracy, robustness, and inference latency of one- and two-stage pretrained object detectors combined with state-of-the-art feature extractors such as EfficientNet, ResNet50, and MobilenetV2 as a backbone. We also investigated the effect of transfer learning with fine-tuning on the performance of the aforementioned pretrained models. Experimental results showed that our proposed methods were capable of detecting the defective paddy rice seedlings with the highest precision and an F1-Score of 0.83 and 0.77, respectively, using a one-stage pretrained object detector called EfficientDet-D1 EficientNet.
KW  - paddy seedlings
KW  - computer vision
KW  - object detection
KW  - deep learning
KW  - convolutional neural networks
DO  - 10.3390/rs14020274
ER  -
TY  - EJOU
AU  - Yang, Qun
AU  - Shen, Dejian
TI  - Learning Damage Representations with Sequence-to-Sequence Models
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 2
SN  - 1424-8220

AB  - Natural hazards have caused damages to structures and economic losses worldwide. Post-hazard responses require accurate and fast damage detection and assessment. In many studies, the development of data-driven damage detection within the research community of structural health monitoring has emerged due to the advances in deep learning models. Most data-driven models for damage detection focus on classifying different damage states and hence damage states cannot be effectively quantified. To address such a deficiency in data-driven damage detection, we propose a sequence-to-sequence (Seq2Seq) model to quantify a probability of damage. The model was trained to learn damage representations with only undamaged signals and then quantify the probability of damage by feeding damaged signals into models. We tested the validity of our proposed Seq2Seq model with a signal dataset which was collected from a two-story timber building subjected to shake table tests. Our results show that our Seq2Seq model has a strong capability of distinguishing damage representations and quantifying the probability of damage in terms of highlighting the regions of interest.
KW  - structural health monitoring
KW  - damage detection
KW  - deep learning
KW  - Seq2Seq model
DO  - 10.3390/s22020452
ER  -
TY  - EJOU
AU  - Zhang, Tao
AU  - Jiang, Xiaodong
AU  - Jiang, Linlin
AU  - Li, Xuran
AU  - Yang, Shenbin
AU  - Li, Yingxue
TI  - Hyperspectral Reflectance Characteristics of Rice Canopies under Changes in Diffuse Radiation Fraction
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - To analyze the hyperspectral reflectance characteristics of rice canopies under changes in diffuse radiation fraction, experiments using different cover materials were performed in Nanjing, China, during 2016 and 2017. Each year, two treatments with different reduction ratios of diffuse radiation fraction but with similar shading rates were set in the field experiment: In T1, total solar radiation shading rate was 14.10%, and diffuse radiation fraction was 31.09%; in T2, total solar radiation shading rate was 14.42%, and diffuse radiation fraction was 39.98%, respectively. A non-shading treatment was included as a control (CK). Canopy hyperspectral reflectance, soil and plant analyzer development (SPAD), and leaf area index (LAI) were measured under shading treatments on different days after heading. The red-edge parameters (position, &lambda;0; maximum amplitude, D&lambda;; area, &alpha;0; width, &sigma;) were calculated, as well as the area, depth, and width of three absorption bands. The location of the first absorption band appeared in the range of 553&ndash;788 nm, and the second and third absorption bands appeared in the range of 874&ndash;1257 nm. The results show that the shading treatment had a significant effect on the rice canopy&rsquo;s hyperspectral reflectance. Compared with CK, the canopy reflectance of T1 (the diffuse radiation fraction was 31.09%) and T2 (the diffuse radiation fraction was 39.98%) decreased in the visible light range (350&ndash;760 nm) and increased in the near-infrared range (800&ndash;1350 nm), while the red-edge parameters (&lambda;0, D&lambda;, &alpha;0), SPAD, and LAI increased. On the other hand, under shading treatment, the increase in diffuse radiation fraction also had a significant impact on the hyperspectral spectra of the rice canopy, especially at 14 days after heading. Compared with T1, the green peak (550 nm) of T2 reduced by 16.12%, and the average reflectance at 800&ndash;900 nm increased by 10%. Based on correlation analysis, it was found that these hyperspectral reflectance characteristics were mainly due to the increase in SPAD (2.31%) and LAI (7.62%), which also led to the increase in D&lambda; (8.70%) and &alpha;0 (13.89%). Then, the second and third absorption features of T2 were significantly different from that of T1, which suggests that the change in diffuse radiation fraction could affect the process of water vapor absorption by rice.
KW  - diffuse radiation fraction
KW  - rice
KW  - hyperspectral reflectance
DO  - 10.3390/rs14020285
ER  -
TY  - EJOU
AU  - Ritter, Tim
AU  - Gollob, Christoph
AU  - Kraßnitzer, Ralf
AU  - Stampfer, Karl
AU  - Nothdurft, Arne
TI  - A Robust Method for Detecting Wind-Fallen Stems from Aerial RGB Images Using a Line Segment Detection Algorithm
T2  - Forests

PY  - 2022
VL  - 13
IS  - 1
SN  - 1999-4907

AB  - Increased frequencies and windspeeds of storms may cause disproportionately high increases in windthrow damage. Storm-felled trees provide a surplus of breeding material for bark beetles, often resulting in calamities in the subsequent years. Thus, the timely removal of fallen trees is regarded as a good management practice that requires strategic planning of salvage harvesting. Precise information on the number of stems and their location and orientation are needed for the efficient planning of strip roads and/or cable yarding lines. An accurate assessment of these data using conventional field-based methods is very difficult and time-consuming; remote sensing techniques may be a cost-efficient alternative. In this research, a methodology for the automatic detection of fallen stems from aerial RGB images is presented. The presented methodology was based on a line segment detection algorithm and proved to be robust regarding image quality. It was shown that the method can detect frequency, position, spatial distribution and orientation of fallen stems with high accuracy, while stem lengths were systematically underestimated. The methodology can be used for the optimized planning of salvage harvesting in the future and may thus help to reduce consequential bark beetle calamities after storm events.
KW  - windthrow
KW  - storm damage
KW  - salvage logging planning
KW  - remote sensing
KW  - image interpretation
DO  - 10.3390/f13010090
ER  -
TY  - EJOU
AU  - Cira, Calimanut-Ionut
AU  - Kada, Martin
AU  - Manso-Callejo, Miguel-Ángel
AU  - Alcarria, Ramón
AU  - Bordel Sanchez, Borja
TI  - Improving Road Surface Area Extraction via Semantic Segmentation with Conditional Generative Learning for Deep Inpainting Operations
T2  - ISPRS International Journal of Geo-Information

PY  - 2022
VL  - 11
IS  - 1
SN  - 2220-9964

AB  - The road surface area extraction task is generally carried out via semantic segmentation over remotely-sensed imagery. However, this supervised learning task is often costly as it requires remote sensing images labelled at the pixel level, and the results are not always satisfactory (presence of discontinuities, overlooked connection points, or isolated road segments). On the other hand, unsupervised learning does not require labelled data and can be employed for post-processing the geometries of geospatial objects extracted via semantic segmentation. In this work, we implement a conditional Generative Adversarial Network to reconstruct road geometries via deep inpainting procedures on a new dataset containing unlabelled road samples from challenging areas present in official cartographic support from Spain. The goal is to improve the initial road representations obtained with semantic segmentation models via generative learning. The performance of the model was evaluated on unseen data by conducting a metrical comparison where a maximum Intersection over Union (IoU) score improvement of 1.3% was observed when compared to the initial semantic segmentation result. Next, we evaluated the appropriateness of applying unsupervised generative learning using a qualitative perceptual validation to identify the strengths and weaknesses of the proposed method in very complex scenarios and gain a better intuition of the model&rsquo;s behaviour when performing large-scale post-processing with generative learning and deep inpainting procedures and observed important improvements in the generated data.
KW  - conditional learning
KW  - generative adversarial network
KW  - generative learning
KW  - image inpainting
KW  - image post-processing
KW  - road extraction
KW  - unsupervised learning
DO  - 10.3390/ijgi11010043
ER  -
TY  - EJOU
AU  - Samadzadegan, Farhad
AU  - Dadrass Javan, Farzaneh
AU  - Ashtari Mahini, Farnaz
AU  - Gholamshahi, Mehrnaz
TI  - Detection and Recognition of Drones Based on a Deep Convolutional Neural Network Using Visible Imagery
T2  - Aerospace

PY  - 2022
VL  - 9
IS  - 1
SN  - 2226-4310

AB  - Drones are becoming increasingly popular not only for recreational purposes but also in a variety of applications in engineering, disaster management, logistics, securing airports, and others. In addition to their useful applications, an alarming concern regarding physical infrastructure security, safety, and surveillance at airports has arisen due to the potential of their use in malicious activities. In recent years, there have been many reports of the unauthorized use of various types of drones at airports and the disruption of airline operations. To address this problem, this study proposes a novel deep learning-based method for the efficient detection and recognition of two types of drones and birds. Evaluation of the proposed approach with the prepared image dataset demonstrates better efficiency compared to existing detection systems in the literature. Furthermore, drones are often confused with birds because of their physical and behavioral similarity. The proposed method is not only able to detect the presence or absence of drones in an area but also to recognize and distinguish between two types of drones, as well as distinguish them from birds. The dataset used in this work to train the network consists of 10,000 visible images containing two types of drones as multirotors, helicopters, and also birds. The proposed deep learning method can directly detect and recognize two types of drones and distinguish them from birds with an accuracy of 83%, mAP of 84%, and IoU of 81%. The values of average recall, average accuracy, and average F1-score were also reported as 84%, 83%, and 83%, respectively, in three classes.
KW  - drone
KW  - UAV
KW  - deep learning
KW  - convolutional neural network CNN
KW  - drone image dataset
KW  - drone detection
KW  - drone recognition
DO  - 10.3390/aerospace9010031
ER  -
TY  - EJOU
AU  - Aldao, Enrique
AU  - González-deSantos, Luis M.
AU  - Michinel, Humberto
AU  - González-Jorge, Higinio
TI  - UAV Obstacle Avoidance Algorithm to Navigate in Dynamic Building Environments
T2  - Drones

PY  - 2022
VL  - 6
IS  - 1
SN  - 2504-446X

AB  - In this work, a real-time collision avoidance algorithm was presented for autonomous navigation in the presence of fixed and moving obstacles in building environments. The current implementation is designed for autonomous navigation between waypoints of a predefined flight trajectory that would be performed by an UAV during tasks such as inspections or construction progress monitoring. It uses a simplified geometry generated from a point cloud of the scenario. In addition, it also employs information from 3D sensors to detect and position obstacles such as people or other UAVs, which are not registered in the original cloud. If an obstacle is detected, the algorithm estimates its motion and computes an evasion path considering the geometry of the environment. The method has been successfully tested in different scenarios, offering robust results in all avoidance maneuvers. Execution times were measured, demonstrating that the algorithm is computationally feasible to be implemented onboard an UAV.
KW  - UAVs in construction
KW  - obstacle avoidance
KW  - LiDAR
KW  - optimization
KW  - non-linear programming
DO  - 10.3390/drones6010016
ER  -
TY  - EJOU
AU  - Yu, Kunyong
AU  - Hao, Zhenbang
AU  - Post, Christopher J.
AU  - Mikhailova, Elena A.
AU  - Lin, Lili
AU  - Zhao, Gejin
AU  - Tian, Shangfeng
AU  - Liu, Jian
TI  - Comparison of Classical Methods and Mask R-CNN for Automatic Tree Detection and Mapping Using UAV Imagery
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - Detecting and mapping individual trees accurately and automatically from remote sensing images is of great significance for precision forest management. Many algorithms, including classical methods and deep learning techniques, have been developed and applied for tree crown detection from remote sensing images. However, few studies have evaluated the accuracy of different individual tree detection (ITD) algorithms and their data and processing requirements. This study explored the accuracy of ITD using local maxima (LM) algorithm, marker-controlled watershed segmentation (MCWS), and Mask Region-based Convolutional Neural Networks (Mask R-CNN) in a young plantation forest with different test images. Manually delineated tree crowns from UAV imagery were used for accuracy assessment of the three methods, followed by an evaluation of the data processing and application requirements for three methods to detect individual trees. Overall, Mask R-CNN can best use the information in multi-band input images for detecting individual trees. The results showed that the Mask R-CNN model with the multi-band combination produced higher accuracy than the model with a single-band image, and the RGB band combination achieved the highest accuracy for ITD (F1 score = 94.68%). Moreover, the Mask R-CNN models with multi-band images are capable of providing higher accuracies for ITD than the LM and MCWS algorithms. The LM algorithm and MCWS algorithm also achieved promising accuracies for ITD when the canopy height model (CHM) was used as the test image (F1 score = 87.86% for LM algorithm, F1 score = 85.92% for MCWS algorithm). The LM and MCWS algorithms are easy to use and lower computer computational requirements, but they are unable to identify tree species and are limited by algorithm parameters, which need to be adjusted for each classification. It is highlighted that the application of deep learning with its end-to-end-learning approach is very efficient and capable of deriving the information from multi-layer images, but an additional training set is needed for model training, robust computer resources are required, and a large number of accurate training samples are necessary. This study provides valuable information for forestry practitioners to select an optimal approach for detecting individual trees.
KW  - LM algorithm
KW  - Mask R-CNN
KW  - MCWS algorithm
KW  - plantation forest
KW  - UAV imagery
DO  - 10.3390/rs14020295
ER  -
TY  - EJOU
AU  - Tursunboev, Jamshid
AU  - Kang, Yong-Sung
AU  - Huh, Sung-Bum
AU  - Lim, Dong-Woo
AU  - Kang, Jae-Mo
AU  - Jung, Heechul
TI  - Hierarchical Federated Learning for Edge-Aided Unmanned Aerial Vehicle Networks
T2  - Applied Sciences

PY  - 2022
VL  - 12
IS  - 2
SN  - 2076-3417

AB  - Federated learning (FL) allows UAVs to collaboratively train a globally shared machine learning model while locally preserving their private data. Recently, the FL in edge-aided unmanned aerial vehicle (UAV) networks has drawn an upsurge of research interest due to a bursting increase in heterogeneous data acquired by UAVs and the need to build the global model with privacy; however, a critical issue is how to deal with the non-independent and identically distributed (non-i.i.d.) nature of heterogeneous data while ensuring the convergence of learning. To effectively address this challenging issue, this paper proposes a novel and high-performing FL scheme, namely, the hierarchical FL algorithm, for the edge-aided UAV network, which exploits the edge servers located in base stations as intermediate aggregators with employing commonly shared data. Experiment results demonstrate that the proposed hierarchical FL algorithm outperforms several baseline FL algorithms and exhibits better convergence behavior.
KW  - unmanned aerial vehicles
KW  - edge-aided networks
KW  - federated learning
KW  - hierarchical learning
DO  - 10.3390/app12020670
ER  -
TY  - EJOU
AU  - Hardy, Andy
AU  - Oakes, Gregory
AU  - Hassan, Juma
AU  - Yussuf, Yussuf
TI  - Improved Use of Drone Imagery for Malaria Vector Control through Technology-Assisted Digitizing (TAD)
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - Drones have the potential to revolutionize malaria vector control initiatives through rapid and accurate mapping of potential malarial mosquito larval habitats to help direct field Larval Source Management (LSM) efforts. However, there are no clear recommendations on how these habitats can be extracted from drone imagery in an operational context. This paper compares the results of two mapping approaches: supervised image classification using machine learning and Technology-Assisted Digitising (TAD) mapping that employs a new region growing tool suitable for non-experts. These approaches were applied concurrently to drone imagery acquired at seven sites in Zanzibar, United Republic of Tanzania. Whilst the two approaches were similar in processing time, the TAD approach significantly outperformed the supervised classification approach at all sites (t = 5.1, p &lt; 0.01). Overall accuracy scores (mean overall accuracy 62%) suggest that a supervised classification approach is unsuitable for mapping potential malarial mosquito larval habitats in Zanzibar, whereas the TAD approach offers a simple and accurate (mean overall accuracy 96%) means of mapping these complex features. We recommend that this approach be used alongside targeted ground-based surveying (i.e., in areas inappropriate for drone surveying) for generating precise and accurate spatial intelligence to support operational LSM programmes.
KW  - unmanned aerial vehicles
KW  - drones
KW  - malaria
KW  - infectious diseases
KW  - hydrology
KW  - digitizing
DO  - 10.3390/rs14020317
ER  -
TY  - EJOU
AU  - Yu, Xinyang
AU  - Chang, Chunyan
AU  - Song, Jiaxuan
AU  - Zhuge, Yuping
AU  - Wang, Ailing
TI  - Precise Monitoring of Soil Salinity in China&rsquo;s Yellow River Delta Using UAV-Borne Multispectral Imagery and a Soil Salinity Retrieval Index
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 2
SN  - 1424-8220

AB  - Monitoring salinity information of salinized soil efficiently and precisely using the unmanned aerial vehicle (UAV) is critical for the rational use and sustainable development of arable land resources. The sensitive parameter and a precise retrieval method of soil salinity, however, remain unknown. This study strived to explore the sensitive parameter and construct an optimal method for retrieving soil salinity. The UAV-borne multispectral image in China&rsquo;s Yellow River Delta was acquired to extract band reflectance, compute vegetation indexes and soil salinity indexes. Soil samples collected from 120 different study sites were used for laboratory salt content measurements. Grey correlation analysis and Pearson correlation coefficient methods were employed to screen sensitive band reflectance and indexes. A new soil salinity retrieval index (SSRI) was then proposed based on the screened sensitive reflectance. The Partial Least Squares Regression (PLSR), Multivariable Linear Regression (MLR), Back Propagation Neural Network (BPNN), Support Vector Machine (SVM), and Random Forest (RF) methods were employed to construct retrieval models based on the sensitive indexes. The results found that green, red, and near-infrared (NIR) bands were sensitive to soil salinity, which can be used to build SSRI. The SSRI-based RF method was the optimal method for accurately retrieving the soil salinity. Its modeling determination coefficient (R2) and Root Mean Square Error (RMSE) were 0.724 and 1.764, respectively; and the validation R2, RMSE, and Residual Predictive Deviation (RPD) were 0.745, 1.879, and 2.211.
KW  - soil salinity sensitive parameter
KW  - random forest
KW  - support vector machine
KW  - optimal retrieval model
KW  - remote sensing
DO  - 10.3390/s22020546
ER  -
TY  - EJOU
AU  - Bakar, Abu
AU  - Li, Ke
AU  - Liu, Haobo
AU  - Xu, Ziqi
AU  - Alessandrini, Marco
AU  - Wen, Dongsheng
TI  - Multi-Objective Optimization of Low Reynolds Number Airfoil Using Convolutional Neural Network and Non-Dominated Sorting Genetic Algorithm
T2  - Aerospace

PY  - 2022
VL  - 9
IS  - 1
SN  - 2226-4310

AB  - The airfoil is the prime component of flying vehicles. For low-speed flights, low Reynolds number airfoils are used. The characteristic of low Reynolds number airfoils is a laminar separation bubble and an associated drag rise. This paper presents a framework for the design of a low Reynolds number airfoil. The contributions of the proposed research are twofold. First, a convolutional neural network (CNN) is designed for the aerodynamic coefficient prediction of low Reynolds number airfoils. Data generation is discussed in detail and XFOIL is selected to obtain aerodynamic coefficients. The performance of the CNN is evaluated using different learning rate schedulers and adaptive learning rate optimizers. The trained model can predict the aerodynamic coefficients with high accuracy. Second, the trained model is used with a non-dominated sorting genetic algorithm (NSGA-II) for multi-objective optimization of the low Reynolds number airfoil at a specific angle of attack. A similar optimization is performed using NSGA-II directly calling XFOIL, to obtain the aerodynamic coefficients. The Pareto fronts of both optimizations are compared, and it is concluded that the proposed CNN can replicate the actual Pareto in considerably less time.
KW  - low Reynolds number airfoil
KW  - convolutional neural network
KW  - non-dominated sorting genetic algorithm
KW  - multi-objective optimization
KW  - Pareto front
DO  - 10.3390/aerospace9010035
ER  -
TY  - EJOU
AU  - Kociołek, Marcin
AU  - Kozłowski, Michał
AU  - Cardone, Antonio
TI  - A Convolutional Neural Networks-Based Approach for Texture Directionality Detection
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 2
SN  - 1424-8220

AB  - The perceived texture directionality is an important, not fully explored image characteristic. In many applications texture directionality detection is of fundamental importance. Several approaches have been proposed, such as the fast Fourier-based method. We recently proposed a method based on the interpolated grey-level co-occurrence matrix (iGLCM), robust to image blur and noise but slower than the Fourier-based method. Here we test the applicability of convolutional neural networks (CNNs) to texture directionality detection. To obtain the large amount of training data required, we built a training dataset consisting of synthetic textures with known directionality and varying perturbation levels. Subsequently, we defined and tested shallow and deep CNN architectures. We present the test results focusing on the CNN architectures and their robustness with respect to image perturbations. We identify the best performing CNN architecture, and compare it with the iGLCM, the Fourier and the local gradient orientation methods. We find that the accuracy of CNN is lower, yet comparable to the iGLCM, and it outperforms the other two methods. As expected, the CNN method shows the highest computing speed. Finally, we demonstrate the best performing CNN on real-life images. Visual analysis suggests that the learned patterns generalize to real-life image data. Hence, CNNs represent a promising approach for texture directionality detection, warranting further investigation.
KW  - directionality detection
KW  - texture
KW  - convolutional neural networks
DO  - 10.3390/s22020562
ER  -
TY  - EJOU
AU  - Berg, Paul
AU  - Santana Maia, Deise
AU  - Pham, Minh-Tan
AU  - Lefèvre, Sébastien
TI  - Weakly Supervised Detection of Marine Animals in High Resolution Aerial Images
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - Human activities in the sea, such as intensive fishing and exploitation of offshore wind farms, may impact negatively on the marine mega fauna. As an attempt to control such impacts, surveying, and tracking of marine animals are often performed on the sites where those activities take place. Nowadays, thank to high resolution cameras and to the development of machine learning techniques, tracking of wild animals can be performed remotely and the analysis of the acquired images can be automatized using state-of-the-art object detection models. However, most state-of-the-art detection methods require lots of annotated data to provide satisfactory results. Since analyzing thousands of images acquired during a flight survey can be a cumbersome and time consuming task, we focus in this article on the weakly supervised detection of marine animals. We propose a modification of the patch distribution modeling method (PaDiM), which is currently one of the state-of-the-art approaches for anomaly detection and localization for visual industrial inspection. In order to show its effectiveness and suitability for marine animal detection, we conduct a comparative evaluation of the proposed method against the original version, as well as other state-of-the-art approaches on two high-resolution marine animal image datasets. On both tested datasets, the proposed method yielded better F1 and recall scores (75% recall/41% precision, and 57% recall/60% precision, respectively) when trained on images known to contain no object of interest. This shows a great potential of the proposed approach to speed up the marine animal discovery in new flight surveys. Additionally, such a method could be adopted for bounding box proposals to perform faster and cheaper annotation within a fully-supervised detection framework.
KW  - marine animal monitoring
KW  - anomaly detection
KW  - deep learning
KW  - weakly supervised learning
KW  - convolutional neural networks
DO  - 10.3390/rs14020339
ER  -
TY  - EJOU
AU  - Denora, Michele
AU  - Fiorentini, Marco
AU  - Zenobi, Stefano
AU  - Deligios, Paola A.
AU  - Orsini, Roberto
AU  - Ledda, Luigi
AU  - Perniola, Michele
TI  - Validation of Rapid and Low-Cost Approach for the Delineation of Zone Management Based on Machine Learning Algorithms
T2  - Agronomy

PY  - 2022
VL  - 12
IS  - 1
SN  - 2073-4395

AB  - Proximal soil sensors are receiving strong attention from several disciplinary fields, and this has led to a rise in their availability in the market in the last two decades. The aim of this work was to validate agronomically a zone management delineation procedure from electromagnetic induction (EMI) maps applied to two different rainfed durum wheat fields. The k-means algorithm was applied based on the gap statistic index for the identification of the optimal number of management zones and their positions. Traditional statistical analysis was performed to detect significant differences in soil characteristics and crop response of each management zones. The procedure showed the presence of two management zones at both two sites under analysis, and it was agronomically validated by the significant difference in soil texture (+24.17%), bulk density (+6.46%), organic matter (+39.29%), organic carbon (+39.4%), total carbonates (+25.34%), total nitrogen (+30.14%), protein (+1.50%) and yield data (+1.07 t ha&minus;1). Moreover, six unmanned aerial vehicle (UAV) flight missions were performed to investigate the relationship between five vegetation indexes and the EMI maps. The results suggest performing the multispectral images acquisition during the flowering phenological stages to attribute the crop spatial variability to different soil proprieties.
KW  - machine learning
KW  - K-means
KW  - precision agriculture
KW  - zone management
KW  - validation
KW  - low-cost approach
DO  - 10.3390/agronomy12010183
ER  -
TY  - EJOU
AU  - Zhang, Ruohao
AU  - Condomines, Jean-Philippe
AU  - Lochin, Emmanuel
TI  - A Multifractal Analysis and Machine Learning Based Intrusion Detection System with an Application in a UAS/RADAR System
T2  - Drones

PY  - 2022
VL  - 6
IS  - 1
SN  - 2504-446X

AB  - The rapid development of Internet of Things (IoT) technology, together with mobile network technology, has created a never-before-seen world of interconnection, evoking research on how to make it vaster, faster, and safer. To support the ongoing fight against the malicious misuse of networks, in this paper we propose a novel algorithm called AMDES (unmanned aerial system multifractal analysis intrusion detection system) for spoofing attack detection. This novel algorithm is based on both wavelet leader multifractal analysis (WLM) and machine learning (ML) principles. In earlier research on unmanned aerial systems (UAS), intrusion detection systems (IDS) based on multifractal (MF) spectral analysis have been used to provide accurate MF spectrum estimations of network traffic. Such an estimation is then used to detect and characterize flooding anomalies that can be observed in an unmanned aerial vehicle (UAV) network. However, the previous contributions have lacked the consideration of other types of network intrusions commonly observed in UAS networks, such as the man in the middle attack (MITM). In this work, this promising methodology has been accommodated to detect a spoofing attack within a UAS. This methodology highlights a robust approach in terms of false positive performance in detecting intrusions in a UAS location reporting system.
KW  - network intrusion detection system
KW  - wavelet leader multifractal analysis
KW  - spoofing
KW  - machine learning
KW  - long-short term memory
DO  - 10.3390/drones6010021
ER  -
TY  - EJOU
AU  - Abdi, Omid
AU  - Uusitalo, Jori
AU  - Kivinen, Veli-Pekka
TI  - Logging Trail Segmentation via a Novel U-Net Convolutional Neural Network and High-Density Laser Scanning Data
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - Logging trails are one of the main components of modern forestry. However, spotting the accurate locations of old logging trails through common approaches is challenging and time consuming. This study was established to develop an approach, using cutting-edge deep-learning convolutional neural networks and high-density laser scanning data, to detect logging trails in different stages of commercial thinning, in Southern Finland. We constructed a U-Net architecture, consisting of encoder and decoder paths with several convolutional layers, pooling and non-linear operations. The canopy height model (CHM), digital surface model (DSM), and digital elevation models (DEMs) were derived from the laser scanning data and were used as image datasets for training the model. The labeled dataset for the logging trails was generated from different references as well. Three forest areas were selected to test the efficiency of the algorithm that was developed for detecting logging trails. We designed 21 routes, including 390 samples of the logging trails and non-logging trails, covering all logging trails inside the stands. The results indicated that the trained U-Net using DSM (k = 0.846 and IoU = 0.867) shows superior performance over the trained model using CHM (k = 0.734 and IoU = 0.782), DEMavg (k = 0.542 and IoU = 0.667), and DEMmin (k = 0.136 and IoU = 0.155) in distinguishing logging trails from non-logging trails. Although the efficiency of the developed approach in young and mature stands that had undergone the commercial thinning is approximately perfect, it needs to be improved in old stands that have not received the second or third commercial thinning.
KW  - U-Net
KW  - high-density laser scanning
KW  - logging trails
KW  - digital surface model
KW  - canopy height model
KW  - commercial thinning
KW  - semantic segmentation
KW  - convolutional neural networks
DO  - 10.3390/rs14020349
ER  -
TY  - EJOU
AU  - Beltran-Carbajal, Francisco
AU  - Yañez-Badillo, Hugo
AU  - Tapia-Olvera, Ruben
AU  - Favela-Contreras, Antonio
AU  - Valderrabano-Gonzalez, Antonio
AU  - Lopez-Garcia, Irvin
TI  - On Active Vibration Absorption in Motion Control of a Quadrotor UAV
T2  - Mathematics

PY  - 2022
VL  - 10
IS  - 2
SN  - 2227-7390

AB  - Conventional dynamic vibration absorbers are physical control devices designed to be coupled to flexible mechanical structures to be protected against undesirable forced vibrations. In this article, an approach to extend the capabilities of forced vibration suppression of the dynamic vibration absorbers into desired motion trajectory tracking control algorithms for a four-rotor unmanned aerial vehicle (UAV) is introduced. Nevertheless, additional physical control devices for mechanical vibration absorption are unnecessary in the proposed motion profile reference tracking control design perspective. A new dynamic control design approach for efficient tracking of desired motion profiles as well as for simultaneous active harmonic vibration absorption for a quadrotor helicopter is then proposed. In contrast to other control design methods, the presented motion tracking control scheme is based on the synthesis of multiple virtual (nonphysical) dynamic vibration absorbers. The mathematical structure of these physical mechanical devices, known as dynamic vibration absorbers, is properly exploited and extended for control synthesis for underactuated multiple-input multiple-output four-rotor nonlinear aerial dynamic systems. In this fashion, additional capabilities of active suppression of vibrating forces and torques can be achieved in specified motion directions on four-rotor helicopters. Moreover, since the dynamic vibration absorbers are designed to be virtual, these can be directly tuned for diverse operating conditions. In the present study, it is thus demonstrated that the mathematical structure of physical mechanical vibration absorbers can be extended for the design of active vibration control schemes for desired motion trajectory tracking tasks on four-rotor aerial vehicles subjected to adverse harmonic disturbances. The effectiveness of the presented novel design perspective of virtual dynamic vibration absorption schemes is proved by analytical and numerical results. Several operating case studies to stress the advantages to extend the undesirable vibration attenuation capabilities of the dynamic vibration absorbers into trajectory tracking control algorithms for nonlinear four-rotor helicopter systems are presented.
KW  - vibration control
KW  - dynamic vibration absorbers
KW  - aerial vehicles
KW  - quadrotor
KW  - motion tracking control
DO  - 10.3390/math10020235
ER  -
TY  - EJOU
AU  - Sharma, Prakriti
AU  - Leigh, Larry
AU  - Chang, Jiyul
AU  - Maimaitijiang, Maitiniyazi
AU  - Caffé, Melanie
TI  - Above-Ground Biomass Estimation in Oats Using UAV Remote Sensing and Machine Learning
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 2
SN  - 1424-8220

AB  - Current strategies for phenotyping above-ground biomass in field breeding nurseries demand significant investment in both time and labor. Unmanned aerial vehicles (UAV) can be used to derive vegetation indices (VIs) with high throughput and could provide an efficient way to predict forage yield with high accuracy. The main objective of the study is to investigate the potential of UAV-based multispectral data and machine learning approaches in the estimation of oat biomass. UAV equipped with a multispectral sensor was flown over three experimental oat fields in Volga, South Shore, and Beresford, South Dakota, USA, throughout the pre- and post-heading growth phases of oats in 2019. A variety of vegetation indices (VIs) derived from UAV-based multispectral imagery were employed to build oat biomass estimation models using four machine-learning algorithms: partial least squares (PLS), support vector machine (SVM), Artificial neural network (ANN), and random forest (RF). The results showed that several VIs derived from the UAV collected images were significantly positively correlated with dry biomass for Volga and Beresford (r = 0.2&ndash;0.65), however, in South Shore, VIs were either not significantly or weakly correlated with biomass. For Beresford, approximately 70% of the variance was explained by PLS, RF, and SVM validation models using data collected during the post-heading phase. Likewise for Volga, validation models had lower coefficient of determination (R2 = 0.20&ndash;0.25) and higher error (RMSE = 700&ndash;800 kg/ha) than training models (R2 = 0.50&ndash;0.60; RMSE = 500&ndash;690 kg/ha). In South Shore, validation models were only able to explain approx. 15&ndash;20% of the variation in biomass, which is possibly due to the insignificant correlation values between VIs and biomass. Overall, this study indicates that airborne remote sensing with machine learning has potential for above-ground biomass estimation in oat breeding nurseries. The main limitation was inconsistent accuracy in model prediction across locations. Multiple-year spectral data, along with the inclusion of textural features like crop surface model (CSM) derived height and volumetric indicators, should be considered in future studies while estimating biophysical parameters like biomass.
KW  - high throughput phenotyping
KW  - remote sensing
KW  - machine learning
KW  - UAV/drone
KW  - biomass estimation
KW  - oats
DO  - 10.3390/s22020601
ER  -
TY  - EJOU
AU  - Correia, Carlos A. M.
AU  - Andrade, Fabio A. A.
AU  - Sivertsen, Agnar
AU  - Guedes, Ihannah P.
AU  - Pinto, Milena F.
AU  - Manhães, Aline G.
AU  - Haddad, Diego B.
TI  - Comprehensive Direct Georeferencing of Aerial Images for Unmanned Aerial Systems Applications
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 2
SN  - 1424-8220

AB  - Optical image sensors are the most common remote sensing data acquisition devices present in Unmanned Aerial Systems (UAS). In this context, assigning a location in a geographic frame of reference to the acquired image is a necessary task in the majority of the applications. This process is denominated direct georeferencing when ground control points are not used. Despite it applies simple mathematical fundamentals, the complete direct georeferencing process involves much information, such as camera sensor characteristics, mounting measurements, attitude and position of the UAS, among others. In addition, there are many rotations and translations between the different reference frames, among many other details, which makes the whole process a considerable complex operation. Another problem is that manufacturers and software tools may use different reference frames posing additional difficulty when implementing the direct georeferencing. As this information is spread among many sources, researchers may face difficulties on having a complete vision of the method. In fact, there is absolutely no paper in the literature that explain this process in a comprehensive way. In order to supply this implicit demand, this paper presents a comprehensive method for direct georeferencing of aerial images acquired by cameras mounted on UAS, where all required information, mathematical operations and implementation steps are explained in detail. Finally, in order to show the practical use of the method and to prove its accuracy, both simulated and real flights were performed, where objects of the acquired images were georeferenced.
KW  - direct georeferencing
KW  - UAS
KW  - pinhole camera model
DO  - 10.3390/s22020604
ER  -
TY  - EJOU
AU  - Jing, Yafei
AU  - Ren, Yuhuan
AU  - Liu, Yalan
AU  - Wang, Dacheng
AU  - Yu, Linjun
TI  - Automatic Extraction of Damaged Houses by Earthquake Based on Improved YOLOv5: A Case Study in Yangbi
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - Efficiently and automatically acquiring information on earthquake damage through remote sensing has posed great challenges because the classical methods of detecting houses damaged by destructive earthquakes are often both time consuming and low in accuracy. A series of deep-learning-based techniques have been developed and recent studies have demonstrated their high intelligence for automatic target extraction for natural and remote sensing images. For the detection of small artificial targets, current studies show that You Only Look Once (YOLO) has a good performance in aerial and Unmanned Aerial Vehicle (UAV) images. However, less work has been conducted on the extraction of damaged houses. In this study, we propose a YOLOv5s-ViT-BiFPN-based neural network for the detection of rural houses. Specifically, to enhance the feature information of damaged houses from the global information of the feature map, we introduce the Vision Transformer into the feature extraction network. Furthermore, regarding the scale differences for damaged houses in UAV images due to the changes in flying height, we apply the Bi-Directional Feature Pyramid Network (BiFPN) for multi-scale feature fusion to aggregate features with different resolutions and test the model. We took the 2021 Yangbi earthquake with a surface wave magnitude (Ms) of 6.4 in Yunan, China, as an example; the results show that the proposed model presents a better performance, with the average precision (AP) being increased by 9.31% and 1.23% compared to YOLOv3 and YOLOv5s, respectively, and a detection speed of 80 FPS, which is 2.96 times faster than YOLOv3. In addition, the transferability test for five other areas showed that the average accuracy was 91.23% and the total processing time was 4 min, while 100 min were needed for professional visual interpreters. The experimental results demonstrate that the YOLOv5s-ViT-BiFPN model can automatically detect damaged rural houses due to destructive earthquakes in UAV images with a good performance in terms of accuracy and timeliness, as well as being robust and transferable.
KW  - damaged houses
KW  - detection
KW  - orthophotos of UAV
KW  - YOLOv5s-ViT-BiFPN
KW  - Yangbi Ms6.4 earthquake
DO  - 10.3390/rs14020382
ER  -
TY  - EJOU
AU  - Li, Zongpeng
AU  - Chen, Zhen
AU  - Cheng, Qian
AU  - Duan, Fuyi
AU  - Sui, Ruixiu
AU  - Huang, Xiuqiao
AU  - Xu, Honggang
TI  - UAV-Based Hyperspectral and Ensemble Machine Learning for Predicting Yield in Winter Wheat
T2  - Agronomy

PY  - 2022
VL  - 12
IS  - 1
SN  - 2073-4395

AB  - Winter wheat is a widely-grown cereal crop worldwide. Using growth-stage information to estimate winter wheat yields in a timely manner is essential for accurate crop management and rapid decision-making in sustainable agriculture, and to increase productivity while reducing environmental impact. UAV remote sensing is widely used in precision agriculture due to its flexibility and increased spatial and spectral resolution. Hyperspectral data are used to model crop traits because of their ability to provide continuous rich spectral information and higher spectral fidelity. In this study, hyperspectral image data of the winter wheat crop canopy at the flowering and grain-filling stages was acquired by a low-altitude unmanned aerial vehicle (UAV), and machine learning was used to predict winter wheat yields. Specifically, a large number of spectral indices were extracted from the spectral data, and three feature selection methods, recursive feature elimination (RFE), Boruta feature selection, and the Pearson correlation coefficient (PCC), were used to filter high spectral indices in order to reduce the dimensionality of the data. Four major basic learner models, (1) support vector machine (SVM), (2) Gaussian process (GP), (3) linear ridge regression (LRR), and (4) random forest (RF), were also constructed, and an ensemble machine learning model was developed by combining the four base learner models. The results showed that the SVM yield prediction model, constructed on the basis of the preferred features, performed the best among the base learner models, with an R2 between 0.62 and 0.73. The accuracy of the proposed ensemble learner model was higher than that of each base learner model; moreover, the R2 (0.78) for the yield prediction model based on Boruta&rsquo;s preferred characteristics was the highest at the grain-filling stage.
KW  - yield
KW  - feature selection
KW  - flowering
KW  - grain filling
KW  - prediction model
DO  - 10.3390/agronomy12010202
ER  -
TY  - EJOU
AU  - Talaei Khoei, Tala
AU  - Ismail, Shereen
AU  - Kaabouch, Naima
TI  - Dynamic Selection Techniques for Detecting GPS Spoofing Attacks on UAVs
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 2
SN  - 1424-8220

AB  - Unmanned aerial vehicles are prone to several cyber-attacks, including Global Positioning System spoofing. Several techniques have been proposed for detecting such attacks. However, the recurrence and frequent Global Positioning System spoofing incidents show a need for effective security solutions to protect unmanned aerial vehicles. In this paper, we propose two dynamic selection techniques, Metric Optimized Dynamic selector and Weighted Metric Optimized Dynamic selector, which identify the most effective classifier for the detection of such attacks. We develop a one-stage ensemble feature selection method to identify and discard the correlated and low importance features from the dataset. We implement the proposed techniques using ten machine-learning models and compare their performance in terms of four evaluation metrics: accuracy, probability of detection, probability of false alarm, probability of misdetection, and processing time. The proposed techniques dynamically choose the classifier with the best results for detecting attacks. The results indicate that the proposed dynamic techniques outperform the existing ensemble models with an accuracy of 99.6%, a probability of detection of 98.9%, a probability of false alarm of 1.56%, a probability of misdetection of 1.09%, and a processing time of 1.24 s.
KW  - unmanned aerial vehicles
KW  - global positioning system
KW  - GPS spoofing attacks
KW  - detection techniques
KW  - machine learning
KW  - dynamic selection
KW  - hyperparameter tuning
DO  - 10.3390/s22020662
ER  -
TY  - EJOU
AU  - Shi, Yue
AU  - Han, Liangxiu
AU  - Kleerekoper, Anthony
AU  - Chang, Sheng
AU  - Hu, Tongle
TI  - Novel CropdocNet Model for Automated Potato Late Blight Disease Detection from Unmanned Aerial Vehicle-Based Hyperspectral Imagery
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - The accurate and automated diagnosis of potato late blight disease, one of the most destructive potato diseases, is critical for precision agricultural control and management. Recent advances in remote sensing and deep learning offer the opportunity to address this challenge. This study proposes a novel end-to-end deep learning model (CropdocNet) for accurate and automated late blight disease diagnosis from UAV-based hyperspectral imagery. The proposed method considers the potential disease-specific reflectance radiation variance caused by the canopy&rsquo;s structural diversity and introduces multiple capsule layers to model the part-to-whole relationship between spectral&ndash;spatial features and the target classes to represent the rotation invariance of the target classes in the feature space. We evaluate the proposed method with real UAV-based HSI data under controlled and natural field conditions. The effectiveness of the hierarchical features is quantitatively assessed and compared with the existing representative machine learning/deep learning methods on both testing and independent datasets. The experimental results show that the proposed model significantly improves accuracy when considering the hierarchical structure of spectral&ndash;spatial features, with average accuracies of 98.09% for the testing dataset and 95.75% for the independent dataset, respectively.
KW  - potato late blight
KW  - automated crop disease diagnosis
KW  - UAV-based hyperspectral imagery
KW  - deep learning
KW  - classification
DO  - 10.3390/rs14020396
ER  -
TY  - EJOU
AU  - Zhang, Fangfang
AU  - Wang, Changkun
AU  - Pan, Kai
AU  - Guo, Zhiying
AU  - Liu, Jie
AU  - Xu, Aiai
AU  - Ma, Haiyi
AU  - Pan, Xianzhang
TI  - The Simultaneous Prediction of Soil Properties and Vegetation Coverage from Vis-NIR Hyperspectral Data with a One-Dimensional Convolutional Neural Network: A Laboratory Simulation Study
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - Remote sensing of land surface mostly obtains a mixture of spectral information of soil and vegetation. It is thus of great value if soil and vegetation information can be acquired simultaneously from one model. In this study, we designed a laboratory experiment to simulate land surface compositions, including various soil types with varying soil moisture and vegetation coverage. A model of a one-dimensional convolutional neural network (1DCNN) was established to simultaneously estimate soil properties (organic matter, soil moisture, clay, and sand) and vegetation coverage based on the hyperspectral data measured in the experiment. The results showed that the model achieved excellent predictions for soil properties (R2 = 0.88&ndash;0.91, RPIQ = 4.01&ndash;5.78) and vegetation coverage (R2 = 0.95, RPIQ = 7.75). Compared with the partial least-squares regression (PLSR), the prediction accuracy of 1DCNN improved 42.20%, 45.82%, 43.32%, and 36.46% in terms of the root-mean-squared error (RMSE) for predicting soil organic matter, sand, clay, and soil moisture, respectively. The improvement might be caused by the fact that the spectral preprocessing and spectral features useful for predicting soil properties were successfully identified in the 1DCNN model. For the prediction of vegetation coverage, although the prediction accuracy by 1DCNN was excellent, its performance (R2 = 0.95, RPIQ = 7.75, RMSE = 3.92%) was lower than the PLSR model (R2 = 0.98, RPIQ = 12.57, RMSE = 2.41%). These results indicate that 1DCNN can simultaneously predict soil properties and vegetation coverage. However, the factors such as surface roughness and vegetation type that could affect the prediction accuracy should be investigated in the future.
KW  - convolutional neural network
KW  - multitask learning
KW  - soil properties
KW  - vegetation coverage
DO  - 10.3390/rs14020397
ER  -
TY  - EJOU
AU  - Xu, Zhibo
AU  - Huang, Xiaopeng
AU  - Huang, Yuan
AU  - Sun, Haobo
AU  - Wan, Fangxin
TI  - A Real-Time Zanthoxylum Target Detection Method for an Intelligent Picking Robot under a Complex Background, Based on an Improved YOLOv5s Architecture
T2  - Sensors

PY  - 2022
VL  - 22
IS  - 2
SN  - 1424-8220

AB  - The target recognition algorithm is one of the core technologies of Zanthoxylum pepper-picking robots. However, most existing detection algorithms cannot effectively detect Zanthoxylum fruit covered by branches, leaves and other fruits in natural scenes. To improve the work efficiency and adaptability of the Zanthoxylum-picking robot in natural environments, and to recognize and detect fruits in complex environments under different lighting conditions, this paper presents a Zanthoxylum-picking-robot target detection method based on improved YOLOv5s. Firstly, an improved CBF module based on the CBH module in the backbone is raised to improve the detection accuracy. Secondly, the Specter module based on CBF is presented to replace the bottleneck CSP module, which improves the speed of detection with a lightweight structure. Finally, the Zanthoxylum fruit algorithm is checked by the improved YOLOv5 framework, and the differences in detection between YOLOv3, YOLOv4 and YOLOv5 are analyzed and evaluated. Through these improvements, the recall rate, recognition accuracy and mAP of the YOLOv5s are 4.19%, 28.7% and 14.8% higher than those of the original YOLOv5s, YOLOv3 and YOLOv4 models, respectively. Furthermore, the model is transferred to the computing platform of the robot with the cutting-edge NVIDIA Jetson TX2 device. Several experiments are implemented on the TX2, yielding an average time of inference of 0.072, with an average GPU load in 30 s of 20.11%. This method can provide technical support for pepper-picking robots to detect multiple pepper fruits in real time.
KW  - Zanthoxylum
KW  - artificial intelligence
KW  - YOLOv5
KW  - target detection
KW  - picking robot
DO  - 10.3390/s22020682
ER  -
TY  - EJOU
AU  - Paux, Etienne
AU  - Lafarge, Stéphane
AU  - Balfourier, François
AU  - Derory, Jérémy
AU  - Charmet, Gilles
AU  - Alaux, Michael
AU  - Perchet, Geoffrey
AU  - Bondoux, Marion
AU  - Baret, Frédéric
AU  - Barillot, Romain
AU  - Ravel, Catherine
AU  - Sourdille, Pierre
AU  - Le Gouis, Jacques
AU  - on behalf of the BREEDWHEAT Consortium
TI  - Breeding for Economically and Environmentally Sustainable Wheat Varieties: An Integrated Approach from Genomics to Selection
T2  - Biology

PY  - 2022
VL  - 11
IS  - 1
SN  - 2079-7737

AB  - There is currently a strong societal demand for sustainability, quality, and safety in bread wheat production. To address these challenges, new and innovative knowledge, resources, tools, and methods to facilitate breeding are needed. This starts with the development of high throughput genomic tools including single nucleotide polymorphism (SNP) arrays, high density molecular marker maps, and full genome sequences. Such powerful tools are essential to perform genome-wide association studies (GWAS), to implement genomic and phenomic selection, and to characterize the worldwide diversity. This is also useful to breeders to broaden the genetic basis of elite varieties through the introduction of novel sources of genetic diversity. Improvement in varieties particularly relies on the detection of genomic regions involved in agronomical traits including tolerance to biotic (diseases and pests) and abiotic (drought, nutrient deficiency, high temperature) stresses. When enough resolution is achieved, this can result in the identification of candidate genes that could further be characterized to identify relevant alleles. Breeding must also now be approached through in silico modeling to simulate plant development, investigate genotype &times; environment interactions, and introduce marker&ndash;trait linkage information in the models to better implement genomic selection. Breeders must be aware of new developments and the information must be made available to the world wheat community to develop new high-yielding varieties that can meet the challenge of higher wheat production in a sustainable and fluctuating agricultural context. In this review, we compiled all knowledge and tools produced during the BREEDWHEAT project to show how they may contribute to face this challenge in the coming years.
KW  - wheat
KW  - Triticum aestivum
KW  - wheat breeding
KW  - molecular tools
KW  - genomic selection
KW  - high throughput phenotyping
KW  - diversity
KW  - wheat database
DO  - 10.3390/biology11010149
ER  -
TY  - EJOU
AU  - Qi, Guanqiu
AU  - Zhang, Yuanchuan
AU  - Wang, Kunpeng
AU  - Mazur, Neal
AU  - Liu, Yang
AU  - Malaviya, Devanshi
TI  - Small Object Detection Method Based on Adaptive Spatial Parallel Convolution and Fast Multi-Scale Fusion
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 2
SN  - 2072-4292

AB  - As one type of object detection, small object detection has been widely used in daily-life-related applications with many real-time requirements, such as autopilot and navigation. Although deep-learning-based object detection methods have achieved great success in recent years, they are not effective in small object detection and most of them cannot achieve real-time processing. Therefore, this paper proposes a single-stage small object detection network (SODNet) that integrates the specialized feature extraction and information fusion techniques. An adaptively spatial parallel convolution module (ASPConv) is proposed to alleviate the lack of spatial information for target objects and adaptively obtain the corresponding spatial information through multi-scale receptive fields, thereby improving the feature extraction ability. Additionally, a split-fusion sub-module (SF) is proposed to effectively reduce the time complexity of ASPConv. A fast multi-scale fusion module (FMF) is proposed to alleviate the insufficient fusion of both semantic and spatial information. FMF uses two fast upsampling operators to first unify the resolution of the multi-scale feature maps extracted by the network and then fuse them, thereby effectively improving the small object detection ability. Comparative experimental results prove that the proposed method considerably improves the accuracy of small object detection on multiple benchmark datasets and achieves a high real-time performance.
KW  - small object detection
KW  - adaptive spatial parallel convolution
KW  - multi-scale fusion
DO  - 10.3390/rs14020420
ER  -
TY  - EJOU
AU  - Di Gennaro, Salvatore F.
AU  - Toscano, Piero
AU  - Gatti, Matteo
AU  - Poni, Stefano
AU  - Berton, Andrea
AU  - Matese, Alessandro
TI  - Spectral Comparison of UAV-Based Hyper and Multispectral Cameras for Precision Viticulture
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 3
SN  - 2072-4292

AB  - Analysis of the spectral response of vegetation using optical sensors for non-destructive remote monitoring represents a key element for crop monitoring. Considering the wide presence on the market of unmanned aerial vehicle (UAVs) based commercial solutions, the need emerges for clear information on the performance of these products to guide the end-user in their choice and utilization for precision agriculture applications. This work aims to compare two UAV based commercial products, represented by DJI P4M and SENOP HSC-2 for the acquisition of multispectral and hyperspectral images, respectively, in vineyards. The accuracy of both cameras was evaluated on 6 different targets commonly found in vineyards, represented by bare soil, bare-stony soil, stony soil, soil with dry grass, partially grass covered soil and canopy. Given the importance of the radiometric calibration, four methods for multispectral images correction were evaluated, taking in account the irradiance sensor equipped on the camera (M1&ndash;M2) and the use of an empirical line model (ELM) based on reference reflectance panels (M3&ndash;M4). In addition, different DJI P4M exposure setups were evaluated. The performance of the cameras was evaluated by means of the calculation of three widely used vegetation indices (VIs), as percentage error (PE) with respect to ground truth spectroradiometer measurements. The results highlighted the importance of reference panels for the radiometric calibration of multispectral images (M1&ndash;M2 average PE = 21.8&ndash;100.0%; M3&ndash;M4 average PE = 11.9&ndash;29.5%). Generally, the hyperspectral camera provided the best accuracy with a PE ranging between 1.0% and 13.6%. Both cameras showed higher performance on the pure canopy pixel target, compared to mixed targets. However, this issue can be easily solved by applying widespread segmentation techniques for the row extraction. This work provides insights to assist end-users in the UAV spectral monitoring to obtain reliable information for the analysis of spatio-temporal variability within vineyards.
KW  - vegetation indices
KW  - precision agriculture
KW  - remote sensing
KW  - spectral signature
KW  - imaging sensor
KW  - radiometric calibration
DO  - 10.3390/rs14030449
ER  -
TY  - EJOU
AU  - Fan, Yunsheng
AU  - Guo, Hongrun
AU  - Han, Xinjie
AU  - Chen, Xinyu
TI  - Research and Verification of Trajectory Tracking Control of a Quadrotor Carrying a Load
T2  - Applied Sciences

PY  - 2022
VL  - 12
IS  - 3
SN  - 2076-3417

AB  - This paper assumes that considering the unknown and time-varying nature of different strong and weak wind field disturbances and considering the nonlinear, under-driven, strongly coupled quadrotor carrying, a load is disturbed by the complex and variable wind field and unmodeled parts when flying in the real external environment, which will reduce the control effect of the nonlinear controller and make the vehicle fail to affect the flight effect. In order to ensure that the quadrotor carrying a load can carry supplies in the harsh environment for stable trajectory tracking, a neural network adaptive control algorithm is introduced in the article. The neural network algorithm has the role of online dynamic approximation, the compensation of arbitrary external disturbance and the compensation of external disturbance. Its structure is simple and low computation. In the article, the Lyapunov method is used to design the adaptive weight and estimate the weight of the online neural network, and the stability of the system is proved. Finally, the comparison of three algorithms verified by simulation proves that the above interference problem can be solved effectively by the proposed algorithm.
KW  - quadrotor
KW  - load
KW  - neural network
KW  - integral backstepping
KW  - trajectory tracking
DO  - 10.3390/app12031036
ER  -
TY  - EJOU
AU  - Aslan, Muhammet F.
AU  - Durdu, Akif
AU  - Sabanci, Kadir
AU  - Ropelewska, Ewa
AU  - Gültekin, Seyfettin S.
TI  - A Comprehensive Survey of the Recent Studies with UAV for Precision Agriculture in Open Fields and Greenhouses
T2  - Applied Sciences

PY  - 2022
VL  - 12
IS  - 3
SN  - 2076-3417

AB  - The increasing world population makes it necessary to fight challenges such as climate change and to realize production efficiently and quickly. However, the minimum cost, maximum income, environmental pollution protection and the ability to save water and energy are all factors that should be taken into account in this process. The use of information and communication technologies (ICTs) in agriculture to meet all of these criteria serves the purpose of precision agriculture. As unmanned aerial vehicles (UAVs) can easily obtain real-time data, they have a great potential to address and optimize solutions to the problems faced by agriculture. Despite some limitations, such as the battery, load, weather conditions, etc., UAVs will be used frequently in agriculture in the future because of the valuable data that they obtain and their efficient applications. According to the known literature, UAVs have been carrying out tasks such as spraying, monitoring, yield estimation, weed detection, etc. In recent years, articles related to agricultural UAVs have been presented in journals with high impact factors. Most precision agriculture applications with UAVs occur in outdoor environments where GPS access is available, which provides more reliable control of the UAV in both manual and autonomous flights. On the other hand, there are almost no UAV-based applications in greenhouses where all-season crop production is available. This paper emphasizes this deficiency and provides a comprehensive review of the use of UAVs for agricultural tasks and highlights the importance of simultaneous localization and mapping (SLAM) for a UAV solution in the greenhouse.
KW  - indoor and outdoor environments
KW  - greenhouse
KW  - precision agriculture
KW  - SLAM
KW  - UAV
DO  - 10.3390/app12031047
ER  -
TY  - EJOU
AU  - Brewer, Kiara
AU  - Clulow, Alistair
AU  - Sibanda, Mbulisi
AU  - Gokool, Shaeden
AU  - Naiken, Vivek
AU  - Mabhaudhi, Tafadzwanashe
TI  - Predicting the Chlorophyll Content of Maize over Phenotyping as a Proxy for Crop Health in Smallholder Farming Systems
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 3
SN  - 2072-4292

AB  - Smallholder farmers depend on healthy and productive crop yields to sustain their socio-economic status and ensure livelihood security. Advances in South African precision agriculture in the form of unmanned aerial vehicles (UAVs) provide spatially explicit near-real-time information that can be used to assess crop dynamics and inform smallholder farmers. The use of UAVs with remote-sensing techniques allows for the acquisition of high spatial resolution data at various spatio-temporal planes, which is particularly useful at the scale of fields and farms. Specifically, crop chlorophyll content is assessed as it is one of the best known and reliable indicators of crop health, due to its biophysical pigment and biochemical processes that indicate plant productivity. In this regard, the study evaluated the utility of multispectral UAV imagery using the random forest machine learning algorithm to estimate the chlorophyll content of maize through the various growth stages. The results showed that the near-infrared and red-edge wavelength bands and vegetation indices derived from these wavelengths were essential for estimating chlorophyll content during the phenotyping of maize. Furthermore, the random forest model optimally estimated the chlorophyll content of maize over the various phenological stages. Particularly, maize chlorophyll was best predicted during the early reproductive, late vegetative, and early vegetative growth stages to RMSE accuracies of 40.4 &micro;mol/m&minus;2, 39 &micro;mol/m&minus;2, and 61.6 &micro;mol/m&minus;2, respectively. The least accurate chlorophyll content results were predicted during the mid-reproductive and late reproductive growth stages to RMSE accuracies of 66.6 &micro;mol/m&minus;2 and 69.6 &micro;mol/m&minus;2, respectively, as a consequence of a hailstorm. A resultant chlorophyll variation map of the maize growth stages captured the spatial heterogeneity of chlorophyll within the maize field. Therefore, the study&rsquo;s findings demonstrate that the use of remotely sensed UAV imagery with a robust machine algorithm is a critical tool to support the decision-making and management in smallholder farms.
KW  - chlorophyll
KW  - drones
KW  - machine learning
KW  - precision agriculture
KW  - random forest
KW  - smallholder farming systems
KW  - UAV applications
KW  - unmanned aerial vehicle
DO  - 10.3390/rs14030518
ER  -
TY  - EJOU
AU  - Peng, Baochai
AU  - Ren, Dong
AU  - Zheng, Cheng
AU  - Lu, Anxiang
TI  - TRDet: Two-Stage Rotated Detection of Rural Buildings in Remote Sensing Images
T2  - Remote Sensing

PY  - 2022
VL  - 14
IS  - 3
SN  - 2072-4292

AB  - Fast and accurate acquisition of the outline of rural buildings on remote sensing images is an efficient method to monitor illegal rural buildings. The traditional object detection method produces useless background information when detecting rural buildings; the semantic segmentation method cannot accurately segment the contours between buildings; the instance segmentation method cannot obtain regular building contours. The rotated object detection methods can effectively solve the problem that the traditional artificial intelligence method cannot accurately extract the outline of buildings. However, the rotated object detection methods are easy to lose location information of small objects in advanced feature maps and are sensitive to noise. To resolve these problems, this paper proposes a two-stage rotated object detection network for rural buildings (TRDet) by using a deep feature fusion network (DFF-Net) and a pixel attention module (PAM). Specifically, TRDet first fuses low-level location and high-level semantic information through the DFF-Net and then reduces the interference of noise information to the network through the PAM. The experimental results show that the mean average precession (mAP), precision, recall rate, and F1 score of the proposed TRDet are 83.57%, 91.11%, 86.5%, and 88.74%, respectively, which outperform the R2CNN model by 15%, 15.54%, 4.01%, and 9.87%. The results demonstrate that the TRDet can achieve better detection in small rural buildings and dense rural buildings.
KW  - rotated object detection
KW  - rural buildings
KW  - feature fusion
KW  - pixel attention
DO  - 10.3390/rs14030522
ER  -

TY  - EJOU
AU  - Wang, Jie
AU  - Simeonova, Sandra
AU  - Shahbazi, Mozhdeh
TI  - Orientation- and Scale-Invariant Multi-Vehicle Detection and Tracking from Unmanned Aerial Videos
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 18
SN  - 2072-4292

AB  - Along with the advancement of light-weight sensing and processing technologies, unmanned aerial vehicles (UAVs) have recently become popular platforms for intelligent traffic monitoring and control. UAV-mounted cameras can capture traffic-flow videos from various perspectives providing a comprehensive insight into road conditions. To analyze the traffic flow from remotely captured videos, a reliable and accurate vehicle detection-and-tracking approach is required. In this paper, we propose a deep-learning framework for vehicle detection and tracking from UAV videos for monitoring traffic flow in complex road structures. This approach is designed to be invariant to significant orientation and scale variations in the videos. The detection procedure is performed by fine-tuning a state-of-the-art object detector, You Only Look Once (YOLOv3), using several custom-labeled traffic datasets. Vehicle tracking is conducted following a tracking-by-detection paradigm, where deep appearance features are used for vehicle re-identification, and Kalman filtering is used for motion estimation. The proposed methodology is tested on a variety of real videos collected by UAVs under various conditions, e.g., in late afternoons with long vehicle shadows, in dawn with vehicles lights being on, over roundabouts and interchange roads where vehicle directions change considerably, and from various viewpoints where vehicles&rsquo; appearance undergo substantial perspective distortions. The proposed tracking-by-detection approach performs efficiently at 11 frames per second on color videos of 2720p resolution. Experiments demonstrated that high detection accuracy could be achieved with an average F1-score of 92.1%. Besides, the tracking technique performs accurately, with an average multiple-object tracking accuracy (MOTA) of 81.3%. The proposed approach also addressed the shortcomings of the state-of-the-art in multi-object tracking regarding frequent identity switching, resulting in a total of only one identity switch over every 305 tracked vehicles.
KW  - traffic monitoring
KW  - vehicle detection
KW  - multi-vehicle tracking
KW  - vehicle re-identification
KW  - unmanned aerial vehicles
KW  - deep convolutional neural network.
DO  - 10.3390/rs11182155
ER  -
TY  - EJOU
AU  - Wang, Dezhi
AU  - Wan, Bo
AU  - Qiu, Penghua
AU  - Zuo, Zejun
AU  - Wang, Run
AU  - Wu, Xincai
TI  - Mapping Height and Aboveground Biomass of Mangrove Forests on Hainan Island Using UAV-LiDAR Sampling
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 18
SN  - 2072-4292

AB  - Hainan Island is the second-largest island in China and has the most species-diverse mangrove forests in the country. To date, the height and aboveground ground biomass (AGB) of the mangrove forests on Hainan Island are unknown, partly as a result of the challenges faced during extensive field sampling in mangrove habitats (intertidal mudflats inundated by periodic seawater). Therefore, this study used a low-cost UAV-LiDAR (light detection and ranging sensor mounted on an unmanned aerial vehicle) system as a sampling tool and Sentinel-2 imagery as auxiliary data to estimate and map the mangrove height and AGB on Hainan Island. Hainan Island has 3697.02 hectares of mangrove forests with an average patch area of approximately 1 ha. The results show that the mangroves on whole Hainan Island have an average height of 6.99 m, a total AGB of 474,199.31 Mg and an AGB density of 128.27 Mg ha&minus;1. The AGB hot spots are located in Qinglan Harbor and the south of Dongzhai Harbor. The proposed height model LiDAR-S2 performed well with an R2 of 0.67 and an RMSE (root mean square error) of 1.90 m; the proposed AGB model G~LiDAR~S2 performed better (an R2 of 0.62 and an RMSE of 50.36 Mg ha&minus;1) than the traditional AGB model G~S2 that directly related ground plots and Sentinel-2 data. The results also indicate that the LiDAR metrics describing the canopy&rsquo;s thickness and its top and bottom characteristics are the most important variables for mangrove AGB estimation. For the Sentinel-2 indices, the red-edge and shortwave infrared features, especially the red-edge 1 and shortwave infrared Band 11 features, play the most important roles in estimating mangrove AGB and height. In conclusion, this paper presents the first mangrove height and AGB maps of Hainan Island and demonstrates the feasibility of using UAV-LiDAR as a sampling tool for mangrove forests.
KW  - mangroves
KW  - Hainan island
KW  - aboveground biomass
KW  - UAV-LiDAR sampling
KW  - Sentinel-2
KW  - random forest
KW  - feature importance
DO  - 10.3390/rs11182156
ER  -
TY  - EJOU
AU  - Zou, Xiaodan
AU  - Liang, Anjie
AU  - Wu, Bizhi
AU  - Su, Jun
AU  - Zheng, Renhua
AU  - Li, Jian
TI  - UAV-Based High-Throughput Approach for Fast Growing Cunninghamia lanceolata (Lamb.) Cultivar Screening by Machine Learning
T2  - Forests

PY  - 2019
VL  - 10
IS  - 9
SN  - 1999-4907

AB  - Obtaining accurate measurements of tree height and diameter at breast height (DBH) in forests to evaluate the growth rate of cultivars is still a significant challenge, even when using light detection and ranging (LiDAR) and three-dimensional (3-D) modeling. As an alternative, we provide a novel high-throughput strategy for predicting the biomass of forests in the field by vegetation indices. This study proposes an integrated pipeline methodology to measure the biomass of different tree cultivars in plantation forests with high crown density, which combines unmanned aerial vehicles (UAVs), hyperspectral image sensors, and data processing algorithms using machine learning. Using a planation of Cunninghamia lanceolate, which is commonly known as Chinese fir, in Fujian, China, images were collected while using a hyperspectral camera. Vegetation indices and modeling were processed in Python using decision trees, random forests, support vector machine, and eXtreme Gradient Boosting (XGBoost) third-party libraries. The tree height and DBH of 2880 samples were manually measured and clustered into three groups&mdash;&ldquo;Fast&rdquo;, &ldquo;median&rdquo;, and &ldquo;normal&rdquo; growth groups&mdash;and 19 vegetation indices from 12,000 pixels were abstracted as the input of features for the modeling. After modeling and cross-validation, the classifier that was generated by random forests had the best prediction accuracy when compared to other algorithms (75%). This framework can be applied to other tree species to make management and business decisions.
KW  - Cunninghamia lanceolate
KW  - UAVs
KW  - hyperspectral camera
KW  - machine learning
KW  - random forests
KW  - XGBoost
DO  - 10.3390/f10090815
ER  -
TY  - EJOU
AU  - Salameh, Edward
AU  - Frappart, Frédéric
AU  - Almar, Rafael
AU  - Baptista, Paulo
AU  - Heygster, Georg
AU  - Lubac, Bertrand
AU  - Raucoules, Daniel
AU  - Almeida, Luis P.
AU  - Bergsma, Erwin W. J.
AU  - Capo, Sylvain
AU  - De Michele, Marcello
AU  - Idier, Deborah
AU  - Li, Zhen
AU  - Marieu, Vincent
AU  - Poupardin, Adrien
AU  - Silva, Paulo A.
AU  - Turki, Imen
AU  - Laignel, Benoit
TI  - Monitoring Beach Topography and Nearshore Bathymetry Using Spaceborne Remote Sensing: A Review
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 19
SN  - 2072-4292

AB  - With high anthropogenic pressure and the effects of climate change (e.g., sea level rise) on coastal regions, there is a greater need for accurate and up-to-date information about the topography of these systems. Reliable topography and bathymetry information are fundamental parameters for modelling the morpho-hydrodynamics of coastal areas, for flood forecasting, and for coastal management. Traditional methods such as ground, ship-borne, and airborne surveys suffer from limited spatial coverage and temporal sampling due to logistical constraints and high costs which limit their ability to provide the needed information. The recent advancements of spaceborne remote sensing techniques, along with their ability to acquire data over large spatial areas and to provide high frequency temporal monitoring, has made them very attractive for topography and bathymetry mapping. In this review, we present an overview of the current state of spaceborne-based remote sensing techniques used to estimate the topography and bathymetry of beaches, intertidal, and nearshore areas. We also provide some insights about the potential of these techniques when using data provided by new and future satellite missions.
KW  - spaceborne remote sensing
KW  - satellite
KW  - beaches
KW  - intertidal
KW  - nearshore
KW  - shallow waters
KW  - topography
KW  - bathymetry
KW  - digital elevation model (DEM)
DO  - 10.3390/rs11192212
ER  -
TY  - EJOU
AU  - Phuc, Le T.
AU  - Jeon, HyeJun
AU  - Truong, Nguyen T.
AU  - Hak, Jung J.
TI  - Applying the Haar-cascade Algorithm for Detecting Safety Equipment in Safety Management Systems for Multiple Working Environments
T2  - Electronics

PY  - 2019
VL  - 8
IS  - 10
SN  - 2079-9292

AB  - There are many ways to maintain the safety of workers on a working site, such as using a human supervisor, computer supervisor, and smoke&ndash;flame detecting system. In order to create a safety warning system for the working site, the machine-learning algorithm&mdash;Haar-cascade classifier&mdash;was used to build four different classes for safety equipment recognition. Then a proposed algorithm was applied to calculate a score to determine the dangerousness of the current working environment based on the safety equipment and working environment. With this data, the system decides whether it is necessary to give a warning signal. For checking the efficiency of this project, three different situations were installed with this system. Generally, with the promising outcome, this application can be used in maintaining, supervising, and controlling the safety of a worker.
KW  - Haar–cascade algorithm
KW  - safety equipment
KW  - safety management system
DO  - 10.3390/electronics8101079
ER  -
TY  - EJOU
AU  - Pádua, Luís
AU  - Marques, Pedro
AU  - Adão, Telmo
AU  - Guimarães, Nathalie
AU  - Sousa, António
AU  - Peres, Emanuel
AU  - Sousa, Joaquim J.
TI  - Vineyard Variability Analysis through UAV-Based Vigour Maps to Assess Climate Change Impacts
T2  - Agronomy

PY  - 2019
VL  - 9
IS  - 10
SN  - 2073-4395

AB  - Climate change is projected to be a key influence on crop yields across the globe. Regarding viticulture, primary climate vectors with a significant impact include temperature, moisture stress, and radiation. Within this context, it is of foremost importance to monitor soils&rsquo; moisture levels, as well as to detect pests, diseases, and possible problems with irrigation equipment. Regular monitoring activities will enable timely measures that may trigger field interventions that are used to preserve grapevines&rsquo; phytosanitary state, saving both time and money, while assuring a more sustainable activity. This study employs unmanned aerial vehicles (UAVs) to acquire aerial imagery, using RGB, multispectral and thermal infrared sensors in a vineyard located in the Portuguese Douro wine region. Data acquired enabled the multi-temporal characterization of the vineyard development throughout a season through the computation of the normalized difference vegetation index, crop surface models, and the crop water stress index. Moreover, vigour maps were computed in three classes (high, medium, and low) with different approaches: (1) considering the whole vineyard, including inter-row vegetation and bare soil; (2) considering only automatically detected grapevine vegetation; and (3) also considering grapevine vegetation by only applying a normalization process before creating the vigour maps. Results showed that vigour maps considering only grapevine vegetation provided an accurate representation of the vineyard variability. Furthermore, significant spatial associations can be gathered through (i) a multi-temporal analysis of vigour maps, and (ii) by comparing vigour maps with both height and water stress estimation. This type of analysis can assist, in a significant way, the decision-making processes in viticulture.
KW  - unmanned aerial vehicles
KW  - vigour maps
KW  - spatial variability
KW  - normalized difference vegetation index
KW  - crop water stress index
KW  - crop surface model
KW  - precision viticulture
KW  - climate change
KW  - multi-temporal analysis
DO  - 10.3390/agronomy9100581
ER  -
TY  - EJOU
AU  - Jiao, Leilei
AU  - Sun, Weiwei
AU  - Yang, Gang
AU  - Ren, Guangbo
AU  - Liu, Yinnian
TI  - A Hierarchical Classification Framework of Satellite Multispectral/Hyperspectral Images for Mapping Coastal Wetlands
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 19
SN  - 2072-4292

AB  - Mapping different land cover types with satellite remote sensing data is significant for restoring and protecting natural resources and ecological services in coastal wetlands. In this paper, we propose a hierarchical classification framework (HCF) that implements two levels of classification scheme to identify different land cover types of coastal wetlands. The first level utilizes the designed decision tree to roughly group land covers into four rough classes and the second level combines multiple features (i.e., spectral feature, texture feature and geometric feature) of each class to distinguish different subtypes of land covers in each rough class. Two groups of classification experiments on Landsat and Sentinel multispectral data and China Gaofen (GF)-5 hyperspectral data are carried out in order to testify the classification behaviors of two famous coastal wetlands of China, that is, Yellow River Estuary and Yancheng coastal wetland. Experimental results on Landsat data show that the proposed HCF performs better than support vector machine and random forest in classifying land covers of coastal wetlands. Moreover, HCF is suitable for both multispectral data and hyperspectral data and the GF-5 data is superior to Landsat-8 and Sentinel-2 multispectral data in obtaining fine classification results of coastal wetlands.
KW  - hierarchical classification framework
KW  - coastal wetlands
KW  - Landsat images
KW  - hyperspectral imagery
KW  - Sentinel-2
KW  - GF-5
DO  - 10.3390/rs11192238
ER  -
TY  - EJOU
AU  - Cui, Lei
AU  - Jiao, Ziti
AU  - Dong, Yadong
AU  - Sun, Mei
AU  - Zhang, Xiaoning
AU  - Yin, Siyang
AU  - Ding, Anxin
AU  - Chang, Yaxuan
AU  - Guo, Jing
AU  - Xie, Rui
TI  - Estimating Forest Canopy Height Using MODIS BRDF Data Emphasizing Typical-Angle Reflectances
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 19
SN  - 2072-4292

AB  - Forest-canopy height is an important parameter for the estimation of forest biomass and terrestrial carbon flux and climate-change research at regional and global scales. Currently, various methods combining Light Detection and Ranging (LiDAR) data with various auxiliary data, particularly satellite remotely sensed reflectances, have been widely used to produce spatially continuous canopy-height products. However, current methods in use for remote sensing reflectances mainly focus on the nadir view direction, while anisotropic reflectances, which are theoretically more sensitive to the forest canopy height in the multiangle remote sensing field, have rarely been explored. Here, we attempted to examine the potential of using modeled multiangle reflectances at three typical viewing angles (i.e., from the hotspot, darkspot, and nadir directions) to estimate forest-canopy height as auxiliary data sources. First, the sensitivities of the typical angular reflectances as a function of forest canopy height were fully examined using the Extended Fourier Amplitude Sensitivity Test (EFAST) method based on the 4-scale Bidirectional Reflectance Distribution Function (BRDF) model simulations. This indicated that reflectances in the off-nadir viewing directions are generally sensitive to canopy-height variations. Then, the canopy heights were extracted from airborne Laser Vegetation Imaging Sensor (LVIS) data, which were further divided into training and validation data. Moderate Resolution Imaging Spectroradiometer (MODIS) multiangle reflectances at typical viewing angles were calculated from the MODIS BRDF parameter product (MCD43A1, version 6) as partial training-input data, based on a hotspot-adjusted, kernel-driven linear BRDF model. Subsequently, the Random Forest (RF) machine learning model was trained to acquire the relationship between the extracted canopy heights and the corresponding MODIS typical viewing reflectances. The trained model was further applied to estimate the canopy height metrics in the study areas of Howland Forest, Harvard Forest, and Bartlett Forest. Finally, the estimated canopy heights were independently validated by canopy heights extracted from the LVIS data. The results indicate that the canopy heights modeled through this method exhibit generally high accordance with the LVIS-derived canopy heights (R = 0.65&minus;0.67; RMSE = 3.63&minus;5.78). The results suggest that the MODIS multiangle reflectance data at typical observation angles contain important information regarding forest canopy height and can, therefore, be used to estimate forest canopy height for various ecological applications.
KW  - multiangular reflectances
KW  - BRDF
KW  - kernel-driven BRDF model
KW  - LVIS
KW  - canopy height
KW  - hotspot effect
KW  - darkspot
KW  - LiDAR
KW  - random forest machine learning model
DO  - 10.3390/rs11192239
ER  -
TY  - EJOU
AU  - Hassler, Samuel C.
AU  - Baysal-Gurel, Fulya
TI  - Unmanned Aircraft System (UAS) Technology and Applications in Agriculture
T2  - Agronomy

PY  - 2019
VL  - 9
IS  - 10
SN  - 2073-4395

AB  - Numerous sensors have been developed over time for precision agriculture; though, only recently have these sensors been incorporated into the new realm of unmanned aircraft systems (UAS). This UAS technology has allowed for a more integrated and optimized approach to various farming tasks such as field mapping, plant stress detection, biomass estimation, weed management, inventory counting, and chemical spraying, among others. These systems can be highly specialized depending on the particular goals of the researcher or farmer, yet many aspects of UAS are similar. All systems require an underlying platform&mdash;or unmanned aerial vehicle (UAV)&mdash;and one or more peripherals and sensing equipment such as imaging devices (RGB, multispectral, hyperspectral, near infra-red, RGB depth), gripping tools, or spraying equipment. Along with these wide-ranging peripherals and sensing equipment comes a great deal of data processing. Common tools to aid in this processing include vegetation indices, point clouds, machine learning models, and statistical methods. With any emerging technology, there are also a few considerations that need to be analyzed like legal constraints, economic trade-offs, and ease of use. This review then concludes with a discussion on the pros and cons of this technology, along with a brief outlook into future areas of research regarding UAS technology in agriculture.
KW  - unmanned aircraft system (UAS)
KW  - unmanned aerial vehicle (UAV)
KW  - precision agriculture
KW  - remote sensing
KW  - aerial imaging
DO  - 10.3390/agronomy9100618
ER  -
TY  - EJOU
AU  - Muñoz, David F.
AU  - Cissell, Jordan R.
AU  - Moftakhari, Hamed
TI  - Adjusting Emergent Herbaceous Wetland Elevation with Object-Based Image Analysis, Random Forest and the 2016 NLCD
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 20
SN  - 2072-4292

AB  - Emergent herbaceous wetlands are characterized by complex salt marsh ecosystems that play a key role in diverse coastal processes including carbon storage, nutrient cycling, flood attenuation and shoreline protection. Surface elevation characterization and spatiotemporal distribution of these ecosystems are commonly obtained from LiDAR measurements as this low-cost airborne technique has a wide range of applicability and usefulness in coastal environments. LiDAR techniques, despite significant advantages, show poor performance in generation of digital elevation models (DEMs) in tidal salt marshes due to large vertical errors. In this study, we present a methodology to (i) update emergent herbaceous wetlands (i.e., the ones delineated in the 2016 National Land Cover Database) to present-day conditions; and (ii) automate salt marsh elevation correction in estuarine systems. We integrate object-based image analysis and random forest technique with surface reflectance Landsat imagery to map three emergent U.S. wetlands in Weeks Bay, Alabama, Savannah Estuary, Georgia and Fire Island, New York. Conducting a hyperparameter tuning of random forest and following a hierarchical approach with three nomenclature levels for land cover classification, we are able to better map wetlands and improve overall accuracies in Weeks Bay (0.91), Savannah Estuary (0.97) and Fire Island (0.95). We then develop a tool in ArcGIS to automate salt marsh elevation correction. We use this ‘DEM-correction’ tool to modify an existing DEM (model input) with the calculated elevation correction over salt marsh regions. Our method and tool are validated with real-time kinematic elevation data and helps correct overestimated salt marsh elevation up to 0.50 m in the studied estuaries. The proposed tool can be easily adapted to different vegetation species in wetlands, and thus help provide accurate DEMs for flood inundation mapping in estuarine systems.
KW  - National Land Cover Database
KW  - object-based image analysis
KW  - random forest
KW  - salt marsh
KW  - Savannah Estuary
KW  - Weeks Bay
KW  - Fire Island
DO  - 10.3390/rs11202346
ER  -
TY  - EJOU
AU  - Yang, Baohua
AU  - Wang, Mengxuan
AU  - Sha, Zhengxia
AU  - Wang, Bing
AU  - Chen, Jianlin
AU  - Yao, Xia
AU  - Cheng, Tao
AU  - Cao, Weixing
AU  - Zhu, Yan
TI  - Evaluation of Aboveground Nitrogen Content of Winter Wheat Using Digital Imagery of Unmanned Aerial Vehicles
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 20
SN  - 1424-8220

AB  - Nitrogen (N) content is an important basis for the precise management of wheat fields. The application of unmanned aerial vehicles (UAVs) in agriculture provides an easier and faster way to monitor nitrogen content. Previous studies have shown that the features acquired from UAVs yield favorable results in monitoring wheat growth. However, since most of them are based on different vegetation indices, it is difficult to meet the requirements of accurate image interpretation. Moreover, resampling also easily ignores the structural features of the image information itself. Therefore, a spectral-spatial feature is proposed combining vegetation indices (VIs) and wavelet features (WFs), especially the acquisition of wavelet features from the UAV image, which was transformed from the spatial domain to the frequency domain with a wavelet transformation. In this way, the complete spatial information of different scales can be obtained to realize good frequency localization, scale transformation, and directional change. The different models based on different features were compared, including partial least squares regression (PLSR), support vector regression (SVR), and particle swarm optimization-SVR (PSO-SVR). The results showed that the accuracy of the model based on the spectral-spatial feature by combining VIs and WFs was higher than that of VIs or WF indices alone. The performance of PSO-SVR was the best (R2 = 0.9025, root mean square error (RMSE) = 0.3287) among the three regression algorithms regardless of the use of all the original features or the combination features. Our results implied that our proposed method could improve the estimation accuracy of aboveground nitrogen content of winter wheat from UAVs with consumer digital cameras, which have greater application potential in predicting other growth parameters.
KW  - unmanned aerial vehicles
KW  - wheat
KW  - nitrogen concentration
KW  - camera
KW  - wavelet feature
DO  - 10.3390/s19204416
ER  -
TY  - EJOU
AU  - Zhang, Dongyan
AU  - Wang, Daoyong
AU  - Gu, Chunyan
AU  - Jin, Ning
AU  - Zhao, Haitao
AU  - Chen, Gao
AU  - Liang, Hongyi
AU  - Liang, Dong
TI  - Using Neural Network to Identify the Severity of Wheat Fusarium Head Blight in the Field Environment
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 20
SN  - 2072-4292

AB  - Fusarium head blight (FHB), one of the most important diseases of wheat, mainly occurs in the ear. Given that the severity of the disease cannot be accurately identified, the cost of pesticide application increases every year, and the agricultural ecological environment is also polluted. In this study, a neural network (NN) method was proposed based on the red-green-blue (RGB) image to segment wheat ear and disease spot in the field environment, and then to determine the disease grade. Firstly, a segmentation dataset of single wheat ear was constructed to provide a benchmark for the segmentation of the wheat ear. Secondly, a segmentation model of single wheat ear based on the fully convolutional network (FCN) was established to effectively realize the segmentation of the wheat ear in the field environment. An FHB segmentation algorithm was proposed based on a pulse-coupled neural network (PCNN) with K-means clustering of the improved artificial bee colony (IABC) to segment the diseased spot of wheat ear by automatic optimization of PCNN parameters. Finally, the disease grade was calculated using the ratio of the disease spot to the whole wheat ear. The experimental results show that: (1) the accuracy of the segmentation model for single wheat ear constructed in this study is 0.981. The segmentation time is less than 1 s, indicating that the model can quickly and accurately segment wheat ear in the field environment; (2) the segmentation method of the disease spot performed under each evaluation indicator is improved compared with the traditional segmentation methods, and the accuracy is 0.925 in the disease severity identification. These research results can provide important reference value for grading wheat FHB in the field environment, which also can be beneficial for real-time monitoring of other crops&rsquo; diseases under near-Earth remote sensing.
KW  - Fusarium head blight
KW  - fully convolutional network
KW  - pulse coupled neural network
KW  - artificial bee colony
KW  - disease grading
DO  - 10.3390/rs11202375
ER  -
TY  - EJOU
AU  - Sun, Hanming
AU  - Duo, Bin
AU  - Wang, Zhengqiang
AU  - Lin, Xiaochen
AU  - Gao, Changchun
TI  - Aerial Cooperative Jamming for Cellular-Enabled UAV Secure Communication Network: Joint Trajectory and Power Control Design
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 20
SN  - 1424-8220

AB  - To improve the secrecy performance of cellular-enabled unmanned aerial vehicle (UAV) communication networks, this paper proposes an aerial cooperative jamming scheme and studies its optimal design to achieve the maximum average secrecy rate. Specifically, a base station (BS) transmits confidential messages to a UAV and meanwhile another UAV performs the role of an aerial jammer by cooperatively sending jamming signals to oppose multiple suspicious eavesdroppers on the ground. As the UAVs have the advantage of the controllable mobility, the objective is to maximize the worst-case average secrecy rate by the joint optimization of the two UAVs&rsquo; trajectories and the BS&rsquo;s/UAV jammer&rsquo;s transmit/jamming power over a given mission period. The objective function of the formulated problem is highly non-linear regarding the optimization variables and the problem has non-convex constraints, which is, in general, difficult to achieve a globally optimal solution. Thus, we divide the original problem into four subproblems and then solve them by applying the successive convex approximation (SCA) and block coordinate descent (BCD) methods. Numerical results demonstrate that the significantly better secrecy performance can be obtained by using the proposed algorithm in comparison with benchmark schemes.
KW  - UAV secure communication
KW  - secrecy rate maximization
KW  - jamming
KW  - trajectory design
KW  - power control
DO  - 10.3390/s19204440
ER  -
TY  - EJOU
AU  - Xia, Lang
AU  - Zhang, Ruirui
AU  - Chen, Liping
AU  - Huang, Yanbo
AU  - Xu, Gang
AU  - Wen, Yao
AU  - Yi, Tongchuan
TI  - Monitor Cotton Budding Using SVM and UAV Images
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 20
SN  - 2076-3417

AB  - Monitoring the cotton budding rate is important for growers so that they can replant cotton in a timely fashion at locations at which cotton density is sparse. In this study, a true-color camera was mounted on an unmanned aerial vehicle (UAV) and used to collect images of young cotton plants to estimate the germination of cotton plants. The collected images were preprocessed by stitching them together to obtain the single orthomosaic image. The support-vector machine method and maximum likelihood classification method were conducted to identify the cotton plants in the image. The accuracy evaluation indicated the overall accuracy of the classification for SVM is 96.65% with the Kappa coefficient of 93.99%, while for maximum likelihood classification, the accuracy is 87.85% with a Kappa coefficient of 80.67%. A method based on the morphological characteristics of cotton plants was proposed to identify and count the overlapping cotton plants in this study. The analysis showed that the method can improve the detection accuracy by 6.3% when compared to without it. The validation based on visual interpretation indicated that the method presented an accuracy of 91.13%. The study showed that the minimal resolution of no less than 1.2 cm/pixel in practice for image collection is necessary in order to recognize cotton plants accurately.
KW  - SVM
KW  - budding rate
KW  - UAV
DO  - 10.3390/app9204312
ER  -
TY  - EJOU
AU  - Lee, Joon Y.
AU  - Chung, Albert Y.
AU  - Shim, Hooyeop
AU  - Joe, Changhwan
AU  - Park, Seongjoon
AU  - Kim, Hwangnam
TI  - UAV Flight and Landing Guidance System for Emergency Situations †
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 20
SN  - 1424-8220

AB  - Unmanned aerial vehicles (UAVs) with high mobility can perform various roles such as delivering goods, collecting information, recording videos and more. However, there are many elements in the city that disturb the flight of the UAVs, such as various obstacles and urban canyons which can cause a multi-path effect of GPS signals, which degrades the accuracy of GPS-based localization. In order to empower the safety of the UAVs flying in urban areas, UAVs should be guided to a safe area even in a GPS-denied or network-disconnected environment. Also, UAVs must be able to avoid obstacles while landing in an urban area. For this purpose, we present the UAV detour system for operating UAV in an urban area. The UAV detour system includes a highly reliable laser guidance system to guide the UAVs to a point where they can land, and optical flow magnitude map to avoid obstacles for a safe landing.
KW  - UAV
KW  - laser guidance
KW  - emergency landing
KW  - particle filter
KW  - optical flow
DO  - 10.3390/s19204468
ER  -
TY  - EJOU
AU  - García Rubio, Víctor
AU  - Rodrigo Ferrán, Juan A.
AU  - Menéndez García, Jose M.
AU  - Sánchez Almodóvar, Nuria
AU  - Lalueza Mayordomo, José M.
AU  - Álvarez, Federico
TI  - Automatic Change Detection System over Unmanned Aerial Vehicle Video Sequences Based on Convolutional Neural Networks
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 20
SN  - 1424-8220

AB  - In recent years, the use of unmanned aerial vehicles (UAVs) for surveillance tasks has increased considerably. This technology provides a versatile and innovative approach to the field. However, the automation of tasks such as object recognition or change detection usually requires image processing techniques. In this paper we present a system for change detection in video sequences acquired by moving cameras. It is based on the combination of image alignment techniques with a deep learning model based on convolutional neural networks (CNNs). This approach covers two important topics. Firstly, the capability of our system to be adaptable to variations in the UAV flight. In particular, the difference of height between flights, and a slight modification of the camera&rsquo;s position or movement of the UAV because of natural conditions such as the effect of wind. These modifications can be produced by multiple factors, such as weather conditions, security requirements or human errors. Secondly, the precision of our model to detect changes in diverse environments, which has been compared with state-of-the-art methods in change detection. This has been measured using the Change Detection 2014 dataset, which provides a selection of labelled images from different scenarios for training change detection algorithms. We have used images from dynamic background, intermittent object motion and bad weather sections. These sections have been selected to test our algorithm&rsquo;s robustness to changes in the background, as in real flight conditions. Our system provides a precise solution for these scenarios, as the mean F-measure score from the image analysis surpasses 97%, and a significant precision in the intermittent object motion category, where the score is above 99%.
KW  - change detection
KW  - convolutional neural networks
KW  - moving camera
KW  - image alignment
KW  - UAV
DO  - 10.3390/s19204484
ER  -
TY  - EJOU
AU  - Freimuth, Henk
AU  - König, Markus
TI  - A Framework for Automated Acquisition and Processing of As-Built Data with Autonomous Unmanned Aerial Vehicles
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 20
SN  - 1424-8220

AB  - Planning and scheduling in construction heavily depend on current information about the state of construction processes. However, the acquisition process for visual data requires human personnel to take photographs of construction objects. We propose using unmanned aerial vehicle (UAVs) for automated creation of images and point cloud data of particular construction objects. The method extracts locations of objects that require inspection from Four Dimensional Building Information Modelling (4D-BIM). With this information at hand viable flight missions around the known structures of the construction site are computed. During flight, the UAV uses stereo cameras to detect and avoid any obstacles that are not known to the model, for example moving humans or machinery. The combination of pre-computed waypoint missions and reactive avoidance ensures deterministic routing from takeoff to landing and operational safety for humans and machines. During flight, an additional software component compares the captured point cloud data with the model data, enabling automatic per-object completion checking or reconstruction. The prototype is developed in the Robot Operating System (ROS) and evaluated in Software-In-The-Loop (SITL) simulations for the sake of being executable on real UAVs.
KW  - as-built
KW  - data acquisition
KW  - BIM
KW  - UAV
KW  - point cloud
KW  - octree
KW  - ROS
KW  - depth camera
KW  - obstacle avoidance
DO  - 10.3390/s19204513
ER  -
TY  - EJOU
AU  - Zhang, Haitao
AU  - Zhou, Ming
AU  - Lan, Xudong
TI  - State of Charge Estimation Algorithm for Unmanned Aerial Vehicle Power-Type Lithium Battery Packs Based on the Extended Kalman Filter
T2  - Energies

PY  - 2019
VL  - 12
IS  - 20
SN  - 1996-1073

AB  - The lack of endurance is an important reason restricting further development of unmanned aerial vehicles (UAVs). Accurately estimating the state of charge (SOC) of the Li-Po battery can maximize the battery energy utilization and improve the endurance of UAVs. In this paper, the main current methods for estimating the SOC of vehicles were explored and discussed to unveil their advantages and disadvantages. In addition, the extended Kalman filter algorithm based on an equivalent circuit model was used to estimate SOC of power-type Li-Po batteries at different temperatures. The result showed that the closed-loop control method can effectively improve the battery life of small-sized electric UAVs.
KW  - unmanned aerial vehicle
KW  - power-type Li-Po battery
KW  - state of charge
KW  - extended Kalman filter algorithm
DO  - 10.3390/en12203960
ER  -
TY  - EJOU
AU  - Woodget, Amy S.
AU  - Dietrich, James T.
AU  - Wilson, Robin T.
TI  - Quantifying Below-Water Fluvial Geomorphic Change: The Implications of Refraction Correction, Water Surface Elevations, and Spatially Variable Error
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 20
SN  - 2072-4292

AB  - Much of the geomorphic work of rivers occurs underwater. As a result, high resolutionquantification of geomorphic change in these submerged areas is important. Currently, to quantify thischange, multiple methods are required to get high resolution data for both the exposed and submergedareas. Remote sensing methods are often limited to the exposed areas due to the challenges imposedby the water, and those remote sensing methods for below the water surface require the collection ofextensive calibration data in-channel, which is time-consuming, labour-intensive, and sometimesprohibitive in dicult-to-access areas. Within this paper, we pioneer a novel approach for quantifyingabove- and below-water geomorphic change using Structure-from-Motion photogrammetry andinvestigate the implications of water surface elevations, refraction correction measures, and thespatial variability of topographic errors. We use two epochs of imagery from a site on the River Teme,Herefordshire, UK, collected using a remotely piloted aircraft system (RPAS) and processed usingStructure-from-Motion (SfM) photogrammetry. For the first time, we show that: (1) Quantification ofsubmerged geomorphic change to levels of accuracy commensurate with exposed areas is possiblewithout the need for calibration data or a dierent method from exposed areas; (2) there is minimaldierence in results produced by dierent refraction correction procedures using predominantlynadir imagery (small angle vs. multi-view), allowing users a choice of software packages/processingcomplexity; (3) improvements to our estimations of water surface elevations are critical for accuratetopographic estimation in submerged areas and can reduce mean elevation error by up to 73%;and (4) we can use machine learning, in the form of multiple linear regressions, and a Gaussian Na&iuml;veBayes classifier, based on the relationship between error and 11 independent variables, to generate ahigh resolution, spatially continuous model of geomorphic change in submerged areas, constrained byspatially variable error estimates. Our multiple regression model is capable of explaining up to 54%of magnitude and direction of topographic error, with accuracies of less than 0.04 m. With on-goingtesting and improvements, this machine learning approach has potential for routine application inspatially variable error estimation within the RPAS&ndash;SfM workflow.
KW  - fluvial
KW  - geomorphology
KW  - change detection
KW  - remotely piloted aircraft system
KW  - refraction correction
KW  - structure-from-motion photogrammetry
KW  - water surface elevation
KW  - topographic error
KW  - machine learning
DO  - 10.3390/rs11202415
ER  -
TY  - EJOU
AU  - Wu, Yi-Nan
AU  - Ma, Yu-Jun
AU  - Liu, Wen-Ling
AU  - Zhang, Wu-Zhao
TI  - Modeling the Spatial Distribution of Plateau Pika (Ochotona curzoniae) in the Qinghai Lake Basin, China
T2  - Animals

PY  - 2019
VL  - 9
IS  - 10
SN  - 2076-2615

AB  - The plateau pika (Ochotona curzoniae) is a keystone species in the alpine rangeland ecosystem of the Qinghai&ndash;Tibetan Plateau. Most previous studies of habitat selection by plateau pika have been conducted at a local microhabitat scale; however, little is known about the relationship between the distribution of plateau pika and macrohabitat factors at broad spatial scales. Using a presence-only ecological niche model (maximum entropy, Maxent), we predicted the distribution of plateau pika in the Qinghai Lake basin based on a set of environmental and anthropogenic variables at 1-km spatial resolution, and identified key macrohabitat factors that contribute to the predictive performance. Our results showed suitable area for plateau pika in the Qinghai Lake basin being approximately 3982 km2, which is 15.8% of the land area in the whole watershed. The distance to road emerged as the most important predictor of the distribution patterns of plateau pika, while the soil type was of ancillary importance. Mean air temperature of wettest quarter, distance to resident site and altitude also produced high gains in defining plateau pika&rsquo;s distribution. A higher predictive accuracy was achieved by the model that combined environmental and anthropogenic variables. With the constraint of human factors, the presence probability of plateau pika in about 1661 km2 will increase. These findings demonstrate the impact of human activities on the distribution of plateau pika, and the importance of vegetation reservation for plateau pika control.
KW  - spatial distribution
KW  - environmental variable
KW  - anthropogenic variable
KW  - plateau pika
KW  - maxent
DO  - 10.3390/ani9100843
ER  -
TY  - EJOU
AU  - Pasqualotto, Nieves
AU  - D’Urso, Guido
AU  - Bolognesi, Salvatore F.
AU  - Belfiore, Oscar R.
AU  - Van Wittenberghe, Shari
AU  - Delegido, Jesús
AU  - Pezzola, Alejandro
AU  - Winschel, Cristina
AU  - Moreno, José
TI  - Retrieval of Evapotranspiration from Sentinel-2: Comparison of Vegetation Indices, Semi-Empirical Models and SNAP Biophysical Processor Approach
T2  - Agronomy

PY  - 2019
VL  - 9
IS  - 10
SN  - 2073-4395

AB  - Remote sensing evapotranspiration estimation over agricultural areas is increasingly used for irrigation management during the crop growing cycle. Different methodologies based on remote sensing have emerged for the leaf area index (LAI) and the canopy chlorophyll content (CCC) estimation, essential biophysical parameters for crop evapotranspiration monitoring. Using Sentinel-2 (S2) spectral information, this study performed a comparative analysis of empirical (vegetation indices), semi-empirical (CLAIR model with fixed and calibrated extinction coefficient) and artificial neural network S2 products derived from the Sentinel Application Platform Software (SNAP) biophysical processor (ANN S2 products) approaches for the estimation of LAI and CCC. Four independent in situ collected datasets of LAI and CCC, obtained with standard instruments (LAI-2000, SPAD) and a smartphone application (PocketLAI), were used. The ANN S2 products present good statistics for LAI (R2 &gt; 0.70, root mean square error (RMSE) &lt; 0.86) and CCC (R2 &gt; 0.75, RMSE &lt; 0.68 g/m2) retrievals. The normalized Sentinel-2 LAI index (SeLI) is the index that presents good statistics in each dataset (R2 &gt; 0.71, RMSE &lt; 0.78) and for the CCC, the ratio red-edge chlorophyll index (CIred-edge) (R2 &gt; 0.67, RMSE &lt; 0.62 g/m2). Both indices use bands located in the red-edge zone, highlighting the importance of this region. The LAI CLAIR model with a fixed extinction coefficient value produces a R2 &gt; 0.63 and a RMSE &lt; 1.47 and calibrating this coefficient for each study area only improves the statistics in two areas (RMSE &asymp; 0.70). Finally, this study analyzed the influence of the LAI parameter estimated with the different methodologies in the calculation of crop potential evapotranspiration (ETc) with the adapted Penman&ndash;Monteith (FAO-56 PM), using a multi-temporal dataset. The results were compared with ETc estimated as the product of the reference evapotranspiration (ETo) and on the crop coefficient (Kc) derived from FAO table values. In the absence of independent reference ET data, the estimated ETc with the LAI in situ values were considered as the proxy of the ground-truth. ETc estimated with the ANN S2 LAI product is the closest to the ETc values calculated with the LAI in situ (R2 &gt; 0.90, RMSE &lt; 0.41 mm/d). Our findings indicate the good validation of ANN S2 LAI and CCC products and their further suitability for the implementation in evapotranspiration retrieval of agricultural areas.
KW  - evapotranspiration in standard condition
KW  - leaf area index
KW  - canopy chlorophyll content
KW  - Sentinel-2
KW  - vegetation indices
KW  - artificial neural network
DO  - 10.3390/agronomy9100663
ER  -
TY  - EJOU
AU  - He, Zhi
AU  - He, Dan
AU  - Mei, Xiangqin
AU  - Hu, Saihan
TI  - Wetland Classification Based on a New Efficient Generative Adversarial Network and Jilin-1 Satellite Image
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 20
SN  - 2072-4292

AB  - Recent studies have shown that deep learning methods provide useful tools for wetland classification. However, it is difficult to perform species-level classification with limited labeled samples. In this paper, we propose a semi-supervised method for wetland species classification by using a new efficient generative adversarial network (GAN) and Jilin-1 satellite image. The main contributions of this paper are twofold. First, the proposed method, namely ShuffleGAN, requires only a small number of labeled samples. ShuffleGAN is composed of two neural networks (i.e., generator and discriminator), which perform an adversarial game in the training phase and ShuffleNet units are added in both generator and discriminator to obtain speed-accuracy tradeoff. Second, ShuffleGAN can perform species-level wetland classification. In addition to distinguishing the wetland areas from non-wetlands, different tree species located in the wetland are also identified, thus providing a more detailed distribution of the wetland land-covers. Experiments are conducted on the Haizhu Lake wetland data acquired by the Jilin-1 satellite. Compared with existing GAN, the improvement in overall accuracy (OA) of the proposed ShuffleGAN is more than 2%. This work can not only deepen the application of deep learning in wetland classification but also promote the study of fine classification of wetland land-covers.
KW  - wetland
KW  - classification
KW  - remote sensing
KW  - deep learning
KW  - generative adversarial networks
DO  - 10.3390/rs11202455
ER  -
TY  - EJOU
AU  - Zhu, Wanxue
AU  - Sun, Zhigang
AU  - Huang, Yaohuan
AU  - Lai, Jianbin
AU  - Li, Jing
AU  - Zhang, Junqiang
AU  - Yang, Bin
AU  - Li, Binbin
AU  - Li, Shiji
AU  - Zhu, Kangying
AU  - Li, Yang
AU  - Liao, Xiaohan
TI  - Improving Field-Scale Wheat LAI Retrieval Based on UAV Remote-Sensing Observations and Optimized VI-LUTs
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 20
SN  - 2072-4292

AB  - Leaf area index (LAI) is a key biophysical parameter for monitoring crop growth status, predicting crop yield, and quantifying crop variability in agronomic applications. Mapping the LAI at the field scale using multispectral cameras onboard unmanned aerial vehicles (UAVs) is a promising precision-agriculture application with specific requirements: The LAI retrieval method should be (1) robust so that crop LAI can be estimated with similar accuracy and (2) easy to use so that it can be applied to the adjustment of field management practices. In this study, three UAV remote-sensing missions (UAVs with Micasense RedEdge-M and Cubert S185 cameras) were carried out over six experimental plots from 2018 to 2019 to investigate the performance of reflectance-based lookup tables (LUTs) and vegetation index (VI)-based LUTs generated from the PROSAIL model for wheat LAI retrieval. The effects of the central wavelengths and bandwidths for the VI calculations on the LAI retrieval were further examined. We found that the VI-LUT strategy was more robust and accurate than the reflectance-LUT strategy. The differences in the LAI retrieval accuracy among the four VI-LUTs were small, although the improved modified chlorophyll absorption ratio index-lookup table (MCARI2-LUT) and normalized difference vegetation index-lookup table (NDVI-LUT) performed slightly better. We also found that both of the central wavelengths and bandwidths of the VIs had effects on the LAI retrieval. The VI-LUTs with optimized central wavelengths (red = 612 nm, near-infrared (NIR) = 756 nm) and narrow bandwidths (~4 nm) improved the wheat LAI retrieval accuracy (R2 &ge; 0.75). The results of this study provide an alternative method for retrieving crop LAI, which is robust and easy use for precision-agriculture applications and may be helpful for designing UAV multispectral cameras for agricultural monitoring.
KW  - leaf area index
KW  - unmanned aerial vehicle
KW  - vegetation indices
KW  - multispectral camera
KW  - hyperspectral camera
KW  - precision agriculture
DO  - 10.3390/rs11202456
ER  -
TY  - EJOU
AU  - Li, Huiying
AU  - Jia, Mingming
AU  - Zhang, Rong
AU  - Ren, Yongxing
AU  - Wen, Xin
TI  - Incorporating the Plant Phenological Trajectory into Mangrove Species Mapping with Dense Time Series Sentinel-2 Imagery and the Google Earth Engine Platform
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 21
SN  - 2072-4292

AB  - Information on mangrove species composition and distribution is key to studying functions of mangrove ecosystems and securing sustainable mangrove conservation. Even though remote sensing technology is developing rapidly currently, mapping mangrove forests at the species level based on freely accessible images is still a great challenge. This study built a Sentinel-2 normalized difference vegetation index (NDVI) time series (from 2017-01-01 to 2018-12-31) to represent phenological trajectories of mangrove species and then demonstrated the feasibility of phenology-based mangrove species classification using the random forest algorithm in the Google Earth Engine platform. It was found that (i) in Zhangjiang estuary, the phenological trajectories (NDVI time series) of different mangrove species have great differences; (ii) the overall accuracy and Kappa confidence of the classification map is 84% and 0.84, respectively; and (iii) Months in late winter and early spring play critical roles in mangrove species mapping. This is the first study to use phonological signatures in discriminating mangrove species. The methodology presented can be used as a practical guideline for the mapping of mangrove or other vegetation species in other regions. However, future work should pay attention to various phenological trajectories of mangrove species in different locations.
KW  - phenology
KW  - species mapping
KW  - coastal wetlands
KW  - Zhangjiang estuary
KW  - Spartina alterniflora
DO  - 10.3390/rs11212479
ER  -
TY  - EJOU
AU  - Gebremedhin, Alem
AU  - Badenhorst, Pieter
AU  - Wang, Junping
AU  - Giri, Khageswor
AU  - Spangenberg, German
AU  - Smith, Kevin
TI  - Development and Validation of a Model to Combine NDVI and Plant Height for High-Throughput Phenotyping of Herbage Yield in a Perennial Ryegrass Breeding Program
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 21
SN  - 2072-4292

AB  - Sensor-based phenotyping technologies may offer a non-destructive, high-throughput and efficient assessment of herbage yield (HY) to replace current inefficient phenotyping methods. This paper assesses the feasibility of combining normalised difference vegetative index (NDVI) from multispectral imaging and ultrasonic sonar estimates of plant height to estimate HY of single plants in a large perennial ryegrass breeding program. For sensor calibration, fresh HY (FHY) and dry HY (DHY) were acquired destructively, and plant height was measured at four dates each in 2017 and 2018 from a selected subset of 480 plants. Global multiple linear regression models based on K-fold and random split cross-validation methods were used to evaluate the relationship between observed vs. predicted HY. The coefficient of determination (R2) = 0.67&ndash;0.68 and a root mean square error (RMSE) between 5.43&ndash;7.60 g was obtained for the validation of predicted vs. observed DHY. The mean absolute error (MAE) and mean percentage error (MPE) ranged between 3.59&ndash;5.44 g and 22&ndash;28%, respectively. For the FHY, R2 values ranged from 0.63 to 0.70, with an RMSE between 23.50 and 33 g, MAE between 15.11 and 24.34 g and MPE between ~22% and 31%. Combining NDVI and plant height is a robust method to enable high-throughput phenotyping of herbage yield in perennial ryegrass breeding programs.
KW  - multispectral imaging
KW  - herbage yield
KW  - high-throughput phenotyping
KW  - NDVI
KW  - plant height
KW  - ultrasonic sonar
DO  - 10.3390/rs11212494
ER  -
TY  - EJOU
AU  - Bohnenkamp, David
AU  - Behmann, Jan
AU  - Mahlein, Anne-Katrin
TI  - In-Field Detection of Yellow Rust in Wheat on the Ground Canopy and UAV Scale
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 21
SN  - 2072-4292

AB  - The application of hyperspectral imaging technology for plant disease detection in the field is still challenging. Existing equipment and analysis algorithms are adapted to highly controlled environmental conditions in the laboratory. However, only real time information from the field scale is able to guide plant protection measures and to optimize the use of resources. At the field scale, many parameters such as the optimal measurement distance, informative feature sets, and suitable algorithms have not been investigated. In this study, the hyperspectral detection and quantification of yellow rust in wheat was evaluated using two measurement platforms: a ground-based vehicle and an unmanned aerial vehicle (UAV). Different disease development stages and disease severities were provided in a plot-based field experiment. Measurements were performed weekly during the vegetation period. Data analysis was performed by three prediction algorithms with a focus on the selection of optimal feature sets. In this context, the across-scale application of optimized feature sets, an approach of information transfer between scales, was also evaluated. Relevant aspects for an on-line disease assessment in the field integrating affordable sensor technology, sensor spatial resolution, compact analysis models, and fast evaluation have been outlined and reflected upon. For the first time, a hyperspectral imaging observation experiment of a plant disease was comparatively performed at two scales, ground canopy and UAV.
KW  - feature selection
KW  - spectral angle mapper
KW  - support vector machine
KW  - support vector regression
KW  - hyperspectral imaging
KW  - UAV
KW  - cross-scale
KW  - yellow rust
KW  - spatial resolution
KW  - winter wheat
DO  - 10.3390/rs11212495
ER  -
TY  - EJOU
AU  - Xin, Jiang
AU  - Zhang, Xinchang
AU  - Zhang, Zhiqiang
AU  - Fang, Wu
TI  - Road Extraction of High-Resolution Remote Sensing Images Derived from DenseUNet
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 21
SN  - 2072-4292

AB  - Road network extraction is one of the significant assignments for disaster emergency response, intelligent transportation systems, and real-time updating road network. Road extraction base on high-resolution remote sensing images has become a hot topic. Presently, most of the researches are based on traditional machine learning algorithms, which are complex and computational because of impervious surfaces such as roads and buildings that are discernible in the images. Given the above problems, we propose a new method to extract the road network from remote sensing images using a DenseUNet model with few parameters and robust characteristics. DenseUNet consists of dense connection units and skips connections, which strengthens the fusion of different scales by connections at various network layers. The performance of the advanced method is validated on two datasets of high-resolution images by comparison with three classical semantic segmentation methods. The experimental results show that the method can be used for road extraction in complex scenes.
KW  - high-resolution remote sensing imagery
KW  - multi-scale
KW  - road extraction
KW  - machine learning
KW  - DenseUNet
DO  - 10.3390/rs11212499
ER  -
TY  - EJOU
AU  - Pagay, Vinay
AU  - Kidman, Catherine M.
TI  - Evaluating Remotely-Sensed Grapevine (Vitis vinifera L.) Water Stress Responses Across a Viticultural Region
T2  - Agronomy

PY  - 2019
VL  - 9
IS  - 11
SN  - 2073-4395

AB  - The evolving spatial and temporal knowledge about vineyard performance through the use of remote sensing offers new perspectives for vine water status studies. This paper describes the application of aerial thermal imaging to evaluate vine water status to improve irrigation scheduling decisions, water use efficiency, and overall winegrape quality in the Coonawarra viticultural region of South Australia. Airborne infrared images were acquired during the 2016 and 2017 growing seasons in the region of Coonawarra, South Australia. Several thermal indices of crop water status (CWSI, Ig, (Tc-Ta)) were calculated that correlated with conventional soil and vine water status measures (&Psi;pd, &Psi;s, gs). CWSI and Ig could discriminate between the two cultivars used in this study, Cabernet Sauvignon (CAS) and Shiraz (SHI), as did the conventional water stress measures. The relationship between conventional vine water status measures appeared stronger with CWSI in the warmer and drier season (2016) compared to the cooler and wetter season (2017), where Ig and (Tc-Ta) showed stronger correlations. The study identified CWSI, Ig and (Tc-Ta) to be reliable indicators of vine water status under a variety of environmental conditions. This is the first study to report on high resolution vine water status at a regional scale in Australia using a combination of remote and direct sensing methods. This methodology is promising for aerial surveillance of vine water status across multiple blocks and cultivars to inform irrigation scheduling.
KW  - thermal imagery
KW  - stomatal conductance
KW  - water potential
KW  - grapevine
KW  - variability
KW  - precision viticulture
DO  - 10.3390/agronomy9110682
ER  -
TY  - EJOU
AU  - Kerle, Norman
AU  - Ghaffarian, Saman
AU  - Nawrotzki, Raphael
AU  - Leppert, Gerald
AU  - Lech, Malte
TI  - Evaluating Resilience-Centered Development Interventions with Remote Sensing
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 21
SN  - 2072-4292

AB  - Natural disasters are projected to increase in number and severity, in part due to climate change. At the same time a growing number of disaster risk reduction (DRR) and climate change adaptation measures are being implemented by governmental and non-governmental organizations, and substantial post-disaster donations are frequently pledged. At the same time there has been increasing demand for transparency and accountability, and thus evidence of those measures having a positive effect. We hypothesized that resilience-enhancing interventions should result in less damage during a hazard event, or at least quicker recovery. In this study we assessed recovery over a 3 year period of seven municipalities in the central Philippines devastated by Typhoon Haiyan in 2013. We used very high resolution optical images (&lt;1 m), and created detailed land cover and land use maps for four epochs before and after the event, using a machine learning approach with extreme gradient boosting. The spatially and temporally highly variable recovery maps were then statistically related to detailed questionnaire data acquired by DEval in 2012 and 2016, whose principal aim was to assess the impact of a 10 year land-planning intervention program by the German agency for technical cooperation (GIZ). The survey data allowed very detailed insights into DRR-related perspectives, motivations and drivers of the affected population. To some extent they also helped to overcome the principal limitation of remote sensing, which can effectively describe but not explain the reasons for differential recovery. However, while a number of causal links between intervention parameters and reconstruction was found, the common notion that a resilient community should recover better and more quickly could not be confirmed. The study also revealed a number of methodological limitations, such as the high cost for commercial image data not matching the spatially extensive but also detailed scale of field evaluations, the remote sensing analysis likely overestimating damage and thus providing incorrect recovery metrics, and image data catalogues especially for more remote communities often being incomplete. Nevertheless, the study provides a valuable proof of concept for the synergies resulting from an integration of socio-economic survey data and remote sensing imagery for recovery assessment.
KW  - disaster
KW  - resilience
KW  - impact
KW  - evaluation
KW  - Philippines
KW  - Haiyan
KW  - machine learning
KW  - gradient boosting
KW  - land use planning
KW  - German development cooperation
DO  - 10.3390/rs11212511
ER  -
TY  - EJOU
AU  - Chuang, Hsiu-Min
AU  - He, Dongqing
AU  - Namiki, Akio
TI  - Autonomous Target Tracking of UAV Using High-Speed Visual Feedback
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 21
SN  - 2076-3417

AB  - Most current unmanned aerial vehicles (UAVs) primarily use a global positioning system (GPS) and an inertial measurement unit (IMU) for position estimation. However, compared to birds and insects, the abilities of current UAVs to recognize the environment are not sufficient. To achieve autonomous flight of UAVs, like birds, the UAVs should be able to process and respond to information from their surrounding environment immediately. Therefore, in this paper, we propose a direct visual servoing system for UAVs, using an onboard high-speed monocular camera. There are two advantages of this system. First, the high image sampling rates help to improve the ability to recognize the environment. Second, the issue of control latency can be effectively solved because the position control signals are transmitted to the flight controller directly. In the experiment, the UAV could recognize a target at update rates of about 350 Hz, and a target tracking task was successfully realized.
KW  - UAV
KW  - high-speed vision
KW  - visual servoing
DO  - 10.3390/app9214552
ER  -
TY  - EJOU
AU  - Xia, Wei
AU  - Ma, Caihong
AU  - Liu, Jianbo
AU  - Liu, Shibin
AU  - Chen, Fu
AU  - Yang, Zhi
AU  - Duan, Jianbo
TI  - High-Resolution Remote Sensing Imagery Classification of Imbalanced Data Using Multistage Sampling Method and Deep Neural Networks
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 21
SN  - 2072-4292

AB  - Class imbalance is a key issue for the application of deep learning for remote sensing image classification because a model generated by imbalanced samples training has low classification accuracy for minority classes. In this study, an accurate classification approach using the multistage sampling method and deep neural networks was proposed to classify imbalanced data. We first balance samples by multistage sampling to obtain the training sets. Then, a state-of-the-art model is adopted by combining the advantages of atrous spatial pyramid pooling (ASPP) and Encoder-Decoder for pixel-wise classification, which are two different types of fully convolutional networks (FCNs) that can obtain contextual information of multiple levels in the Encoder stage. The details and spatial dimensions of targets are restored using such information during the Decoder stage. We employ four deep learning-based classification algorithms (basic FCN, FCN-8S, ASPP, and Encoder-Decoder with ASPP of our approach) on multistage training sets (original, MUS1, and MUS2) of WorldView-3 images in southeastern Qinghai-Tibet Plateau and GF-2 images in northeastern Beijing for comparison. The experiments show that, compared with existing sets (original, MUS1, and identical) and existing method (cost weighting), the MUS2 training set of multistage sampling significantly enhance the classification performance for minority classes. Our approach shows distinct advantages for imbalanced data.
KW  - high-resolution remote sensing image
KW  - classification
KW  - deep learning
KW  - imbalanced data
KW  - multistage sampling
KW  - ASPP
KW  - encoder-decoder
DO  - 10.3390/rs11212523
ER  -
TY  - EJOU
AU  - Otsu, Kaori
AU  - Pla, Magda
AU  - Duane, Andrea
AU  - Cardil, Adrián
AU  - Brotons, Lluís
TI  - Estimating the Threshold of Detection on Tree Crown Defoliation Using Vegetation Indices from UAS Multispectral Imagery
T2  - Drones

PY  - 2019
VL  - 3
IS  - 4
SN  - 2504-446X

AB  - Periodical outbreaks of Thaumetopoea pityocampa feeding on pine needles may pose a threat to Mediterranean coniferous forests by causing severe tree defoliation, growth reduction, and eventually mortality. To cost&ndash;effectively monitor the temporal and spatial damages in pine&ndash;oak mixed stands using unmanned aerial systems (UASs) for multispectral imagery, we aimed at developing a simple thresholding classification tool for forest practitioners as an alternative method to complex classifiers such as Random Forest. The UAS flights were performed during winter 2017&ndash;2018 over four study areas in Catalonia, northeastern Spain. To detect defoliation and further distinguish pine species, we conducted nested histogram thresholding analyses with four UAS-derived vegetation indices (VIs) and evaluated classification accuracy. The normalized difference vegetation index (NDVI) and NDVI red edge performed the best for detecting defoliation with an overall accuracy of 95% in the total study area. For discriminating pine species, accuracy results of 93&ndash;96% were only achievable with green NDVI in the partial study area, where the Random Forest classification combined for defoliation and tree species resulted in 91&ndash;93%. Finally, we achieved to estimate the average thresholds of VIs for detecting defoliation over the total area, which may be applicable across similar Mediterranean pine stands for monitoring regional forest health on a large scale.
KW  - unmanned aerial systems (UAS)
KW  - multispectral imagery
KW  - forest defoliation
KW  - Thaumetopoea pityocampa
KW  - vegetation index
KW  - thresholding analysis
DO  - 10.3390/drones3040080
ER  -
TY  - EJOU
AU  - Jensen, Daniel
AU  - Cavanaugh, Kyle C.
AU  - Simard, Marc
AU  - Okin, Gregory S.
AU  - Castañeda-Moya, Edward
AU  - McCall, Annabeth
AU  - Twilley, Robert R.
TI  - Integrating Imaging Spectrometer and Synthetic Aperture Radar Data for Estimating Wetland Vegetation Aboveground Biomass in Coastal Louisiana
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 21
SN  - 2072-4292

AB  - Aboveground biomass (AGB) plays a critical functional role in coastal wetland ecosystem stability, with high biomass vegetation contributing to organic matter production, sediment accretion potential, and the surface elevation&rsquo;s ability to keep pace with relative sea level rise. Many remote sensing studies have employed either imaging spectrometer or synthetic aperture radar (SAR) for AGB estimation in various environments for assessing ecosystem health and carbon storage. This study leverages airborne data from NASA&rsquo;s Airborne Visible/Infrared Imaging Spectrometer-Next Generation (AVIRIS-NG) and Uninhabited Aerial Vehicle Synthetic Aperture Radar (UAVSAR) to assess their unique capabilities in combination to estimate AGB in coastal deltaic wetlands. Here we develop AGB models for emergent herbaceous and forested wetland vegetation in coastal Louisiana. In addition to horizontally emitted, vertically received (HV) backscatter, SAR parameters are expressed by the Freeman&ndash;Durden polarimetric decomposition components representing volume and double-bounce scattering. The imaging spectrometer parameters include normalized difference vegetation index (NDVI), reflectance from 290 visible-shortwave infrared (VSWIR) bands, the first derivatives from those bands, or partial least squares (PLS) x-scores derived from those data. Model metrics and cross-validation indicate that the integrated models using the Freeman-Durden components and PLS x-scores improve AGB estimates for both wetland vegetation types. In our study domain over Louisiana&rsquo;s Wax Lake Delta (WLD), we estimated a mean herbaceous wetland AGB of 3.58 Megagrams/hectare (Mg/ha) and a total of 3551.31 Mg over 9.92 km2, and a mean forested wetland AGB of 294.78 Mg/ha and a total of 27,499.14 Mg over 0.93 km2. While the addition of SAR-derived values to imaging spectrometer data provides a nominal error decrease for herbaceous wetland AGB, this combination significantly improves forested wetland AGB prediction. This integrative approach is particularly effective in forested wetlands as canopy-level biochemical characteristics are captured by the imaging spectrometer in addition to the variable structural information measured by the SAR.
KW  - aboveground biomass
KW  - deltaic wetlands
KW  - coastal Louisiana
KW  - imaging spectroscopy
KW  - hyperspectral
KW  - synthetic aperture radar (SAR)
KW  - remote sensing
KW  - data integration
KW  - airborne visible/infrared imaging spectrometer—next generation (AVIRIS-NG)
KW  - uninhabited aerial vehicle synthetic aperture radar (UAVSAR)
KW  - blue carbon
DO  - 10.3390/rs11212533
ER  -
TY  - EJOU
AU  - Barreto, M. Alejandra P.
AU  - Johansen, Kasper
AU  - Angel, Yoseline
AU  - McCabe, Matthew F.
TI  - Radiometric Assessment of a UAV-Based Push-Broom Hyperspectral Camera
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 21
SN  - 1424-8220

AB  - The use of unmanned aerial vehicles (UAVs) for Earth and environmental sensing has increased significantly in recent years. This is particularly true for multi- and hyperspectral sensing, with a variety of both push-broom and snap-shot systems becoming available. However, information on their radiometric performance and stability over time is often lacking. The authors propose the use of a general protocol for sensor evaluation to characterize the data retrieval and radiometric performance of push-broom hyperspectral cameras, and illustrate the workflow with the Nano-Hyperspec (Headwall Photonics, Boston USA) sensor. The objectives of this analysis were to: (1) assess dark current and white reference consistency, both temporally and spatially; (2) evaluate spectral fidelity; and (3) determine the relationship between sensor-recorded radiance and spectroradiometer-derived reflectance. Both the laboratory-based dark current and white reference evaluations showed an insignificant increase over time (&lt;2%) across spatial pixels and spectral bands for &gt;99.5% of pixel–waveband combinations. Using a mercury/argon (Hg/Ar) lamp, the hyperspectral wavelength bands exhibited a slight shift of 1-3 nm against 29 Hg/Ar wavelength emission lines. The relationship between the Nano-Hyperspec radiance values and spectroradiometer-derived reflectance was found to be highly linear for all spectral bands. The developed protocol for assessing UAV-based radiometric performance of hyperspectral push-broom sensors showed that the Nano-Hyperspec data were both time-stable and spectrally sound.
KW  - hyperspectral
KW  - radiometric
KW  - UAV
KW  - remote sensing
KW  - Headwall Nano-Hyperspec
KW  - spectroradiometer
DO  - 10.3390/s19214699
ER  -
TY  - EJOU
AU  - Liu, Yuxuan
AU  - Aleksandrov, Mitko
AU  - Zlatanova, Sisi
AU  - Zhang, Junjun
AU  - Mo, Fan
AU  - Chen, Xiaojian
TI  - Classification of Power Facility Point Clouds from Unmanned Aerial Vehicles Based on Adaboost and Topological Constraints
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 21
SN  - 1424-8220

AB  - Machine learning algorithms can be well suited to LiDAR point cloud classification, but when they are applied to the point cloud classification of power facilities, many problems such as a large number of computational features and low computational efficiency can be encountered. To solve these problems, this paper proposes the use of the Adaboost algorithm and different topological constraints. For different objects, the top five features with the best discrimination are selected and combined into a strong classifier by the Adaboost algorithm, where coarse classification is performed. For power transmission lines, the optimum scales are selected automatically, and the coarse classification results are refined. For power towers, it is difficult to distinguish the tower from vegetation points by only using spatial features due to the similarity of their proposed key features. Therefore, the topological relationship between the power line and power tower is introduced to distinguish the power tower from vegetation points. The experimental results show that the classification of power transmission lines and power towers by our method can achieve the accuracy of manual classification results and even be more efficient.
KW  - point cloud classification
KW  - power line
KW  - power tower
KW  - the Adaboost algorithm
KW  - topological constraint
DO  - 10.3390/s19214717
ER  -
TY  - EJOU
AU  - Buters, Todd M.
AU  - Belton, David
AU  - Cross, Adam T.
TI  - Multi-Sensor UAV Tracking of Individual Seedlings and Seedling Communities at Millimetre Accuracy
T2  - Drones

PY  - 2019
VL  - 3
IS  - 4
SN  - 2504-446X

AB  - The increasing spatial and temporal scales of ecological recovery projects demand more rapid and accurate methods of predicting restoration trajectory. Unmanned aerial vehicles (UAVs) offer greatly improved rapidity and efficiency compared to traditional biodiversity monitoring surveys and are increasingly employed in the monitoring of ecological restoration. However, the applicability of UAV-based remote sensing in the identification of small features of interest from captured imagery (e.g., small individual plants, &lt;100 cm2) remains untested and the potential of UAVs to track the performance of individual plants or the development of seedlings remains unexplored. This study utilised low-altitude UAV imagery from multi-sensor flights (Red-Green-Blue and multispectral sensors) and an automated object-based image analysis software to detect target seedlings from among a matrix of non-target grasses in order to track the performance of individual target seedlings and the seedling community over a 14-week period. Object-based Image Analysis (OBIA) classification effectively and accurately discriminated among target and non-target seedling objects and these groups exhibited distinct spectral signatures (six different visible-spectrum and multispectral indices) that responded differently over a 24-day drying period. OBIA classification from captured imagery also allowed for the accurate tracking of individual target seedling objects through time, clearly illustrating the capacity of UAV-based monitoring to undertake plant performance monitoring of individual plants at very fine spatial scales.
KW  - drones
KW  - multispectral
KW  - ecological restoration
KW  - rehabilitation
KW  - Object-based image analysis
DO  - 10.3390/drones3040081
ER  -
TY  - EJOU
AU  - Gong, Chizhang
AU  - Buddenbaum, Henning
AU  - Retzlaff, Rebecca
AU  - Udelhoven, Thomas
TI  - An Empirical Assessment of Angular Dependency for RedEdge-M in Sloped Terrain Viticulture
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 21
SN  - 2072-4292

AB  - For grape canopy pixels captured by an unmanned aerial vehicle (UAV) tilt-mounted RedEdge-M multispectral sensor in a sloped vineyard, an in situ Walthall model can be established with purely image-based methods. This was derived from RedEdge-M directional reflectance and a vineyard 3D surface model generated from the same imagery. The model was used to correct the angular effects in the reflectance images to form normalized difference vegetation index (NDVI) orthomosaics of different view angles. The results showed that the effect could be corrected to a certain scope, but not completely. There are three drawbacks that might restrict a successful angular model construction and correction: (1) the observable micro shadow variation on the canopy enabled by the high resolution; (2) the complexity of vine canopies that causes an inconsistency between reflectance and canopy geometry, including effects such as micro shadows and near-infrared (NIR) additive effects; and (3) the resolution limit of a 3D model to represent the accurate real-world optical geometry. The conclusion is that grape canopies might be too inhomogeneous for the tested method to perform the angular correction in high quality.
KW  - viticulture
KW  - multispectral
KW  - UAV
KW  - BRDF
KW  - geometric
DO  - 10.3390/rs11212561
ER  -
TY  - EJOU
AU  - Tavakkoli Piralilou, Sepideh
AU  - Shahabi, Hejar
AU  - Jarihani, Ben
AU  - Ghorbanzadeh, Omid
AU  - Blaschke, Thomas
AU  - Gholamnia, Khalil
AU  - Meena, Sansar R.
AU  - Aryal, Jagannath
TI  - Landslide Detection Using Multi-Scale Image Segmentation and Different Machine Learning Models in the Higher Himalayas
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 21
SN  - 2072-4292

AB  - Landslides represent a severe hazard in many areas of the world. Accurate landslide maps are needed to document the occurrence and extent of landslides and to investigate their distribution, types, and the pattern of slope failures. Landslide maps are also crucial for determining landslide susceptibility and risk. Satellite data have been widely used for such investigations—next to data from airborne or unmanned aerial vehicle (UAV)-borne campaigns and Digital Elevation Models (DEMs). We have developed a methodology that incorporates object-based image analysis (OBIA) with three machine learning (ML) methods, namely, the multilayer perceptron neural network (MLP-NN) and random forest (RF), for landslide detection. We identified the optimal scale parameters (SP) and used them for multi-scale segmentation and further analysis. We evaluated the resulting objects using the object pureness index (OPI), object matching index (OMI), and object fitness index (OFI) measures. We then applied two different methods to optimize the landslide detection task: (a) an ensemble method of stacking that combines the different ML methods for improving the performance, and (b) Dempster–Shafer theory (DST), to combine the multi-scale segmentation and classification results. Through the combination of three ML methods and the multi-scale approach, the framework enhanced landslide detection when it was tested for detecting earthquake-triggered landslides in Rasuwa district, Nepal. PlanetScope optical satellite images and a DEM were used, along with the derived landslide conditioning factors. Different accuracy assessment measures were used to compare the results against a field-based landslide inventory. All ML methods yielded the highest overall accuracies ranging from 83.3% to 87.2% when using objects with the optimal SP compared to other SPs. However, applying DST to combine the multi-scale results of each ML method significantly increased the overall accuracies to almost 90%. Overall, the integration of OBIA with ML methods resulted in appropriate landslide detections, but using the optimal SP and ML method is crucial for success.
KW  - landslide mapping
KW  - object-based image analysis (OBIA)
KW  - scale parameter (SP)
KW  - Dempster–Shafer theory (DST)
KW  - Planetscope
DO  - 10.3390/rs11212575
ER  -
TY  - EJOU
AU  - Mangewa, Lazaro J.
AU  - Ndakidemi, Patrick A.
AU  - Munishi, Linus K.
TI  - Integrating UAV Technology in an Ecological Monitoring System for Community Wildlife Management Areas in Tanzania
T2  - Sustainability

PY  - 2019
VL  - 11
IS  - 21
SN  - 2071-1050

AB  - Unmanned aerial vehicles (UAV) have recently emerged as a new remote sensing aerial platform, and they are seemingly advancing real-time data generation. Nonetheless, considerable uncertainties remain in the extent to which wildlife managers can integrate UAVs into ecological monitoring systems for wildlife and their habitats. In this review, we discuss the recent progress and gaps in UAV use in wildlife conservation and management. The review notes that there is scanty information on UAV use in ecological monitoring of medium-to-large mammals found in groups in heterogeneous habitats. We also explore the need and extent to which the technology can be integrated into ecological monitoring systems for mammals in heterogeneous habitats and in topographically-challenging community wildlife-management areas, as a complementary platform to the traditional techniques. Based on its ability to provide high-resolution images in real-time, further experiments on its wider use in the ecological monitoring of wildlife on a spatiotemporal scale are important. The experimentation outputs will make the UAV a very reliable remote sensing platform that addresses the challenges facing conventional techniques.
KW  - UAV
KW  - remote sensing
KW  - conventional ecological monitoring techniques
KW  - satellite platforms
KW  - medium-to-large mammals
KW  - UAV-based habitat assessment
DO  - 10.3390/su11216116
ER  -
TY  - EJOU
AU  - Carvajal-Ramírez, Fernando
AU  - Serrano, João M.
AU  - Agüera-Vega, Francisco
AU  - Martínez-Carricondo, Patricio
TI  - A Comparative Analysis of Phytovolume Estimation Methods Based on UAV-Photogrammetry and Multispectral Imagery in a Mediterranean Forest
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 21
SN  - 2072-4292

AB  - Management and control operations are crucial for preventing forest fires, especially in Mediterranean forest areas with dry climatic periods. One of them is prescribed fires, in which the biomass fuel present in the controlled plot area must be accurately estimated. The most used methods for estimating biomass are time-consuming and demand too much manpower. Unmanned aerial vehicles (UAVs) carrying multispectral sensors can be used to carry out accurate indirect measurements of terrain and vegetation morphology and their radiometric characteristics. Based on the UAV-photogrammetric project products, four estimators of phytovolume were compared in a Mediterranean forest area, all obtained using the difference between a digital surface model (DSM) and a digital terrain model (DTM). The DSM was derived from a UAV-photogrammetric project based on the structure from a motion algorithm. Four different methods for obtaining a DTM were used based on an unclassified dense point cloud produced through a UAV-photogrammetric project (FFU), an unsupervised classified dense point cloud (FFC), a multispectral vegetation index (FMI), and a cloth simulation filter (FCS). Qualitative and quantitative comparisons determined the ability of the phytovolume estimators for vegetation detection and occupied volume. The results show that there are no significant differences in surface vegetation detection between all the pairwise possible comparisons of the four estimators at a 95% confidence level, but FMI presented the best kappa value (0.678) in an error matrix analysis with reference data obtained from photointerpretation and supervised classification. Concerning the accuracy of phytovolume estimation, only FFU and FFC presented differences higher than two standard deviations in a pairwise comparison, and FMI presented the best RMSE (12.3 m) when the estimators were compared to 768 observed data points grouped in four 500 m2 sample plots. The FMI was the best phytovolume estimator of the four compared for low vegetation height in a Mediterranean forest. The use of FMI based on UAV data provides accurate phytovolume estimations that can be applied on several environment management activities, including wildfire prevention. Multitemporal phytovolume estimations based on FMI could help to model the forest resources evolution in a very realistic way.
KW  - phytovolume
KW  - UAV
KW  - multispectral imagery
DO  - 10.3390/rs11212579
ER  -
TY  - EJOU
AU  - Rodriguez-Ramos, Alejandro
AU  - Alvarez-Fernandez, Adrian
AU  - Bavle, Hriday
AU  - Campoy, Pascual
AU  - How, Jonathan P.
TI  - Vision-Based Multirotor Following Using Synthetic Learning Techniques
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 21
SN  - 1424-8220

AB  - Deep- and reinforcement-learning techniques have increasingly required large sets of real data to achieve stable convergence and generalization, in the context of image-recognition, object-detection or motion-control strategies. On this subject, the research community lacks robust approaches to overcome unavailable real-world extensive data by means of realistic synthetic-information and domain-adaptation techniques. In this work, synthetic-learning strategies have been used for the vision-based autonomous following of a noncooperative multirotor. The complete maneuver was learned with synthetic images and high-dimensional low-level continuous robot states, with deep- and reinforcement-learning techniques for object detection and motion control, respectively. A novel motion-control strategy for object following is introduced where the camera gimbal movement is coupled with the multirotor motion during the multirotor following. Results confirm that our present framework can be used to deploy a vision-based task in real flight using synthetic data. It was extensively validated in both simulated and real-flight scenarios, providing proper results (following a multirotor up to 1.3 m/s in simulation and 0.3 m/s in real flights).
KW  - multirotor
KW  - UAV
KW  - following
KW  - synthetic learning
KW  - reinforcement learning
KW  - deep learning
DO  - 10.3390/s19214794
ER  -
TY  - EJOU
AU  - Yu, Lanbing
AU  - Cao, Ying
AU  - Zhou, Chao
AU  - Wang, Yang
AU  - Huo, Zhitao
TI  - Landslide Susceptibility Mapping Combining Information Gain Ratio and Support Vector Machines: A Case Study from Wushan Segment in the Three Gorges Reservoir Area, China
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 22
SN  - 2076-3417

AB  - Landslides are destructive geological hazards that occur all over the world. Due to the periodic regulation of reservoir water level, a large number of landslides occur in the Three Gorges Reservoir area (TGRA). The main objective of this study was to explore the preference of machine learning models for landslide susceptibility mapping in the TGRA. The Wushan segment of TGRA was selected as a case study. At first, 165 landslides were identified and a total of 14 landslide causal factors were constructed from different data sources. Multicollinearity analysis and information gain ratio (IGR) model were applied to select landslide causal factors. Subsequently, the landslide susceptibility mapping using the calculated results of four models, namely, support vector machines (SVM), artificial neural networks (ANN), classification and regression tree (CART), and logistic regression (LR). The accuracy of these four maps were evaluated using the receive operating characteristic (ROC) and the accuracy statistic. Results revealed that eliminating the inconsequential factors can perhaps improve the accuracy of landslide susceptibility modelling, and the SVM model had the best performance in this study, providing strong technical support for landslide susceptibility modelling in TGRA.
KW  - landslides
KW  - susceptibility mapping
KW  - support vector machines
KW  - Three Gorges Reservoir area (TGRA)
DO  - 10.3390/app9224756
ER  -
TY  - EJOU
AU  - Zhou, Jun
AU  - Tian, Yichen
AU  - Yuan, Chao
AU  - Yin, Kai
AU  - Yang, Guang
AU  - Wen, Meiping
TI  - Improved UAV Opium Poppy Detection Using an Updated YOLOv3 Model
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 22
SN  - 1424-8220

AB  - Rapid detection of illicit opium poppy plants using UAV (unmanned aerial vehicle) imagery has become an important means to prevent and combat crimes related to drug cultivation. However, current methods rely on time-consuming visual image interpretation. Here, the You Only Look Once version 3 (YOLOv3) network structure was used to assess the influence that different backbone networks have on the average precision and detection speed of an UAV-derived dataset of poppy imagery, with MobileNetv2 (MN) selected as the most suitable backbone network. A Spatial Pyramid Pooling (SPP) unit was introduced and Generalized Intersection over Union (GIoU) was used to calculate the coordinate loss. The resulting SPP-GIoU-YOLOv3-MN model improved the average precision by 1.62% (from 94.75% to 96.37%) without decreasing speed and achieved an average precision of 96.37%, with a detection speed of 29 FPS using an RTX 2080Ti platform. The sliding window method was used for detection in complete UAV images, which took approximately 2.2 sec/image, approximately 10&times; faster than visual interpretation. The proposed technique significantly improved the efficiency of poppy detection in UAV images while also maintaining a high detection accuracy. The proposed method is thus suitable for the rapid detection of illicit opium poppy cultivation in residential areas and farmland where UAVs with ordinary visible light cameras can be operated at low altitudes (relative height &lt; 200 m).
KW  - UAV
KW  - opium poppy
KW  - object detection
KW  - YOLOv3 model
KW  - deep learning
KW  - CNN
KW  - spatial pyramid pooling
KW  - GIoU
DO  - 10.3390/s19224851
ER  -
TY  - EJOU
AU  - Shahabi, Hejar
AU  - Jarihani, Ben
AU  - Tavakkoli Piralilou, Sepideh
AU  - Chittleborough, David
AU  - Avand, Mohammadtaghi
AU  - Ghorbanzadeh, Omid
TI  - A Semi-Automated Object-Based Gully Networks Detection Using Different Machine Learning Models: A Case Study of Bowen Catchment, Queensland, Australia
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 22
SN  - 1424-8220

AB  - Gully erosion is a dominant source of sediment and particulates to the Great Barrier Reef (GBR) World Heritage area. We selected the Bowen catchment, a tributary of the Burdekin Basin, as our area of study; the region is associated with a high density of gully networks. We aimed to use a semi-automated object-based gully networks detection process using a combination of multi-source and multi-scale remote sensing and ground-based data. An advanced approach was employed by integrating geographic object-based image analysis (GEOBIA) with current machine learning (ML) models. These included artificial neural networks (ANN), support vector machines (SVM), and random forests (RF), and an ensemble ML model of stacking to deal with the spatial scaling problem in gully networks detection. Spectral indices such as the normalized difference vegetation index (NDVI) and topographic conditioning factors, such as elevation, slope, aspect, topographic wetness index (TWI), slope length (SL), and curvature, were generated from Sentinel 2A images and the ALOS 12-m digital elevation model (DEM), respectively. For image segmentation, the ESP2 tool was used to obtain three optimal scale factors. On using object pureness index (OPI), object matching index (OMI), and object fitness index (OFI), the accuracy of each scale in image segmentation was evaluated. The scale parameter of 45 with OFI of 0.94, which is a combination of OPI and OMI indices, proved to be the optimal scale parameter for image segmentation. Furthermore, segmented objects based on scale 45 were overlaid with 70% and 30% of a prepared gully inventory map to select the ML models&rsquo; training and testing objects, respectively. The quantitative accuracy assessment methods of Precision, Recall, and an F1 measure were used to evaluate the model&rsquo;s performance. Integration of GEOBIA with the stacking model using a scale of 45 resulted in the highest accuracy in detection of gully networks with an F1 measure value of 0.89. Here, we conclude that the adoption of optimal scale object definition in the GEOBIA and application of the ensemble stacking of ML models resulted in higher accuracy in the detection of gully networks.
KW  - geographic object-based image analysis (GEOBIA)
KW  - gully erosion
KW  - optimal scale detection
KW  - stacking model
KW  - Bowen catchment
DO  - 10.3390/s19224893
ER  -
TY  - EJOU
AU  - Silva, Maurício R.
AU  - Souza, Elitelma S.
AU  - Alsina, Pablo J.
AU  - Leite, Deyvid L.
AU  - Morais, Mateus R.
AU  - Pereira, Diego S.
AU  - Nascimento, Luís B. P.
AU  - Medeiros, Adelardo A. D.
AU  - Junior, Francisco H. Cunha
AU  - Nogueira, Marcelo B.
AU  - Albuquerque, Glauberto L. A.
AU  - Dantas, João B. D.
TI  - Performance Evaluation of Multi-UAV Network Applied to Scanning Rocket Impact Area
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 22
SN  - 1424-8220

AB  - This paper presents a communication network for a squadron of unmanned aerial vehicles (UAVs) to be used in the scanning rocket impact area for Barreira do Inferno Launch Center&mdash;CLBI (Rio Grande do Norte, Brazil), aiming at detecting intruder boats. The main features of communication networks associated with multi-UAV systems are presented. This system sends information through Wireless Sensor Networks (WSN). After comparing and analyzing area scanning strategies, it presents the specification of a data communication network architecture for a squadron of UAVs within a sensor network using XBee Pro 900HP S3B modules. A brief description is made about the initial information from the construction of the system. The embedded hardware and the design procedure of a dedicated communication antenna to the XBee modules are presented. In order to evaluate the performance of the proposed architecture in terms of robustness and reliability, a set of experimental tests in different communication scenarios is carried out. Network management software is employed to measure the throughput, packet loss and other performance indicators in the communication links between the different network nodes. Experimental results allow verifying the quality and performance of the network nodes, as well as the reliability of the communication links, assessing signal received quality, range and latency.
KW  - ad hoc network
KW  - wireless sensor networks
KW  - FANET
KW  - multi-UAV system monitoring
KW  - communication architecture
KW  - network performance
DO  - 10.3390/s19224895
ER  -
TY  - EJOU
AU  - Tian, Furui
AU  - Zhao, Ying
AU  - Che, Xiangqian
AU  - Zhao, Yagebai
AU  - Xin, Dabo
TI  - Concrete Crack Identification and Image Mosaic Based on Image Processing
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 22
SN  - 2076-3417

AB  - Crack assessment is an essential process in bridge detection. In general, most non-contact crack detection techniques are not suitable for widespread use. The reason for this is that they all need to position the ruler at the inspection site in advance or calibrate the camera unit pixel size at a certain distance in a very intricate process. However, the object distance method in this paper can complete the calculation using only the crack image and the working distance, which are provided by an acquisition system equipped with a camera and laser range finder. First, the object distance method and the scale method are compared by calculating the crack width, and the results show that the object distance method is the more accurate method. Then, a double edge pixel statistical method is proposed to calculate the crack length, which solves the problem of redundant and missing pixels. In addition, the conventional mosaic algorithm is improved to realize an image mosaic for the more efficient splicing of crack images. Finally, a series of laboratory tests were conducted to verify the proposed approach. The experiments showed that the precision of crack length extraction can reach 92%, and the improved algorithm stitching precision can reach 98%.
KW  - concrete crack
KW  - edge detection
KW  - image identification
KW  - minimum width extraction
KW  - double edge pixel statistics
KW  - image mosaic algorithm
DO  - 10.3390/app9224826
ER  -
TY  - EJOU
AU  - Tsouros, Dimosthenis C.
AU  - Bibi, Stamatia
AU  - Sarigiannidis, Panagiotis G.
TI  - A Review on UAV-Based Applications for Precision Agriculture
T2  - Information

PY  - 2019
VL  - 10
IS  - 11
SN  - 2078-2489

AB  - Emerging technologies such as Internet of Things (IoT) can provide significant potential in Smart Farming and Precision Agriculture applications, enabling the acquisition of real-time environmental data. IoT devices such as Unmanned Aerial Vehicles (UAVs) can be exploited in a variety of applications related to crops management, by capturing high spatial and temporal resolution images. These technologies are expected to revolutionize agriculture, enabling decision-making in days instead of weeks, promising significant reduction in cost and increase in the yield. Such decisions enable the effective application of farm inputs, supporting the four pillars of precision agriculture, i.e., apply the right practice, at the right place, at the right time and with the right quantity. However, the actual proliferation and exploitation of UAVs in Smart Farming has not been as robust as expected mainly due to the challenges confronted when selecting and deploying the relevant technologies, including the data acquisition and image processing methods. The main problem is that still there is no standardized workflow for the use of UAVs in such applications, as it is a relatively new area. In this article, we review the most recent applications of UAVs for Precision Agriculture. We discuss the most common applications, the types of UAVs exploited and then we focus on the data acquisition methods and technologies, appointing the benefits and drawbacks of each one. We also point out the most popular processing methods of aerial imagery and discuss the outcomes of each method and the potential applications of each one in the farming operations.
KW  - remote sensing
KW  - IoT
KW  - UAV
KW  - UAS
KW  - Unmanned Aerial Vehicle
KW  - Unmanned Aerial System
KW  - image processing
KW  - Precision Agriculture
KW  - Smart Farming
KW  - review
DO  - 10.3390/info10110349
ER  -
TY  - EJOU
AU  - Riid, Andri
AU  - Lõuk, Roland
AU  - Pihlak, Rene
AU  - Tepljakov, Aleksei
AU  - Vassiljeva, Kristina
TI  - Pavement Distress Detection with Deep Learning Using the Orthoframes Acquired by a Mobile Mapping System
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 22
SN  - 2076-3417

AB  - The subject matter of this research article is automatic detection of pavement distress on highway roads using computer vision algorithms. Specifically, deep learning convolutional neural network models are employed towards the implementation of the detector. Source data for training the detector come in the form of orthoframes acquired by a mobile mapping system. Compared to our previous work, the orthoframes are generally of better quality, but more importantly, in this work, we introduce a manual preprocessing step: sets of orthoframes are carefully selected for training and manually digitized to ensure adequate performance of the detector. Pretrained convolutional neural networks are then fine-tuned for the problem of pavement distress detection. Corresponding experimental results are provided and analyzed and indicate a successful implementation of the detector.
KW  - pavement distress
KW  - defect detection
KW  - image recognition
KW  - image processing
KW  - deep neural network
DO  - 10.3390/app9224829
ER  -
TY  - EJOU
AU  - Yu, Hao
AU  - Wang, Lei
AU  - Wang, Zongming
AU  - Ren, Chunying
AU  - Zhang, Bai
TI  - Using Landsat OLI and Random Forest to Assess Grassland Degradation with Aboveground Net Primary Production and Electrical Conductivity Data
T2  - ISPRS International Journal of Geo-Information

PY  - 2019
VL  - 8
IS  - 11
SN  - 2220-9964

AB  - Grassland coverage, aboveground net primary production (ANPP), and species composition are used as indicators of grassland degradation. However, soil salinization deficiency, which is also a factor of grassland degradation, is rarely used in grassland degradation assessment in semiarid regions. We assessed grassland degradation by its quality, quantity, and spatial pattern over semiarid west Jilin, China. Considering soil salinization in west Jilin, electrical conductivity (EC) is used as an index with ANPP to assess grassland degradation. First, the spatial distribution of the grassland was measured with information mined from multi-temporal remote sensing images using an object-based image analysis combined with classification and decision tree methods. Second, with 166 field samples, we utilized the random forest (RF) algorithm as the variable selection and regression method for predicting EC and ANPP. Finally, we created a new grassland degradation model (GDM) based on ANPP and EC. The results showed the R2 (0.91) and RMSE (0.057 mS/cm) of the EC model were generally highest and lowest when the ntree was 400; the ANPP model was optimal (R2 = 0.85 and RMSE = 15.81 gC/m2) when the ntree was 600. Grassland area of west Jilin was 609.67 &times; 103 ha in 2017, there were 373.79 &times; 103 ha of degraded grassland, with 210.47 &times; 103 ha being intensively degraded. This paper surpasses past limitations of excessive reliance on vegetation index to construct a grassland degradation model which considers the characteristics of the study area and soil salinity. The results confirm the positive influence of the ecological conservation projects sponsored by the government. The research outcome could offer supporting data for decision making to help alleviate grassland degradation and promote the rehabilitation of grassland vegetation.
KW  - remote sensing
KW  - aboveground net primary productivity (ANPP)
KW  - soil salinity
KW  - grassland degradation model (GDM)
KW  - random forest (RF)
KW  - principle component analysis (PCA)
DO  - 10.3390/ijgi8110511
ER  -
TY  - EJOU
AU  - Zhao, Longcai
AU  - Li, Qiangzi
AU  - Zhang, Yuan
AU  - Wang, Hongyan
AU  - Du, Xin
TI  - Integrating the Continuous Wavelet Transform and a Convolutional Neural Network to Identify Vineyard Using Time Series Satellite Images
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 22
SN  - 2072-4292

AB  - Grape is an economic crop of great importance and is widely cultivated in China. With the development of remote sensing, abundant data sources strongly guarantee that researchers can identify crop types and map their spatial distributions. However, to date, only a few studies have been conducted to identify vineyards using satellite image data. In this study, a vineyard is identified using satellite images, and a new approach is proposed that integrates the continuous wavelet transform (CWT) and a convolutional neural network (CNN). Specifically, the original time series of the normalized difference vegetation index (NDVI), enhanced vegetation index (EVI), and green chlorophyll vegetation index (GCVI) are reconstructed by applying an iterated Savitzky-Golay (S-G) method to form a daily time series for a full year; then, the CWT is applied to three reconstructed time series to generate corresponding scalograms; and finally, CNN technology is used to identify vineyards based on the stacked scalograms. In addition to our approach, a traditional and common approach that uses a random forest (RF) to identify crop types based on multi-temporal images is selected as the control group. The experimental results demonstrated the following: (i) the proposed approach was comprehensively superior to the RF approach; it improved the overall accuracy by 9.87% (up to 89.66%); (ii) the CWT had a stable and effective influence on the reconstructed time series, and the scalograms fully represented the unique time-related frequency pattern of each of the planting conditions; and (iii) the convolution and max pooling processing of the CNN captured the unique and subtle distribution patterns of the scalograms to distinguish vineyards from other crops. Additionally, the proposed approach is considered as able to be applied to other practical scenarios, such as using time series data to identify crop types, map landcover/land use, and is recommended to be tested in future practical applications.
KW  - vineyard
KW  - identification
KW  - CWT
KW  - CNN
KW  - Sentinel-2
KW  - remote sensing
DO  - 10.3390/rs11222641
ER  -
TY  - EJOU
AU  - Liu, Qin
AU  - Yang, Zhaoping
AU  - Han, Fang
AU  - Shi, Hui
AU  - Wang, Zhi
AU  - Chen, Xiaodong
TI  - Ecological Environment Assessment in World Natural Heritage Site Based on Remote-Sensing Data. A Case Study from the Bayinbuluke
T2  - Sustainability

PY  - 2019
VL  - 11
IS  - 22
SN  - 2071-1050

AB  - Ecological environment assessment would be helpful for a rapid and systematic understanding of ecological status and would contribute to formulate appropriate strategies for the sustainability of heritage sites. A procedure based on spatial principle component analysis was employed to measure the ecological status in Bayinbuluke; exploratory spatial data analysis and geo-detector model were introduced to assess the spatio-temporal distribution characteristics and detect the driving factors of the ecological environment. Five results are presented: (1) During 2007&ndash;2018, the average values of moisture, greenness, and heat increased by 51.72%, 23.10%, and 4.99% respectively, and the average values of dryness decreased by 56.70%. However, the fluctuation of each indicator increased. (2) The ecological environment of Bayinbuluke was improved from 2007 to 2018, and presented a distribution pattern that the heritage site was better than the buffer zone, and the southeast area was better than the northwest area. (3) The ecological environment presented a significant spatial clustering characteristic, and four types of spatial associations were proposed for assessing spatial dependence among the samples. (4) Elevation, protection partition, temperature, river, road, tourism, precipitation, community resident, and slope were statistically significant with respect to the changes in ecological status, and the interaction of any two factors was higher than the effect of one factor alone. (5) The remote-sensing ecological index (RSEI) could reflect the vegetation growth to a certain extent, but has limited ability to respond to species structure. Overall, the framework presented in this paper realized a visual and measurable approach for a detailed monitoring of the ecological environment and provided valuable information for the protection and management of heritage sites.
KW  - ecological environment
KW  - heritage monitoring
KW  - remote sensing
KW  - spatial-temporal distribution
DO  - 10.3390/su11226385
ER  -
TY  - EJOU
AU  - Bui, Hoang-Bac
AU  - Nguyen, Hoang
AU  - Choi, Yosoon
AU  - Bui, Xuan-Nam
AU  - Nguyen-Thoi, Trung
AU  - Zandi, Yousef
TI  - A Novel Artificial Intelligence Technique to Estimate the Gross Calorific Value of Coal Based on Meta-Heuristic and Support Vector Regression Algorithms
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 22
SN  - 2076-3417

AB  - Gross calorific value (GCV) is one of the essential parameters for evaluating coal quality. Therefore, accurate GCV prediction is one of the primary ways to improve heating value as well as coal production. A novel evolutionary-based predictive system was proposed in this study for predicting GCV with high accuracy, namely the particle swarm optimization (PSO)-support vector regression (SVR) model. It was developed based on the SVR and PSO algorithms. Three different kernel functions were employed to establish the PSO-SVR models, including radial basis function, linear, and polynomial functions. Besides, three benchmark machine learning models including classification and regression trees (CART), multiple linear regression (MLR), and principle component analysis (PCA) were also developed to estimate GCV and then compared with the proposed PSO-SVR model; 2583 coal samples were used to analyze the proximate components and GCV for this study. Then, they were used to develop the mentioned models as well as check their performance in experimental results. Root-mean-squared error (RMSE), correlation coefficient (R2), ranking, and intensity color criteria were used and computed to evaluate the GCV predictive models developed. The results revealed that the proposed PSO-SVR model with radial basis function had better accuracy than the other models. The PSO algorithm was optimized in the SVR model with high efficiency. These should be used as a supporting tool in practical engineering to determine the heating value of coal seams in complex geological conditions.
KW  - gross calorific value
KW  - coal
KW  - proximate analyze
KW  - artificial intelligence
KW  - PSO-SVR
DO  - 10.3390/app9224868
ER  -
TY  - EJOU
AU  - Abdelbaki, Asmaa
AU  - Schlerf, Martin
AU  - Verhoef, Wout
AU  - Udelhoven, Thomas
TI  - Introduction of Variable Correlation for the Improved Retrieval of Crop Traits Using Canopy Reflectance Model Inversion
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 22
SN  - 2072-4292

AB  - Look-up table (LUT)-based canopy reflectance models are considered robust methods to estimate vegetation attributes from remotely sensed data. However, the LUT inversion approach is sensitive to measurements and model uncertainties, which raise the ill-posed inverse problem. Therefore, regularization options are needed to mitigate this problem and reduce the uncertainties of estimates. In this study, we introduce a new method to regularize the LUT inversion approach to improve the accuracy of biophysical parameters (leaf area index (LAI) and fractional vegetation cover (fCover)). This was achieved by incorporating known variable correlations that existed at the test site into the LUT approach to correlate the model variables of the Soil–Leaf–Canopy (SLC) model using the Cholesky decomposition algorithm. The retrievals of 27 potato plots obtained from the regularized LUT (LUTreg) were compared with the standard LUT (LUTstd), which did not consider variable correlations. Different solutions from both types of LUTs (LUTreg and LUTstd) were utilized to improve the quality of the model outputs. Results indicate that the present method improved the accuracy of LAI estimation, with the coefficient of determination R2 = 0.74 and normalized root-mean-square error NRMSE = 24.45% in LUTreg, compared with R2 = 0.71 and NRMSE = 25.57% in LUTstd. In addition, the variability of LAI decreased in LUTreg (5.10) compared with that in LUTstd (12.10). Hence, our results give new insight into the impact of adding the correlation between variables to the LUT inversion approach to improve the accuracy of estimations. In this study, only two correlated variables (LAI and fCover) were examined; in subsequent studies, the full correlation matrix based on the Cholesky algorithm should be explored.
KW  - LUT inversion-based
KW  - Cholesky decomposition
KW  - regularization strategies
KW  - fractional vegetation cover
KW  - canopy chlorophyll content
KW  - hyperspectral measurements
DO  - 10.3390/rs11222681
ER  -
TY  - EJOU
AU  - Arshad, Bilal
AU  - Ogie, Robert
AU  - Barthelemy, Johan
AU  - Pradhan, Biswajeet
AU  - Verstaevel, Nicolas
AU  - Perez, Pascal
TI  - Computer Vision and IoT-Based Sensors in Flood Monitoring and Mapping: A Systematic Review
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 22
SN  - 1424-8220

AB  - Floods are amongst the most common and devastating of all natural hazards. The alarming number of flood-related deaths and financial losses suffered annually across the world call for improved response to flood risks. Interestingly, the last decade has presented great opportunities with a series of scholarly activities exploring how camera images and wireless sensor data from Internet-of-Things (IoT) networks can improve flood management. This paper presents a systematic review of the literature regarding IoT-based sensors and computer vision applications in flood monitoring and mapping. The paper contributes by highlighting the main computer vision techniques and IoT sensor approaches utilised in the literature for real-time flood monitoring, flood modelling, mapping and early warning systems including the estimation of water level. The paper further contributes by providing recommendations for future research. In particular, the study recommends ways in which computer vision and IoT sensor techniques can be harnessed to better monitor and manage coastal lagoons&mdash;an aspect that is under-explored in the literature.
KW  - remote sensing
KW  - flood
KW  - disaster management
KW  - coastal
KW  - environmental sensor network (ESN)
KW  - IoT
KW  - drones
KW  - UAV
KW  - computer vision
KW  - wireless sensor network
DO  - 10.3390/s19225012
ER  -
TY  - EJOU
AU  - Wang, Wantian
AU  - Tang, Ziyue
AU  - Chen, Yichang
AU  - Zhang, Yuanpeng
AU  - Sun, Yongjian
TI  - Aircraft Target Classification for Conventional Narrow-Band Radar with Multi-Wave Gates Sparse Echo Data
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 22
SN  - 2072-4292

AB  - For a conventional narrow-band radar system, the detectable information of the target is limited, and it is difficult for the radar to accurately identify the target type. In particular, the classification probability will further decrease when part of the echo data is missed. By extracting the target features in time and frequency domains from multi-wave gates sparse echo data, this paper presents a classification algorithm in conventional narrow-band radar to identify three different types of aircraft target, i.e., helicopter, propeller and jet. Firstly, the classical sparse reconstruction algorithm is utilized to reconstruct the target frequency spectrum with single-wave gate sparse echo data. Then, the micro-Doppler effect caused by rotating parts of different targets is analyzed, and the micro-Doppler based features, such as amplitude deviation coefficient, time domain waveform entropy and frequency domain waveform entropy, are extracted from reconstructed echo data to identify targets. Thirdly, the target features extracted from multi-wave gates reconstructed echo data are weighted and fused to improve the accuracy of classification. Finally, the fused feature vectors are fed into a support vector machine (SVM) model for classification. By contrast with the conventional algorithm of aircraft target classification, the proposed algorithm can effectively process sparse echo data and achieve higher classification probability via weighted features fusion of multi-wave gates echo data. The experiments on synthetic data are carried out to validate the effectiveness of the proposed algorithm.
KW  - narrow-band radar
KW  - target classification
KW  - signal reconstruction
KW  - features extraction
KW  - weighted features fusion
DO  - 10.3390/rs11222700
ER  -
TY  - EJOU
AU  - Sun, Ying
AU  - Huang, Jianfeng
AU  - Ao, Zurui
AU  - Lao, Dazhao
AU  - Xin, Qinchuan
TI  - Deep Learning Approaches for the Mapping of Tree Species Diversity in a Tropical Wetland Using Airborne LiDAR and High-Spatial-Resolution Remote Sensing Images
T2  - Forests

PY  - 2019
VL  - 10
IS  - 11
SN  - 1999-4907

AB  - The monitoring of tree species diversity is important for forest or wetland ecosystem service maintenance or resource management. Remote sensing is an efficient alternative to traditional field work to map tree species diversity over large areas. Previous studies have used light detection and ranging (LiDAR) and imaging spectroscopy (hyperspectral or multispectral remote sensing) for species richness prediction. The recent development of very high spatial resolution (VHR) RGB images has enabled detailed characterization of canopies and forest structures. In this study, we developed a three-step workflow for mapping tree species diversity, the aim of which was to increase knowledge of tree species diversity assessment using deep learning in a tropical wetland (Haizhu Wetland) in South China based on VHR-RGB images and LiDAR points. Firstly, individual trees were detected based on a canopy height model (CHM, derived from LiDAR points) by the local-maxima-based method in the FUSION software (Version 3.70, Seattle, USA). Then, tree species at the individual tree level were identified via a patch-based image input method, which cropped the RGB images into small patches (the individually detected trees) based on the tree apexes detected. Three different deep learning methods (i.e., AlexNet, VGG16, and ResNet50) were modified to classify the tree species, as they can make good use of the spatial context information. Finally, four diversity indices, namely, the Margalef richness index, the Shannon&ndash;Wiener diversity index, the Simpson diversity index, and the Pielou evenness index, were calculated from the fixed subset with a size of 30 &times; 30 m for assessment. In the classification phase, VGG16 had the best performance, with an overall accuracy of 73.25% for 18 tree species. Based on the classification results, mapping of tree species diversity showed reasonable agreement with field survey data (R2Margalef = 0.4562, root-mean-square error RMSEMargalef = 0.5629; R2Shannon&ndash;Wiener = 0.7948, RMSEShannon&ndash;Wiener = 0.7202; R2Simpson = 0.7907, RMSESimpson = 0.1038; and R2Pielou = 0.5875, RMSEPielou = 0.3053). While challenges remain for individual tree detection and species classification, the deep-learning-based solution shows potential for mapping tree species diversity.
KW  - tree species diversity
KW  - tropical wetland
KW  - high-resolution remote sensing images
KW  - LiDAR
KW  - individual tree level
KW  - deep learning
DO  - 10.3390/f10111047
ER  -
TY  - EJOU
AU  - Ashapure, Akash
AU  - Jung, Jinha
AU  - Chang, Anjin
AU  - Oh, Sungchan
AU  - Maeda, Murilo
AU  - Landivar, Juan
TI  - A Comparative Study of RGB and Multispectral Sensor-Based Cotton Canopy Cover Modelling Using Multi-Temporal UAS Data
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 23
SN  - 2072-4292

AB  - This study presents a comparative study of multispectral and RGB (red, green, and blue) sensor-based cotton canopy cover modelling using multi-temporal unmanned aircraft systems (UAS) imagery. Additionally, a canopy cover model using an RGB sensor is proposed that combines an RGB-based vegetation index with morphological closing. The field experiment was established in 2017 and 2018, where the whole study area was divided into approximately 1 x 1 m size grids. Grid-wise percentage canopy cover was computed using both RGB and multispectral sensors over multiple flights during the growing season of the cotton crop. Initially, the normalized difference vegetation index (NDVI)-based canopy cover was estimated, and this was used as a reference for the comparison with RGB-based canopy cover estimations. To test the maximum achievable performance of RGB-based canopy cover estimation, a pixel-wise classification method was implemented. Later, four RGB-based canopy cover estimation methods were implemented using RGB images, namely Canopeo, the excessive greenness index, the modified red green vegetation index and the red green blue vegetation index. The performance of RGB-based canopy cover estimation was evaluated using NDVI-based canopy cover estimation. The multispectral sensor-based canopy cover model was considered to be a more stable and accurately estimating canopy cover model, whereas the RGB-based canopy cover model was very unstable and failed to identify canopy when cotton leaves changed color after canopy maturation. The application of a morphological closing operation after the thresholding significantly improved the RGB-based canopy cover modeling. The red green blue vegetation index turned out to be the most efficient vegetation index to extract canopy cover with very low average root mean square error (2.94% for the 2017 dataset and 2.82% for the 2018 dataset), with respect to multispectral sensor-based canopy cover estimation. The proposed canopy cover model provides an affordable alternate of the multispectral sensors which are more sensitive and expensive.
KW  - precision agriculture
KW  - canopy cover
KW  - UAS
KW  - image analysis
KW  - multispectral
KW  - crop mapping
DO  - 10.3390/rs11232757
ER  -
TY  - EJOU
AU  - Bithas, Petros S.
AU  - Michailidis, Emmanouel T.
AU  - Nomikos, Nikolaos
AU  - Vouyioukas, Demosthenes
AU  - Kanatas, Athanasios G.
TI  - A Survey on Machine-Learning Techniques for UAV-Based Communications
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 23
SN  - 1424-8220

AB  - Unmanned aerial vehicles (UAVs) will be an integral part of the next generation wireless communication networks. Their adoption in various communication-based applications is expected to improve coverage and spectral efficiency, as compared to traditional ground-based solutions. However, this new degree of freedom that will be included in the network will also add new challenges. In this context, the machine-learning (ML) framework is expected to provide solutions for the various problems that have already been identified when UAVs are used for communication purposes. In this article, we provide a detailed survey of all relevant research works, in which ML techniques have been used on UAV-based communications for improving various design and functional aspects such as channel modeling, resource management, positioning, and security.
KW  - 5G networks
KW  - air-to-ground communications
KW  - machine-learning
KW  - unmanned aerial vehicles (UAVs)
KW  - cellular networks
DO  - 10.3390/s19235170
ER  -
TY  - EJOU
AU  - Moreno-Armendáriz, Marco A.
AU  - Calvo, Hiram
AU  - Duchanoy, Carlos A.
AU  - López-Juárez, Anayantzin P.
AU  - Vargas-Monroy, Israel A.
AU  - Suarez-Castañon, Miguel S.
TI  - Deep Green Diagnostics: Urban Green Space Analysis Using Deep Learning and Drone Images
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 23
SN  - 1424-8220

AB  - Nowadays, more than half of the world’s population lives in urban areas, and this number continues increasing. Consequently, there are more and more scientific publications that analyze health problems of people associated with living in these highly urbanized locations. In particular, some of the recent work has focused on relating people’s health to the quality and quantity of urban green areas. In this context, and considering the huge amount of land area in large cities that must be supervised, our work seeks to develop a deep learning-based solution capable of determining the level of health of the land and to assess whether it is contaminated. The main purpose is to provide health institutions with software capable of creating updated maps that indicate where these phenomena are presented, as this information could be very useful to guide public health goals in large cities. Our software is released as open source code, and the data used for the experiments presented in this paper are also freely available.
KW  - deep learning (for social good)
KW  - remote sensing
KW  - biomass analysis
DO  - 10.3390/s19235287
ER  -
TY  - EJOU
AU  - Hasan, Umut
AU  - Sawut, Mamat
AU  - Chen, Shuisen
TI  - Estimating the Leaf Area Index of Winter Wheat Based on Unmanned Aerial Vehicle RGB-Image Parameters
T2  - Sustainability

PY  - 2019
VL  - 11
IS  - 23
SN  - 2071-1050

AB  - The leaf area index (LAI) is not only an important parameter for monitoring crop growth, but also an important input parameter for crop yield prediction models and hydrological and climatic models. Several studies have recently been conducted to estimate crop LAI using unmanned aerial vehicle (UAV) multispectral and hyperspectral data. However, there are few studies on estimating the LAI of winter wheat using unmanned aerial vehicle (UAV) RGB images. In this study, we estimated the LAI of winter wheat at the jointing stage on simple farmland in Xinjiang, China, using parameters derived from UAV RGB images. According to gray correlation analysis, UAV RGB-image parameters such as the Visible Atmospherically Resistant Index (VARI), the Red Green Blue Vegetation Index (RGBVI), the Digital Number (DN) of Blue Channel (B) and the Green Leaf Algorithm (GLA) were selected to develop models for estimating the LAI of winter wheat. The results showed that it is feasible to use UAV RGB images for inverting and mapping the LAI of winter wheat at the jointing stage on the field scale, and the partial least squares regression (PLSR) model based on the VARI, RGBVI, B and GLA had the best prediction accuracy (R2 = 0.776, root mean square error (RMSE) = 0.468, residual prediction deviation (RPD) = 1.838) among all the regression models. To conclude, UAV RGB images not only have great potential in estimating the LAI of winter wheat, but also can provide more reliable and accurate data for precision agriculture management.
KW  - leaf area index
KW  - jointing stage
KW  - UAV
KW  - grey correlation analysis
KW  - vegetation indices
DO  - 10.3390/su11236829
ER  -
TY  - EJOU
AU  - Cogato, Alessia
AU  - Pagay, Vinay
AU  - Marinello, Francesco
AU  - Meggio, Franco
AU  - Grace, Peter
AU  - De Antoni Migliorati, Massimiliano
TI  - Assessing the Feasibility of Using Sentinel-2 Imagery to Quantify the Impact of Heatwaves on Irrigated Vineyards
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 23
SN  - 2072-4292

AB  - Heatwaves are common in many viticultural regions of Australia. We evaluated the potential of satellite-based remote sensing to detect the effects of high temperatures on grapevines in a South Australian vineyard over the 2016&ndash;2017 and 2017&ndash;2018 seasons. The study involved: (i) comparing the normalized difference vegetation index (NDVI) from medium- and high-resolution satellite images; (ii) determining correlations between environmental conditions and vegetation indices (Vis); and (iii) identifying VIs that best indicate heatwave effects. Pearson&rsquo;s correlation and Bland&ndash;Altman testing showed a significant agreement between the NDVI of high- and medium-resolution imagery (R = 0.74, estimated difference &minus;0.093). The band and the VI most sensitive to changes in environmental conditions were 705 nm and enhanced vegetation index (EVI), both of which correlated with relative humidity (R = 0.65 and R = 0.62, respectively). Conversely, SWIR (short wave infrared, 1610 nm) exhibited a negative correlation with growing degree days (R = &minus;0.64). The analysis of heat stress showed that green and red edge bands&mdash;the chlorophyll absorption ratio index (CARI) and transformed chlorophyll absorption ratio index (TCARI)&mdash;were negatively correlated with thermal environmental parameters such as air and soil temperature and growing degree days (GDDs). The red and red edge bands&mdash;the soil-adjusted vegetation index (SAVI) and CARI2&mdash;were correlated with relative humidity. To the best of our knowledge, this is the first study demonstrating the effectiveness of using medium-resolution imagery for the detection of heat stress on grapevines in irrigated vineyards.
KW  - heat stress
KW  - water stress
KW  - grapevine
KW  - sentinel-2
KW  - vegetation indices
KW  - multispectral remote sensing
KW  - growing degree days
DO  - 10.3390/rs11232869
ER  -
TY  - EJOU
AU  - Kayad, Ahmed
AU  - Sozzi, Marco
AU  - Gatto, Simone
AU  - Marinello, Francesco
AU  - Pirotti, Francesco
TI  - Monitoring Within-Field Variability of Corn Yield using Sentinel-2 and Machine Learning Techniques
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 23
SN  - 2072-4292

AB  - Monitoring and prediction of within-field crop variability can support farmers to make the right decisions in different situations. The current advances in remote sensing and the availability of high resolution, high frequency, and free Sentinel-2 images improve the implementation of Precision Agriculture (PA) for a wider range of farmers. This study investigated the possibility of using vegetation indices (VIs) derived from Sentinel-2 images and machine learning techniques to assess corn (Zea mays) grain yield spatial variability within the field scale. A 22-ha study field in North Italy was monitored between 2016 and 2018; corn yield was measured and recorded by a grain yield monitor mounted on the harvester machine recording more than 20,000 georeferenced yield observation points from the study field for each season. VIs from a total of 34 Sentinel-2 images at different crop ages were analyzed for correlation with the measured yield observations. Multiple regression and two different machine learning approaches were also tested to model corn grain yield. The three main results were the following: (i) the Green Normalized Difference Vegetation Index (GNDVI) provided the highest R2 value of 0.48 for monitoring within-field variability of corn grain yield; (ii) the most suitable period for corn yield monitoring was a crop age between 105 and 135 days from the planting date (R4&ndash;R6); (iii) Random Forests was the most accurate machine learning approach for predicting within-field variability of corn yield, with an R2 value of almost 0.6 over an independent validation set of half of the total observations. Based on the results, within-field variability of corn yield for previous seasons could be investigated from archived Sentinel-2 data with GNDVI at crop stage (R4&ndash;R6).
KW  - Sentinel-2
KW  - precision agriculture
KW  - machine learning
KW  - vegetation indices
KW  - corn yield
KW  - within-field variability
KW  - digital farming
DO  - 10.3390/rs11232873
ER  -
TY  - EJOU
AU  - Liu, Wei
AU  - Yang, MengYuan
AU  - Xie, Meng
AU  - Guo, Zihui
AU  - Li, ErZhu
AU  - Zhang, Lianpeng
AU  - Pei, Tao
AU  - Wang, Dong
TI  - Accurate Building Extraction from Fused DSM and UAV Images Using a Chain Fully Convolutional Neural Network
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 24
SN  - 2072-4292

AB  - Accurate extraction of buildings using high spatial resolution imagery is essential to a wide range of urban applications. However, it is difficult to extract semantic features from a variety of complex scenes (e.g., suburban, urban and urban village areas) because various complex man-made objects usually appear heterogeneous with large intra-class and low inter-class variations. The automatic extraction of buildings is thus extremely challenging. The fully convolutional neural networks (FCNs) developed in recent years have performed well in the extraction of urban man-made objects due to their ability to learn state-of-the-art features and to label pixels end-to-end. One of the most successful FCNs used in building extraction is U-net. However, the commonly used skip connection and feature fusion refinement modules in U-net often ignore the problem of feature selection, and the ability to extract smaller buildings and refine building boundaries needs to be improved. In this paper, we propose a trainable chain fully convolutional neural network (CFCN), which fuses high spatial resolution unmanned aerial vehicle (UAV) images and the digital surface model (DSM) for building extraction. Multilevel features are obtained from the fusion data, and an improved U-net is used for the coarse extraction of the building. To solve the problem of incomplete extraction of building boundaries, a U-net network is introduced by chain, which is used for the introduction of a coarse building boundary constraint, hole filling, and "speckle" removal. Typical areas such as suburban, urban, and urban villages were selected for building extraction experiments. The results show that the CFCN achieved recall of 98.67%, 98.62%, and 99.52% and intersection over union (IoU) of 96.23%, 96.43%, and 95.76% in suburban, urban, and urban village areas, respectively. Considering the IoU in conjunction with the CFCN and U-net resulted in improvements of 6.61%, 5.31%, and 6.45% in suburban, urban, and urban village areas, respectively. The proposed method can extract buildings with higher accuracy and with clearer and more complete boundaries.
KW  - building extraction
KW  - digital surface model
KW  - unmanned aerial vehicle images
KW  - chain full convolution neural network
KW  - fusion
DO  - 10.3390/rs11242912
ER  -
TY  - EJOU
AU  - Prado Osco, Lucas
AU  - Marques Ramos, Ana P.
AU  - Roberto Pereira, Danilo
AU  - Akemi Saito Moriya, Érika
AU  - Nobuhiro Imai, Nilton
AU  - Takashi Matsubara, Edson
AU  - Estrabis, Nayara
AU  - de Souza, Maurício
AU  - Marcato Junior, José
AU  - Gonçalves, Wesley N.
AU  - Li, Jonathan
AU  - Liesenberg, Veraldo
AU  - Eduardo Creste, José
TI  - Predicting Canopy Nitrogen Content in Citrus-Trees Using Random Forest Algorithm Associated to Spectral Vegetation Indices from UAV-Imagery
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 24
SN  - 2072-4292

AB  - The traditional method of measuring nitrogen content in plants is a time-consuming and labor-intensive task. Spectral vegetation indices extracted from unmanned aerial vehicle (UAV) images and machine learning algorithms have been proved effective in assisting nutritional analysis in plants. Still, this analysis has not considered the combination of spectral indices and machine learning algorithms to predict nitrogen in tree-canopy structures. This paper proposes a new framework to infer the nitrogen content in citrus-tree at a canopy-level using spectral vegetation indices processed with the random forest algorithm. A total of 33 spectral indices were estimated from multispectral images acquired with a UAV-based sensor. Leaf samples were gathered from different planting-fields and the leaf nitrogen content (LNC) was measured in the laboratory, and later converted into the canopy nitrogen content (CNC). To evaluate the robustness of the proposed framework, we compared it with other machine learning algorithms. We used 33,600 citrus trees to evaluate the performance of the machine learning models. The random forest algorithm had higher performance in predicting CNC than all models tested, reaching an R2 of 0.90, MAE of 0.341 g&middot;kg&minus;1 and MSE of 0.307 g&middot;kg&minus;1. We demonstrated that our approach is able to reduce the need for chemical analysis of the leaf tissue and optimizes citrus orchard CNC monitoring.
KW  - UAV multispectral imagery
KW  - spectral vegetation indices
KW  - machine learning
KW  - plant nutrition
DO  - 10.3390/rs11242925
ER  -
TY  - EJOU
AU  - Natarajan, Sijesh
AU  - Basnayake, Jayampathi
AU  - Wei, Xianming
AU  - Lakshmanan, Prakash
TI  - High-Throughput Phenotyping of Indirect Traits for Early-Stage Selection in Sugarcane Breeding
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 24
SN  - 2072-4292

AB  - One of the major limitations for sugarcane genetic improvement is the low heritability of yield in the early stages of breeding, mainly due to confounding inter-plot competition effects. In this study, we investigate an indirect selection index (Si), developed based on traits correlated to yield (indirect traits) that were measured using an unmanned aerial vehicle (UAV), to improve clonal assessment in early stages of sugarcane breeding. A single-row early-stage clonal assessment trial, involving 2134 progenies derived from 245 crosses, and a multi-row experiment representative of pure-stand conditions, with an unrelated population of 40 genotypes, were used in this study. Both experiments were screened at several stages using visual, multispectral, and thermal sensors mounted on a UAV for indirect traits, including canopy cover, canopy height, canopy temperature, and normalised difference vegetation index (NDVI). To construct the indirect selection index, phenotypic and genotypic variance-covariances were estimated in the single-row and multi-row experiment, respectively. Clonal selection from the indirect selection index was compared to single-row yield-based selection. Ground observations of stalk number and plant height at six months after planting made from a subset of 75 clones within the single-row experiment were highly correlated to canopy cover (rg = 0.72) and canopy height (rg = 0.69), respectively. The indirect traits had high heritability and strong genetic correlation with cane yield in both the single-row and multi-row experiments. Only 45% of the clones were common between the indirect selection index and single-row yield based selection, and the expected efficiency of correlated response to selection for pure-stand yield based on indirect traits (44%&ndash;73%) was higher than that based on single-row yield (45%). These results highlight the potential of high-throughput phenotyping of indirect traits combined in an indirect selection index for improving early-stage clonal selections in sugarcane breeding.
KW  - inter-plot competition
KW  - indirect selection index
KW  - UAV
KW  - plant breeding
KW  - canopy temperature
DO  - 10.3390/rs11242952
ER  -
TY  - EJOU
AU  - Barbedo, Jayme G.
AU  - Koenigkan, Luciano V.
AU  - Santos, Thiago T.
AU  - Santos, Patrícia M.
TI  - A Study on the Detection of Cattle in UAV Images Using Deep Learning
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 24
SN  - 1424-8220

AB  - Unmanned aerial vehicles (UAVs) are being increasingly viewed as valuable tools to aid the management of farms. This kind of technology can be particularly useful in the context of extensive cattle farming, as production areas tend to be expansive and animals tend to be more loosely monitored. With the advent of deep learning, and convolutional neural networks (CNNs) in particular, extracting relevant information from aerial images has become more effective. Despite the technological advancements in drone, imaging and machine learning technologies, the application of UAVs for cattle monitoring is far from being thoroughly studied, with many research gaps still remaining. In this context, the objectives of this study were threefold: (1) to determine the highest possible accuracy that could be achieved in the detection of animals of the Canchim breed, which is visually similar to the Nelore breed (Bos taurus indicus); (2) to determine the ideal ground sample distance (GSD) for animal detection; (3) to determine the most accurate CNN architecture for this specific problem. The experiments involved 1853 images containing 8629 samples of animals, and 15 different CNN architectures were tested. A total of 900 models were trained (15 CNN architectures &times; 3 spacial resolutions &times; 2 datasets &times; 10-fold cross validation), allowing for a deep analysis of the several aspects that impact the detection of cattle using aerial images captured using UAVs. Results revealed that many CNN architectures are robust enough to reliably detect animals in aerial images even under far from ideal conditions, indicating the viability of using UAVs for cattle monitoring.
KW  - unmanned aerial vehicles
KW  - drones
KW  - canchim breed
KW  - nelore breed
KW  - convolutional neural networks
DO  - 10.3390/s19245436
ER  -
TY  - EJOU
AU  - Siebring, Jasper
AU  - Valente, João
AU  - Domingues Franceschini, Marston H.
AU  - Kamp, Jan
AU  - Kooistra, Lammert
TI  - Object-Based Image Analysis Applied to Low Altitude Aerial Imagery for Potato Plant Trait Retrieval and Pathogen Detection
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 24
SN  - 1424-8220

AB  - There is a growing demand in both food quality and quantity, but as of now, one-third of all food produced for human consumption is lost due to pests and other pathogens accounting for roughly 40% of pre-harvest loss in potatoes. Pathogens in potato plants, like the Erwinia bacteria and the PVYNTN virus for example, exhibit symptoms of varying severity that are not easily captured by pixel-based classes (as these ignore shape, texture, and context in general). The aim of this research is to develop an object-based image analysis (OBIA) method for trait retrieval of individual potato plants that maximizes information output from Unmanned Aerial Vehicle (UAV) RGB very high resolution (VHR) imagery and its derivatives, to be used for disease detection of the Solanum tuberosum. The approach proposed can be split in two steps: (1) object-based mapping of potato plants using an optimized implementation of large scale mean-shift segmentation (LSMSS), and (2) classification of disease using a random forest (RF) model for a set of morphological traits computed from their associative objects. The approach was proven viable as the associative RF model detected presence of Erwinia and PVY pathogens with a maximum F1 score of 0.75 and an average Matthews Correlation Coefficient (MCC) score of 0.47. It also shows that low-altitude imagery acquired with a commercial UAV is a viable off-the-shelf tool for precision farming, and potato pathogen detection.
KW  - OBIA
KW  - VHR
KW  - erwinia bacteria
KW  - PVY virus
KW  - disease detection
KW  - color spaces
DO  - 10.3390/s19245477
ER  -
TY  - EJOU
AU  - Wubben, Jamie
AU  - Fabra, Francisco
AU  - Calafate, Carlos T.
AU  - Krzeszowski, Tomasz
AU  - Marquez-Barja, Johann M.
AU  - Cano, Juan-Carlos
AU  - Manzoni, Pietro
TI  - Accurate Landing of Unmanned Aerial Vehicles Using Ground Pattern Recognition
T2  - Electronics

PY  - 2019
VL  - 8
IS  - 12
SN  - 2079-9292

AB  - Over the last few years, several researchers have been developing protocols and applications in order to autonomously land unmanned aerial vehicles (UAVs). However, most of the proposed protocols rely on expensive equipment or do not satisfy the high precision needs of some UAV applications such as package retrieval and delivery or the compact landing of UAV swarms. Therefore, in this work, a solution for high precision landing based on the use of ArUco markers is presented. In the proposed solution, a UAV equipped with a low-cost camera is able to detect ArUco markers sized     56 &times; 56     cm from an altitude of up to 30 m. Once the marker is detected, the UAV changes its flight behavior in order to land on the exact position where the marker is located. The proposal was evaluated and validated using both the ArduSim simulation platform and real UAV flights. The results show an average offset of only 11 cm from the target position, which vastly improves the landing accuracy compared to the traditional GPS-based landing, which typically deviates from the intended target by 1 to 3 m.
KW  - UAV
KW  - autonomous landing
KW  - vision-based
KW  - ArduSim
KW  - ArUco marker
DO  - 10.3390/electronics8121532
ER  -
TY  - EJOU
AU  - Abbas, Syed M.
AU  - Aslam, Salman
AU  - Berns, Karsten
AU  - Muhammad, Abubakr
TI  - Analysis and Improvements in AprilTag Based State Estimation
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 24
SN  - 1424-8220

AB  - In this paper, we analyzed the accuracy and precision of AprilTag as a visual fiducial marker in detail. We have analyzed error propagation along two horizontal axes along with the effect of angular rotation about the vertical axis. We have identified that the angular rotation of the camera (yaw angle) about its vertical axis is the primary source of error that decreases the precision to the point where the marker system is not potentially viable for sub-decimeter precise tasks. Other factors are the distance and viewing angle of the camera from the AprilTag. Based on these observations, three improvement steps have been proposed. One is the trigonometric correction of the yaw angle to point the camera towards the center of the tag. Second, the use of a custom-built yaw-axis gimbal, which tracks the center of the tag in real-time. Third, we have presented for the first time a pose-indexed probabilistic sensor error model of the AprilTag using a Gaussian Processes based regression of experimental data, validated by particle filter tracking. Our proposed approach, which can be deployed with all three improvement steps, increases the system&rsquo;s overall accuracy and precision by manifolds with a slight trade-off with execution time over commonly available AprilTag library. These proposed improvements make AprilTag suitable to be used as precision localization systems for outdoor and indoor applications.
KW  - robot sensing and perception
KW  - sensor modelling
KW  - localization
DO  - 10.3390/s19245480
ER  -
TY  - EJOU
AU  - Hadavandsiri, Zahra
AU  - Lichti, Derek D.
AU  - Jahraus, Adam
AU  - Jarron, David
TI  - Concrete Preliminary Damage Inspection by Classification of Terrestrial Laser Scanner Point Clouds through Systematic Threshold Definition
T2  - ISPRS International Journal of Geo-Information

PY  - 2019
VL  - 8
IS  - 12
SN  - 2220-9964

AB  - This paper presents a novel approach for automatic, preliminary detection of damage in concrete structures using ground-based terrestrial laser scanners. The method is based on computation of defect-sensitive features such as the surface curvature, since the surface roughness changes strongly if an area is affected by damage. A robust version of principal component analysis (PCA) classification is proposed to distinguish between structural damage and outliers present in the laser scanning data. Numerical simulations were conducted to develop a systematic point-wise defect classifier that automatically diagnoses the location of superficial damage on the investigated region. The method provides a complete picture of the surface health of concrete structures. It has been tested on two real datasets: a concrete heritage aqueduct in Brooks, Alberta, Canada; and a civil pedestrian concrete structure. The experiment results demonstrate the validity and accuracy of the proposed systematic framework for detecting and localizing areas of damage as small as 1 cm or less.
KW  - structural damage assessment
KW  - TLS
KW  - automatic damage classification
KW  - robust PCA
KW  - systematic threshold
DO  - 10.3390/ijgi8120585
ER  -
TY  - EJOU
AU  - Ahn, Hyojung
AU  - Choi, Han-Lim
AU  - Kang, Minguk
AU  - Moon, SungTae
TI  - Learning-Based Anomaly Detection and Monitoring for Swarm Drone Flights
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 24
SN  - 2076-3417

AB  - This paper addresses anomaly detection and monitoring for swarm drone flights. While the current practice of swarm flight typically relies on the operator&rsquo;s naked eyes to monitor health of the multiple vehicles, this work proposes a machine learning-based framework to enable detection of abnormal behavior of a large number of flying drones on the fly. The method works in two steps: a sequence of two unsupervised learning procedures reduces the dimensionality of the real flight test data and labels them as normal and abnormal cases; then, a deep neural network classifier with one-dimensional convolution layers followed by fully connected multi-layer perceptron extracts the associated features and distinguishes the anomaly from normal conditions. The proposed anomaly detection scheme is validated on the real flight test data, highlighting its capability of online implementation.
KW  - swarm drone
KW  - anomaly detection
KW  - clustering
KW  - labeling
KW  - classification
DO  - 10.3390/app9245477
ER  -
TY  - EJOU
AU  - Jenal, Alexander
AU  - Bareth, Georg
AU  - Bolten, Andreas
AU  - Kneer, Caspar
AU  - Weber, Immanuel
AU  - Bongartz, Jens
TI  - Development of a VNIR/SWIR Multispectral Imaging System for Vegetation Monitoring with Unmanned Aerial Vehicles
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 24
SN  - 1424-8220

AB  - Short-wave infrared (SWIR) imaging systems with unmanned aerial vehicles (UAVs) are rarely used for remote sensing applications, like for vegetation monitoring. The reasons are that in the past, sensor systems covering the SWIR range were too expensive, too heavy, or not performing well enough, as, in contrast, it is the case in the visible and near-infrared range (VNIR). Therefore, our main objective is the development of a novel modular two-channel multispectral imaging system with a broad spectral sensitivity from the visible to the short-wave infrared spectrum (approx. 400 nm to 1700 nm) that is compact, lightweight and energy-efficient enough for UAV-based remote sensing applications. Various established vegetation indices (VIs) for mapping vegetation traits can then be set up by selecting any suitable filter combination. The study describes the selection of the individual components, starting with suitable camera modules, the optical as well as the control and storage parts. Special bandpass filters are used to select the desired wavelengths to be captured. A unique flange system has been developed, which also allows the filters to be interchanged quickly in order to adapt the system to a new application in a short time. The characterization of the system was performed in the laboratory with an integrating sphere and a climatic chamber. Finally, the integration of the novel modular VNIR/SWIR imaging system into a UAV and a subsequent first outdoor test flight, in which the functionality was tested, are described.
KW  - short-wave infrared (SWIR)
KW  - visible (VIS)
KW  - near-infrared (NIR)
KW  - remote sensing
KW  - unmanned aerial vehicle (UAV)
KW  - multispectral
KW  - precision agriculture
KW  - phenotyping
KW  - forestry
KW  - vegetation
DO  - 10.3390/s19245507
ER  -
TY  - EJOU
AU  - Yang, Shengtian
AU  - Wang, Juan
AU  - Wang, Pengfei
AU  - Gong, Tongliang
AU  - Liu, Huiping
TI  - Low Altitude Unmanned Aerial Vehicles (UAVs) and Satellite Remote Sensing Are Used to Calculated River Discharge Attenuation Coefficients of Ungauged Catchments in Arid Desert
T2  - Water

PY  - 2019
VL  - 11
IS  - 12
SN  - 2073-4441

AB  - The arid desert ecosystem is very fragile, and the change of its river discharge has a direct impact on irrigation and natural environment. River discharge attenuation coefficients is a key index to reveal the stability of desert river ecosystem. However, due to the harsh conditions in desert areas, it is difficult to establish a hydrological station to obtain data and calculate the attenuation coefficients, so it is urgent to develop new methods to master the attenuation coefficients of rivers. In this study, Taklamakan desert river was selected as the research area, and the river discharge of the desert river were estimated by combining low-altitude UAV and satellite remote sensing technology, so as to calculate the attenuation status of the river in its natural state. Combined with satellite remote sensing, the surface runoff in the desert reaches of the Hotan River from 1993 to 2017 were estimated. The results showed that the base of runoff attenuation in the lower reaches of the Hotan River is 40%. Coupled UAV and satellite remote sensing technology can provide technical support for the study of surface runoff in desert rivers within ungauged basins. Using UAV and satellite remote sensing can monitor surface runoff effectively providing important reference for river discharge monitoring in ungauged catchments.
KW  - desert river
KW  - attenuation coefficients
KW  - ungauged basin
KW  - unmanned aerial vehicle (UAV)
KW  - satellite remote sensing
DO  - 10.3390/w11122633
ER  -
TY  - EJOU
AU  - Zhao, Licheng
AU  - Shi, Yun
AU  - Liu, Bin
AU  - Hovis, Ciara
AU  - Duan, Yulin
AU  - Shi, Zhongchao
TI  - Finer Classification of Crops by Fusing UAV Images and Sentinel-2A Data
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 24
SN  - 2072-4292

AB  - Accurate crop distribution maps provide important information for crop censuses, yield monitoring and agricultural insurance assessments. Most existing studies apply low spatial resolution satellite images for crop distribution mapping, even in areas with a fragmented landscape. Unmanned aerial vehicle (UAV) imagery provides an alternative imagery source for crop mapping, yet its spectral resolution is usually lower than satellite images. In order to produce more accurate maps without losing any spatial heterogeneity (e.g., the physical boundary of land parcel), this study fuses Sentinel-2A and UAV images to map crop distribution at a finer spatial scale (i.e., land parcel scale) in an experimental site with various cropping patterns in Heilongjiang Province, Northeast China. Using a random forest algorithm, the original, as well as the fused images, are classified into 10 categories: rice, corn, soybean, buckwheat, other vegetations, greenhouses, bare land, water, roads and houses. In addition, we test the effect of UAV image choice by fusing Sentinel-2A with different UAV images at multiples spatial resolutions: 0.03 m, 0.10 m, 0.50 m, 1.00 m and 3.00 m. Overall, the fused images achieved higher classification accuracies, ranging between 10.58% and 16.39%, than the original images. However, the fused image based on the finest UAV image (i.e., 0.03 m) does not result in the highest accuracy. Instead, the 0.10 m spatial resolution UAV image produced the most accurate map. When the spatial resolution is less than 0.10 m, accuracy decreases gradually as spatial resolution decreases. The results of this paper not only indicate the possibility of combining satellite images and UAV images for land parcel level crop mapping for fragmented landscapes, but it also implies a potential scheme to exploit optimal choice of spatial resolution in fusing UAV images and Sentinel-2A, with little to no adverse side-effects.
KW  - Sentinel-2A
KW  - UAV
KW  - image fusion
KW  - classification
KW  - random forests
KW  - resolution
DO  - 10.3390/rs11243012
ER  -
TY  - EJOU
AU  - Cao, Dongju
AU  - Yang, Wendong
AU  - Xu, Gangyi
TI  - Joint Trajectory and Communication Design for Buffer-Aided Multi-UAV Relaying Networks
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 24
SN  - 2076-3417

AB  - With the rapid development and evolvement of unmanned aerial vehicle (UAV) technology, UAV aided wireless communication technology has been widely studied recently. In this paper, a buffer aided multi-UAV relaying network is investigated to assist blocked ground communication. According to the mobility and implementation flexibility of UAV relays, it is assumed that the communication link between air-to-ground is the Rician fading channel. On the basis of information causality, we derive the state change of the information in the buffer of UAV relays and maximize the end-to-end average throughput by join the relay selection, UAV transmit power, and UAV trajectory optimization. However, the considered problem is a mixed integer non-convex optimization problem, and therefore, it is difficult to solve directly with general optimization methods. In order to make the problem tractable, an efficient iterative algorithm based on the block coordinate descent and the successive convex optimization techniques is proposed. The convergence of the proposed algorithm will be verified analytically at the end of this paper. The simulation results show that by alternately optimizing the relay selection, UAV transmit power, and UAV trajectory, the proposed algorithm is able to achieve convergence quickly and significantly improve the average throughput, as compared to other benchmark schemes.
KW  - UAV relay
KW  - buffer aided
KW  - average throughput
KW  - relay selection
KW  - UAV trajectory
KW  - transmit power
DO  - 10.3390/app9245524
ER  -
TY  - EJOU
AU  - Chen, Yayong
AU  - Hou, Chaojun
AU  - Tang, Yu
AU  - Zhuang, Jiajun
AU  - Lin, Jintian
AU  - He, Yong
AU  - Guo, Qiwei
AU  - Zhong, Zhenyu
AU  - Lei, Huan
AU  - Luo, Shaoming
TI  - Citrus Tree Segmentation from UAV Images Based on Monocular Machine Vision in a Natural Orchard Environment
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 24
SN  - 1424-8220

AB  - The segmentation of citrus trees in a natural orchard environment is a key technology for achieving the fully autonomous operation of agricultural unmanned aerial vehicles (UAVs). Therefore, a tree segmentation method based on monocular machine vision technology and a support vector machine (SVM) algorithm are proposed in this paper to segment citrus trees precisely under different brightness and weed coverage conditions. To reduce the sensitivity to environmental brightness, a selective illumination histogram equalization method was developed to compensate for the illumination, thereby improving the brightness contrast for the foreground without changing its hue and saturation. To accurately differentiate fruit trees from different weed coverage backgrounds, a chromatic aberration segmentation algorithm and the Otsu threshold method were combined to extract potential fruit tree regions. Then, 14 color features, five statistical texture features, and local binary pattern features of those regions were calculated to establish an SVM segmentation model. The proposed method was verified on a dataset with different brightness and weed coverage conditions, and the results show that the citrus tree segmentation accuracy reached 85.27% &plusmn; 9.43%; thus, the proposed method achieved better performance than two similar methods.
KW  - agricultural unmanned aerial vehicles
KW  - monocular computer vision
KW  - tree crown segmentation
KW  - circumstance brightness
KW  - weed environment orchard
DO  - 10.3390/s19245558
ER  -
TY  - EJOU
AU  - Khan, Muhammad F.
AU  - Yau, Kok-Lim A.
AU  - Noor, Rafidah M.
AU  - Imran, Muhammad A.
TI  - Routing Schemes in FANETs: A Survey
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 1
SN  - 1424-8220

AB  - Flying ad hoc network (FANET) is a self-organizing wireless network that enables inexpensive, flexible, and easy-to-deploy flying nodes, such as unmanned aerial vehicles (UAVs), to communicate among themselves in the absence of fixed network infrastructure. FANET is one of the emerging networks that has an extensive range of next-generation applications. Hence, FANET plays a significant role in achieving application-based goals. Routing enables the flying nodes to collaborate and coordinate among themselves and to establish routes to radio access infrastructure, particularly FANET base station (BS). With a longer route lifetime, the effects of link disconnections and network partitions reduce. Routing must cater to two main characteristics of FANETs that reduce the route lifetime. Firstly, the collaboration nature requires the flying nodes to exchange messages and to coordinate among themselves, causing high energy consumption. Secondly, the mobility pattern of the flying nodes is highly dynamic in a three-dimensional space and they may be spaced far apart, causing link disconnection. In this paper, we present a comprehensive survey of the limited research work of routing schemes in FANETs. Different aspects, including objectives, challenges, routing metrics, characteristics, and performance measures, are covered. Furthermore, we present open issues.
KW  - ad hoc networks
KW  - FANETs
KW  - routing
KW  - network topology
DO  - 10.3390/s20010038
ER  -
TY  - EJOU
AU  - Angel, Yoseline
AU  - Turner, Darren
AU  - Parkes, Stephen
AU  - Malbeteau, Yoann
AU  - Lucieer, Arko
AU  - McCabe, Matthew F.
TI  - Automated Georectification and Mosaicking of UAV-Based Hyperspectral Imagery from Push-Broom Sensors
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 1
SN  - 2072-4292

AB  - Hyperspectral systems integrated on unmanned aerial vehicles (UAV) provide unique opportunities to conduct high-resolution multitemporal spectral analysis for diverse applications. However, additional time-consuming rectification efforts in postprocessing are routinely required, since geometric distortions can be introduced due to UAV movements during flight, even if navigation/motion sensors are used to track the position of each scan. Part of the challenge in obtaining high-quality imagery relates to the lack of a fast processing workflow that can retrieve geometrically accurate mosaics while optimizing the ground data collection efforts. To address this problem, we explored a computationally robust automated georectification and mosaicking methodology. It operates effectively in a parallel computing environment and evaluates results against a number of high-spatial-resolution datasets (mm to cm resolution) collected using a push-broom sensor and an associated RGB frame-based camera. The methodology estimates the luminance of the hyperspectral swaths and coregisters these against a luminance RGB-based orthophoto. The procedure includes an improved coregistration strategy by integrating the Speeded-Up Robust Features (SURF) algorithm, with the Maximum Likelihood Estimator Sample Consensus (MLESAC) approach. SURF identifies common features between each swath and the RGB-orthomosaic, while MLESAC fits the best geometric transformation model to the retrieved matches. Individual scanlines are then geometrically transformed and merged into a single spatially continuous mosaic reaching high positional accuracies only with a few number of ground control points (GCPs). The capacity of the workflow to achieve high spatial accuracy was demonstrated by examining statistical metrics such as RMSE, MAE, and the relative positional accuracy at 95% confidence level. Comparison against a user-generated georectification demonstrates that the automated approach speeds up the coregistration process by 85%.
KW  - georectification
KW  - mosaicking
KW  - push-broom
KW  - UAV
KW  - hyperspectral imaging
DO  - 10.3390/rs12010034
ER  -
TY  - EJOU
AU  - Halladin-Dąbrowska, Anna
AU  - Kania, Adam
AU  - Kopeć, Dominik
TI  - The t-SNE Algorithm as a Tool to Improve the Quality of Reference Data Used in Accurate Mapping of Heterogeneous Non-Forest Vegetation
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 1
SN  - 2072-4292

AB  - Supervised classification methods, used for many applications, including vegetation mapping require accurate &ldquo;ground truth&rdquo; to be effective. Nevertheless, it is common for the quality of this data to be poorly verified prior to it being used for the training and validation of classification models. The fact that noisy or erroneous parts of the reference dataset are not removed is usually explained by the relatively high resistance of some algorithms to errors. The objective of this study was to demonstrate the rationale for cleaning the reference dataset used for the classification of heterogeneous non-forest vegetation, and to present a workflow based on the t-distributed stochastic neighbor embedding (t-SNE) algorithm for the better integration of reference data with remote sensing data in order to improve outcomes. The proposed analysis is a new application of the t-SNE algorithm. The effectiveness of this workflow was tested by classifying three heterogeneous non-forest Natura 2000 habitats: Molinia meadows (Molinion caeruleae; code 6410), species-rich Nardus grassland (code 6230) and dry heaths (code 4030), employing two commonly used algorithms: random forest (RF) and AdaBoost (AB), which, according to the literature, differ in their resistance to errors in reference datasets. Polygons collected in the field (on-ground reference data) in 2016 and 2017, containing no intentional errors, were used as the on-ground reference dataset. The remote sensing data used in the classification were obtained in 2017 during the peak growing season by a HySpex sensor consisting of two imaging spectrometers covering spectral ranges of 0.4&ndash;0.9 &mu;m (VNIR-1800) and 0.9&ndash;2.5 &mu;m (SWIR-384). The on-ground reference dataset was gradually cleaned by verifying candidate polygons selected by visual interpretation of t-SNE plots. Around 40&ndash;50% of candidate polygons were ultimately found to contain errors. Altogether, 15% of reference polygons were removed. As a result, the quality of the final map, as assessed by the Kappa and F1 accuracy measures as well as by visual evaluation, was significantly improved. The global map accuracy increased by about 6% (in Kappa coefficient), relative to the baseline classification obtained using random removal of the same number of reference polygons.
KW  - data pre-processing
KW  - hyperspectral data
KW  - image classification
KW  - visualization
KW  - dimensionality reduction
KW  - random forest
KW  - Natura 2000
KW  - grassland
DO  - 10.3390/rs12010039
ER  -
TY  - EJOU
AU  - Wang, Tonghua
AU  - Han, Wenting
AU  - Zhang, Mengfei
AU  - Yao, Xiaomin
AU  - Zhang, Liyuan
AU  - Peng, Xingshuo
AU  - Li, Chaoqun
AU  - Dan, Xvjia
TI  - Unmanned Aerial Vehicle-Borne Sensor System for Atmosphere-Particulate-Matter Measurements: Design and Experiments
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 1
SN  - 1424-8220

AB  - An unmanned aerial vehicle (UAV) particulate-matter (PM) monitoring system was developed that can perform three-dimensional stereoscopic observation of PM2.5 and PM10 in the atmosphere. The UAV monitoring system was mainly integrated by modules of data acquisition and processing, wireless data transmission, and global positioning system (GPS). Particularly, in this study, a ground measurement-control subsystem was added that can display and store collected data in real time and set up measurement scenarios, data-storage modes, and system sampling frequency as needed. The UAV PM monitoring system was calibrated via comparison with a national air-quality monitoring station; the data of both systems were highly correlated. Since rotation of the UAV propeller affects measured PM concentration, this study specifically tested this effect by setting up another identical monitoring system fixed at a tower as reference. The UAV systems worked simultaneously to collect data for comparison. A correction method for the propeller disturbance was proposed. Averaged relative errors for the PM2.5 and PM10 concentrations measured by the two systems were 6.2% and 6.6%, respectively, implying that the UAV system could be used for monitoring PM in an atmosphere environment.
KW  - PM2.5
KW  - PM10
KW  - autonomy and selectivity
KW  - three-dimensional stereoscopic monitoring
KW  - propeller disturbance
KW  - environmental monitoring
DO  - 10.3390/s20010057
ER  -
TY  - EJOU
AU  - Brooke, Christopher
AU  - Clutterbuck, Ben
TI  - Mapping Heterogeneous Buried Archaeological Features Using Multisensor Data from Unmanned Aerial Vehicles
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 1
SN  - 2072-4292

AB  - There is a long history of the use of aerial imagery for archaeological research, but the application of multisensor image data has only recently been facilitated by the development of unmanned aerial vehicles (UAVs). Two archaeological sites in the East Midlands U.K. that differ in age and topography were selected for survey using multisensor imaging from a fixed-wing UAV. The aim of this study was to determine optimum methodology for the use of UAVs in examining archaeological sites that have no obvious surface features and examine issues of ground control target design, thermal effects, image processing and advanced filtration. The information derived from the range of sensors used in this study enabled interpretation of buried archaeology at both sites. For any archaeological survey using UAVs, the acquisition of visible colour (RGB), multispectral, and thermal imagery as a minimum are advised, as no single technique is sufficient to attempt to reveal the maximum amount of potential information.
KW  - multisensor
KW  - ground control
KW  - random forest
KW  - thermal
KW  - multispectral
KW  - archaeology
KW  - UAV
DO  - 10.3390/rs12010041
ER  -
TY  - EJOU
AU  - de Castro, Ana I.
AU  - Peña, José M.
AU  - Torres-Sánchez, Jorge
AU  - Jiménez-Brenes, Francisco M.
AU  - Valencia-Gredilla, Francisco
AU  - Recasens, Jordi
AU  - López-Granados, Francisca
TI  - Mapping Cynodon Dactylon Infesting Cover Crops with an Automatic Decision Tree-OBIA Procedure and UAV Imagery for Precision Viticulture
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 1
SN  - 2072-4292

AB  - The establishment and management of cover crops are common practices widely used in irrigated viticulture around the world, as they bring great benefits not only to protect and improve the soil, but also to control vine vigor and improve the yield quality, among others. However, these benefits are often reduced when cover crops are infested by Cynodon dactylon (bermudagrass), which impacts crop production due to its competition for water and nutrients and causes important economic losses for the winegrowers. Therefore, the discrimination of Cynodon dactylon in cover crops would enable site-specific control to be applied and thus drastically mitigate damage to the vineyard. In this context, this research proposes a novel, automatic and robust image analysis algorithm for the quick and accurate mapping of Cynodon dactylon growing in vineyard cover crops. The algorithm was developed using aerial images taken with an Unmanned Aerial Vehicle (UAV) and combined decision tree (DT) and object-based image analysis (OBIA) approaches. The relevance of this work consisted in dealing with the constraint caused by the spectral similarity of these complex scenarios formed by vines, cover crops, Cynodon dactylon, and bare soil. The incorporation of height information from the Digital Surface Model and several features selected by machine learning tools in the DT-OBIA algorithm solved this spectral similarity limitation and allowed the precise design of Cynodon dactylon maps. Another contribution of this work is the short time needed to apply the full process from UAV flights to image analysis, which can enable useful maps to be created on demand (within two days of the farmer&acute;s request) and is thus timely for controlling Cynodon dactylon in the herbicide application window. Therefore, this combination of UAV imagery and a DT-OBIA algorithm would allow winegrowers to apply site-specific control of Cynodon dactylon and maintain cover crop-based management systems and their consequent benefits in the vineyards, and also comply with the European legal framework for the sustainable use of agricultural inputs and implementation of integrated crop management.
KW  - site-specific weed management
KW  - object-based image analysis (OBIA)
KW  - bermudagrass
KW  - vineyard
KW  - vegetation mapping
KW  - unmanned aerial vehicle
KW  - machine learning
DO  - 10.3390/rs12010056
ER  -
TY  - EJOU
AU  - Laso, Francisco J.
AU  - Benítez, Fátima L.
AU  - Rivas-Torres, Gonzalo
AU  - Sampedro, Carolina
AU  - Arce-Nazario, Javier
TI  - Land Cover Classification of Complex Agroecosystems in the Non-Protected Highlands of the Galapagos Islands
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 1
SN  - 2072-4292

AB  - The humid highlands of the Galapagos are the islands&rsquo; most biologically productive regions and a key habitat for endemic animal and plant species. These areas are crucial for the region&rsquo;s food security and for the control of invasive plants, but little is known about the spatial distribution of its land cover. We generated a baseline high-resolution land cover map of the agricultural zones and their surrounding protected areas. We combined the high spatial resolution of PlanetScope images with the high spectral resolution of Sentinel-2 images in an object-based classification using a RandomForest algorithm. We used images collected with an unmanned aerial vehicle (UAV) to verify and validate our classified map. Despite the astounding diversity and heterogeneity of the highland landscape, our classification yielded useful results (overall Kappa: 0.7, R2: 0.69) and revealed that across all four inhabited islands, invasive plants cover the largest fraction (28.5%) of the agricultural area, followed by pastures (22.3%), native vegetation (18.6%), food crops (18.3%), and mixed forest and pioneer plants (11.6%). Our results are consistent with historical trajectories of colonization and abandonment of the highlands. The produced dataset is designed to suit the needs of practitioners of both conservation and agriculture and aims to foster collaboration between the two areas.
KW  - agriculture
KW  - conservation
KW  - galapagos
KW  - image fusion
KW  - invasive species
KW  - land cover
KW  - planetscope
KW  - random forest
KW  - sentinel-2
KW  - uav
DO  - 10.3390/rs12010065
ER  -
TY  - EJOU
AU  - Cao, Lin
AU  - Liu, Yunxiao
AU  - Wang, Dongfeng
AU  - Wang, Tao
AU  - Fu, Chong
TI  - A Novel Density Peak Fuzzy Clustering Algorithm for Moving Vehicles Using Traffic Radar
T2  - Electronics

PY  - 2020
VL  - 9
IS  - 1
SN  - 2079-9292

AB  - The detection of adjacent vehicles in highway scenes has the problem of inaccurate clustering results. In order to solve this problem, this paper proposes a new clustering algorithm, namely Spindle-based Density Peak Fuzzy Clustering (SDPFC) algorithm. Its main feature is to use the density peak clustering algorithm to perform initial clustering to obtain the number of clusters and the cluster center of each cluster. The final clustering result is obtained by a fuzzy clustering algorithm based on the spindle update. The experimental data are the radar echo signal collected in the real highway scenes. Compared with the DBSCAN, FCM, and K-Means algorithms, the algorithm has higher clustering accuracy in certain scenes. The average clustering accuracy of SDPFC can reach more than 95%. It is also proved that the proposed algorithm has strong robustness in certain highway scenes.
KW  - fuzzy clustering
KW  - spindle update
KW  - radar echo signal
KW  - highway scenes
DO  - 10.3390/electronics9010046
ER  -
TY  - EJOU
AU  - Pytka, Jaroslaw
AU  - Budzyński, Piotr
AU  - Łyszczyk, Tomasz
AU  - Józwik, Jerzy
AU  - Michałowska, Joanna
AU  - Tofil, Arkadiusz
AU  - Błażejczak, Dariusz
AU  - Laskowski, Jan
TI  - Determining Wheel Forces and Moments on Aircraft Landing Gear with a Dynamometer Sensor
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 1
SN  - 1424-8220

AB  - This paper describes airfield measurement of forces and moments that act on a landing gear wheel. For the measurement, a wheel force sensor was used. The sensor was designed and built based on strain gage technology and was embedded in the left landing gear wheel of a test aircraft. The sensor is capable of measuring simultaneously three perpendicular forces and three moments and sends data to a handheld device wirelessly. For the airfield tests, the sensor was installed on a PZL 104 Wilga 35A multipurpose aircraft. The aircraft was towed at a &ldquo;marching man&rdquo; speed and the measurements were performed at three driving modes: Free rolling, braking, and turning. The paper contains results obtained in the field measurements performed on a grassy runway of the Rzesz&oacute;w Jasionka Aerodrome, Poland. Rolling resistance of aircraft tire, braking friction, as well as aligning moment were analyzed and discussed with respect to surface conditions.
KW  - airfield performance
KW  - landing gear
KW  - wheel
KW  - force and moment measurement
KW  - strain gage
KW  - wheel force sensor
KW  - wireless data transfer
KW  - grassy airfield
KW  - GARFIELD System
DO  - 10.3390/s20010227
ER  -
TY  - EJOU
AU  - Wijesingha, Jayan
AU  - Astor, Thomas
AU  - Schulze-Brüninghoff, Damian
AU  - Wengert, Matthias
AU  - Wachendorf, Michael
TI  - Predicting Forage Quality of Grasslands Using UAV-Borne Imaging Spectroscopy
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 1
SN  - 2072-4292

AB  - The timely knowledge of forage quality of grasslands is vital for matching the demands in animal feeding. Remote sensing (RS) is a promising tool for estimating field-scale forage quality compared with traditional methods, which usually do not provide equally detailed information. However, the applicability of RS prediction models depends on the variability of the underlying calibration data, which can be brought about by the inclusion of a multitude of grassland types and management practices in the model development. Major aims of this study were (i) to build forage quality estimation models for multiple grassland types based on an unmanned aerial vehicle (UAV)-borne imaging spectroscopy and (ii) to generate forage quality distribution maps using the best models obtained. The study examined data from eight grasslands in northern Hesse, Germany, which largely differed in terms of vegetation type and cutting regime. The UAV with a hyperspectral camera on board was utilised to acquire spectral images from the grasslands, and crude protein (CP) and acid detergent fibre (ADF) concentration of the forage was assessed at each cut. Five predictive modelling regression algorithms were applied to develop quality estimation models. Further, grassland forage quality distribution maps were created using the best models developed. The normalised spectral reflectance data showed the strongest relationship with both CP and ADF concentration. From all predictive algorithms, support vector regression provided the highest precision and accuracy for CP estimation (median normalised root mean square error prediction (nRMSEp) = 10.6%), while cubist regression model proved best for ADF estimation (median nRMSEp = 13.4%). The maps generated for both CP and ADF showed a distinct spatial variation in forage quality values for the different grasslands and cutting regimes. Overall, the results disclose that UAV-borne imaging spectroscopy, in combination with predictive modelling, provides a promising tool for accurate forage quality estimation of multiple grasslands.
KW  - unmanned aerial vehicle
KW  - hyperspectral
KW  - grassland
KW  - crude protein
KW  - acid detergent fibre
KW  - predictive modelling
DO  - 10.3390/rs12010126
ER  -
TY  - EJOU
AU  - Dong, Xinyu
AU  - Zhang, Zhichao
AU  - Yu, Ruiyang
AU  - Tian, Qingjiu
AU  - Zhu, Xicun
TI  - Extraction of Information about Individual Trees from High-Spatial-Resolution UAV-Acquired Images of an Orchard
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 1
SN  - 2072-4292

AB  - The extraction of information about individual trees is essential to supporting the growing of fruit in orchard management. Data acquired from spectral sensors mounted on unmanned aerial vehicles (UAVs) have very high spatial and temporal resolution. However, an efficient and reliable method for extracting information about individual trees with irregular tree-crown shapes and a complicated background is lacking. In this study, we developed and tested the performance of an approach, based on UAV imagery, to extracting information about individual trees in an orchard with a complicated background that includes apple trees (Plot 1) and pear trees (Plot 2). The workflow involves the construction of a digital orthophoto map (DOM), digital surface models (DSMs), and digital terrain models (DTMs) using the Structure from Motion (SfM) and Multi-View Stereo (MVS) approaches, as well as the calculation of the Excess Green minus Excess Red Index (ExGR) and the selection of various thresholds. Furthermore, a local-maxima filter method and marker-controlled watershed segmentation were used for the detection and delineation, respectively, of individual trees. The accuracy of the proposed method was evaluated by comparing its results with manual estimates of the numbers of trees and the areas and diameters of tree-crowns, all three of which parameters were obtained from the DOM. The results of the proposed method are in good agreement with these manual estimates: The F-scores for the estimated numbers of individual trees were 99.0% and 99.3% in Plot 1 and Plot 2, respectively, while the Producer&rsquo;s Accuracy (PA) and User&rsquo;s Accuracy (UA) for the delineation of individual tree-crowns were above 95% for both of the plots. For the area of individual tree-crowns, root-mean-square error (RMSE) values of 0.72 m2 and 0.48 m2 were obtained for Plot 1 and Plot 2, respectively, while for the diameter of individual tree-crowns, RMSE values of 0.39 m and 0.26 m were obtained for Plot 1 (339 trees correctly identified) and Plot 2 (203 trees correctly identified), respectively. Both the areas and diameters of individual tree-crowns were overestimated to varying degrees.
KW  - fruit tree growing
KW  - orchard
KW  - image processing
KW  - remote sensing
KW  - unmanned aerial vehicles
KW  - digital height model
KW  - image segmentation
DO  - 10.3390/rs12010133
ER  -
TY  - EJOU
AU  - Mohamed, Hassan
AU  - Nadaoka, Kazuo
AU  - Nakamura, Takashi
TI  - Towards Benthic Habitat 3D Mapping Using Machine Learning Algorithms and Structures from Motion Photogrammetry
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 1
SN  - 2072-4292

AB  - The accurate classification and 3D mapping of benthic habitats in coastal ecosystems are vital for developing management strategies for these valuable shallow water environments. However, both automatic and semiautomatic approaches for deriving ecologically significant information from a towed video camera system are quite limited. In the current study, we demonstrate a semiautomated framework for high-resolution benthic habitat classification and 3D mapping using Structure from Motion and Multi View Stereo (SfM-MVS) algorithms and automated machine learning classifiers. The semiautomatic classification of benthic habitats was performed using several attributes extracted automatically from labeled examples by a human annotator using raw towed video camera image data. The Bagging of Features (BOF), Hue Saturation Value (HSV), and Gray Level Co-occurrence Matrix (GLCM) methods were used to extract these attributes from 3000 images. Three machine learning classifiers (k-nearest neighbor (k-NN), support vector machine (SVM), and bagging (BAG)) were trained by using these attributes, and their outputs were assembled by the fuzzy majority voting (FMV) algorithm. The correctly classified benthic habitat images were then geo-referenced using a differential global positioning system (DGPS). Finally, SfM-MVS techniques used the resulting classified geo-referenced images to produce high spatial resolution digital terrain models and orthophoto mosaics for each category. The framework was tested for the identification and 3D mapping of seven habitats in a portion of the Shiraho area in Japan. These seven habitats were corals (Acropora and Porites), blue corals (H. coerulea), brown algae, blue algae, soft sand, hard sediments (pebble, cobble, and boulders), and seagrass. Using the FMV algorithm, we achieved an overall accuracy of 93.5% in the semiautomatic classification of the seven habitats.
KW  - machine learning algorithms
KW  - benthic 3D mapping
KW  - towed underwater video camera
KW  - hybrid classifiers
KW  - structure from motion
DO  - 10.3390/rs12010127
ER  -
TY  - EJOU
AU  - Zha, Hainie
AU  - Miao, Yuxin
AU  - Wang, Tiantian
AU  - Li, Yue
AU  - Zhang, Jing
AU  - Sun, Weichao
AU  - Feng, Zhengqi
AU  - Kusnierek, Krzysztof
TI  - Improving Unmanned Aerial Vehicle Remote Sensing-Based Rice Nitrogen Nutrition Index Prediction with Machine Learning
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 2
SN  - 2072-4292

AB  - Optimizing nitrogen (N) management in rice is crucial for China&rsquo;s food security and sustainable agricultural development. Nondestructive crop growth monitoring based on remote sensing technologies can accurately assess crop N status, which may be used to guide the in-season site-specific N recommendations. The fixed-wing unmanned aerial vehicle (UAV)-based remote sensing is a low-cost, easy-to-operate technology for collecting spectral reflectance imagery, an important data source for precision N management. The relationships between many vegetation indices (VIs) derived from spectral reflectance data and crop parameters are known to be nonlinear. As a result, nonlinear machine learning methods have the potential to improve the estimation accuracy. The objective of this study was to evaluate five different approaches for estimating rice (Oryza sativa L.) aboveground biomass (AGB), plant N uptake (PNU), and N nutrition index (NNI) at stem elongation (SE) and heading (HD) stages in Northeast China: (1) single VI (SVI); (2) stepwise multiple linear regression (SMLR); (3) random forest (RF); (4) support vector machine (SVM); and (5) artificial neural networks (ANN) regression. The results indicated that machine learning methods improved the NNI estimation compared to VI-SLR and SMLR methods. The RF algorithm performed the best for estimating NNI (R2 = 0.94 (SE) and 0.96 (HD) for calibration and 0.61 (SE) and 0.79 (HD) for validation). The root mean square errors (RMSEs) were 0.09, and the relative errors were &lt;10% in all the models. It is concluded that the RF machine learning regression can significantly improve the estimation of rice N status using UAV remote sensing. The application machine learning methods offers a new opportunity to better use remote sensing data for monitoring crop growth conditions and guiding precision crop management. More studies are needed to further improve these machine learning-based models by combining both remote sensing data and other related soil, weather, and management information for applications in precision N and crop management.
KW  - fixed-wing UAV remote sensing
KW  - nitrogen status diagnosis
KW  - random forest
KW  - precision nitrogen management
KW  - machine learning
DO  - 10.3390/rs12020215
ER  -
TY  - EJOU
AU  - Zhang, Xiuwei
AU  - Jin, Jiaojiao
AU  - Lan, Zeze
AU  - Li, Chunjiang
AU  - Fan, Minhao
AU  - Wang, Yafei
AU  - Yu, Xin
AU  - Zhang, Yanning
TI  - ICENET: A Semantic Segmentation Deep Network for River Ice by Fusing Positional and Channel-Wise Attentive Features
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 2
SN  - 2072-4292

AB  - River ice monitoring is of great significance for river management, ship navigation and ice hazard forecasting in cold-regions. Accurate ice segmentation is one most important pieces of technology in ice monitoring research. It can provide the prerequisite information for the calculation of ice cover density, drift ice speed, ice cover distribution, change detection and so on. Unmanned aerial vehicle (UAV) aerial photography has the advantages of higher spatial and temporal resolution. As UAV technology has become more popular and cheaper, it has been widely used in ice monitoring. So, we focused on river ice segmentation based on UAV remote sensing images. In this study, the NWPU_YRCC dataset was built for river ice segmentation, in which all images were captured by different UAVs in the region of the Yellow River, the most difficult river to manage in the world. To the best of our knowledge, this is the first public UAV image dataset for river ice segmentation. Meanwhile, a semantic segmentation deep convolution neural network by fusing positional and channel-wise attentive features is proposed for river ice semantic segmentation, named ICENET. Experiments demonstrated that the proposed ICENET outperforms the state-of-the-art methods, achieving a superior result on the NWPU_YRCC dataset.
KW  - river ice
KW  - position attention
KW  - channel-wise attention
KW  - deep convolutional neural network
KW  - semantic segmentation
DO  - 10.3390/rs12020221
ER  -
TY  - EJOU
AU  - Takahashi Miyoshi, Gabriela
AU  - Imai, Nilton N.
AU  - Garcia Tommaselli, Antonio M.
AU  - Antunes de Moraes, Marcus V.
AU  - Honkavaara, Eija
TI  - Evaluation of Hyperspectral Multitemporal Information to Improve Tree Species Identification in the Highly Diverse Atlantic Forest
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 2
SN  - 2072-4292

AB  - The monitoring of forest resources is crucial for their sustainable management, and tree species identification is one of the fundamental tasks in this process. Unmanned aerial vehicles (UAVs) and miniaturized lightweight sensors can rapidly provide accurate monitoring information. The objective of this study was to investigate the use of multitemporal, UAV-based hyperspectral imagery for tree species identification in the highly diverse Brazilian Atlantic forest. Datasets were captured over three years to identify eight different tree species. The study area comprised initial to medium successional stages of the Brazilian Atlantic forest. Images were acquired with a spatial resolution of 10 cm, and radiometric adjustment processing was performed to reduce the variations caused by different factors, such as the geometry of acquisition. The random forest classification method was applied in a region-based classification approach with leave-one-out cross-validation, followed by computing the area under the receiver operating characteristic (AUCROC) curve. When using each dataset alone, the influence of different weather behaviors on tree species identification was evident. When combining all datasets and minimizing illumination differences over each tree crown, the identification of three tree species was improved. These results show that UAV-based, hyperspectral, multitemporal remote sensing imagery is a promising tool for tree species identification in tropical forests.
KW  - tree species classification
KW  - semideciduous forest
KW  - hyperspectral multitemporal information
KW  - UAV
DO  - 10.3390/rs12020244
ER  -
TY  - EJOU
AU  - Senthilnath, J.
AU  - Varia, Neelanshi
AU  - Dokania, Akanksha
AU  - Anand, Gaotham
AU  - Benediktsson, Jón A.
TI  - Deep TEC: Deep Transfer Learning with Ensemble Classifier for Road Extraction from UAV Imagery
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 2
SN  - 2072-4292

AB  - Unmanned aerial vehicle (UAV) remote sensing has a wide area of applications and in this paper, we attempt to address one such problem&mdash;road extraction from UAV-captured RGB images. The key challenge here is to solve the road extraction problem using the UAV multiple remote sensing scene datasets that are acquired with different sensors over different locations. We aim to extract the knowledge from a dataset that is available in the literature and apply this extracted knowledge on our dataset. The paper focuses on a novel method which consists of deep TEC (deep transfer learning with ensemble classifier) for road extraction using UAV imagery. The proposed deep TEC performs road extraction on UAV imagery in two stages, namely, deep transfer learning and ensemble classifier. In the first stage, with the help of deep learning methods, namely, the conditional generative adversarial network, the cycle generative adversarial network and the fully convolutional network, the model is pre-trained on the benchmark UAV road extraction dataset that is available in the literature. With this extracted knowledge (based on the pre-trained model) the road regions are then extracted on our UAV acquired images. Finally, for the road classified images, ensemble classification is carried out. In particular, the deep TEC method has an average quality of 71%, which is 10% higher than the next best standard deep learning methods. Deep TEC also shows a higher level of performance measures such as completeness, correctness and F1 score measures. Therefore, the obtained results show that the deep TEC is efficient in extracting road networks in an urban region.
KW  - UAV
KW  - remote sensing
KW  - road extraction
KW  - deep learning
KW  - transfer learning
KW  - ensemble classifier
DO  - 10.3390/rs12020245
ER  -
TY  - EJOU
AU  - González-Patiño, David
AU  - Villuendas-Rey, Yenny
AU  - Argüelles-Cruz, Amadeo J.
AU  - Camacho-Nieto, Oscar
AU  - Yáñez-Márquez, Cornelio
TI  - AISAC: An Artificial Immune System for Associative Classification Applied to Breast Cancer Detection
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 2
SN  - 2076-3417

AB  - Early breast cancer diagnosis is crucial, as it can prevent further complications and save the life of the patient by treating the disease at its most curable stage. In this paper, we propose a new artificial immune system model for associative classification with competitive performance for breast cancer detection. The proposed model has its foundations in the biological immune system; it mimics the detection skills of the immune system to provide correct identification of antigens. The Wilcoxon test was used to identify the statistically significant differences between our proposal and other classification algorithms based on the same bio-inspired model. These statistical tests evidenced the enhanced performance shown by the proposed model by outperforming other immune-based algorithms. The proposed model proved to be competitive with respect to other well-known classification models. In addition, the model benefits from a low computational cost. The success of this model for classification tasks shows that swarm intelligence is useful for this kind of problem, and that it is not limited to optimization tasks.
KW  - swarm intelligence
KW  - artificial immune systems
KW  - classification
KW  - breast cancer
DO  - 10.3390/app10020515
ER  -
TY  - EJOU
AU  - Cardim Ferreira Lima, Matheus
AU  - Krus, Anne
AU  - Valero, Constantino
AU  - Barrientos, Antonio
AU  - del Cerro, Jaime
AU  - Roldán-Gómez, Juan J.
TI  - Monitoring Plant Status and Fertilization Strategy through Multispectral Images
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 2
SN  - 1424-8220

AB  - A crop monitoring system was developed for the supervision of organic fertilization status on tomato plants at early stages. An automatic and nondestructive approach was used to analyze tomato plants with different levels of water-soluble organic fertilizer (3 + 5 NK) and vermicompost. The evaluation system was composed by a multispectral camera with five lenses: green (550 nm), red (660 nm), red edge (735 nm), near infrared (790 nm), RGB, and a computational image processing system. The water-soluble fertilizer was applied weekly in four different treatments: (T0: 0 mL, T1: 6.25 mL, T2: 12.5 mL and T3: 25 mL) and the vermicomposting was added in Weeks 1 and 5. The trial was conducted in a greenhouse and 192 images were taken with each lens. A plant segmentation algorithm was developed and several vegetation indices were calculated. On top of calculating indices, multiple morphological features were obtained through image processing techniques. The morphological features were revealed to be more feasible to distinguish between the control and the organic fertilized plants than the vegetation indices. The system was developed in order to be assembled in a precision organic fertilization robotic platform.
KW  - multispectral image
KW  - computer vision
KW  - precision agriculture
KW  - vegetation indices
KW  - morphological features
DO  - 10.3390/s20020435
ER  -
TY  - EJOU
AU  - Rokhsaritalemi, Somaiieh
AU  - Sadeghi-Niaraki, Abolghasem
AU  - Choi, Soo-Mi
TI  - A Review on Mixed Reality: Current Trends, Challenges and Prospects
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 2
SN  - 2076-3417

AB  - Currently, new technologies have enabled the design of smart applications that are used as decision-making tools in the problems of daily life. The key issue in designing such an application is the increasing level of user interaction. Mixed reality (MR) is an emerging technology that deals with maximum user interaction in the real world compared to other similar technologies. Developing an MR application is complicated, and depends on the different components that have been addressed in previous literature. In addition to the extraction of such components, a comprehensive study that presents a generic framework comprising all components required to develop MR applications needs to be performed. This review studies intensive research to obtain a comprehensive framework for MR applications. The suggested framework comprises five layers: the first layer considers system components; the second and third layers focus on architectural issues for component integration; the fourth layer is the application layer that executes the architecture; and the fifth layer is the user interface layer that enables user interaction. The merits of this study are as follows: this review can act as a proper resource for MR basic concepts, and it introduces MR development steps and analytical models, a simulation toolkit, system types, and architecture types, in addition to practical issues for stakeholders such as considering MR different domains.
KW  - mixed reality
KW  - review
KW  - trend
KW  - challenge
KW  - future prospect
DO  - 10.3390/app10020636
ER  -
TY  - EJOU
AU  - Jung, Daekyo
AU  - Tran Tuan, Vu
AU  - Quoc Tran, Dai
AU  - Park, Minsoo
AU  - Park, Seunghee
TI  - Conceptual Framework of an Intelligent Decision Support System for Smart City Disaster Management
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 2
SN  - 2076-3417

AB  - In order to protect human lives and infrastructure, as well as to minimize the risk of damage, it is important to predict and respond to natural disasters in advance. However, currently, the standardized disaster response system in South Korea still needs further advancement, and the response phase systems need to be improved to ensure that they are properly equipped to cope with natural disasters. Existing studies on intelligent disaster management systems (IDSSs) in South Korea have focused only on storms, floods, and earthquakes, and they have not used past data. This research proposes a new conceptual framework of an IDSS for disaster management, with particular attention paid to wildfires and cold/heat waves. The IDSS uses big data collected from open application programming interface (API) and artificial intelligence (AI) algorithms to help decision-makers make faster and more accurate decisions. In addition, a simple example of the use of a convolutional neural network (CNN) to detect fire in surveillance video has been developed, which can be used for automatic fire detection and provide an appropriate response. The system will also consider connecting to open source intelligence (OSINT) to identify vulnerabilities, mitigate risks, and develop more robust security policies than those currently in place to prevent cyber-attacks.
KW  - decision support system
KW  - big data
KW  - artificial intelligence
KW  - Internet of Things
KW  - disaster management
DO  - 10.3390/app10020666
ER  -
TY  - EJOU
AU  - Agrafiotis, Panagiotis
AU  - Karantzalos, Konstantinos
AU  - Georgopoulos, Andreas
AU  - Skarlatos, Dimitrios
TI  - Correcting Image Refraction: Towards Accurate Aerial Image-Based Bathymetry Mapping in Shallow Waters
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 2
SN  - 2072-4292

AB  - Although aerial image-based bathymetric mapping can provide, unlike acoustic or LiDAR (Light Detection and Ranging) sensors, both water depth and visual information, water refraction poses significant challenges for accurate depth estimation. In order to tackle this challenge, we propose an image correction methodology, which first exploits recent machine learning procedures that recover depth from image-based dense point clouds and then corrects refraction on the original imaging dataset. This way, the structure from motion (SfM) and multi-view stereo (MVS) processing pipelines are executed on a refraction-free set of aerial datasets, resulting in highly accurate bathymetric maps. Performed experiments and validation were based on datasets acquired during optimal sea state conditions and derived from four different test-sites characterized by excellent sea bottom visibility and textured seabed. Results demonstrated the high potential of our approach, both in terms of bathymetric accuracy, as well as texture and orthoimage quality.
KW  - bathymetry
KW  - UAV
KW  - aerial imagery
KW  - seabed mapping
KW  - coastal mapping
KW  - refraction correction
KW  - DSM
KW  - image correction
KW  - SfM
KW  - machine learning
DO  - 10.3390/rs12020322
ER  -
TY  - EJOU
AU  - Zhang, Yishan
AU  - Wu, Lun
AU  - Ren, Huazhong
AU  - Liu, Yu
AU  - Zheng, Yongqian
AU  - Liu, Yaowen
AU  - Dong, Jiaji
TI  - Mapping Water Quality Parameters in Urban Rivers from Hyperspectral Images Using a New Self-Adapting Selection of Multiple Artificial Neural Networks
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 2
SN  - 2072-4292

AB  - Protection of water environments is an important part of overall environmental protection; hence, many people devote their efforts to monitoring and improving water quality. In this study, a self-adapting selection method of multiple artificial neural networks (ANNs) using hyperspectral remote sensing and ground-measured water quality data is proposed to quantitatively predict water quality parameters, including phosphorus, nitrogen, biochemical oxygen demand (BOD), chemical oxygen demand (COD), and chlorophyll a. Seventy-nine ground measured data samples are used as training data in the establishment of the proposed model, and 30 samples are used as testing data. The proposed method based on traditional ANNs of numerical prediction involves feature selection of bands, self-adapting selection based on multiple selection criteria, stepwise backtracking, and combined weighted correlation. Water quality parameters are estimated with coefficient of determination      R 2      ranging from 0.93 (phosphorus) to 0.98 (nitrogen), which is higher than the value (0.7 to 0.8) obtained by traditional ANNs. MPAE (mean percent of absolute error) values ranging from 5% to 11% are used rather than root mean square error to evaluate the predicting precision of the proposed model because the magnitude of each water quality parameter considerably differs, thereby providing reasonable and interpretable results. Compared with other ANNs with backpropagation, this study proposes an auto-adapting method assisted by the above-mentioned methods to select the best model with all settings, such as the number of hidden layers, number of neurons in each hidden layer, choice of optimizer, and activation function. Different settings for ANNS with backpropagation are important to improve precision and compatibility for different data. Furthermore, the proposed method is applied to hyperspectral remote sensing images collected using an unmanned aerial vehicle for monitoring the water quality in the Shiqi River, Zhongshan City, Guangdong Province, China. Obtained results indicate the locations of pollution sources.
KW  - self-adapting
KW  - deep learning
KW  - multiple neural network
KW  - hyperspectral image
KW  - water quality monitoring
DO  - 10.3390/rs12020336
ER  -
TY  - EJOU
AU  - Alganci, Ugur
AU  - Soydas, Mehmet
AU  - Sertel, Elif
TI  - Comparative Research on Deep Learning Approaches for Airplane Detection from Very High-Resolution Satellite Images
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 3
SN  - 2072-4292

AB  - Object detection from satellite images has been a challenging problem for many years. With the development of effective deep learning algorithms and advancement in hardware systems, higher accuracies have been achieved in the detection of various objects from very high-resolution (VHR) satellite images. This article provides a comparative evaluation of the state-of-the-art convolutional neural network (CNN)-based object detection models, which are Faster R-CNN, Single Shot Multi-box Detector (SSD), and You Look Only Once-v3 (YOLO-v3), to cope with the limited number of labeled data and to automatically detect airplanes in VHR satellite images. Data augmentation with rotation, rescaling, and cropping was applied on the test images to artificially increase the number of training data from satellite images. Moreover, a non-maximum suppression algorithm (NMS) was introduced at the end of the SSD and YOLO-v3 flows to get rid of the multiple detection occurrences near each detected object in the overlapping areas. The trained networks were applied to five independent VHR test images that cover airports and their surroundings to evaluate their performance objectively. Accuracy assessment results of the test regions proved that Faster R-CNN architecture provided the highest accuracy according to the F1 scores, average precision (AP) metrics, and visual inspection of the results. The YOLO-v3 ranked as second, with a slightly lower performance but providing a balanced trade-off between accuracy and speed. The SSD provided the lowest detection performance, but it was better in object localization. The results were also evaluated in terms of the object size and detection accuracy manner, which proved that large- and medium-sized airplanes were detected with higher accuracy.
KW  - convolutional neural networks (CNNs)
KW  - end-to-end detection
KW  - transfer learning
KW  - remote sensing
KW  - single shot multi-box detector (SSD)
KW  - You Look Only Once-v3 (YOLO-v3)
KW  - Faster RCNN
DO  - 10.3390/rs12030458
ER  -
TY  - EJOU
AU  - Chang, Zhilu
AU  - Du, Zhen
AU  - Zhang, Fan
AU  - Huang, Faming
AU  - Chen, Jiawu
AU  - Li, Wenbin
AU  - Guo, Zizheng
TI  - Landslide Susceptibility Prediction Based on Remote Sensing Images and GIS: Comparisons of Supervised and Unsupervised Machine Learning Models
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 3
SN  - 2072-4292

AB  - Landslide susceptibility prediction (LSP) has been widely and effectively implemented by machine learning (ML) models based on remote sensing (RS) images and Geographic Information System (GIS). However, comparisons of the applications of ML models for LSP from the perspectives of supervised machine learning (SML) and unsupervised machine learning (USML) have not been explored. Hence, this study aims to compare the LSP performance of these SML and USML models, thus further to explore the advantages and disadvantages of these ML models and to realize a more accurate and reliable LSP result. Two representative SML models (support vector machine (SVM) and CHi-squared Automatic Interaction Detection (CHAID)) and two representative USML models (K-means and Kohonen models) are respectively used to scientifically predict the landslide susceptibility indexes, and then these prediction results are discussed. Ningdu County with 446 recorded landslides obtained through field investigations is introduced as case study. A total of 12 conditioning factors are obtained through procession of Landsat TM 8 images and high-resolution aerial images, topographical and hydrological spatial analysis of Digital Elevation Modeling in GIS software, and government reports. The area value under the curve of receiver operating features (AUC) is applied for evaluating the prediction accuracy of SML models, and the frequency ratio (FR) accuracy is then introduced to compare the remarkable prediction performance differences between SML and USML models. Overall, the receiver operation curve (ROC) results show that the AUC of the SVM is 0.892 and is slightly greater than the AUC of the CHAID model (0.872). The FR accuracy results show that the SVM model has the highest accuracy for LSP (77.80%), followed by the CHAID model (74.50%), the Kohonen model (72.8%) and the K-means model (69.7%), which indicates that the SML models can reach considerably better prediction capability than the USML models. It can be concluded that selecting recorded landslides as prior knowledge to train and test the LSP models is the key reason for the higher prediction accuracy of the SML models, while the lack of a priori knowledge and target guidance is an important reason for the low LSP accuracy of the USML models. Nevertheless, the USML models can also be used to implement LSP due to their advantages of efficient modeling processes, dimensionality reduction and strong scalability.
KW  - landslide susceptibility prediction
KW  - supervised machine learning
KW  - unsupervised machine learning
KW  - remote sensing
KW  - Geographic Information System
DO  - 10.3390/rs12030502
ER  -
TY  - EJOU
AU  - Fu, Zhaopeng
AU  - Jiang, Jie
AU  - Gao, Yang
AU  - Krienke, Brian
AU  - Wang, Meng
AU  - Zhong, Kaitai
AU  - Cao, Qiang
AU  - Tian, Yongchao
AU  - Zhu, Yan
AU  - Cao, Weixing
AU  - Liu, Xiaojun
TI  - Wheat Growth Monitoring and Yield Estimation based on Multi-Rotor Unmanned Aerial Vehicle
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 3
SN  - 2072-4292

AB  - Leaf area index (LAI) and leaf dry matter (LDM) are important indices of crop growth. Real-time, nondestructive monitoring of crop growth is instructive for the diagnosis of crop growth and prediction of grain yield. Unmanned aerial vehicle (UAV)-based remote sensing is widely used in precision agriculture due to its unique advantages in flexibility and resolution. This study was carried out on wheat trials treated with different nitrogen levels and seeding densities in three regions of Jiangsu Province in 2018&ndash;2019. Canopy spectral images were collected by the UAV equipped with a multi-spectral camera during key wheat growth stages. To verify the results of the UAV images, the LAI, LDM, and yield data were obtained by destructive sampling. We extracted the wheat canopy reflectance and selected the best vegetation index for monitoring growth and predicting yield. Simple linear regression (LR), multiple linear regression (MLR), stepwise multiple linear regression (SMLR), partial least squares regression (PLSR), artificial neural network (ANN), and random forest (RF) modeling methods were used to construct a model for wheat yield estimation. The results show that the multi-spectral camera mounted on the multi-rotor UAV has a broad application prospect in crop growth index monitoring and yield estimation. The vegetation index combined with the red edge band and the near-infrared band was significantly correlated with LAI and LDM. Machine learning methods (i.e., PLSR, ANN, and RF) performed better for predicting wheat yield. The RF model constructed by normalized difference vegetation index (NDVI) at the jointing stage, heading stage, flowering stage, and filling stage was the optimal wheat yield estimation model in this study, with an R2 of 0.78 and relative root mean square error (RRMSE) of 0.1030. The results provide a theoretical basis for monitoring crop growth with a multi-rotor UAV platform and explore a technical method for improving the precision of yield estimation.
KW  - UAV multispectral image
KW  - leaf area index
KW  - leaf dry matter
KW  - grain yield
KW  - estimation
KW  - wheat
KW  - machine learning
DO  - 10.3390/rs12030508
ER  -
TY  - EJOU
AU  - Maxwell, Aaron E.
AU  - Pourmohammadi, Pariya
AU  - Poyner, Joey D.
TI  - Mapping the Topographic Features of Mining-Related Valley Fills Using Mask R-CNN Deep Learning and Digital Elevation Data
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 3
SN  - 2072-4292

AB  - Modern elevation-determining remote sensing technologies such as light-detection and ranging (LiDAR) produce a wealth of topographic information that is increasingly being used in a wide range of disciplines, including archaeology and geomorphology. However, automated methods for mapping topographic features have remained a significant challenge. Deep learning (DL) mask regional-convolutional neural networks (Mask R-CNN), which provides context-based instance mapping, offers the potential to overcome many of the difficulties of previous approaches to topographic mapping. We therefore explore the application of Mask R-CNN to extract valley fill faces (VFFs), which are a product of mountaintop removal (MTR) coal mining in the Appalachian region of the eastern United States. LiDAR-derived slopeshades are provided as the only predictor variable in the model. Model generalization is evaluated by mapping multiple study sites outside the training data region. A range of assessment methods, including precision, recall, and F1 score, all based on VFF counts, as well as area- and a fuzzy area-based user&rsquo;s and producer&rsquo;s accuracy, indicate that the model was successful in mapping VFFs in new geographic regions, using elevation data derived from different LiDAR sensors. Precision, recall, and F1-score values were above 0.85 using VFF counts while user&rsquo;s and producer&rsquo;s accuracy were above 0.75 and 0.85 when using the area- and fuzzy area-based methods, respectively, when averaged across all study areas characterized with LiDAR data. Due to the limited availability of LiDAR data until relatively recently, we also assessed how well the model generalizes to terrain data created using photogrammetric methods that characterize past terrain conditions. Unfortunately, the model was not sufficiently general to allow successful mapping of VFFs using photogrammetrically-derived slopeshades, as all assessment metrics were lower than 0.60; however, this may partially be attributed to the quality of the photogrammetric data. The overall results suggest that the combination of Mask R-CNN and LiDAR has great potential for mapping anthropogenic and natural landscape features. To realize this vision, however, research on the mapping of other topographic features is needed, as well as the development of large topographic training datasets including a variety of features for calibrating and testing new methods.
KW  - light detection and ranging
KW  - LiDAR
KW  - deep learning
KW  - convolutional neural networks
KW  - CNNs
KW  - mask regional-convolutional neural networks
KW  - mask R-CNN
KW  - digital terrain analysis
KW  - resource extraction
DO  - 10.3390/rs12030547
ER  -
TY  - EJOU
AU  - Perera, Asanka G.
AU  - Khanam, Fatema-Tuz-Zohra
AU  - Al-Naji, Ali
AU  - Chahl, Javaan
TI  - Detection and Localisation of Life Signs from the Air Using Image Registration and Spatio-Temporal Filtering
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 3
SN  - 2072-4292

AB  - In search and rescue operations, it is crucial to rapidly identify those people who are alive from those who are not. If this information is known, emergency teams can prioritize their operations to save more lives. However, in some natural disasters the people may be lying on the ground covered with dust, debris, or ashes making them difficult to detect by video analysis that is tuned to human shapes. We present a novel method to estimate the locations of people from aerial video using image and signal processing designed to detect breathing movements. We have shown that this method can successfully detect clearly visible people and people who are fully occluded by debris. First, the aerial videos were stabilized using the key points of adjacent image frames. Next, the stabilized video was decomposed into tile videos and the temporal frequency bands of interest were motion magnified while the other frequencies were suppressed. Image differencing and temporal filtering were performed on each tile video to detect potential breathing signals. Finally, the detected frequencies were remapped to the image frame creating a life signs map that indicates possible human locations. The proposed method was validated with both aerial and ground recorded videos in a controlled environment. Based on the dataset, the results showed good reliability for aerial videos and no errors for ground recorded videos where the average precision measures for aerial videos and ground recorded videos were 0.913 and 1 respectively.
KW  - search and rescue
KW  - drone
KW  - breathing detection
KW  - human detection
DO  - 10.3390/rs12030577
ER  -
TY  - EJOU
AU  - Anand, Akash
AU  - Pandey, Prem C.
AU  - Petropoulos, George P.
AU  - Pavlides, Andrew
AU  - Srivastava, Prashant K.
AU  - Sharma, Jyoti K.
AU  - Malhi, Ramandeep Kaur M.
TI  - Use of Hyperion for Mangrove Forest Carbon Stock Assessment in Bhitarkanika Forest Reserve: A Contribution Towards Blue Carbon Initiative
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 4
SN  - 2072-4292

AB  - Mangrove forest coastal ecosystems contain significant amount of carbon stocks and contribute to approximately 15% of the total carbon sequestered in ocean sediments. The present study aims at exploring the ability of Earth Observation EO-1 Hyperion hyperspectral sensor in estimating aboveground carbon stocks in mangrove forests. Bhitarkanika mangrove forest has been used as case study, where field measurements of the biomass and carbon were acquired simultaneously with the satellite data. The spatial distribution of most dominant mangrove species was identified using the Spectral Angle Mapper (SAM) classifier, which was implemented using the spectral profiles extracted from the hyperspectral data. SAM performed well, identifying the total area that each of the major species covers (overall kappa = 0.81). From the hyperspectral images, the NDVI (Normalized Difference Vegetation Index) and EVI (Enhanced Vegetation Index) were applied to assess the carbon stocks of the various species using machine learning (Linear, Polynomial, Logarithmic, Radial Basis Function (RBF), and Sigmoidal Function) models. NDVI and EVI is generated using covariance matrix based band selection algorithm. All the five machine learning models were tested between the carbon measured in the field sampling and the carbon estimated by the vegetation indices NDVI and EVI was satisfactory (Pearson correlation coefficient, R, of 86.98% for EVI and of 84.1% for NDVI), with the RBF model showing the best results in comparison to other models. As such, the aboveground carbon stocks for species-wise mangrove for the study area was estimated. Our study findings confirm that hyperspectral images such as those from Hyperion can be used to perform species-wise mangrove analysis and assess the carbon stocks with satisfactory accuracy.
KW  - blue carbon
KW  - hyperspectral data
KW  - mangrove forest
KW  - carbon stock
KW  - Bhitarkanika Forest Reserve
KW  - regression models
KW  - machine learning
DO  - 10.3390/rs12040597
ER  -
TY  - EJOU
AU  - Zhang, Jing
AU  - Tian, Haiqing
AU  - Wang, Di
AU  - Li, Haijun
AU  - Mouazen, Abdul M.
TI  - A Novel Approach for Estimation of Above-Ground Biomass of Sugar Beet Based on Wavelength Selection and Optimized Support Vector Machine
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 4
SN  - 2072-4292

AB  - Timely diagnosis of sugar beet above-ground biomass (AGB) is critical for the prediction of yield and optimal precision crop management. This study established an optimal quantitative prediction model of AGB of sugar beet by using hyperspectral data. Three experiment campaigns in 2014, 2015 and 2018 were conducted to collect ground-based hyperspectral data at three different growth stages, across different sites, for different cultivars and nitrogen (N) application rates. A competitive adaptive reweighted sampling (CARS) algorithm was applied to select the most sensitive wavelengths to AGB. This was followed by developing a novel modified differential evolution grey wolf optimization algorithm (MDE&ndash;GWO) by introducing differential evolution algorithm (DE) and dynamic non-linear convergence factor to grey wolf optimization algorithm (GWO) to optimize the parameters c and &gamma; of a support vector machine (SVM) model for the prediction of AGB. The prediction performance of SVM models under the three GWO, DE&ndash;GWO and MDE&ndash;GWO optimization methods for CARS selected wavelengths and whole spectral data was examined. Results showed that CARS resulted in a huge wavelength reduction of 97.4% for the rapid growth stage of leaf cluster, 97.2% for the sugar growth stage and 97.4% for the sugar accumulation stage. Models resulted after CARS wavelength selection were found to be more accurate than models developed using the entire spectral data. The best prediction accuracy was achieved after the MDE&ndash;GWO optimization of SVM model parameters for the prediction of AGB in sugar beet, independent of growing stage, years, sites and cultivars. The best coefficient of determination (R2), root mean square error (RMSE) and residual prediction deviation (RPD) ranged, respectively, from 0.74 to 0.80, 46.17 to 65.68 g/m2 and 1.42 to 1.97 for the rapid growth stage of leaf cluster, 0.78 to 0.80, 30.16 to 37.03 g/m2 and 1.69 to 2.03 for the sugar growth stage, and 0.69 to 0.74, 40.17 to 104.08 g/m2 and 1.61 to 1.95 for the sugar accumulation stage. It can be concluded that the methodology proposed can be implemented for the prediction of AGB of sugar beet using proximal hyperspectral sensors under a wide range of environmental conditions.
KW  - sugar beet
KW  - above-ground biomass
KW  - grey wolf optimization
KW  - support vector machine
KW  - hyperspectral sensing
DO  - 10.3390/rs12040620
ER  -
TY  - EJOU
AU  - Erena, Manuel
AU  - Domínguez, José A.
AU  - Atenza, Joaquín F.
AU  - García-Galiano, Sandra
AU  - Soria, Juan
AU  - Pérez-Ruzafa, Ángel
TI  - Bathymetry Time Series Using High Spatial Resolution Satellite Images
T2  - Water

PY  - 2020
VL  - 12
IS  - 2
SN  - 2073-4441

AB  - The use of the new generation of remote sensors, such as echo sounders and Global Navigation Satellite System (GNSS) receivers with differential correction installed in a drone, allows the acquisition of high-precision data in areas of shallow water, as in the case of the channel of the Encañizadas in the Mar Menor lagoon. This high precision information is the first step to develop the methodology to monitor the bathymetry of the Mar Menor channels. The use of high spatial resolution satellite images is the solution for monitoring many hydrological changes and it is the basis of the three-dimensional (3D) numerical models used to study transport over time, environmental variability, and water ecosystem complexity.
KW  - Mar Menor
KW  - spatio-temporal variability
KW  - Pleiades-1
DO  - 10.3390/w12020531
ER  -
TY  - EJOU
AU  - Karydas, Christos
AU  - Iatrou, Miltiadis
AU  - Kouretas, Dimitrios
AU  - Patouna, Anastasia
AU  - Iatrou, George
AU  - Lazos, Nikolaos
AU  - Gewehr, Sandra
AU  - Tseni, Xanthi
AU  - Tekos, Fotis
AU  - Zartaloudis, Zois
AU  - Mainos, Evangelos
AU  - Mourelatos, Spiros
TI  - Prediction of Antioxidant Activity of Cherry Fruits from UAS Multispectral Imagery Using Machine Learning
T2  - Antioxidants

PY  - 2020
VL  - 9
IS  - 2
SN  - 2076-3921

AB  - In this research, a model for the estimation of antioxidant content in cherry fruits from multispectral imagery acquired from drones was developed, based on machine learning methods. For two consecutive cultivation years, the trees were sampled on different dates and then analysed for their fruits&rsquo; radical scavenging activity (DPPH) and Folin&ndash;Ciocalteu (FCR) reducing capacity. Multispectral images from unmanned aerial vehicles were acquired on the same dates with fruit sampling. Soil samples were collected throughout the study fields at the end of the season. Topographic, hydrographic and weather data also were included in modelling. First-year data were used for model-fitting, whereas second-year data for testing. Spatial autocorrelation tests indicated unbiased sampling and, moreover, allowed restriction of modelling input parameters to a smaller group. The optimum model employs 24 input variables resulting in a 6.74 root mean square error. Provided that soil profiles and other ancillary data are known in advance of the cultivation season, capturing drone images in critical growth phases, together with contemporary weather data, can support site- and time-specific harvesting. It could also support site-specific treatments (precision farming) for improving fruit quality in the long-term, with analogous marketing perspectives.
KW  - antioxidant activity
KW  - machine learning
KW  - drones
KW  - precision farming
DO  - 10.3390/antiox9020156
ER  -
TY  - EJOU
AU  - Hufkens, Koen
AU  - de Haulleville, Thalès
AU  - Kearsley, Elizabeth
AU  - Jacobsen, Kim
AU  - Beeckman, Hans
AU  - Stoffelen, Piet
AU  - Vandelook, Filip
AU  - Meeus, Sofie
AU  - Amara, Michael
AU  - Van Hirtum, Leen
AU  - Van den Bulcke, Jan
AU  - Verbeeck, Hans
AU  - Wingate, Lisa
TI  - Historical Aerial Surveys Map Long-Term Changes of Forest Cover and Structure in the Central Congo Basin
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 4
SN  - 2072-4292

AB  - Given the impact of tropical forest disturbances on atmospheric carbon emissions, biodiversity, and ecosystem productivity, accurate long-term reporting of Land-Use and Land-Cover (LULC) change in the pre-satellite era (&lt;1972) is an imperative. Here, we used a combination of historical (1958) aerial photography and contemporary remote sensing data to map long-term changes in the extent and structure of the tropical forest surrounding Yangambi (DR Congo) in the central Congo Basin. Our study leveraged structure-from-motion and a convolutional neural network-based LULC classifier, using synthetic landscape-based image augmentation to map historical forest cover across a large orthomosaic (~93,431 ha) geo-referenced to ~4.7 ± 4.3 m at submeter resolution. A comparison with contemporary LULC data showed a shift from previously highly regular industrial deforestation of large areas to discrete smallholder farming clearing, increasing landscape fragmentation and providing opportunties for substantial forest regrowth. We estimated aboveground carbon gains through reforestation to range from 811 to 1592 Gg C, partially offsetting historical deforestation (2416 Gg C), in our study area. Efforts to quantify long-term canopy texture changes and their link to aboveground carbon had limited to no success. Our analysis provides methods and insights into key spatial and temporal patterns of deforestation and reforestation at a multi-decadal scale, providing a historical context for past and ongoing forest research in the area.
KW  - aerial survey
KW  - data recovery
KW  - CNN
KW  - deep learning
KW  - SfM
KW  - Congo Basin
DO  - 10.3390/rs12040638
ER  -
TY  - EJOU
AU  - Yu, Zhi
AU  - Shi, Xiuzhi
AU  - Zhou, Jian
AU  - Chen, Xin
AU  - Qiu, Xianyang
TI  - Effective Assessment of Blast-Induced Ground Vibration Using an Optimized Random Forest Model Based on a Harris Hawks Optimization Algorithm
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 4
SN  - 2076-3417

AB  - Most mines choose the drilling and blasting method which has the characteristics of being a cheap and efficient method to fragment rock mass, but blast-induced ground vibration damages the surrounding rock mass and structure and is a drawback. To predict, analyze and control the blast-induced ground vibration, the random forest (RF) model, Harris hawks optimization (HHO) algorithm and Monte Carlo simulation approach were utilized. A database consisting of 137 datasets was collected at different locations around the Tonglvshan open-cast mine, China. Seven variables were selected and collected as the input variables, and peak particle velocity was chosen as the output variable. At first, an RF model and a hybrid model, namely a HHO-RF model, were developed, and the prediction results checked by 3 performance indices to show that the proposed HHO-RF model can provide higher prediction performance. Then blast-induced ground vibration was simulated by using the Monte Carlo simulation approach and the developed HHO-RF model. After analyzing, the mean peak particle velocity value was 0.98 cm/s, and the peak particle velocity value did not exceed 1.95 cm/s with a probability of 90%. The research results of this study provided a simple, accurate method and basis for predicting, evaluating blast-induced ground vibration and optimizing the blast design before blast operation.
KW  - blast-induced ground vibration
KW  - random forest
KW  - Harris hawks optimization
KW  - Monte Carlo simulation
KW  - sensitive analysis
DO  - 10.3390/app10041403
ER  -
TY  - EJOU
AU  - Lin, Yan-Ting
AU  - Yang, Ming-Der
AU  - Han, Jen-Yu
AU  - Su, Yuan-Fong
AU  - Jang, Jiun-Huei
TI  - Quantifying Flood Water Levels Using Image-Based Volunteered Geographic Information
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 4
SN  - 2072-4292

AB  - Many people use smartphone cameras to record their living environments through captured images, and share aspects of their daily lives on social networks, such as Facebook, Instagram, and Twitter. These platforms provide volunteered geographic information (VGI), which enables the public to know where and when events occur. At the same time, image-based VGI can also indicate environmental changes and disaster conditions, such as flooding ranges and relative water levels. However, little image-based VGI has been applied for the quantification of flooding water levels because of the difficulty of identifying water lines in image-based VGI and linking them to detailed terrain models. In this study, flood detection has been achieved through image-based VGI obtained by smartphone cameras. Digital image processing and a photogrammetric method were presented to determine the water levels. In digital image processing, the random forest classification was applied to simplify ambient complexity and highlight certain aspects of flooding regions, and the HT-Canny method was used to detect the flooding line of the classified image-based VGI. Through the photogrammetric method and a fine-resolution digital elevation model based on the unmanned aerial vehicle mapping technique, the detected flooding lines were employed to determine water levels. Based on the results of image-based VGI experiments, the proposed approach identified water levels during an urban flood event in Taipei City for demonstration. Notably, classified images were produced using random forest supervised classification for a total of three classes with an average overall accuracy of 88.05%. The quantified water levels with a resolution of centimeters (&lt;3-cm difference on average) can validate flood modeling so as to extend point-basis observations to area-basis estimations. Therefore, the limited performance of image-based VGI quantification has been improved to help in flood disasters. Consequently, the proposed approach using VGI images provides a reliable and effective flood-monitoring technique for disaster management authorities.
KW  - volunteered geographic information (VGI)
KW  - social network
KW  - random forest
KW  - water level detection
KW  - image processing
KW  - smartphones
DO  - 10.3390/rs12040706
ER  -
TY  - EJOU
AU  - Spachos, Petros
TI  - Towards a Low-Cost Precision Viticulture System Using Internet of Things Devices
T2  - IoT

PY  - 2020
VL  - 1
IS  - 1
SN  - 2624-831X

AB  - Precision Agriculture (PA) is an ever-expanding field that takes modern technological advancements and applies it to farming practices to reduce waste and increase output. One advancement that can play a significant role in achieving precision agriculture is wireless technology, and specifically the Internet of Things (IoT) devices. Small, inch scale and low-cost devices can be used to monitor great agricultural areas. In this paper, a system for precision viticulture which uses IoT devices for real-time monitoring is proposed. The different components of the system are programmed properly and the interconnection between them is designed to minimize energy consumption. Wireless sensor nodes measure soil moisture and soil temperature in the field and transmit the information to a base station. If the conditions are optimal for a disease or pest to occur, a drone flies towards the area. When the drone is over the node, pictures are captured and then it returns to the base station for further processing. The feasibility of the system is examined through experimentation in a realistic scenario.
KW  - precision viticulture
KW  - Internet of Things
KW  - sensors and instrumentation
KW  - smart agriculture
DO  - 10.3390/iot1010002
ER  -
TY  - EJOU
AU  - Noguera, Miguel
AU  - Millán, Borja
AU  - Pérez-Paredes, Juan J.
AU  - Ponce, Juan M.
AU  - Aquino, Arturo
AU  - Andújar, José M.
TI  - A New Low-Cost Device Based on Thermal Infrared Sensors for Olive Tree Canopy Temperature Measurement and Water Status Monitoring
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 4
SN  - 2072-4292

AB  - In recent years, many olive orchards, which are a major crop in the Mediterranean basin, have been converted into intensive or super high-density hedgerow systems. This configuration is more efficient in terms of yield per hectare, but at the same time the water requirements are higher than in traditional grove arrangements. Moreover, irrigation regulations have a high environmental (through water use optimization) impact and influence on crop quality and yield. The mapping of (spatio-temporal) variability with conventional water stress assessment methods is impractical due to time and labor constraints, which often involve staff training. To address this problem, this work presents the development of a new low-cost device based on a thermal infrared (IR) sensor for the measurement of olive tree canopy temperature and monitoring of water status. The performance of the developed device was compared to a commercial thermal camera. Furthermore, the proposed device was evaluated in a commercially managed olive orchard, where two different irrigation treatments were established: a full irrigation treatment (FI) and a regulated deficit irrigation (RDC), aimed at covering 100% and 50% of crop evapotranspiration (ETc), respectively. Predawn leaf water potential (&Psi;PD) and stomatal conductance (gs), two widely accepted indicators for crop water status, were regressed to the measured canopy temperature. The results were promising, reaching a coefficient of determination R2 &ge; 0.80. On the other hand, the crop water stress index (CWSI) was also calculated, resulting in a coefficient of determination R2 &ge; 0.79. The outcomes provided by the developed device support its suitability for fast, low-cost, and reliable estimation of an olive orchard&rsquo;s water status, even suppressing the need for supervised acquisition of reference temperatures. The newly developed device can be used for water management, reducing water usage, and for overall improvements to olive orchard management.
KW  - thermal infrared
KW  - remote sensor
KW  - water stress
KW  - irrigation
KW  - canopy temperature
KW  - stomatal conductance
KW  - predawn leaf water potential
KW  - olive
DO  - 10.3390/rs12040723
ER  -
TY  - EJOU
AU  - Pastick, Neal J.
AU  - Dahal, Devendra
AU  - Wylie, Bruce K.
AU  - Parajuli, Sujan
AU  - Boyte, Stephen P.
AU  - Wu, Zhouting
TI  - Characterizing Land Surface Phenology and Exotic Annual Grasses in Dryland Ecosystems Using Landsat and Sentinel-2 Data in Harmony
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 4
SN  - 2072-4292

AB  - Invasive annual grasses, such as cheatgrass (Bromus tectorum L.), have proliferated in dryland ecosystems of the western United States, promoting increased fire activity and reduced biodiversity that can be detrimental to socio-environmental systems. Monitoring exotic annual grass cover and dynamics over large areas requires the use of remote sensing that can support early detection and rapid response initiatives. However, few studies have leveraged remote sensing technologies and computing frameworks capable of providing rangeland managers with maps of exotic annual grass cover at relatively high spatiotemporal resolutions and near real-time latencies. Here, we developed a system for automated mapping of invasive annual grass (%) cover using in situ observations, harmonized Landsat and Sentinel-2 (HLS) data, maps of biophysical variables, and machine learning techniques. A robust and automated cloud, cloud shadow, water, and snow/ice masking procedure (mean overall accuracy &gt;81%) was implemented using time-series outlier detection and data mining techniques prior to spatiotemporal interpolation of HLS data via regression tree models (r = 0.94; mean absolute error (MAE) = 0.02). Weekly, cloud-free normalized difference vegetation index (NDVI) image composites (2016&ndash;2018) were used to construct a suite of spectral and phenological metrics (e.g., start and end of season dates), consistent with information derived from Moderate Resolution Image Spectroradiometer (MODIS) data. These metrics were incorporated into a data mining framework that accurately (r = 0.83; MAE = 11) modeled and mapped exotic annual grass (%) cover throughout dryland ecosystems in the western United States at a native, 30-m spatial resolution. Our results show that inclusion of weekly HLS time-series data and derived indicators improves our ability to map exotic annual grass cover, as compared to distribution models that use MODIS products or monthly, seasonal, or annual HLS composites as primary inputs. This research fills a critical gap in our ability to effectively assess, manage, and monitor drylands by providing a framework that allows for an accurate and timely depiction of land surface phenology and exotic annual grass cover at spatial and temporal resolutions that are meaningful to local resource managers.
KW  - data mining
KW  - invasive plants
KW  - Landsat
KW  - Sentinel-2
KW  - time-series analysis
KW  - phenology
DO  - 10.3390/rs12040725
ER  -
TY  - EJOU
AU  - Yuan, Weitao
AU  - Zhang, Wangle
AU  - Lai, Zhongping
AU  - Zhang, Jingxiong
TI  - Extraction of Yardang Characteristics Using Object-Based Image Analysis and Canny Edge Detection Methods
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 4
SN  - 2072-4292

AB  - Parameters of geomorphological characteristics are critical for research on yardangs. However, methods which are low-cost, accurate, and automatic or semi-automatic for extracting these parameters are limited. We present here semi-automatic techniques for this purpose. They are object-based image analysis (OBIA) and Canny edge detection (CED), using free, very high spatial resolution images from Google Earth. We chose yardang fields in Dunhuang of west China to test the methods. Our results showed that the extractions registered an overall accuracy of 92.26% with a Kappa coefficient of agreement of 0.82 at a segmentation scale of 52 using the OBIA method, and the exaction of yardangs had the highest accuracy at medium segmentation scales (138, 145). Using CED, we resampled the experimental image subset to a series of lower spatial resolutions for eliminating noise. The total length of yardang boundaries showed a logarithmically decreasing (R2 = 0.904) trend with decreasing spatial resolution, and there was also a linear relationship between yardang median widths and spatial resolutions (R2 = 0.95). Despite the difficulty of identifying shadows, the CED method achieved an overall accuracy of 89.23% with a kappa coefficient of agreement of 0.72, similar to that of the OBIA method at medium segmentation scale (138).
KW  - extracting yardang geomorphological characteristics
KW  - object-based image analysis (OBIA)
KW  - Canny edge detection (CED)
KW  - free very high-resolution image in Google Earth
DO  - 10.3390/rs12040726
ER  -
TY  - EJOU
AU  - Nogueira, Keiller
AU  - L. S. Machado, Gabriel
AU  - H. T. Gama, Pedro
AU  - C. V. da Silva, Caio
AU  - Balaniuk, Remis
AU  - A. dos Santos, Jefersson
TI  - Facing Erosion Identification in Railway Lines Using Pixel-Wise Deep-Based Approaches
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 4
SN  - 2072-4292

AB  - Soil erosion is considered one of the most expensive natural hazards with a high impact on several infrastructure assets. Among them, railway lines are one of the most likely constructions for the appearance of erosion and, consequently, one of the most troublesome due to the maintenance costs, risks of derailments, and so on. Therefore, it is fundamental to identify and monitor erosion in railway lines to prevent major consequences. Currently, erosion identification is manually performed by humans using huge image sets, a time-consuming and slow task. Hence, automatic machine learning methods appear as an appealing alternative. A crucial step for automatic erosion identification is to create a good feature representation. Towards such objective, deep learning can learn data-driven features and classifiers. In this paper, we propose a novel deep learning-based framework capable of performing erosion identification in railway lines. Six techniques were evaluated and the best one, Dynamic Dilated ConvNet, was integrated into this framework that was then encapsulated into a new ArcGIS plugin to facilitate its use by non-programmer users. To analyze such techniques, we also propose a new dataset, composed of almost 2000 high-resolution images.
KW  - deep learning
KW  - remote sensing
KW  - erosion identification
KW  - high-resolution images
DO  - 10.3390/rs12040739
ER  -
TY  - EJOU
AU  - Ding, Hu
AU  - Liu, Kai
AU  - Chen, Xiaozheng
AU  - Xiong, Liyang
AU  - Tang, Guoan
AU  - Qiu, Fang
AU  - Strobl, Josef
TI  - Optimized Segmentation Based on the Weighted Aggregation Method for Loess Bank Gully Mapping
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 5
SN  - 2072-4292

AB  - The Chinese Loess Plateau suffers severe gully erosion. Gully mapping is a fundamental task for gully erosion monitoring in this region. Among the different gully types in the Loess Plateau, the bank gully is usually regarded as the most important source for the generation of sediment. However, approaches for bank gully extraction are still limited. This study put forward an integrated framework, including segmentation optimization, evaluation and Extreme Gradient Boosting (XGBoost)-based classification, for the bank gully mapping of Zhifanggou catchment in the Chinese Loess Plateau. The approach was conducted using a 1-m resolution digital elevation model (DEM), based on unmanned aerial vehicle (UAV) photogrammetry and WorldView-3 imagery. The methodology first divided the study area into different watersheds. Then, segmentation by weighted aggregation (SWA) was implemented to generate multi-level segments. For achieving an optimum segmentation, area-weighted variance (WV) and Moran&rsquo;s I (MI) were adopted and calculated within each sub-watershed. After that, a new discrepancy metric, the area-number index (ANI), was developed for evaluating the segmentation results, and the results were compared with the multi-resolution segmentation (MRS) algorithm. Finally, bank gully mappings were obtained based on the XGBoost model after fine-tuning. The experiment results demonstrate that the proposed method can achieve superior segmentation compared to MRS. Moreover, the overall accuracy of the bank gully extraction results was 78.57%. The proposed approach provides a credible tool for mapping bank gullies, which could be useful for the catchment-scale gully erosion process.
KW  - object-based image analysis
KW  - gully mapping
KW  - segmentation optimization
KW  - unmanned aerial vehicle (UAV)
KW  - XGBoost
DO  - 10.3390/rs12050793
ER  -
TY  - EJOU
AU  - Han, Xiongzhe
AU  - Thomasson, J. A.
AU  - Wang, Tianyi
AU  - Swaminathan, Vaishali
TI  - Autonomous Mobile Ground Control Point Improves Accuracy of Agricultural Remote Sensing through Collaboration with UAV
T2  - Inventions

PY  - 2020
VL  - 5
IS  - 1
SN  - 2411-5134

AB  - Ground control points (GCPs) are critical for agricultural remote sensing that require georeferencing and calibration of images collected from an unmanned aerial vehicles (UAV) at different times. However, the conventional stationary GCPs are time-consuming and labor-intensive to measure, distribute, and collect their information in a large field setup. An autonomous mobile GCP and a collaboration strategy to communicate with the UAV were developed to improve the efficiency and accuracy of the UAV-based data collection process. Prior to actual field testing, preliminary tests were conducted using the system to show the capability of automatic path tracking by reducing the root mean square error (RMSE) for lateral deviation from 34.3 cm to 15.6 cm based on the proposed look-ahead tracking method. The tests also indicated the feasibility of moving reflectance reference panels successively along all the waypoints without having detrimental effects on pixel values in the mosaicked images, with the percentage errors in digital number values ranging from &minus;1.1% to 0.1%. In the actual field testing, the autonomous mobile GCP was able to successfully cooperate with the UAV in real-time without any interruption, showing superior performances for georeferencing, radiometric calibration, height calibration, and temperature calibration, compared to the conventional calibration method that has stationary GCPs.
KW  - autonomous mobile GCP
KW  - collaboration strategy
KW  - georeferencing
KW  - radiometric calibration
KW  - height calibration
KW  - temperature calibration
DO  - 10.3390/inventions5010012
ER  -
TY  - EJOU
AU  - Cao, Huiru
AU  - Guo, Zhongwei
AU  - Wang, Shian
AU  - Cheng, Haixiu
AU  - Zhan, Choujun
TI  - Intelligent Wide-Area Water Quality Monitoring and Analysis System Exploiting Unmanned Surface Vehicles and Ensemble Learning
T2  - Water

PY  - 2020
VL  - 12
IS  - 3
SN  - 2073-4441

AB  - Water environment pollution is an acute problem, especially in developing countries, so water quality monitoring is crucial for water protection. This paper presents an intelligent three-dimensional wide-area water quality monitoring and online analysis system. The proposed system is composed of an automatic cruise intelligent unmanned surface vehicle (USV), a water quality monitoring system (WQMS), and a water quality analysis algorithm. An automatic positioning cruising system is constructed for the USV. The WQMS consists of a series of low-power water quality detecting sensors and a lifting device that can collect the water quality monitoring data at different water depths. These data are analyzed by the proposed water quality analysis algorithm based on the ensemble learning method to estimate the water quality level. Then, a real experiment is conducted in a lake to verify the feasibility of the proposed design. The experimental results obtained in real application demonstrate good performance and feasibility of the proposed monitoring system.
KW  - unmanned surface vehicle
KW  - water monitoring
KW  - ensemble learning
KW  - dynamic power management
DO  - 10.3390/w12030681
ER  -
TY  - EJOU
AU  - Lee, Yong-Suk
AU  - Lee, Sunmin
AU  - Baek, Won-Kyung
AU  - Jung, Hyung-Sup
AU  - Park, Sung-Hwan
AU  - Lee, Moung-Jin
TI  - Mapping Forest Vertical Structure in Jeju Island from Optical and Radar Satellite Images Using Artificial Neural Network
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 5
SN  - 2072-4292

AB  - Recently, due to the acceleration of global warming, an accurate understanding and management of forest carbon stocks, such as forest aboveground biomass, has become very important. The vertical structure of the forest, which is the internal structure of the forest, was mainly investigated by field surveys that are labor intensive. Recently, remote sensing techniques have been actively used to explore large and inaccessible areas. In addition, machine learning techniques that could classify and analyze large amounts of data are being used in various fields. Thus, this study aims to analyze the forest vertical structure (number of tree layers) to estimate forest aboveground biomass in Jeju Island from optical and radar satellite images using artificial neural networks (ANN). For this purpose, the eight input neurons of the forest related layers, based on remote sensing data, were prepared: normalized difference vegetation index (NDVI), normalized difference water index (NDWI), NDVI texture, NDWI texture, average canopy height, standard deviation canopy height and two types of coherence maps were created using the Kompsat-3 optical image, L-band ALOS PALSAR-1 radar images, digital surface model (DSM), and digital terrain model (DTM). The forest vertical structure data, based on field surveys, was divided into the training/validation and test data and the hyper-parameters of ANN were trained using the training/validation data. The forest vertical classification result from ANN was evaluated by comparison to the test data. It showed about a 65.7% overall accuracy based on the error matrix. This result shows that the forest vertical structure map can be effectively generated from optical and radar satellite images and existing DEM and DTM using the ANN approach, especially for national scale mapping.
KW  - forest vertical structure
KW  - KOMPSAT-3
KW  - ALOS PALSAR-1
KW  - artificial neural network
DO  - 10.3390/rs12050797
ER  -
TY  - EJOU
AU  - Vilar, Pedro
AU  - Morais, Tiago G.
AU  - Rodrigues, Nuno R.
AU  - Gama, Ivo
AU  - Monteiro, Marta L.
AU  - Domingos, Tiago
AU  - Teixeira, Ricardo F. M.
TI  - Object-Based Classification Approaches for Multitemporal Identification and Monitoring of Pastures in Agroforestry Regions using Multispectral Unmanned Aerial Vehicle Products
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 5
SN  - 2072-4292

AB  - Sown Biodiverse Pastures (SBP) are the basis of a high-yield grazing system tailored for Mediterranean ecosystems and widely implemented in Southern Portugal. The application of precision farming methods in SBP requires cost-effective monitoring using remote sensing (RS). The main hurdle for the remote monitoring of SBP is the fact that the bulk of the pastures are installed in open Montado agroforestry systems. Sparsely distributed trees cast shadows that hinder the identification of the underlaying pasture using Unmanned Aerial Vehicles (UAV) imagery. Image acquisition in the Spring is made difficult by the presence of flowers that mislead the classification algorithms. Here, we tested multiple procedures for the geographical, object-based image classification (GEOBIA) of SBP, aiming to reduce the effects of tree shadows and flowers in open Montado systems. We used remotely sensed data acquired between November 2017 and May 2018 in three Portuguese farms. We used three machine learning supervised classification algorithms: Random Forests (RF), Support Vector Machine (SVM) and Artificial Neural Networks (ANN). We classified SBP based on: (1) a single-period image for the maximum Normalized Difference Vegetation Index (NDVI) epoch in each of the three farms, and (2) multi-temporal image stacking. RF, SVM and ANN were trained using some visible (red, green and blue bands) and near-infrared (NIR) reflectance bands, plus NDVI and a Digital Surface Model (DSM). We obtained high overall accuracy and kappa index (higher than 79% and 0.60, respectively). The RF algorithm had the highest overall accuracy (more than 92%) for all farms. Multitemporal image classification increased the accuracy of the algorithms. as it helped to correctly identify as SBP the areas covered by tree shadows and flower patches, which would be misclassified using single image classification. This study thus established the first workflow for SBP monitoring based on remotely sensed data, suggesting an operational approach for SBP identification. The workflow can be applied to other types of pastures in agroforestry regions to reduce the effects of shadows and flowering in classification problems.
KW  - remote sensing
KW  - multitemporal classification
KW  - machine learning algorithms
KW  - land cover classification
KW  - tree shadows
KW  - flowering
DO  - 10.3390/rs12050814
ER  -
TY  - EJOU
AU  - Guo, Han
AU  - Zhou, Jun
AU  - Liu, Fei
AU  - He, Yong
AU  - Huang, He
AU  - Wang, Hongyan
TI  - Application of Machine Learning Method to Quantitatively Evaluate the Droplet Size and Deposition Distribution of the UAV Spray Nozzle
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 5
SN  - 2076-3417

AB  - Unmanned Aerial Vehicle (UAV) spray has been used for efficient and adaptive pesticide applications with its low costs. However, droplet drift is the main problem for UAV spray and will induce pesticide waste and safety concerns. Droplet size and deposition distribution are both highly related to droplet drift and spray effect, which are determined by the nozzle. Therefore, it is necessary to propose an evaluating method for a specific UAV spray nozzles. In this paper, four machine learning methods (REGRESS, least squares support vector machines (LS-SVM), extreme learning machine, and radial basis function neural network (RBFNN)) were applied for quantitatively evaluating one type of UAV spray nozzle (TEEJET XR110015VS), and the case of twin nozzles was investigated. The results showed REGRESS and LS-SVM are good candidates for droplet size evaluation with the coefficient of determination in the calibration set above 0.9 and root means square errors of the prediction set around 2 &micro;m. RBFNN achieved the best performance for the evaluation of deposition distribution and showed its potential for determining the droplet size of overlapping area. Overall, this study proved the accuracy and efficiency of using the machine learning method for UAV spray nozzle evaluation. Additionally, the study demonstrated the feasibility of using machine learning model to predict the droplet size in the overlapping area of twin nozzles.
KW  - UAV spray nozzle
KW  - spray characteristics
KW  - machine learning
KW  - quantitative modeling
DO  - 10.3390/app10051759
ER  -
TY  - EJOU
AU  - Zhang, Chongyuan
AU  - Craine, Wilson A.
AU  - McGee, Rebecca J.
AU  - Vandemark, George J.
AU  - Davis, James B.
AU  - Brown, Jack
AU  - Hulbert, Scot H.
AU  - Sankaran, Sindhuja
TI  - Image-Based Phenotyping of Flowering Intensity in Cool-Season Crops
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 5
SN  - 1424-8220

AB  - The timing and duration of flowering are key agronomic traits that are often associated with the ability of a variety to escape abiotic stress such as heat and drought. Flowering information is valuable in both plant breeding and agricultural production management. Visual assessment, the standard protocol used for phenotyping flowering, is a low-throughput and subjective method. In this study, we evaluated multiple imaging sensors (RGB and multiple multispectral cameras), image resolution (proximal/remote sensing at 1.6 to 30 m above ground level/AGL), and image processing (standard and unsupervised learning) techniques in monitoring flowering intensity of four cool-season crops (canola, camelina, chickpea, and pea) to enhance the accuracy and efficiency in quantifying flowering traits. The features (flower area, percentage of flower area with respect to canopy area) extracted from proximal (1.6–2.2 m AGL) RGB and multispectral (with near infrared, green and blue band) image data were strongly correlated (r up to 0.89) with visual rating scores, especially in pea and canola. The features extracted from unmanned aerial vehicle integrated RGB image data (15–30 m AGL) could also accurately detect and quantify large flowers of winter canola (r up to 0.84), spring canola (r up to 0.72), and pea (r up to 0.72), but not camelina or chickpea flowers. When standard image processing using thresholds and unsupervised machine learning such as k-means clustering were utilized for flower detection and feature extraction, the results were comparable. In general, for applicability of imaging for flower detection, it is recommended that the image data resolution (i.e., ground sampling distance) is at least 2–3 times smaller than that of the flower size. Overall, this study demonstrates the feasibility of utilizing imaging for monitoring flowering intensity in multiple varieties of evaluated crops.
KW  - image processing
KW  - multispectral imaging
KW  - phenomics
KW  - plant breeding
KW  - UAV
DO  - 10.3390/s20051450
ER  -
TY  - EJOU
AU  - Frey, Julian
AU  - Asbeck, Thomas
AU  - Bauhus, Jürgen
TI  - Predicting Tree-Related Microhabitats by Multisensor Close-Range Remote Sensing Structural Parameters for the Selection of Retention Elements
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 5
SN  - 2072-4292

AB  - The retention of structural elements such as habitat trees in forests managed for timber production is essential for fulfilling the objectives of biodiversity conservation. This paper seeks to predict tree-related microhabitats (TreMs) by close-range remote sensing parameters. TreMs, such as cavities or crown deadwood, are an established tool to quantify the suitability of habitat trees for biodiversity conservation. The aim to predict TreMs based on remote sensing (RS) parameters is supposed to assist a more objective and efficient selection of retention elements. The RS parameters were collected by the use of terrestrial laser scanning as well as unmanned aerial vehicles structure from motion point cloud generation to provide a 3D distribution of plant tissue. Data was recorded on 135 1-ha plots in Germany. Statistical models were used to test the influence of 28 RS predictors, which described TreM richness (R2: 0.31) and abundance (R2: 0.31) in moderate precision and described a deviance of 44% for the abundance and 38% for richness of TreMs. Our results indicate that multiple RS techniques can achieve moderate predictions of TreM occurrence. This method allows a more efficient and objective selection of retention elements such as habitat trees that are keystone features for biodiversity conservation, even if it cannot be considered a full replacement of TreM inventories due to the moderate statistical relationship at this stage.
KW  - forest biodiversity
KW  - tree related microhabitats
KW  - terrestrial laser scanning
KW  - UAV
KW  - structure from motion
KW  - forest structure
DO  - 10.3390/rs12050867
ER  -
TY  - EJOU
AU  - Gao, Demin
AU  - Sun, Quan
AU  - Hu, Bin
AU  - Zhang, Shuo
TI  - A Framework for Agricultural Pest and Disease Monitoring Based on Internet-of-Things and Unmanned Aerial Vehicles
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 5
SN  - 1424-8220

AB  - With the development of information technology, Internet-of-Things (IoT) and low-altitude remote-sensing technology represented by Unmanned Aerial Vehicles (UAVs) are widely used in environmental monitoring fields. In agricultural modernization, IoT and UAV can monitor the incidence of crop diseases and pests from the ground micro and air macro perspectives, respectively. IoT technology can collect real-time weather parameters of the crop growth by means of numerous inexpensive sensor nodes. While depending on spectral camera technology, UAVs can capture the images of farmland, and these images can be utilize for analyzing the occurrence of pests and diseases of crops. In this work, we attempt to design an agriculture framework for providing profound insights into the specific relationship between the occurrence of pests/diseases and weather parameters. Firstly, considering that most farms are usually located in remote areas and far away from infrastructure, making it hard to deploy agricultural IoT devices due to limited energy supplement, a sun tracker device is designed to adjust the angle automatically between the solar panel and the sunlight for improving the energy-harvesting rate. Secondly, for resolving the problem of short flight time of UAV, a flight mode is introduced to ensure the maximum utilization of wind force and prolong the fight time. Thirdly, the images captured by UAV are transmitted to the cloud data center for analyzing the degree of damage of pests and diseases based on spectrum analysis technology. Finally, the agriculture framework is deployed in the Yangtze River Zone of China and the results demonstrate that wheat is susceptible to disease when the temperature is between 14 &deg;C and 16 &deg;C, and high rainfall decreases the spread of wheat powdery mildew.
KW  - agricultural pests and diseases
KW  - internet of things
KW  - unmanned aerial vehicle
DO  - 10.3390/s20051487
ER  -
TY  - EJOU
AU  - Zhu, Xiaobo
AU  - He, Honglin
AU  - Ma, Mingguo
AU  - Ren, Xiaoli
AU  - Zhang, Li
AU  - Zhang, Fawei
AU  - Li, Yingnian
AU  - Shi, Peili
AU  - Chen, Shiping
AU  - Wang, Yanfen
AU  - Xin, Xiaoping
AU  - Ma, Yaoming
AU  - Zhang, Yu
AU  - Du, Mingyuan
AU  - Ge, Rong
AU  - Zeng, Na
AU  - Li, Pan
AU  - Niu, Zhongen
AU  - Zhang, Liyun
AU  - Lv, Yan
AU  - Song, Zengjing
AU  - Gu, Qing
TI  - Estimating Ecosystem Respiration in the Grasslands of Northern China Using Machine Learning: Model Evaluation and Comparison
T2  - Sustainability

PY  - 2020
VL  - 12
IS  - 5
SN  - 2071-1050

AB  - While a number of machine learning (ML) models have been used to estimate RE, systematic evaluation and comparison of these models are still limited. In this study, we developed three traditional ML models and a deep learning (DL) model, stacked autoencoders (SAE), to estimate RE in northern China&rsquo;s grasslands. The four models were trained with two strategies: training for all of northern China&rsquo;s grasslands and separate training for the alpine and temperate grasslands. Our results showed that all four ML models estimated RE in northern China&rsquo;s grasslands fairly well, while the SAE model performed best (R2 = 0.858, RMSE = 0.472 gC m&minus;2 d&minus;1, MAE = 0.304 gC m&minus;2 d&minus;1). Models trained with the two strategies had almost identical performances. The enhanced vegetation index and soil organic carbon density (SOCD) were the two most important environmental variables for estimating RE in the grasslands of northern China. Air temperature (Ta) was more important than the growing season land surface water index (LSWI) in the alpine grasslands, while the LSWI was more important than Ta in the temperate grasslands. These findings may promote the application of DL models and the inclusion of SOCD for RE estimates with increased accuracy.
KW  - ecosystem respiration
KW  - machine learning
KW  - deep learning
KW  - grasslands
KW  - northern China
DO  - 10.3390/su12052099
ER  -
TY  - EJOU
AU  - Zhao, Dan
AU  - Pang, Yong
AU  - Liu, Lijuan
AU  - Li, Zengyuan
TI  - Individual Tree Classification Using Airborne LiDAR and Hyperspectral Data in a Natural Mixed Forest of Northeast China
T2  - Forests

PY  - 2020
VL  - 11
IS  - 3
SN  - 1999-4907

AB  - This paper proposes a method to classify individual tree species groups based on individual tree segmentation and crown-level spectrum extraction (&ldquo;crown-based ITC&rdquo; for abbr.) in a natural mixed forest of Northeast China, and compares with the pixel-based classification and segment summarization results (&ldquo;pixel-based ITC&rdquo; for abbr.). Tree species is a basic factor in forest management, and it is traditionally identified by field survey. This paper aims to explore the potential of individual tree classification in a natural, needle-leaved and broadleaved mixed forest. First, individual trees were isolated, and the spectra of individual trees were then extracted. The support vector machine (SVM) and spectrum angle mapper (SAM) classifiers were applied to classify the trees species. The pixel-based classification results from hyperspectral data and LiDAR derived individual tree isolation were compared. The results showed that the crown-based ITC classified broadleaved trees better than pixel-based ITC, while the classes distribution of the crown-based ITC was closer to the survey data. This indicated that crown-based ITC performed better than pixel-based ITC. Crown-based ITC efficiently identified the classes of the dominant and sub-dominant species. Regardless of whether SVM or SAM was used, the identification consistency relative to the field observations for the class of the dominant species was greater than 90%. In contrast, the consistencies of the classes of the sub-dominant species were approximately 60%, and the overall consistency of both the SVM and SAM was greater than 70%.
KW  - individual tree classification
KW  - LiDAR
KW  - hyperspectral
KW  - SVM
KW  - natural forest
DO  - 10.3390/f11030303
ER  -
TY  - EJOU
AU  - Osco, Lucas P.
AU  - Ramos, Ana P.
AU  - Faita Pinheiro, Mayara M.
AU  - Moriya, Érika A.
AU  - Imai, Nilton N.
AU  - Estrabis, Nayara
AU  - Ianczyk, Felipe
AU  - Araújo, Fábio F.
AU  - Liesenberg, Veraldo
AU  - Jorge, Lúcio A.
AU  - Li, Jonathan
AU  - Ma, Lingfei
AU  - Gonçalves, Wesley N.
AU  - Marcato Junior, José
AU  - Eduardo Creste, José
TI  - A Machine Learning Framework to Predict Nutrient Content in Valencia-Orange Leaf Hyperspectral Measurements
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - This paper presents a framework based on machine learning algorithms to predict nutrient content in leaf hyperspectral measurements. This is the first approach to evaluate macro- and micronutrient content with both machine learning and reflectance/first-derivative data. For this, citrus-leaves collected at a Valencia-orange orchard were used. Their spectral data was measured with a Fieldspec ASD FieldSpec&reg; HandHeld 2 spectroradiometer and the surface reflectance and first-derivative spectra from the spectral range of 380 to 1020 nm (640 spectral bands) was evaluated. A total of 320 spectral signatures were collected, and the leaf-nutrient content (N, P, K, Mg, S, Cu, Fe, Mn, and Zn) was associated with them. For this, 204,800 (320 &times; 640) combinations were used. The following machine learning algorithms were used in this framework: k-Nearest Neighbor (kNN), Lasso Regression, Ridge Regression, Support Vector Machine (SVM), Artificial Neural Network (ANN), Decision Tree (DT), and Random Forest (RF). The training methods were assessed based on Cross-Validation and Leave-One-Out. The Relief-F metric of the algorithms&rsquo; prediction was used to determine the most contributive wavelength or spectral region associated with each nutrient. This approach was able to return, with high predictions (R2), nutrients like N (0.912), Mg (0.832), Cu (0.861), Mn (0.898), and Zn (0.855), and, to a lesser extent, P (0.771), K (0.763), and S (0.727). These accuracies were obtained with different algorithms, but RF was the most suitable to model most of them. The results indicate that, for the Valencia-orange leaves, surface reflectance data is more suitable to predict macronutrients, while first-derivative spectra is better linked to micronutrients. A final contribution of this study is the identification of the wavelengths responsible for contributing to these predictions.
KW  - spectroscopy
KW  - proximal sensor
KW  - macronutrient
KW  - micronutrient
KW  - artificial intelligence
DO  - 10.3390/rs12060906
ER  -
TY  - EJOU
AU  - Meiforth, Jane J.
AU  - Buddenbaum, Henning
AU  - Hill, Joachim
AU  - Shepherd, James
TI  - Monitoring of Canopy Stress Symptoms in New Zealand Kauri Trees Analysed with AISA Hyperspectral Data
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - The endemic New Zealand kauri trees (Agathis australis) are under threat by the deadly kauri dieback disease (Phytophthora agathidicida (PA)). This study aimed to identify spectral index combinations for characterising visible stress symptoms in the kauri canopy. The analysis is based on an aerial AISA hyperspectral image mosaic and 1258 reference crowns in three study sites in the Waitakere Ranges west of Auckland. A field-based assessment scheme for canopy stress symptoms (classes 1&ndash;5) was further optimised for use with RGB aerial images. A combination of four indices with six bands in the spectral range 450&ndash;1205 nm resulted in a correlation of 0.93 (mean absolute error 0.27, RMSE 0.48) for all crown sizes. Comparable results were achieved with five indices in the 450&ndash;970 nm region. A Random Forest (RF) regression gave the most accurate predictions while a M5P regression tree performed nearly as well and a linear regression resulted in slightly lower correlations. Normalised Difference Vegetation Indices (NDVI) in the near-infrared / red spectral range were the most important index combinations, followed by indices with bands in the near-infrared spectral range from 800 to 1205 nm. A test on different crown sizes revealed that stress symptoms in smaller crowns with denser foliage are best described in combination with pigment-sensitive indices that include bands in the green and blue spectral range. A stratified approach with individual models for pre-segmented low and high forest stands improved the overall performance. The regression models were also tested in a pixel-based analysis. A manual interpretation of the resulting raster map with stress symptom patterns observed in aerial imagery indicated a good match. With bandwidths of 10 nm and a maximum number of six bands, the selected index combinations can be used for large-area monitoring on an airborne multispectral sensor. This study establishes the base for a cost-efficient, objective monitoring method for stress symptoms in kauri canopies, suitable to cover large forest areas with an airborne multispectral sensor.
KW  - hyperspectral
KW  - forest health
KW  - random forest
KW  - AISA Fenix
KW  - Waitakere ranges
KW  - New Zealand
KW  - kauri dieback disease
KW  - Phytophthora agathidicida
DO  - 10.3390/rs12060926
ER  -
TY  - EJOU
AU  - Gaffey, Clare
AU  - Bhardwaj, Anshuman
TI  - Applications of Unmanned Aerial Vehicles in Cryosphere: Latest Advances and Prospects
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - Owing to usual logistic hardships related to field-based cryospheric research, remote sensing has played a significant role in understanding the frozen components of the Earth system. Conventional spaceborne or airborne remote sensing platforms have their own merits and limitations. Unmanned aerial vehicles (UAVs) have emerged as a viable and inexpensive option for studying the cryospheric components at unprecedented spatiotemporal resolutions. UAVs are adaptable to various cryospheric research needs in terms of providing flexibility with data acquisition windows, revisits, data/sensor types (multispectral, hyperspectral, microwave, thermal/night imaging, Light Detection and Ranging (LiDAR), and photogrammetric stereos), viewing angles, flying altitudes, and overlap dimensions. Thus, UAVs have the potential to act as a bridging remote sensing platform between spatially discrete in situ observations and spatially continuous but coarser and costlier spaceborne or conventional airborne remote sensing. In recent years, a number of studies using UAVs for cryospheric research have been published. However, a holistic review discussing the methodological advancements, hardware and software improvements, results, and future prospects of such cryospheric studies is completely missing. In the present scenario of rapidly changing global and regional climate, studying cryospheric changes using UAVs is bound to gain further momentum and future studies will benefit from a balanced review on this topic. Our review covers the most recent applications of UAVs within glaciology, snow, permafrost, and polar research to support the continued development of high-resolution investigations of cryosphere. We also analyze the UAV and sensor hardware, and data acquisition and processing software in terms of popularity for cryospheric applications and revisit the existing UAV flying regulations in cold regions of the world. The recent usage of UAVs outlined in 103 case studies provide expertise that future investigators should base decisions on.
KW  - UAV
KW  - unmanned aerial systems (UAS)
KW  - drone
KW  - cryosphere
KW  - arctic
KW  - polar
KW  - remote sensing
DO  - 10.3390/rs12060948
ER  -
TY  - EJOU
AU  - Pashaei, Mohammad
AU  - Kamangir, Hamid
AU  - Starek, Michael J.
AU  - Tissot, Philippe
TI  - Review and Evaluation of Deep Learning Architectures for Efficient Land Cover Mapping with UAS Hyper-Spatial Imagery: A Case Study Over a Wetland
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - Deep learning has already been proved as a powerful state-of-the-art technique for many image understanding tasks in computer vision and other applications including remote sensing (RS) image analysis. Unmanned aircraft systems (UASs) offer a viable and economical alternative to a conventional sensor and platform for acquiring high spatial and high temporal resolution data with high operational flexibility. Coastal wetlands are among some of the most challenging and complex ecosystems for land cover prediction and mapping tasks because land cover targets often show high intra-class and low inter-class variances. In recent years, several deep convolutional neural network (CNN) architectures have been proposed for pixel-wise image labeling, commonly called semantic image segmentation. In this paper, some of the more recent deep CNN architectures proposed for semantic image segmentation are reviewed, and each model&rsquo;s training efficiency and classification performance are evaluated by training it on a limited labeled image set. Training samples are provided using the hyper-spatial resolution UAS imagery over a wetland area and the required ground truth images are prepared by manual image labeling. Experimental results demonstrate that deep CNNs have a great potential for accurate land cover prediction task using UAS hyper-spatial resolution images. Some simple deep learning architectures perform comparable or even better than complex and very deep architectures with remarkably fewer training epochs. This performance is especially valuable when limited training samples are available, which is a common case in most RS applications.
KW  - coastal wetland
KW  - land cover mapping
KW  - semantic image segmentation
KW  - machine learning
KW  - deep learning
KW  - convolutional neural networks
KW  - transfer learning
KW  - unmanned aircraft systems
DO  - 10.3390/rs12060959
ER  -
TY  - EJOU
AU  - Liu, Changyu
AU  - Huang, Xiaodong
AU  - Li, Xubing
AU  - Liang, Tiangang
TI  - MODIS Fractional Snow Cover Mapping Using Machine Learning Technology in a Mountainous Area
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - To improve the poor accuracy of the MODIS (Moderate Resolution Imaging Spectroradiometer) daily fractional snow cover product over the complex terrain of the Tibetan Plateau (RMSE = 0.30), unmanned aerial vehicle and machine learning technologies are employed to map the fractional snow cover based on MODIS over this terrain. Three machine learning models, including random forest, support vector machine, and back-propagation artificial neural network models, are trained and compared in this study. The results indicate that compared with the MODIS daily fractional snow cover product, the introduction of a highly accurate snow map acquired by unmanned aerial vehicles as a reference into machine learning models can significantly improve the MODIS fractional snow cover mapping accuracy. The random forest model shows the best accuracy among the three machine learning models, with an RMSE (root-mean-square error) of 0.23, especially over forestland and shrubland, with RMSEs of 0.13 and 0.18, respectively. Although the accuracy of the support vector machine and back-propagation artificial neural network models are worse over forestland and shrubland, their average errors are still better than that of MOD10A1. Different fractional snow cover gradients also affect the accuracy of the machine learning algorithms. Nevertheless, the random forest model remains stable in different fractional snow cover gradients and is, therefore, the best machine learning algorithm for MODIS fractional snow cover mapping in Tibetan Plateau areas with complex terrain and severely fragmented snow cover.
KW  - MODIS
KW  - fractinal snow cover
KW  - UAV
KW  - Tibetan Plateau
DO  - 10.3390/rs12060962
ER  -
TY  - EJOU
AU  - Sonobe, Rei
AU  - Hirono, Yuhei
AU  - Oi, Ayako
TI  - Non-Destructive Detection of Tea Leaf Chlorophyll Content Using Hyperspectral Reflectance and Machine Learning Algorithms
T2  - Plants

PY  - 2020
VL  - 9
IS  - 3
SN  - 2223-7747

AB  - Tea trees are kept in shaded locations to increase their chlorophyll content, which influences green tea quality. Therefore, monitoring change in chlorophyll content under low light conditions is important for managing tea trees and producing high-quality green tea. Hyperspectral remote sensing is one of the most frequently used methods for estimating chlorophyll content. Numerous studies based on data collected under relatively low-stress conditions and many hyperspectral indices and radiative transfer models show that shade-grown tea performs poorly. The performance of four machine learning algorithms&mdash;random forest, support vector machine, deep belief nets, and kernel-based extreme learning machine (KELM)&mdash;in evaluating data collected from tea leaves cultivated under different shade treatments was tested. KELM performed best with a root-mean-square error of 8.94 &plusmn; 3.05 &mu;g cm&minus;2 and performance to deviation values from 1.70 to 8.04 for the test data. These results suggest that a combination of hyperspectral reflectance and KELM has the potential to trace changes in the chlorophyll content of shaded tea leaves.
KW  - deep belief nets
KW  - extreme learning machine
KW  - first derivative spectra
KW  - random forest
KW  - shade-grown tea
KW  - support vector machine
DO  - 10.3390/plants9030368
ER  -
TY  - EJOU
AU  - Mohd Noor, Norzailawati
AU  - Ibrahim, Illyani
AU  - Abdullah, Alias
AU  - Abdullah, Ahmad A.
TI  - Information Fusion for Cultural Heritage Three-Dimensional Modeling of Malay Cities
T2  - ISPRS International Journal of Geo-Information

PY  - 2020
VL  - 9
IS  - 3
SN  - 2220-9964

AB  - Malaysia&rsquo;s heritage structures are facing challenges due to rapid local development and societal challenges that threaten their cultural and artistic values. Improving conservation approaches in this context is an urgent and crucial task. The application of geo-information technologies in laser scanning, photogrammetry, and geographic information systems (GISs) has significantly improved these conservation approaches. In this study, we fused drone images and range data from a laser scanner to construct a high-resolution three-dimensional GIS city model for one traditional Malay settlement located in Malaysia. The results showed that fusing photogrammetry and laser scanning can effectively capture the architectural uniqueness of Malay buildings, including specific fa&ccedil;ade geometries on walls, roofs, and motifs. The findings show that the development of various geoinformation approaches can assist with the conservation of Malay city heritage in this region.
KW  - UAV
KW  - mobile laser scanner
KW  - Malay city heritage
KW  - 3D GIS modeling
KW  - Geoinformation
DO  - 10.3390/ijgi9030177
ER  -
TY  - EJOU
AU  - Martin-Abadal, Miguel
AU  - Ruiz-Frau, Ana
AU  - Hinz, Hilmar
AU  - Gonzalez-Cid, Yolanda
TI  - Jellytoring: Real-Time Jellyfish Monitoring Based on Deep Learning Object Detection
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 6
SN  - 1424-8220

AB  - During the past decades, the composition and distribution of marine species have changed due to multiple anthropogenic pressures. Monitoring these changes in a cost-effective manner is of high relevance to assess the environmental status and evaluate the effectiveness of management measures. In particular, recent studies point to a rise of jellyfish populations on a global scale, negatively affecting diverse marine sectors like commercial fishing or the tourism industry. Past monitoring efforts using underwater video observations tended to be time-consuming and costly due to human-based data processing. In this paper, we present Jellytoring, a system to automatically detect and quantify different species of jellyfish based on a deep object detection neural network, allowing us to automatically record jellyfish presence during long periods of time. Jellytoring demonstrates outstanding performance on the jellyfish detection task, reaching an F1 score of 95.2%; and also on the jellyfish quantification task, as it correctly quantifies the number and class of jellyfish on a real-time processed video sequence up to a 93.8% of its duration. The results of this study are encouraging and provide the means towards a efficient way to monitor jellyfish, which can be used for the development of a jellyfish early-warning system, providing highly valuable information for marine biologists and contributing to the reduction of jellyfish impacts on humans.
KW  - deep learning
KW  - object detection
KW  - jellyfish quantification
KW  - jellyfish monitoring
DO  - 10.3390/s20061708
ER  -
TY  - EJOU
AU  - Mandlburger, Gottfried
AU  - Pfennigbauer, Martin
AU  - Schwarz, Roland
AU  - Flöry, Sebastian
AU  - Nussbaumer, Lukas
TI  - Concept and Performance Evaluation of a Novel UAV-Borne Topo-Bathymetric LiDAR Sensor
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - We present the sensor concept and first performance and accuracy assessment results of a novel lightweight topo-bathymetric laser scanner designed for integration on Unmanned Aerial Vehicles (UAVs), light aircraft, and helicopters. The instrument is particularly well suited for capturing river bathymetry in high spatial resolution as a consequence of (i) the low nominal flying altitude of 50&ndash;150 m above ground level resulting in a laser footprint diameter on the ground of typically 10&ndash;30 cm and (ii) the high pulse repetition rate of up to 200 kHz yielding a point density on the ground of approximately 20&ndash;50 points/m2. The instrument features online waveform processing and additionally stores the full waveform within the entire range gate for waveform analysis in post-processing. The sensor was tested in a real-world environment by acquiring data from two freshwater ponds and a 500 m section of the pre-Alpine Pielach River (Lower Austria). The captured underwater points featured a maximum penetration of two times the Secchi depth. On dry land, the 3D point clouds exhibited (i) a measurement noise in the range of 1&ndash;3 mm; (ii) a fitting precision of redundantly captured flight strips of 1 cm; and (iii) an absolute accuracy of 2&ndash;3 cm compared to terrestrially surveyed checkerboard targets. A comparison of the refraction corrected LiDAR point cloud with independent underwater checkpoints exhibited a maximum deviation of 7.8 cm and revealed a systematic depth-dependent error when using a refraction coefficient of n = 1.36 for time-of-flight correction. The bias is attributed to multi-path effects in the turbid water column (Secchi depth: 1.1 m) caused by forward scattering of the laser signal at suspended particles. Due to the high spatial resolution, good depth performance, and accuracy, the sensor shows a high potential for applications in hydrology, fluvial morphology, and hydraulic engineering, including flood simulation, sediment transport modeling, and habitat mapping.
KW  - UAV LiDAR
KW  - airborne laser bathymetry
KW  - full waveform processing
KW  - performance assessment
KW  - high resolution hydro-mapping
DO  - 10.3390/rs12060986
ER  -
TY  - EJOU
AU  - Shi, Wenlei
AU  - Li, Zerui
AU  - Lv, Wenjun
AU  - Wu, Yuping
AU  - Chang, Ji
AU  - Li, Xiaochuan
TI  - Laplacian Support Vector Machine for Vibration-Based Robotic Terrain Classification
T2  - Electronics

PY  - 2020
VL  - 9
IS  - 3
SN  - 2079-9292

AB  - The achievement of robot autonomy has environmental perception as a prerequisite. The hazards rendered from uneven, soft and slippery terrains, which are generally named non-geometric hazards, are another potential threat reducing the traversing efficient, and therefore receiving more and more attention from the robotics community. In the paper, the vibration-based terrain classification (VTC) is investigated by taking a very practical issue, i.e., lack of labels, into consideration. According to the intrinsic temporal correlation existing in the sampled terrain sequence, a modified Laplacian SVM is proposed to utilise the unlabelled data to improve the classification performance. To the best of our knowledge, this is the first paper studying semi-supervised learning problem in robotic terrain classification. The experiment demonstrates that: (1) supervised learning (SVM) achieves a relatively low classification accuracy if given insufficient labels; (2) feature-space homogeneity based semi-supervised learning (traditional Laplacian SVM) cannot improve supervised learning&rsquo;s accuracy, and even makes it worse; (3) feature- and temporal-space based semi-supervised learning (modified Laplacian SVM), which is proposed in the paper, could increase the classification accuracy very significantly.
KW  - non-geometric hazards
KW  - terrain classification
KW  - vibration
KW  - semi-supervised learning
DO  - 10.3390/electronics9030513
ER  -
TY  - EJOU
AU  - Tomaszewski, Michał
AU  - Michalski, Paweł
AU  - Osuchowski, Jakub
TI  - Evaluation of Power Insulator Detection Efficiency with the Use of Limited Training Dataset
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 6
SN  - 2076-3417

AB  - This article presents an analysis of the effectiveness of object detection in digital images with the application of a limited quantity of input. The possibility of using a limited set of learning data was achieved by developing a detailed scenario of the task, which strictly defined the conditions of detector operation in the considered case of a convolutional neural network. The described solution utilizes known architectures of deep neural networks in the process of learning and object detection. The article presents comparisons of results from detecting the most popular deep neural networks while maintaining a limited training set composed of a specific number of selected images from diagnostic video. The analyzed input material was recorded during an inspection flight conducted along high-voltage lines. The object detector was built for a power insulator. The main contribution of the presented papier is the evidence that a limited training set (in our case, just 60 training frames) could be used for object detection, assuming an outdoor scenario with low variability of environmental conditions. The decision of which network will generate the best result for such a limited training set is not a trivial task. Conducted research suggests that the deep neural networks will achieve different levels of effectiveness depending on the amount of training data. The most beneficial results were obtained for two convolutional neural networks: the faster region-convolutional neural network (faster R-CNN) and the region-based fully convolutional network (R-FCN). Faster R-CNN reached the highest AP (average precision) at a level of 0.8 for 60 frames. The R-FCN model gained a worse AP result; however, it can be noted that the relationship between the number of input samples and the obtained results has a significantly lower influence than in the case of other CNN models, which, in the authors&rsquo; assessment, is a desired feature in the case of a limited training set.
KW  - convolutional neural network
KW  - deep neural network
KW  - insulator detection
KW  - efficiency evaluation
KW  - power system maintenance
DO  - 10.3390/app10062104
ER  -
TY  - EJOU
AU  - Tmušić, Goran
AU  - Manfreda, Salvatore
AU  - Aasen, Helge
AU  - James, Mike R.
AU  - Gonçalves, Gil
AU  - Ben-Dor, Eyal
AU  - Brook, Anna
AU  - Polinova, Maria
AU  - Arranz, Jose J.
AU  - Mészáros, János
AU  - Zhuang, Ruodan
AU  - Johansen, Kasper
AU  - Malbeteau, Yoann
AU  - de Lima, Isabel P.
AU  - Davids, Corine
AU  - Herban, Sorin
AU  - McCabe, Matthew F.
TI  - Current Practices in UAS-based Environmental Monitoring
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - With the increasing role that unmanned aerial systems (UAS) are playing in data collection for environmental studies, two key challenges relate to harmonizing and providing standardized guidance for data collection, and also establishing protocols that are applicable across a broad range of environments and conditions. In this context, a network of scientists are cooperating within the framework of the Harmonious Project to develop and promote harmonized mapping strategies and disseminate operational guidance to ensure best practice for data collection and interpretation. The culmination of these efforts is summarized in the present manuscript. Through this synthesis study, we identify the many interdependencies of each step in the collection and processing chain, and outline approaches to formalize and ensure a successful workflow and product development. Given the number of environmental conditions, constraints, and variables that could possibly be explored from UAS platforms, it is impractical to provide protocols that can be applied universally under all scenarios. However, it is possible to collate and systematically order the fragmented knowledge on UAS collection and analysis to identify the best practices that can best ensure the streamlined and rigorous development of scientific products.
KW  - UAS-based mapping
KW  - environmental monitoring
KW  - effective workflow
KW  - guidelines
DO  - 10.3390/rs12061001
ER  -
TY  - EJOU
AU  - Xu, Jin
AU  - Wang, Haixia
AU  - Cui, Can
AU  - Zhao, Baigang
AU  - Li, Bo
TI  - Oil Spill Monitoring of Shipborne Radar Image Features Using SVM and Local Adaptive Threshold
T2  - Algorithms

PY  - 2020
VL  - 13
IS  - 3
SN  - 1999-4893

AB  - In the case of marine accidents, monitoring marine oil spills can provide an important basis for identifying liabilities and assessing the damage. Shipborne radar can ensure large-scale, real-time monitoring, in all weather, with high-resolution. It therefore has the potential for broad applications in oil spill monitoring. Considering the original gray-scale image from the shipborne radar acquired in the case of the Dalian 7.16 oil spill accident, a complete oil spill detection method is proposed. Firstly, the co-frequency interferences and speckles in the original image are eliminated by preprocessing. Secondly, the wave information is classified using a support vector machine (SVM), and the effective wave monitoring area is generated according to the gray distribution matrix. Finally, oil spills are detected by a local adaptive threshold and displayed on an electronic chart based on geographic information system (GIS). The results show that the SVM can extract the effective wave information from the original shipborne radar image, and the local adaptive threshold method has strong applicability for oil film segmentation. This method can provide a technical basis for real-time cleaning and liability determination in oil spill accidents.
KW  - oil spill
KW  - SVM
KW  - real-time monitoring
KW  - shipborne radar
KW  - remote sensing
KW  - image processing
KW  - GIS
DO  - 10.3390/a13030069
ER  -
TY  - EJOU
AU  - Zhao, Yan
AU  - Potgieter, Andries B.
AU  - Zhang, Miao
AU  - Wu, Bingfang
AU  - Hammer, Graeme L.
TI  - Predicting Wheat Yield at the Field Scale by Combining High-Resolution Sentinel-2 Satellite Imagery and Crop Modelling
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - Accurate prediction of crop yield at the field scale is critical to addressing crop production challenges and reducing the impacts of climate variability and change. Recently released Sentinel-2 (S2) satellite data with a return cycle of five days and a high resolution at 13 spectral bands allows close observation of crop phenology and crop physiological attributes at field scale during crop growth. Here, we test the potential for indices derived from S2 data to estimate dryland wheat yields at the field scale and the potential for enhanced predictability by incorporating a modelled crop water stress index (SI). Observations from 103 study fields over the 2016 and 2017 cropping seasons across Northeastern Australia were used. Vegetation indices derived from S2 showed moderately high accuracy in yield prediction and explained over 70% of the yield variability. Specifically, the red edge chlorophyll index (CI; chlorophyll) (R2 = 0.76, RMSE = 0.88 t/ha) and the optimized soil-adjusted vegetation index (OSAVI; structural) (R2 = 0.74, RMSE = 0.91 t/ha) showed the best correlation with field yields. Furthermore, combining the crop model-derived SI with both structural and chlorophyll indices significantly enhanced predictability. The best model with combined OSAVI, CI and SI generated a much higher correlation, with R2 = 0.91 and RMSE = 0.54 t/ha. When validating the models on an independent set of fields, this model also showed high correlation (R2 = 0.93, RMSE = 0.64 t/ha). This study demonstrates the potential of combining S2-derived indices and crop model-derived indices to construct an enhanced yield prediction model suitable for fields in diversified climate conditions.
KW  - sentinel
KW  - Google Earth Engine
KW  - atmospheric correction
KW  - wheat yield prediction
KW  - crop stress
DO  - 10.3390/rs12061024
ER  -
TY  - EJOU
AU  - Elmes, Arthur
AU  - Alemohammad, Hamed
AU  - Avery, Ryan
AU  - Caylor, Kelly
AU  - Eastman, J. R.
AU  - Fishgold, Lewis
AU  - Friedl, Mark A.
AU  - Jain, Meha
AU  - Kohli, Divyani
AU  - Laso Bayas, Juan C.
AU  - Lunga, Dalton
AU  - McCarty, Jessica L.
AU  - Pontius, Robert G.
AU  - Reinmann, Andrew B.
AU  - Rogan, John
AU  - Song, Lei
AU  - Stoynova, Hristiana
AU  - Ye, Su
AU  - Yi, Zhuang-Fang
AU  - Estes, Lyndon
TI  - Accounting for Training Data Error in Machine Learning Applied to Earth Observations
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 6
SN  - 2072-4292

AB  - Remote sensing, or Earth Observation (EO), is increasingly used to understand Earth system dynamics and create continuous and categorical maps of biophysical properties and land cover, especially based on recent advances in machine learning (ML). ML models typically require large, spatially explicit training datasets to make accurate predictions. Training data (TD) are typically generated by digitizing polygons on high spatial-resolution imagery, by collecting in situ data, or by using pre-existing datasets. TD are often assumed to accurately represent the truth, but in practice almost always have error, stemming from (1) sample design, and (2) sample collection errors. The latter is particularly relevant for image-interpreted TD, an increasingly commonly used method due to its practicality and the increasing training sample size requirements of modern ML algorithms. TD errors can cause substantial errors in the maps created using ML algorithms, which may impact map use and interpretation. Despite these potential errors and their real-world consequences for map-based decisions, TD error is often not accounted for or reported in EO research. Here we review the current practices for collecting and handling TD. We identify the sources of TD error, and illustrate their impacts using several case studies representing different EO applications (infrastructure mapping, global surface flux estimates, and agricultural monitoring), and provide guidelines for minimizing and accounting for TD errors. To harmonize terminology, we distinguish TD from three other classes of data that should be used to create and assess ML models: training reference data, used to assess the quality of TD during data generation; validation data, used to iteratively improve models; and map reference data, used only for final accuracy assessment. We focus primarily on TD, but our advice is generally applicable to all four classes, and we ground our review in established best practices for map accuracy assessment literature. EO researchers should start by determining the tolerable levels of map error and appropriate error metrics. Next, TD error should be minimized during sample design by choosing a representative spatio-temporal collection strategy, by using spatially and temporally relevant imagery and ancillary data sources during TD creation, and by selecting a set of legend definitions supported by the data. Furthermore, TD error can be minimized during the collection of individual samples by using consensus-based collection strategies, by directly comparing interpreted training observations against expert-generated training reference data to derive TD error metrics, and by providing image interpreters with thorough application-specific training. We strongly advise that TD error is incorporated in model outputs, either directly in bias and variance estimates or, at a minimum, by documenting the sources and implications of error. TD should be fully documented and made available via an open TD repository, allowing others to replicate and assess its use. To guide researchers in this process, we propose three tiers of TD error accounting standards. Finally, we advise researchers to clearly communicate the magnitude and impacts of TD error on map outputs, with specific consideration given to the likely map audience.
KW  - training data
KW  - machine learning
KW  - map accuracy
KW  - error propagation
DO  - 10.3390/rs12061034
ER  -
TY  - EJOU
AU  - Abubakar, Ghali A.
AU  - Wang, Ke
AU  - Shahtahamssebi, AmirReza
AU  - Xue, Xingyu
AU  - Belete, Marye
AU  - Gudo, Adam J.
AU  - Mohamed Shuka, Kamal A.
AU  - Gan, Muye
TI  - Mapping Maize Fields by Using Multi-Temporal Sentinel-1A and Sentinel-2A Images in Makarfi, Northern Nigeria, Africa
T2  - Sustainability

PY  - 2020
VL  - 12
IS  - 6
SN  - 2071-1050

AB  - A timely and accurate crop type mapping is very significant, and a prerequisite for agricultural regions and ensuring global food security. The combination of remotely sensed optical and radar datasets presents an opportunity for acquiring crop information at relative spatial resolution and temporal resolution adequately to capture the growth profiles of various crop species. In this paper, we employed Sentinel-1A (S-1) and Sentinel-2A (S-2) data acquired between the end of June and early September 2016, on a semi-arid area in northern Nigeria. A different set of (VV and VH) SAR and optical (SI and SB) images, illustrating crop phenological development stage, were employed as inputs to the two machines learning Random Forest (RF) and Support Vector Machine (SVM) algorithms to automatically map maize fields. Significant increases in overall classification were shown when the multi-temporal spectral indices (SI) and spectral band (SB) datasets were added with the different integration of SAR datasets (i.e., VV and VH). The best overall accuracy (OA) for maize (96.93%) was derived by using RF classification algorithms with SI-SB-SAR datasets, although the SI datasets for RF and SB datasets for SVM also produced high overall maize classification accuracies, of 97.04% and 97.44%. The outcomes indicate the robustness of the RF or SVM methods to produce high-resolution maps of maize for subsequent application from agronomists, policy planners, and the government, because such information is lacking in our study area.
KW  - Sentinel-1
KW  - Sentinel-2
KW  - smallholder
KW  - tropical
KW  - food security
KW  - maize fields
KW  - random forest
KW  - support vector machine
DO  - 10.3390/su12062539
ER  -
TY  - EJOU
AU  - Gibril, Mohamed Barakat A.
AU  - Kalantar, Bahareh
AU  - Al-Ruzouq, Rami
AU  - Ueda, Naonori
AU  - Saeidi, Vahideh
AU  - Shanableh, Abdallah
AU  - Mansor, Shattri
AU  - Shafri, Helmi Z. M.
TI  - Mapping Heterogeneous Urban Landscapes from the Fusion of Digital Surface Model and Unmanned Aerial Vehicle-Based Images Using Adaptive Multiscale Image Segmentation and Classification
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - Considering the high-level details in an ultrahigh-spatial-resolution (UHSR) unmanned aerial vehicle (UAV) dataset, detailed mapping of heterogeneous urban landscapes is extremely challenging because of the spectral similarity between classes. In this study, adaptive hierarchical image segmentation optimization, multilevel feature selection, and multiscale (MS) supervised machine learning (ML) models were integrated to accurately generate detailed maps for heterogeneous urban areas from the fusion of the UHSR orthomosaic and digital surface model (DSM). The integrated approach commenced through a preliminary MS image segmentation parameter selection, followed by the application of three supervised ML models, namely, random forest (RF), support vector machine (SVM), and decision tree (DT). These models were implemented at the optimal MS levels to identify preliminary information, such as the optimal segmentation level(s) and relevant features, for extracting 12 land use/land cover (LULC) urban classes from the fused datasets. Using the information obtained from the first phase of the analysis, detailed MS classification was iteratively conducted to improve the classification accuracy and derive the final urban LULC maps. Two UAV-based datasets were used to develop and assess the effectiveness of the proposed framework. The hierarchical classification of the pilot study area showed that the RF was superior with an overall accuracy (OA) of 94.40% and a kappa coefficient (K) of 0.938, followed by SVM (OA = 92.50% and K = 0.917) and DT (OA = 91.60% and K = 0.908). The classification results of the second dataset revealed that SVM was superior with an OA of 94.45% and K of 0.938, followed by RF (OA = 92.46% and K = 0.916) and DT (OA = 90.46% and K = 0.893). The proposed framework exhibited an excellent potential for the detailed mapping of heterogeneous urban landscapes from the fusion of UHSR orthophoto and DSM images using various ML models.
KW  - unmanned aerial vehicle
KW  - urban LULC
KW  - GEOBIA
KW  - multiscale classification
DO  - 10.3390/rs12071081
ER  -
TY  - EJOU
AU  - Zhang, Weixing
AU  - Liljedahl, Anna K.
AU  - Kanevskiy, Mikhail
AU  - Epstein, Howard E.
AU  - Jones, Benjamin M.
AU  - Jorgenson, M. T.
AU  - Kent, Kelcy
TI  - Transferability of the Deep Learning Mask R-CNN Model for Automated Mapping of Ice-Wedge Polygons in High-Resolution Satellite and UAV Images
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - State-of-the-art deep learning technology has been successfully applied to relatively small selected areas of very high spatial resolution (0.15 and 0.25 m) optical aerial imagery acquired by a fixed-wing aircraft to automatically characterize ice-wedge polygons (IWPs) in the Arctic tundra. However, any mapping of IWPs at regional to continental scales requires images acquired on different sensor platforms (particularly satellite) and a refined understanding of the performance stability of the method across sensor platforms through reliable evaluation assessments. In this study, we examined the transferability of a deep learning Mask Region-Based Convolutional Neural Network (R-CNN) model for mapping IWPs in satellite remote sensing imagery (~0.5 m) covering 272 km2 and unmanned aerial vehicle (UAV) (0.02 m) imagery covering 0.32 km2. Multi-spectral images were obtained from the WorldView-2 satellite sensor and pan-sharpened to ~0.5 m, and a 20 mp CMOS sensor camera onboard a UAV, respectively. The training dataset included 25,489 and 6022 manually delineated IWPs from satellite and fixed-wing aircraft aerial imagery near the Arctic Coastal Plain, northern Alaska. Quantitative assessments showed that individual IWPs were correctly detected at up to 72% and 70%, and delineated at up to 73% and 68% F1 score accuracy levels for satellite and UAV images, respectively. Expert-based qualitative assessments showed that IWPs were correctly detected at good (40&ndash;60%) and excellent (80&ndash;100%) accuracy levels for satellite and UAV images, respectively, and delineated at excellent (80&ndash;100%) level for both images. We found that (1) regardless of spatial resolution and spectral bands, the deep learning Mask R-CNN model effectively mapped IWPs in both remote sensing satellite and UAV images; (2) the model achieved a better accuracy in detection with finer image resolution, such as UAV imagery, yet a better accuracy in delineation with coarser image resolution, such as satellite imagery; (3) increasing the number of training data with different resolutions between the training and actual application imagery does not necessarily result in better performance of the Mask R-CNN in IWPs mapping; (4) and overall, the model underestimates the total number of IWPs particularly in terms of disjoint/incomplete IWPs.
KW  - ice-wedge polygons
KW  - Arctic
KW  - deep learning
KW  - Mask R-CNN
KW  - WorldView-2
KW  - UAV
DO  - 10.3390/rs12071085
ER  -
TY  - EJOU
AU  - Dupuis, Chloé
AU  - Lejeune, Philippe
AU  - Michez, Adrien
AU  - Fayolle, Adeline
TI  - How Can Remote Sensing Help Monitor Tropical Moist Forest Degradation?—A Systematic Review
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - In the context of the climate and biodiversity crisis facing our planet, tropical forests playing a key role in global carbon flux and containing over half of Earth&rsquo;s species are important to preserve. They are today threatened by deforestation but also by forest degradation, which is more difficult to study. Here, we performed a systematic review of studies on moist tropical forest degradation using remote sensing and fitting indicators of forest resilience to perturbations. Geographical repartition, spatial extent and temporal evolution were analyzed. Indicators of compositional, structural and regeneration criteria were noted as well as remote sensing indices and metrics used. Tropical moist forest degradation is not extensively studied especially in the Congo basin and in southeast Asia. Forest structure (i.e., canopy gaps, fragmentation and biomass) is the most widely and easily measured criteria with remote sensing, while composition and regeneration are more difficult to characterize. Mixing LiDAR/Radar and optical data shows good potential as well as very high-resolution satellite data. The awaited GEDI and BIOMASS satellites data will fill the actual gap to a large extent and provide accurate structural information. LiDAR and unmanned aerial vehicles (UAVs) form a good bridge between field and satellite data. While the performance of the LiDAR is no longer to be demonstrated, particular attention should be brought to the UAV that shows great potential and could be more easily used by local communities and stakeholders.
KW  - tropical moist forest
KW  - forest degradation
KW  - remote sensing
KW  - forest degradation metrics
KW  - forest resilience
KW  - forest structure
KW  - forest composition
KW  - forest regeneration
DO  - 10.3390/rs12071087
ER  -
TY  - EJOU
AU  - Yuzugullu, Onur
AU  - Lorenz, Frank
AU  - Fröhlich, Peter
AU  - Liebisch, Frank
TI  - Understanding Fields by Remote Sensing: Soil Zoning and Property Mapping
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - Precision agriculture aims to optimize field management to increase agronomic yield, reduce environmental impact, and potentially foster soil carbon sequestration. In 2015, the Copernicus mission, with Sentinel-1 and -2, opened a new era by providing freely available high spatial and temporal resolution satellite data. Since then, many studies have been conducted to understand, monitor and improve agricultural systems. This paper presents results from the SolumScire project, focusing on the prediction of the spatial distribution of soil zones and topsoil properties, such as pH, soil organic matter (SOM) and clay content in agricultural fields through random forest algorithms. For this purpose, samples from 120 fields were investigated. The zoning and soil property prediction has an accuracy greater than 90%. This is supported by a high agreement of the derived zones with farmer&rsquo;s observations. The trained models revealed a prediction accuracy of 94%, 89% and 96% for pH, SOM and clay content, respectively. The obtained models for soil properties can support precision field management, the improvement of soil sampling and fertilization strategies, and eventually the management of soil properties such as SOM.
KW  - soil property prediction
KW  - pH
KW  - soil organic matter
KW  - soil clay content
KW  - precision agriculture
KW  - Copernicus mission
KW  - Sentinel
KW  - multi-spectral imagery
KW  - synthetic aperture radar imagery
KW  - machine learning
KW  - random forest
DO  - 10.3390/rs12071116
ER  -
TY  - EJOU
AU  - Farhood, Helia
AU  - Perry, Stuart
AU  - Cheng, Eva
AU  - Kim, Juno
TI  - Enhanced 3D Point Cloud from a Light Field Image
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - The importance of three-dimensional (3D) point cloud technologies in the field of agriculture environmental research has increased in recent years. Obtaining dense and accurate 3D reconstructions of plants and urban areas provide useful information for remote sensing. In this paper, we propose a novel strategy for the enhancement of 3D point clouds from a single 4D light field (LF) image. Using a light field camera in this way creates an easy way for obtaining 3D point clouds from one snapshot and enabling diversity in monitoring and modelling applications for remote sensing. Considering an LF image and associated depth map as an input, we first apply histogram equalization and histogram stretching to enhance the separation between depth planes. We then apply multi-modal edge detection by using feature matching and fuzzy logic from the central sub-aperture LF image and the depth map. These two steps of depth map enhancement are significant parts of our novelty for this work. After combing the two previous steps and transforming the point&ndash;plane correspondence, we can obtain the 3D point cloud. We tested our method with synthetic and real world image databases. To verify the accuracy of our method, we compared our results with two different state-of-the-art algorithms. The results showed that our method can reliably mitigate noise and had the highest level of detail compared to other existing methods.
KW  - 3D point cloud
KW  - light field camera
KW  - 3D reconstruction
KW  - 3D modelling
KW  - three-dimensional data
KW  - enhanced depth map
DO  - 10.3390/rs12071125
ER  -
TY  - EJOU
AU  - Torresan, Chiara
AU  - Carotenuto, Federico
AU  - Chiavetta, Ugo
AU  - Miglietta, Franco
AU  - Zaldei, Alessandro
AU  - Gioli, Beniamino
TI  - Individual Tree Crown Segmentation in Two-Layered Dense Mixed Forests from UAV LiDAR Data
T2  - Drones

PY  - 2020
VL  - 4
IS  - 2
SN  - 2504-446X

AB  - In forests with dense mixed canopies, laser scanning is often the only effective technique to acquire forest inventory attributes, rather than structure-from-motion optical methods. This study investigates the potential of laser scanner data collected with a low-cost unmanned aerial vehicle laser scanner (UAV-LS), for individual tree crown (ITC) delineation to derive forest biometric parameters, over two-layered dense mixed forest stands in central Italy. A raster-based local maxima region growing algorithm (itcLiDAR) and a point cloud-based algorithm (li2012) were applied to isolate individual tree crowns, compute height and crown area, estimate the diameter at breast height (DBH) and the above ground biomass (AGB) of individual trees. To maximize the level of detection rate, the ITC algorithm parameters were tuned varying 1350 setting combinations and matching the segmented trees with field measured trees. For each setting, the delineation accuracy was assessed by computing the detection rate, the omission and commission errors over three forest plots. Segmentation using itcLiDAR showed detection rates between 40% and 57%, while ITC delineation was successful at segmenting trees with DBH larger than 10 cm (detection rate ~78%), while failed to detect trees with smaller DBH (detection rate ~37%). The performance of li2012 was quite lower with the higher detection rate equal to 27%. Errors and goodness-of-fit between field-surveyed and flight-derived biometric parameters (AGB and tree height) were species-dependent, with higher error and lower r2 for shorter species that constitute the lowermost layer of the forest. Overall, while the application of UAV-LS to delineate tree crowns and estimate biometric parameters is satisfactory, its accuracy is affected by the presence of a multilayered and multispecies canopy that will require specific approaches and algorithms to better deal with the added complexity.
KW  - laser scanning
KW  - ITC detection algorithms
KW  - parameter calibration
KW  - itcSegment package
KW  - lidR package
KW  - detection rate
KW  - forest inventory
DO  - 10.3390/drones4020010
ER  -
TY  - EJOU
AU  - Kislov, Dmitry E.
AU  - Korznikov, Kirill A.
TI  - Automatic Windthrow Detection Using Very-High-Resolution Satellite Imagery and Deep Learning
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - Wind disturbances are significant phenomena in forest spatial structure and succession dynamics. They cause changes in biodiversity, impact on forest ecosystems at different spatial scales, and have a strong influence on economics and human beings. The reliable recognition and mapping of windthrow areas are of high importance from the perspective of forest management and nature conservation. Recent research in artificial intelligence and computer vision has demonstrated the incredible potential of neural networks in addressing image classification problems. The most efficient algorithms are based on artificial neural networks of nested and complex architecture (e.g., convolutional neural networks (CNNs)), which are usually referred to by a common term&mdash;deep learning. Deep learning provides powerful algorithms for the precise segmentation of remote sensing data. We developed an algorithm based on a U-Net-like CNN, which was trained to recognize windthrow areas in Kunashir Island, Russia. We used satellite imagery of very-high spatial resolution (0.5 m/pixel) as source data. We performed a grid search among 216 parameter combinations defining different U-Net-like architectures. The best parameter combination allowed us to achieve an overall accuracy for recognition of windthrow sites of up to 94% for forested landscapes by coniferous and mixed coniferous forests. We found that the false-positive decisions of our algorithm correspond to either seashore logs, which may look similar to fallen tree trunks, or leafless forest stands. While the former can be rectified by applying a forest mask, the latter requires the usage of additional information, which is not always provided by satellite imagery.
KW  - convolutional neural network
KW  - deep learning
KW  - image segmentation
KW  - machine learning
KW  - forest disturbance
KW  - windthrow
DO  - 10.3390/rs12071145
ER  -
TY  - EJOU
AU  - Zhou, Jingjing
AU  - Dian, Yuanyong
AU  - Wang, Xiong
AU  - Yao, Chonghuai
AU  - Jian, Yongfeng
AU  - Li, Yuan
AU  - Han, Zeming
TI  - Comparison of GF2 and SPOT6 Imagery on Canopy Cover Estimating in Northern Subtropics Forest in China
T2  - Forests

PY  - 2020
VL  - 11
IS  - 4
SN  - 1999-4907

AB  - Canopy cover is an important vegetation attribute used for many environmental applications such as defining management objectives, thinning and ecological modeling. However, the estimation of canopy cover from high spatial resolution imagery is still a difficult task due to limited spectral information and the heterogeneous pixel values of the same canopy. In this paper, we compared the capacity of two high spatial resolution sensors (SPOT6 and GF2) using three ensemble learning models (Adaptive Boosting (AdaBoost), Gradient Boosting (GDBoost), and random forest (RF)), to estimate canopy cover (CC) in a Chinese northern subtropics forest. Canopy cover across 97 plots was measured across 41 needle forest plots, 24 broadleaf forest plots, and 32 mixed forest plots. Results showed that (1) the textural features performed more importantly than spectral variables according to the number of variables in the top ten predictors in estimating canopy cover (CC) in both SPOT6 and GF2. Moreover, the vegetation indices in spectral variables had a lower relative importance value than the band reflectance variables. (2) GF2 imagery outperformed SPOT6 imagery in estimating CC when using the ensemble learning model in our data. On average across the models, the R2 was almost 0.08 higher for GF2 over SPOT6. Likewise, the average RMSE and average MAE were 0.002 and 0.01 lower in GF2 than in SPOT6. (3) The ensemble learning model showed good results in estimating CC, yet the different models performed a little differently in the results. Additionally, the GDBoost model performed the best of all the ensemble learning models with R2 = 0.92, root mean square error (RMSE) = 0.001 and mean absolute error (MAE) = 0.022.
KW  - GF2
KW  - SPOT6
KW  - high spatial resolution
KW  - canopy cover
KW  - ensemble learning model
KW  - gray level co-occurrence matrix (GLCM)
DO  - 10.3390/f11040407
ER  -
TY  - EJOU
AU  - Sestras, Paul
AU  - Roșca, Sanda
AU  - Bilașco, Ștefan
AU  - Naș, Sanda
AU  - Buru, Stefan M.
AU  - Kovacs, Leontina
AU  - Spalević, Velibor
AU  - Sestras, Adriana F.
TI  - Feasibility Assessments Using Unmanned Aerial Vehicle Technology in Heritage Buildings: Rehabilitation-Restoration, Spatial Analysis and Tourism Potential Analysis
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 7
SN  - 1424-8220

AB  - The Transylvanian region of Romania is a place of rich history since ancient times, where the original natural environment around architectural heritage sites or buildings has not been severely altered by urban development. Unfortunately, many such places are left by the authorities to degrade or totally collapse for lack of funds, vision or initiatives. The current paper addresses the potential of Unmanned Aerial Vehicles (UAVs) in the assessment of a viable and feasible prospect of restoration on a 19th century mansion that belonged to a nobiliary family. UAV use is rising in many industries and has become very popular in the last decade, but for survey engineering and related domains they represent a quantum leap in technology. Integrating UAV-acquired data and structure from motion software, has enabled modern techniques to obtain useful metrics from the field, accurate photorealistic 3D models for visual inspection, structural damage analyses, architectural rehabilitation-restoration, conservation and spatial analysis of the surrounding area. In this work a socio-cultural planning and design process is explored and presented to improve the local community and inclusion in a tourist circuit based on the regional potential, as well as an evaluation of accessibility derived from a vector-raster database that highlights the central position of the cultural heritage in regards to the axis of circulation between the important metropolitan areas and the local tourist attractions. This established workflow of modern topographic and construction measurements is fully integrable into the architectural process, building information modelling, heritage conservation and reconstruction.
KW  - 3D model
KW  - accessibility study
KW  - GIS analysis
KW  - monumental heritage
KW  - point cloud
KW  - remote sensing
KW  - structure from motion (SfM)
KW  - topographical survey
DO  - 10.3390/s20072054
ER  -
TY  - EJOU
AU  - Lin, Yukun
AU  - Zhu, Zhe
AU  - Guo, Wenxuan
AU  - Sun, Yazhou
AU  - Yang, Xiaoyuan
AU  - Kovalskyy, Valeriy
TI  - Continuous Monitoring of Cotton Stem Water Potential using Sentinel-2 Imagery
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - Monitoring cotton status during the growing season is critical in increasing production efficiency. The water status in cotton is a key factor for yield and cotton quality. Stem water potential (SWP) is a precise indicator for assessing cotton water status. Satellite remote sensing is an effective approach for monitoring cotton growth at a large scale. The aim of this study is to estimate cotton water stress at a high temporal frequency and at a large scale. In this study, we measured midday SWP samples according to the acquisition dates of Sentinel-2 images and used them to build linear-regression-based and machine-learning-based models to estimate cotton water stress during the growing season (June to August, 2018). For the linear-regression-based method, we estimated SWP based on different Sentinel-2 spectral bands and vegetation indices, where the normalized difference index 45 (NDI45) achieved the best performance (R2 = 0.6269; RMSE = 3.6802 (-1*swp (bars))). For the machine-learning-based method, we used random forest regression to estimate SWP and received even better results (R2 = 0.6709; RMSE = 3.3742 (-1*swp (bars))). To find the best selection of input variables for the machine-learning-based approach, we tried three different data input datasets, including (1) 9 original spectral bands (e.g., blue, green, red, red edge, near infrared (NIR), and shortwave infrared (SWIR)), (2) 21 vegetation indices, and (3) a combination of original Sentinel-2 spectral bands and vegetation indices. The highest accuracy was achieved when only the original spectral bands were used. We also found the SWIR and red edge band were the most important spectral bands, and the vegetation indices based on red edge and NIR bands were particularly helpful. Finally, we applied the best approach for the linear-regression-based and the machine-learning-based methods to generate cotton water potential maps at a large scale and high temporal frequency. Results suggests that the methods developed here has the potential for continuous monitoring of SWP at large scales and the machine-learning-based method is preferred.
KW  - cotton stem water potential
KW  - linear regression
KW  - vegetation indices
KW  - machine learning
KW  - random forest
KW  - Sentinel-2
DO  - 10.3390/rs12071176
ER  -
TY  - EJOU
AU  - Deng, Lu
AU  - Chu, Hong-Hu
AU  - Shi, Peng
AU  - Wang, Wei
AU  - Kong, Xuan
TI  - Region-Based CNN Method with Deformable Modules for Visually Classifying Concrete Cracks
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 7
SN  - 2076-3417

AB  - Cracks are often the most intuitive indicators for assessing the condition of in-service structures. Intelligent detection methods based on regular convolutional neural networks (CNNs) have been widely applied to the field of crack detection in recently years; however, these methods exhibit unsatisfying performance on the detection of out-of-plane cracks. To overcome this drawback, a new type of region-based CNN (R-CNN) crack detector with deformable modules is proposed in the present study. The core idea of the method is to replace the traditional regular convolution and pooling operation with a deformable convolution operation and a deformable pooling operation. The idea is implemented on three different regular detectors, namely the Faster R-CNN, region-based fully convolutional networks (R-FCN), and feature pyramid network (FPN)-based Faster R-CNN. To examine the advantages of the proposed method, the results obtained from the proposed detector and corresponding regular detectors are compared. The results show that the addition of deformable modules improves the mean average precisions (mAPs) achieved by the Faster R-CNN, R-FCN, and FPN-based Faster R-CNN for crack detection. More importantly, adding deformable modules enables these detectors to detect the out-of-plane cracks that are difficult for regular detectors to detect.
KW  - structural health monitoring (SHM)
KW  - deep learning
KW  - convolutional neural network
KW  - deformable convolution
KW  - concrete cracks
KW  - out-of-plane crack
DO  - 10.3390/app10072528
ER  -
TY  - EJOU
AU  - Feng, Chuncheng
AU  - Zhang, Hua
AU  - Wang, Haoran
AU  - Wang, Shuang
AU  - Li, Yonglong
TI  - Automatic Pixel-Level Crack Detection on Dam Surface Using Deep Convolutional Network
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 7
SN  - 1424-8220

AB  - Crack detection on dam surfaces is an important task for safe inspection of hydropower stations. More and more object detection methods based on deep learning are being applied to crack detection. However, most of the methods can only achieve the classification and rough location of cracks. Pixel-level crack detection can provide more intuitive and accurate detection results for dam health assessment. To realize pixel-level crack detection, a method of crack detection on dam surface (CDDS) using deep convolution network is proposed. First, we use an unmanned aerial vehicle (UAV) to collect dam surface images along a predetermined trajectory. Second, raw images are cropped. Then crack regions are manually labelled on cropped images to create the crack dataset, and the architecture of CDDS network is designed. Finally, the CDDS network is trained, validated and tested using the crack dataset. To validate the performance of the CDDS network, the predicted results are compared with ResNet152-based, SegNet, UNet and fully convolutional network (FCN). In terms of crack segmentation, the recall, precision, F-measure and IoU are 80.45%, 80.31%, 79.16%, and 66.76%. The results on test dataset show that the CDDS network has better performance for crack detection of dam surfaces.
KW  - crack detection
KW  - dam surface
KW  - UAV
KW  - pixel-level
KW  - deep convolutional network
DO  - 10.3390/s20072069
ER  -
TY  - EJOU
AU  - Bohak, Ciril
AU  - Slemenik, Matej
AU  - Kordež, Jaka
AU  - Marolt, Matija
TI  - Aerial LiDAR Data Augmentation for Direct Point-Cloud Visualisation
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 7
SN  - 1424-8220

AB  - Direct point-cloud visualisation is a common approach for visualising large datasets of aerial terrain LiDAR scans. However, because of the limitations of the acquisition technique, such visualisations often lack the desired visual appeal and quality, mostly because certain types of objects are incomplete or entirely missing (e.g., missing water surfaces, missing building walls and missing parts of the terrain). To improve the quality of direct LiDAR point-cloud rendering, we present a point-cloud processing pipeline that uses data fusion to augment the data with additional points on water surfaces, building walls and terrain through the use of vector maps of water surfaces and building outlines. In the last step of the pipeline, we also add colour information, and calculate point normals for illumination of individual points to make the final visualisation more visually appealing. We evaluate our approach on several parts of the Slovenian LiDAR dataset.
KW  - LiDAR
KW  - point-clouds
KW  - point-cloud visualisation
KW  - terrain reconstruction
KW  - water surface reconstruction
DO  - 10.3390/s20072089
ER  -
TY  - EJOU
AU  - Mallinis, Giorgos
AU  - Chrysafis, Irene
AU  - Korakis, Georgios
AU  - Pana, Eleanna
AU  - Kyriazopoulos, Apostolos P.
TI  - A Random Forest Modelling Procedure for a Multi-Sensor Assessment of Tree Species Diversity
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - Earth observation data can provide important information for tree species diversity mapping and monitoring. The relatively recent advances in remote sensing data characteristics and processing systems elevate the potential of satellite imagery for providing accurate, timely, consistent, and robust spatially explicit estimates of tree species diversity over forest ecosystems. This study was conducted in Northern Pindos National Park, the largest terrestrial park in Greece and aimed to assess the potential of four satellite sensors with different instrumental characteristics, for the estimation of tree diversity. Through field measurements, we originally quantified two diversity indices, namely the Shannon diversity index (H&rsquo;) and Simpson&rsquo;s diversity (D1). Random forest regression models were developed for associating remotely sensed spectral signal with tree species diversity within the area. The models generated from the use of the WorldView-2 image were the most accurate with a coefficient of determination of up to 0.44 for H&rsquo; and 0.37 for D1. The Sentinel-2 -based models of tree species diversity performed slightly worse, but were better than the Landsat-8 and RapidEye models. The coefficient of variation quantifying internal variability of spectral values within each plot provided little or no usage for improving the modelling accuracy. Our results suggest that very-high-spatial-resolution imagery provides the most important information for the assessment of tree species diversity in heterogeneous Mediterranean ecosystems.
KW  - biodiversity indices
KW  - Sentinel-2
KW  - Landsat-8
KW  - RapidEye
KW  - machine learning
KW  - Mediterranean forest habitats
KW  - WorldView-2
DO  - 10.3390/rs12071210
ER  -
TY  - EJOU
AU  - Raza, Muhammad M.
AU  - Harding, Chris
AU  - Liebman, Matt
AU  - Leandro, Leonor F.
TI  - Exploring the Potential of High-Resolution Satellite Imagery for the Detection of Soybean Sudden Death Syndrome
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 7
SN  - 2072-4292

AB  - Sudden death syndrome (SDS) is one of the major yield-limiting soybean diseases in the Midwestern United States. Effective management for SDS requires accurate detection in soybean fields. Since traditional scouting methods are time-consuming, labor-intensive, and often destructive, alternative methods to monitor SDS in large soybean fields are needed. This study explores the potential of using high-resolution (3 m) PlanetScope satellite imagery for detection of SDS using the random forest classification algorithm. Image data from blue, green, red, and near-infrared (NIR) spectral bands, the calculated normalized difference vegetation index (NDVI), and crop rotation information were used to detect healthy and SDS-infected quadrats in a soybean field experiment with different rotation treatments, located in Boone County, Iowa. Datasets collected during the 2016, 2017, and 2018 soybean growing seasons were analyzed. The results indicate that spectral features, when combined with ground-based information, can detect areas in soybean plots that are at risk for disease, even before foliar symptoms develop. The classification of healthy and diseased soybean quadrats was &gt;75% accurate and the area under the receiver operating characteristic curve (AUROC) was &gt;70%. Our results indicate that high-resolution satellite imagery and random forest analyses have the potential to detect SDS in soybean fields, and that this approach may facilitate large-scale monitoring of SDS (and possibly other economically important soybean diseases). It may also be useful for guiding recommendations for site-specific management in current and future seasons.
KW  - soybean disease
KW  - sudden death syndrome
KW  - disease detection
KW  - remote sensing
KW  - PlanetScope
KW  - satellite imagery
KW  - random forest
DO  - 10.3390/rs12071213
ER  -
TY  - EJOU
AU  - Chen, Zhixiong
AU  - Xiao, Nan
AU  - Han, Dongsheng
TI  - Multilevel Task Offloading and Resource Optimization of Edge Computing Networks Considering UAV Relay and Green Energy
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 7
SN  - 2076-3417

AB  - Unmanned aerial vehicle (UAV)-assisted relay mobile edge computing (MEC) network is a prominent concept, where network deployment is flexible and network coverage is wide. In scenarios such as emergency communications and low-cost coverage, optimization of offloading methods and resource utilization are important ways to improve system effectiveness due to limited terminal and UAV energy and hardware equipment. A multilevel edge computing network resource optimization model on the basis of UAV fusion that provides relay forwarding and offload services is established by considering the initial energy state of the UAV, the green energy charging function, and the reliability of computing offload. With normalized system utility function maximization as the goal, a Markov decision process algorithm meets the needs of the practical application scene and provides a flexible and effective unloading mode. This algorithm is adopted to solve the optimal offloading mode and the optimal resource utilization scheme. Simulations verify the effectiveness and reliability of the proposed multilevel offloading model. The proposed model can optimize system resource allocation and effectively improve the utility function and user experience of computing offloading systems.
KW  - Unmanned aerial vehicle (UAV)
KW  - Mobile Edge Computing (MEC) Network
KW  - green energy resources
KW  - MDP algorithm
DO  - 10.3390/app10072592
ER  -
TY  - EJOU
AU  - Silveira Kupssinskü, Lucas
AU  - Thomassim Guimarães, Tainá
AU  - Menezes de Souza, Eniuce
AU  - C. Zanotta, Daniel
AU  - Roberto Veronez, Mauricio
AU  - Gonzaga, Luiz
AU  - Mauad, Frederico F.
TI  - A Method for Chlorophyll-a and Suspended Solids Prediction through Remote Sensing and Machine Learning
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 7
SN  - 1424-8220

AB  - Total Suspended Solids (TSS) and chlorophyll-a concentration are two critical parameters to monitor water quality. Since directly collecting samples for laboratory analysis can be expensive, this paper presents a methodology to estimate this information through remote sensing and Machine Learning (ML) techniques. TSS and chlorophyll-a are optically active components, therefore enabling measurement by remote sensing. Two study cases in distinct water bodies are performed, and those cases use different spatial resolution data from Sentinel-2 spectral images and unmanned aerial vehicles together with laboratory analysis data. In consonance with the methodology, supervised ML algorithms are trained to predict the concentration of TSS and chlorophyll-a. The predictions are evaluated separately in both study areas, where both TSS and chlorophyll-a models achieved R-squared values above 0.8.
KW  - chlorophyll-a
KW  - total suspended solids
KW  - remote sensing
KW  - machine learning
KW  - artificial neural networks
KW  - random forest
KW  - K nearest neighbors
KW  - water quality
DO  - 10.3390/s20072125
ER  -
TY  - EJOU
AU  - Xu, Zhiqiang
AU  - Chen, Yumin
AU  - Yang, Fan
AU  - Chu, Tianyou
AU  - Zhou, Hongyan
TI  - A Postearthquake Multiple Scene Recognition Model Based on Classical SSD Method and Transfer Learning
T2  - ISPRS International Journal of Geo-Information

PY  - 2020
VL  - 9
IS  - 4
SN  - 2220-9964

AB  - The recognition of postearthquake scenes plays an important role in postearthquake rescue and reconstruction. To overcome the over-reliance on expert visual interpretation and the poor recognition performance of traditional machine learning in postearthquake scene recognition, this paper proposes a postearthquake multiple scene recognition (PEMSR) model based on the classical deep learning Single Shot MultiBox Detector (SSD) method. In this paper, a labeled postearthquake scenes dataset is constructed by segmenting acquired remote sensing images, which are classified into six categories: landslide, houses, ruins, trees, clogged and ponding. Due to the insufficiency and imbalance of the original dataset, transfer learning and a data augmentation and balancing strategy are utilized in the PEMSR model. To evaluate the PEMSR model, the evaluation metrics of precision, recall and F1 score are used in the experiment. Multiple experimental test results demonstrate that the PEMSR model shows a stronger performance in postearthquake scene recognition. The PEMSR model improves the detection accuracy of each scene compared with SSD by transfer learning and data augmentation strategy. In addition, the average detection time of the PEMSR model only needs 0.4565s, which is far less than the 8.3472s of the traditional Histogram of Oriented Gradient + Support Vector Machine (HOG+SVM) method.
KW  - earthquake disasters
KW  - scene recognition
KW  - deep learning
KW  - classical SSD method
KW  - transfer learning
DO  - 10.3390/ijgi9040238
ER  -
TY  - EJOU
AU  - Pan, Xinliang
AU  - Jiang, Tao
AU  - Zhang, Zhen
AU  - Sui, Baikai
AU  - Liu, Chenxi
AU  - Zhang, Linjing
TI  - A New Method for Extracting Laver Culture Carriers Based on Inaccurate Supervised Classification with FCN-CRF
T2  - Journal of Marine Science and Engineering

PY  - 2020
VL  - 8
IS  - 4
SN  - 2077-1312

AB  - Timely monitoring of marine aquaculture has considerable significance for marine ecological protection and maritime safety and security. Considering that supervised learning needs to rely on a large number of training samples and the characteristics of intensive and regular distribution of the laver aquaculture zone, in this paper, an inaccurate supervised classification model based on fully convolutional neural network and conditional random filed (FCN-CRF) is designed for the study of a laver aquaculture zone in Lianyungang, Jiangsu Province. The proposed model can extract the aquaculture zone and calculate the area and quantity of laver aquaculture net simultaneously. The FCN is used to extract the laver aquaculture zone by roughly making the training label. Then, the CRF is used to extract the isolated laver aquaculture net with high precision. The results show that the     k a p p a     coefficient of the proposed model is 0.984, the      F 1      is 0.99, and the recognition effect is outstanding. For label production, the fault tolerance rate is high and does not affect the final classification accuracy, thereby saving more label production time. The findings provide a data basis for future aquaculture yield estimation and offshore resource planning as well as technical support for marine ecological supervision and marine traffic management.
KW  - laver culture
KW  - FCN
KW  - conditional random filed
KW  - inaccurate supervised classification
DO  - 10.3390/jmse8040274
ER  -
TY  - EJOU
AU  - Šarlah, Nikolaj
AU  - Podobnikar, Tomaž
AU  - Ambrožič, Tomaž
AU  - Mušič, Branko
TI  - Application of Kinematic GPR-TPS Model with High 3D Georeference Accuracy for Underground Utility Infrastructure Mapping: A Case Study from Urban Sites in Celje, Slovenia
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 8
SN  - 2072-4292

AB  - This paper describes in detail the applicability of the developed ground-penetrating radar (GPR) model with a kinematic GPR and self-tracking (robotic) terrestrial positioning system (TPS) surveying setup (GPR-TPS model) for the acquisition, processing and visualisation of underground utility infrastructure (UUI) in a real urban environment. The integration of GPR with TPS can significantly improve the accuracy of UUI positioning in a real urban environment by means of efficient control of GPR trajectories. Two areas in the urban part of Celje in Slovenia were chosen. The accuracy of the kinematic GPR-TPS model was analysed by comparing the three-dimensional (3D) position of UUI given as reference values (true 3D position) from the officially consolidated cadastre of utility infrastructure in the Republic of Slovenia and those obtained by the GPR-TPS method. To determine the reference 3D position of the GPR antenna and UUI, the same positional and height geodetic network was used. Small unmanned aerial vehicles (UAV) were used for recording to provide a better spatial display of the results of UUI obtained with the GPR-TPS method. As demonstrated by the results, the kinematic GPR-TPS model for data acquisition can achieve an accuracy of fewer than 15 centimetres in a real urban environment.
KW  - kinematic GPR-TPS model
KW  - self-tracking terrestrial positioning system
KW  - underground utility infrastructure
KW  - unmanned aerial vehicle
KW  - horizontal accuracy
KW  - vertical accuracy
KW  - real urban environment
DO  - 10.3390/rs12081228
ER  -
TY  - EJOU
AU  - Merlino, Silvia
AU  - Paterni, Marco
AU  - Berton, Andrea
AU  - Massetti, Luciano
TI  - Unmanned Aerial Vehicles for Debris Survey in Coastal Areas: Long-Term Monitoring Programme to Study Spatial and Temporal Accumulation of the Dynamics of Beached Marine Litter
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 8
SN  - 2072-4292

AB  - Unmanned aerial vehicles (UAVs) are becoming increasingly accessible tools with widespread use as environmental monitoring systems. They can be used for anthropogenic marine debris survey, a recently growing research field. In fact, while the increasing efforts for offshore investigations lead to a considerable collection of data on this type of pollution in the open sea, there is still little knowledge of the materials deposited along the coasts and the mechanism that leads to their accumulation pattern. UAVs can be effective in bridging this gap by increasing the amount of data acquired to study coastal deposits, while also limiting the anthropogenic impact in protected areas. In this study, UAVs have been used to acquire geo-referenced RGB images in a selected zone of a protected marine area (the Migliarino, Massacciuccoli, and San Rossore park near Pisa, Italy), during a long-term (ten months) monitoring programme. A post processing system based on visual interpretation of the images allows the localization and identification of the anthropogenic marine debris within the scanned area, and the estimation of their spatial and temporal distribution in different zones of the beach. These results provide an opportunity to investigate the dynamics of accumulation over time, suggesting that our approach might be appropriate for monitoring and collecting such data in isolated, and especially in protected, areas with significant benefits for different types of stakeholders.
KW  - unmanned-aerial-vehicles
KW  - UAVs
KW  - anthropogenic-marine-debris
KW  - AMD
KW  - beached-marine-litter
KW  - BML
KW  - marine-protected-areas
KW  - MPA
KW  - ortho-photo
KW  - marine-pollution
KW  - accumulation-rate
DO  - 10.3390/rs12081260
ER  -
TY  - EJOU
AU  - Zhao, Xin
AU  - Li, Hui
AU  - Wang, Ping
AU  - Jing, Linhai
TI  - An Image Registration Method for Multisource High-Resolution Remote Sensing Images for Earthquake Disaster Assessment
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 8
SN  - 1424-8220

AB  - For earthquake disaster assessment using remote sensing (RS), multisource image registration is an important step. However, severe earthquakes will increase the deformation between the remote sensing images acquired before and after the earthquakes on different platforms. Traditional image registration methods can hardly meet the requirements of accuracy and efficiency of image registration of post-earthquake RS images used for disaster assessment. Therefore, an improved image registration method was proposed for the registration of multisource high-resolution remote sensing images. The proposed method used the combination of the Shi_Tomasi corner detection algorithm and scale-invariant feature transform (SIFT) to detect tie points from image patches obtained by an image partition strategy considering geographic information constraints. Then, the random sample consensus (RANSAC) and greedy algorithms were employed to remove outliers and redundant matched tie points. Additionally, a pre-earthquake RS image database was constructed using pre-earthquake high-resolution RS images and used as the references for image registration. The performance of the proposed method was evaluated using three image pairs covering regions affected by severe earthquakes. It was shown that the proposed method provided higher accuracy, less running time, and more tie points with a more even distribution than the classic SIFT method and the SIFT method using the same image partitioning strategy.
KW  - image registration
KW  - multisource high-resolution remote sensing image
KW  - earthquake damage assessment
KW  - Shi_Tomasi corner detection algorithm
KW  - SIFT
DO  - 10.3390/s20082286
ER  -
TY  - EJOU
AU  - Miyoshi, Gabriela T.
AU  - Arruda, Mauro D.
AU  - Osco, Lucas P.
AU  - Marcato Junior, José
AU  - Gonçalves, Diogo N.
AU  - Imai, Nilton N.
AU  - Tommaselli, Antonio M.
AU  - Honkavaara, Eija
AU  - Gonçalves, Wesley N.
TI  - A Novel Deep Learning Method to Identify Single Tree Species in UAV-Based Hyperspectral Images
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 8
SN  - 2072-4292

AB  - Deep neural networks are currently the focus of many remote sensing approaches related to forest management. Although they return satisfactory results in most tasks, some challenges related to hyperspectral data remain, like the curse of data dimensionality. In forested areas, another common problem is the highly-dense distribution of trees. In this paper, we propose a novel deep learning approach for hyperspectral imagery to identify single-tree species in highly-dense areas. We evaluated images with 25 spectral bands ranging from 506 to 820 nm taken over a semideciduous forest of the Brazilian Atlantic biome. We included in our network&rsquo;s architecture a band combination selection phase. This phase learns from multiple combinations between bands which contributed the most for the tree identification task. This is followed by a feature map extraction and a multi-stage model refinement of the confidence map to produce accurate results of a highly-dense target. Our method returned an f-measure, precision and recall values of 0.959, 0.973, and 0.945, respectively. The results were superior when compared with a principal component analysis (PCA) approach. Compared to other learning methods, ours estimate a combination of hyperspectral bands that most contribute to the mentioned task within the network&rsquo;s architecture. With this, the proposed method achieved state-of-the-art performance for detecting and geolocating individual tree-species in UAV-based hyperspectral images in a complex forest.
KW  - high-density object
KW  - data-reduction
KW  - band selection
KW  - convolutional neural network
KW  - tree species identification
DO  - 10.3390/rs12081294
ER  -
TY  - EJOU
AU  - Zhang, Lin
AU  - Zhu, Yian
AU  - Shi, Xianchen
TI  - A Hierarchical Decision-Making Method with a Fuzzy Ant Colony Algorithm for Mission Planning of Multiple UAVs
T2  - Information

PY  - 2020
VL  - 11
IS  - 4
SN  - 2078-2489

AB  - Unmanned aerial vehicles (UAVs) received an unprecedented surge of people&rsquo;s interest worldwide in recent years. This paper investigates the specific problem of cooperative mission planning for multiple UAVs on the battlefield from a hierarchical decision-making perspective. From the view of the actual mission planning issue, the two key problems to be solved in UAV collaborative mission planning are mission allocation and route planning. In this paper, both of these problems are taken into account via a hierarchical decision-making model. Firstly, we use a target clustering algorithm to divide the original targets into target subgroups, where each target subgroup contains multiple targets. Secondly, a fuzzy ant colony algorithm is used to calculate the global path between target subgroups for a single-target group. Thirdly, a fuzzy ant colony algorithm is also used to calculate the local path between multiple targets for a single-target subgroup. After three levels of decision-making, the complete path for multiple UAVs can be obtained. In order to improve the efficiency of a collaborative task between different types of UAVs, a cooperative communication strategy is developed, which can reduce the number of UAVs performing tasks. Finally, experimental results demonstrate the effectiveness of the proposed cooperative mission planning and cooperative communication strategy for multiple UAVs.
KW  - multiple UAVs
KW  - mission planning
KW  - fuzzy ant colony algorithm
KW  - hierarchical decision-making
KW  - target clustering algorithm
DO  - 10.3390/info11040226
ER  -
TY  - EJOU
AU  - Wang, Tianyi
AU  - Thomasson, J. A.
AU  - Yang, Chenghai
AU  - Isakeit, Thomas
AU  - Nichols, Robert L.
TI  - Automatic Classification of Cotton Root Rot Disease Based on UAV Remote Sensing
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 8
SN  - 2072-4292

AB  - Cotton root rot (CRR) is a persistent soilborne fungal disease that is devastating to cotton in the southwestern U.S. and Mexico. Research has shown that CRR can be prevented or at least mitigated by applying a fungicide at planting, but the fungicide should be applied precisely to minimize the quantity of product used and the treatment cost. The CRR-infested areas within a field are consistent from year to year, so it is possible to apply the fungicide only at locations where CRR is manifest, thus minimizing the amount of fungicide applied across the field. Previous studies have shown that remote sensing (RS) from manned aircraft is an effective means of delineating CRR-infested field areas. Applying various classification methods to moderate-resolution (1.0 m/pixel) RS images has recently become the conventional way to delineate CRR-infested areas. In this research, an unmanned aerial vehicle (UAV) was used to collect high-resolution remote sensing (RS) images in three Texas fields known to be infested with CRR. Supervised, unsupervised, and combined unsupervised classification methods were evaluated for differentiating CRR from healthy zones of cotton plants. Two new automated classification methods that take advantage of the high resolution inherent in UAV RS images were also evaluated. The results indicated that the new automated methods were up to 8.89% better than conventional classification methods in overall accuracy. One of these new methods, an automated method combining k-means segmentation and morphological opening and closing, provided the best results, with overall accuracy of 88.5% and the lowest errors of omission (11.44%) and commission (16.13%) of all methods considered.
KW  - precision agriculture
KW  - disease detection
KW  - UAV
KW  - cotton root rot
KW  - machine learning
KW  - classification
KW  - image analysis
KW  - semi-supervised
DO  - 10.3390/rs12081310
ER  -
TY  - EJOU
AU  - Pan, Jeng-Shyang
AU  - Chai, Qing-Wei
AU  - Chu, Shu-Chuan
AU  - Wu, Ning
TI  - 3-D Terrain Node Coverage of Wireless Sensor Network Using Enhanced Black Hole Algorithm
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 8
SN  - 1424-8220

AB  - In this paper, a new intelligent computing algorithm named Enhanced Black Hole (EBH) is proposed to which the mutation operation and weight factor are applied. In EBH, several elites are taken as role models instead of only one in the original Black Hole (BH) algorithm. The performance of the EBH algorithm is verified by the CEC 2013 test suit, and shows better results than the original BH. In addition, the EBH and other celebrated algorithms can be used to solve node coverage problems of Wireless Sensor Network (WSN) in 3-D terrain with satisfactory performance.
KW  - node coverage
KW  - 3-D node deployed
KW  - WSN
KW  - intelligence computing
KW  - black hole
DO  - 10.3390/s20082411
ER  -
TY  - EJOU
AU  - Kouhdaragh, Vahid
AU  - Verde, Francesco
AU  - Gelli, Giacinto
AU  - Abouei, Jamshid
TI  - On the Application of Machine Learning to the Design of UAV-Based 5G Radio Access Networks
T2  - Electronics

PY  - 2020
VL  - 9
IS  - 4
SN  - 2079-9292

AB  - A groundbreaking design of radio access networks (RANs) is needed to fulfill 5G traffic requirements. To this aim, a cost-effective and flexible strategy consists of complementing terrestrial RANs with unmanned aerial vehicles (UAVs). However, several problems must be solved in order to effectively deploy such UAV-based RANs (U-RANs). Indeed, due to the high complexity and heterogeneity of these networks, model-based design approaches, often relying on restrictive assumptions and constraints, exhibit severe limitation in real-world scenarios. Moreover, design of a set of appropriate protocols for such U-RANs is a highly sophisticated task. In this context, machine learning (ML) emerges as a useful tool to obtain practical and effective solutions. In this paper, we discuss why, how, and which types of ML methods are useful for designing U-RANs, by focusing in particular on supervised and reinforcement learning strategies.
KW  - 5G and beyond systems
KW  - machine learning
KW  - radio access networks
KW  - reinforcement learning
KW  - supervised learning
KW  - unmanned aerial vehicles (UAVs)
DO  - 10.3390/electronics9040689
ER  -
TY  - EJOU
AU  - Alsharif, Mohammed H.
AU  - Kelechi, Anabi H.
AU  - Albreem, Mahmoud A.
AU  - Chaudhry, Shehzad A.
AU  - Zia, M. S.
AU  - Kim, Sunghwan
TI  - Sixth Generation (6G) Wireless Networks: Vision, Research Activities, Challenges and Potential Solutions
T2  - Symmetry

PY  - 2020
VL  - 12
IS  - 4
SN  - 2073-8994

AB  - The standardization activities of the fifth generation communications are clearly over and deployment has commenced globally. To sustain the competitive edge of wireless networks, industrial and academia synergy have begun to conceptualize the next generation of wireless communication systems (namely, sixth generation, (6G)) aimed at laying the foundation for the stratification of the communication needs of the 2030s. In support of this vision, this study highlights the most promising lines of research from the recent literature in common directions for the 6G project. Its core contribution involves exploring the critical issues and key potential features of 6G communications, including: (i) vision and key features; (ii) challenges and potential solutions; and (iii) research activities. These controversial research topics were profoundly examined in relation to the motivation of their various sub-domains to achieve a precise, concrete, and concise conclusion. Thus, this article will contribute significantly to opening new horizons for future research directions.
KW  - wireless networks
KW  - beyond 5G
KW  - 6G
KW  - 6G mobile communication
KW  - terahertz communications
KW  - holographic communications
KW  - terahertz spectrum
KW  - visible-light communications
DO  - 10.3390/sym12040676
ER  -
TY  - EJOU
AU  - Maimaitijiang, Maitiniyazi
AU  - Sagan, Vasit
AU  - Sidike, Paheding
AU  - Daloye, Ahmad M.
AU  - Erkbol, Hasanjan
AU  - Fritschi, Felix B.
TI  - Crop Monitoring Using Satellite/UAV Data Fusion and Machine Learning
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 9
SN  - 2072-4292

AB  - Non-destructive crop monitoring over large areas with high efficiency is of great significance in precision agriculture and plant phenotyping, as well as decision making with regards to grain policy and food security. The goal of this research was to assess the potential of combining canopy spectral information with canopy structure features for crop monitoring using satellite/unmanned aerial vehicle (UAV) data fusion and machine learning. Worldview-2/3 satellite data were tasked synchronized with high-resolution RGB image collection using an inexpensive unmanned aerial vehicle (UAV) at a heterogeneous soybean (Glycine max (L.) Merr.) field. Canopy spectral information (i.e., vegetation indices) was extracted from Worldview-2/3 data, and canopy structure information (i.e., canopy height and canopy cover) was derived from UAV RGB imagery. Canopy spectral and structure information and their combination were used to predict soybean leaf area index (LAI), aboveground biomass (AGB), and leaf nitrogen concentration (N) using partial least squares regression (PLSR), random forest regression (RFR), support vector regression (SVR), and extreme learning regression (ELR) with a newly proposed activation function. The results revealed that: (1) UAV imagery-derived high-resolution and detailed canopy structure features, canopy height, and canopy coverage were significant indicators for crop growth monitoring, (2) integration of satellite imagery-based rich canopy spectral information with UAV-derived canopy structural features using machine learning improved soybean AGB, LAI, and leaf N estimation on using satellite or UAV data alone, (3) adding canopy structure information to spectral features reduced background soil effect and asymptotic saturation issue to some extent and led to better model performance, (4) the ELR model with the newly proposed activated function slightly outperformed PLSR, RFR, and SVR in the prediction of AGB and LAI, while RFR provided the best result for N estimation. This study introduced opportunities and limitations of satellite/UAV data fusion using machine learning in the context of crop monitoring.
KW  - data fusion
KW  - machine learning
KW  - activation function
KW  - crop monitoring
KW  - extreme learning machine (ELM)
KW  - unmanned aerial vehicle (UAV)
DO  - 10.3390/rs12091357
ER  -
TY  - EJOU
AU  - Tang, Ziyang
AU  - Liu, Xiang
AU  - Chen, Hanlin
AU  - Hupy, Joseph
AU  - Yang, Baijian
TI  - Deep Learning Based Wildfire Event Object Detection from 4K Aerial Images Acquired by UAS
T2  - AI

PY  - 2020
VL  - 1
IS  - 2
SN  - 2673-2688

AB  - Unmanned Aerial Systems, hereafter referred to as UAS, are of great use in hazard events such as wildfire due to their ability to provide high-resolution video imagery over areas deemed too dangerous for manned aircraft and ground crews. This aerial perspective allows for identification of ground-based hazards such as spot fires and fire lines, and to communicate this information with fire fighting crews. Current technology relies on visual interpretation of UAS imagery, with little to no computer-assisted automatic detection. With the help of big labeled data and the significant increase of computing power, deep learning has seen great successes on object detection with fixed patterns, such as people and vehicles. However, little has been done for objects, such as spot fires, with amorphous and irregular shapes. Additional challenges arise when data are collected via UAS as high-resolution aerial images or videos; an ample solution must provide reasonable accuracy with low delays. In this paper, we examined 4K (    3840 × 2160    ) videos collected by UAS from a controlled burn and created a set of labeled video sets to be shared for public use. We introduce a coarse-to-fine framework to auto-detect wildfires that are sparse, small, and irregularly-shaped. The coarse detector adaptively selects the sub-regions that are likely to contain the objects of interest while the fine detector passes only the details of the sub-regions, rather than the entire 4K region, for further scrutiny. The proposed two-phase learning therefore greatly reduced time overhead and is capable of maintaining high accuracy. Compared against the real-time one-stage object backbone of YoloV3, the proposed methods improved the mean average precision(mAP) from     0 . 29     to     0 . 67    , with an average inference speed of 7.44 frames per second. Limitations and future work are discussed with regard to the design and the experiment results.
KW  - wildfire detection
KW  - deep learning
KW  - unmanned aerial systems
KW  - high resolution images
KW  - dataset
DO  - 10.3390/ai1020010
ER  -
TY  - EJOU
AU  - Tian, Yanlin
AU  - Jia, Mingming
AU  - Wang, Zongming
AU  - Mao, Dehua
AU  - Du, Baojia
AU  - Wang, Chao
TI  - Monitoring Invasion Process of Spartina alterniflora by Seasonal Sentinel-2 Imagery and an Object-Based Random Forest Classification
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 9
SN  - 2072-4292

AB  - In the late 1990s, the exotic plant Spartina alterniflora (S. alterniflora), was introduced to the Zhangjiang Estuary of China for tidal zone reclamation and protection. However, it invaded rapidly and has caused serious ecological problems. Accurate information on the seasonal invasion of S. alterniflora is vital to understand invasion pattern and mechanism, especially at a high temporal resolution. This study aimed to explore the S. alterniflora invasion process at a seasonal scale from 2016 to 2018. However, due to the uncertainties caused by periodic inundation of local tides, accurately monitoring the spatial extent of S. alterniflora is challenging. Thus, to achieve the goal and address the challenge, we firstly built a high-quality seasonal Sentinel-2 image collection by developing a new submerged S. alterniflora index (SAI) to reduce the errors caused by high tide fluctuations. Then, an object-based random forest (RF) classification method was applied to the image collection. Finally, seasonal extents of S. alterniflora were captured. Results showed that (1) the red edge bands (bands 5, 6, and 7) of Sentinel-2 imagery played critical roles in delineating submerged S. alterniflora; (2) during March 2016 to November 2018, the extent of S. alterniflora increased from 151.7 to 270.3 ha, with an annual invasion rate of 39.5 ha; (3) S. alterniflora invaded with a rate of 31.5 ha/season during growing season and 12.1 ha/season during dormant season. To our knowledge, this is the first study monitoring S. alterniflora invasion process at a seasonal scale during continuous years, discovering that S. alterniflora also expands during dormant seasons. This discovery is of great significance for understanding the invasion pattern and mechanism of S. alterniflora and will facilitate coastal biodiversity conservation efforts.
KW  - Spartina alterniflora
KW  - invasion process
KW  - growing season
KW  - dormant season
KW  - Sentinel-2 imagery
DO  - 10.3390/rs12091383
ER  -
TY  - EJOU
AU  - Postorino, Maria N.
AU  - Sarné, Giuseppe M. L.
TI  - Reinventing Mobility Paradigms: Flying Car Scenarios and Challenges for Urban Mobility
T2  - Sustainability

PY  - 2020
VL  - 12
IS  - 9
SN  - 2071-1050

AB  - Flying vehicles are receiving more and more attention and are becoming an opportunity to start a new urban mobility paradigm. The most interesting feature of flying cars is the expected opportunity they could offer to reduce congestion, traffic jams and the loss of time to move between origin/destination pairs in urban contexts. In this perspective, urban air mobility might meet the concept of &ldquo;sustainable mobility&rdquo;, intended as the ideal model of a transport system that minimizes the environmental impacts by maximizing efficiency and travel speed. For transport engineering planning issues, further knowledge is required in this field to understand the effects that a possible urban air mobility system, including the ground traffic component, could have in terms of sustainable mobility in the above meaning. This paper contributes to this topic by providing an analysis of different urban flying car scenarios by using an agent-based approach with different traffic conditions. The preliminary results obtained on some test networks and focusing on travel cost effects suggest that the expected advantages the flying car will depend on trip origin/destination points, average distances travelled in the urban contexts and the location of transition nodes, which are introduced as interchange nodes between aerial and ground mode.
KW  - urban air mobility (UAM)
KW  - flying cars
KW  - traffic management
KW  - transportation network
KW  - software agents
DO  - 10.3390/su12093581
ER  -
TY  - EJOU
AU  - Mazzia, Vittorio
AU  - Comba, Lorenzo
AU  - Khaliq, Aleem
AU  - Chiaberge, Marcello
AU  - Gay, Paolo
TI  - UAV and Machine Learning Based Refinement of a Satellite-Driven Vegetation Index for Precision Agriculture
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 9
SN  - 1424-8220

AB  - Precision agriculture is considered to be a fundamental approach in pursuing a low-input, high-efficiency, and sustainable kind of agriculture when performing site-specific management practices. To achieve this objective, a reliable and updated description of the local status of crops is required. Remote sensing, and in particular satellite-based imagery, proved to be a valuable tool in crop mapping, monitoring, and diseases assessment. However, freely available satellite imagery with low or moderate resolutions showed some limits in specific agricultural applications, e.g., where crops are grown by rows. Indeed, in this framework, the satellite&rsquo;s output could be biased by intra-row covering, giving inaccurate information about crop status. This paper presents a novel satellite imagery refinement framework, based on a deep learning technique which exploits information properly derived from high resolution images acquired by unmanned aerial vehicle (UAV) airborne multispectral sensors. To train the convolutional neural network, only a single UAV-driven dataset is required, making the proposed approach simple and cost-effective. A vineyard in Serralunga d&rsquo;Alba (Northern Italy) was chosen as a case study for validation purposes. Refined satellite-driven normalized difference vegetation index (NDVI) maps, acquired in four different periods during the vine growing season, were shown to better describe crop status with respect to raw datasets by correlation analysis and ANOVA. In addition, using a K-means based classifier, 3-class vineyard vigor maps were profitably derived from the NDVI maps, which are a valuable tool for growers.
KW  - precision agriculture
KW  - remote sensing
KW  - moderate resolution satellite imagery
KW  - UAV
KW  - convolutional neural network
DO  - 10.3390/s20092530
ER  -
TY  - EJOU
AU  - Chen, Je-Chian
AU  - Wang, Yu-Min
TI  - Comparing Activation Functions in Modeling Shoreline Variation Using Multilayer Perceptron Neural Network
T2  - Water

PY  - 2020
VL  - 12
IS  - 5
SN  - 2073-4441

AB  - The study has modeled shoreline changes by using a multilayer perceptron (MLP) neural network with the data collected from five beaches in southern Taiwan. The data included aerial survey maps of the Forestry Bureau for years 1982, 2002, and 2006, which served as predictors, while the unmanned aerial vehicle (UAV) surveyed data of 2019 served as the respondent. The MLP was configured using five different activation functions with the aim of evaluating their significance. These functions were Identity, Tahn, Logistic, Exponential, and Sine Functions. The results have shown that the performance of an MLP model may be affected by the choice of an activation function. Logistic and the Tahn activation functions outperformed the other models, with Logistic performing best in three beaches and Tahn having the rest. These findings suggest that the application of machine learning to shoreline changes should be accompanied by an extensive evaluation of the different activation functions.
KW  - neural networks
KW  - shoreline variation
KW  - activation functions
DO  - 10.3390/w12051281
ER  -
TY  - EJOU
AU  - Silva, Vanessa S.
AU  - Silva, Carlos A.
AU  - Mohan, Midhun
AU  - Cardil, Adrián
AU  - Rex, Franciel E.
AU  - Loureiro, Gabrielle H.
AU  - Almeida, Danilo R.
AU  - Broadbent, Eben N.
AU  - Gorgens, Eric B.
AU  - Dalla Corte, Ana P.
AU  - Silva, Emanuel A.
AU  - Valbuena, Rubén
AU  - Klauberg, Carine
TI  - Combined Impact of Sample Size and Modeling Approaches for Predicting Stem Volume in Eucalyptus spp. Forest Plantations Using Field and LiDAR Data
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 9
SN  - 2072-4292

AB  - Light Detection and Ranging (LiDAR) remote sensing has been established as one of the most promising tools for large-scale forest monitoring and mapping. Continuous advances in computational techniques, such as machine learning algorithms, have been increasingly improving our capability to model forest attributes accurately and at high spatial and temporal resolution. While there have been previous studies exploring the use of LiDAR and machine learning algorithms for forest inventory modeling, as yet, no studies have demonstrated the combined impact of sample size and different modeling techniques for predicting and mapping stem total volume in industrial Eucalyptus spp. tree plantations. This study aimed to compare the combined effects of parametric and nonparametric modeling methods for estimating volume in Eucalyptus spp. tree plantation using airborne LiDAR data while varying the reference data (sample size). The modeling techniques were compared in terms of root mean square error (RMSE), bias, and R2 with 500 simulations. The best performance was verified for the ordinary least-squares (OLS) method, which was able to provide comparable results to the traditional forest inventory approaches using only 40% (n = 63; ~0.04 plots/ha) of the total field plots, followed by the random forest (RF) algorithm with identical sample size values. This study provides solutions for increasing the industry efficiency in monitoring and managing forest plantation stem volume for the paper and pulp supply chain.
KW  - LiDAR
KW  - eucalyptus
KW  - forest attributes
KW  - machine learning
KW  - variable selection
DO  - 10.3390/rs12091438
ER  -
TY  - EJOU
AU  - Abdollahi, Abolfazl
AU  - Pradhan, Biswajeet
AU  - Shukla, Nagesh
AU  - Chakraborty, Subrata
AU  - Alamri, Abdullah
TI  - Deep Learning Approaches Applied to Remote Sensing Datasets for Road Extraction: A State-Of-The-Art Review
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 9
SN  - 2072-4292

AB  - One of the most challenging research subjects in remote sensing is feature extraction, such as road features, from remote sensing images. Such an extraction influences multiple scenes, including map updating, traffic management, emergency tasks, road monitoring, and others. Therefore, a systematic review of deep learning techniques applied to common remote sensing benchmarks for road extraction is conducted in this study. The research is conducted based on four main types of deep learning methods, namely, the GANs model, deconvolutional networks, FCNs, and patch-based CNNs models. We also compare these various deep learning models applied to remote sensing datasets to show which method performs well in extracting road parts from high-resolution remote sensing images. Moreover, we describe future research directions and research gaps. Results indicate that the largest reported performance record is related to the deconvolutional nets applied to remote sensing images, and the F1 score metric of the generative adversarial network model, DenseNet method, and FCN-32 applied to UAV and Google Earth images are high: 96.08%, 95.72%, and 94.59%, respectively.
KW  - road extraction
KW  - common benchmarks
KW  - machine learning
KW  - deep learning
KW  - remote sensing
DO  - 10.3390/rs12091444
ER  -
TY  - EJOU
AU  - Adamo, Maria
AU  - Tomaselli, Valeria
AU  - Tarantino, Cristina
AU  - Vicario, Saverio
AU  - Veronico, Giuseppe
AU  - Lucas, Richard
AU  - Blonda, Palma
TI  - Knowledge-Based Classification of Grassland Ecosystem Based on Multi-Temporal WorldView-2 Data and FAO-LCCS Taxonomy
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 9
SN  - 2072-4292

AB  - Grassland ecosystems can provide a variety of services for humans, such as carbon storage, food production, crop pollination and pest regulation. However, grasslands are today one of the most endangered ecosystems due to land use change, agricultural intensification, land abandonment as well as climate change. The present study explores the performance of a knowledge-driven GEOgraphic-Object&mdash;based Image Analysis (GEOBIA) learning scheme to classify Very High Resolution (VHR) images for natural grassland ecosystem mapping. The classification was applied to a Natura 2000 protected area in Southern Italy. The Food and Agricultural Organization Land Cover Classification System (FAO-LCCS) hierarchical scheme was instantiated in the learning phase of the algorithm. Four multi-temporal WorldView-2 (WV-2) images were classified by combining plant phenology and agricultural practices rules with prior-image spectral knowledge. Drawing on this knowledge, spectral bands and entropy features from one single date (Post Peak of Biomass) were firstly used for multiple-scale image segmentation into Small Objects (SO) and Large Objects (LO). Thereafter, SO were labelled by considering spectral and context-sensitive features from the whole multi-seasonal data set available together with ancillary data. Lastly, the labelled SO were overlaid to LO segments and, in turn, the latter were labelled by adopting FAO-LCCS criteria about the SOs presence dominance in each LO. Ground reference samples were used only for validating the SO and LO output maps. The knowledge driven GEOBIA classifier for SO classification obtained an OA value of 97.35% with an error of 0.04. For LO classification the value was 75.09% with an error of 0.70. At SO scale, grasslands ecosystem was classified with 92.6%, 99.9% and 96.1% of User&rsquo;s, Producer&rsquo;s Accuracy and F1-score, respectively. The findings reported indicate that the knowledge-driven approach not only can be applied for (semi)natural grasslands ecosystem mapping in vast and not accessible areas but can also reduce the costs of ground truth data acquisition. The approach used may provide different level of details (small and large objects in the scene) but also indicates how to design and validate local conservation policies.
KW  - expert knowledge
KW  - Very High Resolution (VHR)
KW  - grasslands ecosystems
KW  - object-based classification
DO  - 10.3390/rs12091447
ER  -
TY  - EJOU
AU  - Gorkin, Robert
AU  - Adams, Kye
AU  - Berryman, Matthew J.
AU  - Aubin, Sam
AU  - Li, Wanqing
AU  - Davis, Andrew R.
AU  - Barthelemy, Johan
TI  - Sharkeye: Real-Time Autonomous Personal Shark Alerting via Aerial Surveillance
T2  - Drones

PY  - 2020
VL  - 4
IS  - 2
SN  - 2504-446X

AB  - While aerial shark spotting has been a standard practice for beach safety for decades, new technologies offer enhanced opportunities, ranging from drones/unmanned aerial vehicles (UAVs) that provide new viewing capabilities, to new apps that provide beachgoers with up-to-date risk analysis before entering the water. This report describes the Sharkeye platform, a first-of-its-kind project to demonstrate personal shark alerting for beachgoers in the water and on land, leveraging innovative UAV image collection, cloud-hosted machine learning detection algorithms, and reporting via smart wearables. To execute, our team developed a novel detection algorithm trained via machine learning based on aerial footage of real sharks and rays collected at local beaches, hosted and deployed the algorithm in the cloud, and integrated push alerts to beachgoers in the water via a shark app to run on smartwatches. The project was successfully trialed in the field in Kiama, Australia, with over 350 detection events recorded, followed by the alerting of multiple smartwatches simultaneously both on land and in the water, and with analysis capable of detecting shark analogues, rays, and surfers in average beach conditions, and all based on ~1 h of training data in total. Additional demonstrations showed potential of the system to enable lifeguard-swimmer communication, and the ability to create a network on demand to enable the platform. Our system was developed to provide swimmers and surfers with immediate information via smart apps, empowering lifeguards/lifesavers and beachgoers to prevent unwanted encounters with wildlife before it happens.
KW  - UAV
KW  - blimp
KW  - shark spotting
KW  - machine learning
KW  - wearables
DO  - 10.3390/drones4020018
ER  -
TY  - EJOU
AU  - Sancho Martínez, Jorge
AU  - Fernández, Yadira B.
AU  - Leinster, Paul
AU  - Casado, Mónica R.
TI  - Combining Unmanned Aircraft Systems and Image Processing for Wastewater Treatment Plant Asset Inspection
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 9
SN  - 2072-4292

AB  - Wastewater treatment plants are essential for preserving the water quality of freshwater and marine ecosystems. It is estimated that, in the UK, as much as 11 billion liters of wastewater are treated on a daily basis. Effective and efficient treatment of wastewater requires treatment plants to be maintained in good condition. Recent studies have highlighted the potential of unmanned aircraft systems (UASs) and image processing to be used in autonomous and automated monitoring systems. However, the combined use of UASs and image processing for wastewater treatment plant inspections has not yet been tested. This paper presents a novel image processing-UAS framework for the identification of failures in trickling filters and activated sludge facilities. The results show that the proposed framework has an accuracy of 95% in the detection of failures in activated sludge assets, with the accuracy ranging between 55% and 81% for trickling filters. These results are promising and they highlight the potential use of the technology for the inspection of wastewater treatment plants.
KW  - trickling filters
KW  - activated sludge
KW  - unmanned aircraft systems
KW  - UASs
KW  - asset inspection
KW  - wastewater treatment plants
KW  - site inspection
DO  - 10.3390/rs12091461
ER  -
TY  - EJOU
AU  - Ding, Yanling
AU  - Zhang, Hongyan
AU  - Wang, Zhongqiang
AU  - Xie, Qiaoyun
AU  - Wang, Yeqiao
AU  - Liu, Lin
AU  - Hall, Christopher C.
TI  - A Comparison of Estimating Crop Residue Cover from Sentinel-2 Data Using Empirical Regressions and Machine Learning Methods
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 9
SN  - 2072-4292

AB  - Quantifying crop residue cover (CRC) on field surfaces is important for monitoring the tillage intensity and promoting sustainable management. Remote-sensing-based techniques have proven practical for determining CRC, however, the methods used are primarily limited to empirical regression based on crop residue indices (CRIs). This study provides a systematic evaluation of empirical regressions and machine learning (ML) algorithms based on their ability to estimate CRC using Sentinel-2 Multispectral Instrument (MSI) data. Unmanned aerial vehicle orthomosaics were used to extracted ground CRC for training Sentinel-2 data-based CRC models. For empirical regression, nine MSI bands, 10 published CRIs, three proposed CRIs, and four mean textural features were evaluated using univariate linear regression. The best performance was obtained by a three-band index calculated using (B2 &minus; B4)/(B2 &minus; B12), with an R2cv of 0.63 and RMSEcv of 6.509%, using a 10-fold cross-validation. The methodologies of partial least squares regression (PLSR), artificial neural network (ANN), Gaussian process regression (GPR), support vector regression (SVR), and random forest (RF) were compared with four groups of predictors, including nine MSI bands, 13 CRIs, a combination of MSI bands and mean textural features, and a combination of CRIs and textural features. In general, ML approaches achieved high accuracy. A PLSR model with 13 CRIs and textural features resulted in an accuracy of R2cv = 0.66 and RMSEcv = 6.427%. An RF model with predictors of MSI bands and textural features estimated CRC with an R2cv = 0.61 and RMSEcv = 6.415%. The estimation was improved by an SVR model with the same input predictors (R2cv = 0.67, RMSEcv = 6.343%), followed by a GPR model based on CRIs and textural features. The performance of GPR models was further improved by optimal input variables. A GPR model with six input variables, three MSI bands and three textural features, performed the best, with R2cv = 0.69 and RMSEcv = 6.149%. This study provides a reference for estimating CRC from Sentinel-2 imagery using ML approaches. The GPR approach is recommended. A combination of spectral information and textural features leads to an improvement in the retrieval of CRC.
KW  - crop residue cover
KW  - crop residue indices
KW  - empirical regression
KW  - machine learning regression
KW  - Sentinel-2 MSI
KW  - textural feature
KW  - unmanned aerial vehicle
DO  - 10.3390/rs12091470
ER  -
TY  - EJOU
AU  - Zhao, Peng
AU  - Wang, Jianzhong
AU  - Kong, Lingren
TI  - Construction and Optimization of Biconnected and Wide-Coverage Topology Based on Node Mobility
T2  - Symmetry

PY  - 2020
VL  - 12
IS  - 5
SN  - 2073-8994

AB  - Constructing a communications topology with fault tolerance and effective coverage plays an important role in wireless sensor networks. This paper is aimed at constructing and maintaining a biconnected topology, while minimizing the movement distance of the nodes and maximizing the coverage of the field of interest. First, it presents a new model with the motion constraint. If the nodes move at distance within the limit value calculated by the model, the topology is always connected, whether the neighbors of nodes are dynamic or static. Secondly, it improves the coverage strategy based on the nearest neighbor rule (NNR) and finds a rule of nodes&rsquo; spreading so that the nodes are distributed evenly and the spacing of the adjacent nodes is controllable. In addition, the nodes move only when necessary according to the added judgment conditions. Consequently, the movement distance is reduced. The simulation results prove the feasibility and effectiveness of the Localized Topology Optimized Method (LTOM) proposed by this paper. The connected indicators of the system&rsquo;s topology during implementing LTOM are consistent, and the transformation of topology by LTOM is symmetric. Compared with the other distributed algorithm, NNR, LTOM reduces the movement distance of nodes, improves the connected probability, and maximizes the coverage of the topological structures under the biconnected conditions.
KW  - biconnected topology
KW  - minimize the movement
KW  - maximize the coverage
KW  - distributed optimization
DO  - 10.3390/sym12050791
ER  -
TY  - EJOU
AU  - Randazzo, Giovanni
AU  - Barreca, Giovanni
AU  - Cascio, Maria
AU  - Crupi, Antonio
AU  - Fontana, Marco
AU  - Gregorio, Francesco
AU  - Lanza, Stefania
AU  - Muzirafuti, Anselme
TI  - Analysis of Very High Spatial Resolution Images for Automatic Shoreline Extraction and Satellite-Derived Bathymetry Mapping
T2  - Geosciences

PY  - 2020
VL  - 10
IS  - 5
SN  - 2076-3263

AB  - The amount of Earth observation images available to the public has been the main source of information, helping governments and decision-makers tackling the current world&rsquo;s most pressing global challenge. However, a number of highly skilled and qualified personnel are still needed to fill the gap and help turn these data into intelligence. In addition, the accuracy of this intelligence relies on the quality of these images in times of temporal, spatial, and spectral resolution. For the purpose of contributing to the global effort aiming at monitoring natural and anthropic processes affecting coastal areas, we proposed a framework for image processing to extract the shoreline and the shallow water depth on GeoEye-1 satellite image and orthomosaic image acquired by an unmanned aerial vehicle (UAV) on the coast of San Vito Lo Capo, with image preprocessing steps involving orthorectification, atmospheric correction, pan sharpening, and binary imaging for water and non-water pixels analysis. Binary imaging analysis step was followed by automatic instantaneous shoreline extraction on a digital image and satellite-derived bathymetry (SDB) mapping on GeoEye-1 water pixels. The extraction of instantaneous shoreline was conducted automatically in ENVI software using a raster to vector (R2V) algorithm, whereas the SDB was computed in ArcGIS software using a log-band ratio method applied on the satellite image and available field data for calibration and vertical referencing. The results obtained from these very high spatial resolution images demonstrated the ability of remote sensing techniques in providing information where techniques using traditional methods present some limitations, especially due to their inability to map hard-to-reach areas and very dynamic near shoreline waters. We noticed that for the period of 5 years, the shoreline of San Vito Lo Capo sand beach migrated about 15 m inland, indicating the high dynamism of this coastal area. The bathymetric information obtained on the GeoEye-1 satellite image provided water depth until 10 m deep with R2 = 0.753. In this paper, we presented cost-effective and practical methods for automatic shoreline extraction and bathymetric mapping of shallow water, which can be adopted for the management and the monitoring of coastal areas.
KW  - remote sensing
KW  - GeoEye-1
KW  - unmanned aerial vehicle (UAV)
KW  - image processing
KW  - satellite-derived bathymetry (SDB)
KW  - binary imaging analysis
KW  - coastal erosion
KW  - pocket beach
KW  - San Vito Lo Capo
KW  - climate change
DO  - 10.3390/geosciences10050172
ER  -
TY  - EJOU
AU  - Rodoshi, Rehenuma T.
AU  - Kim, Taewoon
AU  - Choi, Wooyeol
TI  - Resource Management in Cloud Radio Access Network: Conventional and New Approaches
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 9
SN  - 1424-8220

AB  - Cloud radio access network (C-RAN) is a promising mobile wireless sensor network architecture to address the challenges of ever-increasing mobile data traffic and network costs. C-RAN is a practical solution to the strict energy-constrained wireless sensor nodes, often found in Internet of Things (IoT) applications. Although this architecture can provide energy efficiency and reduce cost, it is a challenging task in C-RAN to utilize the resources efficiently, considering the dynamic real-time environment. Several research works have proposed different methodologies for effective resource management in C-RAN. This study performs a comprehensive survey on the state-of-the-art resource management techniques that have been proposed recently for this architecture. The resource management techniques are categorized into computational resource management (CRM) and radio resource management (RRM) techniques. Then both of the techniques are further classified and analyzed based on the strategies used in the studies. Remote radio head (RRH) clustering schemes used in CRM techniques are discussed extensively. In this research work, the investigated performance metrics and their validation techniques are critically analyzed. Moreover, other important challenges and open research issues for efficient resource management in C-RAN are highlighted to provide future research direction.
KW  - cloud radio access network
KW  - resource management
KW  - RRM
KW  - CRM
KW  - RRH clustering
DO  - 10.3390/s20092708
ER  -
TY  - EJOU
AU  - Khaki, Saeed
AU  - Pham, Hieu
AU  - Han, Ye
AU  - Kuhl, Andy
AU  - Kent, Wade
AU  - Wang, Lizhi
TI  - Convolutional Neural Networks for Image-Based Corn Kernel Detection and Counting
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 9
SN  - 1424-8220

AB  - Precise in-season corn grain yield estimates enable farmers to make real-time accurate harvest and grain marketing decisions minimizing possible losses of profitability. A well developed corn ear can have up to 800 kernels, but manually counting the kernels on an ear of corn is labor-intensive, time consuming and prone to human error. From an algorithmic perspective, the detection of the kernels from a single corn ear image is challenging due to the large number of kernels at different angles and very small distance among the kernels. In this paper, we propose a kernel detection and counting method based on a sliding window approach. The proposed method detects and counts all corn kernels in a single corn ear image taken in uncontrolled lighting conditions. The sliding window approach uses a convolutional neural network (CNN) for kernel detection. Then, a non-maximum suppression (NMS) is applied to remove overlapping detections. Finally, windows that are classified as kernel are passed to another CNN regression model for finding the     ( x , y )     coordinates of the center of kernel image patches. Our experiments indicate that the proposed method can successfully detect the corn kernels with a low detection error and is also able to detect kernels on a batch of corn ears positioned at different angles.
KW  - corn kernel counting
KW  - object detection
KW  - convolutional neural networks
KW  - digital agriculture
DO  - 10.3390/s20092721
ER  -
TY  - EJOU
AU  - Jiang, Ling
AU  - Hu, Yang
AU  - Xia, Xilin
AU  - Liang, Qiuhua
AU  - Soltoggio, Andrea
AU  - Kabir, Syed R.
TI  - A Multi-Scale Mapping Approach Based on a Deep Learning CNN Model for Reconstructing High-Resolution Urban DEMs
T2  - Water

PY  - 2020
VL  - 12
IS  - 5
SN  - 2073-4441

AB  - The scarcity of high-resolution urban digital elevation model (DEM) datasets, particularly in certain developing countries, has posed a challenge for many water-related applications such as flood risk management. A solution to address this is to develop effective approaches to reconstruct high-resolution DEMs from their low-resolution equivalents that are more widely available. However, the current high-resolution DEM reconstruction approaches mainly focus on natural topography. Few attempts have been made for urban topography, which is typically an integration of complex artificial and natural features. This study proposed a novel multi-scale mapping approach based on convolutional neural network (CNN) to deal with the complex features of urban topography and to reconstruct high-resolution urban DEMs. The proposed multi-scale CNN model was firstly trained using urban DEMs that contained topographic features at different resolutions, and then used to reconstruct the urban DEM at a specified (high) resolution from a low-resolution equivalent. A two-level accuracy assessment approach was also designed to evaluate the performance of the proposed urban DEM reconstruction method, in terms of numerical accuracy and morphological accuracy. The proposed DEM reconstruction approach was applied to a 121 km2 urbanized area in London, United Kingdom. Compared with other commonly used methods, the current CNN-based approach produced superior results, providing a cost-effective innovative method to acquire high-resolution DEMs in other data-scarce regions.
KW  - urban DEM
KW  - high resolution
KW  - deep learning
KW  - convolutional neural network
KW  - multiple scales
KW  - flood modeling
DO  - 10.3390/w12051369
ER  -
TY  - EJOU
AU  - Fu, Jun
AU  - Yuan, Haikuo
AU  - Zhao, Rongqiang
AU  - Chen, Zhi
AU  - Ren, Luquan
TI  - Peeling Damage Recognition Method for Corn Ear Harvest Using RGB Image
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 10
SN  - 2076-3417

AB  - Corn ear damage caused by peeling significantly influence the output and quality of corn harvest. Ear damage recognition is the basis to adjust working parameters and to reduce damage. Image processing is attracting increasing attentions in the field of agriculture. Conventional image processing methods are difficult to be used for recognizing corn ear damage caused by peeling in field harvesting. To address the this problem, in this paper, we propose a peeling damage recognition method based on RGB image. For our method, we develop a dictionary-learning-based method to recognize corn kernels and a thresholding method to recognize ear damage regions. To obtain better performance, we also develop the corroding algorithm and the expanding algorithm for the post-processing of recognized results. The experimental results demonstrate the practicality and accuracy of the proposed method. This study could provide the theoretical basis to develop online peeling damage detection system for corn ear harvesters.
KW  - corn damage
KW  - peeling damage
KW  - recognition method
KW  - RGB image
KW  - corn ear harvest
DO  - 10.3390/app10103371
ER  -
TY  - EJOU
AU  - Azimi, Mohsen
AU  - Eslamlou, Armin D.
AU  - Pekcan, Gokhan
TI  - Data-Driven Structural Health Monitoring and Damage Detection through Deep Learning: State-of-the-Art Review
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 10
SN  - 1424-8220

AB  - Data-driven methods in structural health monitoring (SHM) is gaining popularity due to recent technological advancements in sensors, as well as high-speed internet and cloud-based computation. Since the introduction of deep learning (DL) in civil engineering, particularly in SHM, this emerging and promising tool has attracted significant attention among researchers. The main goal of this paper is to review the latest publications in SHM using emerging DL-based methods and provide readers with an overall understanding of various SHM applications. After a brief introduction, an overview of various DL methods (e.g., deep neural networks, transfer learning, etc.) is presented. The procedure and application of vibration-based, vision-based monitoring, along with some of the recent technologies used for SHM, such as sensors, unmanned aerial vehicles (UAVs), etc. are discussed. The review concludes with prospects and potential limitations of DL-based methods in SHM applications.
KW  - deep learning
KW  - machine learning
KW  - structural health monitoring
KW  - crack detection
KW  - damage detection
KW  - data science
KW  - computer vision
DO  - 10.3390/s20102778
ER  -
TY  - EJOU
AU  - Chun, Pang-jo
AU  - Yamane, Tatsuro
AU  - Izumi, Shota
AU  - Kuramoto, Naoya
TI  - Development of a Machine Learning-Based Damage Identification Method Using Multi-Point Simultaneous Acceleration Measurement Results
T2  - Sensors

PY  - 2020
VL  - 20
IS  - 10
SN  - 1424-8220

AB  - It is necessary to assess damage properly for the safe use of a structure and for the development of an appropriate maintenance strategy. Although many efforts have been made to measure the vibration of a structure to determine the degree of damage, the accuracy of evaluation is not high enough, so it is difficult to say that a damage evaluation based on vibrations in a structure has not been put to practical use. In this study, we propose a method to evaluate damage by measuring the acceleration of a structure at multiple points and interpreting the results with a Random Forest, which is a kind of supervised machine learning. The proposed method uses the maximum response acceleration, standard deviation, logarithmic decay rate, and natural frequency to improve the accuracy of damage assessment. We propose a three-step Random Forest method to evaluate various damage types based on the results of these many measurements. Then, the accuracy of the proposed method is verified based on the results of a cross-validation and a vibration test of an actual damaged specimen.
KW  - artificial intelligence
KW  - machine learning
KW  - Random Forest
KW  - vibration
KW  - damage detection
KW  - damage evaluation
DO  - 10.3390/s20102780
ER  -
TY  - EJOU
AU  - Hong, Suk-Ju
AU  - Kim, Sang-Yeon
AU  - Kim, Eungchan
AU  - Lee, Chang-Hyup
AU  - Lee, Jung-Sup
AU  - Lee, Dong-Soo
AU  - Bang, Jiwoong
AU  - Kim, Ghiseok
TI  - Moth Detection from Pheromone Trap Images Using Deep Learning Object Detectors
T2  - Agriculture

PY  - 2020
VL  - 10
IS  - 5
SN  - 2077-0472

AB  - Diverse pheromones and pheromone-based traps, as well as images acquired from insects captured by pheromone-based traps, have been studied and developed to monitor the presence and abundance of pests and to protect plants. The purpose of this study is to construct models that detect three species of pest moths in pheromone trap images using deep learning object detection methods and compare their speed and accuracy. Moth images in pheromone traps were collected for training and evaluation of deep learning detectors. Collected images were then subjected to a labeling process that defines the ground truths of target objects for their box locations and classes. Because there were a few negative objects in the dataset, non-target insects were labeled as unknown class and images of non-target insects were added to the dataset. Moreover, data augmentation methods were applied to the training process, and parameters of detectors that were pre-trained with the COCO dataset were used as initial parameter values. Seven detectors&mdash;Faster R-CNN ResNet 101, Faster R-CNN ResNet 50, Faster R-CNN Inception v.2, R-FCN ResNet 101, Retinanet ResNet 50, Retinanet Mobile v.2, and SSD Inception v.2 were trained and evaluated. Faster R-CNN ResNet 101 detector exhibited the highest accuracy (mAP as 90.25), and seven different detector types showed different accuracy and speed. Furthermore, when unexpected insects were included in the collected images, a four-class detector with an unknown class (non-target insect) showed lower detection error than a three-class detector.
KW  - pheromone trap
KW  - pest
KW  - moth
KW  - deep learning
KW  - horticulture
KW  - insect detection
DO  - 10.3390/agriculture10050170
ER  -
TY  - EJOU
AU  - Pan, Zhuokun
AU  - Xu, Jiashu
AU  - Guo, Yubin
AU  - Hu, Yueming
AU  - Wang, Guangxing
TI  - Deep Learning Segmentation and Classification for Urban Village Using a Worldview Satellite Image Based on U-Net
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 10
SN  - 2072-4292

AB  - Unplanned urban settlements exist worldwide. The geospatial information of these areas is critical for urban management and reconstruction planning but usually unavailable. Automatically characterizing individual buildings in the unplanned urban village using remote sensing imagery is very challenging due to complex landscapes and high-density settlements. The newly emerging deep learning method provides the potential to characterize individual buildings in a complex urban village. This study proposed an urban village mapping paradigm based on U-net deep learning architecture. The study area is located in Guangzhou City, China. The Worldview satellite image with eight pan-sharpened bands at a 0.5-m spatial resolution and building boundary vector file were used as research purposes. There are ten sites of the urban villages included in this scene of the Worldview image. The deep neural network model was trained and tested based on the selected six and four sites of the urban village, respectively. Models for building segmentation and classification were both trained and tested. The results indicated that the U-net model reached overall accuracy over 86% for building segmentation and over 83% for the classification. The F1-score ranged from 0.9 to 0.98 for the segmentation, and from 0.63 to 0.88 for the classification. The Interaction over Union reached over 90% for the segmentation and 86% for the classification. The superiority of the deep learning method has been demonstrated through comparison with Random Forest and object-based image analysis. This study fully showed the feasibility, efficiency, and potential of the deep learning in delineating individual buildings in the high-density urban village. More importantly, this study implied that through deep learning methods, mapping unplanned urban settlements could further characterize individual buildings with considerable accuracy.
KW  - deep learning
KW  - urban village settlement
KW  - Worldview imagery
KW  - U-net
KW  - segmentation
KW  - Guangzhou
DO  - 10.3390/rs12101574
ER  -
TY  - EJOU
AU  - Cholula, Uriel
AU  - da Silva, Jorge A.
AU  - Marconi, Thiago
AU  - Thomasson, J. A.
AU  - Solorzano, Jorge
AU  - Enciso, Juan
TI  - Forecasting Yield and Lignocellulosic Composition of Energy Cane Using Unmanned Aerial Systems
T2  - Agronomy

PY  - 2020
VL  - 10
IS  - 5
SN  - 2073-4395

AB  - Crop monitoring and appropriate agricultural management practices of elite germplasm will enhance bioenergy&rsquo;s efficiency. Unmanned aerial systems (UAS) may be a useful tool for this purpose. The objective of this study was to assess the use of UAS with true color and multispectral imagery to predict the yield and total cellulosic content (TCC) of newly created energy cane germplasm. A trial was established in the growing season of 2016 at the Texas A&amp;M AgriLife Research Center in Weslaco, Texas, where 15 energy cane elite lines and three checks were grown on experimental plots, arranged in a complete block design and replicated four times. Four flights were executed at different growth stages in 2018, at the first ratoon crop, using two multi-rotor UAS: the DJI Phantom 4 Pro equipped with RGB camera and the DJI Matrice 100, equipped with multispectral sensor (SlantRange 3p). Canopy cover, canopy height, NDVI (Normalized Difference Vegetation Index), and ExG (Excess Green Index) were extracted from the images and used to perform a stepwise regression to obtain the yield and TCC models. The results showed a good agreement between the predicted and the measured yields (R2 = 0.88); however, a low coefficient of determination was found between the predicted and the observed TCC (R2 = 0.30). This study demonstrated the potential application of UAS to estimate energy cane yield with high accuracy, enabling plant breeders to phenotype larger populations and make selections with higher confidence.
KW  - energy cane
KW  - NDVI
KW  - ExG
KW  - yield
KW  - total cellulosic content
DO  - 10.3390/agronomy10050718
ER  -
TY  - EJOU
AU  - Thompson, Laura J.
AU  - Puntel, Laila A.
TI  - Transforming Unmanned Aerial Vehicle (UAV) and Multispectral Sensor into a Practical Decision Support System for Precision Nitrogen Management in Corn
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 10
SN  - 2072-4292

AB  - Determining the optimal nitrogen (N) rate in corn remains a critical issue, mainly due to unaccounted spatial (e.g., soil properties) and temporal (e.g., weather) variability. Unmanned aerial vehicles (UAVs) equipped with multispectral sensors may provide opportunities to improve N management by the timely informing of spatially variable, in-season N applications. Here, we developed a practical decision support system (DSS) to translate spatial field characteristics and normalized difference red edge (NDRE) values into an in-season N application recommendation. On-farm strip-trials were established at three sites over two years to compare farmer&rsquo;s traditional N management to a split-application N management guided by our UAV sensor-based DSS. The proposed systems increased nitrogen use efficiency 18.3 &plusmn; 6.1 kg grain kg N&minus;1 by reducing N rates by 31 &plusmn; 6.3 kg N ha&minus;1 with no yield differences compared to the farmers&rsquo; traditional management. We identify five avenues for further improvement of the proposed DSS: definition of the initial base N rate, estimation of inputs for sensor algorithms, management zone delineation, high-resolution image normalization approach, and the threshold for triggering N application. Two virtual reference (VR) methods were compared with the high N (HN) reference strip method for normalizing high-resolution sensor data. The VR methods resulted in significantly lower sufficiency index values than those generated by the HN reference, resulting in N fertilization recommendations that were 31.4 &plusmn; 10.3 kg ha&minus;1 higher than the HN reference N fertilization recommendation. The use of small HN reference blocks in contrasting management zones may be more appropriate to translate field-scale, high-resolution imagery into in-season N recommendations. In view of a growing interest in using UAVs in commercial fields and the need to improve crop NUE, further work is needed to refine approaches for translating imagery into in-season N recommendations.
KW  - precision ag
KW  - UAV
KW  - spatial variability
KW  - NDRE
KW  - nitrogen
KW  - on-farm
KW  - corn
KW  - multispectral sensor
KW  - site-specific management
KW  - nitrogen use efficiency
DO  - 10.3390/rs12101597
ER  -
TY  - EJOU
AU  - Deng, Xiaoling
AU  - Tong, Zejing
AU  - Lan, Yubin
AU  - Huang, Zixiao
TI  - Detection and Location of Dead Trees with Pine Wilt Disease Based on Deep Learning and UAV Remote Sensing
T2  - AgriEngineering

PY  - 2020
VL  - 2
IS  - 2
SN  - 2624-7402

AB  - Pine wilt disease causes huge economic losses to pine wood forestry because of its destructiveness and rapid spread. This paper proposes a detection and location method of pine wood nematode disease at a large scale adopting UAV (Unmanned Aerial Vehicle) remote sensing and artificial intelligence technology. The UAV remote sensing images were enhanced by computer vision tools. A Faster-RCNN (Faster Region Convolutional Neural Networks) deep learning framework based on a RPN (Region Proposal Network) network and the ResNet residual neural network were used to train the pine wilt diseased dead tree detection model. The loss function and the anchors in the RPN of the convolutional neural network were optimized. Finally, the location of pine wood nematode dead tree was conducted, which generated the geographic information on the detection results. The results show that ResNet101 performed better than VGG16 (Visual Geometry Group 16) convolutional neural network. The detection accuracy was improved and reached to about 90% after a series of optimizations to the network, meaning that the optimization methods proposed in this paper are feasible to pine wood nematode dead tree detection.
KW  - pine wilt disease
KW  - Faster-RCNN
KW  - UAV remote sensing
KW  - deep learning
KW  - geographical information
DO  - 10.3390/agriengineering2020019
ER  -
TY  - EJOU
AU  - Iizuka, Kotaro
AU  - Hayakawa, Yuichi S.
AU  - Ogura, Takuro
AU  - Nakata, Yasutaka
AU  - Kosugi, Yoshiko
AU  - Yonehara, Taichiro
TI  - Integration of Multi-Sensor Data to Estimate Plot-Level Stem Volume Using Machine Learning Algorithms–Case Study of Evergreen Conifer Planted Forests in Japan
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 10
SN  - 2072-4292

AB  - The development of new methods for estimating precise forest structure parameters is essential for the quantitative evaluation of forest resources. Conventional use of satellite image data, increasing use of terrestrial laser scanning (TLS), and emerging trends in the use of unmanned aerial systems (UASs) highlight the importance of modern technologies in the realm of forest observation. Each technology has different advantages, and this work seeks to incorporate multiple satellite, TLS- and UAS-based remote sensing data sets to improve the ability to estimate forest structure parameters. In this paper, two regression analysis approaches are considered for the estimation: random forest regression (RFR) and support vector regression (SVR). To collect the dependent variable, in situ measurements of individual tree parameters (tree height and diameter at breast height (DBH)) were taken in a Japanese cypress forest using the nondestructive TLS method, which scans the forest to obtain dense and accurate point clouds under the tree canopy. Based on the TLS data, the stem volume was then computed and treated as ground truth information. Topographic and UAS information was then used to calculate various remotely sensed explanatory variables, such as canopy size, canopy cover, and tree height. Canopy cover and canopy shapes were computed via the orthoimages derived from the UAS and watershed segmentation method, respectively. Tree height was computed by combining the digital surface model (DSM) from the UAS and the digital terrain model (DTM) from the TLS data. Topographic variables were computed from the DTM. The backscattering intensity in the satellite imagery was obtained based on L-band (Advanced Land Observing Satellite-2 (ALOS-2) Phased Array type L-band Synthetic Aperture Radar-2 (PALSAR-2)) and C-band (Sentinel-1) synthetic aperture radar (SAR). All satellite (10&ndash;25 m resolution), TLS (3.4 mm resolution) and UAS (2.3&ndash;4.6 cm resolution) data were then combined, and RFR and SVR were trained; the resulting predictive powers were then compared. The RFR method yielded fitting R2 up to 0.665 and RMSE up to 66.87 m3/ha (rRMSE = 11.95%) depending on the input variables (best result with canopy height, canopy size, canopy cover, and Sentinel-1 data), and the SVR method showed fitting R2 up to 0.519 and RMSE up to 80.12 m3/ha (rRMSE = 12.67%). The RFR outperformed the SVR method, which could delineate the relationship between the variables for better model accuracy. This work has demonstrated that incorporating various remote sensing data to satellite data, especially adding finer resolution data, can provide good estimates of forest parameters at a plot level (10 by 10 m), potentially allowing advancements in precision forestry.
KW  - UAS
KW  - stem volume
KW  - TLS
KW  - SAR
KW  - random forest
KW  - support vector
KW  - multiple regression
KW  - forest
KW  - biophysical parameter
DO  - 10.3390/rs12101649
ER  -
TY  - EJOU
AU  - Ciaburro, Giuseppe
AU  - Iannace, Gino
AU  - Trematerra, Amelia
TI  - Research for the Presence of Unmanned Aerial Vehicle inside Closed Environments with Acoustic Measurements
T2  - Buildings

PY  - 2020
VL  - 10
IS  - 5
SN  - 2075-5309

AB  - Small UAVs (unmanned aerial vehicle) can be used in many sectors such as the acquisition of images or the transport of objects. Small UAVs have also been used for terrorist activities or to disturb the flight of airplanes. Due to the small size and the presence of only rotating parts, drones escape traditional controls and therefore represent a danger. This paper reports a methodology for identifying the presence of small UAVs inside a closed environment by measuring the noise emitted during the flight. Acoustic measurements of the noise emitted by a drone inside a large environment (12.0 &times; 30.0 &times; 12.0 m) were performed. The noise was measured with a sound level meter placed at different distances (5, 10, and 15 m), to characterize the noise in the absence of anthropic noise. In this configuration, a typical tonal component of drone noise is highlighted at the frequency of one-third of an octave at 5000 Hz due to the rotation of the blades. This component is also present 15 m away from the source point. Subsequent measurements were performed by introducing into the environment, through a loudspeaker, the anthropogenic noise produced by the buzz of people and background music. It is possible to distinguish the typical tonal component of UAV noise at the frequency of 5000 Hz even when the level of recording of anthropogenic noise emitted by the loudspeaker is at the maximum power tested. It is therefore possible to search for the presence of small UAVs inside a specific closed environment with only acoustic measurements, paying attention to the typical frequency of noise emission equal to 5000 Hz.
KW  - UAV
KW  - frequency
KW  - acoustic measurements
KW  - noise
KW  - closed environments
DO  - 10.3390/buildings10050096
ER  -
TY  - EJOU
AU  - Mielcarek, Miłosz
AU  - Kamińska, Agnieszka
AU  - Stereńczak, Krzysztof
TI  - Digital Aerial Photogrammetry (DAP) and Airborne Laser Scanning (ALS) as Sources of Information about Tree Height: Comparisons of the Accuracy of Remote Sensing Methods for Tree Height Estimation
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 11
SN  - 2072-4292

AB  - The rapid developments in the field of digital aerial photogrammetry (DAP) in recent years have increased interest in the application of DAP data for extracting three-dimensional (3D) models of forest canopies. This technology, however, still requires further investigation to confirm its reliability in estimating forest attributes in complex forest conditions. The main purpose of this study was to evaluate the accuracy of tree height estimation based on a crown height model (CHM) generated from the difference between a DAP-derived digital surface model (DSM) and an airborne laser scanning (ALS)-derived digital terrain model (DTM). The tree heights determined based on the DAP-CHM were compared with ground-based measurements and heights obtained using ALS data only (ALS-CHM). Moreover, tree- and stand-related factors were examined to evaluate the potential influence on the obtained discrepancies between ALS- and DAP-derived heights. The obtained results indicate that the differences between the means of field-measured heights and DAP-derived heights were statistically significant. The root mean square error (RMSE) calculated in the comparison of field heights and DAP-derived heights was 1.68 m (7.34%). The results obtained for the CHM generated using only ALS data produced slightly lower errors, with RMSE = 1.25 m (5.46%) on average. Both ALS and DAP displayed the tendency to underestimate tree heights compared to those measured in the field; however, DAP produced a higher bias (1.26 m) than ALS (0.88 m). Nevertheless, DAP heights were highly correlated with the heights measured in the field (R2 = 0.95) and ALS-derived heights (R2 = 0.97). Tree species and height difference (the difference between the reference tree height and mean tree height in a sample plot) had the greatest influence on the differences between ALS- and DAP-derived heights. Our study confirms that a CHM computed based on the difference between a DAP-derived DSM and an ALS-derived DTM can be successfully used to measure the height of trees in the upper canopy layer.
KW  - DAP
KW  - ALS
KW  - CHM
KW  - tree height
KW  - forestry
KW  - photogrammetry
KW  - stereomatching
DO  - 10.3390/rs12111808
ER  -
TY  - EJOU
AU  - Zhang, Zhao
AU  - Flores, Paulo
AU  - Igathinathane, C.
AU  - L. Naik, Dayakar
AU  - Kiran, Ravi
AU  - Ransom, Joel K.
TI  - Wheat Lodging Detection from UAS Imagery Using Machine Learning Algorithms
T2  - Remote Sensing

PY  - 2020
VL  - 12
IS  - 11
SN  - 2072-4292

AB  - The current mainstream approach of using manual measurements and visual inspections for crop lodging detection is inefficient, time-consuming, and subjective. An innovative method for wheat lodging detection that can overcome or alleviate these shortcomings would be welcomed. This study proposed a systematic approach for wheat lodging detection in research plots (372 experimental plots), which consisted of using unmanned aerial systems (UAS) for aerial imagery acquisition, manual field evaluation, and machine learning algorithms to detect the occurrence or not of lodging. UAS imagery was collected on three different dates (23 and 30 July 2019, and 8 August 2019) after lodging occurred. Traditional machine learning and deep learning were evaluated and compared in this study in terms of classification accuracy and standard deviation. For traditional machine learning, five types of features (i.e. gray level co-occurrence matrix, local binary pattern, Gabor, intensity, and Hu-moment) were extracted and fed into three traditional machine learning algorithms (i.e., random forest (RF), neural network, and support vector machine) for detecting lodged plots. For the datasets on each imagery collection date, the accuracies of the three algorithms were not significantly different from each other. For any of the three algorithms, accuracies on the first and last date datasets had the lowest and highest values, respectively. Incorporating standard deviation as a measurement of performance robustness, RF was determined as the most satisfactory. Regarding deep learning, three different convolutional neural networks (simple convolutional neural network, VGG-16, and GoogLeNet) were tested. For any of the single date datasets, GoogLeNet consistently had superior performance over the other two methods. Further comparisons between RF and GoogLeNet demonstrated that the detection accuracies of the two methods were not significantly different from each other (p &gt; 0.05); hence, the choice of any of the two would not affect the final detection accuracies. However, considering the fact that the average accuracy of GoogLeNet (93%) was larger than RF (91%), it was recommended to use GoogLeNet for wheat lodging detection. This research demonstrated that UAS RGB imagery, coupled with the GoogLeNet machine learning algorithm, can be a novel, reliable, objective, simple, low-cost, and effective (accuracy &gt; 90%) tool for wheat lodging detection.
KW  - precision agriculture
KW  - field crops
KW  - machine learning
KW  - deep learning
KW  - image processing
KW  - textural features
DO  - 10.3390/rs12111838
ER  -
TY  - EJOU
AU  - de la Fuente Castillo, Víctor
AU  - Díaz-Álvarez, Alberto
AU  - Manso-Callejo, Miguel-Ángel
AU  - Serradilla García, Francisco
TI  - Grammar Guided Genetic Programming for Network Architecture Search and Road Detection on Aerial Orthophotography
T2  - Applied Sciences

PY  - 2020
VL  - 10
IS  - 11
SN  - 2076-3417

AB  - Photogrammetry involves aerial photography of the Earth&rsquo;s surface and subsequently processing the images to provide a more accurate depiction of the area (Orthophotography). It is used by the Spanish Instituto Geogr&aacute;fico Nacional to update road cartography but requires a significant amount of manual labor due to the need to perform visual inspection of all tiled images. Deep learning techniques (artificial neural networks with more than one hidden layer) can perform road detection but it is still unclear how to find the optimal network architecture. Our main goal is the automatic design of deep neural network architectures with grammar-guided genetic programming. In this kind of evolutive algorithm, all the population individuals (here candidate network architectures) are constrained to rules specified by a grammar that defines valid and useful structural patterns to guide the search process. Grammar used includes well-known complex structures (e.g., Inception-like modules) combined with a custom designed mutation operator (dynamically links the mutation probability to structural diversity). Pilot results show that the system is able to design models for road detection that obtain test accuracies similar to that reached by state-of-the-art models when evaluated over a dataset from the Spanish National Aerial Orthophotography Plan.
KW  - grammar evolution
KW  - deep learning
KW  - network architecture search
KW  - grammar-guided genetic programming
DO  - 10.3390/app10113953
ER  -

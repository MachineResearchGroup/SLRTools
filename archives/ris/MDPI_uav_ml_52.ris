TY  - EJOU
AU  - Xie, Xuelin
AU  - Shen, Jingfang
TI  - Waterlogging Resistance Evaluation Index and Photosynthesis Characteristics Selection: Using Machine Learning Methods to Judge Poplar’s Waterlogging Resistance
T2  - Mathematics

PY  - 2021
VL  - 9
IS  - 13
SN  - 2227-7390

AB  - Flood disasters are the major natural disaster that affects the growth of agriculture and forestry crops. Due to rapid growth and strong waterlogging resistance characteristics, many studies have explained the waterlogging resistance mechanism of poplar from different perspectives. However, there is no accurate method to define the evaluation index of waterlogging resistance. In addition, there is also a lack of research on predicting the waterlogging resistance of poplars. Based on the changes of poplar biomass and seedling height, the evaluation index of poplar resistance to waterlogging was well determined, and the characteristics of photosynthesis were used to predict the waterlogging resistance of poplars. First, four methods of hierarchical clustering, lasso, stepwise regression and all-subsets regression were used to extract the photosynthesis characteristics. After that, the support vector regression model of poplar resistance to waterlogging was established by using the characteristic parameters of photosynthesis. Finally, the results show that the SVR model based on Stepwise regression and Lasso method has high precision. On the test set, the coefficient of determination (R2) was 0.8581 and 0.8492, the mean square error (MSE) was 0.0104 and 0.0341, and the mean relative error (MRE) was 9.78% and 9.85%, respectively. Therefore, using the characteristic parameters of photosynthesis to predict the waterlogging resistance of poplars is feasible.
KW  - flood disasters
KW  - waterlogging stress
KW  - waterlogging resistance index
KW  - feature extraction
KW  - SVR model
DO  - 10.3390/math9131542
ER  -
TY  - EJOU
AU  - Kaczorowska, Monika
AU  - Karczmarek, Paweł
AU  - Plechawska-Wójcik, Małgorzata
AU  - Tokovarov, Mikhail
TI  - On the Improvement of Eye Tracking-Based Cognitive Workload Estimation Using Aggregation Functions
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 13
SN  - 1424-8220

AB  - Cognitive workload, being a quantitative measure of mental effort, draws significant interest of researchers, as it allows to monitor the state of mental fatigue. Estimation of cognitive workload becomes especially important for job positions requiring outstanding engagement and responsibility, e.g., air-traffic dispatchers, pilots, car or train drivers. Cognitive workload estimation finds its applications also in the field of education material preparation. It allows to monitor the difficulty degree for specific tasks enabling to adjust the level of education materials to typical abilities of students. In this study, we present the results of research conducted with the goal of examining the influence of various fuzzy or non-fuzzy aggregation functions upon the quality of cognitive workload estimation. Various classic machine learning models were successfully applied to the problem. The results of extensive in-depth experiments with over 2000 aggregation operators shows the applicability of the approach based on the aggregation functions. Moreover, the approach based on aggregation process allows for further improvement of classification results. A wide range of aggregation functions is considered and the results suggest that the combination of classical machine learning models and aggregation methods allows to achieve high quality of cognitive workload level recognition preserving low computational cost.
KW  - aggregation
KW  - generalized Choquet integral
KW  - fuzzy measure
KW  - classical machine learning
KW  - cognitive workload
DO  - 10.3390/s21134542
ER  -
TY  - EJOU
AU  - Li, Xiaohui
AU  - Savkin, Andrey V.
TI  - Networked Unmanned Aerial Vehicles for Surveillance and Monitoring: A Survey
T2  - Future Internet

PY  - 2021
VL  - 13
IS  - 7
SN  - 1999-5903

AB  - As a typical cyber-physical system, networked unmanned aerial vehicles (UAVs) have received much attention in recent years. Emerging communication technologies and high-performance control methods enable networked UAVs to operate as aerial sensor networks to collect more complete and consistent information with significantly improved mobility and flexibility than traditional sensing platforms. One of the main applications of networked UAVs is surveillance and monitoring, which constitute essential components of a well-functioning public safety system and many industrial applications. Although the existing literature on surveillance and monitoring UAVs is extensive, a comprehensive survey on this topic is lacking. This article classifies publications on networked UAVs for surveillance and monitoring using the targets of interest and analyzes several typical problems on this topic, including the control, navigation, and deployment optimization of UAVs. The related research gaps and future directions are also presented.
KW  - cyber-physical systems
KW  - unmanned aerial vehicles (UAVs)
KW  - drones
KW  - autonomous systems
KW  - navigation
KW  - deployment
KW  - control
KW  - surveillance
KW  - monitoring
KW  - wildlife monitoring
DO  - 10.3390/fi13070174
ER  -
TY  - EJOU
AU  - Mohan, Midhun
AU  - Richardson, Gabriella
AU  - Gopan, Gopika
AU  - Aghai, Matthew M.
AU  - Bajaj, Shaurya
AU  - Galgamuwa, G. A. Pabodha
AU  - Vastaranta, Mikko
AU  - Arachchige, Pavithra S. Pitumpe
AU  - Amorós, Lot
AU  - Corte, Ana P.
AU  - de-Miguel, Sergio
AU  - Leite, Rodrigo V.
AU  - Kganyago, Mahlatse
AU  - Broadbent, Eben N.
AU  - Doaemo, Willie
AU  - Shorab, Mohammed A.
AU  - Cardil, Adrian
TI  - UAV-Supported Forest Regeneration: Current Trends, Challenges and Implications
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - Replanting trees helps with avoiding desertification, reducing the chances of soil erosion and flooding, minimizing the risks of zoonotic disease outbreaks, and providing ecosystem services and livelihood to the indigenous people, in addition to sequestering carbon dioxide for mitigating climate change. Consequently, it is important to explore new methods and technologies that are aiming to upscale and fast-track afforestation and reforestation (A/R) endeavors, given that many of the current tree planting strategies are not cost effective over large landscapes, and suffer from constraints associated with time, energy, manpower, and nursery-based seedling production. UAV (unmanned aerial vehicle)-supported seed sowing (UAVsSS) can promote rapid A/R in a safe, cost-effective, fast and environmentally friendly manner, if performed correctly, even in otherwise unsafe and/or inaccessible terrains, supplementing the overall manual planting efforts globally. In this study, we reviewed the recent literature on UAVsSS, to analyze the current status of the technology. Primary UAVsSS applications were found to be in areas of post-wildfire reforestation, mangrove restoration, forest restoration after degradation, weed eradication, and desert greening. Nonetheless, low survival rates of the seeds, future forest diversity, weather limitations, financial constraints, and seed-firing accuracy concerns were determined as major challenges to operationalization. Based on our literature survey and qualitative analysis, twelve recommendations—ranging from the need for publishing germination results to linking UAVsSS operations with carbon offset markets—are provided for the advancement of UAVsSS applications.
KW  - planting trees with drones
KW  - seed pods
KW  - unmanned aerial system (UAS)
KW  - seed spraying drones
KW  - forestry applications of UAVs
KW  - afforestation and reforestation using UAVs
DO  - 10.3390/rs13132596
ER  -
TY  - EJOU
AU  - Bahrami, Hazhir
AU  - Homayouni, Saeid
AU  - Safari, Abdolreza
AU  - Mirzaei, Sayeh
AU  - Mahdianpari, Masoud
AU  - Reisi-Gahrouei, Omid
TI  - Deep Learning-Based Estimation of Crop Biophysical Parameters Using Multi-Source and Multi-Temporal Remote Sensing Observations
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 7
SN  - 2073-4395

AB  - Remote sensing data are considered as one of the primary data sources for precise agriculture. Several studies have demonstrated the excellent capability of radar and optical imagery for crop mapping and biophysical parameter estimation. This paper aims at modeling the crop biophysical parameters, e.g., Leaf Area Index (LAI) and biomass, using a combination of radar and optical Earth observations. We extracted several radar features from polarimetric Synthetic Aperture Radar (SAR) data and Vegetation Indices (VIs) from optical images to model crops’ LAI and dry biomass. Then, the mutual correlations between these features and Random Forest feature importance were calculated. We considered two scenarios to estimate crop parameters. First, Machine Learning (ML) algorithms, e.g., Support Vector Regression (SVR), Random Forest (RF), Gradient Boosting (GB), and Extreme Gradient Boosting (XGB), were utilized to estimate two crop biophysical parameters. To this end, crops’ dry biomass and LAI were estimated using three input data; (1) SAR polarimetric features; (2) spectral VIs; (3) integrating both SAR and optical features. Second, a deep artificial neural network was created. These input data were fed to the mentioned algorithms and evaluated using the in-situ measurements. These observations of three cash crops, including soybean, corn, and canola, have been collected over Manitoba, Canada, during the Soil Moisture Active Validation Experimental 2012 (SMAPVEX-12) campaign. The results showed that GB and XGB have great potential in parameter estimation and remarkably improved accuracy. Our results also demonstrated a significant improvement in the dry biomass and LAI estimation compared to the previous studies. For LAI, the validation Root Mean Square Error (RMSE) was reported as 0.557 m2/m2 for canola using GB, and 0.298 m2/m2 for corn using GB, 0.233 m2/m2 for soybean using XGB. RMSE was reported for dry biomass as 26.29 g/m2 for canola utilizing SVR, 57.97 g/m2 for corn using RF, and 5.00 g/m2 for soybean using GB. The results revealed that the deep artificial neural network had a better potential to estimate crop parameters than the ML algorithms.
KW  - crop biomass
KW  - Leaf Area Index
KW  - Earth observations
KW  - Synthetic Aperture Radar
KW  - optical images
KW  - machine learning algorithms
KW  - SMAPVEX-12
DO  - 10.3390/agronomy11071363
ER  -
TY  - EJOU
AU  - Moura, Marks M.
AU  - de Oliveira, Luiz E.
AU  - Sanquetta, Carlos R.
AU  - Bastos, Alexis
AU  - Mohan, Midhun
AU  - Corte, Ana P.
TI  - Towards Amazon Forest Restoration: Automatic Detection of Species from UAV Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - Precise assessments of forest species’ composition help analyze biodiversity patterns, estimate wood stocks, and improve carbon stock estimates. Therefore, the objective of this work was to evaluate the use of high-resolution images obtained from Unmanned Aerial Vehicle (UAV) for the identification of forest species in areas of forest regeneration in the Amazon. For this purpose, convolutional neural networks (CNN) were trained using the Keras–Tensorflow package with the faster_rcnn_inception_v2_pets model. Samples of six forest species were used to train CNN. From these, attempts were made with the number of thresholds, which is the cutoff value of the function; any value below this output is considered 0, and values above are treated as an output 1; that is, values above the value stipulated in the Threshold are considered as identified species. The results showed that the reduction in the threshold decreases the accuracy of identification, as well as the overlap of the polygons of species identification. However, in comparison with the data collected in the field, it was observed that there exists a high correlation between the trees identified by the CNN and those observed in the plots. The statistical metrics used to validate the classification results showed that CNN are able to identify species with accuracy above 90%. Based on our results, which demonstrate good accuracy and precision in the identification of species, we conclude that convolutional neural networks are an effective tool in classifying objects from UAV images.
KW  - deep learning
KW  - drone
KW  - forest identification
KW  - unmanned aerial vehicles
DO  - 10.3390/rs13132627
ER  -
TY  - EJOU
AU  - Grybas, Heather
AU  - Congalton, Russell G.
TI  - A Comparison of Multi-Temporal RGB and Multispectral UAS Imagery for Tree Species Classification in Heterogeneous New Hampshire Forests
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 13
SN  - 2072-4292

AB  - Unmanned aerial systems (UASs) have recently become an affordable means to map forests at the species level, but research into the performance of different classification methodologies and sensors is necessary so users can make informed choices that maximize accuracy. This study investigated whether multi-temporal UAS data improved the classified accuracy of 14 species examined the optimal time-window for data collection, and compared the performance of a consumer-grade RGB sensor to that of a multispectral sensor. A time series of UAS data was collected from early spring to mid-summer and a sequence of mono-temporal and multi-temporal classifications were carried out. Kappa comparisons were conducted to ascertain whether the multi-temporal classifications significantly improved accuracy and whether there were significant differences between the RGB and multispectral classifications. The multi-temporal classification approach significantly improved accuracy; however, there was no significant benefit when more than three dates were used. Mid- to late spring imagery produced the highest accuracies, potentially due to high spectral heterogeneity between species and homogeneity within species during this time. The RGB sensor exhibited significantly higher accuracies, probably due to the blue band, which was found to be very important for classification accuracy and lacking in the multispectral sensor employed here.
KW  - remote sensing
KW  - forests
KW  - New Hampshire
KW  - UAS
KW  - multi-temporal
KW  - species level
KW  - OBIA
DO  - 10.3390/rs13132631
ER  -
TY  - EJOU
AU  - Wang, Hao
AU  - Ren, Yaxin
AU  - Meng, Zhijun
TI  - A Farm Management Information System for Semi-Supervised Path Planning and Autonomous Vehicle Control
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 13
SN  - 2071-1050

AB  - This paper presents a farm management information system targeting improvements in the ease of use and sustainability of robot farming systems. The system integrates the functionalities of field survey, path planning, monitoring, and controlling agricultural vehicles in real time. Firstly, a Grabcut-based semi-supervised field registration method is proposed for arable field detection from the orthoimage taken by the drone with an RGB camera. It partitions a complex field into simple geometric entities with simple user interaction. The average Mean Intersection over Union is about 0.95 when the field size ranges from 2.74 ha to 5.06 ha. In addition, a desktop software and a web application are developed as the entity of an FMIS. Compared to existing FMISs, this system provides more advanced features in robot farming, while providing simpler user interaction and better results. It allows clients to invoke web services and receive responses independent of programming language and platforms. Moreover, the system is compatible with other services, users, and devices following the open-source access protocol. We have evaluated the system by controlling 5 robot tractors with a 2 Hz communication frequency. The communication protocols will be publicly available to protentional users.
KW  - smart agriculture
KW  - image segmentation
KW  - agricultural robot
KW  - field registration
DO  - 10.3390/su13137497
ER  -
TY  - EJOU
AU  - Cichowicz, Robert
AU  - Dobrzański, Maciej
TI  - 3D Spatial Analysis of Particulate Matter (PM10, PM2.5 and PM1.0) and Gaseous Pollutants (H2S, SO2 and VOC) in Urban Areas Surrounding a Large Heat and Power Plant
T2  - Energies

PY  - 2021
VL  - 14
IS  - 14
SN  - 1996-1073

AB  - In many regions of the world, the winter period is a time of poor air quality, due primarily to the increased use of individual and district heating systems. As a consequence, the atmospheric air contains increased concentrations of both particulate matter and gaseous pollutants (as a result of “low” emissions at altitudes of up to 40 m and “high” emissions more than 40 m above ground level). In winter, the increased pollution is very often exacerbated by meteorological conditions, including air temperature, pressure, air speed, wind direction, and thermal inversion. Here, we analyze the concentrations of particulate matter (PM10, PM2.5, and PM1.0) and gaseous pollutants (H2S, SO2, and VOC) in the immediate vicinity of a large solid fuel-fired heat and power plant located in an urban agglomeration. Two locations were selected for analysis. The first was close to an air quality measurement station in the center of a multi-family housing estate. The second was the intersection of two main communication routes. To determine the impact of “low” and “high” emissions on air quality, the selected pollutants were measured at heights of between 2 and 50 m using an unmanned aerial vehicle. The results were compared with permissible standards for the concentration of pollutants. Temperature inversion was found to have a strong influence on the level of pollutants at various heights, with higher concentrations of particulate matter registered at altitudes above 40 m. The source of PM, H2S, and SO2 pollutants was confirmed to be “low emission” from local transport, industrial plant areas, and the housing estate comprising detached houses located in the vicinity of the measuring points. “High emission” was found to be responsible for the high concentrations of VOC at altitudes of more than 40 m above the intersection and in the area of the housing estate.
KW  - air quality monitoring
KW  - SO2
KW  - VOC
KW  - H2S
KW  - PM10
KW  - PM2.5
KW  - PM1.0
KW  - outdoor air quality
KW  - air flow aerodynamics
KW  - street canyon
DO  - 10.3390/en14144070
ER  -
TY  - EJOU
AU  - Munawar, Hafiz S.
AU  - Ullah, Fahim
AU  - Qayyum, Siddra
AU  - Khan, Sara I.
AU  - Mojtahedi, Mohammad
TI  - UAVs in Disaster Management: Application of Integrated Aerial Imagery and Convolutional Neural Network for Flood Detection
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 14
SN  - 2071-1050

AB  - Floods have been a major cause of destruction, instigating fatalities and massive damage to the infrastructure and overall economy of the affected country. Flood-related devastation results in the loss of homes, buildings, and critical infrastructure, leaving no means of communication or travel for the people stuck in such disasters. Thus, it is essential to develop systems that can detect floods in a region to provide timely aid and relief to stranded people, save their livelihoods, homes, and buildings, and protect key city infrastructure. Flood prediction and warning systems have been implemented in developed countries, but the manufacturing cost of such systems is too high for developing countries. Remote sensing, satellite imagery, global positioning system, and geographical information systems are currently used for flood detection to assess the flood-related damages. These techniques use neural networks, machine learning, or deep learning methods. However, unmanned aerial vehicles (UAVs) coupled with convolution neural networks have not been explored in these contexts to instigate a swift disaster management response to minimize damage to infrastructure. Accordingly, this paper uses UAV-based aerial imagery as a flood detection method based on Convolutional Neural Network (CNN) to extract flood-related features from the images of the disaster zone. This method is effective in assessing the damage to local infrastructures in the disaster zones. The study area is based on a flood-prone region of the Indus River in Pakistan, where both pre-and post-disaster images are collected through UAVs. For the training phase, 2150 image patches are created by resizing and cropping the source images. These patches in the training dataset train the CNN model to detect and extract the regions where a flood-related change has occurred. The model is tested against both pre-and post-disaster images to validate it, which has positive flood detection results with an accuracy of 91%. Disaster management organizations can use this model to assess the damages to critical city infrastructure and other assets worldwide to instigate proper disaster responses and minimize the damages. This can help with the smart governance of the cities where all emergent disasters are addressed promptly.
KW  - convolutional neural network (CNN)
KW  - disaster management
KW  - aerial imagery
KW  - flood detection
KW  - unmanned aerial vehicles (UAVs)
DO  - 10.3390/su13147547
ER  -
TY  - EJOU
AU  - Jadoun, Vinay K.
AU  - Sharma, Nipun
AU  - Jha, Piyush
AU  - S., Jayalakshmi N.
AU  - Malik, Hasmat
AU  - Garcia Márquez, Fausto P.
TI  - Optimal Scheduling of Dynamic Pricing Based V2G and G2V Operation in Microgrid Using Improved Elephant Herding Optimization
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 14
SN  - 2071-1050

AB  - The unpredictable nature of the loads and non-linearity of the components of microgrid systems make optimal scheduling more complex. In this paper, a deterministic optimal load-scheduling problem is developed for microgrids operating in both islanding and grid-connected mode under different energy scenarios. Various cases are considered in this research, based on the interaction and dynamic behavior of the microgrid, considering electric vehicles (EVs) in the scenario. The aim of this research is to minimize the overall cost of microgrid operations. The concept of dynamic pricing has also been introduced in order to optimize the energy cost for the consumers. For ensuring the stability of the microgrids, a load variance index has been considered, and the fuzzy-based approach has been used for cost and load variance minimization to reduce the operation cost without compromising the stability of the microgrid. The grid-to-vehicle (G2V) and vehicle-to-grid (V2G) operations of EVs are integrated into the microgrid, which would help in valley filling and peak shaving of the loads during the off-peak and peak hours, respectively. In order to solve the proposed complex combinatorial optimization problem, elephant herding optimization (EHO) is modified and implemented. The performance of the proposed improved EHO (IEHO) is first tested on the latest CEC test functions. The results obtained by IEHO after 100 different trials are compared with the latest published methods and are found to be better based on the average value and the standard deviation for different CEC test functions. In addition, the simulation results obtained by particle swarm optimization (PSO), EHO, and proposed IEHO on a microgrid test system for different scenarios with all cases reveal that the proposed model with a mix of energy resources in the dynamic load dispatch environment bring the maximum benefits of microgrid systems. Furthermore, the results obtained from the simulation verifies that if free trade of power is allowed between the microgrids and the main grid, the process of power generation can be more economical, and further introduction of dynamic pricing into the scenario proves to be even cheaper. The implementation of the G2V and V2G operations of EVs operations in the proposed scenario not only helped in cost minimization but also helped in stabilizing the grid.
KW  - microgrid
KW  - optimal scheduling
KW  - dynamic pricing
KW  - load variance
KW  - electric vehicles
KW  - elephant herding optimization
DO  - 10.3390/su13147551
ER  -
TY  - EJOU
AU  - Jozdani, Shahab
AU  - Chen, Dongmei
AU  - Chen, Wenjun
AU  - Leblanc, Sylvain G.
AU  - Prévost, Christian
AU  - Lovitt, Julie
AU  - He, Liming
AU  - Johnson, Brian A.
TI  - Leveraging Deep Neural Networks to Map Caribou Lichen in High-Resolution Satellite Images Based on a Small-Scale, Noisy UAV-Derived Map
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - Lichen is an important food source for caribou in Canada. Lichen mapping using remote sensing (RS) images could be a challenging task, however, as lichens generally appear in unevenly distributed, small patches, and could resemble surficial features. Moreover, collecting lichen labeled data (reference data) is expensive, which restricts the application of many robust supervised classification models that generally demand a large quantity of labeled data. The goal of this study was to investigate the potential of using a very-high-spatial resolution (1-cm) lichen map of a small sample site (e.g., generated based on a single UAV scene and using field data) to train a subsequent classifier to map caribou lichen over a much larger area (~0.04 km2 vs. ~195 km2) and a lower spatial resolution image (in this case, a 50-cm WorldView-2 image). The limited labeled data from the sample site were also partially noisy due to spatial and temporal mismatching issues. For this, we deployed a recently proposed Teacher-Student semi-supervised learning (SSL) approach (based on U-Net and U-Net++ networks) involving unlabeled data to assist with improving the model performance. Our experiments showed that it was possible to scale-up the UAV-derived lichen map to the WorldView-2 scale with reasonable accuracy (overall accuracy of 85.28% and F1-socre of 84.38%) without collecting any samples directly in the WorldView-2 scene. We also found that our noisy labels were partially beneficial to the SSL robustness because they improved the false positive rate compared to the use of a cleaner training set directly collected within the same area in the WorldView-2 image. As a result, this research opens new insights into how current very high-resolution, small-scale caribou lichen maps can be used for generating more accurate large-scale caribou lichen maps from high-resolution satellite imagery.
KW  - remote sensing
KW  - lichen mapping
KW  - deep learning
KW  - semi-supervised learning
KW  - teacher-student learning
KW  - WorldView-2
KW  - unmanned aerial vehicle
DO  - 10.3390/rs13142658
ER  -
TY  - EJOU
AU  - Liu, Wen-Cheng
AU  - Lu, Chien-Hsing
AU  - Huang, Wei-Che
TI  - Large-Scale Particle Image Velocimetry to Measure Streamflow from Videos Recorded from Unmanned Aerial Vehicle and Fixed Imaging System
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - The accuracy of river velocity measurements plays an important role in the effective management of water resources. Various methods have been developed to measure river velocity. Currently, image-based techniques provide a promising approach to avoid physical contact with targeted water bodies by researchers. In this study, measured surface velocities collected under low flow and high flow conditions in the Houlong River, Taiwan, using large-scale particle image velocimetry (LSPIV) captured by an unmanned aerial vehicle (UAV) and a terrestrial fixed station were analyzed and compared. Under low flow conditions, the mean absolute errors of the measured surface velocities using LSPIV from a UAV with shooting heights of 9, 12, and 15 m fell within 0.055 ± 0.015 m/s, which was lower than that obtained using LSPIV on video recorded from a terrestrial fixed station (i.e., 0.34 m/s). The mean absolute errors obtained using LSPIV derived from UAV aerial photography at a flight height of 12 m without seeding particles and with different seeding particle densities were slightly different, and fell within the range of 0.095 ± 0.025 m/s. Under high flow conditions, the mean absolute errors associated with using LSPIV derived from terrestrial fixed photography and LSPIV derived from a UAV with flight heights of 32, 62, and 112 m were 0.46 m/s and 0.49 m/s, 0.27 m, and 0.97 m/s, respectively. A UAV flight height of 62 m yielded the best measured surface velocity result. Moreover, we also demonstrated that the optimal appropriate interrogation area and image acquisition time interval using LSPIV with a UAV were 16 × 16 pixels and 1/8 s, respectively. These two parameters should be carefully adopted to accurately measure the surface velocity of rivers.
KW  - unmanned aerial vehicle (UAV)
KW  - LSPIV
KW  - flight height
KW  - seeding artificial particle
KW  - interrogation area
KW  - image acquisition time interval
DO  - 10.3390/rs13142661
ER  -
TY  - EJOU
AU  - Mirzazade, Ali
AU  - Popescu, Cosmin
AU  - Blanksvärd, Thomas
AU  - Täljsten, Björn
TI  - Workflow for Off-Site Bridge Inspection Using Automatic Damage Detection-Case Study of the Pahtajokk Bridge
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - For the inspection of structures, particularly bridges, it is becoming common to replace humans with autonomous systems that use unmanned aerial vehicles (UAV). In this paper, a framework for autonomous bridge inspection using a UAV is proposed with a four-step workflow: (a) data acquisition with an efficient UAV flight path, (b) computer vision comprising training, testing and validation of convolutional neural networks (ConvNets), (c) point cloud generation using intelligent hierarchical dense structure from motion (DSfM), and (d) damage quantification. This workflow starts with planning the most efficient flight path that allows for capturing of the minimum number of images required to achieve the maximum accuracy for the desired defect size, then followed by bridge and damage recognition. Three types of autonomous detection are used: masking the background of the images, detecting areas of potential damage, and pixel-wise damage segmentation. Detection of bridge components by masking extraneous parts of the image, such as vegetation, sky, roads or rivers, can improve the 3D reconstruction in the feature detection and matching stages. In addition, detecting damaged areas involves the UAV capturing close-range images of these critical regions, and damage segmentation facilitates damage quantification using 2D images. By application of DSfM, a denser and more accurate point cloud can be generated for these detected areas, and aligned to the overall point cloud to create a digital model of the bridge. Then, this generated point cloud is evaluated in terms of outlier noise, and surface deviation. Finally, damage that has been detected is quantified and verified, based on the point cloud generated using the Terrestrial Laser Scanning (TLS) method. The results indicate this workflow for autonomous bridge inspection has potential.
KW  - bridge inspection
KW  - computer vision
KW  - intelligent hierarchical DSfM
KW  - bridge 3D modeling
KW  - damage detection
KW  - damage segmentation
KW  - damage assessment
KW  - unmanned inspections
KW  - UAV
DO  - 10.3390/rs13142665
ER  -
TY  - EJOU
AU  - Łabędź, Piotr
AU  - Skabek, Krzysztof
AU  - Ozimek, Paweł
AU  - Nytko, Mateusz
TI  - Histogram Adjustment of Images for Improving Photogrammetric Reconstruction
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 14
SN  - 1424-8220

AB  - The accuracy of photogrammetric reconstruction depends largely on the acquisition conditions and on the quality of input photographs. This paper proposes methods of improving raster images that increase photogrammetric reconstruction accuracy. These methods are based on modifying color image histograms. Special emphasis was placed on the selection of channels of the RGB and CIE L*a*b* color models for further improvement of the reconstruction process. A methodology was proposed for assessing the quality of reconstruction based on premade reference models using positional statistics. The analysis of the influence of image enhancement on reconstruction was carried out for various types of objects. The proposed methods can significantly improve the quality of reconstruction. The superiority of methods based on the luminance channel of the L*a*b* model was demonstrated. Our studies indicated high efficiency of the histogram equalization method (HE), although these results were not highly distinctive for all performed tests.
KW  - photogrammetry
KW  - preprocessing
KW  - enhancement
KW  - point cloud
KW  - 3D reconstruction
KW  - image processing
KW  - image histogram
DO  - 10.3390/s21144654
ER  -
TY  - EJOU
AU  - Ge, Haixiao
AU  - Ma, Fei
AU  - Li, Zhenwang
AU  - Tan, Zhengzheng
AU  - Du, Changwen
TI  - Improved Accuracy of Phenological Detection in Rice Breeding by Using Ensemble Models of Machine Learning Based on UAV-RGB Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - Accurate and timely detection of phenology at plot scale in rice breeding trails is crucial for understanding the heterogeneity of varieties and guiding field management. Traditionally, remote sensing studies of phenology detection have heavily relied on the time-series vegetation index (VI) data. However, the methodology based on time-series VI data was often limited by the temporal resolution. In this study, three types of ensemble models including hard voting (majority voting), soft voting (weighted majority voting) and model stacking, were proposed to identify the principal phenological stages of rice based on unmanned aerial vehicle (UAV) RGB imagery. These ensemble models combined RGB-VIs, color space (e.g., RGB and HSV) and textures derived from UAV-RGB imagery, and five machine learning algorithms (random forest; k-nearest neighbors; Gaussian naïve Bayes; support vector machine and logistic regression) as base models to estimate phenological stages in rice breeding. The phenological estimation models were trained on the dataset of late-maturity cultivars and tested independently on the dataset of early-medium-maturity cultivars. The results indicated that all ensemble models outperform individual machine learning models in all datasets. The soft voting strategy provided the best performance for identifying phenology with the overall accuracy of 90% and 93%, and the mean F1-scores of 0.79 and 0.81, respectively, in calibration and validation datasets, which meant that the overall accuracy and mean F1-scores improved by 5% and 7%, respectively, in comparison with those of the best individual model (GNB), tested in this study. Therefore, the ensemble models demonstrated great potential in improving the accuracy of phenology detection in rice breeding.
KW  - UAV
KW  - machine learning
KW  - ensemble models
KW  - phenology
KW  - breeding
DO  - 10.3390/rs13142678
ER  -
TY  - EJOU
AU  - Herzig, Paul
AU  - Borrmann, Peter
AU  - Knauer, Uwe
AU  - Klück, Hans-Christian
AU  - Kilias, David
AU  - Seiffert, Udo
AU  - Pillen, Klaus
AU  - Maurer, Andreas
TI  - Evaluation of RGB and Multispectral Unmanned Aerial Vehicle (UAV) Imagery for High-Throughput Phenotyping and Yield Prediction in Barley Breeding
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - With advances in plant genomics, plant phenotyping has become a new bottleneck in plant breeding and the need for reliable high-throughput plant phenotyping techniques has emerged. In the face of future climatic challenges, it does not seem appropriate to continue to solely select for grain yield and a few agronomically important traits. Therefore, new sensor-based high-throughput phenotyping has been increasingly used in plant breeding research, with the potential to provide non-destructive, objective and continuous plant characterization that reveals the formation of the final grain yield and provides insights into the physiology of the plant during the growth phase. In this context, we present the comparison of two sensor systems, Red-Green-Blue (RGB) and multispectral cameras, attached to unmanned aerial vehicles (UAV), and investigate their suitability for yield prediction using different modelling approaches in a segregating barley introgression population at three environments with weekly data collection during the entire vegetation period. In addition to vegetation indices, morphological traits such as canopy height, vegetation cover and growth dynamics traits were used for yield prediction. Repeatability analyses and genotype association studies of sensor-based traits were compared with reference values from ground-based phenotyping to test the use of conventional and new traits for barley breeding. The relative height estimation of the canopy by UAV achieved high precision (up to r = 0.93) and repeatability (up to R2 = 0.98). In addition, we found a great overlap of detected significant genotypes between the reference heights and sensor-based heights. The yield prediction accuracy of both sensor systems was at the same level and reached a maximum prediction accuracy of r2 = 0.82 with a continuous increase in precision throughout the entire vegetation period. Due to the lower costs and the consumer-friendly handling of image acquisition and processing, the RGB imagery seems to be more suitable for yield prediction in this study.
KW  - barley (Hordeum vulgare ssp. vulgare)
KW  - remote sensing
KW  - unmanned aerial vehicle (UAV)
KW  - multi-spectral imagery
KW  - RGB imagery
KW  - crop height modelling
KW  - vegetation cover modelling
KW  - growth dynamics
KW  - yield prediction
KW  - genotype association study
DO  - 10.3390/rs13142670
ER  -
TY  - EJOU
AU  - Liu, Zhi
AU  - Yang, Shuyuan
AU  - Feng, Zhixi
AU  - Gao, Quanwei
AU  - Wang, Min
TI  - Fast SAR Autofocus Based on Ensemble Convolutional Extreme Learning Machine
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - Inaccurate Synthetic Aperture Radar (SAR) navigation information will lead to unknown phase errors in SAR data. Uncompensated phase errors can blur the SAR images. Autofocus is a technique that can automatically estimate phase errors from data. However, existing autofocus algorithms either have poor focusing quality or a slow focusing speed. In this paper, an ensemble learning-based autofocus method is proposed. Convolutional Extreme Learning Machine (CELM) is constructed and utilized to estimate the phase error. However, the performance of a single CELM is poor. To overcome this, a novel, metric-based combination strategy is proposed, combining multiple CELMs to further improve the estimation accuracy. The proposed model is trained with the classical bagging-based ensemble learning method. The training and testing process is non-iterative and fast. Experimental results conducted on real SAR data show that the proposed method has a good trade-off between focusing quality and speed.
KW  - synthetic aperture radar
KW  - autofocus
KW  - ensemble learning
KW  - extreme learning machine
KW  - convolutional neural network
DO  - 10.3390/rs13142683
ER  -
TY  - EJOU
AU  - Mhango, Joseph K.
AU  - Harris, Edwin W.
AU  - Green, Richard
AU  - Monaghan, James M.
TI  - Mapping Potato Plant Density Variation Using Aerial Imagery and Deep Learning Techniques for Precision Agriculture
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - In potato (Solanum tuberosum) production, the number of tubers harvested and their sizes are related to the plant population. Field maps of the spatial variation in plant density can therefore provide a decision support tool for spatially variable harvest timing to optimize tuber sizes by allowing densely populated management zones more tuber-bulking time. Computer vision has been proposed to enumerate plant numbers using images from unmanned aerial vehicles (UAV) but inaccurate predictions in images of merged canopies remains a challenge. Some research has been done on individual potato plant bounding box prediction but there is currently no information on the spatial structure of plant density that these models may reveal and its relationship with potato yield quality attributes. In this study, the Faster Region-based Convolutional Neural Network (FRCNN) framework was used to produce a plant detection model and estimate plant densities across a UAV orthomosaic. Using aerial images of 2 mm ground sampling distance (GSD) collected from potatoes at 40 days after planting, the FRCNN model was trained to an average precision (aP) of 0.78 on unseen testing data. The model was then used to generate predictions on quadrants imposed on orthorectified rasters captured at 14 and 18 days after emergence. After spatially interpolating the plant densities, the resultant surfaces were highly correlated to manually-determined plant density (R2 = 0.80). Further correlations were observed with tuber number (r = 0.54 at Butter Hill; r = 0.53 at Horse Foxhole), marketable tuber weight per plant (r = −0.57 at Buttery Hill; r = −0.56 at Horse Foxhole) and the normalized difference vegetation index (r = 0.61). These results show that accurate two-dimensional maps of plant density can be constructed from UAV imagery with high correlation to important yield components, despite the loss of accuracy of FRCNN models in partially merged canopies.
KW  - potatoes
KW  - UAV
KW  - deep learning
KW  - satellite
KW  - precision agriculture
DO  - 10.3390/rs13142705
ER  -
TY  - EJOU
AU  - Huang, Shenjin
AU  - Han, Wenting
AU  - Chen, Haipeng
AU  - Li, Guang
AU  - Tang, Jiandong
TI  - Recognizing Zucchinis Intercropped with Sunflowers in UAV Visible Images Using an Improved Method Based on OCRNet
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - An improved semantic segmentation method based on object contextual representations network (OCRNet) is proposed to accurately identify zucchinis intercropped with sunflowers from unmanned aerial vehicle (UAV) visible images taken over Hetao Irrigation District, Inner Mongolia, China. The proposed method improves on the performance of OCRNet in two respects. First, based on the object region context extraction structure of the OCRNet, a branch that uses the channel attention module was added in parallel to rationally use channel feature maps with different weights and reduce the noise of invalid channel features. Secondly, Lovász-Softmax loss was introduced to improve the accuracy of the object region representation in the OCRNet and optimize the final segmentation result at the object level. We compared the proposed method with extant advanced semantic segmentation methods (PSPNet, DeepLabV3+, DNLNet, and OCRNet) in two test areas to test its effectiveness. The results showed that the proposed method achieved the best semantic segmentation effect in the two test areas. More specifically, our method performed better in processing image details, segmenting field edges, and identifying intercropping fields. The proposed method has significant advantages for crop classification and intercropping recognition based on UAV visible images, and these advantages are more substantive in object-level evaluation metrics (mIoU and intercropping IoU).
KW  - intercropping identification
KW  - UAV remote sensing
KW  - semantic segmentation
KW  - OCRNet
DO  - 10.3390/rs13142706
ER  -
TY  - EJOU
AU  - Bui, Quang-Thanh
AU  - Chou, Tien-Yin
AU  - Hoang, Thanh-Van
AU  - Fang, Yao-Min
AU  - Mu, Ching-Yun
AU  - Huang, Pi-Hui
AU  - Pham, Vu-Dong
AU  - Nguyen, Quoc-Huy
AU  - Anh, Do T.
AU  - Pham, Van-Manh
AU  - Meadows, Michael E.
TI  - Gradient Boosting Machine and Object-Based CNN for Land Cover Classification
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - In regular convolutional neural networks (CNN), fully-connected layers act as classifiers to estimate the probabilities for each instance in classification tasks. The accuracy of CNNs can be improved by replacing fully connected layers with gradient boosting algorithms. In this regard, this study investigates three robust classifiers, namely XGBoost, LightGBM, and Catboost, in combination with a CNN for a land cover study in Hanoi, Vietnam. The experiments were implemented using SPOT7 imagery through (1) image segmentation and extraction of features, including spectral information and spatial metrics, (2) normalization of attribute values and generation of graphs, and (3) using graphs as the input dataset to the investigated models for classifying six land cover classes, namely House, Bare land, Vegetation, Water, Impervious Surface, and Shadow. The results show that CNN-based XGBoost (Overall accuracy = 0.8905), LightGBM (0.8956), and CatBoost (0.8956) outperform the other methods used for comparison. It can be seen that the combination of object-based image analysis and CNN-based gradient boosting algorithms significantly improves classification accuracies and can be considered as alternative methods for land cover analysis.
KW  - object-based image analysis
KW  - gradient boosting
KW  - convolutional neural network
KW  - land cover
DO  - 10.3390/rs13142709
ER  -
TY  - EJOU
AU  - Li, Guang
AU  - Han, Wenting
AU  - Huang, Shenjin
AU  - Ma, Weitong
AU  - Ma, Qian
AU  - Cui, Xin
TI  - Extraction of Sunflower Lodging Information Based on UAV Multi-Spectral Remote Sensing and Deep Learning
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - The rapid and accurate identification of sunflower lodging is important for the assessment of damage to sunflower crops. To develop a fast and accurate method of extraction of information on sunflower lodging, this study improves the inputs to SegNet and U-Net to render them suitable for multi-band image processing. Random forest and two improved deep learning methods are combined with RGB, RGB + NIR, RGB + red-edge, and RGB + NIR + red-edge bands of multi-spectral images captured by a UAV (unmanned aerial vehicle) to construct 12 models to extract information on sunflower lodging. These models are then combined with the method used to ignore edge-related information to predict sunflower lodging. The results of experiments show that the deep learning methods were superior to the random forest method in terms of the obtained lodging information and accuracy. The predictive accuracy of the model constructed by using a combination of SegNet and RGB + NIR had the highest overall accuracy of 88.23%. Adding NIR to RGB improved the accuracy of extraction of the lodging information whereas adding red-edge reduced it. An overlay analysis of the results for the lodging area shows that the extraction error was mainly caused by the failure of the model to recognize lodging in mixed areas and low-coverage areas. The predictive accuracy of information on sunflower lodging when edge-related information was ignored was about 2% higher than that obtained by using the direct splicing method.
KW  - sunflower lodging
KW  - deep learning
KW  - multispectral remote sensing
KW  - UAV (unmanned aerial vehicle)
DO  - 10.3390/rs13142721
ER  -
TY  - EJOU
AU  - Abdollahi, Abolfazl
AU  - Pradhan, Biswajeet
TI  - Urban Vegetation Mapping from Aerial Imagery Using Explainable AI (XAI)
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 14
SN  - 1424-8220

AB  - Urban vegetation mapping is critical in many applications, i.e., preserving biodiversity, maintaining ecological balance, and minimizing the urban heat island effect. It is still challenging to extract accurate vegetation covers from aerial imagery using traditional classification approaches, because urban vegetation categories have complex spatial structures and similar spectral properties. Deep neural networks (DNNs) have shown a significant improvement in remote sensing image classification outcomes during the last few years. These methods are promising in this domain, yet unreliable for various reasons, such as the use of irrelevant descriptor features in the building of the models and lack of quality in the labeled image. Explainable AI (XAI) can help us gain insight into these limits and, as a result, adjust the training dataset and model as needed. Thus, in this work, we explain how an explanation model called Shapley additive explanations (SHAP) can be utilized for interpreting the output of the DNN model that is designed for classifying vegetation covers. We want to not only produce high-quality vegetation maps, but also rank the input parameters and select appropriate features for classification. Therefore, we test our method on vegetation mapping from aerial imagery based on spectral and textural features. Texture features can help overcome the limitations of poor spectral resolution in aerial imagery for vegetation mapping. The model was capable of obtaining an overall accuracy (OA) of 94.44% for vegetation cover mapping. The conclusions derived from SHAP plots demonstrate the high contribution of features, such as Hue, Brightness, GLCM_Dissimilarity, GLCM_Homogeneity, and GLCM_Mean to the output of the proposed model for vegetation mapping. Therefore, the study indicates that existing vegetation mapping strategies based only on spectral characteristics are insufficient to appropriately classify vegetation covers.
KW  - XAI
KW  - deep neural network
KW  - remote sensing
KW  - SHAP
KW  - vegetation mapping
DO  - 10.3390/s21144738
ER  -
TY  - EJOU
AU  - Anderson, Nicholas T.
AU  - Walsh, Kerry B.
AU  - Wulfsohn, Dvoralai
TI  - Technologies for Forecasting Tree Fruit Load and Harvest Timing—From Ground, Sky and Time
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 7
SN  - 2073-4395

AB  - The management and marketing of fruit requires data on expected numbers, size, quality and timing. Current practice estimates orchard fruit load based on the qualitative assessment of fruit number per tree and historical orchard yield, or manually counting a subsample of trees. This review considers technological aids assisting these estimates, in terms of: (i) improving sampling strategies by the number of units to be counted and their selection; (ii) machine vision for the direct measurement of fruit number and size on the canopy; (iii) aerial or satellite imagery for the acquisition of information on tree structural parameters and spectral indices, with the indirect assessment of fruit load; (iv) models extrapolating historical yield data with knowledge of tree management and climate parameters, and (v) technologies relevant to the estimation of harvest timing such as heat units and the proximal sensing of fruit maturity attributes. Machine vision is currently dominating research outputs on fruit load estimation, while the improvement of sampling strategies has potential for a widespread impact. Techniques based on tree parameters and modeling offer scalability, but tree crops are complicated (perennialism). The use of machine vision for flowering estimates, fruit sizing, external quality evaluation is also considered. The potential synergies between technologies are highlighted.
KW  - yield
KW  - estimation
KW  - machine vision
KW  - remote sensing
KW  - correlative
KW  - models
KW  - fruit
KW  - tree
KW  - review
DO  - 10.3390/agronomy11071409
ER  -
TY  - EJOU
AU  - Lai, Zhengchao
AU  - Liu, Fei
AU  - Guo, Shangwei
AU  - Meng, Xiantong
AU  - Han, Shaokun
AU  - Li, Wenhao
TI  - Onboard Real-Time Dense Reconstruction in Large Terrain Scene Using Embedded UAV Platform
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - Using unmanned aerial vehicles (UAVs) for remote sensing has the advantages of high flexibility, convenient operation, low cost, and wide application range. It fills the need for rapid acquisition of high-resolution aerial images in modern photogrammetry applications. Due to the insufficient parallaxes and the computation-intensive process, dense real-time reconstruction for large terrain scenes is a considerable challenge. To address these problems, we proposed a novel SLAM-based MVS (Multi-View-Stereo) approach, which can incrementally generate a dense 3D (three-dimensional) model of the terrain by using the continuous image stream during the flight. The pipeline of the proposed methodology starts with pose estimation based on SLAM algorithm. The tracked frames were then selected by a novel scene-adaptive keyframe selection method to construct a sliding window frame-set. This was followed by depth estimation using a flexible search domain approach, which can improve accuracy without increasing the iterate time or memory consumption. The whole system proposed in this study was implemented on the embedded GPU based on an UAV platform. We proposed a highly parallel and memory-efficient CUDA-based depth computing architecture, enabling the system to achieve good real-time performance. The evaluation experiments were carried out in both simulation and real-world environments. A virtual large terrain scene was built using the Gazebo simulator. The simulated UAV equipped with an RGB-D camera was used to obtain synthetic evaluation datasets, which were divided by flight altitudes (800-, 1000-, 1200 m) and terrain height difference (100-, 200-, 300 m). In addition, the system has been extensively tested on various types of real scenes. Comparison with commercial 3D reconstruction software is carried out to evaluate the precision in real-world data. According to the results on the synthetic datasets, over 93.462% of the estimation with absolute error distance of less then 0.9%. In the real-world dataset captured at 800 m flight height, more than 81.27% of our estimated point cloud are less then 5 m difference with the results of Photoscan. All evaluation experiments show that the proposed approach outperforms the state-of-the-art ones in terms of accuracy and efficiency.
KW  - UAV
KW  - SLAM
KW  - MVS
KW  - real-time 3D reconstruction
KW  - embedded GPU
KW  - CUDA
KW  - Gazebo simulator
DO  - 10.3390/rs13142778
ER  -
TY  - EJOU
AU  - Gibril, Mohamed Barakat A.
AU  - Shafri, Helmi Z.
AU  - Shanableh, Abdallah
AU  - Al-Ruzouq, Rami
AU  - Wayayok, Aimrun
AU  - Hashim, Shaiful J.
TI  - Deep Convolutional Neural Network for Large-Scale Date Palm Tree Mapping from UAV-Based Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - Large-scale mapping of date palm trees is vital for their consistent monitoring and sustainable management, considering their substantial commercial, environmental, and cultural value. This study presents an automatic approach for the large-scale mapping of date palm trees from very-high-spatial-resolution (VHSR) unmanned aerial vehicle (UAV) datasets, based on a deep learning approach. A U-Shape convolutional neural network (U-Net), based on a deep residual learning framework, was developed for the semantic segmentation of date palm trees. A comprehensive set of labeled data was established to enable the training and evaluation of the proposed segmentation model and increase its generalization capability. The performance of the proposed approach was compared with those of various state-of-the-art fully convolutional networks (FCNs) with different encoder architectures, including U-Net (based on VGG-16 backbone), pyramid scene parsing network, and two variants of DeepLab V3+. Experimental results showed that the proposed model outperformed other FCNs in the validation and testing datasets. The generalizability evaluation of the proposed approach on a comprehensive and complex testing dataset exhibited higher classification accuracy and showed that date palm trees could be automatically mapped from VHSR UAV images with an F-score, mean intersection over union, precision, and recall of 91%, 85%, 0.91, and 0.92, respectively. The proposed approach provides an efficient deep learning architecture for the automatic mapping of date palm trees from VHSR UAV-based images.
KW  - date palm trees
KW  - tree species classification
KW  - semantic segmentation
KW  - fully convolutional neural networks
KW  - unmanned aerial vehicle (UAV)
DO  - 10.3390/rs13142787
ER  -
TY  - EJOU
AU  - Munawar, Hafiz S.
AU  - Hammad, Ahmed W. A.
AU  - Waller, S. T.
AU  - Thaheem, Muhammad J.
AU  - Shrestha, Asheem
TI  - An Integrated Approach for Post-Disaster Flood Management Via the Use of Cutting-Edge Technologies and UAVs: A Review
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 14
SN  - 2071-1050

AB  - Rapid advances that improve flood management have facilitated the disaster response by providing first aid services, finding safe routes, maintaining communication and developing flood maps. Different technologies such as image processing, satellite imagery, synthetic imagery and integrated approaches have been extensively analysed in the literature for disaster operations. There is a need to review cutting-edge technologies for flood management. This paper presents a review of the latest advancements in the flood management domain based on image processing, artificial intelligence and integrated approaches with a focus on post-disaster. It answers the following research questions: (1) What are the latest developments in image processing for flood management in a post-disaster scenario? (2) What are the latest techniques for flood management based on artificial intelligence in a post-disaster scenario? (3) What are the existing gaps in the selected technologies for post-disaster? (4) How can the authorities improve the existing post-disaster management operation with cutting-edge technologies? A novel framework has been proposed to optimise flood management with the application of a holistic approach.
KW  - natural disaster
KW  - early warning system
KW  - artificial intelligence
KW  - image processing
DO  - 10.3390/su13147925
ER  -
TY  - EJOU
AU  - Li, Jingbo
AU  - Li, Changchun
AU  - Fei, Shuaipeng
AU  - Ma, Chunyan
AU  - Chen, Weinan
AU  - Ding, Fan
AU  - Wang, Yilin
AU  - Li, Yacong
AU  - Shi, Jinjin
AU  - Xiao, Zhen
TI  - Wheat Ear Recognition Based on RetinaNet and Transfer Learning
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 14
SN  - 1424-8220

AB  - The number of wheat ears is an essential indicator for wheat production and yield estimation, but accurately obtaining wheat ears requires expensive manual cost and labor time. Meanwhile, the characteristics of wheat ears provide less information, and the color is consistent with the background, which can be challenging to obtain the number of wheat ears required. In this paper, the performance of Faster regions with convolutional neural networks (Faster R-CNN) and RetinaNet to predict the number of wheat ears for wheat at different growth stages under different conditions is investigated. The results show that using the Global WHEAT dataset for recognition, the RetinaNet method, and the Faster R-CNN method achieve an average accuracy of 0.82 and 0.72, with the RetinaNet method obtaining the highest recognition accuracy. Secondly, using the collected image data for recognition, the R2 of RetinaNet and Faster R-CNN after transfer learning is 0.9722 and 0.8702, respectively, indicating that the recognition accuracy of the RetinaNet method is higher on different data sets. We also tested wheat ears at both the filling and maturity stages; our proposed method has proven to be very robust (the R2 is above 90). This study provides technical support and a reference for automatic wheat ear recognition and yield estimation.
KW  - RetinaNet
KW  - deep learning
KW  - transfer learning
KW  - wheat ears
KW  - Global WHEAT
DO  - 10.3390/s21144845
ER  -
TY  - EJOU
AU  - Ran, Shuhao
AU  - Gao, Xianjun
AU  - Yang, Yuanwei
AU  - Li, Shaohua
AU  - Zhang, Guangbin
AU  - Wang, Ping
TI  - Building Multi-Feature Fusion Refined Network for Building Extraction from High-Resolution Remote Sensing Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - Deep learning approaches have been widely used in building automatic extraction tasks and have made great progress in recent years. However, the missing detection and wrong detection causing by spectrum confusion is still a great challenge. The existing fully convolutional networks (FCNs) cannot effectively distinguish whether the feature differences are from one building or the building and its adjacent non-building objects. In order to overcome the limitations, a building multi-feature fusion refined network (BMFR-Net) was presented in this paper to extract buildings accurately and completely. BMFR-Net is based on an encoding and decoding structure, mainly consisting of two parts: the continuous atrous convolution pyramid (CACP) module and the multiscale output fusion constraint (MOFC) structure. The CACP module is positioned at the end of the contracting path and it effectively minimizes the loss of effective information in multiscale feature extraction and fusion by using parallel continuous small-scale atrous convolution. To improve the ability to aggregate semantic information from the context, the MOFC structure performs predictive output at each stage of the expanding path and integrates the results into the network. Furthermore, the multilevel joint weighted loss function effectively updates parameters well away from the output layer, enhancing the learning capacity of the network for low-level abstract features. The experimental results demonstrate that the proposed BMFR-Net outperforms the other five state-of-the-art approaches in both visual interpretation and quantitative evaluation.
KW  - high-resolution remote sensing images
KW  - building extraction
KW  - multiscale features
KW  - aggregate semantic information
KW  - feature pyramid
DO  - 10.3390/rs13142794
ER  -
TY  - EJOU
AU  - Vandendaele, Bastien
AU  - Fournier, Richard A.
AU  - Vepakomma, Udayalakshmi
AU  - Pelletier, Gaetan
AU  - Lejeune, Philippe
AU  - Martin-Ducup, Olivier
TI  - Estimation of Northern Hardwood Forest Inventory Attributes Using UAV Laser Scanning (ULS): Transferability of Laser Scanning Methods and Comparison of Automated Approaches at the Tree- and Stand-Level
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - UAV laser scanning (ULS) has the potential to support forest operations since it provides high-density data with flexible operational conditions. This study examined the use of ULS systems to estimate several tree attributes from an uneven-aged northern hardwood stand. We investigated: (1) the transferability of raster-based and bottom-up point cloud-based individual tree detection (ITD) algorithms to ULS data; and (2) automated approaches to the retrieval of tree-level (i.e., height, crown diameter (CD), DBH) and stand-level (i.e., tree count, basal area (BA), DBH-distribution) forest inventory attributes. These objectives were studied under leaf-on and leaf-off canopy conditions. Results achieved from ULS data were cross-compared with ALS and TLS to better understand the potential and challenges faced by different laser scanning systems and methodological approaches in hardwood forest environments. The best results that characterized individual trees from ULS data were achieved under leaf-off conditions using a point cloud-based bottom-up ITD. The latter outperformed the raster-based ITD, improving the accuracy of tree detection (from 50% to 71%), crown delineation (from R2 = 0.29 to R2 = 0.61), and prediction of tree DBH (from R2 = 0.36 to R2 = 0.67), when compared with values that were estimated from reference TLS data. Major improvements were observed for the detection of trees in the lower canopy layer (from 9% with raster-based ITD to 51% with point cloud-based ITD) and in the intermediate canopy layer (from 24% with raster-based ITD to 59% with point cloud-based ITD). Under leaf-on conditions, LiDAR data from aerial systems include substantial signal occlusion incurred by the upper canopy. Under these conditions, the raster-based ITD was unable to detect low-level canopy trees (from 5% to 15% of trees detected from lower and intermediate canopy layers, respectively), resulting in a tree detection rate of about 40% for both ULS and ALS data. The cylinder-fitting method used to estimate tree DBH under leaf-off conditions did not meet inventory standards when compared to TLS DBH, resulting in RMSE = 7.4 cm, Bias = 3.1 cm, and R2 = 0.75. Yet, it yielded more accurate estimates of the BA (+3.5%) and DBH-distribution of the stand than did allometric models −12.9%), when compared with in situ field measurements. Results suggest that the use of bottom-up ITD on high-density ULS data from leaf-off hardwood forest leads to promising results when estimating trees and stand attributes, which opens up new possibilities for supporting forest inventories and operations.
KW  - UAV laser scanning (ULS)
KW  - hardwood
KW  - uneven-aged forest
KW  - individual tree detection and delineation (ITD)
KW  - forest inventory
KW  - diameter at breast height (DBH)
KW  - airborne laser scanning (ALS)
KW  - terrestrial laser scanning (TLS)
KW  - open-source analytic tools
DO  - 10.3390/rs13142796
ER  -
TY  - EJOU
AU  - Banfi, Fabrizio
AU  - Mandelli, Alessandro
TI  - Computer Vision Meets Image Processing and UAS PhotoGrammetric Data Integration: From HBIM to the eXtended Reality Project of Arco della Pace in Milan and Its Decorative Complexity
T2  - Journal of Imaging

PY  - 2021
VL  - 7
IS  - 7
SN  - 2313-433X

AB  - This study aims to enrich the knowledge of the monument Arco della Pace in Milan, surveying and modelling the sculpture that crowns the upper part of the building. The statues and the decorative apparatus are recorded with the photogrammetric technique using both a terrestrial camera and an Unmanned Aerial Vehicle (UAV). Research results and performance are oriented to improve computer vision and image processing integration with Unmanned Aerial System (UAS) photogrammetric data to enhance interactivity and information sharing between user and digital heritage models. The vast number of images captured from terrestrial and aerial photogrammetry will also permit to use of the Historic Building Information Modelling (HBIM) model in an eXtended Reality (XR) project developed ad-hoc, allowing different types of users (professionals, non-expert users, virtual tourists, and students) and devices (mobile phones, tablets, PCs, VR headsets) to access details and information that are not visible from the ground.
KW  - Unmanned Aerial System (UAS)
KW  - heritage documentation
KW  - photogrammetry
KW  - 3D modelling
KW  - eXtended Reality (XR)
KW  - virtual museums
KW  - computer vision
DO  - 10.3390/jimaging7070118
ER  -
TY  - EJOU
AU  - Vásquez, Felipe
AU  - Cravero, Ania
AU  - Castro, Manuel
AU  - Acevedo, Patricio
TI  - Decision Support System Development of Wildland Fire: A Systematic Mapping
T2  - Forests

PY  - 2021
VL  - 12
IS  - 7
SN  - 1999-4907

AB  - Wildland fires have been a rising problem on the worldwide level, generating ecological and economic losses. Specifically, between wildland fire types, uncontrolled fires are critical due to the potential damage to the ecosystem and their effects on the soil, and, in the last decade, different technologies have been applied to fight them. Selecting a specific technology and Decision Support Systems (DSS) is fundamental, since the results and validity of this could drastically oscillate according to the different environmental and geographic factors of the terrain to be studied. Given the above, a systematic mapping was realized, with the purpose of recognizing the most-used DSS and context where they have been applied. One hundred and eighty-three studies were found that used different types of DSS to solve problems of detection, prediction, prevention, monitoring, simulation, administration, and access to routes. The concepts key to the type of solution are related to the use or development of systems or Information and Communication Technologies (ICT) in the computer science area. Although the use of BA and Big Data has increased in recent years, there are still many challenges to face, such as staff training, the friendly environment of DSS, and real-time decision-making.
KW  - wildland fire
KW  - forest fire
KW  - decision support systems
KW  - systematic mapping
DO  - 10.3390/f12070943
ER  -
TY  - EJOU
AU  - Lin, Zhe
AU  - Guo, Wenxuan
TI  - Cotton Stand Counting from Unmanned Aerial System Imagery Using MobileNet and CenterNet Deep Learning Models
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - An accurate stand count is a prerequisite to determining the emergence rate, assessing seedling vigor, and facilitating site-specific management for optimal crop production. Traditional manual counting methods in stand assessment are labor intensive and time consuming for large-scale breeding programs or production field operations. This study aimed to apply two deep learning models, the MobileNet and CenterNet, to detect and count cotton plants at the seedling stage with unmanned aerial system (UAS) images. These models were trained with two datasets containing 400 and 900 images with variations in plant size and soil background brightness. The performance of these models was assessed with two testing datasets of different dimensions, testing dataset 1 with 300 by 400 pixels and testing dataset 2 with 250 by 1200 pixels. The model validation results showed that the mean average precision (mAP) and average recall (AR) were 79% and 73% for the CenterNet model, and 86% and 72% for the MobileNet model with 900 training images. The accuracy of cotton plant detection and counting was higher with testing dataset 1 for both CenterNet and MobileNet models. The results showed that the CenterNet model had a better overall performance for cotton plant detection and counting with 900 training images. The results also indicated that more training images are required when applying object detection models on images with different dimensions from training datasets. The mean absolute percentage error (MAPE), coefficient of determination (R2), and the root mean squared error (RMSE) values of the cotton plant counting were 0.07%, 0.98 and 0.37, respectively, with testing dataset 1 for the CenterNet model with 900 training images. Both MobileNet and CenterNet models have the potential to accurately and timely detect and count cotton plants based on high-resolution UAS images at the seedling stage. This study provides valuable information for selecting the right deep learning tools and the appropriate number of training images for object detection projects in agricultural applications.
KW  - cotton stand count
KW  - unmanned aerial systems
KW  - deep learning
KW  - remote sensing
KW  - MobileNet
KW  - CenterNet
KW  - Python
KW  - Tensorflow
DO  - 10.3390/rs13142822
ER  -
TY  - EJOU
AU  - Hu, Pengcheng
AU  - Chapman, Scott C.
AU  - Jin, Huidong
AU  - Guo, Yan
AU  - Zheng, Bangyou
TI  - Comparison of Modelling Strategies to Estimate Phenotypic Values from an Unmanned Aerial Vehicle with Spectral and Temporal Vegetation Indexes
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 14
SN  - 2072-4292

AB  - Aboveground dry weight (AGDW) and leaf area index (LAI) are indicators of crop growth status and grain yield as affected by interactions of genotype, environment, and management. Unmanned aerial vehicle (UAV) based remote sensing provides cost-effective and non-destructive methods for the high-throughput phenotyping of crop traits (e.g., AGDW and LAI) through the integration of UAV-derived vegetation indexes (VIs) with statistical models. However, the effects of different modelling strategies that use different dataset compositions of explanatory variables (i.e., combinations of sources and temporal combinations of the VI datasets) on estimates of AGDW and LAI have rarely been evaluated. In this study, we evaluated the effects of three sources of VIs (visible, spectral, and combined) and three types of temporal combinations of the VI datasets (mono-, multi-, and full-temporal) on estimates of AGDW and LAI. The VIs were derived from visible (RGB) and multi-spectral imageries, which were acquired by a UAV-based platform over a wheat trial at five sampling dates before flowering. Partial least squares regression models were built with different modelling strategies to estimate AGDW and LAI at each prediction date. The results showed that models built with the three sources of mono-temporal VIs obtained similar performances for estimating AGDW (RRMSE = 11.86% to 15.80% for visible, 10.25% to 16.70% for spectral, and 10.25% to 16.70% for combined VIs) and LAI (RRMSE = 13.30% to 22.56% for visible, 12.04% to 22.85% for spectral, and 13.45% to 22.85% for combined VIs) across prediction dates. Mono-temporal models built with visible VIs outperformed the other two sources of VIs in general. Models built with mono-temporal VIs generally obtained better estimates than models with multi- and full-temporal VIs. The results suggested that the use of UAV-derived visible VIs can be an alternative to multi-spectral VIs for high-throughput and in-season estimates of AGDW and LAI. The combination of modelling strategies that used mono-temporal datasets and a self-calibration method demonstrated the potential for in-season estimates of AGDW and LAI (RRMSE normally less than 15%) in breeding or agronomy trials.
KW  - aboveground dry weight
KW  - leaf area index
KW  - high-throughput phenotyping
KW  - remote sensing
DO  - 10.3390/rs13142827
ER  -
TY  - EJOU
AU  - Che’Ya, Nik N.
AU  - Dunwoody, Ernest
AU  - Gupta, Madan
TI  - Assessment of Weed Classification Using Hyperspectral Reflectance and Optimal Multispectral UAV Imagery
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 7
SN  - 2073-4395

AB  - Weeds compete with crops and are hard to differentiate and identify due to their similarities in color, shape, and size. In this study, the weed species present in sorghum (sorghum bicolor (L.) Moench) fields, such as amaranth (Amaranthus macrocarpus), pigweed (Portulaca oleracea), mallow weed (Malva sp.), nutgrass (Cyperus rotundus), liver seed grass (Urochoa panicoides), and Bellive (Ipomea plebeian), were discriminated using hyperspectral data and were detected and analyzed using multispectral images. Discriminant analysis (DA) was used to identify the most significant spectral bands in order to discriminate weeds from sorghum using hyperspectral data. The results demonstrated good separation accuracy for Amaranthus macrocarpus, Urochoa panicoides, Malva sp., Cyperus rotundus, and Sorghum bicolor (L.) Moench at 440, 560, 680, 710, 720, and 850 nm. Later, the multispectral images of these six bands were collected to detect weeds in the sorghum crop fields using object-based image analysis (OBIA). The results showed that the differences between sorghum and weed species were detectable using the six selected bands, with data collected using an unmanned aerial vehicle. Here, the highest spatial resolution had the highest accuracy for weed detection. It was concluded that each weed was successfully discriminated using hyperspectral data and was detectable using multispectral data with higher spatial resolution.
KW  - weed classification
KW  - hyperspectral reflectance
KW  - discriminant analysis
KW  - weed species
KW  - weed mapping
KW  - site-specific weed management
DO  - 10.3390/agronomy11071435
ER  -
TY  - EJOU
AU  - Liu, Jingjing
AU  - Liu, Chuanyang
AU  - Wu, Yiquan
AU  - Xu, Huajie
AU  - Sun, Zuo
TI  - An Improved Method Based on Deep Learning for Insulator Fault Detection in Diverse Aerial Images
T2  - Energies

PY  - 2021
VL  - 14
IS  - 14
SN  - 1996-1073

AB  - Insulators play a significant role in high-voltage transmission lines, and detecting insulator faults timely and accurately is important for the safe and stable operation of power grids. Since insulator faults are extremely small and the backgrounds of aerial images are complex, insulator fault detection is a challenging task for automatically inspecting transmission lines. In this paper, a method based on deep learning is proposed for insulator fault detection in diverse aerial images. Firstly, to provide sufficient insulator fault images for training, a novel insulator fault dataset named “InSF-detection” is constructed. Secondly, an improved YOLOv3 model is proposed to reuse features and prevent feature loss. To improve the accuracy of insulator fault detection, SPP-networks and a multi-scale prediction network are employed for the improved YOLOv3 model. Finally, the improved YOLOv3 model and the compared models are trained and tested on the “InSF-detection”. The average precision (AP) of the improved YOLOv3 model is superior to YOLOv3 and YOLOv3-dense models, and just a little (1.2%) lower than that of CSPD-YOLO model; more importantly, the memory usage of the improved YOLOv3 model is 225 MB, which is the smallest between the four compared models. The experimental results and analysis validate that the improved YOLOv3 model achieves good performance for insulator fault detection in aerial images with diverse backgrounds.
KW  - insulator fault detection
KW  - aerial image
KW  - deep learning
KW  - YOLO
KW  - DenseNet
KW  - complex backgrounds
DO  - 10.3390/en14144365
ER  -
TY  - EJOU
AU  - Hallee, Mitchell J.
AU  - Napolitano, Rebecca K.
AU  - Reinhart, Wesley F.
AU  - Glisic, Branko
TI  - Crack Detection in Images of Masonry Using CNNs
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 14
SN  - 1424-8220

AB  - While there is a significant body of research on crack detection by computer vision methods in concrete and asphalt, less attention has been given to masonry. We train a convolutional neural network (CNN) on images of brick walls built in a laboratory environment and test its ability to detect cracks in images of brick-and-mortar structures both in the laboratory and on real-world images taken from the internet. We also compare the performance of the CNN to a variety of simpler classifiers operating on handcrafted features. We find that the CNN performed better on the domain adaptation from laboratory to real-world images than these simple models. However, we also find that performance is significantly better in performing the reverse domain adaptation task, where the simple classifiers are trained on real-world images and tested on the laboratory images. This work demonstrates the ability to detect cracks in images of masonry using a variety of machine learning methods and provides guidance for improving the reliability of such models when performing domain adaptation for crack detection in masonry.
KW  - computer vision
KW  - crack detection
KW  - structural health monitoring
KW  - masonry
KW  - machine learning
KW  - convolutional neural network
DO  - 10.3390/s21144929
ER  -
TY  - EJOU
AU  - Wei, Baoquan
AU  - Zuo, Yong
AU  - Liu, Yande
AU  - Luo, Wei
AU  - Wen, Kaiyun
AU  - Deng, Fangming
TI  - Novel MOA Fault Detection Technology Based on Small Sample Infrared Image
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 15
SN  - 2079-9292

AB  - This paper proposes a novel metal oxide arrester (MOA) fault detection technology based on a small sample infrared image. The research is carried out from the detection process and data enhancement. A lightweight MOA identification and location algorithm is designed at the edge, which can not only reduce the amount of data uploaded, but also reduce the search space of cloud algorithm. In order to improve the accuracy and generalization ability of the defect detection model under the condition of small samples, a multi-model fusion detection algorithm is proposed. Different features of the image are extracted by multiple convolutional neural networks, and then multiple classifiers are trained. Finally, the weighted voting strategy is used for fault diagnosis. In addition, the extended model of fault samples is constructed by transfer learning and deep convolutional generative adversarial networks (DCGAN) to solve the problem of unbalanced training data sets. The experimental results show that the proposed method can realize the accurate location of arrester under the condition of small samples, and after the data expansion, the recognition rate of arrester anomalies can be improved from 83% to 85%, showing high effectiveness and reliability.
KW  - metal oxide arrester
KW  - deep learning
KW  - edge computing
KW  - condition monitoring
DO  - 10.3390/electronics10151748
ER  -
TY  - EJOU
AU  - Zhang, Ziyuan
AU  - Hua, Zexi
AU  - Tang, Yongchuan
AU  - Zhang, Yunjia
AU  - Lu, Weijun
AU  - Dai, Congfei
TI  - Recognition Method of Digital Meter Readings in Substation Based on Connected Domain Analysis Algorithm
T2  - Actuators

PY  - 2021
VL  - 10
IS  - 8
SN  - 2076-0825

AB  - Aiming at the problem that the number and decimal point of digital instruments in substations are prone to misdetection and missed detection, a method of digital meter readings in a substation based on connected domain analysis algorithm is proposed. This method uses Faster R-CNN (Faster Region Convolutional Neural Network) as a positioning network to localize the dial area, and after acquiring the partial image, it enhances the useful information of the digital area. YOLOv4 (You Only Look Once) convolutional neural network is used as the detector to detect the digital area. The purpose is to distinguish the numbers and obtain the digital area that may contain a decimal point or no decimal point at the tail. Combined with the connected domain analysis algorithm, the difference between the number of connected domain categories and the area ratio of the digital area is analyzed, and the judgment of the decimal point is realized. The method reduces the problem of mutual interference among categories when detecting YOLOv4. The experimental results show that the method improves the detection accuracy of the algorithm.
KW  - deep learning
KW  - YOLOv4
KW  - target detection
KW  - connected domain
KW  - digital meter readings
DO  - 10.3390/act10080170
ER  -
TY  - EJOU
AU  - Ammar, Adel
AU  - Koubaa, Anis
AU  - Benjdira, Bilel
TI  - Deep-Learning-Based Automated Palm Tree Counting and Geolocation in Large Farms from Aerial Geotagged Images
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 8
SN  - 2073-4395

AB  - In this paper, we propose an original deep learning framework for the automated counting and geolocation of palm trees from aerial images using convolutional neural networks. For this purpose, we collected aerial images from two different regions in Saudi Arabia, using two DJI drones, and we built a dataset of around 11,000 instances of palm trees. Then, we applied several recent convolutional neural network models (Faster R-CNN, YOLOv3, YOLOv4, and EfficientDet) to detect palms and other trees, and we conducted a complete comparative evaluation in terms of average precision and inference speed. YOLOv4 and EfficientDet-D5 yielded the best trade-off between accuracy and speed (up to 99% mean average precision and 7.4 FPS). Furthermore, using the geotagged metadata of aerial images, we used photogrammetry concepts and distance corrections to automatically detect the geographical location of detected palm trees. This geolocation technique was tested on two different types of drones (DJI Mavic Pro and Phantom 4 pro) and was assessed to provide an average geolocation accuracy that attains 1.6 m. This GPS tagging allows us to uniquely identify palm trees and count their number from a series of drone images, while correctly dealing with the issue of image overlapping. Moreover, this innovative combination between deep learning object detection and geolocalization can be generalized to any other objects in UAV images.
KW  - unmanned aerial vehicles
KW  - convolutional neural networks
KW  - Faster R-CNN
KW  - You Only Look Once (YOLO)
DO  - 10.3390/agronomy11081458
ER  -
TY  - EJOU
AU  - Walambe, Rahee
AU  - Marathe, Aboli
AU  - Kotecha, Ketan
TI  - Multiscale Object Detection from Drone Imagery Using Ensemble Transfer Learning
T2  - Drones

PY  - 2021
VL  - 5
IS  - 3
SN  - 2504-446X

AB  - Object detection in uncrewed aerial vehicle (UAV) images has been a longstanding challenge in the field of computer vision. Specifically, object detection in drone images is a complex task due to objects of various scales such as humans, buildings, water bodies, and hills. In this paper, we present an implementation of ensemble transfer learning to enhance the performance of the base models for multiscale object detection in drone imagery. Combined with a test-time augmentation pipeline, the algorithm combines different models and applies voting strategies to detect objects of various scales in UAV images. The data augmentation also presents a solution to the deficiency of drone image datasets. We experimented with two specific datasets in the open domain: the VisDrone dataset and the AU-AIR Dataset. Our approach is more practical and efficient due to the use of transfer learning and two-level voting strategy ensemble instead of training custom models on entire datasets. The experimentation shows significant improvement in the mAP for both VisDrone and AU-AIR datasets by employing the ensemble transfer learning method. Furthermore, the utilization of voting strategies further increases the 3reliability of the ensemble as the end-user can select and trace the effects of the mechanism for bounding box predictions.
KW  - drone imagery
KW  - 2D object detection
KW  - ensemble techniques
KW  - voting strategies
DO  - 10.3390/drones5030066
ER  -
TY  - EJOU
AU  - Wang, Jingrui
AU  - Wang, Shuqing
AU  - Zou, Dongxiao
AU  - Chen, Huimin
AU  - Zhong, Run
AU  - Li, Hanliang
AU  - Zhou, Wei
AU  - Yan, Kai
TI  - Social Network and Bibliometric Analysis of Unmanned Aerial Vehicle Remote Sensing Applications from 2010 to 2021
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 15
SN  - 2072-4292

AB  - Unmanned Aerial Vehicle (UAV) Remote sensing (RS) has unique advantages over traditional satellite RS, including convenience, high resolution, affordability and fast acquisition speed, making it widely used in many fields. To provide an overview of the development of UAV RS applications during the past decade, we screened related publications from the Web of Science core database from 2010 to 2021, built co-author networks, a discipline interaction network, a keywords timeline view, a co-citation cluster, and detected burst citations using bibliometrics and social network analysis. Our results show that: (1) The number of UAV RS publications had an increasing trend, with explosive growth in the past five years. The number of papers published by China and the United States (US) is far ahead in this field; (2) The US has currently the greatest influence in this field through the largest number of international cooperations. Cooperation is mainly concentrated in countries and institutions with a large number of publications but is not widely distributed. (3) The application of UAV RS involves multiple interdisciplinary subjects, among which “Environmental Science and Ecology” ranks first; (4) Future research trends of UAV RS are expected to be related to artificial intelligence (e.g., artificial neural networks-based research). This paper provides a scientific basis and guidance for future developments of UAV RS applications, which can help the research community to better grasp the developments of this field.
KW  - Unmanned Aerial Vehicle (UAV)
KW  - Remote Sensing (RS)
KW  - Bibliometric
KW  - Scientometric
KW  - visualization
DO  - 10.3390/rs13152912
ER  -
TY  - EJOU
AU  - Wei, Lifei
AU  - Wang, Kun
AU  - Lu, Qikai
AU  - Liang, Yajing
AU  - Li, Haibo
AU  - Wang, Zhengxiang
AU  - Wang, Run
AU  - Cao, Liqin
TI  - Crops Fine Classification in Airborne Hyperspectral Imagery Based on Multi-Feature Fusion and Deep Learning
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 15
SN  - 2072-4292

AB  - Hyperspectral imagery has been widely used in precision agriculture due to its rich spectral characteristics. With the rapid development of remote sensing technology, the airborne hyperspectral imagery shows detailed spatial information and temporal flexibility, which open a new way to accurate agricultural monitoring. To extract crop types from the airborne hyperspectral images, we propose a fine classification method based on multi-feature fusion and deep learning. In this research, the morphological profiles, GLCM texture and endmember abundance features are leveraged to exploit the spatial information of the hyperspectral imagery. Then, the multiple spatial information is fused with the original spectral information to generate classification result by using the deep neural network with conditional random field (DNN+CRF) model. Specifically, the deep neural network (DNN) is a deep recognition model which can extract depth features and mine the potential information of data. As a discriminant model, conditional random field (CRF) considers both spatial and contextual information to reduce the misclassification noises while keeping the object boundaries. Moreover, three multiple feature fusion approaches, namely feature stacking, decision fusion and probability fusion, are taken into account. In the experiments, two airborne hyperspectral remote sensing datasets (Honghu dataset and Xiong’an dataset) are used. The experimental results show that the classification performance of the proposed method is satisfactory, where the salt and pepper noise is decreased, and the boundary of the ground object is preserved.
KW  - hyperspectral imagery
KW  - crops fine classification
KW  - multi-feature fusion
KW  - deep neural network
KW  - conditional random field
DO  - 10.3390/rs13152917
ER  -
TY  - EJOU
AU  - Banerjee, Bikram P.
AU  - Sharma, Vikas
AU  - Spangenberg, German
AU  - Kant, Surya
TI  - Machine Learning Regression Analysis for Estimation of Crop Emergence Using Multispectral UAV Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 15
SN  - 2072-4292

AB  - Optimal crop emergence is an important trait in crop breeding for genotypic screening and for achieving potential growth and yield. Emergence is conventionally quantified manually by counting the sub-sections of field plots or scoring; these are less reliable, laborious and inefficient. Remote sensing technology is being increasingly used for high-throughput estimation of agronomic traits in field crops. This study developed a method for estimating wheat seedlings using multispectral images captured from an unmanned aerial vehicle. A machine learning regression (MLR) analysis was used by combining spectral and morphological information extracted from the multispectral images. The approach was tested on diverse wheat genotypes varying in seedling emergence. In this study, three supervised MLR models including regression trees, support vector regression and Gaussian process regression (GPR) were evaluated for estimating wheat seedling emergence. The GPR model was the most effective compared to the other methods, with R2 = 0.86, RMSE = 4.07 and MAE = 3.21 when correlated to the manual seedling count. In addition, imagery data collected at multiple flight altitudes and different wheat growth stages suggested that 10 m altitude and 20 days after sowing were desirable for optimal spatial resolution and image analysis. The method is deployable on larger field trials and other crops for effective and reliable seedling emergence estimates.
KW  - field trials
KW  - plant count
KW  - plant phenotyping
KW  - wheat
DO  - 10.3390/rs13152918
ER  -
TY  - EJOU
AU  - Behjati, Mehran
AU  - Mohd Noh, Aishah B.
AU  - Alobaidy, Haider A. H.
AU  - Zulkifley, Muhammad A.
AU  - Nordin, Rosdiadee
AU  - Abdullah, Nor F.
TI  - LoRa Communications as an Enabler for Internet of Drones towards Large-Scale Livestock Monitoring in Rural Farms
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 15
SN  - 1424-8220

AB  - Currently, smart farming is considered an effective solution to enhance the productivity of farms; thereby, it has recently received broad interest from service providers to offer a wide range of applications, from pest identification to asset monitoring. Although the emergence of digital technologies, such as the Internet of Things (IoT) and low-power wide-area networks (LPWANs), has led to significant advances in the smart farming industry, farming operations still need more efficient solutions. On the other hand, the utilization of unmanned aerial vehicles (UAVs), also known as drones, is growing rapidly across many civil application domains. This paper aims to develop a farm monitoring system that incorporates UAV, LPWAN, and IoT technologies to transform the current farm management approach and aid farmers in obtaining actionable data from their farm operations. In this regard, an IoT-based water quality monitoring system was developed because water is an essential aspect in livestock development. Then, based on the Long-Range Wide-Area Network (LoRaWAN®) technology, a multi-channel LoRaWAN® gateway was developed and integrated into a vertical takeoff and landing drone to convey collected data from the sensors to the cloud for further analysis. In addition, to develop LoRaWAN®-based aerial communication, a series of measurements and simulations were performed under different configurations and scenarios. Finally, to enhance the efficiency of aerial-based data collection, the UAV path planning was optimized. Measurement results showed that the maximum achievable LoRa coverage when operating on-air via the drone is about 10 km, and the Longley–Rice irregular terrain model provides the most suitable path loss model for the scenario of large-scale farms, and a multi-channel gateway with a spreading factor of 12 provides the most reliable communication link at a high drone speed (up to 95 km/h). Simulation results showed that the developed system can overcome the coverage limitation of LoRaWAN® and it can establish a reliable communication link over large-scale wireless sensor networks. In addition, it was shown that by optimizing flight paths, aerial data collection could be performed in a much shorter time than industrial mission planning (up to four times in our case).
KW  - unmanned aircraft vehicle (UAV)
KW  - drone
KW  - long range (LoRa)
KW  - wireless sensor network
KW  - Internet of Things (IoT)
KW  - remote sensing
KW  - smart farming
KW  - path planning
DO  - 10.3390/s21155044
ER  -
TY  - EJOU
AU  - Fernández, Claudio I.
AU  - Leblon, Brigitte
AU  - Wang, Jinfei
AU  - Haddadi, Ata
AU  - Wang, Keri
TI  - Detecting Infected Cucumber Plants with Close-Range Multispectral Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 15
SN  - 2072-4292

AB  - This study used close-range multispectral imagery over cucumber plants inside a commercial greenhouse to detect powdery mildew due to Podosphaera xanthii. It was collected using a MicaSense® RedEdge camera at 1.5 m over the top of the plant. Image registration was performed using Speeded-Up Robust Features (SURF) with an affine geometric transformation. The image background was removed using a binary mask created with the aligned NIR band of each image, and the illumination was corrected using Cheng et al.’s algorithm. Different features were computed, including RGB, image reflectance values, and several vegetation indices. For each feature, a fine Gaussian Support Vector Machines algorithm was trained and validated to classify healthy and infected pixels. The data set to train and validate the SVM was composed of 1000 healthy and 1000 infected pixels, split 70–30% into training and validation datasets, respectively. The overall validation accuracy was 89, 73, 82, 51, and 48%, respectively, for blue, green, red, red-edge, and NIR band image. With the RGB images, we obtained an overall validation accuracy of 89%, while the best vegetation index image was the PMVI-2 image which produced an overall accuracy of 81%. Using the five bands together, overall accuracy dropped from 99% in the training to 57% in the validation dataset. While the results of this work are promising, further research should be considered to increase the number of images to achieve better training and validation datasets.
KW  - speeded-up robust features
KW  - SURF features
KW  - support vector machines
KW  - image alignment
KW  - powdery mildew
DO  - 10.3390/rs13152948
ER  -
TY  - EJOU
AU  - Ghaffarian, Saman
AU  - Valente, João
AU  - van der Voort, Mariska
AU  - Tekinerdogan, Bedir
TI  - Effect of Attention Mechanism in Deep Learning-Based Remote Sensing Image Processing: A Systematic Literature Review
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 15
SN  - 2072-4292

AB  - Machine learning, particularly deep learning (DL), has become a central and state-of-the-art method for several computer vision applications and remote sensing (RS) image processing. Researchers are continually trying to improve the performance of the DL methods by developing new architectural designs of the networks and/or developing new techniques, such as attention mechanisms. Since the attention mechanism has been proposed, regardless of its type, it has been increasingly used for diverse RS applications to improve the performances of the existing DL methods. However, these methods are scattered over different studies impeding the selection and application of the feasible approaches. This study provides an overview of the developed attention mechanisms and how to integrate them with different deep learning neural network architectures. In addition, it aims to investigate the effect of the attention mechanism on deep learning-based RS image processing. We identified and analyzed the advances in the corresponding attention mechanism-based deep learning (At-DL) methods. A systematic literature review was performed to identify the trends in publications, publishers, improved DL methods, data types used, attention types used, overall accuracies achieved using At-DL methods, and extracted the current research directions, weaknesses, and open problems to provide insights and recommendations for future studies. For this, five main research questions were formulated to extract the required data and information from the literature. Furthermore, we categorized the papers regarding the addressed RS image processing tasks (e.g., image classification, object detection, and change detection) and discussed the results within each group. In total, 270 papers were retrieved, of which 176 papers were selected according to the defined exclusion criteria for further analysis and detailed review. The results reveal that most of the papers reported an increase in overall accuracy when using the attention mechanism within the DL methods for image classification, image segmentation, change detection, and object detection using remote sensing images.
KW  - remote sensing
KW  - image processing
KW  - attention mechanism
KW  - spatial attention
KW  - channel attention
KW  - deep learning
KW  - CNN
DO  - 10.3390/rs13152965
ER  -
TY  - EJOU
AU  - Hajjar, Chantal
AU  - Ghattas, Ghassan
AU  - Sarkis, Maya K.
AU  - Chamoun, Yolla G.
TI  - Vine Identification and Characterization in Goblet-Trained Vineyards Using Remotely Sensed Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 15
SN  - 2072-4292

AB  - This paper proposes a novel approach for living and missing vine identification and vine characterization in goblet-trained vine plots using aerial images. Given the periodic structure of goblet vineyards, the RGB color coded parcel image is analyzed using proper processing techniques in order to determine the locations of living and missing vines. Vine characterization is achieved by implementing the marker-controlled watershed transform where the centers of the living vines serve as object markers. As a result, a precise mortality rate is calculated for each parcel. Moreover, all vines, even the overlapping ones, are fully recognized providing information about their size, shape, and green color intensity. The presented approach is fully automated and yields accuracy values exceeding 95% when the obtained results are assessed with ground-truth data. This unsupervised and automated approach can be applied to any type of plots presenting similar spatial patterns requiring only the image as input.
KW  - vine characterization
KW  - missing and living vine identification
KW  - goblet vineyards
KW  - Hough transform
KW  - watershed transform
KW  - remote sensing
KW  - semantic segmentation
DO  - 10.3390/rs13152992
ER  -
TY  - EJOU
AU  - Wang, Yang
AU  - Tian, Yongzhong
AU  - Cao, Yan
TI  - Dam Siting: A Review
T2  - Water

PY  - 2021
VL  - 13
IS  - 15
SN  - 2073-4441

AB  - Dams can effectively regulate the spatial and temporal distribution of water resources, where the rationality of dam siting determines whether the role of dams can be effectively performed. This paper reviews the research literature on dam siting in the past 20 years, discusses the methods used for dam siting, focuses on the factors influencing dam siting, and assesses the impact of different dam functions on siting factors. The results show the following: (1) Existing siting methods can be categorized into three types—namely, GIS/RS-based siting, MCDM- and MCDM-GIS-based siting, and machine learning-based siting. GIS/RS emphasizes the ability to capture and analyze data, MCDM has the advantage of weighing the importance of the relationship between multiple factors, and machine learning methods have a strong ability to learn and process complex data. (2) Site selection factors vary greatly, depending on the function of the dam. For dams with irrigation and water supply as the main purpose, the site selection is more focused on the evaluation of water quality. For dams with power generation as the main purpose, the hydrological factors characterizing the power generation potential are the most important. For dams with flood control as the main purpose, the topography and geological conditions are more important. (3) The integration of different siting methods and the siting of new functional dams in the existing research is not sufficient. Future research should focus on the integration of different methods and disciplines, in order to explore the siting of new types of dams.
KW  - dam siting
KW  - multi-criteria decision-making
KW  - geographic information systems
KW  - machine learning
KW  - siting factors
DO  - 10.3390/w13152080
ER  -
TY  - EJOU
AU  - Wang, Hao
AU  - Lyu, Suxing
AU  - Ren, Yaxin
TI  - Paddy Rice Imagery Dataset for Panicle Segmentation
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 8
SN  - 2073-4395

AB  - Accurate panicle identification is a key step in rice-field phenotyping. Deep learning methods based on high-spatial-resolution images provide a high-throughput and accurate solution of panicle segmentation. Panicle segmentation tasks require costly annotations to train an accurate and robust deep learning model. However, few public datasets are available for rice-panicle phenotyping. We present a semi-supervised deep learning model training process, which greatly assists the annotation and refinement of training datasets. The model learns the panicle features with limited annotations and localizes more positive samples in the datasets, without further interaction. After the dataset refinement, the number of annotations increased by 40.6%. In addition, we trained and tested modern deep learning models to show how the dataset is beneficial to both detection and segmentation tasks. Results of our comparison experiments can inspire others in dataset preparation and model selection.
KW  - image segmentation
KW  - panicle detection
KW  - deep learning
KW  - smart agriculture
KW  - unmanned aerial vehicle platform
DO  - 10.3390/agronomy11081542
ER  -
TY  - EJOU
AU  - Kim, Minsu
AU  - Lee, Chaewon
AU  - Hong, Subin
AU  - Kim, Song L.
AU  - Baek, Jeong-Ho
AU  - Kim, Kyung-Hwan
TI  - High-Throughput Phenotyping Methods for Breeding Drought-Tolerant Crops
T2  - International Journal of Molecular Sciences

PY  - 2021
VL  - 22
IS  - 15
SN  - 1422-0067

AB  - Drought is a main factor limiting crop yields. Modern agricultural technologies such as irrigation systems, ground mulching, and rainwater storage can prevent drought, but these are only temporary solutions. Understanding the physiological, biochemical, and molecular reactions of plants to drought stress is therefore urgent. The recent rapid development of genomics tools has led to an increasing interest in phenomics, i.e., the study of phenotypic plant traits. Among phenomic strategies, high-throughput phenotyping (HTP) is attracting increasing attention as a way to address the bottlenecks of genomic and phenomic studies. HTP provides researchers a non-destructive and non-invasive method yet accurate in analyzing large-scale phenotypic data. This review describes plant responses to drought stress and introduces HTP methods that can detect changes in plant phenotypes in response to drought.
KW  - high-throughput phenotyping
KW  - drought
KW  - phenomics
KW  - breeding
DO  - 10.3390/ijms22158266
ER  -
TY  - EJOU
AU  - Ma, Huiqin
AU  - Huang, Wenjiang
AU  - Dong, Yingying
AU  - Liu, Linyi
AU  - Guo, Anting
TI  - Using UAV-Based Hyperspectral Imagery to Detect Winter Wheat Fusarium Head Blight
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 15
SN  - 2072-4292

AB  - Fusarium head blight (FHB) is a major winter wheat disease in China. The accurate and timely detection of wheat FHB is vital to scientific field management. By combining three types of spectral features, namely, spectral bands (SBs), vegetation indices (VIs), and wavelet features (WFs), in this study, we explore the potential of using hyperspectral imagery obtained from an unmanned aerial vehicle (UAV), to detect wheat FHB. First, during the wheat filling period, two UAV-based hyperspectral images were acquired. SBs, VIs, and WFs that were sensitive to wheat FHB were extracted and optimized from the two images. Subsequently, a field-scale wheat FHB detection model was formulated, based on the optimal spectral feature combination of SBs, VIs, and WFs (SBs + VIs + WFs), using a support vector machine. Two commonly used data normalization algorithms were utilized before the construction of the model. The single WFs, and the spectral feature combination of optimal SBs and VIs (SBs + VIs), were respectively used to formulate models for comparison and testing. The results showed that the detection model based on the normalized SBs + VIs + WFs, using min–max normalization algorithm, achieved the highest R2 of 0.88 and the lowest RMSE of 2.68% among the three models. Our results suggest that UAV-based hyperspectral imaging technology is promising for the field-scale detection of wheat FHB. Combining traditional SBs and VIs with WFs can improve the detection accuracy of wheat FHB effectively.
KW  - crop disease
KW  - remote sensing detection
KW  - hyperspectral imaging
KW  - spectral feature combination
KW  - data normalization
DO  - 10.3390/rs13153024
ER  -
TY  - EJOU
AU  - Sharma, Meenakshi
AU  - Kaushik, Prashant
AU  - Chawade, Aakash
TI  - Frontiers in the Solicitation of Machine Learning Approaches in Vegetable Science Research
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 15
SN  - 2071-1050

AB  - Along with essential nutrients and trace elements, vegetables provide raw materials for the food processing industry. Despite this, plant diseases and unfavorable weather patterns continue to threaten the delicate balance between vegetable production and consumption. It is critical to utilize machine learning (ML) in this setting because it provides context for decision-making related to breeding goals. Cutting-edge technologies for crop genome sequencing and phenotyping, combined with advances in computer science, are currently fueling a revolution in vegetable science and technology. Additionally, various ML techniques such as prediction, classification, and clustering are frequently used to forecast vegetable crop production in the field. In the vegetable seed industry, machine learning algorithms are used to assess seed quality before germination and have the potential to improve vegetable production with desired features significantly; whereas, in plant disease detection and management, the ML approaches can improve decision-support systems that assist in converting massive amounts of data into valuable recommendations. On similar lines, in vegetable breeding, ML approaches are helpful in predicting treatment results, such as what will happen if a gene is silenced. Furthermore, ML approaches can be a saviour to insufficient coverage and noisy data generated using various omics platforms. This article examines ML models in the field of vegetable sciences, which encompasses breeding, biotechnology, and genome sequencing.
KW  - machine learning
KW  - vegetables
KW  - models
KW  - predictions
KW  - breeding
KW  - biotechnology
KW  - genomics
DO  - 10.3390/su13158600
ER  -
TY  - EJOU
AU  - Zhao, Yujin
AU  - Sun, Yihan
AU  - Chen, Wenhe
AU  - Zhao, Yanping
AU  - Liu, Xiaoliang
AU  - Bai, Yongfei
TI  - The Potential of Mapping Grassland Plant Diversity with the Links among Spectral Diversity, Functional Trait Diversity, and Species Diversity
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 15
SN  - 2072-4292

AB  - Mapping biodiversity is essential for assessing conservation and ecosystem services in global terrestrial ecosystems. Compared with remotely sensed mapping of forest biodiversity, that of grassland plant diversity has been less studied, because of the small size of individual grass species and the inherent difficulty in identifying these species. The technological advances in unmanned aerial vehicle (UAV)-based or proximal imaging spectroscopy with high spatial resolution provide new approaches for mapping and assessing grassland plant diversity based on spectral diversity and functional trait diversity. However, relatively few studies have explored the relationships among spectral diversity, remote-sensing-estimated functional trait diversity, and species diversity in grassland ecosystems. In this study, we examined the links among spectral diversity, functional trait diversity, and species diversity in a semi-arid grassland monoculture experimental site. The results showed that (1) different grassland plant species harbored different functional traits or trait combinations (functional trait diversity), leading to different spectral patterns (spectral diversity). (2) The spectral diversity of grassland plant species increased gradually from the visible (VIR, 400–700 nm) to the near-infrared (NIR, 700–1100 nm) region, and to the short-wave infrared (SWIR, 1100–2400 nm) region. (3) As the species richness increased, the functional traits and spectral diversity increased in a nonlinear manner, finally tending to saturate. (4) Grassland plant species diversity could be accurately predicted using hyperspectral data (R2 = 0.73, p &lt; 0.001) and remotely sensed functional traits (R2 = 0.66, p &lt; 0.001) using cluster algorithms. This will enhance our understanding of the effect of biodiversity on ecosystem functions and support regional grassland biodiversity conservation.
KW  - grassland
KW  - biodiversity
KW  - remote sensing
KW  - functional trait
KW  - spectral diversity
KW  - imaging spectroscopy
DO  - 10.3390/rs13153034
ER  -
TY  - EJOU
AU  - Doukari, Michaela
AU  - Batsaris, Marios
AU  - Topouzelis, Konstantinos
TI  - UASea: A Data Acquisition Toolbox for Improving Marine Habitat Mapping
T2  - Drones

PY  - 2021
VL  - 5
IS  - 3
SN  - 2504-446X

AB  - Unmanned aerial systems (UAS) are widely used in the acquisition of high-resolution information in the marine environment. Although the potential applications of UAS in marine habitat mapping are constantly increasing, many limitations need to be overcome—most of which are related to the prevalent environmental conditions—to reach efficient UAS surveys. The knowledge of the UAS limitations in marine data acquisition and the examination of the optimal flight conditions led to the development of the UASea toolbox. This study presents the UASea, a data acquisition toolbox that is developed for efficient UAS surveys in the marine environment. The UASea uses weather forecast data (i.e., wind speed, cloud cover, precipitation probability, etc.) and adaptive thresholds in a ruleset that calculates the optimal flight times in a day for the acquisition of reliable marine imagery using UAS in a given day. The toolbox provides hourly positive and negative suggestions, based on optimal or non-optimal survey conditions in a day, calculated according to the ruleset calculations. We acquired UAS images in optimal and non-optimal conditions and estimated their quality using an image quality equation. The image quality estimates are based on the criteria of sunglint presence, sea surface texture, water turbidity, and image naturalness. The overall image quality estimates were highly correlated with the suggestions of the toolbox, with a correlation coefficient of −0.84. The validation showed that 40% of the toolbox suggestions were a positive match to the images with higher quality. Therefore, we propose the optimal flight times to acquire reliable and accurate UAS imagery in the coastal environment through the UASea. The UASea contributes to proper flight planning and efficient UAS surveys by providing valuable information for mapping, monitoring, and management of the marine environment, which can be used globally in research and marine applications.
KW  - UAS
KW  - UASea
KW  - marine habitat mapping
KW  - image quality
KW  - UAS toolbox
DO  - 10.3390/drones5030073
ER  -
TY  - EJOU
AU  - Sheu, Ming-Hwa
AU  - Jhang, Yu-Syuan
AU  - Morsalin, S M.
AU  - Huang, Yao-Fong
AU  - Sun, Chi-Chia
AU  - Lai, Shin-Chi
TI  - UAV Object Tracking Application Based on Patch Color Group Feature on Embedded System
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 15
SN  - 2079-9292

AB  - The discriminative object tracking system for unmanned aerial vehicles (UAVs) is widely used in numerous applications. While an ample amount of research has been carried out in this domain, implementing a low computational cost algorithm on a UAV onboard embedded system is still challenging. To address this issue, we propose a low computational complexity discriminative object tracking system for UAVs approach using the patch color group feature (PCGF) framework in this work. The tracking object is separated into several non-overlapping local image patches then the features are extracted into the PCGFs, which consist of the Gaussian mixture model (GMM). The object location is calculated by the similar PCGFs comparison from the previous frame and current frame. The background PCGFs of the object are removed by four directions feature scanning and dynamic threshold comparison, which improve the performance accuracy. In the terms of speed execution, the proposed algorithm accomplished 32.5 frames per second (FPS) on the x64 CPU platform without a GPU accelerator and 17 FPS in Raspberry Pi 4. Therefore, this work could be considered as a good solution for achieving a low computational complexity PCGF algorithm on a UAV onboard embedded system to improve flight times.
KW  - unmanned aerial vehicle (UAV)
KW  - UAV object tracking
KW  - Gaussian mixture model (GMM)
KW  - patch color group feature (PCGF)
KW  - embedded system
DO  - 10.3390/electronics10151864
ER  -
TY  - EJOU
AU  - Lee, Dong-Ho
AU  - Kim, Hyeon-Jin
AU  - Park, Jong-Hwa
TI  - UAV, a Farm Map, and Machine Learning Technology Convergence Classification Method of a Corn Cultivation Area
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 8
SN  - 2073-4395

AB  - South Korea’s agriculture is characterized by a mixture of various cultivated crops. In such an agricultural environment, convergence technology for ICT (information, communications, and technology) and AI (artificial intelligence) as well as agriculture is required to classify objects and predict yields. In general, the classification of paddy fields and field boundaries takes a lot of time and effort. The Farm Map was developed to clearly demarcate and classify the boundaries of paddy fields and fields in Korea. Therefore, this study tried to minimize the time and effort required to divide paddy fields and fields through the application of the Farm Map. To improve the fact that UAV image processing for a wide area requires a lot of time and effort to classify objects, we suggest a method for optimizing cultivated crop recognition. This study aimed to evaluate the applicability and effectiveness of machine learning classification techniques using a Farm Map in object-based mapping of agricultural land using unmanned aerial vehicles (UAVs). In this study, the advanced function selection method for object classification is to improve classification accuracy by using two types of classifiers, support vector machine (SVM) and random forest (RF). As a result of classification by applying a Farm Map-based SVM algorithm to wide-area UAV images, producer’s accuracy (PA) was 81.68%, user’s accuracy (UA) was 75.09%, the Kappa coefficient was 0.77, and the F-measure was 0.78. The results of classification by the Farm Map-based RF algorithm were as follows: PA of 96.58%, UA of 92.27%, a Kappa coefficient of 0.94, and the F-measure of 0.94. In the cultivation environment in which various crops were mixed, the corn cultivation area was estimated to be 96.54 ha by SVM, showing an accuracy of 90.27%. RF provided an estimate of 98.77 ha and showed an accuracy of 92.36%, which was higher than that of SVM. As a result of using the Farm Map for the object-based classification method, the agricultural land classification showed a higher efficiency in terms of time than the existing object classification method. Most importantly, it was confirmed that the efficiency of data processing can be increased by minimizing the possibility of misclassification in the obtained results. The obtained results confirmed that rapid and reliable analysis is possible when the cultivated area of crops is identified using UAV images, a Farm Map, and machine learning.
KW  - unmanned aerial vehicles
KW  - Farm Map
KW  - support vector machines
KW  - random forest
DO  - 10.3390/agronomy11081554
ER  -
TY  - EJOU
AU  - Ghajar, Shayan
AU  - Tracy, Benjamin
TI  - Proximal Sensing in Grasslands and Pastures
T2  - Agriculture

PY  - 2021
VL  - 11
IS  - 8
SN  - 2077-0472

AB  - Reliable measures of biomass, species composition, nitrogen status, and nutritive value provide important indicators of the status of pastures and rangelands, allowing managers to make informed decisions. Traditional methods of sample collection necessitate significant investments in time and labor. Proximal sensing technologies have the potential to collect more data with a smaller investment in time and labor. However, methods and protocols for conducting pasture assessments with proximal sensors are still in development, equipment and software vary considerably, and the accuracy and utility of these assessments differ between methods and sites. This review summarizes the methods currently being developed to assess pastures and rangelands worldwide and discusses these emerging technologies in the context of diffusion of innovation theory.
KW  - proximal
KW  - sensing
KW  - LiDAR
KW  - photogrammetry
KW  - grasslands
KW  - pastures
DO  - 10.3390/agriculture11080740
ER  -
TY  - EJOU
AU  - Zhao, Licheng
AU  - Guo, Wei
AU  - Wang, Jian
AU  - Wang, Haozhou
AU  - Duan, Yulin
AU  - Wang, Cong
AU  - Wu, Wenbin
AU  - Shi, Yun
TI  - An Efficient Method for Estimating Wheat Heading Dates Using UAV Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 16
SN  - 2072-4292

AB  - Convenient, efficient, and high-throughput estimation of wheat heading dates is of great significance in plant sciences and agricultural research. However, documenting heading dates is time-consuming, labor-intensive, and subjective on a large-scale field. To overcome these challenges, model- and image-based approaches are used to estimate heading dates. Phenology models usually require complicated parameters calibrations, making it difficult to model other varieties and different locations, while in situ field-image recognition usually requires the deployment of a large amount of observational equipment, which is expensive. Therefore, in this study, we proposed a growth curve-based method for estimating wheat heading dates. The method first generates a height-based continuous growth curve based on five time-series unmanned aerial vehicle (UAV) images captured over the entire wheat growth cycle (&gt;200 d). Then estimate the heading date by generated growth curve. As a result, the proposed method had a mean absolute error of 2.81 d and a root mean square error of 3.49 d for 72 wheat plots composed of different varieties and densities sown on different dates. Thus, the proposed method is straightforward, efficient, and affordable and meets the high-throughput estimation requirements of large-scale fields and underdeveloped areas.
KW  - heading date
KW  - UAV images
KW  - plant height
KW  - growth curve
KW  - wheat
DO  - 10.3390/rs13163067
ER  -
TY  - EJOU
AU  - Perroy, Ryan L.
AU  - Sullivan, Timo
AU  - Benitez, David
AU  - Hughes, R. F.
AU  - Keith, Lisa M.
AU  - Brill, Eva
AU  - Kissinger, Karma
AU  - Duda, Daniel
TI  - Spatial Patterns of ‘Ōhi‘a Mortality Associated with Rapid ‘Ōhi‘a Death and Ungulate Presence
T2  - Forests

PY  - 2021
VL  - 12
IS  - 8
SN  - 1999-4907

AB  - Effective forest management, particularly during forest disturbance events, requires timely and accurate monitoring information at appropriate spatial scales. In Hawai‘i, widespread ‘ōhi‘a (Metrosideros polymorpha Gaud.) mortality associated with introduced fungal pathogens affects forest stands across the archipelago, further impacting native ecosystems already under threat from invasive species. Here, we share results from an integrated monitoring program based on high resolution (&lt;5 cm) aerial imagery, field sampling, and confirmatory laboratory testing to detect and monitor ‘ōhi‘a mortality at the individual tree level across four representative sites on Hawai‘i island. We developed a custom imaging system for helicopter operations to map thousands of hectares (ha) per flight, a more useful scale than the ten to hundreds of ha typically covered using small, unoccupied aerial systems. Based on collected imagery, we developed a rating system of canopy condition to identify ‘ōhi‘a trees suspected of infection by the fungal pathogens responsible for rapid ‘ōhi‘a death (ROD); we used this system to quickly generate and share suspect tree candidate locations with partner agencies to rapidly detect new mortality outbreaks and prioritize field sampling efforts. In three of the four sites, 98% of laboratory samples collected from suspect trees assigned a high confidence rating (n = 50) and 89% of those assigned a medium confidence rating (n = 117) returned positive detections for the fungal pathogens responsible for ROD. The fourth site, which has a history of unexplained ‘ōhi‘a mortality, exhibited much lower positive detection rates: only 6% of sampled trees assigned a high confidence rating (n = 16) and 0% of the sampled suspect trees assigned a medium confidence rating (n = 20) were found to be positive for the pathogen. The disparity in positive detection rates across study sites illustrates challenges to definitively determine the cause of ‘ōhi‘a mortality from aerial imagery alone. Spatial patterns of ROD-associated ‘ōhi‘a mortality were strongly affected by ungulate presence or absence as measured by the density of suspected ROD trees in fenced (i.e., ungulate-free) and unfenced (i.e., ungulate present) areas. Suspected ROD tree densities in neighboring areas containing ungulates were two to 69 times greater than those found in ungulate-free zones. In one study site, a fence line breach occurred during the study period, and feral ungulates entered an area that was previously ungulate-free. Following the breach, suspect ROD tree densities in this area rose from 0.02 to 2.78 suspect trees/ha, highlighting the need for ungulate control to protect ‘ōhi‘a stands from Ceratocystis-induced mortality and repeat monitoring to detect forest changes and resource threats.
KW  - Hawai‘i
KW  - Metrosideros polymorpha
KW  - Ceratocystis lukuohia
KW  - remote sensing
KW  - helicopter
KW  - visible imagery
DO  - 10.3390/f12081035
ER  -
TY  - EJOU
AU  - Pikalov, Simon
AU  - Azaria, Elisha
AU  - Sonnenberg, Shaya
AU  - Ben-Moshe, Boaz
AU  - Azaria, Amos
TI  - Vision-Less Sensing for Autonomous Micro-Drones
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 16
SN  - 1424-8220

AB  - This work presents a concept of intelligent vision-less micro-drones, which are motivated by flying animals such as insects, birds, and bats. The presented micro-drone (named BAT: Blind Autonomous Tiny-drone) can perform bio-inspired complex tasks without the use of cameras. The BAT uses LIDARs and self-emitted optical-flow in order to perform obstacle avoiding and maze-solving. The controlling algorithms were implemented on an onboard micro-controller, allowing the BAT to be fully autonomous. We further present a method for using the information collected by the drone to generate a detailed mapping of the environment. A complete model of the BAT was implemented and tested using several scenarios both in simulation and field experiments, in which it was able to explore and map complex building autonomously even in total darkness.
KW  - autonomous micro-drones
KW  - sensor fusion
KW  - indoor mapping
KW  - bio-inspired micro-robotics
DO  - 10.3390/s21165293
ER  -
TY  - EJOU
AU  - Qi, Guanghui
AU  - Chang, Chunyan
AU  - Yang, Wei
AU  - Gao, Peng
AU  - Zhao, Gengxing
TI  - Soil Salinity Inversion in Coastal Corn Planting Areas by the Satellite-UAV-Ground Integration Approach
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 16
SN  - 2072-4292

AB  - Soil salinization is a significant factor affecting corn growth in coastal areas. How to use multi-source remote sensing data to achieve the target of rapid, efficient and accurate soil salinity monitoring in a large area is worth further study. In this research, using Kenli District of the Yellow River Delta as study area, the inversion of soil salinity in a corn planting area was carried out based on the integration of ground imaging hyperspectral, unmanned aerial vehicles (UAV) multispectral and Sentinel-2A satellite multispectral images. The UAV and ground images were fused, and the partial least squares inversion model was constructed by the fused UAV image. Then, inversion model was scaled up to the satellite by the TsHARP method, and finally, the accuracy of the satellite-UAV-ground inversion model and results was verified. The results show that the band fusion of UAV and ground images effectively enrich the spectral information of the UAV image. The accuracy of the inversion model constructed based on the fused UAV images was improved. The inversion results of soil salinity based on the integration of satellite-UAV-ground were highly consistent with the measured soil salinity (R2 = 0.716 and RMSE = 0.727), and the inversion model had excellent universal applicability. This research integrated the advantages of multi-source data to establish a unified satellite-UAV-ground model, which improved the ability of large-scale remote sensing data to finely indicate soil salinity.
KW  - Sentinel-2A
KW  - UAV
KW  - ground imaging hyperspectral
KW  - multi-source remote sensing data
KW  - soil salinity
DO  - 10.3390/rs13163100
ER  -
TY  - EJOU
AU  - Sinaice, Brian B.
AU  - Owada, Narihiro
AU  - Saadat, Mahdi
AU  - Toriya, Hisatoshi
AU  - Inagaki, Fumiaki
AU  - Bagai, Zibisani
AU  - Kawamura, Youhei
TI  - Coupling NCA Dimensionality Reduction with Machine Learning in Multispectral Rock Classification Problems
T2  - Minerals

PY  - 2021
VL  - 11
IS  - 8
SN  - 2075-163X

AB  - Though multitudes of industries depend on the mining industry for resources, this industry has taken hits in terms of declining mineral ore grades and its current use of traditional, time-consuming and computationally costly rock and mineral identification methods. Therefore, this paper proposes integrating Hyperspectral Imaging, Neighbourhood Component Analysis (NCA) and Machine Learning (ML) as a combined system that can identify rocks and minerals. Modestly put, hyperspectral imaging gathers electromagnetic signatures of the rocks in hundreds of spectral bands. However, this data suffers from what is termed the ‘dimensionality curse’, which led to our employment of NCA as a dimensionality reduction technique. NCA, in turn, highlights the most discriminant feature bands, number of which being dependent on the intended application(s) of this system. Our envisioned application is rock and mineral classification via unmanned aerial vehicle (UAV) drone technology. In this study, we performed a 204-hyperspectral to 5-band multispectral reduction, because current production drones are limited to five multispectral bands sensors. Based on these bands, we applied ML to identify and classify rocks, thereby proving our hypothesis, reducing computational costs, attaining an ML classification accuracy of 71%, and demonstrating the potential mining industry optimisations attainable through this integrated system.
KW  - hyperspectral imaging
KW  - multispectral imaging
KW  - dimensionality reduction
KW  - neighbourhood component analysis
KW  - artificial intelligence
KW  - machine learning
DO  - 10.3390/min11080846
ER  -
TY  - EJOU
AU  - Jembre, Yalew Z.
AU  - Nugroho, Yuniarto W.
AU  - Khan, Muhammad T.
AU  - Attique, Muhammad
AU  - Paul, Rajib
AU  - Shah, Syed H.
AU  - Kim, Beomjoon
TI  - Evaluation of Reinforcement and Deep Learning Algorithms in Controlling Unmanned Aerial Vehicles
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 16
SN  - 2076-3417

AB  - Unmanned Aerial Vehicles (UAVs) are abundantly becoming a part of society, which is a trend that is expected to grow even further. The quadrotor is one of the drone technologies that is applicable in many sectors and in both military and civilian activities, with some applications requiring autonomous flight. However, stability, path planning, and control remain significant challenges in autonomous quadrotor flights. Traditional control algorithms, such as proportional-integral-derivative (PID), have deficiencies, especially in tuning. Recently, machine learning has received great attention in flying UAVs to desired positions autonomously. In this work, we configure the quadrotor to fly autonomously by using agents (the machine learning schemes being used to fly the quadrotor autonomously) to learn about the virtual physical environment. The quadrotor will fly from an initial to a desired position. When the agent brings the quadrotor closer to the desired position, it is rewarded; otherwise, it is punished. Two reinforcement learning models, Q-learning and SARSA, and a deep learning deep Q-network network are used as agents. The simulation is conducted by integrating the robot operating system (ROS) and Gazebo, which allowed for the implementation of the learning algorithms and the physical environment, respectively. The result has shown that the Deep Q-network network with Adadelta optimizer is the best setting to fly the quadrotor from the initial to desired position.
KW  - reinforcement learning
KW  - UAV
KW  - quadrotor
KW  - flight control
KW  - intelligent control
DO  - 10.3390/app11167240
ER  -
TY  - EJOU
AU  - Kim, Yongsu
AU  - Kang, Hyoeun
AU  - Suryanto, Naufal
AU  - Larasati, Harashta T.
AU  - Mukaroh, Afifatul
AU  - Kim, Howon
TI  - Extended Spatially Localized Perturbation GAN (eSLP-GAN) for Robust Adversarial Camouflage Patches
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 16
SN  - 1424-8220

AB  - Deep neural networks (DNNs), especially those used in computer vision, are highly vulnerable to adversarial attacks, such as adversarial perturbations and adversarial patches. Adversarial patches, often considered more appropriate for a real-world attack, are attached to the target object or its surroundings to deceive the target system. However, most previous research employed adversarial patches that are conspicuous to human vision, making them easy to identify and counter. Previously, the spatially localized perturbation GAN (SLP-GAN) was proposed, in which the perturbation was only added to the most representative area of the input images, creating a spatially localized adversarial camouflage patch that excels in terms of visual fidelity and is, therefore, difficult to detect by human vision. In this study, the use of the method called eSLP-GAN was extended to deceive classifiers and object detection systems. Specifically, the loss function was modified for greater compatibility with an object-detection model attack and to increase robustness in the real world. Furthermore, the applicability of the proposed method was tested on the CARLA simulator for a more authentic real-world attack scenario.
KW  - adversarial patch
KW  - generative adversarial networks
KW  - camouflage
DO  - 10.3390/s21165323
ER  -
TY  - EJOU
AU  - Li, Clyde Z.
AU  - Hu, Mingcong
AU  - Xiao, Bing
AU  - Chen, Zhe
AU  - Tam, Vivian W. Y.
AU  - Zhao, Yiyu
TI  - Mapping the Knowledge Domains of Emerging Advanced Technologies in the Management of Prefabricated Construction
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 16
SN  - 2071-1050

AB  - Emerging advanced technologies (EAT) have been regarded as significant technological innovations which can greatly improve the transforming construction industry. Given that research on EAT related to the management of prefabricated construction (MPC) has not yet been conducted, various researchers require a state-of-the-art summary of EAT research and implementation in the MPC field. The purpose of this paper is to provide a systematic literature review by analysing the selected 526 related publications in peer-reviewed leading journals during 2009–2020. Through a thorough review of selected papers from the state-of-the-art academic journals in the construction industry, EAT is recognised as the key area affecting the development of the MPC discipline. This study has value in offering original insights to summarise the advanced status quo of this field, helping subsequent researchers gain an in-depth understanding of the underlying structure of this field and allowing them to continue future research directions.
KW  - emerging advanced technologies
KW  - prefabricated construction
KW  - knowledge map
KW  - literature review
DO  - 10.3390/su13168800
ER  -
TY  - EJOU
AU  - Ramalingam, Balakrishnan
AU  - Tun, Thein
AU  - Mohan, Rajesh E.
AU  - Gómez, Braulio F.
AU  - Cheng, Ruoxi
AU  - Balakrishnan, Selvasundari
AU  - Mohan Rayaguru, Madan
AU  - Hayat, Abdullah A.
TI  - AI Enabled IoRT Framework for Rodent Activity Monitoring in a False Ceiling Environment
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 16
SN  - 1424-8220

AB  - Routine rodent inspection is essential to curbing rat-borne diseases and infrastructure damages within the built environment. Rodents find false ceilings to be a perfect spot to seek shelter and construct their habitats. However, a manual false ceiling inspection for rodents is laborious and risky. This work presents an AI-enabled IoRT framework for rodent activity monitoring inside a false ceiling using an in-house developed robot called “Falcon”. The IoRT serves as a bridge between the users and the robots, through which seamless information sharing takes place. The shared images by the robots are inspected through a Faster RCNN ResNet 101 object detection algorithm, which is used to automatically detect the signs of rodent inside a false ceiling. The efficiency of the rodent activity detection algorithm was tested in a real-world false ceiling environment, and detection accuracy was evaluated with the standard performance metrics. The experimental results indicate that the algorithm detects rodent signs and 3D-printed rodents with a good confidence level.
KW  - rodent detection
KW  - faster RCNN
KW  - deep learning
KW  - object detection
KW  - IoRT
KW  - inspection robot
DO  - 10.3390/s21165326
ER  -
TY  - EJOU
AU  - Zheng, Yuemin
AU  - Tao, Jin
AU  - Sun, Hao
AU  - Sun, Qinglin
AU  - Chen, Zengqiang
AU  - Dehmer, Matthias
AU  - Zhou, Quan
TI  - Load Frequency Active Disturbance Rejection Control for Multi-Source Power System Based on Soft Actor-Critic
T2  - Energies

PY  - 2021
VL  - 14
IS  - 16
SN  - 1996-1073

AB  - To ensure the safe operation of an interconnected power system, it is necessary to maintain the stability of the frequency and the tie-line exchanged power. This is one of the hottest issues in the power system field and is usually called load frequency control. To overcome the influences of load disturbances on multi-source power systems containing thermal power plants, hydropower plants, and gas turbine plants, we design a linear active disturbance rejection control (LADRC) based on the tie-line bias control mode. For LADRC, the parameter selection of the controller directly affects the response performance of the entire system, and it is usually not feasible to manually adjust parameters. Therefore, to obtain the optimal controller parameters, we use the Soft Actor-Critic algorithm in reinforcement learning to obtain the controller parameters in real time, and we design the reward function according to the needs of the power system. We carry out simulation experiments to verify the effectiveness of the proposed method. Compared with the results of other proportional–integral–derivative control techniques using optimization algorithms and LADRC with constant parameters, the proposed method shows significant advantages in terms of overshoot, undershoot, and settling time. In addition, by adding different disturbances to different areas of the multi-source power system, we demonstrate the robustness of the proposed control strategy.
KW  - load frequency control
KW  - linear active disturbance rejection control
KW  - soft actor-critic
KW  - multi-source power system
KW  - reinforcement learning
DO  - 10.3390/en14164804
ER  -
TY  - EJOU
AU  - Safonova, Anastasiia
AU  - Hamad, Yousif
AU  - Dmitriev, Egor
AU  - Georgiev, Georgi
AU  - Trenkin, Vladislav
AU  - Georgieva, Margarita
AU  - Dimitrov, Stelian
AU  - Iliev, Martin
TI  - Individual Tree Crown Delineation for the Species Classification and Assessment of Vital Status of Forest Stands from UAV Images
T2  - Drones

PY  - 2021
VL  - 5
IS  - 3
SN  - 2504-446X

AB  - Monitoring the structure parameters and damage to trees plays an important role in forest management. Remote-sensing data collected by an unmanned aerial vehicle (UAV) provides valuable resources to improve the efficiency of decision making. In this work, we propose an approach to enhance algorithms for species classification and assessment of the vital status of forest stands by using automated individual tree crowns delineation (ITCD). The approach can be potentially used for inventory and identifying the health status of trees in regional-scale forest areas. The proposed ITCD algorithm goes through three stages: preprocessing (contrast enhancement), crown segmentation based on wavelet transformation and morphological operations, and boundaries detection. The performance of the ITCD algorithm was demonstrated for different test plots containing homogeneous and complex structured forest stands. For typical scenes, the crown contouring accuracy is about 95%. The pixel-by-pixel classification is based on the ensemble supervised classification method error correcting output codes with the Gaussian kernel support vector machine chosen as a binary learner. We demonstrated that pixel-by-pixel species classification of multi-spectral images can be performed with a total error of about 1%, which is significantly less than by processing RGB images. The advantage of the proposed approach lies in the combined processing of multispectral and RGB photo images.
KW  - remote sensing
KW  - pattern recognition
KW  - unmanned aerial vehicle
KW  - aerial photo and multispectral images
KW  - individual tree crowns delineation
KW  - species classification
KW  - vital status assessment
DO  - 10.3390/drones5030077
ER  -
TY  - EJOU
AU  - Monteiro, António
AU  - Santos, Sérgio
AU  - Gonçalves, Pedro
TI  - Precision Agriculture for Crop and Livestock Farming—Brief Review
T2  - Animals

PY  - 2021
VL  - 11
IS  - 8
SN  - 2076-2615

AB  - In the last few decades, agriculture has played an important role in the worldwide economy. The need to produce more food for a rapidly growing population is creating pressure on crop and animal production and a negative impact to the environment. On the other hand, smart farming technologies are becoming increasingly common in modern agriculture to assist in optimizing agricultural and livestock production and minimizing the wastes and costs. Precision agriculture (PA) is a technology-enabled, data-driven approach to farming management that observes, measures, and analyzes the needs of individual fields and crops. Precision livestock farming (PLF), relying on the automatic monitoring of individual animals, is used for animal growth, milk production, and the detection of diseases as well as to monitor animal behavior and their physical environment, among others. This study aims to briefly review recent scientific and technological trends in PA and their application in crop and livestock farming, serving as a simple research guide for the researcher and farmer in the application of technology to agriculture. The development and operation of PA applications involve several steps and techniques that need to be investigated further to make the developed systems accurate and implementable in commercial environments.
KW  - crop and animal production
KW  - smart farming technologies
KW  - precision agriculture
KW  - precision livestock farming
KW  - trends
DO  - 10.3390/ani11082345
ER  -
TY  - EJOU
AU  - Zhang, Qiang
AU  - Sun, Banyong
AU  - Cheng, Yaxiong
AU  - Li, Xijie
TI  - Residual Self-Calibration and Self-Attention Aggregation Network for Crop Disease Recognition
T2  - International Journal of Environmental Research and Public Health

PY  - 2021
VL  - 18
IS  - 16
SN  - 1660-4601

AB  - The correct diagnosis and recognition of crop diseases play an important role in ensuring crop yields and preventing food safety. The existing methods for crop disease recognition mainly focus on accuracy while ignoring the algorithm’s robustness. In practice, the acquired images are often accompanied by various noises. These noises lead to a huge challenge for improving the robustness and accuracy of the recognition algorithm. In order to solve this problem, this paper proposes a residual self-calibration and self-attention aggregation network (RCAA-Net) for crop disease recognition in actual scenarios. The proposed RCAA-Net is composed of three main modules: (1) multi-scale residual module, (2) feedback self-calibration module, and (3) self-attention aggregation module. Specifically, the multi-scale residual module is designed to learn multi-scale features and provide both global and local information for the appearance of the disease to improve the performance of the model. The feedback self-calibration is proposed to improve the robustness of the model by suppressing the background noise in the original deep features. The self-attention aggregation module is introduced to further improve the robustness and accuracy of the model by capturing multi-scale information in different semantic spaces. The experimental results on the challenging 2018ai_challenger crop disease recognition dataset show that the proposed RCAA-Net achieves state-of-the-art performance on robustness and accuracy for crop disease recognition in actual scenarios.
KW  - crop disease recognition
KW  - self-calibration
KW  - self-attention
KW  - residual
DO  - 10.3390/ijerph18168404
ER  -
TY  - EJOU
AU  - Yu, Bo
AU  - Chen, Fang
AU  - Xu, Chong
AU  - Wang, Lei
AU  - Wang, Ning
TI  - Matrix SegNet: A Practical Deep Learning Framework for Landslide Mapping from Images of Different Areas with Different Spatial Resolutions
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 16
SN  - 2072-4292

AB  - Practical landslide inventory maps covering large-scale areas are essential in emergency response and geohazard analysis. Recently proposed techniques in landslide detection generally focused on landslides in pure vegetation backgrounds and image radiometric correction. There are still challenges in regard to robust methods that automatically detect landslides from images with multiple platforms and without radiometric correction. It is a significant issue in practical application. In order to detect landslides from images over different large-scale areas with different spatial resolutions, this paper proposes a two-branch Matrix SegNet to semantically segment input images by change detection. The Matrix SegNet learns landslide features in multiple scales and aspect ratios. The pre- and post- event images are captured directly from Google Earth, without radiometric correction. To evaluate the proposed framework, we conducted landslide detection in four study areas with two different spatial resolutions. Moreover, two other widely used frameworks: U-Net and SegNet, were adapted to detect landslides via the same data by change detection. The experiments show that our model improves the performance largely in terms of recall, precision, F1-score, and IOU. It is a good starting point to develop a practical, deep learning landslide detection framework for large scale application, using images from different areas, with different spatial resolutions.
KW  - landslide detection
KW  - Matrix nets
KW  - different spatial resolutions
DO  - 10.3390/rs13163158
ER  -
TY  - EJOU
AU  - Wang, Zi-Hao
AU  - Chen, Wen-Jie
AU  - Qin, Kai-Yu
TI  - Dynamic Target Tracking and Ingressing of a Small UAV Using Monocular Sensor Based on the Geometric Constraints
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 16
SN  - 2079-9292

AB  - In many applications of airborne visual techniques for unmanned aerial vehicles (UAVs), lightweight sensors and efficient visual positioning and tracking algorithms are essential in a GNSS-denied environment. Meanwhile, many tasks require the ability of recognition, localization, avoiding, or flying pass through these dynamic obstacles. In this paper, for a small UAV equipped with a lightweight monocular sensor, a single-frame parallel-features positioning method (SPPM) is proposed and verified for a real-time dynamic target tracking and ingressing problem. The solution is featured with systematic modeling of the geometric characteristics of moving targets, and the introduction of numeric iteration algorithms to estimate the geometric center of moving targets. The geometric constraint relationships of the target feature points are modeled as non-linear equations for scale estimation. Experiments show that the root mean square error percentage of static target tracking is less than 1.03% and the root mean square error of dynamic target tracking is less than 7.92 cm. Comprehensive indoor flight experiments are conducted to show the real-time convergence of the algorithm, the effectiveness of the solution in locating and tracking a moving target, and the excellent robustness to measurement noises.
KW  - target tracking
KW  - dynamic target ingress
KW  - obstacle avoidance
KW  - geometric constraint equations
KW  - newton numerical optimization
KW  - unmanned aerial vehicles navigation
DO  - 10.3390/electronics10161931
ER  -
TY  - EJOU
AU  - Takechi, Hitoshi
AU  - Aragaki, Shunsuke
AU  - Irie, Mitsuteru
TI  - Differentiation of River Sediments Fractions in UAV Aerial Images by Convolution Neural Network
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 16
SN  - 2072-4292

AB  - Riverbed material has multiple functions in river ecosystems, such as habitats, feeding grounds, spawning grounds, and shelters for aquatic organisms, and particle size of riverbed material reflects the tractive force of the channel flow. Therefore, regular surveys of riverbed material are conducted for environmental protection and river flood control projects. The field method is the most conventional riverbed material survey. However, conventional surveys of particle size of riverbed material require much labor, time, and cost to collect material on site. Furthermore, its spatial representativeness is also a problem because of the limited survey area against a wide riverbank. As a further solution to these problems, in this study, we tried an automatic classification of riverbed conditions using aerial photography with an unmanned aerial vehicle (UAV) and image recognition with artificial intelligence (AI) to improve survey efficiency. Due to using AI for image processing, a large number of images can be handled regardless of whether they are of fine or coarse particles. We tried a classification of aerial riverbed images that have the difference of particle size characteristics with a convolutional neural network (CNN). GoogLeNet, Alexnet, VGG-16 and ResNet, the common pre-trained networks, were retrained to perform the new task with the 70 riverbed images using transfer learning. Among the networks tested, GoogleNet showed the best performance for this study. The overall accuracy of the image classification reached 95.4%. On the other hand, it was supposed that shadows of the gravels caused the error of the classification. The network retrained with the images taken in the uniform temporal period gives higher accuracy for classifying the images taken in the same period as the training data. The results suggest the potential of evaluating riverbed materials using aerial photography with UAV and image recognition with CNN.
KW  - channel bed condition
KW  - particle size
KW  - convolution neural network
KW  - UAV
DO  - 10.3390/rs13163188
ER  -
TY  - EJOU
AU  - Li, Kai-Yun
AU  - Burnside, Niall G.
AU  - de Lima, Raul S.
AU  - Peciña, Miguel V.
AU  - Sepp, Karli
AU  - Cabral Pinheiro, Victor H.
AU  - de Lima, Bruno R.
AU  - Yang, Ming-Der
AU  - Vain, Ants
AU  - Sepp, Kalev
TI  - An Automated Machine Learning Framework in Unmanned Aircraft Systems: New Insights into Agricultural Management Practices Recognition Approaches
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 16
SN  - 2072-4292

AB  - The recent trend of automated machine learning (AutoML) has been driving further significant technological innovation in the application of artificial intelligence from its automated algorithm selection and hyperparameter optimization of the deployable pipeline model for unraveling substance problems. However, a current knowledge gap lies in the integration of AutoML technology and unmanned aircraft systems (UAS) within image-based data classification tasks. Therefore, we employed a state-of-the-art (SOTA) and completely open-source AutoML framework, Auto-sklearn, which was constructed based on one of the most widely used ML systems: Scikit-learn. It was combined with two novel AutoML visualization tools to focus particularly on the recognition and adoption of UAS-derived multispectral vegetation indices (VI) data across a diverse range of agricultural management practices (AMP). These include soil tillage methods (STM), cultivation methods (CM), and manure application (MA), and are under the four-crop combination fields (i.e., red clover-grass mixture, spring wheat, pea-oat mixture, and spring barley). Furthermore, they have currently not been efficiently examined and accessible parameters in UAS applications are absent for them. We conducted the comparison of AutoML performance using three other common machine learning classifiers, namely Random Forest (RF), support vector machine (SVM), and artificial neural network (ANN). The results showed AutoML achieved the highest overall classification accuracy numbers after 1200 s of calculation. RF yielded the second-best classification accuracy, and SVM and ANN were revealed to be less capable among some of the given datasets. Regarding the classification of AMPs, the best recognized period for data capture occurred in the crop vegetative growth stage (in May). The results demonstrated that CM yielded the best performance in terms of classification, followed by MA and STM. Our framework presents new insights into plant–environment interactions with capable classification capabilities. It further illustrated the automatic system would become an important tool in furthering the understanding for future sustainable smart farming and field-based crop phenotyping research across a diverse range of agricultural environmental assessment and management applications.
KW  - unmanned aircraft system
KW  - automated machine learning
KW  - agricultural management practices
KW  - image classification
KW  - precision agriculture
KW  - variety performance trials
KW  - crop breeding
KW  - crop phenotyping
KW  - agriculture decision-making
DO  - 10.3390/rs13163190
ER  -
TY  - EJOU
AU  - Ezzy, Haitham
AU  - Charter, Motti
AU  - Bonfante, Antonello
AU  - Brook, Anna
TI  - How the Small Object Detection via Machine Learning and UAS-Based Remote-Sensing Imagery Can Support the Achievement of SDG2: A Case Study of Vole Burrows
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 16
SN  - 2072-4292

AB  - Small mammals, and particularly rodents, are common inhabitants of farmlands, where they play key roles in the ecosystem, but when overabundant, they can be major pests, able to reduce crop production and farmers’ incomes, with tangible effects on the achievement of Sustainable Development Goals no 2 (SDG2, Zero Hunger) of the United Nations. Farmers do not currently have a standardized, accurate method of detecting the presence, abundance, and locations of rodents in their fields, and hence do not have environmentally efficient methods of rodent control able to promote sustainable agriculture oriented to reduce the environmental impacts of cultivation. New developments in unmanned aerial system (UAS) platforms and sensor technology facilitate cost-effective data collection through simultaneous multimodal data collection approaches at very high spatial resolutions in environmental and agricultural contexts. Object detection from remote-sensing images has been an active research topic over the last decade. With recent increases in computational resources and data availability, deep learning-based object detection methods are beginning to play an important role in advancing remote-sensing commercial and scientific applications. However, the performance of current detectors on various UAS-based datasets, including multimodal spatial and physical datasets, remains limited in terms of small object detection. In particular, the ability to quickly detect small objects from a large observed scene (at field scale) is still an open question. In this paper, we compare the efficiencies of applying one- and two-stage detector models to a single UAS-based image and a processed (via Pix4D mapper photogrammetric program) UAS-based orthophoto product to detect rodent burrows, for agriculture/environmental applications as to support farmer activities in the achievements of SDG2. Our results indicate that the use of multimodal data from low-cost UASs within a self-training YOLOv3 model can provide relatively accurate and robust detection for small objects (mAP of 0.86 and an F1-score of 93.39%), and can deliver valuable insights for field management with high spatial precision able to reduce the environmental costs of crop production in the direction of precision agriculture management.
KW  - small object detection
KW  - UAS
KW  - YOLOv3
KW  - Faster R-CNN
KW  - EfficientNet
KW  - RetinaNet
DO  - 10.3390/rs13163191
ER  -
TY  - EJOU
AU  - Zhang, Binghan
AU  - Yang, Bin
AU  - Wang, Congjun
AU  - Wang, Zhichen
AU  - Liu, Boda
AU  - Fang, Tengwei
TI  - Computer Vision-Based Construction Process Sensing for Cyber–Physical Systems: A Review
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 16
SN  - 1424-8220

AB  - Cyber–physical systems (CPSs) are generally considered to be the next generation of engineered systems. However, the actual application of CPSs in the Architecture, Engineering and Construction (AEC) industry is still at a low level. The sensing method in the construction process plays a very important role in the establishment of CPSs. Therefore, the purpose of this paper is to discuss the application potential of computer vision-based sensing methods and provide practical suggestions through a literature review. This paper provides a review of the current application of CPSs in the AEC industry, summarizes the current knowledge gaps, and discusses the problems with the current construction site sensing approach. Considering the unique advantages of the computer vision (CV) method at the construction site, the application of CV for different construction entities was reviewed and summarized to achieve a CV-based construction site sensing approach for construction process CPSs. The potential of CPS can be further stimulated by providing rich information from on-site sensing using CV methods. According to the review, this approach has unique advantages in the specific environment of the construction site. Based on the current knowledge gap identified in the literature review, this paper proposes a novel concept of visual-based construction site sensing method for CPS application, and an architecture for CV-based CPS is proposed as an implementation of this concept. The main contribution of this paper is to propose a CPS architecture using computer vision as the main information acquisition method based on the literature review. This architecture innovatively introduces computer vision as a sensing method of construction sites, and realizes low-cost and non-invasive information acquisition in complex construction scenarios. This method can be used as an important supplement to on-site sensing to further promote the automation and intelligence of the construction process.
KW  - computer vision
KW  - cyber–physical systems
KW  - sensing system
KW  - review
DO  - 10.3390/s21165468
ER  -
TY  - EJOU
AU  - Wang, Rui
AU  - Zou, Jialing
AU  - Wen, James Z.
TI  - SFA-MDEN: Semantic-Feature-Aided Monocular Depth Estimation Network Using Dual Branches
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 16
SN  - 1424-8220

AB  - Monocular depth estimation based on unsupervised learning has attracted great attention due to the rising demand for lightweight monocular vision sensors. Inspired by multi-task learning, semantic information has been used to improve the monocular depth estimation models. However, multi-task learning is still limited by multi-type annotations. As far as we know, there are scarcely any large public datasets that provide all the necessary information. Therefore, we propose a novel network architecture Semantic-Feature-Aided Monocular Depth Estimation Network (SFA-MDEN) to extract multi-resolution depth features and semantic features, which are merged and fed into the decoder, with the goal of predicting depth with the support of semantics. Instead of using loss functions to relate the semantics and depth, the fusion of feature maps for semantics and depth is employed to predict the monocular depth. Therefore, two accessible datasets with similar topics for depth estimation and semantic segmentation can meet the requirements of SFA-MDEN for training sets. We explored the performance of the proposed SFA-MDEN with experiments on different datasets, including KITTI, Make3D, and our own dataset BHDE-v1. The experimental results demonstrate that SFA-MDEN achieves competitive accuracy and generalization capacity compared to state-of-the-art methods.
KW  - monocular depth estimation
KW  - semantic segmentation
KW  - feature fusion
KW  - multi-task deep learning
DO  - 10.3390/s21165476
ER  -
TY  - EJOU
AU  - Munawar, Hafiz S.
AU  - Hammad, Ahmed W. A.
AU  - Haddad, Assed
AU  - Soares, Carlos A.
AU  - Waller, S. T.
TI  - Image-Based Crack Detection Methods: A Review
T2  - Infrastructures

PY  - 2021
VL  - 6
IS  - 8
SN  - 2412-3811

AB  - Annually, millions of dollars are spent to carry out defect detection in key infrastructure including roads, bridges, and buildings. The aftermath of natural disasters like floods and earthquakes leads to severe damage to the urban infrastructure. Maintenance operations that follow for the damaged infrastructure often involve a visual inspection and assessment of their state to ensure their functional and physical integrity. Such damage may appear in the form of minor or major cracks, which gradually spread, leading to ultimate collapse or destruction of the structure. Crack detection is a very laborious task if performed via manual visual inspection. Many infrastructure elements need to be checked regularly and it is therefore not feasible as it will require significant human resources. This may also result in cases where cracks go undetected. A need, therefore, exists for performing automatic defect detection in infrastructure to ensure its effectiveness and reliability. Using image processing techniques, the captured or scanned images of the infrastructure parts can be analyzed to identify any possible defects. Apart from image processing, machine learning methods are being increasingly applied to ensure better performance outcomes and robustness in crack detection. This paper provides a review of image-based crack detection techniques which implement image processing and/or machine learning. A total of 30 research articles have been collected for the review which is published in top tier journals and conferences in the past decade. A comprehensive analysis and comparison of these methods are performed to highlight the most promising automated approaches for crack detection.
KW  - crack detection
KW  - machine learning
KW  - artificial intelligence
KW  - image processing
DO  - 10.3390/infrastructures6080115
ER  -
TY  - EJOU
AU  - Zuo, Mingjiu
AU  - Wang, Guandao
AU  - Xiao, Yongxin
AU  - Xiang, Gong
TI  - A Unified Approach for Underwater Homing and Docking of over-Actuated AUV
T2  - Journal of Marine Science and Engineering

PY  - 2021
VL  - 9
IS  - 8
SN  - 2077-1312

AB  - During the implementation of time-consuming tasks such as underwater observation or detection, AUV has to face a difficult and urgent problem that its working duration is greatly shortened by the limited energy stored in the battery device. To solve the power problem, a docking station is installed underwater for AUV charging its battery. However, to realize the automatic underwater charging of AUV via a docking station, the accurate and efficient completion of underwater homing and docking is required for AUV. Underwater automatic homing and docking system is of great significance to improve work efficiency and prolong the endurance of AUV save cost. In this paper, a unified approach that involves such as task planning, guidance and control design, thrust allocation has been proposed to provide a complete solution to the problem of homing and docking of an over-actuated AUV. The task-based hybrid target point/line planning and following strategy are proposed for AUV homing and docking. At the beginning of homing, AUV is planned to follow a straight line via the line of sight (LoS) method. Afterward, AUV starts to follow multiple predefined target points until reaching the docking station. At the final stage of docking (within 10 m), a dedicated computer vision algorithm is applied to detect a newly designed LED light array fixed on the docking station to provide accurate guidance for the AUV to dock. The sliding mode control technique is used for the motion control of the AUV allowing robustness. As the AUV configured with eight thrusters is over-actuated, the problem of the thrust allocation is very important and successfully solved using the quadratic programming (QP) optimization method. Finally, the simulations of homing and docking tasks using the AUV are accomplished to verify the proposed approach.
KW  - AUV
KW  - homing and docking
KW  - vision-based guidance
KW  - target point/line planning and following
KW  - thrust allocation
DO  - 10.3390/jmse9080884
ER  -
TY  - EJOU
AU  - Shen, Shengyu
AU  - Chen, Jiasheng
AU  - Zhang, Shaoyi
AU  - Cheng, Dongbing
AU  - Wang, Zhigang
AU  - Zhang, Tong
TI  - Deep Fusion of DOM and DSM Features for Benggang Discovery
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 8
SN  - 2220-9964

AB  - Benggang is a typical erosional landform in southern and southeastern China. Since benggang poses significant risks to local ecological environments and economic infrastructure, it is vital to accurately detect benggang-eroded areas. Relying only on remote sensing imagery for benggang detection cannot produce satisfactory results. In this study, we propose integrating high-resolution Digital Orthophoto Map (DOM) and Digital Surface Model (DSM) data for efficient and automatic benggang discovery. The fusion of complementary rich information hidden in both DOM and DSM data is realized by a two-stream convolutional neural network (CNN), which integrates aggregated terrain and activation image features that are both extracted by supervised deep learning. We aggregate local low-level geomorphic features via a supervised diffusion-convolutional embedding branch for expressive representations of benggang terrain variations. Activation image features are obtained from an image-oriented convolutional neural network branch. The two sources of information (DOM and DSM) are fused via a gated neural network, which learns the most discriminative features for the detection of benggang. The evaluation of a challenging benggang dataset demonstrates that our method exceeds several baselines, even with limited training examples. The results show that the fusion of DOM and DSM data is beneficial for benggang detection via supervised convolutional and deep fusion networks.
KW  - benggang
KW  - deep learning
KW  - fusion
KW  - CNN
KW  - DOM
KW  - DSM
DO  - 10.3390/ijgi10080556
ER  -
TY  - EJOU
AU  - Tina, Giuseppe M.
AU  - Ventura, Cristina
AU  - Ferlito, Sergio
AU  - De Vito, Saverio
TI  - A State-of-Art-Review on Machine-Learning Based Methods for PV
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 16
SN  - 2076-3417

AB  - In the current era, Artificial Intelligence (AI) is becoming increasingly pervasive with applications in several applicative fields effectively changing our daily life. In this scenario, machine learning (ML), a subset of AI techniques, provides machines with the ability to programmatically learn from data to model a system while adapting to new situations as they learn more by data they are ingesting (on-line training). During the last several years, many papers have been published concerning ML applications in the field of solar systems. This paper presents the state of the art ML models applied in solar energy’s forecasting field i.e., for solar irradiance and power production forecasting (both point and interval or probabilistic forecasting), electricity price forecasting and energy demand forecasting. Other applications of ML into the photovoltaic (PV) field taken into account are the modelling of PV modules, PV design parameter extraction, tracking the maximum power point (MPP), PV systems efficiency optimization, PV/Thermal (PV/T) and Concentrating PV (CPV) system design parameters’ optimization and efficiency improvement, anomaly detection and energy management of PV’s storage systems. While many review papers already exist in this regard, they are usually focused only on one specific topic, while in this paper are gathered all the most relevant applications of ML for solar systems in many different fields. The paper gives an overview of the most recent and promising applications of machine learning used in the field of photovoltaic systems.
KW  - machine learning
KW  - solar energy
KW  - forecast
KW  - diagnostic
KW  - electricity markets
DO  - 10.3390/app11167550
ER  -
TY  - EJOU
AU  - Wang, Kaixuan
AU  - Zhang, Jiaqiao
AU  - Ni, Hongjun
AU  - Ren, Fuji
TI  - Thermal Defect Detection for Substation Equipment Based on Infrared Image Using Convolutional Neural Network
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 16
SN  - 2079-9292

AB  - Thermal defects of substation equipment have a great impact on the stability of power systems. Temperature is crucial for thermal defect detection in infrared images. The traditional detection methods, which have low efficiency and poor accuracy, record the temperature of infrared images manually. In this study, a thermal defect detection method based on infrared images using a convolutional neural network (CNN) is proposed. Firstly, the improved pre-processing method is applied to reduce background information, and the region of interest is located according to the contour and position information, hence improving the quality of images. Then, the temperature values are segmented to establish the dataset (T-IR11), which contains 11 labels. Finally, the CNN model is constructed to extract features, and the support vector machine is trained for classification. To verify the effectiveness of the proposed method, precision, recall, and F1 score are adopted and 10-fold cross-validation is employed on the T-IR11 dataset. The results demonstrate that the accuracy of the proposed method is 99.50%, and the performance is superior to that of previous methods in terms of infrared images. The proposed method can realize automatic temperature recognition and equipment with thermal defects can be recorded systematically, which has significant practical value for defect detection in substation equipment.
KW  - infrared image
KW  - substation equipment
KW  - thermal defect detection
KW  - adaptive binarization
KW  - character recognition
KW  - convolutional neural network
DO  - 10.3390/electronics10161986
ER  -
TY  - EJOU
AU  - Malbéteau, Yoann
AU  - Johansen, Kasper
AU  - Aragon, Bruno
AU  - Al-Mashhawari, Samir K.
AU  - McCabe, Matthew F.
TI  - Overcoming the Challenges of Thermal Infrared Orthomosaics Using a Swath-Based Approach to Correct for Dynamic Temperature and Wind Effects
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 16
SN  - 2072-4292

AB  - The miniaturization of thermal infrared sensors suitable for integration with unmanned aerial vehicles (UAVs) has provided new opportunities to observe surface temperature at ultra-high spatial and temporal resolutions. In parallel, there has been a rapid development of software capable of streamlining the generation of orthomosaics. However, these approaches were developed to process optical and multi-spectral image data and were not designed to account for the often rapidly changing surface characteristics inherent in the collection and processing of thermal data. Although radiometric calibration and shutter correction of uncooled sensors have improved, the processing of thermal image data remains difficult due to (1) vignetting effects on the uncooled microbolometer focal plane array; (2) inconsistencies between images relative to in-flight effects (wind-speed and direction); (3) unsuitable methods for thermal infrared orthomosaic generation. Here, we use thermal infrared UAV data collected with a FLIR-based TeAx camera over an agricultural field at different times of the day to assess inconsistencies in orthophotos and their impact on UAV-based thermal infrared orthomosaics. Depending on the wind direction and speed, we found a significant difference in UAV-based surface temperature (up to 2 °C) within overlapping areas of neighboring flight lines, with orthophotos collected with tail wind being systematically cooler than those with head wind. To address these issues, we introduce a new swath-based mosaicking approach, which was compared to three standard blending modes for orthomosaic generation. The swath-based mosaicking approach improves the ability to identify rapid changes of surface temperature during data acquisition, corrects for the influence of flight direction relative to the wind orientation, and provides uncertainty (pixel-based standard deviation) maps to accompany the orthomosaic of surface temperature. It also produced more accurate temperature retrievals than the other three standard orthomosaicking methods, with a root mean square error of 1.2 °C when assessed against in situ measurements. As importantly, our findings demonstrate that thermal infrared data require appropriate processing to reduce inconsistencies between observations, and thus, improve the accuracy and utility of orthomosaics.
KW  - thermal infrared
KW  - unmanned aerial vehicle
KW  - UAV
KW  - wind
KW  - flight direction
KW  - orthomosaic
KW  - precision agriculture
KW  - temperature
DO  - 10.3390/rs13163255
ER  -
TY  - EJOU
AU  - Liu, Zhijie
AU  - Guo, Pengju
AU  - Liu, Heng
AU  - Fan, Pan
AU  - Zeng, Pengzong
AU  - Liu, Xiangyang
AU  - Feng, Ce
AU  - Wang, Wang
AU  - Yang, Fuzeng
TI  - Gradient Boosting Estimation of the Leaf Area Index of Apple Orchards in UAV Remote Sensing
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 16
SN  - 2072-4292

AB  - The leaf area index (LAI) is a key parameter for describing the canopy structure of apple trees. This index is also employed in evaluating the amount of pesticide sprayed per unit volume of apple trees. Hence, numerous manual and automatic methods have been explored for LAI estimation. In this work, the leaf area indices for different types of apple trees are obtained in terms of multispectral remote-sensing data collected with an unmanned aerial vehicle (UAV), along with simultaneous measurements of apple orchards. The proposed approach was tested on apple trees of the “Fuji”, “Golden Delicious”, and “Ruixue” types, which were planted in the Apple Experimental Station of the Northwest Agriculture and Forestry University in Baishui County, Shaanxi Province, China. Five vegetation indices of strong correlation with the apple leaf area index were selected and used to train models of support vector regression (SVR) and gradient-boosting decision trees (GBDT) for predicting the leaf area index of apple trees. The best model was selected based on the metrics of the coefficient of determination (R2) and the root-mean-square error (RMSE). The experimental results showed that the gradient-boosting decision tree model achieved the best performance with an R2 of 0.846, an RMSE of 0.356, and a spatial efficiency (SPAEF) of 0.57. This demonstrates the feasibility of our approach for fast and accurate remote-sensing-based estimation of the leaf area index of apple trees.
KW  - leaf area index
KW  - gradient-boosting decision trees
KW  - UAV remote sensing
KW  - apple orchards
KW  - vegetation index
DO  - 10.3390/rs13163263
ER  -
TY  - EJOU
AU  - Ivošević, Bojana
AU  - Lugonja, Predrag
AU  - Brdar, Sanja
AU  - Radulović, Mirjana
AU  - Vujić, Ante
AU  - Valente, João
TI  - UAV-Based Land Cover Classification for Hoverfly (Diptera: Syrphidae) Habitat Condition Assessment: A Case Study on Mt. Stara Planina (Serbia)
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 16
SN  - 2072-4292

AB  - Habitat degradation, mostly caused by human impact, is one of the key drivers of biodiversity loss. This is a global problem, causing a decline in the number of pollinators, such as hoverflies. In the process of digitalizing ecological studies in Serbia, remote-sensing-based land cover classification has become a key component for both current and future research. Object-based land cover classification, using machine learning algorithms of very high resolution (VHR) imagery acquired by an unmanned aerial vehicle (UAV) was carried out in three different study sites on Mt. Stara Planina, Eastern Serbia. UAV land cover classified maps with seven land cover classes (trees, shrubs, meadows, road, water, agricultural land, and forest patches) were studied. Moreover, three different classification algorithms—support vector machine (SVM), random forest (RF), and k-NN (k-nearest neighbors)—were compared. This study shows that the random forest classifier performs better with respect to the other classifiers in all three study sites, with overall accuracy values ranging from 0.87 to 0.96. The overall results are robust to changes in labeling ground truth subsets. The obtained UAV land cover classified maps were compared with the Map of the Natural Vegetation of Europe (EPNV) and used to quantify habitat degradation and assess hoverfly species richness. It was concluded that the percentage of habitat degradation is primarily caused by anthropogenic pressure, thus affecting the richness of hoverfly species in the study sites. In order to enable research reproducibility, the datasets used in this study are made available in a public repository.
KW  - unmanned aerial vehicle
KW  - object-based image analysis
KW  - Orfeo ToolBox
KW  - QGIS
KW  - random forest
KW  - hoverfly
KW  - Map of the Natural Vegetation of Europe
DO  - 10.3390/rs13163272
ER  -
TY  - EJOU
AU  - Ulhaq, Anwaar
AU  - Adams, Peter
AU  - Cox, Tarnya E.
AU  - Khan, Asim
AU  - Low, Tom
AU  - Paul, Manoranjan
TI  - Automated Detection of Animals in Low-Resolution Airborne Thermal Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 16
SN  - 2072-4292

AB  - Detecting animals to estimate abundance can be difficult, particularly when the habitat is dense or the target animals are fossorial. The recent surge in the use of thermal imagers in ecology and their use in animal detections can increase the accuracy of population estimates and improve the subsequent implementation of management programs. However, the use of thermal imagers results in many hours of captured flight videos which require manual review for confirmation of species detection and identification. Therefore, the perceived cost and efficiency trade-off often restricts the use of these systems. Additionally, for many off-the-shelf systems, the exported imagery can be quite low resolution (&lt;9 Hz), increasing the difficulty of using automated detections algorithms to streamline the review process. This paper presents an animal species detection system that utilises the cost-effectiveness of these lower resolution thermal imagers while harnessing the power of transfer learning and an enhanced small object detection algorithm. We have proposed a distant object detection algorithm named Distant-YOLO (D-YOLO) that utilises YOLO (You Only Look Once) and improves its training and structure for the automated detection of target objects in thermal imagery. We trained our system on thermal imaging data of rabbits, their active warrens, feral pigs, and kangaroos collected by thermal imaging researchers in New South Wales and Western Australia. This work will enhance the visual analysis of animal species while performing well on low, medium and high-resolution thermal imagery.
KW  - invasive species
KW  - thermal imaging
KW  - habitat identification
KW  - deep learning
KW  - drone
DO  - 10.3390/rs13163276
ER  -
TY  - EJOU
AU  - Martins, Leandro do C.
AU  - Tordecilla, Rafael D.
AU  - Castaneda, Juliana
AU  - Juan, Angel A.
AU  - Faulin, Javier
TI  - Electric Vehicle Routing, Arc Routing, and Team Orienteering Problems in Sustainable Transportation
T2  - Energies

PY  - 2021
VL  - 14
IS  - 16
SN  - 1996-1073

AB  - The increasing use of electric vehicles in road and air transportation, especially in last-mile delivery and city mobility, raises new operational challenges due to the limited capacity of electric batteries. These limitations impose additional driving range constraints when optimizing the distribution and mobility plans. During the last years, several researchers from the Computer Science, Artificial Intelligence, and Operations Research communities have been developing optimization, simulation, and machine learning approaches that aim at generating efficient and sustainable routing plans for hybrid fleets, including both electric and internal combustion engine vehicles. After contextualizing the relevance of electric vehicles in promoting sustainable transportation practices, this paper reviews the existing work in the field of electric vehicle routing problems. In particular, we focus on articles related to the well-known vehicle routing, arc routing, and team orienteering problems. The review is followed by numerical examples that illustrate the gains that can be obtained by employing optimization methods in the aforementioned field. Finally, several research opportunities are highlighted.
KW  - electric batteries
KW  - vehicle routing problem
KW  - arc routing problem
KW  - team orienteering problem
DO  - 10.3390/en14165131
ER  -
TY  - EJOU
AU  - Shan, Donghui
AU  - Lei, Tian
AU  - Yin, Xiaohong
AU  - Luo, Qin
AU  - Gong, Lei
TI  - Extracting Key Traffic Parameters from UAV Video with On-Board Vehicle Data Validation
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 16
SN  - 1424-8220

AB  - The advantages of UAV video in flexibility, traceability, easy-operation, and abundant information make it a popular and powerful aerial tool applied in traffic monitoring in recent years. This paper proposed a systematic approach to detect and track vehicles based on the YOLO v3 model and the deep SORT algorithm for further extracting key traffic parameters. A field experiment was implemented to provide data for model training and validation to ensure the accuracy of the proposed approach. In the experiment, 5400 frame images and 1192 speed points were collected from two test vehicles equipped with high-precision GNSS-RTK and onboard OBD after completion of seven experimental groups with a different height (150 m to 500 m) and operating speed (40 km/h to 90 km/h). The results indicate that the proposed approach exhibits strong robustness and reliability, due to the 90.88% accuracy of object detection and 98.9% precision of tracking vehicle. Moreover, the absolute and relative error of extracted speed falls within ±3 km/h and 2%, respectively. The overall accuracy of the extracted parameters reaches up to 98%.
KW  - UAV video
KW  - traffic information extraction
KW  - vehicle detection and tracking
KW  - validation experiment
KW  - accuracy
DO  - 10.3390/s21165620
ER  -
TY  - EJOU
AU  - Li, Xuanye
AU  - Li, Hongguang
AU  - Jiang, Yalong
AU  - Wang, Meng
TI  - Lightweight Detection Network Based on Sub-Pixel Convolution and Objectness-Aware Structure for UAV Images
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 16
SN  - 1424-8220

AB  - Unmanned Aerial Vehicles (UAVs) can serve as an ideal mobile platform in various situations. Real-time object detection with on-board apparatus provides drones with increased flexibility as well as a higher intelligence level. In order to achieve good detection results in UAV images with complex ground scenes, small object size and high object density, most of the previous work introduced models with higher computational burdens, making deployment on mobile platforms more difficult.This paper puts forward a lightweight object detection framework. Besides being anchor-free, the framework is based on a lightweight backbone and a simultaneous up-sampling and detection module to form a more efficient detection architecture. Meanwhile, we add an objectness branch to assist the multi-class center point prediction, which notably improves the detection accuracy and only takes up very little computing resources. The results of the experiment indicate that the computational cost of this paper is 92.78% lower than the CenterNet with ResNet18 backbone, and the mAP is 2.8 points higher on the Visdrone-2018-VID dataset. A frame rate of about 220 FPS is achieved. Additionally, we perform ablation experiments to check on the validity of each part, and the method we propose is compared with other representative lightweight object detection methods on UAV image datasets.
KW  - lightweight convolutional neural network
KW  - object detection
KW  - UAV images
DO  - 10.3390/s21165656
ER  -
TY  - EJOU
AU  - Huang, Xin
AU  - Dong, Xiaoya
AU  - Ma, Jing
AU  - Liu, Kuan
AU  - Ahmed, Shibbir
AU  - Lin, Jinlong
AU  - Qiu, Baijing
TI  - The Improved A* Obstacle Avoidance Algorithm for the Plant Protection UAV with Millimeter Wave Radar and Monocular Camera Data Fusion
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 17
SN  - 2072-4292

AB  - To enhance obstacle avoidance abilities of the plant protection UAV in unstructured farmland, this article improved the traditional A* algorithms through dynamic heuristic functions, search point optimization, and inflection point optimization based on millimeter wave radar and monocular camera data fusion. Obstacle information extraction experiments were carried out. The performance between the improved algorithm and traditional algorithm was compared. Additionally, obstacle avoidance experiments were also carried out. The results show that the maximum error in distance measurement of data fusion method was 8.2%. Additionally, the maximum error in obstacle width and height measurement were 27.3% and 18.5%, respectively. The improved algorithm is more useful in path planning, significantly reduces data processing time, search grid, and turning points. The algorithm at most increases path length by 2.0%, at least reduces data processing time by 68.4%, search grid by 74.9%, and turning points by 20.7%. The maximum trajectory offset error was proportional to the flight speed, with a maximum trajectory offset of 1.4 m. The distance between the UAV and obstacle was inversely proportional to flight speed, with a minimum distance of 1.6 m. This method can provide a new idea for obstacle avoidance of the plant protection UAV.
KW  - the plant protection UAV
KW  - obstacle avoidance
KW  - improved A* algorithm
KW  - millimeter wave radar
KW  - monocular camera
KW  - data fusion
DO  - 10.3390/rs13173364
ER  -
TY  - EJOU
AU  - Marzialetti, Flavio
AU  - Frate, Ludovico
AU  - De Simone, Walter
AU  - Frattaroli, Anna R.
AU  - Acosta, Alicia T.
AU  - Carranza, Maria L.
TI  - Unmanned Aerial Vehicle (UAV)-Based Mapping of Acacia saligna Invasion in the Mediterranean Coast
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 17
SN  - 2072-4292

AB  - Remote Sensing (RS) is a useful tool for detecting and mapping Invasive Alien Plants (IAPs). IAPs mapping on dynamic and heterogeneous landscapes, using satellite RS data, is not always feasible. Unmanned aerial vehicles (UAV) with ultra-high spatial resolution data represent a promising tool for IAPs detection and mapping. This work develops an operational workflow for detecting and mapping Acacia saligna invasion along Mediterranean coastal dunes. In particular, it explores and tests the potential of RGB (Red, Green, Blue) and multispectral (Green, Red, Red Edge, Near Infra—Red) UAV images collected in pre-flowering and flowering phenological stages for detecting and mapping A. saligna. After ortho—mosaics generation, we derived from RGB images the DSM (Digital Surface Model) and HIS (Hue, Intensity, Saturation) variables, and we calculated the NDVI (Normalized Difference Vegetation Index). For classifying images of the two phenological stages we built a set of raster stacks which include different combination of variables. For image classification, we used the Geographic Object-Based Image Analysis techniques (GEOBIA) in combination with Random Forest (RF) classifier. All classifications derived from RS information (collected on pre-flowering and flowering stages and using different combinations of variables) produced A. saligna maps with acceptable accuracy values, with higher performances on classification derived from flowering period images, especially using DSM + HIS combination. The adopted approach resulted an efficient method for mapping and early detection of IAPs, also in complex environments offering a sound support to the prioritization of conservation and management actions claimed by the EU IAS Regulation 1143/2014.
KW  - invasive plant species
KW  - coastal dunes
KW  - RGB and multispectral images
KW  - species flowering
KW  - drones
KW  - GEOBIA
KW  - HIS variables
KW  - random forest
DO  - 10.3390/rs13173361
ER  -
TY  - EJOU
AU  - Abdelmaboud, Abdelzahir
TI  - The Internet of Drones: Requirements, Taxonomy, Recent Advances, and Challenges of Research Trends
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 17
SN  - 1424-8220

AB  - The use of unmanned aerial vehicles or drones are a valuable technique in coping with issues related to life in the general public’s daily routines. Given the growing number of drones in low-altitude airspace, linking drones to form the Internet of drones (IoD) is a highly desirable trend to improve the safety as well as the quality of flight. However, there remain security, privacy, and communication issues related to IoD. In this paper, we discuss the key requirements of security, privacy, and communication and we present a taxonomy of IoD based on the most relevant considerations. Furthermore, we present the most commonly used commercial case studies and address the latest advancements and solutions proposed for the IoD environments. Lastly, we discuss the challenges and future research directions of IoD.
KW  - Internet of drones
KW  - communication
KW  - security
KW  - privacy
DO  - 10.3390/s21175718
ER  -
TY  - EJOU
AU  - Ansari, Emaad
AU  - Akhtar, Mohammad N.
AU  - Abdullah, Mohamad N.
AU  - Othman, Wan A.
AU  - Bakar, Elmi A.
AU  - Hawary, Ahmad F.
AU  - Alhady, Syed S.
TI  - Image Processing of UAV Imagery for River Feature Recognition of Kerian River, Malaysia
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 17
SN  - 2071-1050

AB  - The impact of floods is the most severe among the natural calamities occurring in Malaysia. The knock of floods is consistent and annually forces thousands of Malaysians to relocate. The lack of information from the Ministry of Environment and Water, Malaysia is the foremost obstacle in upgrading the flood mapping. With the expeditious evolution of computer techniques, processing of satellite and unmanned aerial vehicle (UAV) images for river hydromorphological feature detection and flood management have gathered pace in the last two decades. Different image processing algorithms—structure from motion (SfM), multi-view stereo (MVS), gradient vector flow (GVF) snake algorithm, etc.—and artificial neural networks are implemented for the monitoring and classification of river features. This paper presents the application of the k-means algorithm along with image thresholding to quantify variation in river surface flow areas and vegetation growth along Kerian River, Malaysia. The river characteristic recognition directly or indirectly assists in studying river behavior and flood monitoring. Dice similarity coefficient and Jaccard index are numerated between thresholded images that are clustered using the k-means algorithm and manually segmented images. Based on quantitative evaluation, a dice similarity coefficient and Jaccard index of up to 97.86% and 94.36% were yielded for flow area and vegetation calculation. Thus, the present technique is functional in evaluating river characteristics with reduced errors. With minimum errors, the present technique can be utilized for quantifying agricultural areas and urban areas around the river basin.
KW  - image processing
KW  - unmanned aerial vehicle
KW  - feature recognition
KW  - image segmentation
KW  - color space
KW  - floods
KW  - sediment
DO  - 10.3390/su13179568
ER  -
TY  - EJOU
AU  - Qader, Sarchil H.
AU  - Dash, Jadu
AU  - Alegana, Victor A.
AU  - Khwarahm, Nabaz R.
AU  - Tatem, Andrew J.
AU  - Atkinson, Peter M.
TI  - The Role of Earth Observation in Achieving Sustainable Agricultural Production in Arid and Semi-Arid Regions of the World
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 17
SN  - 2072-4292

AB  - Crop production is a major source of food and livelihood for many people in arid and semi-arid (ASA) regions across the world. However, due to irregular climatic events, ASA regions are affected commonly by frequent droughts that can impact food production. In addition, ASA regions in the Middle East and Africa are often characterised by political instability, which can increase population vulnerability to hunger and ill health. Remote sensing (RS) provides a platform to improve the spatial prediction of crop production and food availability, with the potential to positively impact populations. This paper, firstly, describes some of the important characteristics of agriculture in ASA regions that require monitoring to improve their management. Secondly, it demonstrates how freely available RS data can support decision-making through a cost-effective monitoring system that complements traditional approaches for collecting agricultural data. Thirdly, it illustrates the challenges of employing freely available RS data for mapping and monitoring crop area, crop status and forecasting crop yield in these regions. Finally, existing approaches used in these applications are evaluated, and the challenges associated with their use and possible future improvements are discussed. We demonstrate that agricultural activities can be monitored effectively and both crop area and crop yield can be predicted in advance using RS data. We also discuss the future challenges associated with maintaining food security in ASA regions and explore some recent advances in RS that can be used to monitor cropland and forecast crop production and yield.
KW  - agriculture
KW  - arid and semi-arid regions
KW  - crop monitoring
KW  - remote sensing
KW  - crop yield
DO  - 10.3390/rs13173382
ER  -
TY  - EJOU
AU  - Mikula, Karol
AU  - Šibíková, Mária
AU  - Ambroz, Martin
AU  - Kollár, Michal
AU  - Ožvat, Aneta A.
AU  - Urbán, Jozef
AU  - Jarolímek, Ivan
AU  - Šibík, Jozef
TI  - NaturaSat—A Software Tool for Identification, Monitoring and Evaluation of Habitats by Remote Sensing Techniques
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 17
SN  - 2072-4292

AB  - The NaturaSat software integrates various image processing techniques together with vegetation data, into one multipurpose tool that is designed for performing facilities for all requirements of habitat exploration, all in one place. It provides direct access to multispectral Sentinel-2 data provided by the European Space Agency. It supports using these data with various vegetation databases, in a user-friendly environment, for, e.g., vegetation scientists, fieldwork experts, and nature conservationists. The presented study introduces the NaturaSat software, describes new powerful tools, such as the semi-automatic and automatic segmentation methods, and natural numerical networks, together with validated examples comparing field surveys and software outputs. The software is robust enough for field work researchers and stakeholders to accurately extract target units’ borders, even on the habitat level. The deep learning algorithm, developed for habitat classification within the NaturaSat software, can also be used in various research tasks or in nature conservation practices, such as identifying ecosystem services and conservation value. The exact maps of the habitats obtained within the project can improve many further vegetation and landscape ecology studies.
KW  - aerial photographs
KW  - biodiversity
KW  - curve evolution
KW  - image segmentation
KW  - landscape structure
KW  - natura 2000
KW  - satellite images
KW  - sentinel-2
KW  - vegetation
DO  - 10.3390/rs13173381
ER  -
TY  - EJOU
AU  - Amicone, Donatello
AU  - Cannas, Andrea
AU  - Marci, Alberto
AU  - Tortora, Giuseppe
TI  - A Smart Capsule Equipped with Artificial Intelligence for Autonomous Delivery of Medical Material through Drones
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 17
SN  - 2076-3417

AB  - In the last few years, many examples of blood and medicine delivery drones have been demonstrated worldwide, which mainly rely on aeronautical experience that is not common in the medical world. Speaking about drone delivery, attention should focus on the most important thing: the transported lifesaving good. Traditional boxes that monitor temperature are not usually in real time, and are not suitable for drone transportation because they are heavy and bulky. This means that the biomedical characteristics of delivery are of primary importance. A Smart Capsule, equipped with artificial intelligence (AI), is the first system ever proposed to provide a fully autonomous drone delivery service for perishable and high-value medical products, integrating real-time quality monitoring and control. It consists in a smart casing that is able to guide any autonomous aerial vehicle attached to it, specifically designed for transporting blood, organs, tissues, test samples and drugs, among others. The system monitors the conditions of the product (e.g., temperature, agitation and humidity) and adjusts them when needed by exploiting, for instance, vibrations to maintain the required agitation, ensuring that goods are ready to be used as soon as they are delivered. The Smart Capsule also leverages external temperature to reduce energy uptake from the drone, thus improving the drone’s battery life and flight range. The system replaces the need for specialized drivers and traditional road-bound transportation means, while guaranteeing compliance with all applicable safety regulations. A series of 16 experimental tests was performed to demonstrate the possibility of using the smart capsule to manage the flight and internal good delivery. Eighty-one missions were carried out for a total of 364 min of flight. The Smart Capsule greatly improves emergency response and efficiency of healthcare systems by reducing delivery times by up to 80% and costs by at least 28%. The Smart Capsule and its enabling technology based on AI for drone deliveries are discussed in this paper. The aim of this work is to show the possibility of managing drone delivery with an AI-based device.
KW  - medical delivery
KW  - drone delivery
KW  - telemedicine
KW  - autonomous robot
KW  - AI
DO  - 10.3390/app11177976
ER  -
TY  - EJOU
AU  - Ali, Wasiq
AU  - Li, Yaan
AU  - Raja, Muhammad A.
AU  - Khan, Wasim U.
AU  - He, Yigang
TI  - State Estimation of an Underwater Markov Chain Maneuvering Target Using Intelligent Computing
T2  - Entropy

PY  - 2021
VL  - 23
IS  - 9
SN  - 1099-4300

AB  - In this study, an application of deep learning-based neural computing is proposed for efficient real-time state estimation of the Markov chain underwater maneuvering object. The designed intelligent strategy is exploiting the strength of nonlinear autoregressive with an exogenous input (NARX) network model, which has the capability for estimating the dynamics of the systems that follow the discrete-time Markov chain. Nonlinear Bayesian filtering techniques are often applied for underwater maneuvering state estimation applications by following state-space methodology. The robustness and precision of NARX neural network are efficiently investigated for accurate state prediction of the passive Markov chain highly maneuvering underwater target. A continuous coordinated turning trajectory of an underwater maneuvering object is modeled for analyzing the performance of the neural computing paradigm. State estimation modeling is developed in the context of bearings only tracking technology in which the efficiency of the NARX neural network is investigated for ideal and complex ocean environments. Real-time position and velocity of maneuvering object are computed for five different cases by varying standard deviations of white Gaussian measured noise. Sufficient Monte Carlo simulation results validate the competence of NARX neural computing over conventional generalized pseudo-Bayesian filtering algorithms like an interacting multiple model extended Kalman filter and an interacting multiple model unscented Kalman filter.
KW  - neural computing
KW  - state estimation
KW  - Markov chain
KW  - turning trajectory
KW  - bearings only tracking
KW  - maneuvering object
DO  - 10.3390/e23091124
ER  -
TY  - EJOU
AU  - Aghababaei, Masoumeh
AU  - Ebrahimi, Ataollah
AU  - Naghipour, Ali A.
AU  - Asadi, Esmaeil
AU  - Verrelst, Jochem
TI  - Classification of Plant Ecological Units in Heterogeneous Semi-Steppe Rangelands: Performance Assessment of Four Classification Algorithms
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 17
SN  - 2072-4292

AB  - Plant Ecological Unit’s (PEUs) are the abstraction of vegetation communities that occur on a site which similarly respond to management actions and natural disturbances. Identification and monitoring of PEUs in a heterogeneous landscape is the most difficult task in medium resolution satellite images datasets. The main objective of this study is to compare pixel-based classification versus object-based classification for accurately classifying PEUs with four selected different algorithms across heterogeneous rangelands in Central Zagros, Iran. We used images of Landsat-8 OLI that were pan-sharpened to 15 m to classify four PEU classes based on a random dataset collected in the field (40%). In the first stage, we applied the following classification algorithms to distinguish PEUs: Minimum Distance (MD), Maximum Likelihood Classification (MLC), Neural Network-Multi Layer Perceptron (NN-MLP) and Classification Tree Analysis (CTA) for pixel based method and object based method. Then, by using the most accurate classification approach, in the second stage auxiliary data (Principal Component Analysis (PCA)) was incorporated to improve the accuracy of the PEUs classification process. At the end, test data (60%) were used for accuracy assessment of the resulting maps. Object-based maps clearly outperformed pixel-based maps, especially with CTA, NN-MLP and MD algorithms with overall accuracies of 86%, 72% and 59%, respectively. The MLC algorithm did not reveal any significant difference between the object-based and pixel-based analyses. Finally, complementing PCA auxiliary bands to the CTA algorithms offered the most successful PEUs classification strategy, with the highest overall accuracy (89%). The results clearly underpin the importance of object-based classification with the CTA classifier together with PCA auxiliary data to optimize identification of PEU classes.
KW  - object-based classification
KW  - machine learning algorithms
KW  - principal component analysis
KW  - plant ecological units mapping
DO  - 10.3390/rs13173433
ER  -
TY  - EJOU
AU  - Qi, Yuan
AU  - Dong, Xuhua
AU  - Chen, Pengchao
AU  - Lee, Kyeong-Hwan
AU  - Lan, Yubin
AU  - Lu, Xiaoyang
AU  - Jia, Ruichang
AU  - Deng, Jizhong
AU  - Zhang, Yali
TI  - Canopy Volume Extraction of Citrus reticulate Blanco cv. Shatangju Trees Using UAV Image-Based Point Cloud Deep Learning
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 17
SN  - 2072-4292

AB  - Automatic acquisition of the canopy volume parameters of the Citrus reticulate Blanco cv. Shatangju tree is of great significance to precision management of the orchard. This research combined the point cloud deep learning algorithm with the volume calculation algorithm to segment the canopy of the Citrus reticulate Blanco cv. Shatangju trees. The 3D (Three-Dimensional) point cloud model of a Citrus reticulate Blanco cv. Shatangju orchard was generated using UAV tilt photogrammetry images. The segmentation effects of three deep learning models, PointNet++, MinkowskiNet and FPConv, on Shatangju trees and the ground were compared. The following three volume algorithms: convex hull by slices, voxel-based method and 3D convex hull were applied to calculate the volume of Shatangju trees. Model accuracy was evaluated using the coefficient of determination (R2) and Root Mean Square Error (RMSE). The results show that the overall accuracy of the MinkowskiNet model (94.57%) is higher than the other two models, which indicates the best segmentation effect. The 3D convex hull algorithm received the highest R2 (0.8215) and the lowest RMSE (0.3186 m3) for the canopy volume calculation, which best reflects the real volume of Citrus reticulate Blanco cv. Shatangju trees. The proposed method is capable of rapid and automatic acquisition for the canopy volume of Citrus reticulate Blanco cv. Shatangju trees.
KW  - canopy volume
KW  - UAV tilt photogrammetry
KW  - point cloud
KW  - deep learning
KW  - Citrus reticulate Blanco cv. Shatangju trees
DO  - 10.3390/rs13173437
ER  -
TY  - EJOU
AU  - Tan, Junxiang
AU  - Zhao, Haojie
AU  - Yang, Ronghao
AU  - Liu, Hua
AU  - Li, Shaoda
AU  - Liu, Jianfei
TI  - An Entropy-Weighting Method for Efficient Power-Line Feature Evaluation and Extraction from LiDAR Point Clouds
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 17
SN  - 2072-4292

AB  - Power-line inspection is an important means to maintain the safety of power networks. Light detection and ranging (LiDAR) technology can provide high-precision 3D information about power corridors for automated power-line inspection, so there are more and more utility companies relying on LiDAR systems instead of traditional manual operation. However, it is still a challenge to automatically detect power lines with high precision. To achieve efficient and accurate power-line extraction, this paper proposes an algorithm using entropy-weighting feature evaluation (EWFE), which is different from the existing hierarchical-multiple-rule evaluation of many geometric features. Six significant features are selected (Height above Ground Surface (HGS), Vertical Range Ratio (VRR), Horizontal Angle (HA), Surface Variation (SV), Linearity (LI) and Curvature Change (CC)), and then the features are combined to construct a vector for quantitative evaluation. The feature weights are determined by an entropy-weighting method (EWM) to achieve optimal distribution. The point clouds are filtered out by the HGS feature, which possesses the highest entropy value, and a portion of non-power-line points can be removed without loss of power-line points. The power lines are extracted by evaluation of the other five features. To decrease the interference from pylon points, this paper analyzes performance in different pylon situations and performs an adaptive weight transformation. We evaluate the EWFE method using four datasets with different transmission voltage scales captured by a light unmanned aerial vehicle (UAV) LiDAR system and a mobile LiDAR system. Experimental results show that our method demonstrates efficient performance, while algorithm parameters remain consistent for the four datasets. The precision F value ranges from 98.4% to 99.7%, and the efficiency ranges from 0.9 million points/s to 5.2 million points/s.
KW  - unmanned aerial vehicle (UAV)
KW  - power-line extraction
KW  - entropy weighting
KW  - feature evaluation
DO  - 10.3390/rs13173446
ER  -
TY  - EJOU
AU  - Liu, Chengqi
AU  - Zhou, Han
AU  - Cao, Jing
AU  - Guo, Xuchao
AU  - Su, Jie
AU  - Wang, Longhe
AU  - Lu, Shuhan
AU  - Li, Lin
TI  - Behavior Trajectory Tracking of Piglets Based on DLC-KPCA
T2  - Agriculture

PY  - 2021
VL  - 11
IS  - 9
SN  - 2077-0472

AB  - Tracking the behavior trajectories in pigs in group is becoming increasingly important for welfare feeding. A novel method was proposed in this study to accurately track individual trajectories of pigs in group and analyze their behavior characteristics. First, a multi-pig trajectory tracking model was established based on DeepLabCut (DLC) to realize the daily trajectory tracking of piglets. Second, a high-dimensional spatiotemporal feature model was established based on kernel principal component analysis (KPCA) to achieve nonlinear trajectory optimal clustering. At the same time, the abnormal trajectory correction model was established from five dimensions (semantic, space, angle, time, and velocity) to avoid trajectory loss and drift. Finally, the thermal map of the track distribution was established to analyze the four activity areas of the piggery (resting, drinking, excretion, and feeding areas). Experimental results show that the trajectory tracking accuracy of our method reaches 96.88%, the tracking speed is 350 fps, and the loss value is 0.002. Thus, the method based on DLC–KPCA can meet the requirements of identification of piggery area and tracking of piglets’ behavior. This study is helpful for automatic monitoring of animal behavior and provides data support for breeding.
KW  - piglets
KW  - behavior tracking
KW  - trajectory correction
KW  - DeepLabCut
KW  - KPCA
DO  - 10.3390/agriculture11090843
ER  -
TY  - EJOU
AU  - Pranga, Joanna
AU  - Borra-Serrano, Irene
AU  - Aper, Jonas
AU  - De Swaef, Tom
AU  - Ghesquiere, An
AU  - Quataert, Paul
AU  - Roldán-Ruiz, Isabel
AU  - Janssens, Ivan A.
AU  - Ruysschaert, Greet
AU  - Lootens, Peter
TI  - Improving Accuracy of Herbage Yield Predictions in Perennial Ryegrass with UAV-Based Structural and Spectral Data Fusion and Machine Learning
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 17
SN  - 2072-4292

AB  - High-throughput field phenotyping using close remote sensing platforms and sensors for non-destructive assessment of plant traits can support the objective evaluation of yield predictions of large breeding trials. The main objective of this study was to examine the potential of unmanned aerial vehicle (UAV)-based structural and spectral features and their combination in herbage yield predictions across diploid and tetraploid varieties and breeding populations of perennial ryegrass (Lolium perenne L.). Canopy structural (i.e., canopy height) and spectral (i.e., vegetation indices) information were derived from data gathered with two sensors: a consumer-grade RGB and a 10-band multispectral (MS) camera system, which were compared in the analysis. A total of 468 field plots comprising 115 diploid and 112 tetraploid varieties and populations were considered in this study. A modelling framework established to predict dry matter yield (DMY), was used to test three machine learning algorithms, including Partial Least Squares Regression (PLSR), Random Forest (RF), and Support Vector Machines (SVM). The results of the nested cross-validation revealed: (a) the fusion of structural and spectral features achieved better DMY estimates as compared to models fitted with structural or spectral data only, irrespective of the sensor, ploidy level or machine learning algorithm applied; (b) models built with MS-based predictor variables, despite their lower spatial resolution, slightly outperformed the RGB-based models, as lower mean relative root mean square error (rRMSE) values were delivered; and (c) on average, the RF technique reported the best model performances among tested algorithms, regardless of the dataset used. The approach introduced in this study can provide accurate yield estimates (up to an RMSE = 308 kg ha−1) and useful information for breeders and practical farm-scale applications.
KW  - high-throughput field phenotyping (HTFP)
KW  - pasture
KW  - forage
KW  - RGB sensor
KW  - multispectral sensor
KW  - close remote sensing
KW  - partial least squares regression (PLSR)
KW  - random forest (RF)
KW  - support vector machines (SVM)
DO  - 10.3390/rs13173459
ER  -
TY  - EJOU
AU  - Alexandris, Stavros
AU  - Psomiadis, Emmanouil
AU  - Proutsos, Nikolaos
AU  - Philippopoulos, Panos
AU  - Charalampopoulos, Ioannis
AU  - Kakaletris, George
AU  - Papoutsi, Eleni-Magda
AU  - Vassilakis, Stylianos
AU  - Paraskevopoulos, Antoniοs
TI  - Integrating Drone Technology into an Innovative Agrometeorological Methodology for the Precise and Real-Time Estimation of Crop Water Requirements
T2  - Hydrology

PY  - 2021
VL  - 8
IS  - 3
SN  - 2306-5338

AB  - Precision agriculture has been at the cutting edge of research during the recent decade, aiming to reduce water consumption and ensure sustainability in agriculture. The proposed methodology was based on the crop water stress index (CWSI) and was applied in Greece within the ongoing research project GreenWaterDrone. The innovative approach combines real spatial data, such as infrared canopy temperature, air temperature, air relative humidity, and thermal infrared image data, taken above the crop field using an aerial micrometeorological station (AMMS) and a thermal (IR) camera installed on an unmanned aerial vehicle (UAV). Following an initial calibration phase, where the ground micrometeorological station (GMMS) was installed in the crop, no equipment needed to be maintained in the field. Aerial and ground measurements were transferred in real time to sophisticated databases and applications over existing mobile networks for further processing and estimation of the actual water requirements of a specific crop at the field level, dynamically alerting/informing local farmers/agronomists of the irrigation necessity and additionally for potential risks concerning their fields. The supported services address farmers’, agricultural scientists’, and local stakeholders’ needs to conform to regional water management and sustainable agriculture policies. As preliminary results of this study, we present indicative original illustrations and data from applying the methodology to assess UAV functionality while aiming to evaluate and standardize all system processes.
KW  - CWSI
KW  - UAV
KW  - remote sensing
KW  - micrometeorological data
KW  - spatial IRT measurements
KW  - crop irrigation scheduling and management
KW  - infrared radiometer sensors
KW  - real-time data analysis
DO  - 10.3390/hydrology8030131
ER  -
TY  - EJOU
AU  - Kalyani, Yogeswaranathan
AU  - Collier, Rem
TI  - A Systematic Survey on the Role of Cloud, Fog, and Edge Computing Combination in Smart Agriculture
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 17
SN  - 1424-8220

AB  - Cloud Computing is a well-established paradigm for building service-centric systems. However, ultra-low latency, high bandwidth, security, and real-time analytics are limitations in Cloud Computing when analysing and providing results for a large amount of data. Fog and Edge Computing offer solutions to the limitations of Cloud Computing. The number of agricultural domain applications that use the combination of Cloud, Fog, and Edge is increasing in the last few decades. This article aims to provide a systematic literature review of current works that have been done in Cloud, Fog, and Edge Computing applications in the smart agriculture domain between 2015 and up-to-date. The key objective of this review is to identify all relevant research on new computing paradigms with smart agriculture and propose a new architecture model with the combinations of Cloud–Fog–Edge. Furthermore, it also analyses and examines the agricultural application domains, research approaches, and the application of used combinations. Moreover, this survey discusses the components used in the architecture models and briefly explores the communication protocols used to interact from one layer to another. Finally, the challenges of smart agriculture and future research directions are briefly pointed out in this article.
KW  - cloud
KW  - fog
KW  - edge
KW  - smart agriculture
DO  - 10.3390/s21175922
ER  -
TY  - EJOU
AU  - Vrochidou, Eleni
AU  - Bazinas, Christos
AU  - Manios, Michail
AU  - Papakostas, George A.
AU  - Pachidis, Theodore P.
AU  - Kaburlasos, Vassilis G.
TI  - Machine Vision for Ripeness Estimation in Viticulture Automation
T2  - Horticulturae

PY  - 2021
VL  - 7
IS  - 9
SN  - 2311-7524

AB  - Ripeness estimation of fruits and vegetables is a key factor for the optimization of field management and the harvesting of the desired product quality. Typical ripeness estimation involves multiple manual samplings before harvest followed by chemical analyses. Machine vision has paved the way for agricultural automation by introducing quicker, cost-effective, and non-destructive methods. This work comprehensively surveys the most recent applications of machine vision techniques for ripeness estimation. Due to the broad area of machine vision applications in agriculture, this review is limited only to the most recent techniques related to grapes. The aim of this work is to provide an overview of the state-of-the-art algorithms by covering a wide range of applications. The potential of current machine vision techniques for specific viticulture applications is also analyzed. Problems, limitations of each technique, and future trends are discussed. Moreover, the integration of machine vision algorithms in grape harvesting robots for real-time in-field maturity assessment is additionally examined.
KW  - machine vision
KW  - grape ripeness estimation
KW  - image analysis
KW  - precision agriculture
KW  - agrobots
KW  - harvesting robot
DO  - 10.3390/horticulturae7090282
ER  -
TY  - EJOU
AU  - Mohammadi, Masoud
AU  - Rashidi, Maria
AU  - Mousavi, Vahid
AU  - Karami, Ali
AU  - Yu, Yang
AU  - Samali, Bijan
TI  - Quality Evaluation of Digital Twins Generated Based on UAV Photogrammetry and TLS: Bridge Case Study
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 17
SN  - 2072-4292

AB  - In the current modern era of information and technology, emerging remote advancements have been widely established for detailed virtual inspections and assessments of infrastructure assets, especially bridges. These technologies are capable of creating an accurate digital representation of the existing assets, commonly known as the digital twins. Digital twins are suitable alternatives to in-person and on-site based assessments that can provide safer, cheaper, more reliable, and less distributive bridge inspections. In the case of bridge monitoring, Unmanned Aerial Vehicle (UAV) photogrammetry and Terrestrial Laser Scanning (TLS) are among the most common advanced technologies that hold the potential to provide qualitative digital models; however, the research is still lacking a reliable methodology to evaluate the generated point clouds in terms of quality and geometric accuracy for a bridge size case study. Therefore, this paper aims to provide a comprehensive methodology along with a thorough bridge case study to evaluate two digital point clouds developed from an existing Australian heritage bridge via both UAV-based photogrammetry and TLS. In this regard, a range of proposed approaches were employed to compare point clouds in terms of points’ distribution, level of outlier noise, data completeness, surface deviation, and geometric accuracy. The comparative results of this case study not only proved the capability and applicability of the proposed methodology and approaches in evaluating these two voluminous point clouds, but they also exhibited a higher level of point density and more acceptable agreements with as-is measurements in TLS-based point clouds subjected to the implementation of a precise data capture and a 3D reconstruction model.
KW  - digital twin
KW  - quality evaluation
KW  - geometric accuracy
KW  - point cloud
KW  - UAV-based photogrammetry
KW  - terrestrial laser scanning (TLS)
KW  - bridge inspection
DO  - 10.3390/rs13173499
ER  -
TY  - EJOU
AU  - Fuentes, Sigfredo
AU  - Tongson, Eden
AU  - Unnithan, Ranjith R.
AU  - Gonzalez Viejo, Claudia
TI  - Early Detection of Aphid Infestation and Insect-Plant Interaction Assessment in Wheat Using a Low-Cost Electronic Nose (E-Nose), Near-Infrared Spectroscopy and Machine Learning Modeling
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 17
SN  - 1424-8220

AB  - Advances in early insect detection have been reported using digital technologies through camera systems, sensor networks, and remote sensing coupled with machine learning (ML) modeling. However, up to date, there is no cost-effective system to monitor insect presence accurately and insect-plant interactions. This paper presents results on the implementation of near-infrared spectroscopy (NIR) and a low-cost electronic nose (e-nose) coupled with machine learning. Several artificial neural network (ANN) models were developed based on classification to detect the level of infestation and regression to predict insect numbers for both e-nose and NIR inputs, and plant physiological response based on e-nose to predict photosynthesis rate (A), transpiration (E) and stomatal conductance (gs). Results showed high accuracy for classification models ranging within 96.5–99.3% for NIR and between 94.2–99.2% using e-nose data as inputs. For regression models, high correlation coefficients were obtained for physiological parameters (gs, E and A) using e-nose data from all samples as inputs (R = 0.86) and R = 0.94 considering only control plants (no insect presence). Finally, R = 0.97 for NIR and R = 0.99 for e-nose data as inputs were obtained to predict number of insects. Performances for all models developed showed no signs of overfitting. In this paper, a field-based system using unmanned aerial vehicles with the e-nose as payload was proposed and described for deployment of ML models to aid growers in pest management practices.
KW  - remote sensing
KW  - volatile compounds
KW  - artificial neural networks
KW  - photosynthesis modeling
KW  - plant water status modeling
DO  - 10.3390/s21175948
ER  -
TY  - EJOU
AU  - Ma, Lei
AU  - Zhu, Xiaoxiang
AU  - Qiu, Chunping
AU  - Blaschke, Thomas
AU  - Li, Manchun
TI  - Advances of Local Climate Zone Mapping and Its Practice Using Object-Based Image Analysis
T2  - Atmosphere

PY  - 2021
VL  - 12
IS  - 9
SN  - 2073-4433

AB  - In the context of climate change and urban heat islands, the concept of local climate zones (LCZ) aims for consistent and comparable mapping of urban surface structure and cover across cities. This study provides a timely survey of remote sensing-based applications of LCZ mapping considering the recent increase in publications. We analyze and evaluate several aspects that affect the performance of LCZ mapping, including mapping units/scale, transferability, sample dataset, low accuracy, and classification schemes. Since current LCZ analysis and mapping are based on per-pixel approaches, this study implements an object-based image analysis (OBIA) method and tests it for two cities in Germany using Sentinel 2 data. A comparison with a per-pixel method yields promising results. This study shall serve as a blueprint for future object-based remotely sensed LCZ mapping approaches.
KW  - local climate zones
KW  - remote sensing
KW  - mapping unit
KW  - transferability
KW  - object-based image analysis
DO  - 10.3390/atmos12091146
ER  -
TY  - EJOU
AU  - Arredondo-Méndez, Víctor H.
AU  - Para-González, Lorena
AU  - Mascaraque-Ramírez, Carlos
AU  - Domínguez, Manuel
TI  - The 4.0 Industry Technologies and Their Impact in the Continuous Improvement and the Organizational Results: An Empirical Approach
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 17
SN  - 2071-1050

AB  - This study analyses the relationships between the technologies of Industry 4.0, continuous improvement, and the business results. To carry out this study, 109 questionnaires to companies of different sectors were collected, but an indispensable condition to take into account was the fact that these companies develop themselves their logistics management. The analysis of the results obtained through the Partial Least Squares (PLS) methodology argues that there is a positive relationship between 4.0 Industry and continuous improvement processes, as well as between continuous improvement processes and organizational results, although it cannot be concluded that a direct relationship between 4.0 Industry and organizational results exists, which means that there are other variables, such as continuous improvement, mediating between them. With this work, there is already an accredited reference of the relationship, which has been verified to exist, between the Industry 4.0, the continuous improvement, and the business results.
KW  - 4.0 Industry
KW  - continuous improvement
KW  - organizational results
KW  - partial least squares
DO  - 10.3390/su13179965
ER  -
TY  - EJOU
AU  - Du, Chunyu
AU  - Fan, Wenyi
AU  - Ma, Ye
AU  - Jin, Hung-Il
AU  - Zhen, Zhen
TI  - The Effect of Synergistic Approaches of Features and Ensemble Learning Algorithms on Aboveground Biomass Estimation of Natural Secondary Forests Based on ALS and Landsat 8
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 17
SN  - 1424-8220

AB  - Although the combination of Airborne Laser Scanning (ALS) data and optical imagery and machine learning algorithms were proved to improve the estimation of aboveground biomass (AGB), the synergistic approaches of different data and ensemble learning algorithms have not been fully investigated, especially for natural secondary forests (NSFs) with complex structures. This study aimed to explore the effects of the two factors on AGB estimation of NSFs based on ALS data and Landsat 8 imagery. The synergistic method of extracting novel features (i.e., COLI1 and COLI2) using optimal Landsat 8 features and the best-performing ALS feature (i.e., elevation mean) yielded higher accuracy of AGB estimation than either optical-only or ALS-only features. However, both of them failed to improve the accuracy compared to the simple combination of the untransformed features that generated them. The convolutional neural networks (CNN) model was much superior to other classic machine learning algorithms no matter of features. The stacked generalization (SG) algorithms, a kind of ensemble learning algorithms, greatly improved the accuracies compared to the corresponding base model, and the SG with the CNN meta-model performed best. This study provides technical support for a wall-to-wall AGB mapping of NSFs of northeastern China using efficient features and algorithms.
KW  - ensemble learning
KW  - machine learning
KW  - feature extraction
KW  - AGB
KW  - NSFs
DO  - 10.3390/s21175974
ER  -
TY  - EJOU
AU  - Koeva, Mila
AU  - Gasuku, Oscar
AU  - Lengoiboni, Monica
AU  - Asiama, Kwabena
AU  - Bennett, Rohan M.
AU  - Potel, Jossam
AU  - Zevenbergen, Jaap
TI  - Remote Sensing for Property Valuation: A Data Source Comparison in Support of Fair Land Taxation in Rwanda
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 18
SN  - 2072-4292

AB  - Remotely sensed data is increasingly applied across many domains, including fit-for-purpose land administration (FFPLA), where the focus is on fast, affordable, and accurate property information collection. Property valuation, as one of the main functions of land administration systems, is influenced by locational, physical, legal, and economic factors. Despite the importance of property valuation to economic development, there are often no standardized rules or strict data requirements for property valuation for taxation in developing contexts, such as Rwanda. This study aims at assessing different remote sensing data in support of developing a new approach for property valuation for taxation in Rwanda; one that aligns with the FFPLA philosophy. Three different remote sensing technologies, (i) aerial images acquired with a digital camera, (ii) WorldView2 satellite images, and (iii) unmanned aerial vehicle (UAV) images obtained with a DJI Phantom 2 Vision Plus quadcopter, are compared and analyzed in terms of their fitness to fulfil the requirements for valuation for taxation purposes. Quantitative and qualitative methods are applied for the comparative analysis. Prior to the field visit, the fundamental concepts of property valuation for taxation and remote sensing were reviewed. In the field, reference data using high precision GNSS (Leica) was collected and used for quantitative assessment. Primary data was further collected via semi-structured interviews and focus group discussions. The results show that UAVs have the highest potential for collecting data to support property valuation for taxation. The main reasons are the prime need for accurate-enough and up-to-date information. The comparison of the different remote sensing techniques and the provided new approach can support land valuers and professionals in the field in bottom-up activities following the FFPLA principles and maintaining the temporal quality of data needed for fair taxation.
KW  - property valuation
KW  - property taxation
KW  - remote sensing
KW  - land
KW  - UAV
DO  - 10.3390/rs13183563
ER  -
TY  - EJOU
AU  - Roslim, Muhammad H.
AU  - Juraimi, Abdul S.
AU  - Che’Ya, Nik N.
AU  - Sulaiman, Nursyazyla
AU  - Manaf, Muhammad N.
AU  - Ramli, Zaid
AU  - Motmainna, Mst.
TI  - Using Remote Sensing and an Unmanned Aerial System for Weed Management in Agricultural Crops: A Review
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 9
SN  - 2073-4395

AB  - Weeds are unwanted plants that can reduce crop yields by competing for water, nutrients, light, space, and carbon dioxide, which need to be controlled to meet future food production requirements. The integration of drones, artificial intelligence, and various sensors, which include hyperspectral, multi-spectral, and RGB (red-green-blue), ensure the possibility of a better outcome in managing weed problems. Most of the major or minor challenges caused by weed infestation can be faced by implementing remote sensing systems in various agricultural tasks. It is a multi-disciplinary science that includes spectroscopy, optics, computer, photography, satellite launching, electronics, communication, and several other fields. Future challenges, including food security, sustainability, supply and demand, climate change, and herbicide resistance, can also be overcome by those technologies based on machine learning approaches. This review provides an overview of the potential and practical use of unmanned aerial vehicle and remote sensing techniques in weed management practices and discusses how they overcome future challenges.
KW  - weeds
KW  - artificial intelligence
KW  - hyperspectral
KW  - multi-spectral
KW  - weeds management
DO  - 10.3390/agronomy11091809
ER  -
TY  - EJOU
AU  - Xia, Lang
AU  - Zhang, Ruirui
AU  - Chen, Liping
AU  - Li, Longlong
AU  - Yi, Tongchuan
AU  - Wen, Yao
AU  - Ding, Chenchen
AU  - Xie, Chunchun
TI  - Evaluation of Deep Learning Segmentation Models for Detection of Pine Wilt Disease in Unmanned Aerial Vehicle Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 18
SN  - 2072-4292

AB  - Pine wilt disease (PWD) is a serious threat to pine forests. Combining unmanned aerial vehicle (UAV) images and deep learning (DL) techniques to identify infected pines is the most efficient method to determine the potential spread of PWD over a large area. In particular, image segmentation using DL obtains the detailed shape and size of infected pines to assess the disease’s degree of damage. However, the performance of such segmentation models has not been thoroughly studied. We used a fixed-wing UAV to collect images from a pine forest in Laoshan, Qingdao, China, and conducted a ground survey to collect samples of infected pines and construct prior knowledge to interpret the images. Then, training and test sets were annotated on selected images, and we obtained 2352 samples of infected pines annotated over different backgrounds. Finally, high-performance DL models (e.g., fully convolutional networks for semantic segmentation, DeepLabv3+, and PSPNet) were trained and evaluated. The results demonstrated that focal loss provided a higher accuracy and a finer boundary than Dice loss, with the average intersection over union (IoU) for all models increasing from 0.656 to 0.701. From the evaluated models, DeepLLabv3+ achieved the highest IoU and an F1 score of 0.720 and 0.832, respectively. Also, an atrous spatial pyramid pooling module encoded multiscale context information, and the encoder–decoder architecture recovered location/spatial information, being the best architecture for segmenting trees infected by the PWD. Furthermore, segmentation accuracy did not improve as the depth of the backbone network increased, and neither ResNet34 nor ResNet50 was the appropriate backbone for most segmentation models.
KW  - deep learning
KW  - image segmentation
KW  - pine wilt disease
KW  - infected pine DeepLabv3+
KW  - focal loss
DO  - 10.3390/rs13183594
ER  -
TY  - EJOU
AU  - Zdziebko, Paweł
AU  - Holak, Krzysztof
TI  - Synthetic Image Generation Using the Finite Element Method and Blender Graphics Program for Modeling of Vision-Based Measurement Systems
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 18
SN  - 1424-8220

AB  - Computer vision is a frequently used approach in static and dynamic measurements of various mechanical structures. Sometimes, however, conducting a large number of experiments is time-consuming and may require significant financial and human resources. On the contrary, the authors propose a simulation approach for performing experiments to synthetically generate vision data. Synthetic images of mechanical structures subjected to loads are generated in the following way. The finite element method is adopted to compute deformations of the studied structure, and next, the Blender graphics program is used to render images presenting that structure. As a result of the proposed approach, it is possible to obtain synthetic images that reliably reflect static and dynamic experiments. This paper presents the results of the application of the proposed approach in the analysis of a complex-shaped structure for which experimental validation was carried out. In addition, the second example of the process of 3D reconstruction of the examined structure (in a multicamera system) is provided. The results for the structure with damage (cantilever beam) are also presented. The obtained results allow concluding that the proposed approach reliably imitates the images captured during real experiments. In addition, the method can become a tool supporting the vision system configuration process before conducting final experimental research.
KW  - image-based measurement
KW  - vision sensor modeling
KW  - vision system simulation
KW  - image-based reconstruction
KW  - finite element method
KW  - physics-based computer graphics
DO  - 10.3390/s21186046
ER  -
TY  - EJOU
AU  - Yin, Qian
AU  - Chen, Ziyi
AU  - Zheng, Xin
AU  - Xu, Yingjun
AU  - Liu, Tianxue
TI  - Sliding Windows Method Based on Terrain Self-Similarity for Higher DEM Resolution in Flood Simulating Modeling
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 18
SN  - 2072-4292

AB  - A digital elevation model (DEM) is a quantitative representation of terrain and an important tool for Earth science and hydrological applications. A high-resolution DEM provides accurate basic Geodata and plays a crucial role in related scientific research and practical applications. However, in reality, high-resolution DEMs are often difficult to obtain. Due to the self-similarity present within terrains, we proposed a method using the original DEM itself as a sample to expand the DEM using sliding windows method (SWM) and generate a higher resolution DEM. The main processes of SWM include downsampling the original DEM and constructing mapping sets, searching for the optimal matching, window replacement. Then, we repeat these processes with the small-scale expansion factor. In this paper, the grid resolution of the Taitou Basin was expanded from 30 to 10 m. Overall, the superresolution reconstruction results showed that the method could achieve better outcomes than other commonly used techniques and exhibited a slight deviation (root mean square error (RMSE) = 3.38) from the realistic DEM. The generated high-resolution DEM prove to be significant in the application of flood simulation modeling.
KW  - flash flood disasters
KW  - DEM
KW  - high-resolution reconstruction
KW  - sliding windows
DO  - 10.3390/rs13183604
ER  -
TY  - EJOU
AU  - Wada, Daichi
AU  - Araujo-Estrada, Sergio A.
AU  - Windsor, Shane
TI  - Unmanned Aerial Vehicle Pitch Control under Delay Using Deep Reinforcement Learning with Continuous Action in Wind Tunnel Test
T2  - Aerospace

PY  - 2021
VL  - 8
IS  - 9
SN  - 2226-4310

AB  - Nonlinear flight controllers for fixed-wing unmanned aerial vehicles (UAVs) can potentially be developed using deep reinforcement learning. However, there is often a reality gap between the simulation models used to train these controllers and the real world. This study experimentally investigated the application of deep reinforcement learning to the pitch control of a UAV in wind tunnel tests, with a particular focus of investigating the effect of time delays on flight controller performance. Multiple neural networks were trained in simulation with different assumed time delays and then wind tunnel tested. The neural networks trained with shorter delays tended to be susceptible to delay in the real tests and produce fluctuating behaviour. The neural networks trained with longer delays behaved more conservatively and did not produce oscillations but suffered steady state errors under some conditions due to unmodeled frictional effects. These results highlight the importance of performing physical experiments to validate controller performance and how the training approach used with reinforcement learning needs to be robust to reality gaps between simulation and the real world.
KW  - attitude control
KW  - deep reinforcement learning
KW  - fixed-wing aircraft
KW  - unmanned aerial vehicle
KW  - wind tunnel test
DO  - 10.3390/aerospace8090258
ER  -
TY  - EJOU
AU  - Fourlas, George K.
AU  - Karras, George C.
TI  - A Survey on Fault Diagnosis and Fault-Tolerant Control Methods for Unmanned Aerial Vehicles
T2  - Machines

PY  - 2021
VL  - 9
IS  - 9
SN  - 2075-1702

AB  - The continuous evolution of modern technology has led to the creation of increasingly complex and advanced systems. This has been also reflected in the technology of Unmanned Aerial Vehicles (UAVs), where the growing demand for more reliable performance necessitates the development of sophisticated techniques that provide fault diagnosis and fault tolerance in a timely and accurate manner. Typically, a UAV consists of three types of subsystems: actuators, main structure and sensors. Therefore, a fault-monitoring system must be specifically designed to supervise and debug each of these subsystems, so that any faults can be addressed before they lead to disastrous consequences. In this survey article, we provide a detailed overview of recent advances and studies regarding fault diagnosis, Fault-Tolerant Control (FTC) and anomaly detection for UAVs. Concerning fault diagnosis, our interest is mainly focused on sensors and actuators, as these subsystems are mostly prone to faults, while their healthy operation usually ensures the smooth and reliable performance of the aerial vehicle.
KW  - fault diagnosis
KW  - fault tolerant control
KW  - anomaly detection
KW  - unmanned aerial vehicles
DO  - 10.3390/machines9090197
ER  -
TY  - EJOU
AU  - Liu, Wenyao
AU  - Meng, Qingfeng
AU  - Li, Zhen
AU  - Hu, Xin
TI  - Applications of Computer Vision in Monitoring the Unsafe Behavior of Construction Workers: Current Status and Challenges
T2  - Buildings

PY  - 2021
VL  - 11
IS  - 9
SN  - 2075-5309

AB  - The unsafe behavior of construction workers is one of the main causes of safety accidents at construction sites. To reduce the incidence of construction accidents and improve the safety performance of construction projects, there is a need to identify risky factors by monitoring the behavior of construction workers. Computer vision (CV) technology, which is a powerful and automated tool used for extracting images and video information from construction sites, has been recognized and adopted as an effective construction site monitoring technology for the identification of risky factors resulting from the unsafe behavior of construction workers. In this article, we introduce the research background of this field and conduct a systematic statistical analysis of the relevant literature in this field through the bibliometric analysis method. Thereafter, we adopt a content-based analysis method to depict the historical explorations in the field. On this basis, the limitations and challenges in this field are identified, and future research directions are proposed. It is found that CV technology can effectively monitor the unsafe behaviors of construction workers. The research findings can enhance people’s understanding of construction safety management.
KW  - computer vision
KW  - construction workers
KW  - monitoring
KW  - unsafe behavior
KW  - literature review
DO  - 10.3390/buildings11090409
ER  -
TY  - EJOU
AU  - Zhang, Zhenduo
AU  - Zheng, Wenbo
AU  - Li, Ying
AU  - Cao, Kai
AU  - Xie, Ming
AU  - Wu, Peng
TI  - Monitoring Sulfur Content in Marine Fuel Oil Using Ultraviolet Imaging Technology
T2  - Atmosphere

PY  - 2021
VL  - 12
IS  - 9
SN  - 2073-4433

AB  - The emission of SO2 from ships is an important source of atmospheric pollution. Therefore, the International Maritime Organization (IMO) has established strict requirements for the sulfur content of marine fuel oil. In this paper, a new optical noncontact detection technique for ship exhaust emissions analysis is studied. Firstly, the single-band simulation analysis model of the imaging detection technology for SO2 concentration in ship exhaust gas and the deep neural network model for the prediction of sulfur content were established. A bench test was designed to monitor the tail gas concentration simultaneously using online and imaging detection methods, so as to obtain the concentration data in the flue and the ultraviolet image data. The results showed that 300 nm had a higher inversion accuracy than the other two bands. Finally, a deep neural network model was trained with the SO2 concentration data from the inversion and the engine power, and the predictive model of sulfur content in marine fuel oil was thereby obtained. When the deep learning model was used to predict sulfur content, the prediction accuracy at 300, 310, and 330 nm was 73%, 94%, and 71%, respectively.
KW  - ship emissions
KW  - exhaust plume
KW  - SO2 concentration
KW  - deep learning
KW  - imaging detection
DO  - 10.3390/atmos12091182
ER  -
TY  - EJOU
AU  - Li, Wangbin
AU  - Sun, Kaimin
AU  - Du, Zhuotong
AU  - Hu, Xiuqing
AU  - Li, Wenzhuo
AU  - Wei, Jinjiang
AU  - Gao, Song
TI  - PCNet: Cloud Detection in FY-3D True-Color Imagery Using Multi-Scale Pyramid Contextual Information
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 18
SN  - 2072-4292

AB  - Cloud, one of the poor atmospheric conditions, significantly reduces the usability of optical remote-sensing data and hampers follow-up applications. Thus, the identification of cloud remains a priority for various remote-sensing activities, such as product retrieval, land-use/cover classification, object detection, and especially for change detection. However, the complexity of clouds themselves make it difficult to detect thin clouds and small isolated clouds. To accurately detect clouds in satellite imagery, we propose a novel neural network named the Pyramid Contextual Network (PCNet). Considering the limited applicability of a regular convolution kernel, we employed a Dilated Residual Block (DRB) to extend the receptive field of the network, which contains a dilated convolution and residual connection. To improve the detection ability for thin clouds, the proposed new model, pyramid contextual block (PCB), was used to generate global information at different scales. FengYun-3D MERSI-II remote-sensing images covering China with 14,165 × 24,659 pixels, acquired on 17 July 2019, are processed to conduct cloud-detection experiments. Experimental results show that the overall precision rates of the trained network reach 97.1% and the overall recall rates reach 93.2%, which performs better both in quantity and quality than U-Net, UNet++, UNet3+, PSPNet and DeepLabV3+.
KW  - cloud detection
KW  - FY-3D remote-sensing images
KW  - pyramid contextual
KW  - deep learning
DO  - 10.3390/rs13183670
ER  -
TY  - EJOU
AU  - Daranagama, Samitha
AU  - Witayangkurn, Apichon
TI  - Automatic Building Detection with Polygonizing and Attribute Extraction from High-Resolution Images
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 9
SN  - 2220-9964

AB  - Buildings can be introduced as a fundamental element for forming a city. Therefore, up-to-date building maps have become vital for many applications, including urban mapping and urban expansion analysis. With the development of deep learning, segmenting building footprints from high-resolution remote sensing imagery has become a subject of intense study. Here, a modified version of the U-Net architecture with a combination of pre- and post-processing techniques was developed to extract building footprints from high-resolution aerial imagery and unmanned aerial vehicle (UAV) imagery. Data pre-processing with the logarithmic correction image enhancing algorithm showed the most significant improvement in the building detection accuracy for aerial images; meanwhile, the CLAHE algorithm improved the most concerning UAV images. This study developed a post-processing technique using polygonizing and polygon smoothing called the Douglas–Peucker algorithm, which made the building output directly ready to use for different applications. The attribute information, land use data, and population count data were applied using two open datasets. In addition, the building area and perimeter of each building were calculated as geometric attributes.
KW  - deep learning
KW  - building extraction
KW  - UAV images
KW  - aerial images
KW  - semantic segmentation
KW  - transfer learning
KW  - polygonizing
KW  - polygon smoothing
KW  - attribute extraction
DO  - 10.3390/ijgi10090606
ER  -
TY  - EJOU
AU  - Oseland, Eric
AU  - Shannon, Kent
AU  - Zhou, Jianfeng
AU  - Fritschi, Felix
AU  - Bish, Mandy D.
AU  - Bradley, Kevin W.
TI  - Evaluating the Spectral Response and Yield of Soybean Following Exposure to Sublethal Rates of 2,4-D and Dicamba at Vegetative and Reproductive Growth Stages
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 18
SN  - 2072-4292

AB  - The commercialization of synthetic auxin-resistant crops and the commensurate increase in post-emergent auxin-mimic herbicide applications has resulted in millions of hectares of injury to sensitive soybeans in the United States since 2016. Visual yield loss estimations following auxin injury can be difficult. The goal of this research was to determine if spectral variations following auxin injury to soybean allow for more precise yield loss estimations. Identical field experiments were performed in 2018, 2019, and 2020 in Columbia, Missouri to compare the ability of established vegetative indices to differentiate between exposure levels of 2,4-D and dicamba in soybean and predict yield loss. Soybeans were planted at three timings for growth stage separation and were exposed to sublethal rates of 2,4-D and dicamba at the R2, R1, and V3 growth stages. A UAV-mounted multispectral sensor was flown over the trial 14 days after the herbicide treatments. The results of this research found that vegetative indices incorporating the red-edge wavelength were more consistent in estimating yield loss than indices comprised of only visible or NIR wavelengths. Yield loss estimations became difficult when soybean injury occurred during later reproductive stages when soybean biomass was increased. This research also determined that when injury occurs to soybean in vegetative growth stages late in the growing season there is a greater likelihood for yield loss to occur due to decreased time for recovery. The results of this research could provide direction for more objective and accurate evaluations of yield loss following synthetic auxin injury than what is currently available.
KW  - dicamba
KW  - 2,4-D
KW  - UAV
KW  - vegetative index
DO  - 10.3390/rs13183682
ER  -
TY  - EJOU
AU  - Yang, Su
AU  - Hou, Miaole
AU  - Shaker, Ahmed
AU  - Li, Songnian
TI  - Modeling and Processing of Smart Point Clouds of Cultural Relics with Complex Geometries
T2  - ISPRS International Journal of Geo-Information

PY  - 2021
VL  - 10
IS  - 9
SN  - 2220-9964

AB  - The digital documentation of cultural relics plays an important role in archiving, protection, and management. In the field of cultural heritage, three-dimensional (3D) point cloud data is effective at expressing complex geometric structures and geometric details on the surface of cultural relics, but lacks semantic information. To elaborate the geometric information of cultural relics and add meaningful semantic information, we propose a modeling and processing method of smart point clouds of cultural relics with complex geometries. An information modeling framework for complex geometric cultural relics was designed based on the concept of smart point clouds, in which 3D point cloud data are organized through the time dimension and different spatial scales indicating different geometric details. The proposed model allows smart point clouds or a subset to be linked with semantic information or related documents. As such, this novel information modeling framework can be used to describe rich semantic information and high-level details of geometry. The proposed information model not only expresses the complex geometric structure of the cultural relics and the geometric details on the surface, but also has rich semantic information, and can even be associated with documents. A case study of the Dazu Thousand-Hand Bodhisattva Statue, which is characterized by a variety of complex geometries, reveals that our proposed framework is capable of modeling and processing the statue with excellent applicability and expansibility. This work provides insights into the sustainable development of cultural heritage protection globally.
KW  - cultural heritage
KW  - point cloud
KW  - 3D model
KW  - information modeling
KW  - complex geometry
DO  - 10.3390/ijgi10090617
ER  -
TY  - EJOU
AU  - Joseph, Seena
AU  - Olugbara, Oludayo O.
TI  - Detecting Salient Image Objects Using Color Histogram Clustering for Region Granularity
T2  - Journal of Imaging

PY  - 2021
VL  - 7
IS  - 9
SN  - 2313-433X

AB  - Salient object detection represents a novel preprocessing stage of many practical image applications in the discipline of computer vision. Saliency detection is generally a complex process to copycat the human vision system in the processing of color images. It is a convoluted process because of the existence of countless properties inherent in color images that can hamper performance. Due to diversified color image properties, a method that is appropriate for one category of images may not necessarily be suitable for others. The selection of image abstraction is a decisive preprocessing step in saliency computation and region-based image abstraction has become popular because of its computational efficiency and robustness. However, the performances of the existing region-based salient object detection methods are extremely hooked on the selection of an optimal region granularity. The incorrect selection of region granularity is potentially prone to under- or over-segmentation of color images, which can lead to a non-uniform highlighting of salient objects. In this study, the method of color histogram clustering was utilized to automatically determine suitable homogenous regions in an image. Region saliency score was computed as a function of color contrast, contrast ratio, spatial feature, and center prior. Morphological operations were ultimately performed to eliminate the undesirable artifacts that may be present at the saliency detection stage. Thus, we have introduced a novel, simple, robust, and computationally efficient color histogram clustering method that agglutinates color contrast, contrast ratio, spatial feature, and center prior for detecting salient objects in color images. Experimental validation with different categories of images selected from eight benchmarked corpora has indicated that the proposed method outperforms 30 bottom-up non-deep learning and seven top-down deep learning salient object detection methods based on the standard performance metrics.
KW  - color contrast
KW  - contrast ratio
KW  - histogram clustering
KW  - region saliency
KW  - saliency detection
DO  - 10.3390/jimaging7090187
ER  -
TY  - EJOU
AU  - Abdollahi, Abolfazl
AU  - Pradhan, Biswajeet
AU  - Shukla, Nagesh
AU  - Chakraborty, Subrata
AU  - Alamri, Abdullah
TI  - Multi-Object Segmentation in Complex Urban Scenes from High-Resolution Remote Sensing Data
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 18
SN  - 2072-4292

AB  - Terrestrial features extraction, such as roads and buildings from aerial images using an automatic system, has many usages in an extensive range of fields, including disaster management, change detection, land cover assessment, and urban planning. This task is commonly tough because of complex scenes, such as urban scenes, where buildings and road objects are surrounded by shadows, vehicles, trees, etc., which appear in heterogeneous forms with lower inter-class and higher intra-class contrasts. Moreover, such extraction is time-consuming and expensive to perform by human specialists manually. Deep convolutional models have displayed considerable performance for feature segmentation from remote sensing data in the recent years. However, for the large and continuous area of obstructions, most of these techniques still cannot detect road and building well. Hence, this work’s principal goal is to introduce two novel deep convolutional models based on UNet family for multi-object segmentation, such as roads and buildings from aerial imagery. We focused on buildings and road networks because these objects constitute a huge part of the urban areas. The presented models are called multi-level context gating UNet (MCG-UNet) and bi-directional ConvLSTM UNet model (BCL-UNet). The proposed methods have the same advantages as the UNet model, the mechanism of densely connected convolutions, bi-directional ConvLSTM, and squeeze and excitation module to produce the segmentation maps with a high resolution and maintain the boundary information even under complicated backgrounds. Additionally, we implemented a basic efficient loss function called boundary-aware loss (BAL) that allowed a network to concentrate on hard semantic segmentation regions, such as overlapping areas, small objects, sophisticated objects, and boundaries of objects, and produce high-quality segmentation maps. The presented networks were tested on the Massachusetts building and road datasets. The MCG-UNet improved the average F1 accuracy by 1.85%, and 1.19% and 6.67% and 5.11% compared with UNet and BCL-UNet for road and building extraction, respectively. Additionally, the presented MCG-UNet and BCL-UNet networks were compared with other state-of-the-art deep learning-based networks, and the results proved the superiority of the networks in multi-object segmentation tasks.
KW  - building extraction
KW  - boundary-aware loss
KW  - deep learning
KW  - remote sensing
KW  - road extraction
DO  - 10.3390/rs13183710
ER  -
TY  - EJOU
AU  - Jamali, Ali
AU  - Mahdianpari, Masoud
TI  - A Cloud-Based Framework for Large-Scale Monitoring of Ocean Plastics Using Multi-Spectral Satellite Imagery and Generative Adversarial Network
T2  - Water

PY  - 2021
VL  - 13
IS  - 18
SN  - 2073-4441

AB  - Marine debris is considered a threat to the inhabitants, as well as the marine environments. Accumulation of marine debris, besides climate change factors, including warming water, sea-level rise, and changes in oceans’ chemistry, are causing the potential collapse of the marine environment’s health. Due to the increase of marine debris, including plastics in coastlines, ocean and sea surfaces, and even in deep ocean layers, there is a need for developing new advanced technology for the detection of large-sized marine pollution (with sizes larger than 1 m) using state-of-the-art remote sensing and machine learning tools. Therefore, we developed a cloud-based framework for large-scale marine pollution detection with the integration of Sentinel-2 satellite imagery and advanced machine learning tools on the Sentinel Hub cloud application programming interface (API). Moreover, we evaluated the performance of two shallow machine learning algorithms of random forest (RF) and support vector machine (SVM), as well as the deep learning method of the generative adversarial network-random forest (GAN-RF) for the detection of ocean plastics in the pilot site of Mytilene Island, Greece. Based on the obtained results, the shallow algorithms of RF and SVM achieved an overall accuracy of 88% and 84%, respectively, with available training data of plastic debris. The GAN-RF classifier improved the detection of ocean plastics of the RF method by 8%, achieving an overall accuracy of 96% by generating several synthetic ocean plastic samples.
KW  - ocean plastics
KW  - support vector machine
KW  - random forest
KW  - marine debris
KW  - marine pollution
KW  - Sentinel Hub
KW  - generative adversarial network
DO  - 10.3390/w13182553
ER  -
TY  - EJOU
AU  - Richardson, Galen
AU  - Leblanc, Sylvain G.
AU  - Lovitt, Julie
AU  - Rajaratnam, Krishan
AU  - Chen, Wenjun
TI  - Leveraging AI to Estimate Caribou Lichen in UAV Orthomosaics from Ground Photo Datasets
T2  - Drones

PY  - 2021
VL  - 5
IS  - 3
SN  - 2504-446X

AB  - Relating ground photographs to UAV orthomosaics is a key linkage required for accurate multi-scaled lichen mapping. Conventional methods of multi-scaled lichen mapping, such as random forest models and convolutional neural networks, heavily rely on pixel DN values for classification. However, the limited spectral range of ground photos requires additional characteristics to differentiate lichen from spectrally similar objects, such as bright logs. By applying a neural network to tiles of a UAV orthomosaics, additional characteristics, such as surface texture and spatial patterns, can be used for inferences. Our methodology used a neural network (UAV LiCNN) trained on ground photo mosaics to predict lichen in UAV orthomosaic tiles. The UAV LiCNN achieved mean user and producer accuracies of 85.84% and 92.93%, respectively, in the high lichen class across eight different orthomosaics. We compared the known lichen percentages found in 77 vegetation microplots with the predicted lichen percentage calculated from the UAV LiCNN, resulting in a R2 relationship of 0.6910. This research shows that AI models trained on ground photographs effectively classify lichen in UAV orthomosaics. Limiting factors include the misclassification of spectrally similar objects to lichen in the RGB bands and dark shadows cast by vegetation.
KW  - image classification
KW  - lichen mapping
KW  - orthomosaics
KW  - artificial intelligence
KW  - UAV
DO  - 10.3390/drones5030099
ER  -
TY  - EJOU
AU  - Li, Daoliang
AU  - Du, Ling
TI  - AUV Trajectory Tracking Models and Control Strategies: A Review
T2  - Journal of Marine Science and Engineering

PY  - 2021
VL  - 9
IS  - 9
SN  - 2077-1312

AB  - Autonomous underwater vehicles (AUVs) have been widely used to perform underwater tasks. Due to the environmental disturbances, underactuated problems, system constraints, and system coupling, AUV trajectory tracking control is challenging. Thus, further investigation of dynamic characteristics and trajectory tracking control methods of the AUV motion system will be of great importance to improve underwater task performance. An AUV controller must be able to cope with various challenges with the underwater vehicle, adaptively update the reference model, and overcome unexpected deviations. In order to identify modeling strategies and the best control practices, this paper presents an overview of the main factors of control-oriented models and control strategies for AUVs. In modeling, two fields are considered: (i) models that come from simplifications of Fossen’s equations; and (ii) system identification models. For each category, a brief description of the control-oriented modeling strategies is given. In the control field, three relevant aspects are considered: (i) significance of AUV trajectory tracking control, (ii) control strategies; and (iii) control performance. For each aspect, the most important features are explained. Furthermore, in the aspect of control strategies, mathematical modeling study and physical experiment study are introduced in detail. Finally, with the aim of establishing the acceptability of the reported modeling and control techniques, as well as challenges that remain open, a discussion and a case study are presented. The literature review shows the development of new control-oriented models, the research in the estimation of unknown inputs, and the development of more innovative control strategies for AUV trajectory tracking systems are still open problems that must be addressed in the short term.
KW  - autonomous underwater vehicle
KW  - trajectory tracking
KW  - modeling
KW  - control strategies
DO  - 10.3390/jmse9091020
ER  -
TY  - EJOU
AU  - Benbouzid, Mohamed
AU  - Berghout, Tarek
AU  - Sarma, Nur
AU  - Djurović, Siniša
AU  - Wu, Yueqi
AU  - Ma, Xiandong
TI  - Intelligent Condition Monitoring of Wind Power Systems: State of the Art Review
T2  - Energies

PY  - 2021
VL  - 14
IS  - 18
SN  - 1996-1073

AB  - Modern wind turbines operate in continuously transient conditions, with varying speed, torque, and power based on the stochastic nature of the wind resource. This variability affects not only the operational performance of the wind power system, but can also affect its integrity under service conditions. Condition monitoring continues to play an important role in achieving reliable and economic operation of wind turbines. This paper reviews the current advances in wind turbine condition monitoring, ranging from conventional condition monitoring and signal processing tools to machine-learning-based condition monitoring and usage of big data mining for predictive maintenance. A systematic review is presented of signal-based and data-driven modeling methodologies using intelligent and machine learning approaches, with the view to providing a critical evaluation of the recent developments in this area, and their applications in diagnosis, prognosis, health assessment, and predictive maintenance of wind turbines and farms.
KW  - wind turbines
KW  - condition monitoring
KW  - diagnosis
KW  - prognosis
KW  - machine learning
KW  - data mining
KW  - health management
KW  - operations and maintenance
DO  - 10.3390/en14185967
ER  -
TY  - EJOU
AU  - Wen, Xiang
AU  - Li, Xing
AU  - Zhang, Ce
AU  - Han, Wenquan
AU  - Li, Erzhu
AU  - Liu, Wei
AU  - Zhang, Lianpeng
TI  - ME-Net: A Multi-Scale Erosion Network for Crisp Building Edge Detection from Very High Resolution Remote Sensing Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - The detection of building edges from very high resolution (VHR) remote sensing imagery is essential to various geo-related applications, including surveying and mapping, urban management, etc. Recently, the rapid development of deep convolutional neural networks (DCNNs) has achieved remarkable progress in edge detection; however, there has always been the problem of edge thickness due to the large receptive field of DCNNs. In this paper, we proposed a multi-scale erosion network (ME-Net) for building edge detection to crisp the building edge through two innovative approaches: (1) embedding an erosion module (EM) in the network to crisp the edge and (2) adding the Dice coefficient and local cross entropy of edge neighbors into the loss function to increase its sensitivity to the receptive field. In addition, a new metric, Ene, to measure the crispness of the predicted building edge was proposed. The experiment results show that ME-Net not only detects the clearest and crispest building edges, but also achieves the best OA of 98.75%, 95.00% and 95.51% on three building edge datasets, and exceeds other edge detection networks 3.17% and 0.44% at least in strict F1-score and Ene. In a word, the proposed ME-Net is an effective and practical approach for detecting crisp building edges from VHR remote sensing imagery.
KW  - building edge detection
KW  - deep convolutional neural network
KW  - erosion module
KW  - very high resolution remote sensing imagery
DO  - 10.3390/rs13193826
ER  -
TY  - EJOU
AU  - Deng, Hongjie
AU  - Ergu, Daji
AU  - Liu, Fangyao
AU  - Ma, Bo
AU  - Cai, Ying
TI  - An Embeddable Algorithm for Automatic Garbage Detection Based on Complex Marine Environment
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 19
SN  - 1424-8220

AB  - With the continuous development of artificial intelligence, embedding object detection algorithms into autonomous underwater detectors for marine garbage cleanup has become an emerging application area. Considering the complexity of the marine environment and the low resolution of the images taken by underwater detectors, this paper proposes an improved algorithm based on Mask R-CNN, with the aim of achieving high accuracy marine garbage detection and instance segmentation. First, the idea of dilated convolution is introduced in the Feature Pyramid Network to enhance feature extraction ability for small objects. Secondly, the spatial-channel attention mechanism is used to make features learn adaptively. It can effectively focus attention on detection objects. Third, the re-scoring branch is added to improve the accuracy of instance segmentation by scoring the predicted masks based on the method of Generalized Intersection over Union. Finally, we train the proposed algorithm in this paper on the Transcan dataset, evaluating its effectiveness by various metrics and comparing it with existing algorithms. The experimental results show that compared to the baseline provided by the Transcan dataset, the algorithm in this paper improves the mAP indexes on the two tasks of garbage detection and instance segmentation by 9.6 and 5.0, respectively, which significantly improves the algorithm performance. Thus, it can be better applied in the marine environment and achieve high precision object detection and instance segmentation.
KW  - deep learning
KW  - object detection
KW  - instance segmentation
KW  - marine ecology
KW  - the attentional mechanism
KW  - dilated convolution
DO  - 10.3390/s21196391
ER  -
TY  - EJOU
AU  - Pérez-Adán, Darian
AU  - Fresnedo, Óscar
AU  - González-Coma, José P.
AU  - Castedo, Luis
TI  - Intelligent Reflective Surfaces for Wireless Networks: An Overview of Applications, Approached Issues, and Open Problems
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 19
SN  - 2079-9292

AB  - An intelligent reflective surface (IRS) is a novel and revolutionizing communication technology destined to enable the control of the radio environment. An IRS is a real-time controllable reflectarray with a massive number of low-cost passive elements which introduce a phase shift to the incoming signals from the sources before the propagation towards the destination. This technology introduces the notion of a smart propagation environment with the aim of improving the system performance. In this paper, we provide a comprehensive literature overview on IRS technology, including its basic concepts and reconfiguration, as well as its design aspects and applications for wireless communication systems. We also study the performance metrics and the setups considered in recent publications related to IRS and provide suggestions of future research lines based on still unexplored use cases in the state-of-the-art.
KW  - intelligent reflective surfaces
KW  - smart propagation environments
KW  - IRS-aided wireless communication systems
DO  - 10.3390/electronics10192345
ER  -
TY  - EJOU
AU  - Kovačič, Boštjan
AU  - Štraus, Luka
AU  - Držečnik, Mateja
AU  - Pučko, Zoran
TI  - Applicability and Analysis of the Results of Non-Contact Methods in Determining the Vertical Displacements of Timber Beams
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 19
SN  - 2076-3417

AB  - Determining the displacements and consequent deformations of structures is a demanding branch of engineering. Displacements are most often determined by geodetic methods, among which high-precision non-contact methods have recently taken the lead. Engineering geodesy is an indispensable part of construction projects. In the desire for efficient and fast measurements, the technology of terrestrial laser scanning (TLS) and the use of robotic total station (RTS) and other geodetic methods are becoming more and more useful for engineers. In the presented study, we focused on the measurement and comparison of vertical displacements with various mentioned equipment and the determination of the influence of meteorological conditions on the displacements of timber beams that we used to perform the experiment. Measurements were performed both in the laboratory and outdoors. A novelty in the work was the use of a TLS scanner to determine the evaluation of small value displacements and the analysis of the usability of geodetic measuring equipment. In the Materials and Methods section, we describe the equipment used and the characteristics of the beams. The Results section describes the experimental outcomes, which include the performance of experimental analysis of vertical displacements of timber beams under different meteorological conditions. Altogether, the results consist of geodetic measurements and the processing of measured data. The results of measurements of vertical displacements with a terrestrial laser scanner were compared with the results obtained with a robotic total station were evaluated and compared with the displacements calculated from static analysis and the results of other methods used.
KW  - terrestrial laser scanning
KW  - displacements
KW  - geodesy
KW  - timber beams
KW  - robotic total station
DO  - 10.3390/app11198936
ER  -
TY  - EJOU
AU  - Pu, Yihan
AU  - Xu, Dandan
AU  - Wang, Haobin
AU  - An, Deshuai
AU  - Xu, Xia
TI  - Extracting Canopy Closure by the CHM-Based and SHP-Based Methods with a Hemispherical FOV from UAV-LiDAR Data in a Poplar Plantation
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - Canopy closure (CC), a useful biophysical parameter for forest structure, is an important indicator of forest resource and biodiversity. Light Detection and Ranging (LiDAR) data has been widely studied recently for forest ecosystems to obtain the three-dimensional (3D) structure of the forests. The components of the Unmanned Aerial Vehicle LiDAR (UAV-LiDAR) are similar to those of the airborne LiDAR, but with higher pulse density, which reveals more detailed vertical structures. Hemispherical photography (HP) had proven to be an effective method for estimating CC, but it was still time-consuming and limited in large forests. Thus, we used UAV-LiDAR data with a canopy-height-model-based (CHM-based) method and a synthetic-hemispherical-photography-based (SHP-based) method to extract CC from a pure poplar plantation in this study. The performance of the CC extraction methods based on an angular viewpoint was validated by the results of HP. The results showed that the CHM-based method had a high accuracy in a 45° zenith angle range with a 0.5 m pixel size and a larger radius (i.e., k = 2; R2 = 0.751, RMSE = 0.053), and the accuracy declined rapidly in zenith angles of 60° and 75° (R2 = 0.707, 0.490; RMSE = 0.053, 0.066). In addition, the CHM-based method showed an underestimate for leaf-off deciduous trees with low CC. The SHP-based method also had a high accuracy in a 45° zenith angle range, and its accuracy was stable in three zenith angle ranges (R2: 0.688, 0.674, 0.601 and RMSE = 0.059, 0.056, 0.058 for a 45°, 60° and 75° zenith angle range, respectively). There was a similar trend of CC change in HP and SHP results with the zenith angle range increase, but there was no significant change with the zenith angle range increase in the CHM-based method, which revealed that it was insensitive to the changes of angular CC compared to the SHP-based method. However, the accuracy of both methods showed differences in plantations with different ages, which had a slight underestimate for 8-year-old plantations and an overestimate for plantations with 17 and 20 years. Our research provided a reference for CC estimation from a point-based angular viewpoint and for monitoring the understory light conditions of plantations.
KW  - canopy closure
KW  - UAV
KW  - LiDAR
KW  - HP
KW  - CHM
KW  - SHP
KW  - poplar plantation
DO  - 10.3390/rs13193837
ER  -
TY  - EJOU
AU  - Neupane, Krishna
AU  - Baysal-Gurel, Fulya
TI  - Automatic Identification and Monitoring of Plant Diseases Using Unmanned Aerial Vehicles: A Review
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - Disease diagnosis is one of the major tasks for increasing food production in agriculture. Although precision agriculture (PA) takes less time and provides a more precise application of agricultural activities, the detection of disease using an Unmanned Aerial System (UAS) is a challenging task. Several Unmanned Aerial Vehicles (UAVs) and sensors have been used for this purpose. The UAVs’ platforms and their peripherals have their own limitations in accurately diagnosing plant diseases. Several types of image processing software are available for vignetting and orthorectification. The training and validation of datasets are important characteristics of data analysis. Currently, different algorithms and architectures of machine learning models are used to classify and detect plant diseases. These models help in image segmentation and feature extractions to interpret results. Researchers also use the values of vegetative indices, such as Normalized Difference Vegetative Index (NDVI), Crop Water Stress Index (CWSI), etc., acquired from different multispectral and hyperspectral sensors to fit into the statistical models to deliver results. There are still various drifts in the automatic detection of plant diseases as imaging sensors are limited by their own spectral bandwidth, resolution, background noise of the image, etc. The future of crop health monitoring using UAVs should include a gimble consisting of multiple sensors, large datasets for training and validation, the development of site-specific irradiance systems, and so on. This review briefly highlights the advantages of automatic detection of plant diseases to the growers.
KW  - UAS
KW  - UAVs
KW  - plant disease detection
KW  - plant monitoring
KW  - convolutional neural networks (CNNs)
KW  - deep learning
KW  - machine learning
DO  - 10.3390/rs13193841
ER  -
TY  - EJOU
AU  - Wu, Yiguang
AU  - Wang, Meizhen
AU  - Liu, Xuejun
AU  - Wang, Ziran
AU  - Ma, Tianwu
AU  - Lu, Zhimin
AU  - Liu, Dan
AU  - Xie, Yujia
AU  - Li, Xiuquan
AU  - Wang, Xing
TI  - Monitoring the Work Cycles of Earthmoving Excavators in Earthmoving Projects Using UAV Remote Sensing
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - Monitoring the work cycles of earthmoving excavators is an important aspect of construction productivity assessment. Currently, the most advanced method for the recognition of work cycles is the “Stretching-Bending” Sequential Pattern (SBSP), which is based on fixed-carrier video monitoring (FC-SBSP). However, the application of this method presupposes the availability of preconstructed installation carriers to act as a surveillance camera as well as installed and commissioned surveillance systems that work in tandem with them. Obviously, this method is difficult to apply to projects with no conditions for a monitoring camera installation or which have a short construction time. This highlights the potential application of Unmanned Aerial Vehicle (UAV) remote sensing, which is flexible and mobile. Unfortunately, few studies have been conducted on the application of UAV remote sensing for the work cycle monitoring of earthmoving excavators. This research is necessary because the use of UAV remote sensing for monitoring the work cycles of earthmoving excavators can improve construction productivity and save time and costs, especially in post-disaster reconstruction projects involving harsh construction environments, and emergency projects with short construction periods. In addition, the challenges posed by UAV shaking may have to be taken into account when using the SBSP for UAV remote sensing. To this end, this study used application experiments in which stabilization processing of UAV video data was performed for UAV shaking. The application experimental results show that the work cycle performance of UAV remote-sensing-based SBSP (UAV-SBSP) for UAV video data was 2.45% and 5.36% lower in terms of precision and recall, respectively, without stabilization processing than after stabilization processing. Comparative experiments were also designed to investigate the applicability of the SBSP oriented toward UAV remote sensing. Comparative experimental results show that the same level of performance was obtained for the recognition of work cycles with the UAV-SBSP as compared with the FC-SBSP, demonstrating the good applicability of this method. Therefore, the results of this study show that UAV remote sensing enables effective monitoring of earthmoving excavator work cycles in construction sites where monitoring cameras are not available for installation, and it can be used as an alternative technology to fixed-carrier video monitoring for onsite proximity monitoring.
KW  - UAV remote sensing
KW  - earthmoving project
KW  - earthmoving excavator
KW  - work cycles
KW  - “Stretching-Bending” Sequential Pattern (SBSP)
KW  - fixed-carrier video monitoring
KW  - UAV shaking
KW  - Intersection Over Union (IOU)
KW  - computer vision
KW  - deep learning
DO  - 10.3390/rs13193853
ER  -
TY  - EJOU
AU  - Czarnecki, Joby M. Prince
AU  - Samiappan, Sathishkumar
AU  - Zhou, Meilun
AU  - McCraine, Cary D.
AU  - Wasson, Louis L.
TI  - Real-Time Automated Classification of Sky Conditions Using Deep Learning and Edge Computing
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - The radiometric quality of remotely sensed imagery is crucial for precision agriculture applications because estimations of plant health rely on the underlying quality. Sky conditions, and specifically shadowing from clouds, are critical determinants in the quality of images that can be obtained from low-altitude sensing platforms. In this work, we first compare common deep learning approaches to classify sky conditions with regard to cloud shadows in agricultural fields using a visible spectrum camera. We then develop an artificial-intelligence-based edge computing system to fully automate the classification process. Training data consisting of 100 oblique angle images of the sky were provided to a convolutional neural network and two deep residual neural networks (ResNet18 and ResNet34) to facilitate learning two classes, namely (1) good image quality expected, and (2) degraded image quality expected. The expectation of quality stemmed from the sky condition (i.e., density, coverage, and thickness of clouds) present at the time of the image capture. These networks were tested using a set of 13,000 images. Our results demonstrated that ResNet18 and ResNet34 classifiers produced better classification accuracy when compared to a convolutional neural network classifier. The best overall accuracy was obtained by ResNet34, which was 92% accurate, with a Kappa statistic of 0.77. These results demonstrate a low-cost solution to quality control for future autonomous farming systems that will operate without human intervention and supervision.
KW  - autonomous systems
KW  - cloud detection
KW  - low-altitude remote sensing
KW  - ResNet
KW  - UAS image quality
DO  - 10.3390/rs13193859
ER  -
TY  - EJOU
AU  - Sharma, Vinamra B.
AU  - Tewari, Saurabh
AU  - Biswas, Susham
AU  - Lohani, Bharat
AU  - Dwivedi, Umakant D.
AU  - Dwivedi, Deepak
AU  - Sharma, Ashutosh
AU  - Jung, Jae P.
TI  - Recent Advancements in AI-Enabled Smart Electronics Packaging for Structural Health Monitoring
T2  - Metals

PY  - 2021
VL  - 11
IS  - 10
SN  - 2075-4701

AB  - Real-time health monitoring of civil infrastructures is performed to maintain their structural integrity, sustainability, and serviceability for a longer time. With smart electronics and packaging technology, large amounts of complex monitoring data are generated, requiring sophisticated artificial intelligence (AI) techniques for their processing. With the advancement of technology, more complex AI models have been applied, from simple models to sophisticated deep learning (DL) models, for structural health monitoring (SHM). In this article, a comprehensive review is performed, primarily on the applications of AI models for SHM to maintain the sustainability of diverse civil infrastructures. Three smart data capturing methods of SHM, namely, camera-based, smartphone-based, and unmanned aerial vehicle (UAV)-based methods, are also discussed, having made the utilization of intelligent paradigms easier. UAV is found to be the most promising smart data acquisition technology, whereas convolution neural networks are the most impressive DL model reported for SHM. Furthermore, current challenges and future perspectives of AI-based SHM systems are also described separately. Moreover, the Internet of Things (IoT) and smart city concepts are explained to elaborate on the contributions of intelligent SHM systems. The integration of SHM with IoT and cloud-based computing is leading us towards the evolution of future smart cities.
KW  - electronics packaging
KW  - lead-free solders
KW  - structural health monitoring
KW  - civil infrastructure
KW  - damage detection
KW  - pipeline leakage detection
DO  - 10.3390/met11101537
ER  -
TY  - EJOU
AU  - Montgomery, Joshua
AU  - Mahoney, Craig
AU  - Brisco, Brian
AU  - Boychuk, Lyle
AU  - Cobbaert, Danielle
AU  - Hopkinson, Chris
TI  - Remote Sensing of Wetlands in the Prairie Pothole Region of North America
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - The Prairie Pothole Region (PPR) of North America is an extremely important habitat for a diverse range of wetland ecosystems that provide a wealth of socio-economic value. This paper describes the ecological characteristics and importance of PPR wetlands and the use of remote sensing for mapping and monitoring applications. While there are comprehensive reviews for wetland remote sensing in recent publications, there is no comprehensive review about the use of remote sensing in the PPR. First, the PPR is described, including the wetland classification systems that have been used, the water regimes that control the surface water and water levels, and the soil and vegetation characteristics of the region. The tools and techniques that have been used in the PPR for analyses of geospatial data for wetland applications are described. Field observations for ground truth data are critical for good validation and accuracy assessment of the many products that are produced. Wetland classification approaches are reviewed, including Decision Trees, Machine Learning, and object versus pixel-based approaches. A comprehensive description of the remote sensing systems and data that have been employed by various studies in the PPR is provided. A wide range of data can be used for various applications, including passive optical data like aerial photographs or satellite-based, Earth-observation data. Both airborne and spaceborne lidar studies are described. A detailed description of Synthetic Aperture RADAR (SAR) data and research are provided. The state of the art is the use of multi-source data to achieve higher accuracies and hybrid approaches. Digital Surface Models are also being incorporated in geospatial analyses to separate forest and shrub and emergent systems based on vegetation height. Remote sensing provides a cost-effective mechanism for mapping and monitoring PPR wetlands, especially with the logistical difficulties and cost of field-based methods. The wetland characteristics of the PPR dictate the need for high resolution in both time and space, which is increasingly possible with the numerous and increasing remote sensing systems available and the trend to open-source data and tools. The fusion of multi-source remote sensing data via state-of-the-art machine learning is recommended for wetland applications in the PPR. The use of such data promotes flexibility for sensor addition, subtraction, or substitution as a function of application needs and potential cost restrictions. This is important in the PPR because of the challenges related to the highly dynamic nature of this unique region.
KW  - prairie pothole region
KW  - wetland
KW  - remote sensing
KW  - monitoring
KW  - classification
KW  - ecology
DO  - 10.3390/rs13193878
ER  -
TY  - EJOU
AU  - Gouiaa, Rafik
AU  - Akhloufi, Moulay A.
AU  - Shahbazi, Mozhdeh
TI  - Advances in Convolution Neural Networks Based Crowd Counting and Density Estimation
T2  - Big Data and Cognitive Computing

PY  - 2021
VL  - 5
IS  - 4
SN  - 2504-2289

AB  - Automatically estimating the number of people in unconstrained scenes is a crucial yet challenging task in different real-world applications, including video surveillance, public safety, urban planning, and traffic monitoring. In addition, methods developed to estimate the number of people can be adapted and applied to related tasks in various fields, such as plant counting, vehicle counting, and cell microscopy. Many challenges and problems face crowd counting, including cluttered scenes, extreme occlusions, scale variation, and changes in camera perspective. Therefore, in the past few years, tremendous research efforts have been devoted to crowd counting, and numerous excellent techniques have been proposed. The significant progress in crowd counting methods in recent years is mostly attributed to advances in deep convolution neural networks (CNNs) as well as to public crowd counting datasets. In this work, we review the papers that have been published in the last decade and provide a comprehensive survey of the recent CNNs based crowd counting techniques. We briefly review detection-based, regression-based, and traditional density estimation based approaches. Then, we delve into detail regarding the deep learning based density estimation approaches and recently published datasets. In addition, we discuss the potential applications of crowd counting and in particular its applications using unmanned aerial vehicle (UAV) images.
KW  - density estimation
KW  - crowd counting
KW  - deep learning
KW  - CNN
KW  - UAV
DO  - 10.3390/bdcc5040050
ER  -
TY  - EJOU
AU  - Zhang, Tianxiang
AU  - Xu, Zhiyong
AU  - Su, Jinya
AU  - Yang, Zhifang
AU  - Liu, Cunjia
AU  - Chen, Wen-Hua
AU  - Li, Jiangyun
TI  - Ir-UNet: Irregular Segmentation U-Shape Network for Wheat Yellow Rust Detection by UAV Multispectral Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - Crop disease is widely considered as one of the most pressing challenges for food crops, and therefore an accurate crop disease detection algorithm is highly desirable for its sustainable management. The recent use of remote sensing and deep learning is drawing increasing research interests in wheat yellow rust disease detection. However, current solutions on yellow rust detection are generally addressed by RGB images and the basic semantic segmentation algorithms (e.g., UNet), which do not consider the irregular and blurred boundary problems of yellow rust area therein, restricting the disease segmentation performance. Therefore, this work aims to develop an automatic yellow rust disease detection algorithm to cope with these boundary problems. An improved algorithm entitled Ir-UNet by embedding irregular encoder module (IEM), irregular decoder module (IDM) and content-aware channel re-weight module (CCRM) is proposed and compared against the basic UNet while with various input features. The recently collected dataset by DJI M100 UAV equipped with RedEdge multispectral camera is used to evaluate the algorithm performance. Comparative results show that the Ir-UNet with five raw bands outperforms the basic UNet, achieving the highest overall accuracy (OA) score (97.13%) among various inputs. Moreover, the use of three selected bands, Red-NIR-RE, in the proposed Ir-UNet can obtain a comparable result (OA: 96.83%) while with fewer spectral bands and less computation load. It is anticipated that this study by seamlessly integrating the Ir-UNet network and UAV multispectral images can pave the way for automated yellow rust detection at farmland scales.
KW  - deep learning
KW  - Ir-UNet
KW  - crop disease detection
KW  - multispectral imagery
KW  - unmanned aerial vehicle (UAV)
DO  - 10.3390/rs13193892
ER  -
TY  - EJOU
AU  - Khan, Mohammad Z.
AU  - Alhazmi, Omar H.
AU  - Javed, Muhammad A.
AU  - Ghandorh, Hamza
AU  - Aloufi, Khalid S.
TI  - Reliable Internet of Things: Challenges and Future Trends
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 19
SN  - 2079-9292

AB  - The Internet of Things (IoT) is a vital component of many future industries. By intelligent integration of sensors, wireless communications, computing techniques, and data analytics, IoT can increase productivity and efficiency of industries. Reliability of data transmission is key to realize several applications offered by IoT. In this paper, we present an overview of future IoT applications, and their major communication requirements. We provide a brief survey of recent work in four major areas of reliable IoT including resource allocation, latency management, security, and reliability metrics. Finally, we highlight some of the important challenges for reliable IoT related to machine learning techniques, 6G communications and blockchain based security that need further investigation and discuss related future directions.
KW  - IoT
KW  - resource allocation
KW  - latency
KW  - security
KW  - metrics
DO  - 10.3390/electronics10192377
ER  -
TY  - EJOU
AU  - Nooralishahi, Parham
AU  - Ibarra-Castanedo, Clemente
AU  - Deane, Shakeb
AU  - López, Fernando
AU  - Pant, Shashank
AU  - Genest, Marc
AU  - Avdelidis, Nicolas P.
AU  - Maldague, Xavier P. V.
TI  - Drone-Based Non-Destructive Inspection of Industrial Sites: A Review and Case Studies
T2  - Drones

PY  - 2021
VL  - 5
IS  - 4
SN  - 2504-446X

AB  - Using aerial platforms for Non-Destructive Inspection (NDI) of large and complex structures is a growing field of interest in various industries. Infrastructures such as: buildings, bridges, oil and gas, etc. refineries require regular and extensive inspections. The inspection reports are used to plan and perform required maintenance, ensuring their structural health and the safety of the workers. However, performing these inspections can be challenging due to the size of the facility, the lack of easy access, the health risks for the inspectors, or several other reasons, which has convinced companies to invest more in drones as an alternative solution to overcome these challenges. The autonomous nature of drones can assist companies in reducing inspection time and cost. Moreover, the employment of drones can lower the number of required personnel for inspection and can increase personnel safety. Finally, drones can provide a safe and reliable solution for inspecting hard-to-reach or hazardous areas. Despite the recent developments in drone-based NDI to reliably detect defects, several limitations and challenges still need to be addressed. In this paper, a brief review of the history of unmanned aerial vehicles, along with a comprehensive review of studies focused on UAV-based NDI of industrial and commercial facilities, are provided. Moreover, the benefits of using drones in inspections as an alternative to conventional methods are discussed, along with the challenges and open problems of employing drones in industrial inspections, are explored. Finally, some of our case studies conducted in different industrial fields in the field of Non-Destructive Inspection are presented.
KW  - unmanned aerial vehicle
KW  - thermography
KW  - non-destructive testing (NDT)
KW  - aerial inspection
DO  - 10.3390/drones5040106
ER  -
TY  - EJOU
AU  - Li, Shuyang
AU  - Hu, Xiaohui
AU  - Du, Yongwen
TI  - Deep Reinforcement Learning for Computation Offloading and Resource Allocation in Unmanned-Aerial-Vehicle Assisted Edge Computing
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 19
SN  - 1424-8220

AB  - Computation offloading technology extends cloud computing to the edge of the access network close to users, bringing many benefits to terminal devices with limited battery and computational resources. Nevertheless, the existing computation offloading approaches are challenging to apply to specific scenarios, such as the dense distribution of end-users and the sparse distribution of network infrastructure. The technological revolution in the unmanned aerial vehicle (UAV) and chip industry has granted UAVs more computing resources and promoted the emergence of UAV-assisted mobile edge computing (MEC) technology, which could be applied to those scenarios. However, in the MEC system with multiple users and multiple servers, making reasonable offloading decisions and allocating system resources is still a severe challenge. This paper studies the offloading decision and resource allocation problem in the UAV-assisted MEC environment with multiple users and servers. To ensure the quality of service for end-users, we set the weighted total cost of delay, energy consumption, and the size of discarded tasks as our optimization objective. We further formulate the joint optimization problem as a Markov decision process and apply the soft actor–critic (SAC) deep reinforcement learning algorithm to optimize the offloading policy. Numerical simulation results show that the offloading policy optimized by our proposed SAC-based dynamic computing offloading (SACDCO) algorithm effectively reduces the delay, energy consumption, and size of discarded tasks for the UAV-assisted MEC system. Compared with the fixed local-UAV scheme in the specific simulation setting, our proposed approach reduces system delay and energy consumption by approximately 50% and 200%, respectively.
KW  - unmanned aerial vehicle
KW  - edge computing
KW  - computation offloading
KW  - resource allocation
KW  - soft actor–critic
DO  - 10.3390/s21196499
ER  -
TY  - EJOU
AU  - Xia, Shuang
AU  - Zhang, Xiangyin
TI  - Constrained Path Planning for Unmanned Aerial Vehicle in 3D Terrain Using Modified Multi-Objective Particle Swarm Optimization
T2  - Actuators

PY  - 2021
VL  - 10
IS  - 10
SN  - 2076-0825

AB  - This paper considered the constrained unmanned aerial vehicle (UAV) path planning problem as the multi-objective optimization problem, in which both costs and constraints are treated as the objective functions. A novel multi-objective particle swarm optimization algorithm based on the Gaussian distribution and the Q-Learning technique (GMOPSO-QL) is proposed and applied to determine the feasible and optimal path for UAV. In GMOPSO-QL, the Gaussian distribution based updating operator is adopted to generate new particles, and the exploration and exploitation modes are introduced to enhance population diversity and convergence speed, respectively. Moreover, the Q-Learning based mode selection logic is introduced to balance the global search with the local search in the evolution process. Simulation results indicate that our proposed GMOPSO-QL can deal with the constrained UAV path planning problem and is superior to existing optimization algorithms in terms of efficiency and robustness.
KW  - 3D path planning
KW  - multi-objective particle swarm optimization
KW  - unmanned aerial vehicle
KW  - Q-Learning
DO  - 10.3390/act10100255
ER  -
TY  - EJOU
AU  - Saddik, Amine
AU  - Latif, Rachid
AU  - El Ouardi, Abdelhafid
TI  - Low-Power FPGA Architecture Based Monitoring Applications in Precision Agriculture
T2  - Journal of Low Power Electronics and Applications

PY  - 2021
VL  - 11
IS  - 4
SN  - 2079-9268

AB  - Today’s on-chip systems technology has grounded impressive advances in computing power and energy consumption. The choice of the right architecture depends on the application. In our case, we were studying vegetation monitoring algorithms in precision agriculture. This study presents a system based on a monitoring algorithm for agricultural fields, an electronic architecture based on a CPU-FPGA SoC system and the OpenCL parallel programming paradigm. We focused our study on our own dataset of agricultural fields to validate the results. The fields studied in our case are in the Guelmin-Oued noun region in the south of Morocco. These fields are divided into two areas, with a total surface of 3.44 Ha2 for the first field and 3.73 Ha2 for the second. The images were collected using a DJI-type unmanned aerial vehicle and an RGB camera. Performance evaluation showed that the system could process up to 86 fps versus 12 fps or 20 fps in C/C++ and OpenMP implementations, respectively. Software optimizations have increased the performance to 107 fps, which meets real-time constraints.
KW  - CPU-FPGA SoC
KW  - on-chip systems
KW  - embedded systems
KW  - precision agriculture
DO  - 10.3390/jlpea11040039
ER  -
TY  - EJOU
AU  - Zawadzka, Joanna
AU  - Truckell, Ian
AU  - Khouakhi, Abdou
AU  - Rivas Casado, Mónica
TI  - Detection of Flood Damage in Urban Residential Areas Using Object-Oriented UAV Image Analysis Coupled with Tree-Based Classifiers
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - Timely clearing-up interventions are essential for effective recovery of flood-damaged housing, however, time-consuming door-to-door inspections for insurance purposes need to take place before major repairs can be done to adequately assess the losses caused by flooding. With the increased probability of flooding, there is a heightened need for rapid flood damage assessment methods. High resolution imagery captured by unmanned aerial vehicles (UAVs) offers an opportunity for accelerating the time needed for inspections, either through visual interpretation or automated image classification. In this study, object-oriented image segmentation coupled with tree-based classifiers was implemented on a 10 cm resolution RGB orthoimage, captured over the English town of Cockermouth a week after a flood triggered by storm Desmond, to automatically detect debris associated with damages predominantly to residential housing. Random forests algorithm achieved a good level of overall accuracy of 74%, with debris being correctly classified at the rate of 58%, and performing well for small debris (67%) and skips (64%). The method was successful at depicting brightly-colored debris, however, was prone to misclassifications with brightly-colored vehicles. Consequently, in the current stage, the methodology could be used to facilitate visual interpretation of UAV images. Methods to improve accuracy have been identified and discussed.
KW  - urban flood damage
KW  - UAV
KW  - object-oriented image analysis
DO  - 10.3390/rs13193913
ER  -
TY  - EJOU
AU  - Korchagin, Sergey A.
AU  - Gataullin, Sergey T.
AU  - Osipov, Aleksey V.
AU  - Smirnov, Mikhail V.
AU  - Suvorov, Stanislav V.
AU  - Serdechnyi, Denis V.
AU  - Bublikov, Konstantin V.
TI  - Development of an Optimal Algorithm for Detecting Damaged and Diseased Potato Tubers Moving along a Conveyor Belt Using Computer Vision Systems
T2  - Agronomy

PY  - 2021
VL  - 11
IS  - 10
SN  - 2073-4395

AB  - The article discusses the problem of detecting sick or mechanically damaged potatoes using machine learning methods. We proposed an algorithm and developed a system for the rapid detection of damaged tubers. The system can be installed on a conveyor belt in a vegetable store, and it consists of a laptop computer and an action camera, synchronized with a flashlight system. The algorithm consists of two phases. The first phase uses the Viola-Jones algorithm, applied to the filtered action camera image, so it aims to detect separate potato tubers on the conveyor belt. The second phase is the application of a method that we choose based on video capturing conditions. To isolate potatoes infected with certain types of diseases (dry rot, for example), we use the Scale Invariant Feature Transform (SIFT)—Support Vector Machine (SVM) method. In case of inconsistent or weak lighting, the histogram of oriented gradients (HOG)—Bag-of-Visual-Words (BOVW)—neural network (BPNN) method is used. Otherwise, Otsu’s threshold binarization—a convolutional neural network (CNN) method is used. The first phase’s result depends on the conveyor’s speed, the density of tubers on the conveyor, and the accuracy of the video system. With the optimal setting, the result reaches 97%. The second phase’s outcome depends on the method and varies from 80% to 97%. When evaluating the performance of the system, it was found that it allows to detect and classify up to 100 tubers in one second, which significantly exceeds the performance of most similar systems.
KW  - neural networks
KW  - defects detection
KW  - crop
KW  - potato disease
KW  - potato classification
KW  - fast detection
KW  - machine learning
DO  - 10.3390/agronomy11101980
ER  -
TY  - EJOU
AU  - Pan, Qian
AU  - Gao, Maofang
AU  - Wu, Pingbo
AU  - Yan, Jingwen
AU  - Li, Shilei
TI  - A Deep-Learning-Based Approach for Wheat Yellow Rust Disease Recognition from Unmanned Aerial Vehicle Images
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 19
SN  - 1424-8220

AB  - Yellow rust is a disease with a wide range that causes great damage to wheat. The traditional method of manually identifying wheat yellow rust is very inefficient. To improve this situation, this study proposed a deep-learning-based method for identifying wheat yellow rust from unmanned aerial vehicle (UAV) images. The method was based on the pyramid scene parsing network (PSPNet) semantic segmentation model to classify healthy wheat, yellow rust wheat, and bare soil in small-scale UAV images, and to investigate the spatial generalization of the model. In addition, it was proposed to use the high-accuracy classification results of traditional algorithms as weak samples for wheat yellow rust identification. The recognition accuracy of the PSPNet model in this study reached 98%. On this basis, this study used the trained semantic segmentation model to recognize another wheat field. The results showed that the method had certain generalization ability, and its accuracy reached 98%. In addition, the high-accuracy classification result of a support vector machine was used as a weak label by weak supervision, which better solved the labeling problem of large-size images, and the final recognition accuracy reached 94%. Therefore, the present study method facilitated timely control measures to reduce economic losses.
KW  - generalization ability
KW  - PSPNet
KW  - UAV image
KW  - weak label
KW  - weakly supervised learning
KW  - wheat yellow rust
DO  - 10.3390/s21196540
ER  -
TY  - EJOU
AU  - Shen, Ying
AU  - Li, Jie
AU  - Lin, Wenfu
AU  - Chen, Liqiong
AU  - Huang, Feng
AU  - Wang, Shu
TI  - Camouflaged Target Detection Based on Snapshot Multispectral Imaging
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - The spectral information contained in the hyperspectral images (HSI) distinguishes the intrinsic properties of a target from the background, which is widely used in remote sensing. However, the low imaging speed and high data redundancy caused by the high spectral resolution of imaging spectrometers limit their application in scenarios with the real-time requirement. In this work, we achieve the precise detection of camouflaged targets based on snapshot multispectral imaging technology and band selection methods in urban-related scenes. Specifically, the camouflaged target detection algorithm combines the constrained energy minimization (CEM) algorithm and the improved maximum between-class variance (OTSU) algorithm (t-OTSU), which is proposed to obtain the initial target detection results and adaptively segment the target region. Moreover, an object region extraction (ORE) algorithm is proposed to obtain a complete target contour that improves the target detection capability of multispectral images (MSI). The experimental results show that the proposed algorithm has the ability to detect different camouflaged targets by using only four bands. The detection accuracy is above 99%, and the false alarm rate is below 0.2%. The research achieves the effective detection of camouflaged targets and has the potential to provide a new means for real-time multispectral sensing in complex scenes.
KW  - snapshot multispectral imaging
KW  - camouflaged target detection
KW  - CEM
KW  - OTSU
KW  - urban object-analysis
DO  - 10.3390/rs13193949
ER  -
TY  - EJOU
AU  - Berghout, Tarek
AU  - Benbouzid, Mohamed
AU  - Bentrcia, Toufik
AU  - Ma, Xiandong
AU  - Djurović, Siniša
AU  - Mouss, Leïla-Hayet
TI  - Machine Learning-Based Condition Monitoring for PV Systems: State of the Art and Future Prospects
T2  - Energies

PY  - 2021
VL  - 14
IS  - 19
SN  - 1996-1073

AB  - To ensure the continuity of electric power generation for photovoltaic systems, condition monitoring frameworks are subject to major enhancements. The continuous uniform delivery of electric power depends entirely on a well-designed condition maintenance program. A just-in-time task to deal with several naturally occurring faults can be correctly undertaken via the cooperation of effective detection, diagnosis, and prognostic analyses. Therefore, the present review first outlines different failure modes to which all photovoltaic systems are subjected, in addition to the essential integrated detection methods and technologies. Then, data-driven paradigms, and their contribution to solving this prediction problem, are also explored. Accordingly, this review primarily investigates the different learning architectures used (i.e., ordinary, hybrid, and ensemble) in relation to their learning frameworks (i.e., traditional and deep learning). It also discusses the extension of machine learning to knowledge-driven approaches, including generative models such as adversarial networks and transfer learning. Finally, this review provides insights into different works to highlight various operating conditions and different numbers and types of failures, and provides links to some publicly available datasets in the field. The clear organization of the abundant information on this subject may result in rigorous guidelines for the trends adopted in the future.
KW  - photovoltaic systems
KW  - machine learning
KW  - deep learning
KW  - condition monitoring
KW  - faults diagnosis
KW  - fault detection
KW  - open source datasets
DO  - 10.3390/en14196316
ER  -
TY  - EJOU
AU  - Zhuang, Jiedong
AU  - Dai, Ming
AU  - Chen, Xuruoyan
AU  - Zheng, Enhui
TI  - A Faster and More Effective Cross-View Matching Method of UAV and Satellite Images for UAV Geolocalization
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - Cross-view geolocalization matches the same target in different images from various views, such as views of unmanned aerial vehicles (UAVs) and satellites, which is a key technology for UAVs to autonomously locate and navigate without a positioning system (e.g., GPS and GNSS). The most challenging aspect in this area is the shifting of targets and nonuniform scales among different views. Published methods focus on extracting coarse features from parts of images, but neglect the relationship between different views, and the influence of scale and shifting. To bridge this gap, an effective network is proposed with well-designed structures, referred to as multiscale block attention (MSBA), based on a local pattern network. MSBA cuts images into several parts with different scales, among which self-attention is applied to make feature extraction more efficient. The features of different views are extracted by a multibranch structure, which was designed to make different branches learn from each other, leading to a more subtle relationship between views. The method was implemented with the newest UAV-based geolocalization dataset. Compared with the existing state-of-the-art (SOTA) method, MSBA accuracy improved by almost 10% when the inference time was equal to that of the SOTA method; when the accuracy of MSBA was the same as that of the SOTA method, inference time was shortened by 30%.
KW  - cross-view image matching
KW  - geolocalization
KW  - UAV image localization
KW  - deep neural network
DO  - 10.3390/rs13193979
ER  -
TY  - EJOU
AU  - Kim, Taeheon
AU  - Han, Youkyung
TI  - Integrated Preprocessing of Multitemporal Very-High-Resolution Satellite Images via Conjugate Points-Based Pseudo-Invariant Feature Extraction
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 19
SN  - 2072-4292

AB  - Multitemporal very-high-resolution (VHR) satellite images are used as core data in the field of remote sensing because they express the topography and features of the region of interest in detail. However, geometric misalignment and radiometric dissimilarity occur when acquiring multitemporal VHR satellite images owing to external environmental factors, and these errors cause various inaccuracies, thereby hindering the effective use of multitemporal VHR satellite images. Such errors can be minimized by applying preprocessing methods such as image registration and relative radiometric normalization (RRN). However, as the data used in image registration and RRN differ, data consistency and computational efficiency are impaired, particularly when processing large amounts of data, such as a large volume of multitemporal VHR satellite images. To resolve these issues, we proposed an integrated preprocessing method by extracting pseudo-invariant features (PIFs), used for RRN, based on the conjugate points (CPs) extracted for image registration. To this end, the image registration was performed using CPs extracted using the speeded-up robust feature algorithm. Then, PIFs were extracted based on the CPs by removing vegetation areas followed by application of the region growing algorithm. Experiments were conducted on two sites constructed under different acquisition conditions to confirm the robustness of the proposed method. Various analyses based on visual and quantitative evaluation of the experimental results were performed from geometric and radiometric perspectives. The results evidence the successful integration of the image registration and RRN preprocessing steps by achieving a reasonable and stable performance.
KW  - multitemporal very-high-resolution satellite image
KW  - image registration
KW  - relative radiometric normalization
KW  - integrated preprocessing
KW  - pseudo invariant features
KW  - conjugate points
DO  - 10.3390/rs13193990
ER  -
TY  - EJOU
AU  - Sánchez-Balseca, Joseph
AU  - Pérez-Foguet, Agustií
TI  - Compositional Spatio-Temporal PM2.5 Modelling in Wildfires
T2  - Atmosphere

PY  - 2021
VL  - 12
IS  - 10
SN  - 2073-4433

AB  - Wildfires are natural ecological processes that generate high levels of fine particulate matter (PM2.5) that are dispersed into the atmosphere. PM2.5 could be a potential health problem due to its size. Having adequate numerical models to predict the spatial and temporal distribution of PM2.5 helps to mitigate the impact on human health. The compositional data approach is widely used in the environmental sciences and concentration analyses (parts of a whole). This numerical approach in the modelling process avoids one common statistical problem: the spurious correlation. PM2.5 is a part of the atmospheric composition. In this way, this study developed an hourly spatio-temporal PM2.5 model based on the dynamic linear modelling framework (DLM) with a compositional approach. The results of the model are extended using a Gaussian–Mattern field. The modelling of PM2.5 using a compositional approach presented adequate quality model indices (NSE = 0.82, RMSE = 0.23, and a Pearson correlation coefficient of 0.91); however, the correlation range showed a slightly lower value than the conventional/traditional approach. The proposed method could be used in spatial prediction in places without monitoring stations.
KW  - air pollution
KW  - CoDa
KW  - environmental statistics
KW  - DLM
KW  - Gaussian fields
DO  - 10.3390/atmos12101309
ER  -
TY  - EJOU
AU  - Byun, Sungwoo
AU  - Shin, In-Kyoung
AU  - Moon, Jucheol
AU  - Kang, Jiyoung
AU  - Choi, Sang-Il
TI  - Road Traffic Monitoring from UAV Images Using Deep Learning Networks
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - In this paper, we propose a deep neural network-based method for estimating speed of vehicles on roads automatically from videos recorded using unmanned aerial vehicle (UAV). The proposed method includes the following; (1) detecting and tracking vehicles by analyzing the videos, (2) calculating the image scales using the distances between lanes on the roads, and (3) estimating the speeds of vehicles on the roads. Our method can automatically measure the speed of the vehicles from the only videos recorded using UAV without additional information in both directions on the roads simultaneously. In our experiments, we evaluate the performance of the proposed method with the visual data at four different locations. The proposed method shows 97.6% recall rate and 94.7% precision rate in detecting vehicles, and it shows error (root mean squared error) of 5.27 km/h in estimating the speeds of vehicles.
KW  - deep learning
KW  - UAV image
KW  - traffic monitoring
KW  - object detection
KW  - object tracking
KW  - image segmentation
DO  - 10.3390/rs13204027
ER  -
TY  - EJOU
AU  - Zhao, Jianghong
AU  - Wang, Yinrui
AU  - Cao, Yuee
AU  - Guo, Ming
AU  - Huang, Xianfeng
AU  - Zhang, Ruiju
AU  - Dou, Xintong
AU  - Niu, Xinyu
AU  - Cui, Yuanyuan
AU  - Wang, Jun
TI  - The Fusion Strategy of 2D and 3D Information Based on Deep Learning: A Review
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - Recently, researchers have realized a number of achievements involving deep-learning-based neural networks for the tasks of segmentation and detection based on 2D images, 3D point clouds, etc. Using 2D and 3D information fusion for the advantages of compensation and accuracy improvement has become a hot research topic. However, there are no critical reviews focusing on the fusion strategies of 2D and 3D information integration based on various data for segmentation and detection, which are the basic tasks of computer vision. To boost the development of this research domain, the existing representative fusion strategies are collected, introduced, categorized, and summarized in this paper. In addition, the general structures of different kinds of fusion strategies were firstly abstracted and categorized, which may inspire researchers. Moreover, according to the methods included in this paper, the 2D information and 3D information of different methods come from various kinds of data. Furthermore, suitable datasets are introduced and comparatively summarized to support the relative research. Last but not least, we put forward some open challenges and promising directions for future research.
KW  - fusion strategy
KW  - deep learning
KW  - segmentation
KW  - detection
DO  - 10.3390/rs13204029
ER  -
TY  - EJOU
AU  - Khun, Kosal
AU  - Tremblay, Nicolas
AU  - Panneton, Bernard
AU  - Vigneault, Philippe
AU  - Lord, Etienne
AU  - Cavayas, François
AU  - Codjia, Claude
TI  - Use of Oblique RGB Imagery and Apparent Surface Area of Plants for Early Estimation of Above-Ground Corn Biomass
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - Estimating above-ground biomass in the context of fertilization management requires the monitoring of crops at early stages. Conventional remote sensing techniques make use of vegetation indices such as the normalized difference vegetation index (NDVI), but they do not exploit the high spatial resolution (ground sampling distance &lt; 5 mm) now achievable with the introduction of unmanned aerial vehicles (UAVs) in agriculture. The aim of this study was to compare image mosaics to single images for the estimation of corn biomass and the influence of viewing angles in this estimation. Nadir imagery was captured by a high spatial resolution camera mounted on a UAV to generate orthomosaics of corn plots at different growth stages (from V2 to V7). Nadir and oblique images (30° and 45° with respect to the vertical) were also acquired from a zip line platform and processed as single images. Image segmentation was performed using the difference color index Excess Green-Excess Red, allowing for the discrimination between vegetation and background pixels. The apparent surface area of plants was then extracted and compared to biomass measured in situ. An asymptotic total least squares regression was performed and showed a strong relationship between the apparent surface area of plants and both dry and fresh biomass. Mosaics tended to underestimate the apparent surface area in comparison to single images because of radiometric degradation. It is therefore conceivable to process only single images instead of investing time and effort in acquiring and processing data for orthomosaic generation. When comparing oblique photography, an angle of 30° yielded the best results in estimating corn biomass, with a low residual standard error of orthogonal distance (RSEOD = 0.031 for fresh biomass, RSEOD = 0.034 for dry biomass). Since oblique imagery provides more flexibility in data acquisition with fewer constraints on logistics, this approach might be an efficient way to monitor crop biomass at early stages.
KW  - Zea mays L.
KW  - corn
KW  - biomass
KW  - oblique imagery
KW  - precision agriculture
KW  - low-altitude remote sensing
KW  - UAV
KW  - drone
DO  - 10.3390/rs13204032
ER  -
TY  - EJOU
AU  - Mirmazloumi, S. M.
AU  - Moghimi, Armin
AU  - Ranjgar, Babak
AU  - Mohseni, Farzane
AU  - Ghorbanian, Arsalan
AU  - Ahmadi, Seyed A.
AU  - Amani, Meisam
AU  - Brisco, Brian
TI  - Status and Trends of Wetland Studies in Canada Using Remote Sensing Technology with a Focus on Wetland Classification: A Bibliographic Analysis
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - A large portion of Canada is covered by wetlands; mapping and monitoring them is of great importance for various applications. In this regard, Remote Sensing (RS) technology has been widely employed for wetland studies in Canada over the past 45 years. This study evaluates meta-data to investigate the status and trends of wetland studies in Canada using RS technology by reviewing the scientific papers published between 1976 and the end of 2020 (300 papers in total). Initially, a meta-analysis was conducted to analyze the status of RS-based wetland studies in terms of the wetland classification systems, methods, classes, RS data usage, publication details (e.g., authors, keywords, citations, and publications time), geographic information, and level of classification accuracies. The deep systematic review of 128 peer-reviewed articles illustrated the rising trend in using multi-source RS datasets along with advanced machine learning algorithms for wetland mapping in Canada. It was also observed that most of the studies were implemented over the province of Ontario. Pixel-based supervised classifiers were the most popular wetland classification algorithms. This review summarizes different RS systems and methodologies for wetland mapping in Canada to outline how RS has been utilized for the generation of wetland inventories. The results of this review paper provide the current state-of-the-art methods and datasets for wetland studies in Canada and will provide direction for future wetland mapping research.
KW  - Canada
KW  - classification
KW  - remote sensing
KW  - wetland
DO  - 10.3390/rs13204025
ER  -
TY  - EJOU
AU  - Yu, Run
AU  - Luo, Youqing
AU  - Li, Haonan
AU  - Yang, Liyuan
AU  - Huang, Huaguo
AU  - Yu, Linfeng
AU  - Ren, Lili
TI  - Three-Dimensional Convolutional Neural Network Model for Early Detection of Pine Wilt Disease Using UAV-Based Hyperspectral Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - As one of the most devastating disasters to pine forests, pine wilt disease (PWD) has caused tremendous ecological and economic losses in China. An effective way to prevent large-scale PWD outbreaks is to detect and remove the damaged pine trees at the early stage of PWD infection. However, early infected pine trees do not show obvious changes in morphology or color in the visible wavelength range, making early detection of PWD tricky. Unmanned aerial vehicle (UAV)-based hyperspectral imagery (HI) has great potential for early detection of PWD. However, the commonly used methods, such as the two-dimensional convolutional neural network (2D-CNN), fail to simultaneously extract and fully utilize the spatial and spectral information, whereas the three-dimensional convolutional neural network (3D-CNN) is able to collect this information from raw hyperspectral data. In this paper, we applied the residual block to 3D-CNN and constructed a 3D-Res CNN model, the performance of which was then compared with that of 3D-CNN, 2D-CNN, and 2D-Res CNN in identifying PWD-infected pine trees from the hyperspectral images. The 3D-Res CNN model outperformed the other models, achieving an overall accuracy (OA) of 88.11% and an accuracy of 72.86% for detecting early infected pine trees (EIPs). Using only 20% of the training samples, the OA and EIP accuracy of 3D-Res CNN can still achieve 81.06% and 51.97%, which is superior to the state-of-the-art method in the early detection of PWD based on hyperspectral images. Collectively, 3D-Res CNN was more accurate and effective in early detection of PWD. In conclusion, 3D-Res CNN is proposed for early detection of PWD in this paper, making the prediction and control of PWD more accurate and effective. This model can also be applied to detect pine trees damaged by other diseases or insect pests in the forest.
KW  - pine wilt disease
KW  - early detection
KW  - UAV-based hyperspectral imagery
KW  - 3D-CNN
KW  - 3D-Res CNN
DO  - 10.3390/rs13204065
ER  -
TY  - EJOU
AU  - Nguyen, Lanh V.
AU  - Phung, Manh D.
AU  - Ha, Quang P.
TI  - Iterative Learning Sliding Mode Control for UAV Trajectory Tracking
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 20
SN  - 2079-9292

AB  - This paper presents a novel iterative learning sliding mode controller (ILSMC) that can be applied to the trajectory tracking of quadrotor unmanned aerial vehicles (UAVs) subject to model uncertainties and external disturbances. Here, the proposed ILSMC is integrated in the outer loop of a controlled system. The control development, conducted in the discrete-time domain, does not require a priori information of the disturbance bound as with conventional SMC techniques. It only involves an equivalent control term for the desired dynamics in the closed loop and an iterative learning term to drive the system state toward the sliding surface to maintain robust performance. By learning from previous iterations, the ILSMC can yield very accurate tracking performance when a sliding mode is induced without control chattering. The design is then applied to the attitude control of a 3DR Solo UAV with a built-in PID controller. The simulation results and experimental validation with real-time data demonstrate the advantages of the proposed control scheme over existing techniques.
KW  - iterative learning
KW  - sliding mode control
KW  - unmanned arial vehicles
KW  - trajectory tracking
DO  - 10.3390/electronics10202474
ER  -
TY  - EJOU
AU  - Megat Mohamed Nazir, Megat N.
AU  - Terhem, Razak
AU  - Norhisham, Ahmad R.
AU  - Mohd Razali, Sheriza
AU  - Meder, Roger
TI  - Early Monitoring of Health Status of Plantation-Grown Eucalyptus pellita at Large Spatial Scale via Visible Spectrum Imaging of Canopy Foliage Using Unmanned Aerial Vehicles
T2  - Forests

PY  - 2021
VL  - 12
IS  - 10
SN  - 1999-4907

AB  - Eucalyptus is a diverse genus from which several species are often deployed for commercial industrial tree plantation due to their desirable wood properties for utilization in both solid wood and fiber products, as well as their growth and productivity in many environments. In this study, a method for monitoring the health status of a 22.78 ha Eucalyptus pellita plantation stand was developed using the red-green-blue channels captured using an unmanned aerial vehicle. The ortho-image was generated, and visual atmospheric resistance index (VARI) indices were developed. Herein, four classification levels of pest and disease were generated using the VARI-green algorithm. The range of normalized VARI-green indices was between −2.0 and 2.0. The results identified seven dead trees (VARI-green index −2 to 0), five trees that were severely infected (VARI-green index 0 to 0.05), 967 trees that were mildly infected (VARI-green index 0.06 to 0.16), and 10,090 trees that were considered healthy (VARI-green index 0.17 to 2.00). The VARI-green indices were verified by manual ground-truthing and by comparison with normalized difference vegetation index which showed a mean correlation of 0.73. This study has shown practical application of aerial survey of a large-scale operational area of industrial tree plantation via low-cost UAV and RGB camera, to analyze VARI-green images in the detection of pest and disease.
KW  - Eucalyptus
KW  - health status
KW  - VARI-green
KW  - aerial survey
KW  - pest
KW  - disease
DO  - 10.3390/f12101393
ER  -
TY  - EJOU
AU  - Ndlovu, Helen S.
AU  - Odindi, John
AU  - Sibanda, Mbulisi
AU  - Mutanga, Onisimo
AU  - Clulow, Alistair
AU  - Chimonyo, Vimbayi G. P.
AU  - Mabhaudhi, Tafadzwanashe
TI  - A Comparative Estimation of Maize Leaf Water Content Using Machine Learning Techniques and Unmanned Aerial Vehicle (UAV)-Based Proximal and Remotely Sensed Data
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - Determining maize water content variability is necessary for crop monitoring and in developing early warning systems to optimise agricultural production in smallholder farms. However, spatially explicit information on maize water content, particularly in Southern Africa, remains elementary due to the shortage of efficient and affordable primary sources of suitable spatial data at a local scale. Unmanned Aerial Vehicles (UAVs), equipped with light-weight multispectral sensors, provide spatially explicit, near-real-time information for determining the maize crop water status at farm scale. Therefore, this study evaluated the utility of UAV-derived multispectral imagery and machine learning techniques in estimating maize leaf water indicators: equivalent water thickness (EWT), fuel moisture content (FMC), and specific leaf area (SLA). The results illustrated that both NIR and red-edge derived spectral variables were critical in characterising the maize water indicators on smallholder farms. Furthermore, the best models for estimating EWT, FMC, and SLA were derived from the random forest regression (RFR) algorithm with an rRMSE of 3.13%, 1%, and 3.48%, respectively. Additionally, EWT and FMC yielded the highest predictive performance and were the most optimal indicators of maize leaf water content. The findings are critical towards developing a robust and spatially explicit monitoring framework of maize water status and serve as a proxy of crop health and the overall productivity of smallholder maize farms.
KW  - precision agriculture
KW  - maize monitoring
KW  - UAV applications
KW  - smallholder farming
KW  - machine learning
DO  - 10.3390/rs13204091
ER  -
TY  - EJOU
AU  - Yang, Baohua
AU  - Zhu, Yue
AU  - Zhou, Shuaijun
TI  - Accurate Wheat Lodging Extraction from Multi-Channel UAV Images Using a Lightweight Network Model
T2  - Sensors

PY  - 2021
VL  - 21
IS  - 20
SN  - 1424-8220

AB  - The extraction of wheat lodging is of great significance to post-disaster agricultural production management, disaster assessment and insurance subsidies. At present, the recognition of lodging wheat in the actual complex field environment still has low accuracy and poor real-time performance. To overcome this gap, first, four-channel fusion images, including RGB and DSM (digital surface model), as well as RGB and ExG (excess green), were constructed based on the RGB image acquired from unmanned aerial vehicle (UAV). Second, a Mobile U-Net model that combined a lightweight neural network with a depthwise separable convolution and U-Net model was proposed. Finally, three data sets (RGB, RGB + DSM and RGB + ExG) were used to train, verify, test and evaluate the proposed model. The results of the experiment showed that the overall accuracy of lodging recognition based on RGB + DSM reached 88.99%, which is 11.8% higher than that of original RGB and 6.2% higher than that of RGB + ExG. In addition, our proposed model was superior to typical deep learning frameworks in terms of model parameters, processing speed and segmentation accuracy. The optimized Mobile U-Net model reached 9.49 million parameters, which was 27.3% and 33.3% faster than the FCN and U-Net models, respectively. Furthermore, for RGB + DSM wheat lodging extraction, the overall accuracy of Mobile U-Net was improved by 24.3% and 15.3% compared with FCN and U-Net, respectively. Therefore, the Mobile U-Net model using RGB + DSM could extract wheat lodging with higher accuracy, fewer parameters and stronger robustness.
KW  - UAV
KW  - wheat lodging
KW  - deep learning
KW  - lightweight
KW  - digital surface model (DSM)
DO  - 10.3390/s21206826
ER  -
TY  - EJOU
AU  - Mohidem, Nur A.
AU  - Che’Ya, Nik N.
AU  - Juraimi, Abdul S.
AU  - Fazlil Ilahi, Wan F.
AU  - Mohd Roslim, Muhammad H.
AU  - Sulaiman, Nursyazyla
AU  - Saberioon, Mohammadmehdi
AU  - Mohd Noor, Nisfariza
TI  - How Can Unmanned Aerial Vehicles Be Used for Detecting Weeds in Agricultural Fields?
T2  - Agriculture

PY  - 2021
VL  - 11
IS  - 10
SN  - 2077-0472

AB  - Weeds are among the most harmful abiotic factors in agriculture, triggering significant yield loss worldwide. Remote sensing can detect and map the presence of weeds in various spectral, spatial, and temporal resolutions. This review aims to show the current and future trends of UAV applications in weed detection in the crop field. This study systematically searched the original articles published from 1 January 2016 to 18 June 2021 in the databases of Scopus, ScienceDirect, Commonwealth Agricultural Bureaux (CAB) Direct, and Web of Science (WoS) using Boolean string: “weed” AND “Unmanned Aerial Vehicle” OR “UAV” OR “drone”. Out of the papers identified, 144 eligible studies did meet our inclusion criteria and were evaluated. Most of the studies (i.e., 27.42%) on weed detection were carried out during the seedling stage of the growing cycle for the crop. Most of the weed images were captured using red, green, and blue (RGB) camera, i.e., 48.28% and main classification algorithm was machine learning techniques, i.e., 47.90%. This review initially highlighted articles from the literature that includes the crops’ typical phenology stage, reference data, type of sensor/camera, classification methods, and current UAV applications in detecting and mapping weed for different types of crop. This study then provides an overview of the advantages and disadvantages of each sensor and algorithm and tries to identify research gaps by providing a brief outlook at the potential areas of research concerning the benefit of this technology in agricultural industries. Integrated weed management, coupled with UAV application improves weed monitoring in a more efficient and environmentally-friendly way. Overall, this review demonstrates the scientific information required to achieve sustainable weed management, so as to implement UAV platform in the real agricultural contexts.
KW  - precision agriculture
KW  - unmanned aerial vehicle
KW  - weed
DO  - 10.3390/agriculture11101004
ER  -
TY  - EJOU
AU  - Rabiei, Saman
AU  - Jalilvand, Ehsan
AU  - Tajrishy, Massoud
TI  - A Method to Estimate Surface Soil Moisture and Map the Irrigated Cropland Area Using Sentinel-1 and Sentinel-2 Data
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 20
SN  - 2071-1050

AB  - Considering variations in surface soil moisture (SSM) is essential in improving crop yield and irrigation scheduling. Today, most remotely sensed soil moisture products have difficulties in resolving irrigation signals at the plot scale. This study aims to use Sentinel-1 radar backscatter and Sentinel-2 multispectral imagery to estimate SSM at high spatial (10 m) and temporal resolution (at least 5 days) over an agricultural domain. Three supervised machine learning algorithms, multilayer perceptron (MLP), a convolutional neural network (CNN), and linear regression models, were trained to estimate changes in SSM based on the variation in surface reflectance and backscatter over five different crops. Results showed that CNN is the best algorithm as it understands spatial relations and better represents two-dimensional images. Estimated values for SSM were in agreement with in-situ measurements regardless of the crop type, with RMSE=0.0292&nbsp;(cm3/cm3) and R2=0.92 for the Sentinel-2 derived SSM and RMSE=0.0317&nbsp;(cm3/cm3) and R2=0.84 for the Sentinel-1 soil moisture data. Moreover, a time series of estimated SSM based on Sentinel-1 (SSM-S1), Sentinel-2 (SSM-S2), and SSM derived from SMAP-Sentinel1 was compared. The developed SSM data showed a significantly higher mean SSM state over irrigated agriculture relative to the rainfed cropland area during the irrigation season. The multiple comparisons (fisher LSD) were tested and found that these two groups are different (pvalue=0.035 in 95% confidence interval). Therefore, by employing the maximum likelihood classification on the SSM data, we managed to map the irrigated agriculture. The overall accuracy of this unsupervised classification is 77%, with a kappa coefficient of 65%.
KW  - soil moisture
KW  - Sentinel-1
KW  - Sentinel-2
KW  - irrigation mapping
KW  - change detection
KW  - supervised learning
KW  - machine learning
DO  - 10.3390/su132011355
ER  -
TY  - EJOU
AU  - Guo, Xuzhan
AU  - Liu, Qingwang
AU  - Sharma, Ram P.
AU  - Chen, Qiao
AU  - Ye, Qiaolin
AU  - Tang, Shouzheng
AU  - Fu, Liyong
TI  - Tree Recognition on the Plantation Using UAV Images with Ultrahigh Spatial Resolution in a Complex Environment
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - The survival rate of seedlings is a decisive factor of afforestation assessment. Generally, ground checking is more accurate than any other methods. However, the survival rate of seedlings can be higher in the growing season, and this can be estimated in a larger area at a relatively lower cost by extracting the tree crown from the unmanned aerial vehicle (UAV) images, which provides an opportunity for monitoring afforestation in an extensive area. At present, studies on extracting individual tree crowns under the complex ground vegetation conditions are limited. Based on the afforestation images obtained by airborne consumer-grade cameras in central China, this study proposes a method of extracting and fusing multiple radii morphological features to obtain the potential crown. A random forest (RF) was used to identify the regions extracted from the images, and then the recognized crown regions were fused selectively according to the distance. A low-cost individual crown recognition framework was constructed for rapid checking of planted trees. The method was tested in two afforestation areas of 5950 m2 and 5840 m2, with a population of 2418 trees (Koelreuteria) in total. Due to the complex terrain of the sample plot, high weed coverage, the crown width of trees, and spacing of saplings vary greatly, which increases both the difficulty and complexity of crown extraction. Nevertheless, recall and F-score of the proposed method reached 93.29%, 91.22%, and 92.24% precisions, respectively, and 2212 trees were correctly recognized and located. The results show that the proposed method is robust to the change of brightness and to splitting up of a multi-directional tree crown, and is an automatic solution for afforestation verification.
KW  - individual trees crown
KW  - multi-radius extraction
KW  - chromatic mapping
KW  - feature extraction
KW  - complex environment
KW  - spectral index
DO  - 10.3390/rs13204122
ER  -
TY  - EJOU
AU  - Li, Dongmei
AU  - Zhao, Li
AU  - Guo, Zhiming
AU  - Yang, Xi
AU  - Deng, Wei
AU  - Zhong, Haoxiang
AU  - Zhou, Peng
TI  - Marine Debris in the Beilun Estuary Mangrove Forest: Monitoring, Assessment and Implications
T2  - International Journal of Environmental Research and Public Health

PY  - 2021
VL  - 18
IS  - 20
SN  - 1660-4601

AB  - A modified approach for marine debris investigation in mangrove forests is developed, including some practical programs, viz., sampling location, time, area, materials, size and sources data processing. The marine debris method was practiced in the Beilun Estuary mangrove forest region in Fangchenggang in 2019, viz., the debris items were classified, counted, weighed and recorded, and the marine debris pollution was assessed to understand the impact of human activities. The results show that the mass density is 21.123 (2.355~51.760) g/m2, and more than 90% came from the land-based and human activities. More than 60% of the total debris weights are plastics, followed by fabrics (17.91%) and Styrofoam (10.07%); the big-size and oversize debris account for 76.41% and 13.33%, respectively. The quantity density is 0.163 (0.013~0.420) item/m2, and ~95% came from land-based human activities. More than 75% of the total debris items were plastics, followed by Styrofoam (14.36%), fabrics (4.10%) and glass (3.59%); the big-size, medium-size and oversize debris are 76.41%, 13.33% and 10.26%, respectively. The results suggest that mangrove forests are barriers for the medium-/big-size marine debris, acting as traps for marine debris. Our study provides recommendations and practical guidance for establishing programs to monitor and assess the distribution and abundance of marine debris. The results show that mangrove areas in the Beilun Estuary are filled with some plastic debris (plastics plus Styrofoam) and that the density and type at Zhushan and Rongshutou near the China-Vietnam border are more than those at Shijiao and Jiaodong. The results of this study are also expected to not only provide baseline data for the future assessment of Beilun Estuary mangroves but also to help China and Vietnam strengthen marine land-based pollution control and promote coastal wetland and mangrove conservation, marine species conservation and sustainable use.
KW  - debris pollution
KW  - mangrove forest
KW  - Beilun Estuary
KW  - monitoring and assessment
DO  - 10.3390/ijerph182010826
ER  -
TY  - EJOU
AU  - Wang, Chuan
AU  - Lan, Hongjie
AU  - Saldanha-da-Gama, Francisco
AU  - Chen, Youhua
TI  - On Optimizing a Multi-Mode Last-Mile Parcel Delivery System with Vans, Truck and Drone
T2  - Electronics

PY  - 2021
VL  - 10
IS  - 20
SN  - 2079-9292

AB  - This work focuses on the optimization of a last-mile delivery system with multiple transportation modes. In this scenario, parcels need to be delivered to each customer point. The major feature of the problem is the combination of a fleet of road vehicles (vans) with a drone. Each van visits a subset of demand nodes to be determined according to the route of the van. The drone serves the customers not served by vans. At the same time, considering the safety, policy and terrain as well as the need to replace the battery, the drone needs to be transported by truck to the identified station along with the parcel. From each such station, the drone serves a subset of customers according to a direct assignment pattern, i.e., every time the drone is launched, it serves one demand node and returns to the station to collect another parcel. Similarly, the truck is used to transport the drone and cargo between stations. This is somewhat different from the research of other scholars. In terms of the joint distribution of the drone and road vehicle, most scholars will choose the combination of two transportation tools, while we use three. The drone and vans are responsible for distribution services, and the trucks are responsible for transporting the goods and drone to the station. The goal is to optimize the total delivery cost which includes the transportation costs for the vans and the delivery cost for the drone. A fixed cost is also considered for each drone parking site corresponding to the cost of positioning the drone and using the drone station. A discrete optimization model is presented for the problem in addition to a two-phase heuristic algorithm. The results of a series of computational tests performed to assess the applicability of the model and the efficiency of the heuristic are reported. The results obtained show that nearly 10% of the cost can be saved by combining the traditional delivery mode with the use of a drone and drone stations.
KW  - logistics
KW  - last-mile distribution
KW  - multiple traveling salesmen problem
KW  - unmanned aerial vehicle
KW  - heuristic algorithm
DO  - 10.3390/electronics10202510
ER  -
TY  - EJOU
AU  - Bao, Wenxia
AU  - Ren, Yangxun
AU  - Wang, Nian
AU  - Hu, Gensheng
AU  - Yang, Xianjun
TI  - Detection of Abnormal Vibration Dampers on Transmission Lines in UAV Remote Sensing Images with PMA-YOLO
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - The accurate detection and timely replacement of abnormal vibration dampers on transmission lines are critical for the safe and stable operation of power systems. Recently, unmanned aerial vehicles (UAVs) have become widely used to inspect transmission lines. In this paper, we constructed a data set of abnormal vibration dampers (DAVDs) on transmission lines in images obtained by UAVs. There are four types of vibration dampers in this data set, and each vibration damper may be rusty, defective, or normal. The challenges in the detection of abnormal vibration dampers on transmission lines in the images captured by UAVs were as following: the images had a high resolution as well as the objects of vibration dampers were relatively small and sparsely distributed, and the backgrounds of cross stage partial networks of the images were complex due to the fact that the transmission lines were erected in a variety of outdoor environments. Existing methods of ground-based object detection significantly reduced the accuracy when dealing with complex backgrounds and small objects of abnormal vibration dampers detection. To address these issues, we proposed an end-to-end parallel mixed attention You Only Look Once (PMA-YOLO) network to improve the detection performance for abnormal vibration dampers. The parallel mixed attention (PMA) module was introduced and integrated into the YOLOv4 network. This module combines a channel attention block and a spatial attention block, and the convolution results of the input feature maps in parallel, allowing the network to pay more attention to critical regions of abnormal vibration dampers in complex background images. Meanwhile, in view of the problem that abnormal vibration dampers are prone to missing detections, we analyzed the scale and ratio of the ground truth boxes and used the K-means algorithm to re-cluster new anchors for abnormal vibration dampers in images. In addition, we introduced a multi-stage transfer learning strategy to improve the efficiency of the original training method and prevent overfitting by the network. The experimental results showed that the mAP@0.5 for PMA-YOLO in the detection of abnormal vibration dampers reached 93.8% on the test set of DAVD, 3.5% higher than that of YOLOv4. When the multi-stage transfer learning strategy was used, the mAP@0.5 was improved by a further 0.2%.
KW  - objective detection
KW  - vibration dampers
KW  - UAV remote sensing images
KW  - transmission lines
KW  - YOLOv4
KW  - attention mechanism
KW  - transfer learning
DO  - 10.3390/rs13204134
ER  -
TY  - EJOU
AU  - Zhou, Xuan
AU  - Ke, Ruimin
AU  - Yang, Hao
AU  - Liu, Chenxi
TI  - When Intelligent Transportation Systems Sensing Meets Edge Computing: Vision and Challenges
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 20
SN  - 2076-3417

AB  - The widespread use of mobile devices and sensors has motivated data-driven applications that can leverage the power of big data to benefit many aspects of our daily life, such as health, transportation, economy, and environment. Under the context of smart city, intelligent transportation systems (ITS), as a main building block of modern cities, and edge computing (EC), as an emerging computing service that targets addressing the limitations of cloud computing, have attracted increasing attention in the research community in recent years. It is well believed that the application of EC in ITS will have considerable benefits to transportation systems regarding efficiency, safety, and sustainability. Despite the growing trend in ITS and EC research, a big gap in the existing literature is identified: the intersection between these two promising directions has been far from well explored. In this paper, we focus on a critical part of ITS, i.e., sensing, and conducting a review on the recent advances in ITS sensing and EC applications in this field. The key challenges in ITS sensing and future directions with the integration of edge computing are discussed.
KW  - intelligent transportation systems
KW  - sensing technology
KW  - edge computing
KW  - traffic data
DO  - 10.3390/app11209680
ER  -
TY  - EJOU
AU  - Ahmad, Uzair
AU  - Alvino, Arturo
AU  - Marino, Stefano
TI  - A Review of Crop Water Stress Assessment Using Remote Sensing
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - Currently, the world is facing high competition and market risks in improving yield, crop illness, and crop water stress. This could potentially be addressed by technological advancements in the form of precision systems, improvements in production, and through ensuring the sustainability of development. In this context, remote-sensing systems are fully equipped to address the complex and technical assessment of crop production, security, and crop water stress in an easy and efficient way. They provide simple and timely solutions for a diverse set of ecological zones. This critical review highlights novel methods for evaluating crop water stress and its correlation with certain measurable parameters, investigated using remote-sensing systems. Through an examination of previous literature, technologies, and data, we review the application of remote-sensing systems in the analysis of crop water stress. Initially, the study presents the relationship of relative water content (RWC) with equivalent water thickness (EWT) and soil moisture crop water stress. Evapotranspiration and sun-induced chlorophyll fluorescence are then analyzed in relation to crop water stress using remote sensing. Finally, the study presents various remote-sensing technologies used to detect crop water stress, including optical sensing systems, thermometric sensing systems, land-surface temperature-sensing systems, multispectral (spaceborne and airborne) sensing systems, hyperspectral sensing systems, and the LiDAR sensing system. The study also presents the future prospects of remote-sensing systems in analyzing crop water stress and how they could be further improved.
KW  - crop water stress
KW  - hyperspectral
KW  - LiDAR
KW  - multispectral
KW  - optical sensing
KW  - remote sensing
KW  - sentinel-1
KW  - soil moisture
KW  - thermometric sensing
DO  - 10.3390/rs13204155
ER  -
TY  - EJOU
AU  - Muhadi, Nur A.
AU  - Abdullah, Ahmad F.
AU  - Bejo, Siti K.
AU  - Mahadi, Muhammad R.
AU  - Mijic, Ana
TI  - Deep Learning Semantic Segmentation for Water Level Estimation Using Surveillance Camera
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 20
SN  - 2076-3417

AB  - The interest in visual-based surveillance systems, especially in natural disaster applications, such as flood detection and monitoring, has increased due to the blooming of surveillance technology. In this work, semantic segmentation based on convolutional neural networks (CNN) was proposed to identify water regions from the surveillance images. This work presented two well-established deep learning algorithms, DeepLabv3+ and SegNet networks, and evaluated their performances using several evaluation metrics. Overall, both networks attained high accuracy when compared to the measurement data but the DeepLabv3+ network performed better than the SegNet network, achieving over 90% for overall accuracy and IoU metrics, and around 80% for boundary F1 score (BF score), respectively. When predicting new images using both trained networks, the results show that both networks successfully distinguished water regions from the background but the outputs from DeepLabv3+ were more accurate than the results from the SegNet network. Therefore, the DeepLabv3+ network was used for practical application using a set of images captured at five consecutive days in the study area. The segmentation result and water level markers extracted from light detection and ranging (LiDAR) data were overlaid to estimate river water levels and observe the water fluctuation. River water levels were predicted based on the elevation from the predefined markers. The proposed water level framework was evaluated according to Spearman’s rank-order correlation coefficient. The correlation coefficient was 0.91, which indicates a strong relationship between the estimated water level and observed water level. Based on these findings, it can be concluded that the proposed approach has high potential as an alternative monitoring system that offers water region information and water level estimation for flood management and related activities.
KW  - flood detection
KW  - deep learning
KW  - water level estimation
KW  - water segmentation
KW  - CCTV
KW  - CNN
DO  - 10.3390/app11209691
ER  -
TY  - EJOU
AU  - Liu, Yan
AU  - Wang, Jingwen
AU  - Qiu, Tiantian
AU  - Qi, Wenting
TI  - An Adaptive Deblurring Vehicle Detection Method for High-Speed Moving Drones: Resistance to Shake
T2  - Entropy

PY  - 2021
VL  - 23
IS  - 10
SN  - 1099-4300

AB  - Vehicle detection is an essential part of an intelligent traffic system, which is an important research field in drone application. Because unmanned aerial vehicles (UAVs) are rarely configured with stable camera platforms, aerial images are easily blurred. There is a challenge for detectors to accurately locate vehicles in blurred images in the target detection process. To improve the detection performance of blurred images, an end-to-end adaptive vehicle detection algorithm (DCNet) for drones is proposed in this article. First, the clarity evaluation module is used to determine adaptively whether the input image is a blurred image using improved information entropy. An improved GAN called Drone-GAN is proposed to enhance the vehicle features of blurred images. Extensive experiments were performed, the results of which show that the proposed method can detect both blurred and clear images well in poor environments (complex illumination and occlusion). The detector proposed achieves larger gains compared with SOTA detectors. The proposed method can enhance the vehicle feature details in blurred images effectively and improve the detection accuracy of blurred aerial images, which shows good performance with regard to resistance to shake.
KW  - unmanned aerial vehicle
KW  - vehicle detection
KW  - entropy
KW  - resistance to shake
DO  - 10.3390/e23101358
ER  -
TY  - EJOU
AU  - Fotouhi, Sakineh
AU  - Khayatzadeh, Saber
AU  - Pui, Wei X.
AU  - Damghani, Mahdi
AU  - Bodaghi, Mahdi
AU  - Fotouhi, Mohamad
TI  - Detection of Barely Visible Impact Damage in Polymeric Laminated Composites Using a Biomimetic Tactile Whisker
T2  - Polymers

PY  - 2021
VL  - 13
IS  - 20
SN  - 2073-4360

AB  - This is a novel investigation on the possibility of detecting barely visible impact damage (BVID) in composite materials by whisking across the surface via tactile whisker sensors that resemble rats’ whiskers. A series of drop tower low-velocity impact tests were performed on quasi-isotropic composite plates. The plates were made from unidirectional T800 carbon/MTM49-3 epoxy prepregs with the stacking sequence of [45/0/90/−45]4S. Investigating the specimens’ surface by the naked eye does not reveal any significant damage, rather than a small dent on the surface, with no tangible difference in the different impact energy levels. Ultrasonic C-scan observations showed the existence of BVID in all the impact energy levels, with an increasing trend in the damage size by increasing the impact energy level. The collected data from whisker sensors were analyzed using the support vector machine classifier, based on their vibrational properties, to identify the impacted region and classify the impact severity. It was observed that after training for 13 whisker contacts, the BVID severity can be classified with an accuracy of 100%. This is offering a new BVID detection technique, with a high potential for automation and high reliability that can be used as an alternative or combined with available inspection systems.
KW  - composite materials
KW  - damage detection
KW  - low velocity impact
KW  - whisker
KW  - ultrasonic
DO  - 10.3390/polym13203587
ER  -
TY  - EJOU
AU  - Nguyen, Tran X.
AU  - Rosser, Kent
AU  - Chahl, Javaan
TI  - A Review of Modern Thermal Imaging Sensor Technology and Applications for Autonomous Aerial Navigation
T2  - Journal of Imaging

PY  - 2021
VL  - 7
IS  - 10
SN  - 2313-433X

AB  - Limited navigation capabilities of many current robots and UAVs restricts their applications in GPS denied areas. Large aircraft with complex navigation systems rely on a variety of sensors including radio frequency aids and high performance inertial systems rendering them somewhat resistant to GPS denial. The rapid development of computer vision has seen cameras incorporated into small drones. Vision-based systems, consisting of one or more cameras, could arguably satisfy both size and weight constraints faced by UAVs. A new generation of thermal sensors is available that are lighter, smaller and widely available. Thermal sensors are a solution to enable navigation in difficult environments, including in low-light, dust or smoke. The purpose of this paper is to present a comprehensive literature review of thermal sensors integrated into navigation systems. Furthermore, the physics and characteristics of thermal sensors will also be presented to provide insight into challenges when integrating thermal sensors in place of conventional visual spectrum sensors.
KW  - review
KW  - UAVs
KW  - optical flow
KW  - simultaneous localization and mapping
KW  - SLAM
KW  - thermal imaging
KW  - LWIR
KW  - navigation
KW  - neural network
DO  - 10.3390/jimaging7100217
ER  -
TY  - EJOU
AU  - Li, Jing
AU  - Song, Yafei
TI  - Design of Supply Chain System Based on Blockchain Technology
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 20
SN  - 2076-3417

AB  - As the interaction between companies becomes more and more complex, the problems of asymmetric information, weak traceability, and low collaboration efficiency in the traditional centralized supply chain are becoming increasingly prominent. To solve these problems, this paper designs a supply chain system based on blockchain. With the help of trade chain and information chain platforms, an overall framework of the supply chain system is constructed. By formulating platform interaction rules, the system information exchange format is standardized to ensure the stability and efficiency of system interaction. Smart contracts are used to manage supply chain system transactions and information interactions to achieve efficient and convenient information sharing, ensuring the security and reliability of supply chain information. The comprehensive performance of the system is evaluated through experiments. Experimental results indicate that while the system realizes the basic functions of the supply chain, it can promote the sharing of information between participants and improve its efficiency.
KW  - supply chain
KW  - blockchain
KW  - information sharing
KW  - smart contract
KW  - alliance chain
DO  - 10.3390/app11209744
ER  -
TY  - EJOU
AU  - Huang, Zhaoyang
AU  - Wang, Feng
AU  - You, Hongjian
AU  - Hu, Yuxin
TI  - STC-Det: A Slender Target Detector Combining Shadow and Target Information in Optical Satellite Images
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 20
SN  - 2072-4292

AB  - Object detection has made great progress. However, due to the unique imaging method of optical satellite remote sensing, the detection of slender targets is still insufficient. Specifically, the perspective of optical satellites is small, and the characteristics of slender targets are severely lost during imaging, resulting in insufficient detection task information; at the same time, the appearance of slender targets in the image is greatly affected by the satellite perspective, which is likely to cause insufficient generalization capabilities of conventional detection models. In response to these two points, we have made some improvements. First, in this paper, we introduce the shadow as auxiliary information to complement the trunk features of the target lost in imaging. Second, to reduce the impact of satellite perspective on imaging, in this paper, we use the characteristic that shadow information is not affected by satellite perspective to design STC-Det. STC-Det treats the shadow and the target as two different types of targets and uses the shadow information to assist the detection, reducing the impact of the satellite perspective on detection. Among them, in order to improve the performance of STC-Det, we propose an automatic matching method (AMM) of shadow and target and a feature fusion method (FFM). Finally, this paper proposes a new method to calculate the heatmaps of detectors, which verifies the effectiveness of the proposed network in a visual way. Experiments show that when the satellite perspective is variable, the precision of STC-Det is increased by 1.7%, and when the satellite perspective is small, the precision of STC-Det is increased by 5.2%.
KW  - optical satellite image
KW  - shadow
KW  - slender targets
KW  - object detection
DO  - 10.3390/rs13204183
ER  -
TY  - EJOU
AU  - Bennett, Rohan M.
AU  - Koeva, Mila
AU  - Asiama, Kwabena
TI  - Review of Remote Sensing for Land Administration: Origins, Debates, and Selected Cases
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Conventionally, land administration—incorporating cadastres and land registration—uses ground-based survey methods. This approach can be traced over millennia. The application of photogrammetry and remote sensing is understood to be far more contemporary, only commencing deeper into the 20th century. This paper seeks to counter this view, contending that these methods are far from recent additions to land administration: successful application dates back much earlier, often complementing ground-based methods. Using now more accessible historical works, made available through archive digitisation, this paper presents an enriched and more complete synthesis of the developments of photogrammetric methods and remote sensing applied to the domain of land administration. Developments from early phototopography and aerial surveys, through to analytical photogrammetric methods, the emergence of satellite remote sensing, digital cameras, and latterly lidar surveys, UAVs, and feature extraction are covered. The synthesis illustrates how debates over the benefits of the technique are hardly new. Neither are well-meaning, although oft-flawed, comparative analyses on criteria relating to time, cost, coverage, and quality. Apart from providing this more holistic view and a timely reminder of previous work, this paper brings contemporary practical value in further demonstrating to land administration practitioners that remote sensing for data capture, and subsequent map production, are an entirely legitimate, if not essential, part of the domain. Contemporary arguments that the tools and approaches do not bring adequate accuracy for land administration purposes are easily countered by the weight of evidence. Indeed, these arguments may be considered to undermine the pragmatism inherent to the surveying discipline, traditionally an essential characteristic of the profession. That said, it is left to land administration practitioners to determine the relevance of these methods for any specific country context.
KW  - photogrammetry
KW  - aerial imagery
KW  - UAV
KW  - HRSI
KW  - lidar
KW  - artificial intelligence
DO  - 10.3390/rs13214198
ER  -
TY  - EJOU
AU  - Koay, Hong V.
AU  - Chuah, Joon H.
AU  - Chow, Chee-Onn
AU  - Chang, Yang-Lang
AU  - Yong, Keh K.
TI  - YOLO-RTUAV: Towards Real-Time Vehicle Detection through Aerial Images with Low-Cost Edge Devices
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Object detection in aerial images has been an active research area thanks to the vast availability of unmanned aerial vehicles (UAVs). Along with the increase of computational power, deep learning algorithms are commonly used for object detection tasks. However, aerial images have large variations, and the object sizes are usually small, rendering lower detection accuracy. Besides, real-time inferencing on low-cost edge devices remains an open-ended question. In this work, we explored the usage of state-of-the-art deep learning object detection on low-cost edge hardware. We propose YOLO-RTUAV, an improved version of YOLOv4-Tiny, as the solution. We benchmarked our proposed models with various state-of-the-art models on the VAID and COWC datasets. Our proposed model can achieve higher mean average precision (mAP) and frames per second (FPS) than other state-of-the-art tiny YOLO models, especially on a low-cost edge device such as the Jetson Nano 2 GB. It was observed that the Jetson Nano 2 GB can achieve up to 12.8 FPS with a model size of only 5.5 MB.
KW  - object detection
KW  - deep learning
KW  - aerial imaging
KW  - real-time detection
DO  - 10.3390/rs13214196
ER  -
TY  - EJOU
AU  - Zhao, Wenchao
AU  - Han, Shuai
AU  - Chen, Yapeng
AU  - Gao, Yusheng
AU  - Liu, Manjie
TI  - Development of Quick Digital Field Recording and Mapping Method of Geological Objects for Hydraulic Engineering
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 21
SN  - 2076-3417

AB  - During the fieldwork of hydraulic engineering, practical engineers normally document geological information manually. Although there are some GIS-based digital tools for geology, they are not perfectly applicable to hydraulic engineering. As a result, the current work mode is ineffective, unmanageable, error-prone, and not conducive to subsequent analysis. To address this problem, we developed a digital tool which enables geological recording and quick modeling based on 3D real scenes in the field of hydropower projects. There are three modules in the surface tool: object recording, image interpretation, and field analysis. The object recording module is to mark geological points (e.g., drills and shafts), lines (e.g., faults, stratigraphic boundaries), and surfaces (e.g., slope and stocking yard) on a 3D scene and then store them in the database. The image interpretation is to interpret the 2D information in images to 3D models loaded in 3D software for further studies, such as GOCAD. The field analysis includes surface fitting, stability analysis of blocks, occurrences calculating, rock recognition, and 69/sketching. The tool is helpful for recording data, drawing geological boundaries, and building a preliminary model in the geological survey.
KW  - field geology
KW  - digital geological recording
KW  - 3D real scene of terrain
KW  - 3D geology model
KW  - hydraulic engineering
DO  - 10.3390/app11219840
ER  -
TY  - EJOU
AU  - Atli, İbrahim
AU  - Ozturk, Metin
AU  - Valastro, Gianluca C.
AU  - Asghar, Muhammad Z.
TI  - Multi-Objective UAV Positioning Mechanism for Sustainable Wireless Connectivity in Environments with Forbidden Flying Zones
T2  - Algorithms

PY  - 2021
VL  - 14
IS  - 11
SN  - 1999-4893

AB  - A communication system based on unmanned aerial vehicles (UAVs) is a viable alternative for meeting the coverage and capacity needs of future wireless networks. However, because of the limitations of UAV-enabled communications in terms of coverage, energy consumption, and flying laws, the number of studies focused on the sustainability element of UAV-assisted networking in the literature was limited thus far. We present a solution to this problem in this study; specifically, we design a Q-learning-based UAV placement strategy for long-term wireless connectivity while taking into account major constraints such as altitude regulations, nonflight zones, and transmit power. The goal is to determine the best location for the UAV base station (BS) while reducing energy consumption and increasing the number of users covered. Furthermore, a weighting method is devised, allowing energy usage and the number of users served to be prioritized based on network/battery circumstances. The suggested Q-learning-based solution is contrasted to the standard k-means clustering method, in which the UAV BS is positioned at the centroid location with the shortest cumulative distance between it and the users. The results demonstrate that the proposed solution outperforms the baseline k-means clustering-based method in terms of the number of users covered while achieving the desired minimization of the energy consumption.
KW  - sustainable wireless connectivity
KW  - energy saving
KW  - UAV
KW  - communication system
KW  - 5G
KW  - positioning
KW  - reinforcement learning
DO  - 10.3390/a14110302
ER  -
TY  - EJOU
AU  - Jia, Jianxin
AU  - Sun, Haibin
AU  - Jiang, Changhui
AU  - Karila, Kirsi
AU  - Karjalainen, Mika
AU  - Ahokas, Eero
AU  - Khoramshahi, Ehsan
AU  - Hu, Peilun
AU  - Chen, Chen
AU  - Xue, Tianru
AU  - Wang, Tinghuai
AU  - Chen, Yuwei
AU  - Hyyppä, Juha
TI  - Review on Active and Passive Remote Sensing Techniques for Road Extraction
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Digital maps of road networks are a vital part of digital cities and intelligent transportation. In this paper, we provide a comprehensive review on road extraction based on various remote sensing data sources, including high-resolution images, hyperspectral images, synthetic aperture radar images, and light detection and ranging. This review is divided into three parts. Part 1 provides an overview of the existing data acquisition techniques for road extraction, including data acquisition methods, typical sensors, application status, and prospects. Part 2 underlines the main road extraction methods based on four data sources. In this section, road extraction methods based on different data sources are described and analysed in detail. Part 3 presents the combined application of multisource data for road extraction. Evidently, different data acquisition techniques have unique advantages, and the combination of multiple sources can improve the accuracy of road extraction. The main aim of this review is to provide a comprehensive reference for research on existing road extraction technologies.
KW  - road extraction
KW  - high-resolution image
KW  - hyperspectral image
KW  - synthetic aperture radar (SAR)
KW  - light detection and ranging (LiDAR)
DO  - 10.3390/rs13214235
ER  -
TY  - EJOU
AU  - Zhang, Ying
AU  - Chi, Zhaohui
AU  - Hui, Fengming
AU  - Li, Teng
AU  - Liu, Xuying
AU  - Zhang, Baogang
AU  - Cheng, Xiao
AU  - Chen, Zhuoqi
TI  - Accuracy Evaluation on Geolocation of the Chinese First Polar Microsatellite (Ice Pathfinder) Imagery
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Ice Pathfinder (Code: BNU-1), launched on 12 September 2019, is the first Chinese polar observation microsatellite. Its main payload is a wide-view camera with a ground resolution of 74 m at the subsatellite point and a scanning width of 744 km. BNU-1 takes into account the balance between spatial resolution and revisit frequency, providing observations with finer spatial resolution than Terra/Aqua MODIS data and more frequent revisits than Landsat-8 OLI and Sentinel-2 MSI. It is a valuable supplement for polar observations. Geolocation is an essential step in satellite image processing. This study aims to geolocate BNU-1 images; this includes two steps. For the first step, a geometric calibration model is applied to transform the image coordinates to geographic coordinates. The images calibrated by the geometric model are the Level1A (L1A) product. Due to the inaccuracy of satellite attitude and orbit parameters, the geometric calibration model also exhibits errors, resulting in geolocation errors in the BNU-1 L1A product. Then, a geometric correction method is applied as the second step to find the control points (CPs) extracted from the BNU-1 L1A product and the corresponding MODIS images. These CPs are used to estimate and correct geolocation errors. The BNU-1 L1A product corrected by the geometric correction method is processed to the Level1B (L1B) product. Although the geometric correction method based on CPs has been widely used to correct the geolocation errors of visible remote sensing images, it is difficult to extract enough CPs from polar images due to the high reflectance of snow and ice. In this study, the geometric correction employs an image division and an image enhancement method to extract more CPs from the BNU-1 L1A products. The results indicate that the number of CPs extracted by the division and image enhancements increases by about 30% to 182%. Twenty-eight images of Antarctica and fifteen images of Arctic regions were evaluated to assess the performance of the geometric correction. The average geolocation error was reduced from 10 km to ~300 m. In general, this study presents the geolocation method, which could serve as a reference for the geolocation of other visible remote sensing images for polar observations.
KW  - geolocation
KW  - microsatellite
KW  - Ice Pathfinder
KW  - BNU-1
KW  - geometric correction
KW  - image division
KW  - image enhancement
DO  - 10.3390/rs13214278
ER  -
TY  - EJOU
AU  - Yu, Jin-Woo
AU  - Yoon, Young-Woong
AU  - Baek, Won-Kyung
AU  - Jung, Hyung-Sup
TI  - Forest Vertical Structure Mapping Using Two-Seasonal Optic Images and LiDAR DSM Acquired from UAV Platform through Random Forest, XGBoost, and Support Vector Machine Approaches
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Research on the forest structure classification is essential, as it plays an important role in assessing the vitality and diversity of vegetation. However, classifying forest structure involves in situ surveying, which requires considerable time and money, and cannot be conducted directly in some instances; also, the update cycle of the classification data is very late. To overcome these drawbacks, feasibility studies on mapping the forest vertical structure from aerial images using machine learning techniques were conducted. In this study, we investigated (1) the performance improvement of the forest structure classification, using a high-resolution LiDAR-derived digital surface model (DSM) acquired from an unmanned aerial vehicle (UAV) platform and (2) the performance comparison of results obtained from the single-seasonal and two-seasonal data, using random forest (RF), extreme gradient boosting (XGBoost), and support vector machine (SVM). For the performance comparison, the UAV optic and LiDAR data were divided into three cases: (1) only used autumn data, (2) only used winter data, and (3) used both autumn and winter data. From the results, the best model was XGBoost, and the F1 scores achieved using this method were approximately 0.92 in the autumn and winter cases. A remarkable improvement was achieved when both two-seasonal images were used. The F1 score improved by 35.3% from 0.68 to 0.92. This implies that (1) the seasonal variation in the forest vertical structure can be more important than the spatial resolution, and (2) the classification performance achieved from the two-seasonal UAV optic images and LiDAR-derived DSMs can reach 0.9 with the application of an optimal machine learning approach.
KW  - forest vertical structure
KW  - multiseason
KW  - machine learning
KW  - classification
DO  - 10.3390/rs13214282
ER  -
TY  - EJOU
AU  - Li, Xiaokun
AU  - Lu, Junwei
AU  - Stegen, Sascha
TI  - Magnetic Coupler Optimization for Inductive Power Transfer System of Unmanned Aerial Vehicles
T2  - Energies

PY  - 2021
VL  - 14
IS  - 21
SN  - 1996-1073

AB  - Unmanned aerial vehicles (UAVs) have been widely used in military and civilian applications. However, the insufficient cruising range restricts the development of UAVs due to the limitation of their battery. Inductive power transfer (IPT) is an effective way to charge the battery and solve this problem. Magnetic coupler is a key component of the IPT system, which greatly affects the power transfer and efficiency of the IPT. This paper proposes a new magnetic coupler with vertical spiral coils and ferrite PQI cores for the IPT system of UAVs, which can enhance the magnetic coupling and improve the performance of the IPT system. Finite element simulations are used to investigate the magnetic field distribution and coupling capability of the proposed magnetic coupler. In addition, an experimental platform is built to prove the validity of the IPT system using the proposed magnetic coupler. The results show that the coupling coefficient can reach 0.98, and the system transfer efficiency is 89.27% with an output power of 93 W. The IPT system also has a perfect misalignment tolerance and can achieve a stable output power.
KW  - coupling coefficient
KW  - inductive power transfer (IPT)
KW  - magnetic coupler
KW  - PQI cores
KW  - unmanned aerial vehicles (UAVs)
DO  - 10.3390/en14217024
ER  -
TY  - EJOU
AU  - Zhao, Genping
AU  - Zhang, Weiguang
AU  - Peng, Yeping
AU  - Wu, Heng
AU  - Wang, Zhuowei
AU  - Cheng, Lianglun
TI  - PEMCNet: An Efficient Multi-Scale Point Feature Fusion Network for 3D LiDAR Point Cloud Classification
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Point cloud classification plays a significant role in Light Detection and Ranging (LiDAR) applications. However, most available multi-scale feature learning networks for large-scale 3D LiDAR point cloud classification tasks are time-consuming. In this paper, an efficient deep neural architecture denoted as Point Expanded Multi-scale Convolutional Network (PEMCNet) is developed to accurately classify the 3D LiDAR point cloud. Different from traditional networks for point cloud processing, PEMCNet includes successive Point Expanded Grouping (PEG) units and Absolute and Relative Spatial Embedding (ARSE) units for representative point feature learning. The PEG unit enables us to progressively increase the receptive field for each observed point and aggregate the feature of a point cloud at different scales but without increasing computation. The ARSE unit following the PEG unit furthermore realizes representative encoding of points relationship, which effectively preserves the geometric details between points. We evaluate our method on both public datasets (the Urban Semantic 3D (US3D) dataset and Semantic3D benchmark dataset) and our new collected Unmanned Aerial Vehicle (UAV) based LiDAR point cloud data of the campus of Guangdong University of Technology. In comparison with four available state-of-the-art methods, our methods ranked first place regarding both efficiency and accuracy. It was observed on the public datasets that with a 2% increase in classification accuracy, over 26% improvement of efficiency was achieved at the same time compared to the second efficient method. Its potential value is also tested on the newly collected point cloud data with over 91% of classification accuracy and 154 ms of processing time.
KW  - LiDAR
KW  - point cloud
KW  - classification
KW  - deep learning
DO  - 10.3390/rs13214312
ER  -
TY  - EJOU
AU  - Hu, Kai
AU  - Chen, Xu
AU  - Xia, Qingfeng
AU  - Jin, Junlan
AU  - Weng, Liguo
TI  - A Control Algorithm for Sea&ndash;Air Cooperative Observation Tasks Based on a Data-Driven Algorithm
T2  - Journal of Marine Science and Engineering

PY  - 2021
VL  - 9
IS  - 11
SN  - 2077-1312

AB  - There is tremendous demand for marine environmental observation, which requires the development of a multi-agent cooperative observation algorithm to guide Unmanned Surface Vehicles (USVs) and Unmanned Aerial Vehicles (UAVs) to observe isotherm data of the mesoscale vortex. The task include two steps: firstly, USVs search out the isotherm, navigate independently along the isotherm, and collect marine data; secondly, a UAV takes off, and in its one round trip, the UAV and USVs jointly perform the task of the UAV reading the observation data from USVs. In this paper, aiming at the first problem of the USV following the isotherm in an unknown environment, a data-driven Deep Deterministic Policy Gradient (DDPG) control algorithm is designed that allows USVs to navigate independently along isotherms in unknown environments. In addition, a hybrid cooperative control algorithm based on a multi-agent DDPG is adopted to solve the second problem, which enables USVs and a UAV to complete data reading tasks with the shortest flight distance of the UAV. The experimental simulation results show that the trained system can complete this tas, with good stability and accuracy.
KW  - sea and air observation
KW  - multi-agent collaboration
KW  - data-driven
KW  - deep reinforcement learning
DO  - 10.3390/jmse9111189
ER  -
TY  - EJOU
AU  - Xiang, Xuanchen
AU  - Foo, Simon
AU  - Zang, Huanyu
TI  - Recent Advances in Deep Reinforcement Learning Applications for Solving Partially Observable Markov Decision Processes (POMDP) Problems Part 2—Applications in Transportation, Industries, Communications and Networking and More Topics
T2  - Machine Learning and Knowledge Extraction

PY  - 2021
VL  - 3
IS  - 4
SN  - 2504-4990

AB  - The two-part series of papers provides a survey on recent advances in Deep Reinforcement Learning (DRL) for solving partially observable Markov decision processes (POMDP) problems. Reinforcement Learning (RL) is an approach to simulate the human’s natural learning process, whose key is to let the agent learn by interacting with the stochastic environment. The fact that the agent has limited access to the information of the environment enables AI to be applied efficiently in most fields that require self-learning. It’s essential to have an organized investigation—we can make good comparisons and choose the best structures or algorithms when applying DRL in various applications. The first part of the overview introduces Markov Decision Processes (MDP) problems and Reinforcement Learning and applications of DRL for solving POMDP problems in games, robotics, and natural language processing. In part two, we continue to introduce applications in transportation, industries, communications and networking, etc. and discuss the limitations of DRL.
KW  - reinforcement learning
KW  - deep reinforcement learning
KW  - Markov decision process
KW  - partially observable markov decision process
DO  - 10.3390/make3040043
ER  -
TY  - EJOU
AU  - Rominger, Kody R.
AU  - Meyer, Susan E.
TI  - Drones, Deep Learning, and Endangered Plants: A Method for Population-Level Census Using Image Analysis
T2  - Drones

PY  - 2021
VL  - 5
IS  - 4
SN  - 2504-446X

AB  - A census of endangered plant populations is critical to determining their size, spatial distribution, and geographical extent. Traditional, on-the-ground methods for collecting census data are labor-intensive, time-consuming, and expensive. Use of drone imagery coupled with application of rapidly advancing deep learning technology could greatly reduce the effort and cost of collecting and analyzing population-level data across relatively large areas. We used a customization of the YOLOv5 object detection model to identify and count individual dwarf bear poppy (Arctomecon humilis) plants in drone imagery obtained at 40 m altitude. We compared human-based and model-based detection at 40 m on n = 11 test plots for two areas that differed in image quality. The model out-performed human visual poppy detection for precision and recall, and was 1100× faster at inference/evaluation on the test plots. Model inference precision was 0.83, and recall was 0.74, while human evaluation resulted in precision of 0.67, and recall of 0.71. Both model and human performance were better in the area with higher-quality imagery, suggesting that image quality is a primary factor limiting model performance. Evaluation of drone-based census imagery from the 255 ha Webb Hill population with our customized YOLOv5 model was completed in &lt;3 h and provided a reasonable estimate of population size (7414 poppies) with minimal investment of on-the-ground resources.
KW  - AI (artificial intelligence)
KW  - Arctomecon humilis
KW  - census
KW  - drone
KW  - dwarf bear poppy
KW  - endangered plant species
KW  - UAS (unmanned aerial system)
KW  - YOLOv5
DO  - 10.3390/drones5040126
ER  -
TY  - EJOU
AU  - Schulze-Brüninghoff, Damian
AU  - Wachendorf, Michael
AU  - Astor, Thomas
TI  - Potentials and Limitations of WorldView-3 Data for the Detection of Invasive Lupinus polyphyllus Lindl. in Semi-Natural Grasslands
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Semi-natural grasslands contribute highly to biodiversity and other ecosystem services, but they are at risk by the spread of invasive plant species, which alter their habitat structure. Large area grassland monitoring can be a powerful tool to manage invaded ecosystems. Therefore, WorldView-3 multispectral sensor data was utilized to train multiple machine learning algorithms in an automatic machine learning workflow called ‘H2O AutoML’ to detect L. polyphyllus in a nature protection grassland ecosystem. Different degree of L. polyphyllus cover was collected on 3 × 3 m2 reference plots, and multispectral bands, indices, and texture features were used in a feature selection process to identify the most promising classification model and machine learning algorithm based on mean per class error, log loss, and AUC metrics. The best performance was achieved with a binary classification of lupin-free vs. fully invaded 3 × 3 m2 plot classification with a set of 7 features out of 763. The findings reveal that L. polyphyllus detection from WorldView-3 sensor data is limited to large dominant spots and not recommendable for lower plant coverage, especially single plant detection. Further research is needed to clarify if different phenological stages of L. polyphyllus as well as time series increase classification performance.
KW  - invasive species
KW  - WorldView-3
KW  - grassland
KW  - machine learning
KW  - feature selection
DO  - 10.3390/rs13214333
ER  -
TY  - EJOU
AU  - Khan, Rabia M.
AU  - Salehi, Bahram
AU  - Mahdianpari, Masoud
AU  - Mohammadimanesh, Fariba
AU  - Mountrakis, Giorgos
AU  - Quackenbush, Lindi J.
TI  - A Meta-Analysis on Harmful Algal Bloom (HAB) Detection and Monitoring: A Remote Sensing Perspective
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Algae serves as a food source for a wide range of aquatic species; however, a high concentration of inorganic nutrients under favorable conditions can result in the development of harmful algal blooms (HABs). Many studies have addressed HAB detection and monitoring; however, no global scale meta-analysis has specifically explored remote sensing-based HAB monitoring. Therefore, this manuscript elucidates and visualizes spatiotemporal trends in HAB detection and monitoring using remote sensing methods and discusses future insights through a meta-analysis of 420 journal articles. The results indicate an increase in the quantity of published articles which have facilitated the analysis of sensors, software, and HAB proxy estimation methods. The comparison across multiple studies highlighted the need for a standardized reporting method for HAB proxy estimation. Research gaps include: (1) atmospheric correction methods, particularly for turbid waters, (2) the use of analytical-based models, (3) the application of machine learning algorithms, (4) the generation of harmonized virtual constellation and data fusion for increased spatial and temporal resolutions, and (5) the use of cloud-computing platforms for large scale HAB detection and monitoring. The planned hyperspectral satellites will aid in filling these gaps to some extent. Overall, this review provides a snapshot of spatiotemporal trends in HAB monitoring to assist in decision making for future studies.
KW  - harmful algal blooms (HABs)
KW  - meta-analysis
KW  - phytoplankton
KW  - remote sensing
KW  - water quality
DO  - 10.3390/rs13214347
ER  -
TY  - EJOU
AU  - Aguilar, Fernando J.
AU  - Nemmaoui, Abderrahim
AU  - Aguilar, Manuel A.
AU  - Peñalver, Alberto
TI  - Building Tree Allometry Relationships Based on TLS Point Clouds and Machine Learning Regression
T2  - Applied Sciences

PY  - 2021
VL  - 11
IS  - 21
SN  - 2076-3417

AB  - Most of the allometric models used to estimate tree aboveground biomass rely on tree diameter at breast height (DBH). However, it is difficult to measure DBH from airborne remote sensors, and is common to draw upon traditional least squares linear regression models to relate DBH with dendrometric variables measured from airborne sensors, such as tree height (H) and crown diameter (CD). This study explores the usefulness of ensemble-type supervised machine learning regression algorithms, such as random forest regression (RFR), categorical boosting (CatBoost), gradient boosting (GBoost), or AdaBoost regression (AdaBoost), as an alternative to linear regression (LR) for modelling the allometric relationships DBH = Φ(H) and DBH = Ψ(H, CD). The original dataset was made up of 2272 teak trees (Tectona grandis Linn. F.) belonging to three different plantations located in Ecuador. All teak trees were digitally reconstructed from terrestrial laser scanning point clouds. The results showed that allometric models involving both H and CD to estimate DBH performed better than those based solely on H. Furthermore, boosting machine learning regression algorithms (CatBoost and GBoost) outperformed RFR (bagging) and LR (traditional linear regression) models, both in terms of goodness-of-fit (R2) and stability (variations in training and testing samples).
KW  - terrestrial laser scanning
KW  - allometric models
KW  - machine learning regression
KW  - teak plantations
KW  - forest inventory
DO  - 10.3390/app112110139
ER  -
TY  - EJOU
AU  - Raza, Wamiq
AU  - Osman, Anas
AU  - Ferrini, Francesco
AU  - Natale, Francesco D.
TI  - Energy-Efficient Inference on the Edge Exploiting TinyML Capabilities for UAVs
T2  - Drones

PY  - 2021
VL  - 5
IS  - 4
SN  - 2504-446X

AB  - In recent years, the proliferation of unmanned aerial vehicles (UAVs) has increased dramatically. UAVs can accomplish complex or dangerous tasks in a reliable and cost-effective way but are still limited by power consumption problems, which pose serious constraints on the flight duration and completion of energy-demanding tasks. The possibility of providing UAVs with advanced decision-making capabilities in an energy-effective way would be extremely beneficial. In this paper, we propose a practical solution to this problem that exploits deep learning on the edge. The developed system integrates an OpenMV microcontroller into a DJI Tello Micro Aerial Vehicle (MAV). The microcontroller hosts a set of machine learning-enabled inference tools that cooperate to control the navigation of the drone and complete a given mission objective. The goal of this approach is to leverage the new opportunistic features of TinyML through OpenMV including offline inference, low latency, energy efficiency, and data security. The approach is successfully validated on a practical application consisting of the onboard detection of people wearing protection masks in a crowded environment.
KW  - UAVs
KW  - energy efficiency
KW  - TinyML
KW  - microcontrollers
KW  - machine learning
KW  - deep learning
KW  - edge computing
DO  - 10.3390/drones5040127
ER  -
TY  - EJOU
AU  - Gopi, Sudheesh P.
AU  - Magarini, Maurizio
AU  - Alsamhi, Saeed H.
AU  - Shvetsov, Alexey V.
TI  - Machine Learning-Assisted Adaptive Modulation for Optimized Drone-User Communication in B5G
T2  - Drones

PY  - 2021
VL  - 5
IS  - 4
SN  - 2504-446X

AB  - The fundamental issue for Beyond fifth Generation (B5G) is providing a pervasive connection to heterogeneous and various devices in smart environments. Therefore, Drones play a vital role in the B5G, allowing for wireless broadcast and high-speed communications. In addition, the drone offers several advantages compared to fixed terrestrial communications, including flexible deployment, robust Line of Sight (LoS) connections, and more design degrees of freedom due to controlled mobility. Drones can provide reliable and high data rate connectivity to users irrespective of their location. However, atmospheric disturbances impact the signal quality between drones and users and degrade the system performance. Considering practical implementation, the location of drones makes the drone–user communication susceptible to several environmental disturbances. In this paper, we evaluate the performance of drone-user connectivity during atmospheric disturbances. Further, a Machine Learning (ML)-assisted algorithm is proposed to adapt to a modulation technique that offers optimal performance during atmospheric disturbances. The results show that, with the algorithm, the system switches to a lower order modulation scheme during higher rain rate and provides reliable communication with optimized data rate and error performance.
KW  - drone
KW  - adaptive modulation
KW  - K-means clustering
KW  - B5G
KW  - machine learning
DO  - 10.3390/drones5040128
ER  -
TY  - EJOU
AU  - Csákvári, Edina
AU  - Halassy, Melinda
AU  - Enyedi, Attila
AU  - Gyulai, Ferenc
AU  - Berke, József
TI  - Is Einkorn Wheat (Triticum monococcum L.) a Better Choice than Winter Wheat (Triticum aestivum L.)? Wheat Quality Estimation for Sustainable Agriculture Using Vision-Based Digital Image Analysis
T2  - Sustainability

PY  - 2021
VL  - 13
IS  - 21
SN  - 2071-1050

AB  - Einkorn wheat (Triticum monococcum L. ssp. monococcum) plays an increasingly important role in agriculture, promoted by organic farming. Although the number of comparative studies about modern and ancient types of wheats is increasing, there are still some knowledge gaps about the nutritional and health benefit differences between ancient and modern bread wheats. The aim of the present study was to compare ancient, traditional and modern wheat cultivars—including a field study and a laboratory stress experiment using vision-based digital image analysis—and to assess the feasibility of imaging techniques. Our study shows that modern winter wheat had better yield and grain quality compared to einkorn wheats, but the latter were not far behind; thus the cultivation of various species could provide a diverse and sustainable agriculture which contributes to higher agrobiodiversity. The results also demonstrate that digital image analysis could be a viable alternate method for the real-time estimation of aboveground biomass and for predicting yield and grain quality parameters. Digital area outperformed other digital variables in biomass prediction in relation to drought stress, but height and Feret’s diameter better correlated with yield and grain quality parameters. Based on these results we suggest that the combination of various vision-based methods could improve the performance estimation of modern and ancient types of wheat in a non-destructive and real-time manner.
KW  - agrobiodiversity
KW  - ecological farming
KW  - einkorn
KW  - winter wheat
KW  - RGB image
KW  - digital image processing
KW  - aboveground biomass
DO  - 10.3390/su132112005
ER  -
TY  - EJOU
AU  - Lan, Yubin
AU  - Huang, Kanghua
AU  - Yang, Chang
AU  - Lei, Luocheng
AU  - Ye, Jiahang
AU  - Zhang, Jianling
AU  - Zeng, Wen
AU  - Zhang, Yali
AU  - Deng, Jizhong
TI  - Real-Time Identification of Rice Weeds by UAV Low-Altitude Remote Sensing Based on Improved Semantic Segmentation Model
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Real-time analysis of UAV low-altitude remote sensing images at airborne terminals facilitates the timely monitoring of weeds in the farmland. Aiming at the real-time identification of rice weeds by UAV low-altitude remote sensing, two improved identification models, MobileNetV2-UNet and FFB-BiSeNetV2, were proposed based on the semantic segmentation models U-Net and BiSeNetV2, respectively. The MobileNetV2-UNet model focuses on reducing the amount of calculation of the original model parameters, and the FFB-BiSeNetV2 model focuses on improving the segmentation accuracy of the original model. In this study, we first tested and compared the segmentation accuracy and operating efficiency of the models before and after the improvement on the computer platform, and then transplanted the improved models to the embedded hardware platform Jetson AGX Xavier, and used TensorRT to optimize the model structure to improve the inference speed. Finally, the real-time segmentation effect of the two improved models on rice weeds was further verified through the collected low-altitude remote sensing video data. The results show that on the computer platform, the MobileNetV2-UNet model reduced the amount of network parameters, model size, and floating point calculations by 89.12%, 86.16%, and 92.6%, and the inference speed also increased by 2.77 times, when compared with the U-Net model. The FFB-BiSeNetV2 model improved the segmentation accuracy compared with the BiSeNetV2 model and achieved the highest pixel accuracy and mean Intersection over Union ratio of 93.09% and 80.28%. On the embedded hardware platform, the optimized MobileNetV2-UNet model and FFB-BiSeNetV2 model inferred 45.05 FPS and 40.16 FPS for a single image under the weight accuracy of FP16, respectively, both meeting the performance requirements of real-time identification. The two methods proposed in this study realize the real-time identification of rice weeds under low-altitude remote sensing by UAV, which provide a reference for the subsequent integrated operation of plant protection drones in real-time rice weed identification and precision spraying.
KW  - low-altitude remote sensing
KW  - semantic segmentation model
KW  - real-time
KW  - rice weeds
KW  - target spraying
DO  - 10.3390/rs13214370
ER  -
TY  - EJOU
AU  - Sun, Long
AU  - Chen, Jie
AU  - Feng, Dazheng
AU  - Xing, Mengdao
TI  - Parallel Ensemble Deep Learning for Real-Time Remote Sensing Video Multi-Target Detection
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - Unmanned aerial vehicle (UAV) is one of the main means of information warfare, such as in battlefield cruises, reconnaissance, and military strikes. Rapid detection and accurate recognition of key targets in UAV images are the basis of subsequent military tasks. The UAV image has characteristics of high resolution and small target size, and in practical application, the detection speed is often required to be fast. Existing algorithms are not able to achieve an effective trade-off between detection accuracy and speed. Therefore, this paper proposes a parallel ensemble deep learning framework for unmanned aerial vehicle video multi-target detection, which is a global and local joint detection strategy. It combines a deep learning target detection algorithm with template matching to make full use of image information. It also integrates multi-process and multi-threading mechanisms to speed up processing. Experiments show that the system has high detection accuracy for targets with focal lengths varying from one to ten times. At the same time, the real-time and stable display of detection results is realized by aiming at the moving UAV video image.
KW  - drone video
KW  - multi-target detection
KW  - multiple focal lengths
KW  - deep learning
KW  - template matching
DO  - 10.3390/rs13214377
ER  -
TY  - EJOU
AU  - Liu, Jia
AU  - Xiang, Jianjian
AU  - Jin, Yongjun
AU  - Liu, Renhua
AU  - Yan, Jining
AU  - Wang, Lizhe
TI  - Boost Precision Agriculture with Unmanned Aerial Vehicle Remote Sensing and Edge Intelligence: A Survey
T2  - Remote Sensing

PY  - 2021
VL  - 13
IS  - 21
SN  - 2072-4292

AB  - In recent years unmanned aerial vehicles (UAVs) have emerged as a popular and cost-effective technology to capture high spatial and temporal resolution remote sensing (RS) images for a wide range of precision agriculture applications, which can help reduce costs and environmental impacts by providing detailed agricultural information to optimize field practices. Furthermore, deep learning (DL) has been successfully applied in agricultural applications such as weed detection, crop pest and disease detection, etc. as an intelligent tool. However, most DL-based methods place high computation, memory and network demands on resources. Cloud computing can increase processing efficiency with high scalability and low cost, but results in high latency and great pressure on the network bandwidth. The emerging of edge intelligence, although still in the early stages, provides a promising solution for artificial intelligence (AI) applications on intelligent edge devices at the edge of the network close to data sources. These devices are with built-in processors enabling onboard analytics or AI (e.g., UAVs and Internet of Things gateways). Therefore, in this paper, a comprehensive survey on the latest developments of precision agriculture with UAV RS and edge intelligence is conducted for the first time. The major insights observed are as follows: (a) in terms of UAV systems, small or light, fixed-wing or industrial rotor-wing UAVs are widely used in precision agriculture; (b) sensors on UAVs can provide multi-source datasets, and there are only a few public UAV dataset for intelligent precision agriculture, mainly from RGB sensors and a few from multispectral and hyperspectral sensors; (c) DL-based UAV RS methods can be categorized into classification, object detection and segmentation tasks, and convolutional neural network and recurrent neural network are the mostly common used network architectures; (d) cloud computing is a common solution to UAV RS data processing, while edge computing brings the computing close to data sources; (e) edge intelligence is the convergence of artificial intelligence and edge computing, in which model compression especially parameter pruning and quantization is the most important and widely used technique at present, and typical edge resources include central processing units, graphics processing units and field programmable gate arrays.
KW  - precision agriculture
KW  - remote sensing
KW  - unmanned aerial vehicles
KW  - deep learning
KW  - high performance
KW  - mobile devices
KW  - edge intelligence
KW  - model compression
DO  - 10.3390/rs13214387
ER  -
TY  - EJOU
AU  - Stolle, Lorena
AU  - Corte, Ana P.
AU  - Sanquetta, Carlos R.
AU  - Behling, Alexandre
AU  - Hentz, Ângela M.
AU  - Eisfeld, Rozane D.
TI  - Predicting Stand Volume by Number of Trees Automatically Detected in UAV Images: An Alternative Method for Forest Inventory
T2  - Forests

PY  - 2021
VL  - 12
IS  - 11
SN  - 1999-4907

AB  - In this study, we estimate the forest stock volume by multiplying the number of trees detected remotely by the estimated mean individual volume of the population (individual approach). A comparison was made with the conventional inventory method (area approach), which included 100 simulations of a simple random sampling process and a Bootstrap resampling. The study area included three stands: stand 1, 16-year-old pine; stand 2, 7-year-old pine; and stand 3, 5-year-old eucalyptus. A census was carried out in each stand for the variables diameter and total height. Individual volume was estimated by a ratio estimator, and the sum of all volumes was considered as the total parametric volume. The area approach presented parametric values within the confidence interval for 91%, 94%, and 98% of the simulations for the three stands, respectively. The mean relative errors for the area approach were −3.5% for stand 1, 0.3% for stand 2, and −0.9% for stand 3. The errors in stands 1 and 3 were associated with the spatial distribution of the volume. The individual approach proved to be efficient for all stands, and their respective parametric values were within the confidence interval. The relative errors were 1% for stand 1, −0.7% for stand 2, and 1.8% for stand 3. For stand 1 and 3, this approach yielded better results than the mean values obtained by the area approach simulations (Bootstrap resampling). Future research should evaluate other remote sources of data and other forest conditions.
KW  - RPA (remotely piloted aircraft)
KW  - CHM (canopy height model)
KW  - tree detection
DO  - 10.3390/f12111508
ER  -

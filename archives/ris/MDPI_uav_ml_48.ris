TY  - EJOU
AU  - Shihavuddin, ASM
AU  - Chen, Xiao
AU  - Fedorov, Vladimir
AU  - Nymark Christensen, Anders
AU  - Andre Brogaard Riis, Nicolai
AU  - Branner, Kim
AU  - Bjorholm Dahl, Anders
AU  - Reinhold Paulsen, Rasmus
TI  - Wind Turbine Surface Damage Detection by Deep Learning Aided Drone Inspection Analysis
T2  - Energies

PY  - 2019
VL  - 12
IS  - 4
SN  - 1996-1073

AB  - Timely detection of surface damages on wind turbine blades is imperative for minimizing downtime and avoiding possible catastrophic structural failures. With recent advances in drone technology, a large number of high-resolution images of wind turbines are routinely acquired and subsequently analyzed by experts to identify imminent damages. Automated analysis of these inspection images with the help of machine learning algorithms can reduce the inspection cost. In this work, we develop a deep learning-based automated damage suggestion system for subsequent analysis of drone inspection images. Experimental results demonstrate that the proposed approach can achieve almost human-level precision in terms of suggested damage location and types on wind turbine blades. We further demonstrate that for relatively small training sets, advanced data augmentation during deep learning training can better generalize the trained model, providing a significant gain in precision.
KW  - wind energy
KW  - rotor blade
KW  - wind turbine
KW  - drone inspection
KW  - damage detection
KW  - deep learning
KW  - Convolutional Neural Network (CNN)
DO  - 10.3390/en12040676
ER  -
TY  - EJOU
AU  - Khaliq, Aleem
AU  - Comba, Lorenzo
AU  - Biglia, Alessandro
AU  - Ricauda Aimonino, Davide
AU  - Chiaberge, Marcello
AU  - Gay, Paolo
TI  - Comparison of Satellite and UAV-Based Multispectral Imagery for Vineyard Variability Assessment
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 4
SN  - 2072-4292

AB  - In agriculture, remotely sensed data play a crucial role in providing valuable information on crop and soil status to perform effective management. Several spectral indices have proven to be valuable tools in describing crop spatial and temporal variability. In this paper, a detailed analysis and comparison of vineyard multispectral imagery, provided by decametric resolution satellite and low altitude Unmanned Aerial Vehicle (UAV) platforms, is presented. The effectiveness of Sentinel-2 imagery and of high-resolution UAV aerial images was evaluated by considering the well-known relation between the Normalised Difference Vegetation Index (NDVI) and crop vigour. After being pre-processed, the data from UAV was compared with the satellite imagery by computing three different NDVI indices to properly analyse the unbundled spectral contribution of the different elements in the vineyard environment considering: (i) the whole cropland surface; (ii) only the vine canopies; and (iii) only the inter-row terrain. The results show that the raw s resolution satellite imagery could not be directly used to reliably describe vineyard variability. Indeed, the contribution of inter-row surfaces to the remotely sensed dataset may affect the NDVI computation, leading to biased crop descriptors. On the contrary, vigour maps computed from the UAV imagery, considering only the pixels representing crop canopies, resulted to be more related to the in-field assessment compared to the satellite imagery. The proposed method may be extended to other crop typologies grown in rows or without intensive layout, where crop canopies do not extend to the whole surface or where the presence of weeds is significant.
KW  - precision agriculture
KW  - remote sensing
KW  - satellite imagery
KW  - UAV
KW  - decision viticulture
DO  - 10.3390/rs11040436
ER  -
TY  - EJOU
AU  - Pasqualotto, Nieves
AU  - Delegido, Jesús
AU  - Van Wittenberghe, Shari
AU  - Rinaldi, Michele
AU  - Moreno, José
TI  - Multi-Crop Green LAI Estimation with a New Simple Sentinel-2 LAI Index (SeLI)
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 4
SN  - 1424-8220

AB  - The spatial quantification of green leaf area index (LAIgreen), the total green photosynthetically active leaf area per ground area, is a crucial biophysical variable for agroecosystem monitoring. The Sentinel-2 mission is with (1) a temporal resolution lower than a week, (2) a spatial resolution of up to 10 m, and (3) narrow bands in the red and red-edge region, a highly promising mission for agricultural monitoring. The aim of this work is to define an easy implementable LAIgreen index for the Sentinel-2 mission. Two large and independent multi-crop datasets of in situ collected LAIgreen measurements were used. Commonly used LAIgreen indices applied on the Sentinel-2 10 m &times; 10 m pixel resulted in a validation R2 lower than 0.6. By calculating all Sentinel-2 band combinations to identify high correlation and physical basis with LAIgreen, the new Sentinel-2 LAIgreen Index (SeLI) was defined. SeLI is a normalized index that uses the 705 nm and 865 nm centered bands, exploiting the red-edge region for low-saturating absorption sensitivity to photosynthetic vegetation. A R2 of 0.708 (root mean squared error (RMSE) = 0.67) and a R2 of 0.732 (RMSE = 0.69) were obtained with a linear fitting for the calibration and validation datasets, respectively, outperforming established indices. Sentinel-2 LAIgreen maps are presented.
KW  - crops
KW  - leaf area index
KW  - vegetation indices
KW  - remote sensing
KW  - Sentinel-2
KW  - red-edge
DO  - 10.3390/s19040904
ER  -
TY  - EJOU
AU  - Sanchez-Gonzalez, Pedro-Luis
AU  - Díaz-Gutiérrez, David
AU  - Leo, Teresa J.
AU  - Núñez-Rivas, Luis R.
TI  - Toward Digitalization of Maritime Transport?
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 4
SN  - 1424-8220

AB  - Although maritime transport is the backbone of world commerce, its digitalization lags significantly behind when we consider some basic facts. This work verifies the state-of-the-art as it currently applies to eight digital domains: Autonomous vehicles and robotics; artificial intelligence; big data; virtual reality, augmented and mixed reality; internet of things; the cloud and edge computing; digital security; and 3D printing and additive engineering. It also provides insight into each of the three sectors into which this industry has been divided: Ship design and shipbuilding; shipping; and ports. The work, based on a systematic literature review, demonstrates that there are domains on which almost no formal study has been done thus far and concludes that there are major areas that require attention in terms of research. It also illustrates the increasing interest on the subject, arising from the necessity of raising the maritime transport industry to the same level of digitalization as other industries.
KW  - additive engineering
KW  - artificial intelligence
KW  - big data
KW  - cloud computing
KW  - digitalization
KW  - internet of things
KW  - maritime transport
KW  - robotics
KW  - virtual reality
DO  - 10.3390/s19040926
ER  -
TY  - EJOU
AU  - Wang, Linhui
AU  - Yue, Xuejun
AU  - Liu, Yongxin
AU  - Wang, Jian
AU  - Wang, Huihui
TI  - An Intelligent Vision Based Sensing Approach for Spraying Droplets Deposition Detection
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 4
SN  - 1424-8220

AB  - The rapid development of vision sensor based on artificial intelligence (AI) is reforming industries and making our world smarter. Among these trends, it is of great significance to adapt AI technologies into the intelligent agricultural management. In smart agricultural aviation spraying, the droplets&rsquo; distribution and deposition are important indexes for estimating effectiveness in plant protection process. However, conventional approaches are problematic, they lack adaptivity to environmental changes, and consumes non-reusable test materials. One example is that the machine vision algorithms they employ can&rsquo;t guarantee that the division of adhesive droplets thereby disabling the accurate measurement of critical parameters. To alleviate these problems, we put forward an intelligent visual droplet detection node which can adapt to the environment illumination change. Then, we propose a modified marker controllable watershed segmentation algorithm to segment those adhesive droplets, and calculate their characteristic parameters on the basis of the segmentation results, including number, coverage, coverage density, etc. Finally, we use the intelligent node to detect droplets, and then expound the situation that the droplet region is effectively segmented and marked. The intelligent node has better adaptability and robustness even under the condition of illumination changing. The large-scale distributed detection result indicates that our approach has good consistency with the non-recyclable water-sensitive paper approach. Our approach provides an intelligent and environmental friendly way of tests for spraying techniques, especially for plant protection with Unmanned Aerial Vehicles.
KW  - droplets
KW  - intelligent node
KW  - vision sensor
KW  - adaptability
KW  - Unmanned Aerial Vehicles
DO  - 10.3390/s19040933
ER  -
TY  - EJOU
AU  - Liu, Zheng
AU  - Abbaszadeh, Shiva
TI  - Double Q-Learning for Radiation Source Detection
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 4
SN  - 1424-8220

AB  - Anomalous radiation source detection in urban environments is challenging due to the complex nature of background radiation. When a suspicious area is determined, a radiation survey is usually carried out to search for anomalous radiation sources. To locate the source with high accuracy and in a short time, different survey approaches have been studied such as scanning the area with fixed survey paths and data-driven approaches that update the survey path on the fly with newly acquired measurements. In this work, we propose reinforcement learning as a data-driven approach to conduct radiation detection tasks with no human intervention. A simulated radiation environment is constructed, and a convolutional neural network-based double Q-learning algorithm is built and tested for radiation source detection tasks. Simulation results show that the double Q-learning algorithm can reliably navigate the detector and reduce the searching time by at least 44% compared with traditional uniform search methods and gradient search methods.
KW  - reinforcement learning
KW  - radiation detection
KW  - source searching
DO  - 10.3390/s19040960
ER  -
TY  - EJOU
AU  - Madokoro, Hirokazu
AU  - Sato, Kazuhito
AU  - Shimoi, Nobuhiro
TI  - Vision-Based Indoor Scene Recognition from Time-Series Aerial Images Obtained Using a MAV Mounted Monocular Camera
T2  - Drones

PY  - 2019
VL  - 3
IS  - 1
SN  - 2504-446X

AB  - This paper presents a vision-based indoor scene recognition method from aerial time-series images obtained using a micro air vehicle (MAV). The proposed method comprises two procedures: a codebook feature description procedure, and a recognition procedure using category maps. For the former procedure, codebooks are created automatically as visual words using self-organizing maps (SOMs) after extracting part-based local features using a part-based descriptor from time-series scene images. For the latter procedure, category maps are created using counter propagation networks (CPNs) with the extraction of category boundaries using a unified distance matrix (U-Matrix). Using category maps, topologies of image features are mapped into a low-dimensional space based on competitive and neighborhood learning. We obtained aerial time-series image datasets of five sets for two flight routes: a round flight route and a zigzag flight route. The experimentally obtained results with leave-one-out cross-validation (LOOCV) revealed respective mean recognition accuracies for the round flight datasets (RFDs) and zigzag flight datasets (ZFDs) of 71.7% and 65.5% for 10 zones. The category maps addressed the complexity of scenes because of segmented categories. Although extraction results of category boundaries using U-Matrix were partially discontinuous, we obtained comprehensive category boundaries that segment scenes into several categories.
KW  - category maps
KW  - counter propagation networks
KW  - leave-one-out cross-validation
KW  - micro air vehicles
KW  - self-organizing maps
KW  - unified distance matrix
DO  - 10.3390/drones3010022
ER  -
TY  - EJOU
AU  - Michez, Adrien
AU  - Lejeune, Philippe
AU  - Bauwens, Sébastien
AU  - Herinaina, Andriamandroso A.
AU  - Blaise, Yannick
AU  - Castro Muñoz, Eloy
AU  - Lebeau, Frédéric
AU  - Bindelle, Jérôme
TI  - Mapping and Monitoring of Biomass and Grazing in Pasture with an Unmanned Aerial System
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 5
SN  - 2072-4292

AB  - The tools available to farmers to manage grazed pastures and adjust forage demand to grass growth are generally rather static. Unmanned aerial systems (UASs) are interesting versatile tools that can provide relevant 3D information, such as sward height (3D structure), or even describe the physical condition of pastures through the use of spectral information. This study aimed to evaluate the potential of UAS to characterize a pasture’s sward height and above-ground biomass at a very fine spatial scale. The pasture height provided by UAS products showed good agreement (R2 = 0.62) with a reference terrestrial light detection and ranging (LiDAR) dataset. We tested the ability of UAS imagery to model pasture biomass based on three different combinations: UAS sward height, UAS sward multispectral reflectance/vegetation indices, and a combination of both UAS data types. The mixed approach combining the UAS sward height and spectral data performed the best (adj. R2 = 0.49). This approach reached a quality comparable to that of more conventional non-destructive on-field pasture biomass monitoring tools. As all of the UAS variables used in the model fitting process were extracted from spatial information (raster data), a high spatial resolution map of pasture biomass was derived based on the best fitted model. A sward height differences map was also derived from UAS-based sward height maps before and after grazing. Our results demonstrate the potential of UAS imagery as a tool for precision grazing study applications. The UAS approach to height and biomass monitoring was revealed to be a potential alternative to the widely used but time-consuming field approaches. While reaching a similar level of accuracy to the conventional field sampling approach, the UAS approach provides wall-to-wall pasture characterization through very high spatial resolution maps, opening up a new area of research for precision grazing.
KW  - unmanned aerial vehicles
KW  - unmanned aerial systems
KW  - drone
KW  - precision grazing
KW  - pasture biomass modeling
KW  - sward height
KW  - pasture height
DO  - 10.3390/rs11050473
ER  -
TY  - EJOU
AU  - Shen, Wenjuan
AU  - Li, Mingshi
AU  - Huang, Chengquan
AU  - Tao, Xin
AU  - Li, Shu
AU  - Wei, Anshi
TI  - Mapping Annual Forest Change Due to Afforestation in Guangdong Province of China Using Active and Passive Remote Sensing Data
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 5
SN  - 2072-4292

AB  - Accurate acquisition of spatial distribution of afforestation in a large area is of great significance to contributing to the sustainable utilization of forest resources and the evaluation of the carbon accounting. Annual forest maps (1986&ndash;2016) of Guangdong, China were generated using time series Landsat images and PALSAR data. Initially, four PALSAR-based classifiers were used to classify land cover types. Then, the optimal mapping algorithm was determined. Next, an accurate identification of forest and non-forest was carried out by combining Landsat-based phenological variables and PALSAR-based land cover classifications. Finally, the spatio-temporal distribution of forest cover change due to afforestation was created and its forest biomass dynamics changes were detected. The results indicated that the overall accuracy of forest classification of the improved model based on the PALSAR-based stochastic gradient boosting (SGB) classification and the maximum value of normalized difference vegetation index (NDVI; SGB-NDVI) were approximately 75&ndash;85% in 2005, 2010, and 2016. Compared with the Japan Aerospace Exploration Agency (JAXA) PALSAR-forest/non-forest, the SGB-NDVI-based forest product showed great improvement, while the SGB-NDVI product was the same or slightly inferior to the Global Land Cover (GLC) and vegetation tracker change (VCT)-based land cover types, respectively. Although this combination of multiple sources contained some errors, the SGB-NDVI model effectively identified the distribution of forest cover changes by afforestation events. By integrating aboveground biomass dynamics (AGB) change with forest cover, the trend in afforestation area closely corresponded with the trend in forest AGB. This technique can provide an essential data baseline for carbon assessment in the planted forests of southern China.
KW  - PALSAR
KW  - Landsat
KW  - forest change (afforestation)
KW  - data integration
KW  - time series
KW  - biomass
DO  - 10.3390/rs11050490
ER  -
TY  - EJOU
AU  - Xu, Hanqiu
AU  - Hu, Xiujuan
AU  - Guan, Huade
AU  - Zhang, Bobo
AU  - Wang, Meiya
AU  - Chen, Shanmu
AU  - Chen, Minghua
TI  - A Remote Sensing Based Method to Detect Soil Erosion in Forests
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 5
SN  - 2072-4292

AB  - Rainwater-induced soil erosion occurring in the forest is a special phenomenon of soil erosion in many red soil areas. Detection of such soil erosion is essential for developing land management to reduce soil loss in areas including southern China and other red soil regions of the world. Remotely sensed canopy cover is often used to determine the potential of soil erosion over a large spatial scale, which, however, becomes less useful in forest areas. This study proposes a new remote sensing method to detect soil erosion under forest canopy and presents a case study in a forest area in southern China. Five factors that are closely related to soil erosion in forest were used as discriminators to develop the model. These factors include fractional vegetation coverage, nitrogen reflectance index, yellow leaf index, bare soil index and slope. They quantitatively represent vegetation density, vegetation health status, soil exposure intensity and terrain steepness that are considered relevant to forest soil erosion. These five factors can all be derived from remote sensing imagery based on related thematic indices or algorithms. The five factors were integrated to create the soil erosion under forest model (SEUFM) through Principal Components Analysis (PCA) or a multiplication method. The case study in the forest area in Changting County of southern China with a Landsat 8 image shows that the first principal component-based SEUFM achieves an overall accuracy close to 90%, while the multiplication-based model reaches 81%. The detected locations of soil erosion in forest provide the target areas to be managed from further soil loss. The proposed method provides a tool to understand more about soil erosion in forested areas where soil erosion is usually not considered an issue. Therefore, the method is useful for soil conservation in forest.
KW  - red-soil erosion
KW  - SEUFM
KW  - detection model
KW  - yellow leaf index
KW  - fractional vegetation coverage
KW  - vegetation health
KW  - principal components analysis
DO  - 10.3390/rs11050513
ER  -
TY  - EJOU
AU  - Yang, Lingbo
AU  - Mansaray, Lamin R.
AU  - Huang, Jingfeng
AU  - Wang, Limin
TI  - Optimal Segmentation Scale Parameter, Feature Subset and Classification Algorithm for Geographic Object-Based Crop Recognition Using Multisource Satellite Imagery
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 5
SN  - 2072-4292

AB  - Geographic object-based image analysis (GEOBIA) has been widely used in the remote sensing of agricultural crops. However, issues related to image segmentation, data redundancy and performance of different classification algorithms with GEOBIA have not been properly addressed in previous studies, thereby compromising the accuracy of subsequent thematic products. It is in this regard that the current study investigates the optimal scale parameter (SP) in multi-resolution segmentation, feature subset, and classification algorithm for use in GEOBIA based on multisource satellite imagery. For this purpose, a novel supervised optimal SP selection method was proposed based on information gain ratio, and was then compared with a preexisting unsupervised optimal SP selection method. Additionally, the recursive feature elimination (RFE) and enhanced RFE (EnRFE) algorithms were modified to generate an improved EnRFE (iEnRFE) algorithm, which was then compared with its precursors in the selection of optimal classification features. Based on the above, random forest (RF), gradient boosting decision tree (GBDT) and support vector machine (SVM) were applied to segmented objects for crop classification. The results indicated that the supervised optimal SP selection method is more suitable for application in heterogeneous land cover, whereas the unsupervised method proved more efficient as it does not require reference segmentation objects. The proposed iEnRFE method outperformed the preexisting EnRFE and RFE methods in optimal feature subset selection as it recorded the highest accuracy and less processing time. The RF, GBDT, and SVM algorithms achieved overall classification accuracies of 91.8%, 92.4%, and 90.5%, respectively. GBDT and RF recorded higher classification accuracies and utilized much less computational time than SVM and are, therefore, considered more suitable for crop classification requiring large numbers of image features. These results have shown that the proposed object-based crop classification scheme could provide a valuable reference for relevant applications of GEOBIA in crop recognition using multisource satellite imagery.
KW  - GEOBIA
KW  - optimal segmentation scale parameter
KW  - iEnRFE
KW  - feature selection
KW  - multisource satellite data
KW  - crop recognition
DO  - 10.3390/rs11050514
ER  -
TY  - EJOU
AU  - Peng, Shubiao
AU  - Ma, Hongchao
AU  - Zhang, Liang
TI  - Automatic Registration of Optical Images with Airborne LiDAR Point Cloud in Urban Scenes Based on Line-Point Similarity Invariant and Extended Collinearity Equations
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 5
SN  - 1424-8220

AB  - This paper proposes a novel method to achieve the automatic registration of optical images and Light Detection and Ranging (LiDAR) points in urban areas. The whole procedure, which adopts a coarse-to-precise registration strategy, can be summarized as follows: Coarse registration is performed through a conventional point-feature-based method. The points needed can be extracted from both datasets through a matured point extractor, such as the Forster operator, followed by the extraction of straight lines. Considering that lines are mainly from building roof edges in urban scenes, and being aware of their inaccuracy when extracted from an irregularly spaced point cloud, an &ldquo;infinitesimal feature analysis method&rdquo; fully utilizing LiDAR scanning characteristics is proposed to refine edge lines. Points which are matched between the image and LiDAR data are then applied as guidance to search for matched lines via the line-point similarity invariant. Finally, a transformation function based on extended collinearity equations is applied to achieve precise registration. The experimental results show that the proposed method outperforms the conventional ones in terms of the registration accuracy and automation level.
KW  - registration
KW  - LiDAR point cloud
KW  - point-line similarity invariant
KW  - line matching
KW  - extended collinearity equations (ECE)
DO  - 10.3390/s19051086
ER  -
TY  - EJOU
AU  - Wen, Sheng
AU  - Zhang, Quanyong
AU  - Yin, Xuanchun
AU  - Lan, Yubin
AU  - Zhang, Jiantao
AU  - Ge, Yufeng
TI  - Design of Plant Protection UAV Variable Spray System Based on Neural Networks
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 5
SN  - 1424-8220

AB  - Recently, unmanned aerial vehicles (UAVs) have rapidly emerged as a new technology in the fields of plant protection and pest control in China. Based on existing variable spray research, a plant protection UAV variable spray system integrating neural network based decision making is designed. Using the existing data on plant protection UAV operations, combined with artificial neural network (ANN) technology, an error back propagation (BP) neural network model between the factors affecting droplet deposition is trained. The factors affecting droplet deposition include ambient temperature, ambient humidity, wind speed, flight speed, flight altitude, propeller pitch, nozzles pitch and prescription value. Subsequently, the BP neural network model is combined with variable rate spray control for plant protection UAVs, and real-time information is collected by multi-sensor. The deposition rate is determined by the neural network model, and the flow rate of the spray system is regulated according to the predicted deposition amount. The amount of droplet deposition can meet the prescription requirement. The results show that the training variance of the ANN is 0.003, and thus, the model is stable and reliable. The outdoor tests show that the error between the predicted droplet deposition and actual droplet deposition is less than 20%. The ratio of droplet deposition to prescription value in each unit is approximately equal, and a variable spray operation under different conditions is realized.
KW  - UAV
KW  - BP neural network
KW  - droplet deposition
KW  - variable spray
DO  - 10.3390/s19051112
ER  -
TY  - EJOU
AU  - Hernandez Bennetts, Victor
AU  - Kamarudin, Kamarulzaman
AU  - Wiedemann, Thomas
AU  - Kucner, Tomasz P.
AU  - Somisetty, Sai L.
AU  - Lilienthal, Achim J.
TI  - Multi-Domain Airflow Modeling and Ventilation Characterization Using Mobile Robots, Stationary Sensors and Machine Learning
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 5
SN  - 1424-8220

AB  - Ventilation systems are critically important components of many public buildings and workspaces. Proper ventilation is often crucial for preventing accidents, such as explosions in mines and avoiding health issues, for example, through long-term exposure to harmful respirable matter. Validation and maintenance of ventilation systems is thus of key interest for plant operators and authorities. However, methods for ventilation characterization, which allow us to monitor whether the ventilation system in place works as desired, hardly exist. This article addresses the critical challenge of ventilation characterization&mdash;measuring and modelling air flow at micro-scales&mdash;that is, creating a high-resolution model of wind speed and direction from airflow measurements. Models of the near-surface micro-scale flow fields are not only useful for ventilation characterization, but they also provide critical information for planning energy-efficient paths for aerial robots and many applications in mobile robot olfaction. In this article we propose a heterogeneous measurement system composed of static, continuously sampling sensing nodes, complemented by localized measurements, collected during occasional sensing missions with a mobile robot. We introduce a novel, data-driven, multi-domain airflow modelling algorithm that estimates (1) fields of posterior distributions over wind direction and speed (&ldquo;ventilation maps&rdquo;, spatial domain); (2) sets of ventilation calendars that capture the evolution of important airflow characteristics at measurement positions (temporal domain); and (3) a frequency domain analysis that can reveal periodic changes of airflow in the environment. The ventilation map and the ventilation calendars make use of an improved estimation pipeline that incorporates a wind sensor model and a transition model to better filter out sporadic, noisy airflow changes. These sudden changes may originate from turbulence or irregular activity in the surveyed environment and can, therefore, disturb modelling of the relevant airflow patterns. We tested the proposed multi-domain airflow modelling approach with simulated data and with experiments in a semi-controlled environment and present results that verify the accuracy of our approach and its sensitivity to different turbulence levels and other disturbances. Finally, we deployed the proposed system in two different real-world industrial environments (foundry halls) with different ventilation regimes for three weeks during full operation. Since airflow ground truth cannot be obtained, we present a qualitative discussion of the generated airflow models with plant operators, who concluded that the computed models accurately depicted the expected airflow patterns and are useful to understand how pollutants spread in the work environment. This analysis may then provide the basis for decisions about corrective actions to avoid long-term exposure of workers to harmful respirable matter.
KW  - airflow modeling
KW  - ventilation
KW  - mobile robotics
KW  - static sensor networks
KW  - environmental monitoring
KW  - machine learning
DO  - 10.3390/s19051119
ER  -
TY  - EJOU
AU  - Li, Yang
AU  - Shi, Leyi
AU  - Feng, Haijie
TI  - A Game-Theoretic Analysis for Distributed Honeypots
T2  - Future Internet

PY  - 2019
VL  - 11
IS  - 3
SN  - 1999-5903

AB  - A honeypot is a decoy tool for luring an attacker and interacting with it, further consuming its resources. Due to its fake property, a honeypot can be recognized by the adversary and loses its value. Honeypots equipped with dynamic characteristics are capable of deceiving intruders. However, most of their dynamic properties are reflected in the system configuration, rather than the location. Dynamic honeypots are faced with the risk of being identified and avoided. In this paper, we focus on the dynamic locations of honeypots and propose a distributed honeypot scheme. By periodically changing the services, the attacker cannot distinguish the real services from honeypots, and the illegal attack flow can be recognized. We adopt game theory to illustrate the effectiveness of our system. Gambit simulations are conducted to validate our proposed scheme. The game-theoretic reasoning shows that our system comprises an innovative system defense. Further simulation results prove that the proposed scheme improves the server’s payoff and that the attacker tends to abandon launching attacks. Therefore, the proposed distributed honeypot scheme is effective for network security.
KW  - game theory
KW  - honeypot
KW  - network security
KW  - proactive defense
DO  - 10.3390/fi11030065
ER  -
TY  - EJOU
AU  - Stavrakoudis, Dimitris
AU  - Katsantonis, Dimitrios
AU  - Kadoglidou, Kalliopi
AU  - Kalaitzidis, Argyris
AU  - Gitas, Ioannis Z.
TI  - Estimating Rice Agronomic Traits Using Drone-Collected Multispectral Imagery
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 5
SN  - 2072-4292

AB  - The knowledge of rice nitrogen (N) requirements and uptake capacity are fundamental for the development of improved N management. This paper presents empirical models for predicting agronomic traits that are relevant to yield and N requirements of rice (Oryza sativa L.) through remotely sensed data. Multiple linear regression models were constructed at key growth stages (at tillering and at booting), using as input reflectance values and vegetation indices obtained from a compact multispectral sensor (green, red, red-edge, and near-infrared channels) onboard an unmanned aerial vehicle (UAV). The models were constructed using field data and images from two consecutive years in a number of experimental rice plots in Greece (Thessaloniki Regional Unit), by applying four different N treatments (C0: 0 N kg∙ha&minus;1, C1: 80 N kg∙ha&minus;1, C2: 160 N kg∙ha&minus;1, and C4: 320 N kg∙ha&minus;1). Models for estimating the current crop status (e.g., N uptake at the time of image acquisition) and predicting the future one (e.g., N uptake of grains at maturity) were developed and evaluated. At the tillering stage, high accuracies (R2 &ge; 0.8) were achieved for N uptake and biomass. At the booting stage, similarly high accuracies were achieved for yield, N concentration, N uptake, biomass, and plant height, using inputs from either two or three images. The results of the present study can be useful for providing N recommendations for the two top-dressing fertilizations in rice cultivation, through a cost-efficient workflow.
KW  - rice agronomic traits
KW  - multispectral UAV imagery
KW  - nitrogen uptake
KW  - nitrogen concentration
KW  - yield
KW  - aboveground biomass
KW  - multiple linear regression modeling
KW  - lasso input selection
DO  - 10.3390/rs11050545
ER  -
TY  - EJOU
AU  - Carl, Christin
AU  - Lehmann, Jan R. K.
AU  - Landgraf, Dirk
AU  - Pretzsch, Hans
TI  - Robinia pseudoacacia L. in Short Rotation Coppice: Seed and Stump Shoot Reproduction as well as UAS-based Spreading Analysis
T2  - Forests

PY  - 2019
VL  - 10
IS  - 3
SN  - 1999-4907

AB  - Varying reproduction strategies are an important trait that tree species need in order both to survive and to spread. Black locust is able to reproduce via seeds, stump shoots, and root suckers. However, little research has been conducted on the reproduction and spreading of black locust in short rotation coppices. This research study focused on seed germination, stump shoot resprout, and spreading by root suckering of black locust in ten short rotation coppices in Germany. Seed experiments and sample plots were analyzed for the study. Spreading was detected and measured with unmanned aerial system (UAS)-based images and classification technology&mdash;object-based image analysis (OBIA). Additionally, the classification of single UAS images was tested by applying a convolutional neural network (CNN), a deep learning model. The analyses showed that seed germination increases with increasing warm-cold variety and scarification. Moreover, it was found that the number of shoots per stump decreases as shoot age increases. Furthermore, spreading increases with greater light availability and decreasing tillage. The OBIA and CNN image analysis technologies achieved 97% and 99.5% accuracy for black locust classification in UAS images. All in all, the three reproduction strategies of black locust in short rotation coppices differ with regards to initialization, intensity, and growth performance, but all play a role in the survival and spreading of black locust.
KW  - Robinia pseudoacacia L.
KW  - reproduction
KW  - spreading
KW  - short rotation coppice
KW  - unmanned aerial system (UAS)
KW  - object-based image analysis (OBIA)
KW  - convolutional neural network (CNN)
DO  - 10.3390/f10030235
ER  -
TY  - EJOU
AU  - Gao, Lin
AU  - Song, Weidong
AU  - Dai, Jiguang
AU  - Chen, Yang
TI  - Road Extraction from High-Resolution Remote Sensing Imagery Using Refined Deep Residual Convolutional Neural Network
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 5
SN  - 2072-4292

AB  - Road extraction is one of the most significant tasks for modern transportation systems. This task is normally difficult due to complex backgrounds such as rural roads that have heterogeneous appearances with large intraclass and low interclass variations and urban roads that are covered by vehicles, pedestrians and the shadows of surrounding trees or buildings. In this paper, we propose a novel method for extracting roads from optical satellite images using a refined deep residual convolutional neural network (RDRCNN) with a postprocessing stage. RDRCNN consists of a residual connected unit (RCU) and a dilated perception unit (DPU). The RDRCNN structure is symmetric to generate the outputs of the same size. A math morphology and a tensor voting algorithm are used to improve RDRCNN performance during postprocessing. Experiments are conducted on two datasets of high-resolution images to demonstrate the performance of the proposed network architectures, and the results of the proposed architectures are compared with those of other network architectures. The results demonstrate the effective performance of the proposed method for extracting roads from a complex scene.
KW  - refined deep residual convolutional neural network
KW  - road extraction
KW  - remote sensing
KW  - tensor voting
KW  - math morphology
KW  - high-resolution imagery
DO  - 10.3390/rs11050552
ER  -
TY  - EJOU
AU  - Heim, René H.J.
AU  - Wright, Ian J.
AU  - Scarth, Peter
AU  - Carnegie, Angus J.
AU  - Taylor, Dominique
AU  - Oldeland, Jens
TI  - Multispectral, Aerial Disease Detection for Myrtle Rust (Austropuccinia psidii) on a Lemon Myrtle Plantation
T2  - Drones

PY  - 2019
VL  - 3
IS  - 1
SN  - 2504-446X

AB  - Disease management in agriculture often assumes that pathogens are spread homogeneously across crops. In practice, pathogens can manifest in patches. Currently, disease detection is predominantly carried out by human assessors, which can be slow and expensive. A remote sensing approach holds promise. Current satellite sensors are not suitable to spatially resolve individual plants or lack temporal resolution to monitor pathogenesis. Here, we used multispectral imaging and unmanned aerial systems (UAS) to explore whether myrtle rust (Austropuccinia psidii) could be detected on a lemon myrtle (Backhousia citriodora) plantation. Multispectral aerial imagery was collected from fungicide treated and untreated tree canopies, the fungicide being used to control myrtle rust. Spectral vegetation indices and single spectral bands were used to train a random forest classifier. Treated and untreated trees could be classified with high accuracy (95%). Important predictors for the classifier were the near-infrared (NIR) and red edge (RE) spectral band. Taking some limitations into account, that are discussedherein, our work suggests potential for mapping myrtle rust-related symptoms from aerial multispectral images. Similar studies could focus on pinpointing disease hotspots to adjust management strategies and to feed epidemiological models.
KW  - disease detection
KW  - drones
KW  - plant disease
KW  - precision agriculture
KW  - random forest
KW  - remote sensing
KW  - rust fungus
KW  - shadow
KW  - UAS
DO  - 10.3390/drones3010025
ER  -
TY  - EJOU
AU  - Asadi, Khashayar
AU  - Chen, Pengyu
AU  - Han, Kevin
AU  - Wu, Tianfu
AU  - Lobaton, Edgar
TI  - LNSNet: Lightweight Navigable Space Segmentation for Autonomous Robots on Construction Sites
T2  - Data

PY  - 2019
VL  - 4
IS  - 1
SN  - 2306-5729

AB  - An autonomous robot that can monitor a construction site should be able to be can contextually detect its surrounding environment by recognizing objects and making decisions based on its observation. Pixel-wise semantic segmentation in real-time is vital to building an autonomous and mobile robot. However, the learning models&rsquo; size and high memory usage associated with real-time segmentation are the main challenges for mobile robotics systems that have limited computing resources. To overcome these challenges, this paper presents an efficient semantic segmentation method named LNSNet (lightweight navigable space segmentation network) that can run on embedded platforms to determine navigable space in real-time. The core of model architecture is a new block based on separable convolution which compresses the parameters of present residual block meanwhile maintaining the accuracy and performance. LNSNet is faster, has fewer parameters and less model size, while provides similar accuracy compared to existing models. A new pixel-level annotated dataset for real-time and mobile navigable space segmentation in construction environments has been constructed for the proposed method. The results demonstrate the effectiveness and efficiency that are necessary for the future development of the autonomous robotics systems.
KW  - efficient real-time segmentation
KW  - embedded platform
KW  - autonomous navigation in construction
KW  - autonomous data collection
DO  - 10.3390/data4010040
ER  -
TY  - EJOU
AU  - Zhang, Chengming
AU  - Han, Yingjuan
AU  - Li, Feng
AU  - Gao, Shuai
AU  - Song, Dejuan
AU  - Zhao, Hui
AU  - Fan, Keqi
AU  - Zhang, Ya’nan
TI  - A New CNN-Bayesian Model for Extracting Improved Winter Wheat Spatial Distribution from GF-2 imagery
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 6
SN  - 2072-4292

AB  - When the spatial distribution of winter wheat is extracted from high-resolution remote sensing imagery using convolutional neural networks (CNN), field edge results are usually rough, resulting in lowered overall accuracy. This study proposed a new per-pixel classification model using CNN and Bayesian models (CNN-Bayesian model) for improved extraction accuracy. In this model, a feature extractor generates a feature vector for each pixel, an encoder transforms the feature vector of each pixel into a category-code vector, and a two-level classifier uses the difference between elements of category-probability vectors as the confidence value to perform per-pixel classifications. The first level is used to determine the category of a pixel with high confidence, and the second level is an improved Bayesian model used to determine the category of low-confidence pixels. The CNN-Bayesian model was trained and tested on Gaofen 2 satellite images. Compared to existing models, our approach produced an improvement in overall accuracy, the overall accuracy of SegNet, DeepLab, VGG-Ex, and CNN-Bayesian was 0.791, 0.852, 0.892, and 0.946, respectively. Thus, this approach can produce superior results when winter wheat spatial distribution is extracted from satellite imagery.
KW  - winter wheat
KW  - convolutional neural network
KW  - Visual Geometry Group Network
KW  - Bayesian model
KW  - per-pixel classification
KW  - high-resolution remote sensing imager
KW  - Gaofen 2 image
DO  - 10.3390/rs11060619
ER  -
TY  - EJOU
AU  - Xiu, Supu
AU  - Wen, Yuanqiao
AU  - Yuan, Haiwen
AU  - Xiao, Changshi
AU  - Zhan, Wenqiang
AU  - Zou, Xiong
AU  - Zhou, Chunhui
AU  - Shah, Sayed C.
TI  - A Multi-Feature and Multi-Level Matching Algorithm Using Aerial Image and AIS for Vessel Identification
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 6
SN  - 1424-8220

AB  - In order to monitor and manage vessels in channels effectively, identification and tracking are very necessary. This work developed a maritime unmanned aerial vehicle (Mar-UAV) system equipped with a high-resolution camera and an Automatic Identification System (AIS). A multi-feature and multi-level matching algorithm using the spatiotemporal characteristics of aerial images and AIS information was proposed to detect and identify field vessels. Specifically, multi-feature information, including position, scale, heading, speed, etc., are used to match between real-time image and AIS message. Additionally, the matching algorithm is divided into two levels, point matching and trajectory matching, for the accurate identification of surface vessels. Through such a matching algorithm, the Mar-UAV system is able to automatically identify the vessel&rsquo;s vision, which improves the autonomy of the UAV in maritime tasks. The multi-feature and multi-level matching algorithm has been employed for the developed Mar-UAV system, and some field experiments have been implemented in the Yangzi River. The results indicated that the proposed matching algorithm and the Mar-UAV system are very significant for achieving autonomous maritime supervision.
KW  - Unmanned Aerial Vehicle (UAV)
KW  - vision
KW  - Automatic Identification System (AIS)
KW  - vessel identification
KW  - maritime monitoring
DO  - 10.3390/s19061317
ER  -
TY  - EJOU
AU  - Safonova, Anastasiia
AU  - Tabik, Siham
AU  - Alcaraz-Segura, Domingo
AU  - Rubtsov, Alexey
AU  - Maglinets, Yuriy
AU  - Herrera, Francisco
TI  - Detection of Fir Trees (Abies sibirica) Damaged by the Bark Beetle in Unmanned Aerial Vehicle Images with Deep Learning
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 6
SN  - 2072-4292

AB  - Invasion of the Polygraphus proximus Blandford bark beetle causes catastrophic damage to forests with firs (Abies sibirica Ledeb) in Russia, especially in Central Siberia. Determining tree damage stage based on the shape, texture and colour of tree crown in unmanned aerial vehicle (UAV) images could help to assess forest health in a faster and cheaper way. However, this task is challenging since (i) fir trees at different damage stages coexist and overlap in the canopy, (ii) the distribution of fir trees in nature is irregular and hence distinguishing between different crowns is hard, even for the human eye. Motivated by the latest advances in computer vision and machine learning, this work proposes a two-stage solution: In a first stage, we built a detection strategy that finds the regions of the input UAV image that are more likely to contain a crown, in the second stage, we developed a new convolutional neural network (CNN) architecture that predicts the fir tree damage stage in each candidate region. Our experiments show that the proposed approach shows satisfactory results on UAV Red, Green, Blue (RGB) images of forest areas in the state nature reserve “Stolby” (Krasnoyarsk, Russia).
KW  - multi-class classification
KW  - drone
KW  - aerial photography
KW  - Siberian fir
KW  - Siberia
KW  - deep-learning
KW  - convolutional neural networks
KW  - forest health
DO  - 10.3390/rs11060643
ER  -
TY  - EJOU
AU  - Zang, Yufu
AU  - Yang, Bisheng
AU  - Li, Jianping
AU  - Guan, Haiyan
TI  - An Accurate TLS and UAV Image Point Clouds Registration Method for Deformation Detection of Chaotic Hillside Areas
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 6
SN  - 2072-4292

AB  - Deformation detection determines the quantified change of a scene&rsquo;s geometric state, which is of great importance for the mitigation of hazards and property loss from earth observation. Terrestrial laser scanning (TLS) provides an efficient and flexible solution to rapidly capture high precision three-dimensional (3D) point clouds of hillside areas. Most existing methods apply multi-temporal TLS surveys to detect deformations depending on a variety of ground control points (GCPs). However, on the one hand, the deployment of various GCPs is time-consuming and labor-intensive, particularly for difficult terrain areas. On the other hand, in most cases, TLS stations do not form a closed loop, such that cumulative errors cannot be corrected effectively by the existing methods. To overcome these drawbacks, this paper proposes a deformation detection method with limited GCPs based on a novel registration algorithm that accurately registers TLS stations to the UAV (Unmanned Aerial Vehicle) dense image points. First, the proposed method extracts patch primitives from smoothed hillside points, and adjacent TLS scans are pairwise registered by comparing the geometric and topological information of or between patches. Second, a new multi-station adjustment algorithm is proposed, which makes full use of locally closed loops to reach the global optimal registration. Finally, digital elevation models (DEMs, a DEM is a numerical representation of the terrain surface, formed by height points to represent the topography), slope and aspect maps, and vertical sections are generated from multi-temporal TLS surveys to detect and analyze the deformations. Comprehensive experiments demonstrate that the proposed deformation detection method obtains good performance for the hillside areas with limited (few) GCPs.
KW  - deformation detection
KW  - terrestrial laser scanning
KW  - multi-temporal
KW  - pairwise registration
KW  - multi-station adjustment
KW  - hillside areas
DO  - 10.3390/rs11060647
ER  -
TY  - EJOU
AU  - Li, Yundong
AU  - Hu, Wei
AU  - Dong, Han
AU  - Zhang, Xueyan
TI  - Building Damage Detection from Post-Event Aerial Imagery Using Single Shot Multibox Detector
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 6
SN  - 2076-3417

AB  - Using aerial cameras, satellite remote sensing or unmanned aerial vehicles (UAV) equipped with cameras can facilitate search and rescue tasks after disasters. The traditional manual interpretation of huge aerial images is inefficient and could be replaced by machine learning-based methods combined with image processing techniques. Given the development of machine learning, researchers find that convolutional neural networks can effectively extract features from images. Some target detection methods based on deep learning, such as the single-shot multibox detector (SSD) algorithm, can achieve better results than traditional methods. However, the impressive performance of machine learning-based methods results from the numerous labeled samples. Given the complexity of post-disaster scenarios, obtaining many samples in the aftermath of disasters is difficult. To address this issue, a damaged building assessment method using SSD with pretraining and data augmentation is proposed in the current study and highlights the following aspects. (1) Objects can be detected and classified into undamaged buildings, damaged buildings, and ruins. (2) A convolution auto-encoder (CAE) that consists of VGG16 is constructed and trained using unlabeled post-disaster images. As a transfer learning strategy, the weights of the SSD model are initialized using the weights of the CAE counterpart. (3) Data augmentation strategies, such as image mirroring, rotation, Gaussian blur, and Gaussian noise processing, are utilized to augment the training data set. As a case study, aerial images of Hurricane Sandy in 2012 were maximized to validate the proposed method&rsquo;s effectiveness. Experiments show that the pretraining strategy can improve of 10% in terms of overall accuracy compared with the SSD trained from scratch. These experiments also demonstrate that using data augmentation strategies can improve mAP and mF1 by 72% and 20%, respectively. Finally, the experiment is further verified by another dataset of Hurricane Irma, and it is concluded that the paper method is feasible.
KW  - building damage assessment
KW  - post-event
KW  - deep learning
KW  - SSD
KW  - convolutional autoencoder
DO  - 10.3390/app9061128
ER  -
TY  - EJOU
AU  - Kranjčić, Nikola
AU  - Medak, Damir
AU  - Župan, Robert
AU  - Rezo, Milan
TI  - Support Vector Machine Accuracy Assessment for Extracting Green Urban Areas in Towns
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 6
SN  - 2072-4292

AB  - The most commonly used model for analyzing satellite imagery is the Support Vector Machine (SVM). Since there are a large number of possible variables for use in SVM, this paper will provide a combination of parameters that fit best for extracting green urban areas from Copernicus mission satellite images. This paper aims to provide a combination of parameters to extract green urban areas with the highest degree of accuracy, in order to speed up urban planning and ultimately improve town environments. Two different towns in Croatia were investigated, and the results provide an optimal combination of parameters for green urban areas extraction with an overall kappa index of 0.87 and 0.89, which demonstrates a very high classification accuracy.
KW  - machine learning
KW  - support vector machine
KW  - kernels
KW  - green urban areas extraction
KW  - satellite images
DO  - 10.3390/rs11060655
ER  -
TY  - EJOU
AU  - Surový, Peter
AU  - Kuželka, Karel
TI  - Acquisition of Forest Attributes for Decision Support at the Forest Enterprise Level Using Remote-Sensing Techniques—A Review
T2  - Forests

PY  - 2019
VL  - 10
IS  - 3
SN  - 1999-4907

AB  - In recent decades, remote sensing techniques and the associated hardware and software have made substantial improvements. With satellite images that can obtain sub-meter spatial resolution, and new hardware, particularly unmanned aerial vehicles and systems, there are many emerging opportunities for improved data acquisition, including variable temporal and spectral resolutions. Combined with the evolution of techniques for aerial remote sensing, such as full wave laser scanners, hyperspectral scanners, and aerial radar sensors, the potential to incorporate this new data in forest management is enormous. Here we provide an overview of the current state-of-the-art remote sensing techniques for large forest areas thousands or tens of thousands of hectares. We examined modern remote sensing techniques used to obtain forest data that are directly applicable to decision making issues, and we provided a general overview of the types of data that can be obtained using remote sensing. The most easily accessible forest variable described in many works is stand or tree height, followed by other inventory variables like basal area, tree number, diameters, and volume, which are crucial in decision making process, especially for thinning and harvest planning, and timber transport optimization. Information about zonation and species composition are often described as more difficult to assess; however, this information usually is not required on annual basis. Counts of studies on forest health show an increasing trend in the last years, mostly in context of availability of new sensors as well as increased forest vulnerability caused by climate change; by virtue to modern sensors interesting methods were developed for detection of stressed or damaged trees. Unexpectedly few works focus on regeneration and seedlings evaluation; though regenerated stands should be regularly monitored in order to maintain forest cover sustainability.
KW  - remote sensing
KW  - forest enterprise
KW  - forest attributes
KW  - forest health
KW  - satellite imagery
KW  - aerial imagery
KW  - aerial laser scanner
KW  - unmanned aerial vehicles (UAV)
DO  - 10.3390/f10030273
ER  -
TY  - EJOU
AU  - Lim, Joongbin
AU  - Kim, Kyoung-Min
AU  - Jin, Ri
TI  - Tree Species Classification Using Hyperion and Sentinel-2 Data with Machine Learning in South Korea and China
T2  - ISPRS International Journal of Geo-Information

PY  - 2019
VL  - 8
IS  - 3
SN  - 2220-9964

AB  - Remote sensing (RS) has been used to monitor inaccessible regions. It is considered a useful technique for deriving important environmental information from inaccessible regions, especially North Korea. In this study, we aim to develop a tree species classification model based on RS and machine learning techniques, which can be utilized for classification in North Korea. Two study sites were chosen, the Korea National Arboretum (KNA) in South Korea and Mt. Baekdu (MTB; a.k.a., Mt. Changbai in Chinese) in China, located in the border area between North Korea and China, and tree species classifications were examined in both regions. As a preliminary step in developing a classification algorithm that can be applied in North Korea, common coniferous species at both study sites, Korean pine (Pinus koraiensis) and Japanese larch (Larix kaempferi), were chosen as targets for investigation. Hyperion data have been used for tree species classification due to the abundant spectral information acquired from across more than 200 spectral bands (i.e., hyperspectral satellite data). However, it is impossible to acquire recent Hyperion data because the satellite ceased operation in 2017. Recently, Sentinel-2 satellite multispectral imagery has been used in tree species classification. Thus, it is necessary to compare these two kinds of satellite data to determine the possibility of reliably classifying species. Therefore, Hyperion and Sentinel-2 data were employed, along with machine learning techniques, such as random forests (RFs) and support vector machines (SVMs), to classify tree species. Three questions were answered, showing that: (1) RF and SVM are well established in the hyperspectral imagery for tree species classification, (2) Sentinel-2 data can be used to classify tree species with RF and SVM algorithms instead of Hyperion data, and (3) training data that were built in the KNA cannot be used for the tree classification of MTB. Random forests and SVMs showed overall accuracies of 0.60 and 0.51 and kappa values of 0.20 and 0.00, respectively. Moreover, combined training data from the KNA and MTB showed high classification accuracies in both regions; RF and SVM values exhibited accuracies of 0.99 and 0.97 and kappa values of 0.98 and 0.95, respectively.
KW  - hyperspectral image
KW  - random forest
KW  - support vector machine
KW  - texture feature
KW  - image spectroscopy
DO  - 10.3390/ijgi8030150
ER  -
TY  - EJOU
AU  - Angelopoulou, Theodora
AU  - Tziolas, Nikolaos
AU  - Balafoutis, Athanasios
AU  - Zalidis, George
AU  - Bochtis, Dionysis
TI  - Remote Sensing Techniques for Soil Organic Carbon Estimation: A Review
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 6
SN  - 2072-4292

AB  - Towards the need for sustainable development, remote sensing (RS) techniques in the Visible-Near Infrared&ndash;Shortwave Infrared (VNIR&ndash;SWIR, 400&ndash;2500 nm) region could assist in a more direct, cost-effective and rapid manner to estimate important indicators for soil monitoring purposes. Soil reflectance spectroscopy has been applied in various domains apart from laboratory conditions, e.g., sensors mounted on satellites, aircrafts and Unmanned Aerial Systems. The aim of this review is to illustrate the research made for soil organic carbon estimation, with the use of RS techniques, reporting the methodology and results of each study. It also aims to provide a comprehensive introduction in soil spectroscopy for those who are less conversant with the subject. In total, 28 journal articles were selected and further analysed. It was observed that prediction accuracy reduces from Unmanned Aerial Systems (UASs) to satellite platforms, though advances in machine learning techniques could further assist in the generation of better calibration models. There are some challenges concerning atmospheric, radiometric and geometric corrections, vegetation cover, soil moisture and roughness that still need to be addressed. The advantages and disadvantages of each approach are highlighted and future considerations are also discussed at the end.
KW  - soil spectroscopy
KW  - soil organic carbon
KW  - VNIR–SWIR
KW  - machine learning
KW  - earth observation
DO  - 10.3390/rs11060676
ER  -
TY  - EJOU
AU  - Qu, Yuquan
AU  - Zhu, Zhongli
AU  - Chai, Linna
AU  - Liu, Shaomin
AU  - Montzka, Carsten
AU  - Liu, Jin
AU  - Yang, Xiaofan
AU  - Lu, Zheng
AU  - Jin, Rui
AU  - Li, Xiang
AU  - Guo, Zhixia
AU  - Zheng, Jie
TI  - Rebuilding a Microwave Soil Moisture Product Using Random Forest Adopting AMSR-E/AMSR2 Brightness Temperature and SMAP over the Qinghai–Tibet Plateau, China
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 6
SN  - 2072-4292

AB  - Time series of soil moisture (SM) data in the Qinghai&ndash;Tibet plateau (QTP) covering a period longer than one decade are important for understanding the dynamics of land surface&ndash;atmosphere feedbacks in the global climate system. However, most existing SM products have a relatively short time series or show low performance over the challenging terrain of the QTP. In order to improve the spaceborne monitoring in this area, this study presents a random forest (RF) method to rebuild a high-accuracy SM product over the QTP from 19 June 2002 to 31 March 2015 by adopting the advanced microwave scanning radiometer for earth observing system (AMSR-E), and the advanced microwave scanning radiometer 2 (AMSR2), and tracking brightness temperatures with latitude and longitude using the International Geosphere&ndash;Biospheres Programme (IGBP) classification data, the digital elevation model (DEM) and the day of the year (DOY) as spatial predictors. Brightness temperature products (from frequencies 10.7 GHz, 18.7 GHz and 36.5 GHz) of AMSR2 were used to train the random forest model on two years of Soil Moisture Active Passive (SMAP) SM data. The simulated SM values were compared with third year SMAP data and in situ stations. The results show that the RF model has high reliability as compared to SMAP, with a high correlation (R = 0.95) and low values of root mean square error (RMSE = 0.03 m3/m3) and mean absolute percent error (MAPE = 19%). Moreover, the random forest soil moisture (RFSM) results agree well with the data from five in situ networks, with mean values of R = 0.75, RMSE = 0.06 m3/m3, and bias = &minus;0.03 m3/m3 over the whole year and R = 0.70, RMSE = 0.07 m3/m3, and bias = &minus;0.05 m3/m3 during the unfrozen seasons. In order to test its performance throughout the whole region of QTP, the three-cornered hat (TCH) method based on removing common signals from observations and then calculating the uncertainties is applied. The results indicate that RFSM has the smallest relative error in 56% of the region, and it performs best relative to the Japan Aerospace Exploration Agency (JAXA), Global Land Data Assimilation System (GLDAS), and European Space Agency&rsquo;s Climate Change Initiative (ESA CCI) project. The spatial distribution shows that RFSM has a similar spatial trend as GLDAS and ESA CCI, but RFSM exhibits a more distinct spatial distribution and responds to precipitation more effectively than GLDAS and ESA CCI. Moreover, a trend analysis shows that the temporal variation of RFSM agrees well with precipitation and LST (land surface temperature), with a dry trend in most regions of QTP and a wet trend in few north, southeast and southwest regions of QTP. In conclusion, a spatiotemporally continuous SM product with a high accuracy over the QTP was obtained.
KW  - soil moisture
KW  - random forest
KW  - Qinghai–Tibet plateau
KW  - SMAP
KW  - AMSR-E
KW  - AMSR2
DO  - 10.3390/rs11060683
ER  -
TY  - EJOU
AU  - Liu, Shengjie
AU  - Qi, Zhixin
AU  - Li, Xia
AU  - Yeh, Anthony G.
TI  - Integration of Convolutional Neural Networks and Object-Based Post-Classification Refinement for Land Use and Land Cover Mapping with Optical and SAR Data
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 6
SN  - 2072-4292

AB  - Object-based image analysis (OBIA) has been widely used for land use and land cover (LULC) mapping using optical and synthetic aperture radar (SAR) images because it can utilize spatial information, reduce the effect of salt and pepper, and delineate LULC boundaries. With recent advances in machine learning, convolutional neural networks (CNNs) have become state-of-the-art algorithms. However, CNNs cannot be easily integrated with OBIA because the processing unit of CNNs is a rectangular image, whereas that of OBIA is an irregular image object. To obtain object-based thematic maps, this study developed a new method that integrates object-based post-classification refinement (OBPR) and CNNs for LULC mapping using Sentinel optical and SAR data. After producing the classification map by CNN, each image object was labeled with the most frequent land cover category of its pixels. The proposed method was tested on the optical-SAR Sentinel Guangzhou dataset with 10 m spatial resolution, the optical-SAR Zhuhai-Macau local climate zones (LCZ) dataset with 100 m spatial resolution, and a hyperspectral benchmark the University of Pavia with 1.3 m spatial resolution. It outperformed OBIA support vector machine (SVM) and random forest (RF). SVM and RF could benefit more from the combined use of optical and SAR data compared with CNN, whereas spatial information learned by CNN was very effective for classification. With the ability to extract spatial features and maintain object boundaries, the proposed method considerably improved the classification accuracy of urban ground targets. It achieved overall accuracy (OA) of 95.33% for the Sentinel Guangzhou dataset, OA of 77.64% for the Zhuhai-Macau LCZ dataset, and OA of 95.70% for the University of Pavia dataset with only 10 labeled samples per class.
KW  - object-based post-classification refinement (OBPR)
KW  - convolutional neural network (CNN)
KW  - synthetic aperture radar (SAR)
KW  - land use and land cover
KW  - object-based image analysis (OBIA)
DO  - 10.3390/rs11060690
ER  -
TY  - EJOU
AU  - Wu, Jintao
AU  - Yang, Guijun
AU  - Yang, Xiaodong
AU  - Xu, Bo
AU  - Han, Liang
AU  - Zhu, Yaohui
TI  - Automatic Counting of in situ Rice Seedlings from UAV Images Based on a Deep Fully Convolutional Neural Network
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 6
SN  - 2072-4292

AB  - The number of rice seedlings in the field is one of the main agronomic components for determining rice yield. This counting task, however, is still mainly performed using human vision rather than computer vision and is thus cumbersome and time-consuming. A fast and accurate alternative method of acquiring such data may contribute to monitoring the efficiency of crop management practices, to earlier estimations of rice yield, and as a phenotyping trait in breeding programs. In this paper, we propose an efficient method that uses computer vision to accurately count rice seedlings in a digital image. First, an unmanned aerial vehicle (UAV) equipped with red-green-blue (RGB) cameras was used to acquire field images at the seedling stage. Next, we use a regression network (Basic Network) inspired by a deep fully convolutional neural network to regress the density map and estimate the number of rice seedlings for a given UAV image. Finally, an improved version of the Basic Network, the Combined Network, is also proposed to further improve counting accuracy. To explore the efficacy of the proposed method, a novel rice seedling counting (RSC) dataset was built, which consisted of 40 images (where the number of seedlings varied between 3732 and 16,173) and corresponding manually-dotted annotations. The results demonstrated high average accuracy (higher than 93%) between counts according to the proposed method and manual (UAV image-based) rice seedling counts, and very good performance, with a high coefficient of determination (R2) (around 0.94). In conclusion, the results indicate that the proposed method is an efficient alternative for large-scale counting of rice seedlings, and offers a new opportunity for yield estimation. The RSC dataset and source code are available online.
KW  - rice seedlings
KW  - object counting
KW  - computer vision
KW  - deep learning
KW  - fully convolutional neural networks
DO  - 10.3390/rs11060691
ER  -
TY  - EJOU
AU  - Nguyen, Ngoc P.
AU  - Hong, Sung K.
TI  - Fault Diagnosis and Fault-Tolerant Control Scheme for Quadcopter UAVs with a Total Loss of Actuator
T2  - Energies

PY  - 2019
VL  - 12
IS  - 6
SN  - 1996-1073

AB  - Fault-tolerant control has drawn attention in recent years owning to its reliability and safe flight during missions. In this article, an active fault-tolerant control method is proposed to control a quadcopter in the presence of actuator faults and disturbances. Firstly, the dynamics of the quadcopter are presented. Secondly, a robust adaptive sliding mode Thau observer is presented to estimate the time-varying magnitudes of actuator faults. Thirdly, a fault-tolerant control scheme based on sliding mode control and reconfiguration technique is designed to maintain the quadcopter at the desired position despite the presence of faults. Unlike previous studies, the proposed method aims to integrate the fault diagnosis and a fault-tolerant control scheme into a single unit with total loss of actuator. Simulation results illustrate the efficiency of the suggested algorithm.
KW  - nonlinear control
KW  - fault-tolerant control
KW  - quadcopter systems
KW  - fault estimation
DO  - 10.3390/en12061139
ER  -
TY  - EJOU
AU  - Rominger, Kody
AU  - Meyer, Susan E.
TI  - Application of UAV-Based Methodology for Census of an Endangered Plant Species in a Fragile Habitat
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 6
SN  - 2072-4292

AB  - Accurate census is essential for endangered plant management, yet lack of resources may make complete on-the-ground census difficult to achieve. Accessibility, especially for species in fragile habitats, is an added constraint. We examined the feasibility of using UAV (unmanned aerial vehicle, drone)-based imagery for census of an endangered plant species, Arctomecon humilis (dwarf bear-poppy), an herbaceous perennial gypsophile endemic of the Mojave Desert, USA. Using UAV technology, we captured imagery at both 50-m altitude (census) and 15-m altitude (validation) at two populations, White Dome (325 ha) and Red Bluffs (166 ha). The imagery was processed into orthomosaics that averaged 2.32 cm ground sampling distance (GSD) for 50-m imagery and 0.73 cm GSD for 15-m imagery. Putative poppy plants were marked in the 50-m imagery according to predefined criteria. We then used the 15-m imagery from each area to verify the identification accuracy of marked plants. Visual evaluation of the 50-m imagery resulted in errors of both commission and omission, mainly caused by failure to accurately identify or detect small poppies (&lt;10 cm diameter). Higher-resolution 30-m altitude imagery (1.19 cm GSD) greatly reduced errors of commission. Habitat classification demonstrated that poppy density variation was closely tied to soil surface color. This study showed that drone imagery can potentially be used to census rare plant species with distinctive morphology in open habitats and understand their spatial distribution.
KW  - Arctomecon humilis
KW  - biodiversity
KW  - conservation
KW  - drone
KW  - dwarf bear-poppy
KW  - edaphic endemism
KW  - gypsum
KW  - habitat classification
KW  - object recognition
KW  - UAS (unmanned aerial system)
KW  - UAV (unmanned aerial vehicle)
DO  - 10.3390/rs11060719
ER  -
TY  - EJOU
AU  - Santamaria, Amilcare F.
AU  - Raimondo, Pierfrancesco
AU  - Tropea, Mauro
AU  - De Rango, Floriano
AU  - Aiello, Carmine
TI  - An IoT Surveillance System Based on a Decentralised Architecture
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 6
SN  - 1424-8220

AB  - In the last few years, we witnessed numerous episodes of terrorist attacks and menaces in public crowded places. The necessity of better surveillance in these places pushed the development of new automated solutions to spot and notify possible menaces as fast as possible. In this work, we propose a novel approach to create a decentralized architecture to manage patrolling drones and cameras exploiting lightweight protocols used in the internet of things (IoT) domain. Through the adoption of the mist computing paradigm it is possible to give to all the object of the smart ecosystem a cognitive intelligence to speed up the recognition and analysis tasks. Distributing the intelligence among all the objects of the surveillance ecosystem allows a faster recognition and reaction to possible warning situations. The recognition of unusual objects in certain areas, e.g., airports, train stations and bus stations, has been made using computer vision algorithms. The adoption of the IoT protocols in a hierarchical architecture provides high scalability allowing an easy and painless join of other smart objects. Also a study on the soft real-time feasibility has been conducted and is herein presented.
KW  - computer vision
KW  - surveillance
KW  - drones
KW  - internet of things
KW  - lightweight protocols
KW  - mist computing
KW  - OpenCV
DO  - 10.3390/s19061469
ER  -
TY  - EJOU
AU  - Windrim, Lloyd
AU  - Bryson, Mitch
AU  - McLean, Michael
AU  - Randle, Jeremy
AU  - Stone, Christine
TI  - Automated Mapping of Woody Debris over Harvested Forest Plantations Using UAVs, High-Resolution Imagery, and Machine Learning
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 6
SN  - 2072-4292

AB  - Surveying of woody debris left over from harvesting operations on managed forests is an important step in monitoring site quality, managing the extraction of residues and reconciling differences in pre-harvest inventories and actual timber yields. Traditional methods for post-harvest survey involving manual assessment of debris on the ground over small sample plots are labor-intensive, time-consuming, and do not scale well to heterogeneous landscapes. In this paper, we propose and evaluate new automated methods for the collection and interpretation of high-resolution, Unmanned Aerial Vehicle (UAV)-borne imagery over post-harvested forests for estimating quantities of fine and coarse woody debris. Using high-resolution, geo-registered color mosaics generated from UAV-borne images, we develop manual and automated processing methods for detecting, segmenting and counting both fine and coarse woody debris, including tree stumps, exploiting state-of-the-art machine learning and image processing techniques. Results are presented using imagery over a post-harvested compartment in a Pinus radiata plantation and demonstrate the capacity for both manual image annotations and automated image processing to accurately detect and quantify coarse woody debris and stumps left over after harvest, providing a cost-effective and scalable survey method for forest managers.
KW  - Unmanned Aerial Vehicles (UAVs)
KW  - computer vision
KW  - forestry
KW  - Coarse Woody Debris (CWD)
KW  - Convolutional Neural Networks (CNNs)
DO  - 10.3390/rs11060733
ER  -
TY  - EJOU
AU  - Hu, Jie
AU  - Peng, Jie
AU  - Zhou, Yin
AU  - Xu, Dongyun
AU  - Zhao, Ruiying
AU  - Jiang, Qingsong
AU  - Fu, Tingting
AU  - Wang, Fei
AU  - Shi, Zhou
TI  - Quantitative Estimation of Soil Salinity Using UAV-Borne Hyperspectral and Satellite Multispectral Images
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 7
SN  - 2072-4292

AB  - Soil salinization is a global issue resulting in soil degradation, arable land loss and ecological environmental deterioration. Over the decades, multispectral and hyperspectral remote sensing have enabled efficient and cost-effective monitoring of salt-affected soils. However, the potential of hyperspectral sensors installed on an unmanned aerial vehicle (UAV) to estimate and map soil salinity has not been thoroughly explored. This study quantitatively characterized and estimated field-scale soil salinity using an electromagnetic induction (EMI) equipment and a hyperspectral camera installed on a UAV platform. In addition, 30 soil samples (0~20 cm) were collected in each field for the lab measurements of electrical conductivity. First, the apparent electrical conductivity (ECa) values measured by EMI were calibrated using the lab measured electrical conductivity derived from soil samples based on empirical line method. Second, the soil salinity was quantitatively estimated using the random forest (RF) regression method based on the reflectance factors of UAV hyperspectral images and satellite multispectral data. The performance of models was assessed by Lin&rsquo;s concordance coefficient (CC), ratio of performance to deviation (RPD), and root mean square error (RMSE). Finally, the soil salinity of three study fields with different land cover were mapped. The results showed that bare land (field A) exhibited the most severe salinity, followed by dense vegetation area (field C) and sparse vegetation area (field B). The predictive models using UAV data outperformed those derived from GF-2 data with lower RMSE, higher CC and RPD values, and the most accurate UAV-derived model was developed using 62 hyperspectral bands of the image of the field A with the RMSE, CC, and RPD values of 1.40 dS m&minus;1, 0.94, and 2.98, respectively. Our results indicated that UAV-borne hyperspectral imager is a useful tool for field-scale soil salinity monitoring and mapping. With the help of the EMI technique, quantitative estimation of surface soil salinity is critical to decision-making in arid land management and saline soil reclamation.
KW  - soil salinity
KW  - unmanned aerial vehicle
KW  - hyperspectral imager
KW  - random forest regression
KW  - electromagnetic induction
DO  - 10.3390/rs11070736
ER  -
TY  - EJOU
AU  - Maimaitiyiming, Matthew
AU  - Sagan, Vasit
AU  - Sidike, Paheding
AU  - Kwasniewski, Misha T.
TI  - Dual Activation Function-Based Extreme Learning Machine (ELM) for Estimating Grapevine Berry Yield and Quality
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 7
SN  - 2072-4292

AB  - Reliable assessment of grapevine productivity is a destructive and time-consuming process. In addition, the mixed effects of grapevine water status and scion-rootstock interactions on grapevine productivity are not always linear. Despite the potential opportunity of applying remote sensing and machine learning techniques to predict plant traits, there are still limitations to previously studied techniques for vine productivity due to the complexity of the system not being adequately modeled. During the 2014 and 2015 growing seasons, hyperspectral reflectance spectra were collected using a handheld spectroradiometer in a vineyard designed to investigate the effects of irrigation level (0%, 50%, and 100%) and rootstocks (1103 Paulsen, 3309 Couderc, SO4 and Chambourcin) on vine productivity. To assess vine productivity, it is necessary to measure factors related to fruit ripeness and not just yield, as an over cropped vine may produce high-yield but poor-quality fruit. Therefore, yield, Total Soluble Solids (TSS), Titratable Acidity (TA) and the ratio TSS/TA (maturation index, IMAD) were measured. A total of 20 vegetation indices were calculated from hyperspectral data and used as input for predictive model calibration. Prediction performance of linear/nonlinear multiple regression methods and Weighted Regularized Extreme Learning Machine (WRELM) were compared with our newly developed WRELM-TanhRe. The developed method is based on two activation functions: hyperbolic tangent (Tanh) and rectified linear unit (ReLU). The results revealed that WRELM and WRELM-TanhRe outperformed the widely used multiple regression methods when model performance was tested with an independent validation dataset. WRELM-TanhRe produced the highest prediction accuracy for all the berry yield and quality parameters (R2 of 0.522&ndash;0.682 and RMSE of 2&ndash;15%), except for TA, which was predicted best with WRELM (R2 of 0.545 and RMSE of 6%). The results demonstrate the value of combining hyperspectral remote sensing and machine learning methods for improving of berry yield and quality prediction.
KW  - grapevine productivity
KW  - hyperspectral reflectance
KW  - stress
KW  - rootstock
KW  - vegetation indices
KW  - WRELM-TanhRe
KW  - neural network
KW  - activation function
DO  - 10.3390/rs11070740
ER  -
TY  - EJOU
AU  - Gebrehiwot, Asmamaw
AU  - Hashemi-Beni, Leila
AU  - Thompson, Gary
AU  - Kordjamshidi, Parisa
AU  - Langan, Thomas E.
TI  - Deep Convolutional Neural Network for Flood Extent Mapping Using Unmanned Aerial Vehicles Data
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 7
SN  - 1424-8220

AB  - Flooding is one of the leading threats of natural disasters to human life and property, especially in densely populated urban areas. Rapid and precise extraction of the flooded areas is key to supporting emergency-response planning and providing damage assessment in both spatial and temporal measurements. Unmanned Aerial Vehicles (UAV) technology has recently been recognized as an efficient photogrammetry data acquisition platform to quickly deliver high-resolution imagery because of its cost-effectiveness, ability to fly at lower altitudes, and ability to enter a hazardous area. Different image classification methods including SVM (Support Vector Machine) have been used for flood extent mapping. In recent years, there has been a significant improvement in remote sensing image classification using Convolutional Neural Networks (CNNs). CNNs have demonstrated excellent performance on various tasks including image classification, feature extraction, and segmentation. CNNs can learn features automatically from large datasets through the organization of multi-layers of neurons and have the ability to implement nonlinear decision functions. This study investigates the potential of CNN approaches to extract flooded areas from UAV imagery. A VGG-based fully convolutional network (FCN-16s) was used in this research. The model was fine-tuned and a k-fold cross-validation was applied to estimate the performance of the model on the new UAV imagery dataset. This approach allowed FCN-16s to be trained on the datasets that contained only one hundred training samples, and resulted in a highly accurate classification. Confusion matrix was calculated to estimate the accuracy of the proposed method. The image segmentation results obtained from FCN-16s were compared from the results obtained from FCN-8s, FCN-32s and SVMs. Experimental results showed that the FCNs could extract flooded areas precisely from UAV images compared to the traditional classifiers such as SVMs. The classification accuracy achieved by FCN-16s, FCN-8s, FCN-32s, and SVM for the water class was 97.52%, 97.8%, 94.20% and 89%, respectively.
KW  - remote sensing
KW  - convolutional neural networks
KW  - floodplain mapping
KW  - fully convolutional network
KW  - unmanned aerial vehicles
KW  - geospatial data processing
DO  - 10.3390/s19071486
ER  -
TY  - EJOU
AU  - Chu, Hone-Jay
AU  - Chen, Yi-Chin
AU  - Ali, Muhammad Z.
AU  - Höfle, Bernhard
TI  - Multi-Parameter Relief Map from High-Resolution DEMs: A Case Study of Mudstone Badland
T2  - International Journal of Environmental Research and Public Health

PY  - 2019
VL  - 16
IS  - 7
SN  - 1660-4601

AB  - Topographic parameters of high-resolution digital elevation models (DEMs) with meter to sub-meter spatial resolution, such as slope, curvature, openness, and wetness index, show the spatial properties and surface characterizations of terrains. The multi-parameter relief map, including two-parameter (2P) or three-parameter (3P) information, can visualize the topographic slope and terrain concavities and convexities in the hue, saturation, and value (HSV) color system. Various combinations of the topographic parameters can be used in the relief map, for instance, using wetness index for upstream representation. In particular, 3P relief maps are integrated from three critical topographic parameters including wetness or aspect, slope, and openness data. This study offers an effective way to explore the combination of topographic parameters in visualizing terrain features using multi-parameter relief maps in badlands and in showing the effects of smoothing and parameter selection. The multi-parameter relief images of high-resolution DEMs clearly show micro-topographic features, e.g., popcorn-like morphology and rill.
KW  - multi-parameter relief map
KW  - red relief
KW  - 3P relief map
KW  - DEM
KW  - badland
DO  - 10.3390/ijerph16071109
ER  -
TY  - EJOU
AU  - Zhao, Zhenbing
AU  - Zhen, Zhen
AU  - Zhang, Lei
AU  - Qi, Yincheng
AU  - Kong, Yinghui
AU  - Zhang, Ke
TI  - Insulator Detection Method in Inspection Image Based on Improved Faster R-CNN
T2  - Energies

PY  - 2019
VL  - 12
IS  - 7
SN  - 1996-1073

AB  - The detection of insulators in power transmission and transformation inspection images is the basis for insulator state detection and fault diagnosis in thereafter. Aiming at the detection of insulators with different aspect ratios and scales and ones with mutual occlusion, a method of insulator inspection image based on the improved faster region-convolutional neural network (R-CNN) is put forward in this paper. By constructing a power transmission and transformation insulation equipment detection dataset and fine-tuning the faster R-CNN model, the anchor generation method and non-maximum suppression (NMS) in the region proposal network (RPN) of the faster R-CNN model were improved, thus realizing a better detection of insulators. The experimental results show that the average precision (AP) value of the faster R-CNN model was increased to 0.818 with the improved anchor generation method under the VGG-16 Net. In addition, the detection effect of different aspect ratios and different scales of insulators in the inspection images was improved significantly, and the occlusion of insulators could be effectively distinguished and detected using the improved NMS.
KW  - insulator
KW  - Faster R-CNN
KW  - object detection
KW  - RPN
KW  - deep learning
DO  - 10.3390/en12071204
ER  -
TY  - EJOU
AU  - Aalerud, Atle
AU  - Dybedal, Joacim
AU  - Hovland, Geir
TI  - Automatic Calibration of an Industrial RGB-D Camera Network Using Retroreflective Fiducial Markers
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 7
SN  - 1424-8220

AB  - This paper describes a non-invasive, automatic, and robust method for calibrating a scalable RGB-D sensor network based on retroreflective ArUco markers and the iterative closest point (ICP) scheme. We demonstrate the system by calibrating a sensor network comprised of six sensor nodes positioned in a relatively large industrial robot cell with an approximate size of     10 &nbsp; m &times; 10 &nbsp; m &times; 4        m   . Here, the automatic calibration achieved an average Euclidean error of 3    c      m    at distances up to     9.45        m   . To achieve robustness, we apply several innovative techniques: Firstly, we mitigate the ambiguity problem that occurs when detecting a marker at long range or low resolution by comparing the camera projection with depth data. Secondly, we use retroreflective fiducial markers in the RGB-D calibration for improved accuracy and detectability. Finally, the repeating ICP refinement uses an exact region of interest such that we employ the precise depth measurements of the retroreflective surfaces only. The complete calibration software and a recorded dataset are publically available and open source.
KW  - 3D sensors
KW  - time-of-flight
KW  - automatic calibration
KW  - retroreflective markers
KW  - ambiguity problem
DO  - 10.3390/s19071561
ER  -
TY  - EJOU
AU  - Wei, Lifei
AU  - Yu, Ming
AU  - Zhong, Yanfei
AU  - Zhao, Ji
AU  - Liang, Yajing
AU  - Hu, Xin
TI  - Spatial–Spectral Fusion Based on Conditional Random Fields for the Fine Classification of Crops in UAV-Borne Hyperspectral Remote Sensing Imagery
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 7
SN  - 2072-4292

AB  - The fine classification of crops is critical for food security and agricultural management. There are many different species of crops, some of which have similar spectral curves. As a result, the precise classification of crops is a difficult task. Although the classification methods that incorporate spatial information can reduce the noise and improve the classification accuracy, to a certain extent, the problem is far from solved. Therefore, in this paper, the method of spatial&ndash;spectral fusion based on conditional random fields (SSF-CRF) for the fine classification of crops in UAV-borne hyperspectral remote sensing imagery is presented. The proposed method designs suitable potential functions in a pairwise conditional random field model, fusing the spectral and spatial features to reduce the spectral variation within the homogenous regions and accurately identify the crops. The experiments on hyperspectral datasets of the cities of Hanchuan and Honghu in China showed that, compared with the traditional methods, the proposed classification method can effectively improve the classification accuracy, protect the edges and shapes of the features, and relieve excessive smoothing, while retaining detailed information. This method has important significance for the fine classification of crops in hyperspectral remote sensing imagery.
KW  - hyperspectral remote sensing imagery
KW  - conditional random fields
KW  - spectral–spatial fusion
KW  - fine crop classification
KW  - unmanned aerial vehicle
DO  - 10.3390/rs11070780
ER  -
TY  - EJOU
AU  - Ostovar, Ahmad
AU  - Talbot, Bruce
AU  - Puliti, Stefano
AU  - Astrup, Rasmus
AU  - Ringdahl, Ola
TI  - Detection and Classification of Root and Butt-Rot (RBR) in Stumps of Norway Spruce Using RGB Images and Machine Learning
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 7
SN  - 1424-8220

AB  - Root and butt-rot (RBR) has a significant impact on both the material and economic outcome of timber harvesting, and therewith on the individual forest owner and collectively on the forest and wood processing industries. An accurate recording of the presence of RBR during timber harvesting would enable a mapping of the location and extent of the problem, providing a basis for evaluating spread in a climate anticipated to enhance pathogenic growth in the future. Therefore, a system to automatically identify and detect the presence of RBR would constitute an important contribution to addressing the problem without increasing workload complexity for the machine operator. In this study, we developed and evaluated an approach based on RGB images to automatically detect tree stumps and classify them as to the absence or presence of rot. Furthermore, since knowledge of the extent of RBR is valuable in categorizing logs, we also classify stumps into three classes of infestation; rot = 0%, 0% &lt; rot &lt; 50% and rot &ge; 50%. In this work we used deep-learning approaches and conventional machine-learning algorithms for detection and classification tasks. The results showed that tree stumps were detected with precision rate of 95% and recall of 80%. Using only the correct output (TP) of the stump detector, stumps without and with RBR were correctly classified with accuracy of 83.5% and 77.5%, respectively. Classifying rot into three classes resulted in 79.4%, 72.4%, and 74.1% accuracy for stumps with rot = 0%, 0% &lt; rot &lt; 50%, and rot &ge; 50%, respectively. With some modifications, the developed algorithm could be used either during the harvesting operation to detect RBR regions on the tree stumps or as an RBR detector for post-harvest assessment of tree stumps and logs.
KW  - deep learning
KW  - forest harvesting
KW  - tree stumps
KW  - automatic detection and classification
DO  - 10.3390/s19071579
ER  -
TY  - EJOU
AU  - Zahran, Shady
AU  - Moussa, Adel
AU  - El-Sheimy, Naser
TI  - Enhanced Drone Navigation in GNSS Denied Environment Using VDM and Hall Effect Sensor
T2  - ISPRS International Journal of Geo-Information

PY  - 2019
VL  - 8
IS  - 4
SN  - 2220-9964

AB  - The last decade has witnessed a wide spread of small drones in many civil and military applications. With the massive advancement in the manufacture of small and lightweight Inertial Navigation System (INS), navigation in challenging environments became feasible. Navigation of these small drones mainly depends on the integration of Global Navigation Satellite Systems (GNSS) and INS. However, the navigation performance of these small drones deteriorates quickly when the GNSS signals are lost, due to accumulated errors of the low-cost INS that is typically used in these drones. During GNSS signal outages, another aiding sensor is required to bound the drift exhibited by the INS. Before adding any additional sensor on-board the drones, there are some limitations that must be taken into considerations. These limitations include limited availability of power, space, weight, and size. This paper presents a novel unconventional method, to enhance the navigation of autonomous drones in GNSS denied environment, through a new utilization of hall effect sensor to act as flying odometer &ldquo;Air-Odo&rdquo; and vehicle dynamic model (VDM) for heading estimation. The proposed approach enhances the navigational solution by estimating the unmanned aerial vehicle (UAV) velocity, and heading and fusing these measurements in the Extended Kalman Filter (EKF) of the integrated system.
KW  - Extended Kalman Filter
KW  - drones
KW  - hall effect sensor
KW  - vehicle dynamic model
KW  - navigation
KW  - GNSS
DO  - 10.3390/ijgi8040169
ER  -
TY  - EJOU
AU  - Xavier, Thomaz W. F.
AU  - Souto, Roberto N. V.
AU  - Statella, Thiago
AU  - Galbieri, Rafael
AU  - Santos, Emerson S.
AU  - S. Suli, George
AU  - Zeilhofer, Peter
TI  - Identification of Ramularia Leaf Blight Cotton Disease Infection Levels by Multispectral, Multiscale UAV Imagery
T2  - Drones

PY  - 2019
VL  - 3
IS  - 2
SN  - 2504-446X

AB  - The reduction of the production cost and negative environmental impacts by pesticide application to control cotton diseases depends on the infection patterns spatialized in the farm scale. Here, we evaluate the potential of three-band multispectral imagery from a multi-rotor unmanned airborne vehicle (UAV) platform for the detection of ramularia leaf blight from different flight heights in an experimental field. Increasing infection levels indicate the progressive degradation of the spectral vegetation signal, however, they were not sufficient to differentiate disease severity levels. At resolutions of ~5 cm (100 m) and ~15 cm (300 m) up to a ground spatial resolution of ~25 cm (500 m flight height), two-scaled infection levels can be detected for the best performing algorithm of four classifiers tested, with an overall accuracy of ~79% and a kappa index of ~0.51. Despite limited classification performance, the results show the potential interest of low-cost multispectral systems to monitor ramularia blight in cotton.
KW  - disease severity assessment
KW  - ground cover
KW  - UAV
KW  - ramularia areola
KW  - remote sensing
DO  - 10.3390/drones3020033
ER  -
TY  - EJOU
AU  - Shen, Xin
AU  - Cao, Lin
AU  - Yang, Bisheng
AU  - Xu, Zhong
AU  - Wang, Guibin
TI  - Estimation of Forest Structural Attributes Using Spectral Indices and Point Clouds from UAS-Based Multispectral and RGB Imageries
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 7
SN  - 2072-4292

AB  - Forest structural attributes are key indicators for parameterization of forest growth models, which play key roles in understanding the biophysical processes and function of the forest ecosystem. In this study, UAS-based multispectral and RGB imageries were used to estimate forest structural attributes in planted subtropical forests. The point clouds were generated from multispectral and RGB imageries using the digital aerial photogrammetry (DAP) approach. Different suits of spectral and structural metrics (i.e., wide-band spectral indices and point cloud metrics) derived from multispectral and RGB imageries were compared and assessed. The selected spectral and structural metrics were used to fit partial least squares (PLS) regression models individually and in combination to estimate forest structural attributes (i.e., Lorey&rsquo;s mean height (HL) and volume(V)), and the capabilities of multispectral- and RGB-derived spectral and structural metrics in predicting forest structural attributes in various stem density forests were assessed and compared. The results indicated that the derived DAP point clouds had perfect visual effects and that most of the structural metrics extracted from the multispectral DAP point cloud were highly correlated with the metrics derived from the RGB DAP point cloud (R2 &gt; 0.75). Although the models including only spectral indices had the capability to predict forest structural attributes with relatively high accuracies (R2 = 0.56&ndash;0.69, relative Root-Mean-Square-Error (RMSE) = 10.88&ndash;21.92%), the models with spectral and structural metrics had higher accuracies (R2 = 0.82&ndash;0.93, relative RMSE = 4.60&ndash;14.17%). Moreover, the models fitted using multispectral- and RGB-derived metrics had similar accuracies (∆R2 = 0&ndash;0.02, ∆ relative RMSE = 0.18&ndash;0.44%). In addition, the combo models fitted with stratified sample plots had relatively higher accuracies than those fitted with all of the sample plots (∆R2 = 0&ndash;0.07, ∆ relative RMSE = 0.49&ndash;3.08%), and the accuracies increased with increasing stem density.
KW  - UAS platform
KW  - multispectral imagery
KW  - point cloud
KW  - forest structural attributes
DO  - 10.3390/rs11070800
ER  -
TY  - EJOU
AU  - Azabi, Yousef
AU  - Savvaris, Al
AU  - Kipouros, Timoleon
TI  - Artificial Intelligence to Enhance Aerodynamic Shape Optimisation of the Aegis UAV
T2  - Machine Learning and Knowledge Extraction

PY  - 2019
VL  - 1
IS  - 2
SN  - 2504-4990

AB  - This article presents an optimisation framework that uses stochastic multi-objective optimisation, combined with an Artificial Neural Network (ANN), and describes its application to the aerodynamic design of aircraft shapes. The framework uses the Multi-Objective Particle Swarm Optimisation (MOPSO) algorithm and the obtained results confirm that the proposed technique provides highly optimal solutions in less computational time than other approaches to the same design problem. The main idea was to focus computational effort on worthwhile design solutions rather than exploring and evaluating all possible solutions in the design space. It is shown that the number of valid solutions obtained using ANN-MOPSO compared to MOPSO for 3000 evaluations grew from 529 to 1006 (90% improvement) with a penalty of only 8.3% (11 min) in computational time. It is demonstrated that including an ANN, the ANN-MOPSO with 3000 evaluations produced a larger number of valid solutions than the MOPSO with 5500 evaluations, and in 33% less computational time (64 min). This is taken as confirmation of the potential power of ANNs when applied to this type of design problem.
KW  - machine learning
KW  - data visualization
KW  - Multi-Objective Particle Swarm Optimisation
KW  - Multi-Objective Tabu Search
KW  - nimrod/tool
KW  - parallel coordinates
KW  - Athena Vortex Lattice
DO  - 10.3390/make1020033
ER  -
TY  - EJOU
AU  - Hong, Suk-Ju
AU  - Han, Yunhyeok
AU  - Kim, Sang-Yeon
AU  - Lee, Ah-Yeong
AU  - Kim, Ghiseok
TI  - Application of Deep-Learning Methods to Bird Detection Using Unmanned Aerial Vehicle Imagery
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 7
SN  - 1424-8220

AB  - Wild birds are monitored with the important objectives of identifying their habitats and estimating the size of their populations. Especially in the case of migratory bird, they are significantly recorded during specific periods of time to forecast any possible spread of animal disease such as avian influenza. This study led to the construction of deep-learning-based object-detection models with the aid of aerial photographs collected by an unmanned aerial vehicle (UAV). The dataset containing the aerial photographs includes diverse images of birds in various bird habitats and in the vicinity of lakes and on farmland. In addition, aerial images of bird decoys are captured to achieve various bird patterns and more accurate bird information. Bird detection models such as Faster Region-based Convolutional Neural Network (R-CNN), Region-based Fully Convolutional Network (R-FCN), Single Shot MultiBox Detector (SSD), Retinanet, and You Only Look Once (YOLO) were created and the performance of all models was estimated by comparing their computing speed and average precision. The test results show Faster R-CNN to be the most accurate and YOLO to be the fastest among the models. The combined results demonstrate that the use of deep-learning-based detection methods in combination with UAV aerial imagery is fairly suitable for bird detection in various environments.
KW  - deep learning
KW  - convolutional neural networks
KW  - unmanned aerial vehicle
KW  - bird detection
DO  - 10.3390/s19071651
ER  -
TY  - EJOU
AU  - Mao, Huihui
AU  - Meng, Jihua
AU  - Ji, Fujiang
AU  - Zhang, Qiankun
AU  - Fang, Huiting
TI  - Comparison of Machine Learning Regression Algorithms for Cotton Leaf Area Index Retrieval Using Sentinel-2 Spectral Bands
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 7
SN  - 2076-3417

AB  - Leaf area index (LAI) is a crucial crop biophysical parameter that has been widely used in a variety of fields. Five state-of-the-art machine learning regression algorithms (MLRAs), namely, artificial neural network (ANN), support vector regression (SVR), Gaussian process regression (GPR), random forest (RF) and gradient boosting regression tree (GBRT), have been used in the retrieval of cotton LAI with Sentinel-2 spectral bands. The performances of the five machine learning models are compared for better applications of MLRAs in remote sensing, since challenging problems remain in the selection of MLRAs for crop LAI retrieval, as well as the decision as to the optimal number for the training sample size and spectral bands to different MLRAs. A comprehensive evaluation was employed with respect to model accuracy, computational efficiency, sensitivity to training sample size and sensitivity to spectral bands. We conducted the comparison of five MLRAs in an agricultural area of Northwest China over three cotton seasons with the corresponding field campaigns for modeling and validation. Results show that the GBRT model outperforms the other models with respect to model accuracy in average (       R 2   &macr;      = 0.854,       R M S E  &macr;      = 0.674 and       M A E  &macr;      = 0.456). SVR achieves the best performance in computational efficiency, which means it is fast to train, and to validate that it has great potentials to deliver near-real-time operational products for crop management. As for sensitivity to training sample size, GBRT behaves as the most robust model, and provides the best model accuracy on the average among the variations of training sample size, compared with other models (       R 2   &macr;      = 0.884,       R M S E  &macr;      = 0.615 and       M A E  &macr;      = 0.452). Spectral bands sensitivity analysis with dCor (distance correlation), combined with the backward elimination approach, indicates that SVR, GPR and RF provide relatively robust performance to the spectral bands, while ANN outperforms the other models in terms of model accuracy on the average among the reduction of spectral bands (       R 2   &macr;      = 0.881,       R M S E  &macr;      = 0.625 and       M A E  &macr;      = 0.480). A comprehensive evaluation indicates that GBRT is an appealing alternative for cotton LAI retrieval, except for its computational efficiency. Despite the different performance of the ML models, all models exhibited considerable potential for cotton LAI retrieval, which could offer accurate crop parameters information timely and accurately for crop fields management and agricultural production decisions.
KW  - leaf area index (LAI)
KW  - machine learning
KW  - Sentinel-2
KW  - sensitivity analysis
KW  - training sample size
KW  - spectral bands
DO  - 10.3390/app9071459
ER  -
TY  - EJOU
AU  - Li, You
AU  - Zahran, Shady
AU  - Zhuang, Yuan
AU  - Gao, Zhouzheng
AU  - Luo, Yiran
AU  - He, Zhe
AU  - Pei, Ling
AU  - Chen, Ruizhi
AU  - El-Sheimy, Naser
TI  - IMU/Magnetometer/Barometer/Mass-Flow Sensor Integrated Indoor Quadrotor UAV Localization with Robust Velocity Updates
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 7
SN  - 2072-4292

AB  - Velocity updates have been proven to be important for constraining motion-sensor-based dead-reckoning (DR) solutions in indoor unmanned aerial vehicle (UAV) applications. The forward velocity from a mass flow sensor and the lateral and vertical non-holonomic constraints (NHC) can be utilized for three-dimensional (3D) velocity updates. However, it is observed that (a) the quadrotor UAV may have a vertical velocity trend when it is controlled to move horizontally; (b) the quadrotor may have a pitch angle when moving horizontally; and (c) the mass flow sensor may suffer from sensor errors, especially the scale factor error. Such phenomenons degrade the performance of velocity updates. Thus, this paper presents a multi-sensor integrated localization system that has more effective sensor interactions. Specifically, (a) the barometer data are utilized to detect height changes and thus determine the weight of vertical velocity update; (b) the pitch angle from the inertial measurement unit (IMU) and magnetometer data fusion is used to set the weight of forward velocity update; and (c) an extra mass flow sensor calibration module is introduced. Indoor flight tests have indicated the effectiveness of the proposed sensor interaction strategies in enhancing indoor quadrotor DR solutions, which can also be used for detecting outliers in external localization technologies such as ultrasonics.
KW  - indoor localization
KW  - quadrotor UAV
KW  - air flow
KW  - inertial sensor
KW  - magnetometer
KW  - barometer
KW  - ultrasonic
KW  - Kalman filter
DO  - 10.3390/rs11070838
ER  -
TY  - EJOU
AU  - Marques, Pedro
AU  - Pádua, Luís
AU  - Adão, Telmo
AU  - Hruška, Jonáš
AU  - Peres, Emanuel
AU  - Sousa, António
AU  - Sousa, Joaquim J.
TI  - UAV-Based Automatic Detection and Monitoring of Chestnut Trees
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 7
SN  - 2072-4292

AB  - Unmanned aerial vehicles have become a popular remote sensing platform for agricultural applications, with an emphasis on crop monitoring. Although there are several methods to detect vegetation through aerial imagery, these remain dependent of manual extraction of vegetation parameters. This article presents an automatic method that allows for individual tree detection and multi-temporal analysis, which is crucial in the detection of missing and new trees and monitoring their health conditions over time. The proposed method is based on the computation of vegetation indices (VIs), while using visible (RGB) and near-infrared (NIR) domain combination bands combined with the canopy height model. An overall segmentation accuracy above 95% was reached, even when RGB-based VIs were used. The proposed method is divided in three major steps: (1) segmentation and first clustering; (2) cluster isolation; and (3) feature extraction. This approach was applied to several chestnut plantations and some parameters&mdash;such as the number of trees present in a plantation (accuracy above 97%), the canopy coverage (93% to 99% accuracy), the tree height (RMSE of 0.33 m and R2 = 0.86), and the crown diameter (RMSE of 0.44 m and R2 = 0.96)&mdash;were automatically extracted. Therefore, by enabling the substitution of time-consuming and costly field campaigns, the proposed method represents a good contribution in managing chestnut plantations in a quicker and more sustainable way.
KW  - unmanned aerial vehicles
KW  - remote sensing
KW  - automatic plantation monitoring
KW  - chestnut trees
KW  - image processing
KW  - photogrammetric processing
KW  - multi-temporal analysis
DO  - 10.3390/rs11070855
ER  -
TY  - EJOU
AU  - Liu, Yao
AU  - Shi, Jianmai
AU  - Liu, Zhong
AU  - Huang, Jincai
AU  - Zhou, Tianren
TI  - Two-Layer Routing for High-Voltage Powerline Inspection by Cooperated Ground Vehicle and Drone
T2  - Energies

PY  - 2019
VL  - 12
IS  - 7
SN  - 1996-1073

AB  - A novel high-voltage powerline inspection system was investigated, which consists of the cooperated ground vehicle and drone. The ground vehicle acts as a mobile platform that can launch and recycle the drone, while the drone can fly over the powerline for inspection within limited endurance. This inspection system enables the drone to inspect powerline networks in a very large area. Both vehicle&rsquo; route in the road network and drone&rsquo;s routes along the powerline network have to be optimized for improving the inspection efficiency, which generates a new Two-Layer Point-Arc Routing Problem (2L-PA-RP). Two constructive heuristics were designed based on &ldquo;Cluster First, Route Second&rdquo; and &ldquo;Route First, Split Second&rdquo;. Then, local search strategies were developed to further improve the quality of the solution. To test the performance of the proposed algorithms, different-scale practical cases were designed based on the road network and powerline network of Ji&rsquo;an, China. Sensitivity analysis on the parameters related to the drone&rsquo;s inspection speed and battery capacity was conducted. Computational results indicate that technical improvement on the inspection sensor is more important for the cooperated ground vehicle and drone system.
KW  - high-voltage powerline inspection
KW  - vehicle routing
KW  - arc routing
KW  - drone
KW  - heuristic
DO  - 10.3390/en12071385
ER  -
TY  - EJOU
AU  - Jiang, Qi
AU  - Fang, Shenghui
AU  - Peng, Yi
AU  - Gong, Yan
AU  - Zhu, Renshan
AU  - Wu, Xianting
AU  - Ma, Yi
AU  - Duan, Bo
AU  - Liu, Jian
TI  - UAV-Based Biomass Estimation for Rice-Combining Spectral, TIN-Based Structural and Meteorological Features
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 7
SN  - 2072-4292

AB  - Accurate estimation of above ground biomass (AGB) is very important for crop growth monitoring. The objective of this study was to estimate rice biomass by utilizing structural and meteorological features with widely used spectral features. Structural features were derived from the triangulated irregular network (TIN), which was directly built from structure from motion (SfM) point clouds. Growing degree days (GDD) was used as the meteorological feature. Three models were used to estimate rice AGB, including the simple linear regression (SLR) model, simple exponential regression (SER) model, and machine learning model (random forest). Compared to models that do not use structural and meteorological features (NDRE, R2 = 0.64, RMSE = 286.79 g/m2, MAE = 236.49 g/m2), models that include such features obtained better estimation accuracy (NDRE*Hcv/GDD, R2 = 0.86, RMSE = 178.37 g/m2, MAE = 127.34 g/m2). This study suggests that the estimation accuracy of rice biomass can benefit from the utilization of structural and meteorological features.
KW  - unmanned aerial vehicle (UAV)
KW  - above ground biomass (AGB)
KW  - triangulated irregular network (TIN)
KW  - growing degree days (GDD)
DO  - 10.3390/rs11070890
ER  -
TY  - EJOU
AU  - Guo, Qiang
AU  - Yu, Xin
AU  - Ruan, Guoqing
TI  - LPI Radar Waveform Recognition Based on Deep Convolutional Neural Network Transfer Learning
T2  - Symmetry

PY  - 2019
VL  - 11
IS  - 4
SN  - 2073-8994

AB  - Low Probability of Intercept (LPI) radar waveform recognition is not only an important branch of the electronic reconnaissance field, but also an important means to obtain non-cooperative radar information. To solve the problems of LPI radar waveform recognition rate, difficult feature extraction and large number of samples needed, an automatic classification and recognition system based on Choi-Williams distribution (CWD) and depth convolution neural network migration learning is proposed in this paper. First, the system performs CWD time-frequency transform on the LPI radar waveform to obtain a 2-D time-frequency image. Then the system preprocesses the original time-frequency image. In addition, then the system sends the pre-processed image to the pre-training model (Inception-v3 or ResNet-152) of the deep convolution network for feature extraction. Finally, the extracted features are sent to a Support Vector Machine (SVM) classifier to realize offline training and online recognition of radar waveforms. The simulation results show that the overall recognition rate of the eight LPI radar signals (LFM, BPSK, Costas, Frank, and T1&ndash;T4) of the ResNet-152-SVM system reaches 97.8%, and the overall recognition rate of the Inception-v3-SVM system reaches 96.2% when the SNR is &minus;2 dB.
KW  - Low Probability of Intercept
KW  - CWD time-frequency analysis
KW  - Inception-v3
KW  - ResNet-152
KW  - transfer learning
DO  - 10.3390/sym11040540
ER  -
TY  - EJOU
AU  - Zhu, Jiasong
AU  - Chen, Siyuan
AU  - Tu, Wei
AU  - Sun, Ke
TI  - Tracking and Simulating Pedestrian Movements at Intersections Using Unmanned Aerial Vehicles
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 8
SN  - 2072-4292

AB  - For a city to be livable and walkable is the ultimate goal of future cities. However, conflicts among pedestrians, vehicles, and cyclists at traffic intersections are becoming severe in high-density urban transportation areas, especially in China. Correspondingly, the transit time at intersections is becoming prolonged, and pedestrian safety is becoming endangered. Simulating pedestrian movements at complex traffic intersections is necessary to optimize the traffic organization. We propose an unmanned aerial vehicle (UAV)-based method for tracking and simulating pedestrian movements at intersections. Specifically, high-resolution videos acquired by a UAV are used to recognize and position moving targets, including pedestrians, cyclists, and vehicles, using the convolutional neural network. An improved social force-based motion model is proposed, considering the conflicts among pedestrians, cyclists, and vehicles. In addition, maximum likelihood estimation is performed to calibrate an improved social force model. UAV videos of intersections in Shenzhen are analyzed to demonstrate the performance of the presented approach. The results demonstrate that the proposed social force-based motion model can effectively simulate the movement of pedestrians and cyclists at road intersections. The presented approach provides an alternative method to track and simulate pedestrian movements, thus benefitting the organization of pedestrian flow and traffic signals controlling the intersections.
KW  - pedestrian simulation
KW  - social force model
KW  - intersection
KW  - UAV
KW  - convolutional neural network
KW  - deep learning
DO  - 10.3390/rs11080925
ER  -
TY  - EJOU
AU  - Tzitzilonis, Vasileios
AU  - Malandrakis, Konstantinos
AU  - Zanotti Fragonara, Luca
AU  - Gonzalez Domingo, Jose A.
AU  - Avdelidis, Nicolas P.
AU  - Tsourdos, Antonios
AU  - Forster, Kevin
TI  - Inspection of Aircraft Wing Panels Using Unmanned Aerial Vehicles
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 8
SN  - 1424-8220

AB  - In large civil aircraft manufacturing, a time-consuming post-production process is the non-destructive inspection of wing panels. This work aims to address this challenge and improve the defects&rsquo; detection by performing automated aerial inspection using a small off-the-shelf multirotor. The UAV is equipped with a wide field-of-view camera and an ultraviolet torch for implementing non-invasive imaging inspection. In particular, the UAV is programmed to perform the complete mission and stream video, in real-time, to the ground control station where the defects&rsquo; detection algorithm is executed. The proposed platform was mathematically modelled in MATLAB/SIMULINK in order to assess the behaviour of the system using a path following method during the aircraft wing inspection. In addition, two defect detection algorithms were implemented and tested on a dataset containing images obtained during inspection at Airbus facilities. The results show that for the current dataset the proposed methods can identify all the images containing defects.
KW  - Non-Destructive Testing
KW  - ultraviolet light
KW  - automated inspection
KW  - defects detection
KW  - UAV
KW  - image processing
DO  - 10.3390/s19081824
ER  -
TY  - EJOU
AU  - Swinfield, Tom
AU  - Lindsell, Jeremy A.
AU  - Williams, Jonathan V.
AU  - Harrison, Rhett D.
AU  - Agustiono
AU  - Habibi
AU  - Gemita, Elva
AU  - Schönlieb, Carola B.
AU  - Coomes, David A.
TI  - Accurate Measurement of Tropical Forest Canopy Heights and Aboveground Carbon Using Structure From Motion
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 8
SN  - 2072-4292

AB  - Unmanned aerial vehicles are increasingly used to monitor forests. Three-dimensional models of tropical rainforest canopies can be constructed from overlapping photos using Structure from Motion (SfM), but it is often impossible to map the ground elevation directly from such data because canopy gaps are rare in rainforests. Without knowledge of the terrain elevation, it is, thus, difficult to accurately measure the canopy height or forest properties, including the recovery stage and aboveground carbon density. Working in an Indonesian ecosystem restoration landscape, we assessed how well SfM derived the estimates of the canopy height and aboveground carbon density compared with those from an airborne laser scanning (also known as LiDAR) benchmark. SfM systematically underestimated the canopy height with a mean bias of approximately 5 m. The linear models suggested that the bias increased quadratically with the top-of-canopy height for short, even-aged, stands but linearly for tall, structurally complex canopies (&gt;10 m). The predictions based on the simple linear model were closely correlated to the field-measured heights when the approach was applied to an independent survey in a different location (    R 2     = 67% and RMSE = 1.85 m), but a negative bias of 0.89 m remained, suggesting the need to refine the model parameters with additional training data. Models that included the metrics of canopy complexity were less biased but with a reduced     R 2    . The inclusion of ground control points (GCPs) was found to be important in accurately registering SfM measurements in space, which is essential if the survey requirement is to produce small-scale restoration interventions or to track changes through time. However, at the scale of several hectares, the top-of-canopy height and above-ground carbon density estimates from SfM and LiDAR were very similar even without GCPs. The ability to produce accurate top-of-canopy height and carbon stock measurements from SfM is game changing for forest managers and restoration practitioners, providing the means to make rapid, low-cost surveys over hundreds of hectares without the need for LiDAR.
KW  - UAV
KW  - structure from motion
KW  - tropical forest
KW  - canopy height
KW  - aboveground carbon
KW  - biomass
DO  - 10.3390/rs11080928
ER  -
TY  - EJOU
AU  - Raber, George T.
AU  - Schill, Steven R.
TI  - Reef Rover: A Low-Cost Small Autonomous Unmanned Surface Vehicle (USV) for Mapping and Monitoring Coral Reefs
T2  - Drones

PY  - 2019
VL  - 3
IS  - 2
SN  - 2504-446X

AB  - In the effort to design a more repeatable and consistent platform to collect data for Structure from Motion (SfM) monitoring of coral reefs and other benthic habitats, we explore the use of recent advances in open source Global Positioning System (GPS)-guided drone technology to design and test a low-cost and transportable small unmanned surface vehicle (sUSV). The vehicle operates using Ardupilot open source software and can be used by local scientists and marine managers to map and monitor marine environments in shallow areas (&lt;20 m) with commensurate visibility. The imaging system uses two Sony a6300 mirrorless cameras to collect stereo photos that can be later processed using photogrammetry software to create underwater high-resolution orthophoto mosaics and digital surface models. The propulsion system consists of two small brushless motors powered by lithium batteries that follow pre-programmed survey transects and are operated by a GPS-guided autopilot control board. Results from our project suggest the sUSV provides a repeatable, viable, and low-cost (&lt;$3000 USD) solution for acquiring images of benthic environments on a frequent basis from directly below the water surface. These images can be used to create SfM models that provide very detailed images and measurements that can be used to monitor changes in biodiversity, reef erosion/accretion, and assessing health conditions.
KW  - coral reef
KW  - small unmanned surface vehicle (sUSV)
KW  - Rover
KW  - underwater
KW  - SfM
KW  - monitoring
DO  - 10.3390/drones3020038
ER  -
TY  - EJOU
AU  - Habyarimana, Ephrem
AU  - Piccard, Isabelle
AU  - Catellani, Marcello
AU  - De Franceschi, Paolo
AU  - Dall’Agata, Michela
TI  - Towards Predictive Modeling of Sorghum Biomass Yields Using Fraction of Absorbed Photosynthetically Active Radiation Derived from Sentinel-2 Satellite Imagery and Supervised Machine Learning Techniques
T2  - Agronomy

PY  - 2019
VL  - 9
IS  - 4
SN  - 2073-4395

AB  - Sorghum crop is grown under tropical and temperate latitudes for several purposes including production of health promoting food from the kernel and forage and biofuels from aboveground biomass. One of the concerns of policy-makers and sorghum growers is to cost-effectively predict biomass yields early during the cropping season to improve biomass and biofuel management. The objective of this study was to investigate if Sentinel-2 satellite images could be used to predict within-season biomass sorghum yields in the Mediterranean region. Thirteen machine learning algorithms were tested on fortnightly Sentinel-2A and Sentinel-2B estimates of the fraction of Absorbed Photosynthetically Active Radiation (fAPAR) in combination with in situ aboveground biomass yields from demonstrative fields in Italy. A gradient boosting algorithm implementing the xgbtree method was the best predictive model as it was satisfactorily implemented anywhere from May to July. The best prediction time was the month of May followed by May&ndash;June and May&ndash;July. To the best of our knowledge, this work represents the first time Sentinel-2-derived fAPAR is used in sorghum biomass predictive modeling. The results from this study will help farmers improve their sorghum biomass business operations and policy-makers and extension services improve energy planning and avoid energy-related crises.
KW  - sorghum biomass
KW  - prediction modeling
KW  - machine learning
KW  - fAPAR
KW  - Sentinel-2 satellite imagery
KW  - big data technology
KW  - remote sensing
DO  - 10.3390/agronomy9040203
ER  -
TY  - EJOU
AU  - Barbedo, Jayme G.
TI  - A Review on the Use of Unmanned Aerial Vehicles and Imaging Sensors for Monitoring and Assessing Plant Stresses
T2  - Drones

PY  - 2019
VL  - 3
IS  - 2
SN  - 2504-446X

AB  - Unmanned aerial vehicles (UAVs) are becoming a valuable tool to collect data in a variety of contexts. Their use in agriculture is particularly suitable, as those areas are often vast, making ground scouting difficult, and sparsely populated, which means that injury and privacy risks are not as important as in urban settings. Indeed, the use of UAVs for monitoring and assessing crops, orchards, and forests has been growing steadily during the last decade, especially for the management of stresses such as water, diseases, nutrition deficiencies, and pests. This article presents a critical overview of the main advancements on the subject, focusing on the strategies that have been used to extract the information contained in the images captured during the flights. Based on the information found in more than 100 published articles and on our own research, a discussion is provided regarding the challenges that have already been overcome and the main research gaps that still remain, together with some suggestions for future research.
KW  - drone
KW  - UAV
KW  - UAS
KW  - precision agriculture
KW  - stress
KW  - crop
KW  - orchard
DO  - 10.3390/drones3020040
ER  -
TY  - EJOU
AU  - Paz-Kagan, Tarin
AU  - Silver, Micha
AU  - Panov, Natalya
AU  - Karnieli, Arnon
TI  - Multispectral Approach for Identifying Invasive Plant Species Based on Flowering Phenology Characteristics
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 8
SN  - 2072-4292

AB  - Invasive plant species (IPS) are the second biggest threat to biodiversity after habitat loss. Since the spatial extent of IPS is essential for managing the invaded ecosystem, the current study aims at identifying and mapping the aggressive IPS of Acacia salicina and Acacia saligna, to understand better the key factors influencing their distribution in the coastal plain of Israel. This goal was achieved by integrating airborne-derived hyperspectral imaging and multispectral earth observation for creating species distribution maps. Hyperspectral data, in conjunction with high spatial resolution species distribution maps, were used to train the multispectral images at the species level. We incorporated a series of statistical models to classify the IPS location and to recognize their distribution and density. We took advantage of the phenological flowering stages of Acacia trees, as obtained by the multispectral images, for the support vector machine classification procedure. The classification yielded an overall Kappa coefficient accuracy of 0.89. We studied the effect of various environmental and human factors on IPS density by using a random forest machine learning model, to understand the mechanisms underlying successful invasions, and to assess where IPS have a higher likelihood of occurring. This algorithm revealed that the high density of Acacia most closely related to elevation, temperature pattern, and distances from rivers, settlements, and roads. Our results demonstrate how the integration of remote-sensing data with different data sources can assist in determining IPS proliferation and provide detailed geographic information for conservation and management efforts to prevent their future spread.
KW  - imaging spectroscopy
KW  - phenology
KW  - machine learning
KW  - biodiversity conservation
KW  - flowering detection
DO  - 10.3390/rs11080953
ER  -
TY  - EJOU
AU  - Chen, Jun
AU  - Xu, Quan
AU  - Luo, Linbo
AU  - Wang, Yongtao
AU  - Wang, Shuchun
TI  - A Robust Method for Automatic Panoramic UAV Image Mosaic
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 8
SN  - 1424-8220

AB  - This paper introduces a robust method for panoramic unmanned aerial vehicle (UAV) image mosaic. In the traditional automatic panoramic image stitching method (Autostitch), it assumes that the camera rotates about its optical centre and the group of transformations the source images may undergo is a special group of homographies. It is rare to get such ideal data in reality. In particular, remote sensing images obtained by UAV do not satisfy such an ideal situation, where the images may not be on a plane yet and even may suffer from nonrigid changes, leading to poor mosaic results. To overcome the above mentioned challenges, in this paper a nonrigid matching algorithm is introduced to the mosaic system to generate accurate feature matching on remote sensing images. We also propose a new strategy for bundle adjustment to make the mosaic system suitable for the UAV image panoramic mosaic effect. Experimental results show that our method outperforms the traditional method and some of the latest methods in terms of visual effect.
KW  - image mosaic
KW  - nonrigid deformation
KW  - bundle adjustment
KW  - feature matching
DO  - 10.3390/s19081898
ER  -
TY  - EJOU
AU  - Sławik, Łukasz
AU  - Niedzielko, Jan
AU  - Kania, Adam
AU  - Piórkowski, Hubert
AU  - Kopeć, Dominik
TI  - Multiple Flights or Single Flight Instrument Fusion of Hyperspectral and ALS Data? A Comparison of their Performance for Vegetation Mapping
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 8
SN  - 2072-4292

AB  - Fusion of remote sensing data often improves vegetation mapping, compared to using data from only a single source. The effectiveness of this fusion is subject to many factors, including the type of data, collection method, and purpose of the analysis. In this study, we compare the usefulness of hyperspectral (HS) and Airborne Laser System (ALS) data fusion acquired in separate flights, Multiple Flights Data Fusion (MFDF), and during a single flight through Instrument Fusion (IF) for the classification of non-forest vegetation. An area of 6.75 km2 was selected, where hyperspectral and ALS data was collected during two flights in 2015 and one flight in 2017. This data was used to classify three non-forest Natura 2000 habitats i.e., Xeric sand calcareous grasslands (code 6120), alluvial meadows of river valleys of the Cnidion dubii (code 6440), species-rich Nardus grasslands (code 6230) using a Random Forest classifier. Our findings show that it is not possible to determine which sensor, HS, or ALS used independently leads to a higher classification accuracy for investigated Natura 2000 habitats. Concurrently, increased stability and consistency of classification results was confirmed, regardless of the type of fusion used; IF, MFDF and varied information relevance of single sensor data. The research shows that the manner of data collection, using MFDF or IF, does not determine the level of relevance of ALS or HS data. The analysis of fusion effectiveness, gauged as the accuracy of the classification result and time consumed for data collection, has shown a superiority of IF over MFDF. IF delivered classification results that are more accurate compared to MFDF. IF is always cheaper than MFDF and the difference in effectiveness of both methods becomes more pronounced when the area of aerial data collection becomes larger.
KW  - data fusion
KW  - imaging spectroscopy
KW  - lidar
KW  - Random Forests
KW  - Natura 2000 habitats
KW  - effectiveness of data fusion
DO  - 10.3390/rs11080970
ER  -
TY  - EJOU
AU  - Pham, Tien D.
AU  - Xia, Junshi
AU  - Ha, Nam T.
AU  - Bui, Dieu T.
AU  - Le, Nga N.
AU  - Tekeuchi, Wataru
TI  - A Review of Remote Sensing Approaches for Monitoring Blue Carbon Ecosystems: Mangroves, Seagrassesand Salt Marshes during 2010–2018
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 8
SN  - 1424-8220

AB  - Blue carbon (BC) ecosystems are an important coastal resource, as they provide a range of goods and services to the environment. They play a vital role in the global carbon cycle by reducing greenhouse gas emissions and mitigating the impacts of climate change. However, there has been a large reduction in the global BC ecosystems due to their conversion to agriculture and aquaculture, overexploitation, and removal for human settlements. Effectively monitoring BC ecosystems at large scales remains a challenge owing to practical difficulties in monitoring and the time-consuming field measurement approaches used. As a result, sensible policies and actions for the sustainability and conservation of BC ecosystems can be hard to implement. In this context, remote sensing provides a useful tool for mapping and monitoring BC ecosystems faster and at larger scales. Numerous studies have been carried out on various sensors based on optical imagery, synthetic aperture radar (SAR), light detection and ranging (LiDAR), aerial photographs (APs), and multispectral data. Remote sensing-based approaches have been proven effective for mapping and monitoring BC ecosystems by a large number of studies. However, to the best of our knowledge, this is the first comprehensive review on the applications of remote sensing techniques for mapping and monitoring BC ecosystems. The main goal of this review is to provide an overview and summary of the key studies undertaken from 2010 onwards on remote sensing applications for mapping and monitoring BC ecosystems. Our review showed that optical imagery, such as multispectral and hyper-spectral data, is the most common for mapping BC ecosystems, while the Landsat time-series are the most widely-used data for monitoring their changes on larger scales. We investigate the limitations of current studies and suggest several key aspects for future applications of remote sensing combined with state-of-the-art machine learning techniques for mapping coastal vegetation and monitoring their extents and changes.
KW  - coastal ecosystems
KW  - remote sensing
KW  - blue carbon
KW  - mangroves
KW  - seagrasses
KW  - salt marshes
DO  - 10.3390/s19081933
ER  -
TY  - EJOU
AU  - Sun, Guibin
AU  - Zhou, Rui
AU  - Di, Bin
AU  - Dong, Zhuoning
AU  - Wang, Yingxun
TI  - A Novel Cooperative Path Planning for Multi-robot Persistent Coverage with Obstacles and Coverage Period Constraints
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 9
SN  - 1424-8220

AB  - In this paper, a multi-robot persistent coverage of the region of interest is considered, where persistent coverage and cooperative coverage are addressed simultaneously. Previous works have mainly concentrated on the paths that allow for repeated coverage, but ignored the coverage period requirements of each sub-region. In contrast, this paper presents a combinatorial approach for path planning, which aims to cover mission domains with different task periods while guaranteeing both obstacle avoidance and minimizing the number of robots used. The algorithm first deploys the sensors in the region to satisfy coverage requirements with minimum cost. Then it solves the travelling salesman problem to obtain the frame of the closed path. Finally, the approach partitions the closed path into the fewest segments under the coverage period constraints, and it generates the closed route for each robot on the basis of portioned segments of the closed path. Therefore, each robot can circumnavigate one closed route to cover the different task areas completely and persistently. The numerical simulations show that the proposed approach is feasible to implement the cooperative coverage in consideration of obstacles and coverage period constraints, and the number of robots used is also minimized.
KW  - multi-robot
KW  - cooperative coverage
KW  - persistent coverage
KW  - path planning
KW  - coverage period constraints
KW  - obstacle avoidance
DO  - 10.3390/s19091994
ER  -
TY  - EJOU
AU  - Li, Zhen
AU  - Zan, Qijie
AU  - Yang, Qiong
AU  - Zhu, Dehuang
AU  - Chen, Youjun
AU  - Yu, Shixiao
TI  - Remote Estimation of Mangrove Aboveground Carbon Stock at the Species Level Using a Low-Cost Unmanned Aerial Vehicle System
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 9
SN  - 2072-4292

AB  - There is ongoing interest in developing remote sensing technology to map and monitor the spatial distribution and carbon stock of mangrove forests. Previous research has demonstrated that the relationship between remote sensing derived parameters and aboveground carbon (AGC) stock varies for different species types. However, the coarse spatial resolution of satellite images has restricted the estimated AGC accuracy, especially at the individual species level. Recently, the availability of unmanned aerial vehicles (UAVs) has provided an operationally efficient approach to map the distribution of species and accurately estimate AGC stock at a fine scale in mangrove areas. In this study, we estimated mangrove AGC in the core area of northern Shenzhen Bay, South China, using four kinds of variables, including species type, canopy height metrics, vegetation indices, and texture features, derived from a low-cost UAV system. Three machine-learning algorithm models, including Random Forest (RF), Support Vector Regression (SVR), and Artificial Neural Network (ANN), were compared in this study, where a 10-fold cross-validation was used to evaluate each model&rsquo;s effectiveness. The results showed that a model that used all four type of variables, which were based on the RF algorithm, provided better AGC estimates (R2 = 0.81, relative RMSE (rRMSE) = 0.20, relative MAE (rMAE) = 0.14). The average predicted AGC from this model was 93.0 &plusmn; 24.3 Mg C ha&minus;1, and the total estimated AGC was 7903.2 Mg for the mangrove forests. The species-based model had better performance than the considered canopy-height-based model for AGC estimation, and mangrove species was the most important variable among all the considered input variables; the mean height (Hmean) the second most important variable. Additionally, the RF algorithms showed better performance in terms of mangrove AGC estimation than the SVR and ANN algorithms. Overall, a low-cost UAV system with a digital camera has the potential to enable satisfactory predictions of AGC in areas of homogenous mangrove forests.
KW  - mangrove forests
KW  - aboveground carbon stocks (AGC)
KW  - Unmanned Aerial Vehicles (UAV)
KW  - high spatial resolution orthoimages
KW  - species type
KW  - canopy height model (CHM)
DO  - 10.3390/rs11091018
ER  -
TY  - EJOU
AU  - Cinat, Paolo
AU  - Di Gennaro, Salvatore F.
AU  - Berton, Andrea
AU  - Matese, Alessandro
TI  - Comparison of Unsupervised Algorithms for Vineyard Canopy Segmentation from UAV Multispectral Images
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 9
SN  - 2072-4292

AB  - Technical resources are currently supporting and enhancing the ability of precision agriculture techniques in crop management. The accuracy of prescription maps is a key aspect to ensure a fast and targeted intervention. In this context, remote sensing acquisition by unmanned aerial vehicles (UAV) is one of the most advanced platforms to collect imagery of the field. Besides the imagery acquisition, canopy segmentation among soil, plants and shadows is another practical and technical aspect that must be fast and precise to ensure a targeted intervention. In this paper, algorithms to be applied to UAV imagery are proposed according to the sensor used that could either be visible spectral or multispectral. These algorithms, called HSV-based (Hue, Saturation, Value), DEM (Digital Elevation Model) and K-means, are unsupervised, i.e., they perform canopy segmentation without human support. They were tested and compared in three different scenarios obtained from two vineyards over two years, 2017 and 2018 for RGB (Red-Green-Blue) and NRG (Near Infrared-Red-Green) imagery. Particular attention is given to the unsupervised ability of these algorithms to identify vines in these different acquisition conditions. This ability is quantified by the introduction of over- and under- estimation indexes, which are the algorithm&rsquo;s ability to over-estimate or under-estimate vine canopies. For RGB imagery, the HSV-based algorithms consistently over-estimate vines, and never under-estimate them. The k-means and DEM method have a similar trend of under-estimation. While for NRG imagery, the HSV is the more stable algorithm and the DEM model slightly over-estimates the vines. HSV-based algorithms and the DEM algorithm have comparable computation time. The k-means algorithm increases computational demand as the quality of the DEM decreases. The algorithms developed can isolate canopy vegetation data, which is useful information about the current vineyard state, and can be used as a tool to be efficiently applied in the crop management procedure within precision viticulture applications.
KW  - UAV
KW  - vineyard segmentation
KW  - multispectral imagery
KW  - precision viticulture
DO  - 10.3390/rs11091023
ER  -
TY  - EJOU
AU  - Quirós Vargas, Juan J.
AU  - Zhang, Chongyuan
AU  - Smitchger, Jamin A.
AU  - McGee, Rebecca J.
AU  - Sankaran, Sindhuja
TI  - Phenotyping of Plant Biomass and Performance Traits Using Remote Sensing Techniques in Pea (Pisum sativum, L.)
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 9
SN  - 1424-8220

AB  - Field pea cultivars are constantly improved through breeding programs to enhance biotic and abiotic stress tolerance and increase seed yield potential. In pea breeding, the Above Ground Biomass (AGBM) is assessed due to its influence on seed yield, canopy closure, and weed suppression. It is also the primary yield component for peas used as a cover crop and/or grazing. Measuring AGBM is destructive and labor-intensive process. Sensor-based phenotyping of such traits can greatly enhance crop breeding efficiency. In this research, high resolution RGB and multispectral images acquired with unmanned aerial systems were used to assess phenotypes in spring and winter pea breeding plots. The Green Red Vegetation Index (GRVI), Normalized Difference Vegetation Index (NDVI), Normalized Difference Red Edge Index (NDRE), plot volume, canopy height, and canopy coverage were extracted from RGB and multispectral information at five imaging times (between 365 to 1948 accumulated degree days/ADD after 1 May) in four winter field pea experiments and at three imaging times (between 1231 to 1648 ADD) in one spring field pea experiment. The image features were compared to ground-truth data including AGBM, lodging, leaf type, days to 50% flowering, days to physiological maturity, number of the first reproductive node, and seed yield. In two of the winter pea experiments, a strong correlation between image features and seed yield was observed at 1268 ADD (flowering). An increase in correlation between image features with the phenological traits such as days to 50% flowering and days to physiological maturity was observed at about 1725 ADD in these winter pea experiments. In the spring pea experiment, the plot volume estimated from images was highly correlated with ground truth canopy height (r = 0.83) at 1231 ADD. In two other winter pea experiments and the spring pea experiment, the GRVI and NDVI features were significantly correlated with AGBM at flowering. When selected image features were used to develop a least absolute shrinkage and selection operator model for AGBM estimation, the correlation coefficient between the actual and predicted AGBM was 0.60 and 0.84 in the winter and spring pea experiments, respectively. A SPOT-6 satellite image (1.5 m resolution) was also evaluated for its applicability to assess biomass and seed yield. The image features extracted from satellite imagery showed significant correlation with seed yield in two winter field pea experiments, however, the trend was not consistent. In summary, the study supports the potential of using unmanned aerial system-based imaging techniques to estimate biomass and crop performance in pea breeding programs.
KW  - crop monitoring
KW  - prediction model
KW  - satellite imagery
KW  - vegetation indices
KW  - crop surface model
DO  - 10.3390/s19092031
ER  -
TY  - EJOU
AU  - Li, Weijia
AU  - He, Conghui
AU  - Fu, Haohuan
AU  - Zheng, Juepeng
AU  - Dong, Runmin
AU  - Xia, Maocai
AU  - Yu, Le
AU  - Luk, Wayne
TI  - A Real-Time Tree Crown Detection Approach for Large-Scale Remote Sensing Images on FPGAs
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 9
SN  - 2072-4292

AB  - The on-board real-time tree crown detection from high-resolution remote sensing images is beneficial for avoiding the delay between data acquisition and processing, reducing the quantity of data transmission from the satellite to the ground, monitoring the growing condition of individual trees, and discovering the damage of trees as early as possible, etc. Existing high performance platform based tree crown detection studies either focus on processing images in a small size or suffer from high power consumption or slow processing speed. In this paper, we propose the first FPGA-based real-time tree crown detection approach for large-scale satellite images. A pipelined-friendly and resource-economic tree crown detection algorithm (PF-TCD) is designed through reconstructing and modifying the workflow of the original algorithm into three computational kernels on FPGAs. Compared with the well-optimized software implementation of the original algorithm on an Intel 12-core CPU, our proposed PF-TCD obtains the speedup of 18.75 times for a satellite image with a size of 12,188 &times; 12,576 pixels without reducing the detection accuracy. The image processing time for the large-scale remote sensing image is only 0.33 s, which satisfies the requirements of the on-board real-time data processing on satellites.
KW  - tree crown detection
KW  - high-resolution satellite images
KW  - field-programmable gate array (FPGA)
KW  - real-time processing
DO  - 10.3390/rs11091025
ER  -
TY  - EJOU
AU  - Tyralis, Hristos
AU  - Papacharalampous, Georgia
AU  - Langousis, Andreas
TI  - A Brief Review of Random Forests for Water Scientists and Practitioners and Their Recent History in Water Resources
T2  - Water

PY  - 2019
VL  - 11
IS  - 5
SN  - 2073-4441

AB  - Random forests (RF) is a supervised machine learning algorithm, which has recently started to gain prominence in water resources applications. However, existing applications are generally restricted to the implementation of Breiman&rsquo;s original algorithm for regression and classification problems, while numerous developments could be also useful in solving diverse practical problems in the water sector. Here we popularize RF and their variants for the practicing water scientist, and discuss related concepts and techniques, which have received less attention from the water science and hydrologic communities. In doing so, we review RF applications in water resources, highlight the potential of the original algorithm and its variants, and assess the degree of RF exploitation in a diverse range of applications. Relevant implementations of random forests, as well as related concepts and techniques in the R programming language, are also covered.
KW  - classification
KW  - data-driven
KW  - hydrological modeling
KW  - hydrology
KW  - machine learning
KW  - prediction
KW  - quantile regression forests
KW  - supervised learning
KW  - variable importance metrics
DO  - 10.3390/w11050910
ER  -
TY  - EJOU
AU  - Luo, Yiran
AU  - Li, Jian
AU  - Yu, Chunyang
AU  - Xu, Bing
AU  - Li, You
AU  - Hsu, Li-Ta
AU  - El-Sheimy, Naser
TI  - Research on Time-Correlated Errors Using Allan Variance in a Kalman Filter Applicable to Vector-Tracking-Based GNSS Software-Defined Receiver for Autonomous Ground Vehicle Navigation
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 9
SN  - 2072-4292

AB  - The global navigation satellite system (GNSS) has been applied to many areas, e.g., the autonomous ground vehicle, unmanned aerial vehicle (UAV), precision agriculture, smart city, and the GNSS-reflectometry (GNSS-R), being of considerable significance over the past few decades. Unfortunately, the GNSS signal performance has the high risk of being reduced by the environmental interference. The vector tracking (VT) technique is promising to enhance the robustness in high dynamics as well as improve the sensitivity against the weak environment of the GNSS receiver. However, the time-correlated error coupled in the receiver clock estimations in terms of the VT loop can decrease the accuracy of the navigation solution. There are few works present dealing with this issue. In this work, the Allan variance is accordingly exploited to specify a model which is expected to account for this type of error based on the 1st-order Gauss-Markov (GM) process. Then, it is used for proposing an enhanced Kalman filter (KF) by which this error can be suppressed. Furthermore, the proposed system model makes use of the innovation sequence so that the process covariance matrix can be adaptively adjusted and updated. The field tests demonstrate the performance of the proposed adaptive vector-tracking time-correlated error suppressed Kalman filter (A-VTTCES-KF). When compared with the results produced by the ordinary adaptive KF algorithm in terms of the VT loop, the real-time kinematic (RTK) positioning and code-based differential global positioning system (DGPS) positioning accuracies have been improved by 14.17% and 9.73%, respectively. On the other hand, the RTK positioning performance has been increased by maximum 21.40% when compared with the results obtained from the commercial low-cost U-Blox receiver.
KW  - global navigation satellite system (GNSS)
KW  - software-defined receiver (SDR)
KW  - vector tracking (VT)
KW  - Kalman filter (KF)
KW  - Allan variance
KW  - time-correlated error
KW  - Gauss-Markov (GM) process
KW  - innovation sequence
KW  - RTKLIB
DO  - 10.3390/rs11091026
ER  -
TY  - EJOU
AU  - Dorafshan, Sattar
AU  - Thomas, Robert J.
AU  - Maguire, Marc
TI  - Benchmarking Image Processing Algorithms for Unmanned Aerial System-Assisted Crack Detection in Concrete Structures
T2  - Infrastructures

PY  - 2019
VL  - 4
IS  - 2
SN  - 2412-3811

AB  - This paper summarizes the results of traditional image processing algorithms for detection of defects in concrete using images taken by Unmanned Aerial Systems (UASs). Such algorithms are useful for improving the accuracy of crack detection during autonomous inspection of bridges and other structures, and they have yet to be compared and evaluated on a dataset of concrete images taken by UAS. The authors created a generic image processing algorithm for crack detection, which included the major steps of filter design, edge detection, image enhancement, and segmentation, designed to uniformly compare different edge detectors. Edge detection was carried out by six filters in the spatial (Roberts, Prewitt, Sobel, and Laplacian of Gaussian) and frequency (Butterworth and Gaussian) domains. These algorithms were applied to fifty images each of defected and sound concrete. Performances of the six filters were compared in terms of accuracy, precision, minimum detectable crack width, computational time, and noise-to-signal ratio. In general, frequency domain techniques were slower than spatial domain methods because of the computational intensity of the Fourier and inverse Fourier transformations used to move between spatial and frequency domains. Frequency domain methods also produced noisier images than spatial domain methods. Crack detection in the spatial domain using the Laplacian of Gaussian filter proved to be the fastest, most accurate, and most precise method, and it resulted in the finest detectable crack width. The Laplacian of Gaussian filter in spatial domain is recommended for future applications of real-time crack detection using UAS.
KW  - structural condition assessment
KW  - concrete structures
KW  - unmanned aerial systems
KW  - crack detection
KW  - image processing
KW  - noncontact methods
DO  - 10.3390/infrastructures4020019
ER  -
TY  - EJOU
AU  - He, Haiqing
AU  - Zhou, Junchao
AU  - Chen, Min
AU  - Chen, Ting
AU  - Li, Dajun
AU  - Cheng, Penggen
TI  - Building Extraction from UAV Images Jointly Using 6D-SLIC and Multiscale Siamese Convolutional Networks
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 9
SN  - 2072-4292

AB  - Automatic building extraction using a single data type, either 2D remotely-sensed images or light detection and ranging 3D point clouds, remains insufficient to accurately delineate building outlines for automatic mapping, despite active research in this area and the significant progress which has been achieved in the past decade. This paper presents an effective approach to extracting buildings from Unmanned Aerial Vehicle (UAV) images through the incorporation of superpixel segmentation and semantic recognition. A framework for building extraction is constructed by jointly using an improved Simple Linear Iterative Clustering (SLIC) algorithm and Multiscale Siamese Convolutional Networks (MSCNs). The SLIC algorithm, improved by additionally imposing a digital surface model for superpixel segmentation, namely 6D-SLIC, is suited for building boundary detection under building and image backgrounds with similar radiometric signatures. The proposed MSCNs, including a feature learning network and a binary decision network, are used to automatically learn a multiscale hierarchical feature representation and detect building objects under various complex backgrounds. In addition, a gamma-transform green leaf index is proposed to truncate vegetation superpixels for further processing to improve the robustness and efficiency of building detection, the Douglas&ndash;Peucker algorithm and iterative optimization are used to eliminate jagged details generated from small structures as a result of superpixel segmentation. In the experiments, the UAV datasets, including many buildings in urban and rural areas with irregular shapes and different heights and that are obscured by trees, are collected to evaluate the proposed method. The experimental results based on the qualitative and quantitative measures confirm the effectiveness and high accuracy of the proposed framework relative to the digitized results. The proposed framework performs better than state-of-the-art building extraction methods, given its higher values of recall, precision, and intersection over Union (IoU).
KW  - building extraction
KW  - simple linear iterative clustering (SLIC)
KW  - multiscale Siamese convolutional networks (MSCNs)
KW  - binary decision network
KW  - unmanned aerial vehicle (UAV)
DO  - 10.3390/rs11091040
ER  -
TY  - EJOU
AU  - Hakdaoui, Sofia
AU  - Emran, Anas
AU  - Pradhan, Biswajeet
AU  - Lee, Chang-Wook
AU  - Nguemhe Fils, Salomon C.
TI  - A Collaborative Change Detection Approach on Multi-Sensor Spatial Imagery for Desert Wetland Monitoring after a Flash Flood in Southern Morocco
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 9
SN  - 2072-4292

AB  - This study aims to present a technique that combines multi-sensor spatial data to monitor wetland areas after a flash-flood event in a Saharan arid region. To extract the most efficient information, seven satellite images (radar and optical) taken before and after the event were used. To achieve the objectives, this study used Sentinel-1 data to discriminate water body and soil roughness, and optical data to monitor the soil moisture after the event. The proposed method combines two approaches: one based on spectral processing, and the other based on categorical processing. The first step was to extract four spectral indices and utilize change vector analysis on multispectral diachronic images from three MSI Sentinel-2 images and two Landsat-8 OLI images acquired before and after the event. The second step was performed using pattern classification techniques, namely, linear classifiers based on support vector machines (SVM) with Gaussian kernels. The results of these two approaches were fused to generate a collaborative wetland change map. The application of co-registration and supervised classification based on textural and intensity information from Radar Sentinel-1 images taken before and after the event completes this work. The results obtained demonstrate the importance of the complementarity of multi-sensor images and a multi-approach methodology to better monitor changes to a wetland area after a flash-flood disaster.
KW  - categorical processing
KW  - collaborative change detection
KW  - remote sensing
KW  - GIS
KW  - wet land monitoring
KW  - Morocco
DO  - 10.3390/rs11091042
ER  -
TY  - EJOU
AU  - Li, Zhiwei
AU  - Lu, Yu
AU  - Shi, Yun
AU  - Wang, Zengguang
AU  - Qiao, Wenxin
AU  - Liu, Yicen
TI  - A Dyna-Q-Based Solution for UAV Networks Against Smart Jamming Attacks
T2  - Symmetry

PY  - 2019
VL  - 11
IS  - 5
SN  - 2073-8994

AB  - Unmanned aerial vehicle (UAV) networks have a wide range of applications, such as in the Internet of Things (IoT), 5G communications, and so forth. However, the communications between UAVs and UAVs to ground control stations mainly use radio channels, and therefore these communications are vulnerable to cyberattacks. With the advent of software-defined radio (SDR), smart attacks that can flexibly select attack strategies according to the defender&rsquo;s state information are gradually attracting the attention of researchers and potential attackers of UAV networks. The smart attack can even induce the defender to take a specific defense strategy, causing even greater damage. Inspired by symmetrical thinking, a solution using a software-defined network (SDN) to combat software-defined radio was proposed. We propose a network architecture which uses dual controllers, including a UAV flight controller and SDN controller, to achieve collaborative decision-making. Built on the top of the SDN, the state information of the whole network converges quickly and is fitted to an environment model used to develop an improved Dyna-Q-based reinforcement learning algorithm. The improved algorithm integrates the power allocation and track planning of UAVs into a unified action space. The simulation data showed that the proposed communication solution can effectively avoid smart jamming attacks and has faster learning efficiency and higher convergence performance than the compared algorithms.
KW  - UAV networks
KW  - SDN
KW  - reinforcement learning
KW  - Dyna-Q
KW  - IoT
KW  - cyberattacks
DO  - 10.3390/sym11050617
ER  -
TY  - EJOU
AU  - Marino, Stefano
AU  - Alvino, Arturo
TI  - Detection of Spatial and Temporal Variability of Wheat Cultivars by High-Resolution Vegetation Indices
T2  - Agronomy

PY  - 2019
VL  - 9
IS  - 5
SN  - 2073-4395

AB  - An on-farm research study was carried out on two small-plots cultivated with two cultivars of durum wheat (Odisseo and Ariosto). The paper presents a theoretical approach for investigating frequency vegetation indices (VIs) in different areas of the experimental plot for early detection of agronomic spatial variability. Four flights were carried out with an unmanned aerial vehicle (UAV) to calculate high-resolution normalized difference vegetation index (NDVI) and optimized soil-adjusted vegetation index (OSAVI) images. Ground agronomic data (biomass, leaf area index (LAI), spikes, plant height, and yield) have been linked to the vegetation indices (VIs) at different growth stages. Regression coefficients of all samplings data were highly significant for both the cultivars and VIs at anthesis and tillering stage. At harvest, the whole plot (W) data were analyzed and compared with two sub-areas characterized by high agronomic performance (H) yield 20% higher than the whole plot, and low performances (L), about 20% lower of yield related to the whole plot). The whole plot and two sub-areas were analyzed backward in time comparing the VIs frequency curves. At anthesis, more than 75% of the surface of H sub-areas showed a VIs value higher than the L sub-plot. The differences were evident also at the tillering and seedling stages, when the 75% (third percentile) of VIs H data was over the 50% (second percentile) of the W curve and over the 25% (first percentile) of L sub-plot. The use of high-resolution images for analyzing the frequency value of VIs in different areas can be a useful approach for the detection of agronomic constraints for precision agriculture purposes.
KW  - UAV
KW  - vegetation indices
KW  - relative frequencies
KW  - yield
KW  - precision agriculture
KW  - cultivars
DO  - 10.3390/agronomy9050226
ER  -
TY  - EJOU
AU  - Desnitsky, Vasily
AU  - Kotenko, Igor
AU  - Zakoldaev, Danil
TI  - Evaluation of Resource Exhaustion Attacks against Wireless Mobile Devices
T2  - Electronics

PY  - 2019
VL  - 8
IS  - 5
SN  - 2079-9292

AB  - Currently, energy resource exhaustion attacks targeted on modern autonomously working mobile devices are becoming more and more important. The underdevelopment of specialized defenses against energy exhaustion attacks as well as their often hidden nature for the owner of the target device determine a necessity of an integrated approach to modeling and evaluation of this class of attacks and various types of intruders. The paper analyzes conditions of applicability of energy resource exhaustion attacks performed by various classes of intruders, models them on physical implementations of devices for two application areas, and calculates their performance indicators. Application areas are a TCP/IP network of end-user mobile devices and a self-organizing mesh network designed for operational management and emergency response.
KW  - cyber-physical security
KW  - energy exhaustion attacks
KW  - denial-of-sleep
KW  - modeling and simulation
DO  - 10.3390/electronics8050500
ER  -
TY  - EJOU
AU  - Chen, Shih-Yu
AU  - Lin, Chinsu
AU  - Chuang, Shang-Ju
AU  - Kao, Zhe-Yuan
TI  - Weighted Background Suppression Target Detection Using Sparse Image Enhancement Technique for Newly Grown Tree Leaves
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 9
SN  - 2072-4292

AB  - The process from leaf sprouting to senescence is a phenological response, which is caused by the effect of temperature and moisture on the physiological response during the life cycle of trees. Therefore, detecting newly grown leaves could be useful for studying tree growth or even climate change. This study applied several target detection techniques to observe the growth of leaves in unmanned aerial vehicle (UAV) multispectral images. The weighted background suppression (WBS) method was proposed in this paper to reduce the interference of the target of interest through a weighted correlation/covariance matrix. This novel technique could strengthen targets and suppress the background. This study also developed the sparse enhancement (SE) method for newly grown leaves (NGL), as sparsity has features similar to newly grown leaves. The experimental results suggested that using SE-WBS based algorithms could improve the detection performance of NGL for most detectors. For the global target detection methods, the SE-WBS version of adaptive coherence estimator (SE-WBS-ACE) refines the area under the receiver operating characteristic curve (AUC) from 0.9417 to 0.9658 and kappa from 0.3389 to 0.4484. The SE-WBS version of target constrained interference minimized filter (SE-WBS-TCIMF) increased AUC from 0.9573 to 0.9708 and kappa from 0.3472 to 0.4417; the SE-WBS version of constrained energy minimization (SE-WBS-CEM) boosted AUC from 0.9606 to 0.9713 and kappa from 0.3604 to 0.4483. For local target detection methods, the SE-WBS version of adaptive sliding window CEM (ASW SE-WBS-CEM) enhanced AUC from 0.9704 to 0.9796 and kappa from 0.4526 to 0.5121, which outperforms other methods.
KW  - Target detection
KW  - sprout detection
KW  - constrained energy minimization
KW  - newly grown tree leaves
KW  - weighted background suppression
DO  - 10.3390/rs11091081
ER  -
TY  - EJOU
AU  - Krenz, Juliane
AU  - Greenwood, Philip
AU  - Kuhn, Nikolaus J.
TI  - Soil Degradation Mapping in Drylands Using Unmanned Aerial Vehicle (UAV) Data
T2  - Soil Systems

PY  - 2019
VL  - 3
IS  - 2
SN  - 2571-8789

AB  - Arid and semi-arid landscapes often show a patchwork of bare and vegetated spaces. Their heterogeneous patterns can be of natural origin, but may also indicate soil degradation. This study investigates the use of unmanned aerial vehicle (UAV) imagery to identify the degradation status of soils, based on the hypothesis that vegetation cover can be used as a proxy for estimating the soils&rsquo; health status. To assess the quality of the UAV-derived products, we compare a conventional field-derived map (FM) with two modelled maps based on (i) vegetation cover (RGB map), and (ii) vegetation cover, topographic information, and a flow accumulation analysis (RGB+DEM map). All methods were able to identify areas of soil degradation but differed in the extent of classified soil degradation, with the RGB map classifying the least amount as degraded. The RGB+DEM map classified 12% more as degraded than the FM, due to the wider perspective of the UAV compared to conventional field mapping. Overall, conventional UAVs provide a valuable tool for soil mapping in heterogeneous landscapes where manual field sampling is very time consuming. Additionally, the UAVs&rsquo; planform view from a bird&rsquo;s-eye perspective can overcome the limited view from the surveyors&rsquo; (ground-based) vantage point.
KW  - erosion
KW  - landscape mapping
KW  - soil degradation
KW  - soil mapping
KW  - unmanned aerial vehicle (UAV)
DO  - 10.3390/soilsystems3020033
ER  -
TY  - EJOU
AU  - Ma, Xiaodan
AU  - Zhu, Kexin
AU  - Guan, Haiou
AU  - Feng, Jiarui
AU  - Yu, Song
AU  - Liu, Gang
TI  - High-Throughput Phenotyping Analysis of Potted Soybean Plants Using Colorized Depth Images Based on A Proximal Platform
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 9
SN  - 2072-4292

AB  - Canopy color and structure can strongly reflect plant functions. Color characteristics and plant height as well as canopy breadth are important aspects of the canopy phenotype of soybean plants. High-throughput phenotyping systems with imaging capabilities providing color and depth information can rapidly acquire data of soybean plants, making it possible to quantify and monitor soybean canopy development. The goal of this study was to develop a 3D imaging approach to quantitatively analyze soybean canopy development under natural light conditions. Thus, a Kinect sensor-based high-throughput phenotyping (HTP) platform was developed for soybean plant phenotyping. To calculate color traits accurately, the distortion phenomenon of color images was first registered in accordance with the principle of three primary colors and color constancy. Then, the registered color images were applied to depth images for the reconstruction of the colorized three-dimensional canopy structure. Furthermore, the 3D point cloud of soybean canopies was extracted from the background according to adjusted threshold, and each area of individual potted soybean plants in the depth images was segmented for the calculation of phenotypic traits. Finally, color indices, plant height and canopy breadth were assessed based on 3D point cloud of soybean canopies. The results showed that the maximum error of registration for the R, G, and B bands in the dataset was 1.26%, 1.09%, and 0.75%, respectively. Correlation analysis between the sensors and manual measurements yielded R2 values of 0.99, 0.89, and 0.89 for plant height, canopy breadth in the west-east (W&ndash;E) direction, and canopy breadth in the north-south (N&ndash;S) direction, and R2 values of 0.82, 0.79, and 0.80 for color indices h, s, and i, respectively. Given these results, the proposed approaches provide new opportunities for the identification of the quantitative traits that control canopy structure in genetic/genomic studies or for soybean yield prediction in breeding programs.
KW  - soybean
KW  - plant height
KW  - canopy breadth
KW  - color indices
KW  - high-throughput
KW  - Kinect sensor
DO  - 10.3390/rs11091085
ER  -
TY  - EJOU
AU  - Casari, Raphael A. C. N.
AU  - Paiva, Dayane S.
AU  - Silva, Vivianny N. B.
AU  - Ferreira, Thalita M. M.
AU  - Souza, Junior, Manoel T.
AU  - Oliveira, Nelson G.
AU  - Kobayashi, Adilson K.
AU  - Molinari, Hugo B. C.
AU  - Santos, Thiago T.
AU  - Gomide, Reinaldo L.
AU  - Magalhães, Paulo C.
AU  - Sousa, Carlos A. F.
TI  - Using Thermography to Confirm Genotypic Variation for Drought Response in Maize
T2  - International Journal of Molecular Sciences

PY  - 2019
VL  - 20
IS  - 9
SN  - 1422-0067

AB  - The feasibility of thermography as a technique for plant screening aiming at drought-tolerance has been proven by its relationship with gas exchange, biomass, and yield. In this study, unlike most of the previous, thermography was applied for phenotyping contrasting maize genotypes whose classification for drought tolerance had already been established in the field. Our objective was to determine whether thermography-based classification would discriminate the maize genotypes in a similar way as the field selection in which just grain yield was taken into account as a criterion. We evaluated gas exchange, daily water consumption, leaf relative water content, aboveground biomass, and grain yield. Indeed, the screening of maize genotypes based on canopy temperature showed similar results to traditional methods. Nevertheless, canopy temperature only partially reflected gas exchange rates and daily water consumption in plants under drought. Part of the explanation may lie in the changes that drought had caused in plant leaves and canopy structure, altering absorption and dissipation of energy, photosynthesis, transpiration, and partitioning rates. Accordingly, although there was a negative relationship between grain yield and plant canopy temperature, it does not necessarily mean that plants whose canopies were maintained cooler under drought achieved the highest yield.
KW  - abiotic stress
KW  - canopy temperature
KW  - plant phenotyping
KW  - thermal image
KW  - water deficit
KW  - Zea mays
DO  - 10.3390/ijms20092273
ER  -
TY  - EJOU
AU  - Zhang, Chuang
AU  - Zhao, Xiubin
AU  - Pang, Chunlei
AU  - Zhang, Liang
AU  - Feng, Bo
TI  - The Influence of Satellite Configuration and Fault Duration Time on the Performance of Fault Detection in GNSS/INS Integration
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 9
SN  - 1424-8220

AB  - For the integration of global navigation satellite system (GNSS) and inertial navigation system (INS), real-time and accurate fault detection is essential to enhance the reliability and precision of the system. Among the existing methods, the residual chi-square detection is still widely used due to its good real-time performance and sensibility of fault detection. However, further investigation on the performance of fault detection for different observational conditions and fault models is still required. In this paper, the principle of chi-square detection based on the predicted residual and least-squares residual is analyzed and the equivalence between them is deduced. Then, choosing the chi-square detection based on the predicted residual as the research object, the influence of satellite configuration and fault duration time on the performance of fault detection is analyzed in theory. The influence of satellite configuration is analyzed from the number and geometry of visible satellites. Several numerical simulations are conducted to verify the theoretical analysis. The results show that, for a single-epoch fault, the location of faulty measurement and the geometry have little effect on the performance of fault detection, while the number of visible satellites has greater influence on the fault detection performance than the geometry. For a continuous fault, the fault detection performance will decrease with the increase of fault duration time when the value of the fault is near the minimal detectable bias (MDB), and faults occurring on different satellite&rsquo;s measurement will result in different detection results.
KW  - GNSS/INS integration
KW  - fault detection
KW  - chi-square test
KW  - satellite configuration
KW  - fault duration time
DO  - 10.3390/s19092147
ER  -
TY  - EJOU
AU  - Wei, Lifei
AU  - Yuan, Ziran
AU  - Zhong, Yanfei
AU  - Yang, Lanfang
AU  - Hu, Xin
AU  - Zhang, Yangxi
TI  - An Improved Gradient Boosting Regression Tree Estimation Model for Soil Heavy Metal (Arsenic) Pollution Monitoring Using Hyperspectral Remote Sensing
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 9
SN  - 2076-3417

AB  - Hyperspectral remote sensing can be used to effectively identify contaminated elements in soil. However, in the field of monitoring soil heavy metal pollution, hyperspectral remote sensing has the characteristics of high dimensionality and high redundancy, which seriously affect the accuracy and stability of hyperspectral inversion models. To resolve the problem, a gradient boosting regression tree (GBRT) hyperspectral inversion algorithm for heavy metal (Arsenic (As)) content in soils based on Spearman&rsquo;s rank correlation analysis (SCA) coupled with competitive adaptive reweighted sampling (CARS) is proposed in this paper. Firstly, the CARS algorithm is used to roughly select the original spectral data. Second derivative (SD), Gaussian filtering (GF), and min-max normalization (MMN) pretreatments are then used to improve the correlation between the spectra and As in the characteristic band enhancement stage. Finally, the low-correlation bands are removed using the SCA method, and a subset with absolute correlation values greater than 0.6 is retained as the optimal band subset after each pretreatment. For the modeling, the five most representative characteristic bands were selected in the Honghu area of China, and the nine most representative characteristic bands were selected in the Daye area of China. In order to verify the generalization ability of the proposed algorithm, 92 soil samples from the Honghu and Daye areas were selected as the research objects. With the use of support vector machine regression (SVMR), linear regression (LR), and random forest (RF) regression methods as comparative methods, all the models obtained a good prediction accuracy. However, among the different combinations, CARS-SCA-GBRT obtained the highest precision, which indicates that the proposed algorithm can select fewer characteristic bands to achieve a better inversion effect, and can thus provide accurate data support for the treatment and recovery of heavy metal pollution in soils.
KW  - soil heavy metal pollution
KW  - competitive adaptive reweighted sampling
KW  - gradient boosting regression tree
KW  - characteristic bands
DO  - 10.3390/app9091943
ER  -
TY  - EJOU
AU  - Petrellis, Nikos
TI  - Plant Disease Diagnosis for Smart Phone Applications with Extensible Set of Diseases
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 9
SN  - 2076-3417

AB  - A plant disease diagnosis method that can be implemented with the resources of a mobile phone application, that does not have to be connected to a remote server, is presented and evaluated on citrus diseases. It can be used both by amateur gardeners and by professional agriculturists for early detection of diseases. The features used are extracted from photographs of plant parts like leaves or fruits and include the color, the relative area and the number of the lesion spots. These classification features, along with additional information like weather metadata, form disease signatures that can be easily defined by the end user (e.g., an agronomist). These signatures are based on the statistical processing of a small number of representative training photographs. The extracted features of a test photograph are compared against the disease signatures in order to select the most likely disease. An important advantage of the proposed approach is that the diagnosis does not depend on the orientation, the scale or the resolution of the photograph. The experiments have been conducted under several light exposure conditions. The accuracy was experimentally measured between 70% and 99%. An acceptable accuracy higher than 90% can be achieved in most of the cases since the lesion spots can recognized interactively with high precision.
KW  - plant disease
KW  - smart phone application
KW  - image processing
KW  - classification
KW  - segmentation
KW  - citrus diseases
DO  - 10.3390/app9091952
ER  -
TY  - EJOU
AU  - Zhou, Ying
AU  - Tang, Yongchuan
AU  - Zhao, Xiaozhe
TI  - A Novel Uncertainty Management Approach for Air Combat Situation Assessment Based on Improved Belief Entropy
T2  - Entropy

PY  - 2019
VL  - 21
IS  - 5
SN  - 1099-4300

AB  - Uncertain information exists in each procedure of an air combat situation assessment. To address this issue, this paper proposes an improved method to address the uncertain information fusion of air combat situation assessment in the Dempster&ndash;Shafer evidence theory (DST) framework. A better fusion result regarding the prediction of military intention can be helpful for decision-making in an air combat situation. To obtain a more accurate fusion result of situation assessment, an improved belief entropy (IBE) is applied to preprocess the uncertainty of situation assessment information. Data fusion of assessment information after preprocessing will be based on the classical Dempster&rsquo;s rule of combination. The illustrative example result validates the rationality and the effectiveness of the proposed method.
KW  - Dempster–Shafer evidence theory (DST)
KW  - air combat situation assessment
KW  - belief entropy
KW  - uncertainty management
KW  - uncertainty measure
DO  - 10.3390/e21050495
ER  -
TY  - EJOU
AU  - Bejiga, Mesay B.
AU  - Melgani, Farid
AU  - Beraldini, Pietro
TI  - Domain Adversarial Neural Networks for Large-Scale Land Cover Classification
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 10
SN  - 2072-4292

AB  - Learning classification models require sufficiently labeled training samples, however, collecting labeled samples for every new problem is time-consuming and costly. An alternative approach is to transfer knowledge from one problem to another, which is called transfer learning. Domain adaptation (DA) is a type of transfer learning that aims to find a new latent space where the domain discrepancy between the source and the target domain is negligible. In this work, we propose an unsupervised DA technique called domain adversarial neural networks (DANNs), composed of a feature extractor, a class predictor, and domain classifier blocks, for large-scale land cover classification. Contrary to the traditional methods that perform representation and classifier learning in separate stages, DANNs combine them into a single stage, thereby learning a new representation of the input data that is both domain-invariant and discriminative. Once trained, the classifier of a DANN can be used to predict both source and target domain labels. Additionally, we also modify the domain classifier of a DANN to evaluate its suitability for multi-target domain adaptation problems. Experimental results obtained for both single and multiple target DA problems show that the proposed method provides a performance gain of up to 40%.
KW  - domain adaptation
KW  - domain adversarial neural networks
KW  - large-scale land cover classification
KW  - representation learning
DO  - 10.3390/rs11101153
ER  -
TY  - EJOU
AU  - Fuentes-Pacheco, Jorge
AU  - Torres-Olivares, Juan
AU  - Roman-Rangel, Edgar
AU  - Cervantes, Salvador
AU  - Juarez-Lopez, Porfirio
AU  - Hermosillo-Valadez, Jorge
AU  - Rendón-Mancha, Juan Manuel
TI  - Fig Plant Segmentation from Aerial Images Using a Deep Convolutional Encoder-Decoder Network
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 10
SN  - 2072-4292

AB  - Crop segmentation is an important task in Precision Agriculture, where the use of aerial robots with an on-board camera has contributed to the development of new solution alternatives. We address the problem of fig plant segmentation in top-view RGB (Red-Green-Blue) images of a crop grown under open-field difficult circumstances of complex lighting conditions and non-ideal crop maintenance practices defined by local farmers. We present a Convolutional Neural Network (CNN) with an encoder-decoder architecture that classifies each pixel as crop or non-crop using only raw colour images as input. Our approach achieves a mean accuracy of 93.85% despite the complexity of the background and a highly variable visual appearance of the leaves. We make available our CNN code to the research community, as well as the aerial image data set and a hand-made ground truth segmentation with pixel precision to facilitate the comparison among different algorithms.
KW  - convolutional neural network
KW  - crop segmentation
KW  - Ficus carica
KW  - unmanned aerial vehicles
DO  - 10.3390/rs11101157
ER  -
TY  - EJOU
AU  - Han, Jiaming
AU  - Yang, Zhong
AU  - Zhang, Qiuyan
AU  - Chen, Cong
AU  - Li, Hongchen
AU  - Lai, Shangxiang
AU  - Hu, Guoxiong
AU  - Xu, Changliang
AU  - Xu, Hao
AU  - Wang, Di
AU  - Chen, Rui
TI  - A Method of Insulator Faults Detection in Aerial Images for High-Voltage Transmission Lines Inspection
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 10
SN  - 2076-3417

AB  - Insulator faults detection is an important task for high-voltage transmission line inspection. However, current methods often suffer from the lack of accuracy and robustness. Moreover, these methods can only detect one fault in the insulator string, but cannot detect a multi-fault. In this paper, a novel method is proposed for insulator one fault and multi-fault detection in UAV-based aerial images, the backgrounds of which usually contain much complex interference. The shapes of the insulators also vary obviously due to the changes in filming angle and distance. To reduce the impact of complex interference on insulator faults detection, we make full use of the deep neural network to distinguish between insulators and background interference. First of all, plenty of insulator aerial images with manually labelled ground-truth are collected to construct a standard insulator detection dataset &lsquo;InST_detection&rsquo;. Secondly, a new convolutional network is proposed to obtain accurate insulator string positions in the aerial image. Finally, a novel fault detection method is proposed that can detect both insulator one fault and multi-fault in aerial images. Experimental results on a large number of aerial images show that our proposed method is more effective and efficient than the state-of-the-art insulator fault detection methods.
KW  - unmanned aerial vehicle
KW  - high-voltage transmission line inspection
KW  - aerial image
KW  - insulator fault detection
DO  - 10.3390/app9102009
ER  -
TY  - EJOU
AU  - Buters, Todd M.
AU  - Bateman, Philip W.
AU  - Robinson, Todd
AU  - Belton, David
AU  - Dixon, Kingsley W.
AU  - Cross, Adam T.
TI  - Methodological Ambiguity and Inconsistency Constrain Unmanned Aerial Vehicles as A Silver Bullet for Monitoring Ecological Restoration
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 10
SN  - 2072-4292

AB  - The last decade has seen an exponential increase in the application of unmanned aerial vehicles (UAVs) to ecological monitoring research, though with little standardisation or comparability in methodological approaches and research aims. We reviewed the international peer-reviewed literature in order to explore the potential limitations on the feasibility of UAV-use in the monitoring of ecological restoration, and examined how they might be mitigated to maximise the quality, reliability and comparability of UAV-generated data. We found little evidence of translational research applying UAV-based approaches to ecological restoration, with less than 7% of 2133 published UAV monitoring studies centred around ecological restoration. Of the 48 studies, &gt; 65% had been published in the three years preceding this study. Where studies utilised UAVs for rehabilitation or restoration applications, there was a strong propensity for single-sensor monitoring using commercially available RPAs fitted with the modest-resolution RGB sensors available. There was a strong positive correlation between the use of complex and expensive sensors (e.g., LiDAR, thermal cameras, hyperspectral sensors) and the complexity of chosen image classification techniques (e.g., machine learning), suggesting that cost remains a primary constraint to the wide application of multiple or complex sensors in UAV-based research. We propose that if UAV-acquired data are to represent the future of ecological monitoring, research requires a) consistency in the proven application of different platforms and sensors to the monitoring of target landforms, organisms and ecosystems, underpinned by clearly articulated monitoring goals and outcomes; b) optimization of data analysis techniques and the manner in which data are reported, undertaken in cross-disciplinary partnership with fields such as bioinformatics and machine learning; and c) the development of sound, reasonable and multi-laterally homogenous regulatory and policy framework supporting the application of UAVs to the large-scale and potentially trans-disciplinary ecological applications of the future.
KW  - ecological restoration
KW  - drone
KW  - UAS
KW  - rehabilitation
KW  - revegetation
DO  - 10.3390/rs11101180
ER  -
TY  - EJOU
AU  - Mao, Dehua
AU  - Liu, Mingyue
AU  - Wang, Zongming
AU  - Li, Lin
AU  - Man, Weidong
AU  - Jia, Mingming
AU  - Zhang, Yuanzhi
TI  - Rapid Invasion of Spartina Alterniflora in the Coastal Zone of Mainland China: Spatiotemporal Patterns and Human Prevention
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 10
SN  - 1424-8220

AB  - Given the extensive spread and ecological consequences of exotic Spartina alterniflora (S. alterniflora) over the coast of mainland China, monitoring its spatiotemporal invasion patterns is important for the sake of coastal ecosystem management and ecological security. In this study, Landsat series images from 1990 to 2015 were used to establish multi-temporal datasets for documenting the temporal dynamics of S. alterniflora invasion. Our observations revealed that S. alterniflora had a continuous expansion with the area increasing by 50,204 ha during the considered 25 years. The largest expansion was identified in Jiangsu Province during the period of 1990&ndash;2000, and in Zhejiang Province during the periods 2000&ndash;2010 and 2010&ndash;2015. Three noticeable hotspots for S. alterniflora invasion were Yancheng of Jiangsu, Chongming of Shanghai, and Ningbo of Zhejiang, and each had a net area increase larger than 5000 ha. Moreover, an obvious shrinkage of S. alterniflora was identified in three coastal cities including the city of Cangzhou of Hebei, Dongguan, and Jiangmen of Guangdong. S. alterniflora invaded mostly into mudflats (&gt;93%) and shrank primarily due to aquaculture (55.5%). This study sheds light on the historical spatial patterns in S. alterniflora distribution and thus is helpful for understanding its invasion mechanism and invasive species management.
KW  - exotic species
KW  - spatiotemporal patterns
KW  - S. alterniflora invasion
KW  - CAS S. alterniflora
KW  - Landsat images
DO  - 10.3390/s19102308
ER  -
TY  - EJOU
AU  - Shanableh, Abdallah
AU  - Al-Ruzouq, Rami
AU  - Gibril, Mohamed Barakat A.
AU  - Flesia, Cristina
AU  - AL-Mansoori, Saeed
TI  - Spatiotemporal Mapping and Monitoring of Whiting in the Semi-Enclosed Gulf Using Moderate Resolution Imaging Spectroradiometer (MODIS) Time Series Images and a Generic Ensemble Tree-Based Model
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 10
SN  - 2072-4292

AB  - Whiting events in seas and lakes are a natural phenomenon caused by suspended calcium carbonate (CaCO3) particles. The Arabian Gulf, which is a semi-enclosed sea, is prone to extensive whiting that covers tens of thousands of square kilometres. Despite the extent and frequency of whiting events in the Gulf, studies documenting the whiting phenomenon are lacking. Therefore, the primary objective of this study was to detect, map and document the spatial and temporal distributions of whiting events in the Gulf using daily images acquired by the Moderate Resolution Imaging Spectroradiometer (MODIS) on NASA&rsquo;s Terra and Aqua satellites from 2002 to 2018. A method integrating a geographic object-based image analysis, the correlation-based feature selection technique (CFS), the adaptive boosting decision tree (AdaBoost DT) and the rule-based classification were used in the study to detect, quantify and assess whiting events in the Gulf from the MODIS data. Firstly, a multiresolution segmentation was optimised using unsupervised quality measures. Secondly, a set of spectral bands and indices were investigated using the CFS to select the most relevant feature(s). Thirdly, a generic AdaBoost DT model and a rule-based classification were adopted to classify the MODIS time series data. Finally, the developed classification model was compared with various tree-based classifiers such as random forest, a single DT and gradient boosted DT. Results showed that both the combination of the mean of the green spectral band and the normalised difference index between the green and blue bands (NDGB), or the combination of the NDGB and the colour index for estimating the concentrations of calcium carbonates (CI) of the image objects, were the most significant features for detecting whiting. Moreover, the generic AdaBoost DT classification model outperformed the other tested tree-based classifiers with an overall accuracy of 97.86% and a kappa coefficient of 0.97. The whiting events during the study period (2002&ndash;2018) occurred exclusively during the winter season (November to March) and mostly in February. Geographically, the whiting events covered areas ranging from 12,000 km2 to 60,000 km2 and were mainly located along the southwest coast of the Gulf. The duration of most whiting events was 2 to 6 days, with some events extending as long as 8 to 11 days. The study documented the spatiotemporal distribution of whiting events in the Gulf from 2002 to 2018 and presented an effective tool for detecting and motoring whiting events.
KW  - whiting event
KW  - calcium carbonate
KW  - semi-enclosed gulf
KW  - MODIS
KW  - GEOBIA
KW  - correlation-based feature selection
KW  - AdaBoost
DO  - 10.3390/rs11101193
ER  -
TY  - EJOU
AU  - Joung, Jingon
AU  - Choi, Jihoon
AU  - Jung, Bang C.
AU  - Yu, Sungwook
TI  - Artificial Noise Injection and Its Power Loading Methods for Secure Space-Time Line Coded Systems
T2  - Entropy

PY  - 2019
VL  - 21
IS  - 5
SN  - 1099-4300

AB  - In this paper, we consider a     2 &times; 2     space-time line coded (STLC) system having two-transmit and two-receive antennas. To improve the secrecy rate of the STLC system, in which an illegitimate receiver eavesdrops the information delivered from the STLC transmitter to the STLC receiver, we propose an artificial noise (AN) injection method. By exploiting the STLC structure, a novel AN for the STLC is designed and its optimal power loading factor is derived. Numerical results verify that the proposed secure STLC systems with the designed AN injection and the power control method can significantly improve the secrecy rate compared to the conventional STLC systems. It is observed that the proposed method is more effective if there is a significant gap between the main-channel and the eavesdropper-channel gains.
KW  - space-time line code
KW  - physical layer security
KW  - secrecy rate
KW  - artificial noise
KW  - power control
DO  - 10.3390/e21050515
ER  -
TY  - EJOU
AU  - Chawade, Aakash
AU  - van Ham, Joost
AU  - Blomquist, Hanna
AU  - Bagge, Oscar
AU  - Alexandersson, Erik
AU  - Ortiz, Rodomiro
TI  - High-Throughput Field-Phenotyping Tools for Plant Breeding and Precision Agriculture
T2  - Agronomy

PY  - 2019
VL  - 9
IS  - 5
SN  - 2073-4395

AB  - High-throughput field phenotyping has garnered major attention in recent years leading to the development of several new protocols for recording various plant traits of interest. Phenotyping of plants for breeding and for precision agriculture have different requirements due to different sizes of the plots and fields, differing purposes and the urgency of the action required after phenotyping. While in plant breeding phenotyping is done on several thousand small plots mainly to evaluate them for various traits, in plant cultivation, phenotyping is done in large fields to detect the occurrence of plant stresses and weeds at an early stage. The aim of this review is to highlight how various high-throughput phenotyping methods are used for plant breeding and farming and the key differences in the applications of such methods. Thus, various techniques for plant phenotyping are presented together with applications of these techniques for breeding and cultivation. Several examples from the literature using these techniques are summarized and the key technical aspects are highlighted.
KW  - field phenotyping
KW  - precision breeding
KW  - precision agriculture
KW  - decision support systems
DO  - 10.3390/agronomy9050258
ER  -
TY  - EJOU
AU  - Held, Philipp
AU  - Schneider von Deimling, Jens
TI  - New Feature Classes for Acoustic Habitat Mapping—A Multibeam Echosounder Point Cloud Analysis for Mapping Submerged Aquatic Vegetation (SAV)
T2  - Geosciences

PY  - 2019
VL  - 9
IS  - 5
SN  - 2076-3263

AB  - A new method for multibeam echosounder (MBES) data analysis is presented with the aim of improving habitat mapping, especially when considering submerged aquatic vegetation (SAV). MBES data were acquired with 400 kHz in 1&ndash;8 m water depth with a spatial resolution in the decimeter scale. The survey area was known to be populated with the seagrass Zostera marina and the bathymetric soundings were highly influenced by this habitat. The depth values often coincide with the canopy of the seagrass. Instead of classifying the data with a digital terrain model and the given derivatives, we derive predictive features from the native point cloud of the MBES soundings in a similar way to terrestrial LiDAR data analysis. We calculated the eigenvalues to derive nine characteristic features, which include linearity, planarity, and sphericity. The features were calculated for each sounding within a cylindrical neighborhood of 0.5 m radius and holding 88 neighboring soundings, on average, during our survey. The occurrence of seagrass was ground-truthed by divers and aerial photography. A data model was constructed and we applied a random forest machine learning supervised classification to predict between the two cases of &ldquo;seafloor&rdquo; and &ldquo;vegetation&rdquo;. Prediction by linearity, planarity, and sphericity resulted in 88.5% prediction accuracy. After constructing the higher-order eigenvalue derivatives and having the nine features available, the model resulted in 96% prediction accuracy. This study outlines for the first time that valuable feature classes can be derived from MBES point clouds&mdash;an approach that could substantially improve bathymetric measurements and habitat mapping.
KW  - habitat mapping
KW  - submerged aquatic vegetation
KW  - multibeam echosounder
KW  - point cloud
DO  - 10.3390/geosciences9050235
ER  -
TY  - EJOU
AU  - De Luca, Giandomenico
AU  - N. Silva, João M.
AU  - Cerasoli, Sofia
AU  - Araújo, João
AU  - Campos, José
AU  - Di Fazio, Salvatore
AU  - Modica, Giuseppe
TI  - Object-Based Land Cover Classification of Cork Oak Woodlands using UAV Imagery and Orfeo ToolBox
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 10
SN  - 2072-4292

AB  - This paper investigates the reliability of free and open-source algorithms used in the geographical object-based image classification (GEOBIA) of very high resolution (VHR) imagery surveyed by unmanned aerial vehicles (UAVs). UAV surveys were carried out in a cork oak woodland located in central Portugal at two different periods of the year (spring and summer). Segmentation and classification algorithms were implemented in the Orfeo ToolBox (OTB) configured in the QGIS environment for the GEOBIA process. Image segmentation was carried out using the Large-Scale Mean-Shift (LSMS) algorithm, while classification was performed by the means of two supervised classifiers, random forest (RF) and support vector machines (SVM), both of which are based on a machine learning approach. The original, informative content of the surveyed imagery, consisting of three radiometric bands (red, green, and NIR), was combined to obtain the normalized difference vegetation index (NDVI) and the digital surface model (DSM). The adopted methodology resulted in a classification with higher accuracy that is suitable for a structurally complex Mediterranean forest ecosystem such as cork oak woodlands, which are characterized by the presence of shrubs and herbs in the understory as well as tree shadows. To improve segmentation, which significantly affects the subsequent classification phase, several tests were performed using different values of the range radius and minimum region size parameters. Moreover, the consistent selection of training polygons proved to be critical to improving the results of both the RF and SVM classifiers. For both spring and summer imagery, the validation of the obtained results shows a very high accuracy level for both the SVM and RF classifiers, with kappa coefficient values ranging from 0.928 to 0.973 for RF and from 0.847 to 0.935 for SVM. Furthermore, the land cover class with the highest accuracy for both classifiers and for both flights was cork oak, which occupies the largest part of the study area. This study shows the reliability of fixed-wing UAV imagery for forest monitoring. The study also evidences the importance of planning UAV flights at solar noon to significantly reduce the shadows of trees in the obtained imagery, which is critical for classifying open forest ecosystems such as cork oak woodlands.
KW  - Geographic Object-Based Image Analysis (GEOBIA)
KW  - Land cover classification
KW  - Unmanned Aerial Vehicles (UAVs)
KW  - Orfeo ToolBox (OTB)
KW  - cork oak woodlands
KW  - machine learning algorithms
KW  - Random Forest (RF)
KW  - Support Vector Machines (SVM)
KW  - Spectral separability
KW  - Accuracy assessment.
DO  - 10.3390/rs11101238
ER  -
TY  - EJOU
AU  - Niu, Yaxiao
AU  - Zhang, Liyuan
AU  - Zhang, Huihui
AU  - Han, Wenting
AU  - Peng, Xingshuo
TI  - Estimating Above-Ground Biomass of Maize Using Features Derived from UAV-Based RGB Imagery
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 11
SN  - 2072-4292

AB  - The rapid, accurate, and economical estimation of crop above-ground biomass at the farm scale is crucial for precision agricultural management. The unmanned aerial vehicle (UAV) remote-sensing system has a great application potential with the ability to obtain remote-sensing imagery with high temporal-spatial resolution. To verify the application potential of consumer-grade UAV RGB imagery in estimating maize above-ground biomass, vegetation indices and plant height derived from UAV RGB imagery were adopted. To obtain a more accurate observation, plant height was directly derived from UAV RGB point clouds. To search the optimal estimation method, the estimation performances of the models based on vegetation indices alone, based on plant height alone, and based on both vegetation indices and plant height were compared. The results showed that plant height directly derived from UAV RGB point clouds had a high correlation with ground-truth data with an R2 value of 0.90 and an RMSE value of 0.12 m. The above-ground biomass exponential regression models based on plant height alone had higher correlations for both fresh and dry above-ground biomass with R2 values of 0.77 and 0.76, respectively, compared to the linear regression model (both R2 values were 0.59). The vegetation indices derived from UAV RGB imagery had great potential to estimate maize above-ground biomass with R2 values ranging from 0.63 to 0.73. When estimating the above-ground biomass of maize by using multivariable linear regression based on vegetation indices, a higher correlation was obtained with an R2 value of 0.82. There was no significant improvement of the estimation performance when plant height derived from UAV RGB imagery was added into the multivariable linear regression model based on vegetation indices. When estimating crop above-ground biomass based on UAV RGB remote-sensing system alone, looking for optimized vegetation indices and establishing estimation models with high performance based on advanced algorithms (e.g., machine learning technology) may be a better way.
KW  - vegetation index
KW  - plant height
KW  - point clouds
KW  - linear regression
KW  - exponential regression
KW  - multivariable linear regression
DO  - 10.3390/rs11111261
ER  -
TY  - EJOU
AU  - Mwenegoha, Hery
AU  - Moore, Terry
AU  - Pinchin, James
AU  - Jabbal, Mark
TI  - Model-Based Autonomous Navigation with Moment of Inertia Estimation for Unmanned Aerial Vehicles
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 11
SN  - 1424-8220

AB  - The dominant navigation system for low-cost, mass-market Unmanned Aerial Vehicles (UAVs) is based on an Inertial Navigation System (INS) coupled with a Global Navigation Satellite System (GNSS). However, problems tend to arise during periods of GNSS outage where the navigation solution degrades rapidly. Therefore, this paper details a model-based integration approach for fixed wing UAVs, using the Vehicle Dynamics Model (VDM) as the main process model aided by low-cost Micro-Electro-Mechanical Systems (MEMS) inertial sensors and GNSS measurements with moment of inertia calibration using an Unscented Kalman Filter (UKF). Results show that the position error does not exceed 14.5 m in all directions after 140 s of GNSS outage. Roll and pitch errors are bounded to 0.06 degrees and the error in yaw grows slowly to 0.65 degrees after 140 s of GNSS outage. The filter is able to estimate model parameters and even the moment of inertia terms even with significant coupling between them. Pitch and yaw moment coefficient terms present significant cross coupling while roll moment terms seem to be decorrelated from all of the other terms, whilst more dynamic manoeuvres could help to improve the overall observability of the parameters.
KW  - GNSS
KW  - INS
KW  - VDM
KW  - Model-Based Navigation
KW  - Unscented Kalman Filter
DO  - 10.3390/s19112467
ER  -
TY  - EJOU
AU  - Chen, Xiang
AU  - Wang, Tao
AU  - Liu, Shulin
AU  - Peng, Fei
AU  - Tsunekawa, Atsushi
AU  - Kang, Wenping
AU  - Guo, Zichen
AU  - Feng, Kun
TI  - A New Application of Random Forest Algorithm to Estimate Coverage of Moss-Dominated Biological Soil Crusts in Semi-Arid Mu Us Sandy Land, China
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 11
SN  - 2072-4292

AB  - Biological soil crusts (BSCs) play an essential role in desert ecosystems. Knowledge of the distribution and disappearance of BSCs is vital for the management of ecosystems and for desertification researches. However, the major remote sensing approaches used to extract BSCs are multispectral indices, which lack accuracy, and hyperspectral indices, which have lower data availability and require a higher computational effort. This study employs random forest (RF) models to optimize the extraction of BSCs using band combinations similar to the two multispectral BSC indices (Crust Index-CI; Biological Soil Crust Index-BSCI), but covering all possible band combinations. Simulated multispectral datasets resampled from in-situ hyperspectral data were used to extract BSC information. Multispectral datasets (Landsat-8 and Sentinel-2 datasets) were then used to detect BSC coverage in Mu Us Sandy Land, located in northern China, where BSCs dominated by moss are widely distributed. The results show that (i) the spectral curves of moss-dominated BSCs are different from those of other typical land surfaces, (ii) the BSC coverage can be predicted using the simulated multispectral data (mean square error (MSE) &lt; 0.01), (iii) Sentinel-2 satellite datasets with CI-based band combinations provided a reliable RF model for detecting moss-dominated BSCs (10-fold validation, R2 = 0.947; ground validation, R2 = 0.906). In conclusion, application of the RF algorithm to the Sentinel-2 dataset can precisely and effectively map BSCs dominated by moss. This new application can be used as a theoretical basis for detecting BSCs in other arid and semi-arid lands within desert ecosystems.
KW  - moss-dominated biological soil crusts (BSCs)
KW  - random forest (RF) algorithm
KW  - in-situ hyperspectral dataset
KW  - multispectral remote sensing
KW  - Mu Us Sandy Land
DO  - 10.3390/rs11111286
ER  -
TY  - EJOU
AU  - Lopes Queiroz, Gustavo
AU  - McDermid, Gregory J.
AU  - Castilla, Guillermo
AU  - Linke, Julia
AU  - Rahman, Mir M.
TI  - Mapping Coarse Woody Debris with Random Forest Classification of Centimetric Aerial Imagery
T2  - Forests

PY  - 2019
VL  - 10
IS  - 6
SN  - 1999-4907

AB  - Coarse woody debris (CWD; large parts of dead trees) is a vital element of forest ecosystems, playing an important role in nutrient cycling, carbon storage, fire fuel, microhabitats, and overall forest structure. However, there is a lack of effective tools for identifying and mapping both standing (snags) and downed (logs) CWD in complex natural settings. We applied a random forest machine learning classifier to detect CWD in centimetric aerial imagery acquired over a 270-hectare study area in the boreal forest of Alberta, Canada. We used a geographic object-based image analysis (GEOBIA) approach in the classification with spectral, spatial, and LiDAR (light detection and ranging)-derived height predictor variables. We found CWD to be detected with great accuracy (93.4 &plusmn; 4.2% completeness and 94.5 &plusmn; 3.2% correctness) when training samples were located within the application area, and with very good accuracy (84.2 &plusmn; 5.2% completeness and 92.2 &plusmn; 3.2% correctness) when training samples were located outside the application area. The addition of LiDAR-derived variables did not increase the accuracy of CWD detection overall (&lt;2%), but aided significantly (p &lt; 0.001) in the distinction between logs and snags. Foresters and researchers interested in CWD can take advantage of these novel methods to produce accurate maps of logs and snags, which will contribute to the understanding and management of forest ecosystems.
KW  - coarse woody debris
KW  - coarse woody material
KW  - large woody debris
KW  - random forest classification
KW  - GEOBIA
KW  - aerial image
KW  - LiDAR
KW  - segmentation
DO  - 10.3390/f10060471
ER  -
TY  - EJOU
AU  - Laamrani, Ahmed
AU  - Berg, Aaron A.
AU  - Voroney, Paul
AU  - Feilhauer, Hannes
AU  - Blackburn, Line
AU  - March, Michael
AU  - Dao, Phuong D.
AU  - He, Yuhong
AU  - Martin, Ralph C.
TI  - Ensemble Identification of Spectral Bands Related to Soil Organic Carbon Levels over an Agricultural Field in Southern Ontario, Canada
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 11
SN  - 2072-4292

AB  - The recent use of hyperspectral remote sensing imagery has introduced new opportunities for soil organic carbon (SOC) assessment and monitoring. These data enable monitoring of a wide variety of soil properties but pose important methodological challenges. Highly correlated hyperspectral spectral bands can affect the prediction and accuracy as well as the interpretability of the retrieval model. Therefore, the spectral dimension needs to be reduced through a selection of specific spectral bands or regions that are most helpful to describing SOC. This study evaluates the efficiency of visible near-infrared (VNIR) and shortwave near-infrared (SWIR) hyperspectral data to identify the most informative hyperspectral bands responding to SOC content in agricultural soils. Soil samples (111) were collected over an agricultural field in southern Ontario, Canada and analyzed against two hyperspectral datasets: An airborne Nano-Hyperspec imaging sensor with 270 bands (400&ndash;1000 nm) and a laboratory hyperspectral dataset (ASD FieldSpec 3) along the 1000&ndash;2500 nm range (NIR-SWIR). In parallel, a multimethod modeling approach consisting of random forest, support vector machine, and partial least squares regression models was used to conduct band selections and to assess the validity of the selected bands. The multimethod model resulted in a selection of optimal band or regions over the VNIR and SWIR sensitive to SOC and potentially for mapping. The bands that achieved the highest respective importance values were 711&ndash;715, 727, 986&ndash;998, and 433&ndash;435 nm regions (VNIR); and 2365&ndash;2373, 2481&ndash;2500, and 2198&ndash;2206 nm (NIR-SWIR). Some of these bands are in agreement with the absorption features of SOC reported in the literature, whereas others have not been reported before. Ultimately, the selection of optimal band and regions is of importance for quantification of agricultural SOC and would provide a new framework for creating optimized SOC-specific sensors.
KW  - remote sensing
KW  - agricultural soils
KW  - imaging spectroscopy
KW  - airborne hyperspectral imaging
KW  - unmanned aerial vehicle (UAV)
KW  - hyperspectral
KW  - feature selection
KW  - multimethod modeling approach
DO  - 10.3390/rs11111298
ER  -
TY  - EJOU
AU  - Li, Xingyu
AU  - Tang, Bo
AU  - Ball, John
AU  - Doude, Matthew
AU  - Carruth, Daniel W.
TI  - Rollover-Free Path Planning for Off-Road Autonomous Driving
T2  - Electronics

PY  - 2019
VL  - 8
IS  - 6
SN  - 2079-9292

AB  - Perception, planning, and control are three enabling technologies to achieve autonomy in autonomous driving. In particular, planning provides vehicles with a safe and collision-free path towards their destinations, accounting for vehicle dynamics, maneuvering capabilities in the presence of obstacles, traffic rules, and road boundaries. Existing path planning algorithms can be divided into two stages: global planning and local planning. In the global planning stage, global routes and the vehicle states are determined from a digital map and the localization system. In the local planning stage, a local path can be achieved based on a global route and surrounding information obtained from sensors such as cameras and LiDARs. In this paper, we present a new local path planning method, which incorporates a vehicle&rsquo;s time-to-rollover model for off-road autonomous driving on different road profiles for a given predefined global route. The proposed local path planning algorithm uses a 3D occupancy grid and generates a series of 3D path candidates in the s-p coordinate system. The optimal path is then selected considering the total cost of safety, including obstacle avoidance, vehicle rollover prevention, and comfortability in terms of path smoothness and continuity with road unevenness. The simulation results demonstrate the effectiveness of the proposed path planning method for various types of roads, indicating its wide practical applications to off-road autonomous driving.
KW  - off-road autonomous driving
KW  - real-time path planning
KW  - vehicle rollover model
KW  - obstacle avoidance
DO  - 10.3390/electronics8060614
ER  -
TY  - EJOU
AU  - Zhou, Xisheng
AU  - Li, Long
AU  - Chen, Longqian
AU  - Liu, Yunqiang
AU  - Cui, Yifan
AU  - Zhang, Yu
AU  - Zhang, Ting
TI  - Discriminating Urban Forest Types from Sentinel-2A Image Data through Linear Spectral Mixture Analysis: A Case Study of Xuzhou, East China
T2  - Forests

PY  - 2019
VL  - 10
IS  - 6
SN  - 1999-4907

AB  - Urban forests are an important component of the urban ecosystem. Urban forest types are a key piece of information required for monitoring the condition of an urban ecosystem. In this study, we propose an urban forest type discrimination method based on linear spectral mixture analysis (LSMA) and a support vector machine (SVM) in the case study of Xuzhou, east China. From 10-m Sentinel-2A imagery data, three different vegetation endmembers, namely broadleaved forest, coniferous forest, and low vegetation, and their abundances were extracted through LSMA. Using a combination of image spectra, topography, texture, and vegetation abundances, four SVM classification models were performed and compared to investigate the impact of these features on classification accuracy. With a particular interest in the role that vegetation abundances play in classification, we also compared SVM and other classifiers, i.e., random forest (RF), artificial neural network (ANN), and quick unbiased efficient statistical tree (QUEST). Results indicate that (1) the LSMA method can derive accurate vegetation abundances from Sentinel-2A image data, and the root-mean-square error (RMSE) was 0.019; (2) the classification accuracies of the four SVM models were improved after adding topographic features, textural features, and vegetation abundances one after the other; (3) the SVM produced higher classification accuracies than the other three classifiers when identical classification features were used; and (4) vegetation endmember abundances improved classification accuracy regardless of which classifier was used. It is concluded that Sentinel-2A image data has a strong capability to discriminate urban forest types in spectrally heterogeneous urban areas, and that vegetation abundances derived from LSMA can enhance such discrimination.
KW  - urban forest
KW  - Sentinel-2A
KW  - LSMA
KW  - SVM
DO  - 10.3390/f10060478
ER  -
TY  - EJOU
AU  - Wang, Dongliang
AU  - Shao, Quanqin
AU  - Yue, Huanyin
TI  - Surveying Wild Animals from Satellites, Manned Aircraft and Unmanned Aerial Systems (UASs): A Review
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 11
SN  - 2072-4292

AB  - This article reviews studies regarding wild animal surveys based on multiple platforms, including satellites, manned aircraft, and unmanned aircraft systems (UASs), and focuses on the data used, animal detection methods, and their accuracies. We also discuss the advantages and limitations of each type of remote sensing data and highlight some new research opportunities and challenges. Submeter very-high-resolution (VHR) spaceborne imagery has potential in modeling the population dynamics of large (&gt;0.6 m) wild animals at large spatial and temporal scales, but has difficulty discerning small (&lt;0.6 m) animals at the species level, although high-resolution commercial satellites, such as WorldView-3 and -4, have been able to collect images with a ground resolution of up to 0.31 m in panchromatic mode. This situation will not change unless the satellite image resolution is greatly improved in the future. Manned aerial surveys have long been employed to capture the centimeter-scale images required for animal censuses over large areas. However, such aerial surveys are costly to implement in small areas and can cause significant disturbances to wild animals because of their noise. In contrast, UAS surveys are seen as a safe, convenient and less expensive alternative to ground-based and conventional manned aerial surveys, but most UASs can cover only small areas. The proposed use of UAS imagery in combination with VHR satellite imagery would produce critical population data for large wild animal species and colonies over large areas. The development of software systems for automatically producing image mosaics and recognizing wild animals will further improve survey efficiency.
KW  - very-high-resolution satellites
KW  - unmanned aircraft systems
KW  - wild animal surveys
KW  - remote sensing
DO  - 10.3390/rs11111308
ER  -
TY  - EJOU
AU  - Zhao, Rui
AU  - Shi, Zhenwei
AU  - Zou, Zhengxia
AU  - Zhang, Zhou
TI  - Ensemble-Based Cascaded Constrained Energy Minimization for Hyperspectral Target Detection
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 11
SN  - 2072-4292

AB  - Ensemble learning is an important group of machine learning techniques that aim to enhance the nonlinearity and generalization ability of a learning system by aggregating multiple learners. We found that ensemble techniques show great potential for improving the performance of traditional hyperspectral target detection algorithms, while at present, there are few previous works have been done on this topic. To this end, we propose an Ensemble based Constrained Energy Minimization (E-CEM) detector for hyperspectral image target detection. Classical hyperspectral image target detection algorithms like Constrained Energy Minimization (CEM), matched filter (MF) and adaptive coherence/cosine estimator (ACE) are usually designed based on constrained least square regression methods or hypothesis testing methods with Gaussian distribution assumption. However, remote sensing hyperspectral data captured in a real-world environment usually shows strong nonlinearity and non-Gaussianity, which will lead to performance degradation of these classical detection algorithms. Although some hierarchical detection models are able to learn strong nonlinear discrimination of spectral data, due to the spectrum changes, these models usually suffer from the instability in detection tasks. The proposed E-CEM is designed based on the classical CEM detection algorithm. To improve both of the detection nonlinearity and generalization ability, the strategies of &ldquo;cascaded detection&rdquo;, &ldquo;random averaging&rdquo; and &ldquo;multi-scale scanning&rdquo; are specifically designed. Experiments on one synthetic hyperspectral image and two real hyperspectral images demonstrate the effectiveness of our method. E-CEM outperforms the traditional CEM detector and other state-of-the-art detection algorithms. Our code will be made publicly available.
KW  - hyperspectral image
KW  - target detection
KW  - constrained energy minimization
KW  - cascaded detection
KW  - ensemble
KW  - multi-scale scanning
DO  - 10.3390/rs11111310
ER  -
TY  - EJOU
AU  - Sothe, Camile
AU  - Dalponte, Michele
AU  - Almeida, Cláudia M.
AU  - Schimalski, Marcos B.
AU  - Lima, Carla L.
AU  - Liesenberg, Veraldo
AU  - Miyoshi, Gabriela T.
AU  - Tommaselli, Antonio M.
TI  - Tree Species Classification in a Highly Diverse Subtropical Forest Integrating UAV-Based Photogrammetric Point Cloud and Hyperspectral Data
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 11
SN  - 2072-4292

AB  - The use of remote sensing data for tree species classification in tropical forests is still a challenging task, due to their high floristic and spectral diversity. In this sense, novel sensors on board of unmanned aerial vehicle (UAV) platforms are a rapidly evolving technology that provides new possibilities for tropical tree species mapping. Besides the acquisition of high spatial and spectral resolution images, UAV-hyperspectral cameras operating in frame format enable to produce 3D hyperspectral point clouds. This study investigated the use of UAV-acquired hyperspectral images and UAV-photogrammetric point cloud (PPC) for classification of 12 major tree species in a subtropical forest fragment in Southern Brazil. Different datasets containing hyperspectral visible/near-infrared (VNIR) bands, PPC features, canopy height model (CHM), and other features extracted from hyperspectral data (i.e., texture, vegetation indices-VIs, and minimum noise fraction-MNF) were tested using a support vector machine (SVM) classifier. The results showed that the use of VNIR hyperspectral bands alone reached an overall accuracy (OA) of 57% (Kappa index of 0.53). Adding PPC features to the VNIR hyperspectral bands increased the OA by 11%. The best result was achieved combining VNIR bands, PPC features, CHM, and VIs (OA of 72.4% and Kappa index of 0.70). When only the CHM was added to VNIR bands, the OA increased by 4.2%. Among the hyperspectral features, besides all the VNIR bands and the two VIs (NDVI and PSSR), the first four MNF features and the textural mean of 565 and 679 nm spectral bands were pointed out as more important to discriminate the tree species according to Jeffries&ndash;Matusita (JM) distance. The SVM method proved to be a good classifier for the tree species recognition task, even in the presence of a high number of classes and a small dataset.
KW  - tree species mapping
KW  - tropical biodiversity
KW  - imaging spectroscopy
KW  - photogrammetry
KW  - support vector machine
DO  - 10.3390/rs11111338
ER  -
TY  - EJOU
AU  - Hao, Pengyu
AU  - Chen, Zhongxin
AU  - Tang, Huajun
AU  - Li, Dandan
AU  - Li, He
TI  - New Workflow of Plastic-Mulched Farmland Mapping using Multi-Temporal Sentinel-2 data
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 11
SN  - 2072-4292

AB  - Using plastic film mulch on cropland improves crop yield in water-deficient areas, but the use of plastic film on cropland leads to soil pollution. The accurate mapping of plastic-mulched land (PML) is valuable for monitoring the environmental problems caused by the use of plastic film. The drawback of PML mapping is that the detectable period of PML changes among the fields, which causes uncertainty when supervised classification methods are used to identify PML. In this study, a new workflow which merging PML of multiple temporal phases (MTPML) is proposed. For each temporal phase, the &ldquo;possible PML&rdquo; is firstly generated, these &ldquo;temporal possible PML&rdquo; layers are then combined to generate the &ldquo;possible PML&rdquo; layer. Finally, the maximum normalized difference vegetation index (NDVI) of the growing season is used to remove the non-cropland pixels from the &ldquo;possible PML layer,&rdquo; and then generate PML images. When generating &ldquo;temporal possible PML layers,&rdquo; three new PML indices (PMLI with near-infrared bands known as PMLI_NIR, PMLI with shortwave infrared bands known as PMLI_SWIR, and Normalized Difference PMLI known as PMLI_ND) are proposed to separate PML from bare land at plastic film cover stage; and the &ldquo;temporal possible PML layer&rdquo; are identified by the threshold based method. To estimate the performance of the three PML indices, two other approaches, PMLI threshold and Random Forest (RF) are used to generate &ldquo;temporal possible PML layer.&rdquo; Finally, PML images generated from the five MTPML approaches are compared with the image time series supervised classification (SUPML) result. Two study regions, Hengshui (HS) and Guyuan (GY), are used in this study. PML identification models are generated using training samples in HS and the models are used for PML mapping in both study regions. The results showed that MTPML workflow outperformed SUPML with 3%&ndash;5% higher classification accuracy. The three proposed PML indices had higher separability and importance score for bare land and PML discrimination. Among the five approaches used to generate the &ldquo;temporal possible PML layer,&rdquo; PMLI_SWIR is the recommended approach because the PMLI_SWIR threshold approach is easy to implement and the accuracy is only slightly lower than the RF approach. It is notable that no training sample was used in GY and the accuracy of the MTPML approach was higher than 85%, which indicated that the rules proposed in this study are suitable for other study regions.
KW  - plastic-mulched land (PML)
KW  - Sentinel-2
KW  - multi-temporal data
KW  - PML indices
KW  - threshold rule
KW  - Random Forest
DO  - 10.3390/rs11111353
ER  -
TY  - EJOU
AU  - Yue, Rui
AU  - Xu, Hao
AU  - Wu, Jianqing
AU  - Sun, Renjuan
AU  - Yuan, Changwei
TI  - Data Registration with Ground Points for Roadside LiDAR Sensors
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 11
SN  - 2072-4292

AB  - The Light Detection and Ranging (LiDAR) sensors are being considered as new traffic infrastructure sensors to detect road users&rsquo; trajectories for connected/autonomous vehicles and other traffic engineering applications. A LiDAR-enhanced traffic infrastructure system requires multiple LiDAR sensors around intersections, along with road segments, which can provide a seamless detection range at intersections or along arterials. Each LiDAR sensor generates cloud points of surrounding objects in a local coordinate system with the sensor at the origin, so it is necessary to integrate multiple roadside LiDAR sensors&rsquo; data into the same coordinate system. None of existing methods can integrate the data from roadside LiDAR sensors, because the extensive detection range of roadside sensors generates low-density cloud points and the alignment of roadside sensors is different from mapping scans or autonomous sensing systems. This paper presents a method to register datasets from multiple roadside LiDAR sensors. This approach innovatively integrates LiDAR datasets with 3D cloud points of road surface and 2D reference point features, so the method is abbreviated as RGP (Registration with Ground and Points). The RGP method applies optimization algorithms to identify the optimized linear coordinate transformation. This research considered the genetic algorithm (global optimization) and the hill climbing algorithm (local optimization). The performance of the RGP method and the different optimization algorithms was evaluated with field LiDAR sensors data. When the developed process can integrate data from roadside sensors, it can also register LiDAR sensors&rsquo; data on an autonomous vehicle or a robot.
KW  - data registration
KW  - Smart Traffic Infrastructure
KW  - ground points
KW  - optimization
DO  - 10.3390/rs11111354
ER  -
TY  - EJOU
AU  - Bote-Curiel, Luis
AU  - Muñoz-Romero, Sergio
AU  - Gerrero-Curieses, Alicia
AU  - Rojo-Álvarez, José L.
TI  - Deep Learning and Big Data in Healthcare: A Double Review for Critical Beginners
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 11
SN  - 2076-3417

AB  - In the last few years, there has been a growing expectation created about the analysis of large amounts of data often available in organizations, which has been both scrutinized by the academic world and successfully exploited by industry. Nowadays, two of the most common terms heard in scientific circles are Big Data and Deep Learning. In this double review, we aim to shed some light on the current state of these different, yet somehow related branches of Data Science, in order to understand the current state and future evolution within the healthcare area. We start by giving a simple description of the technical elements of Big Data technologies, as well as an overview of the elements of Deep Learning techniques, according to their usual description in scientific literature. Then, we pay attention to the application fields that can be said to have delivered relevant real-world success stories, with emphasis on examples from large technology companies and financial institutions, among others. The academic effort that has been put into bringing these technologies to the healthcare sector are then summarized and analyzed from a twofold view as follows: first, the landscape of application examples is globally scrutinized according to the varying nature of medical data, including the data forms in electronic health recordings, medical time signals, and medical images; second, a specific application field is given special attention, in particular the electrocardiographic signal analysis, where a number of works have been published in the last two years. A set of toy application examples are provided with the publicly-available MIMIC dataset, aiming to help the beginners start with some principled, basic, and structured material and available code. Critical discussion is provided for current and forthcoming challenges on the use of both sets of techniques in our future healthcare.
KW  - deep learning
KW  - big data
KW  - statistical learning
KW  - healthcare
KW  - electrocardiogram
KW  - databases
KW  - MIMIC
KW  - review
KW  - machine learning
DO  - 10.3390/app9112331
ER  -
TY  - EJOU
AU  - Ahmed, Sarfraz
AU  - Huda, M. N.
AU  - Rajbhandari, Sujan
AU  - Saha, Chitta
AU  - Elshaw, Mark
AU  - Kanarachos, Stratis
TI  - Pedestrian and Cyclist Detection and Intent Estimation for Autonomous Vehicles: A Survey
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 11
SN  - 2076-3417

AB  - As autonomous vehicles become more common on the roads, their advancement draws on safety concerns for vulnerable road users, such as pedestrians and cyclists. This paper presents a review of recent developments in pedestrian and cyclist detection and intent estimation to increase the safety of autonomous vehicles, for both the driver and other road users. Understanding the intentions of the pedestrian/cyclist enables the self-driving vehicle to take actions to avoid incidents. To make this possible, development of methods/techniques, such as deep learning (DL), for the autonomous vehicle will be explored. For example, the development of pedestrian detection has been significantly advanced using DL approaches, such as; Fast Region-Convolutional Neural Network (R-CNN) , Faster R-CNN and Single Shot Detector (SSD). Although DL has been around for several decades, the hardware to realise the techniques have only recently become viable. Using these DL methods for pedestrian and cyclist detection and applying it for the tracking, motion modelling and pose estimation can allow for a successful and accurate method of intent estimation for the vulnerable road users. Although there has been a growth in research surrounding the study of pedestrian detection using vision-based approaches, further attention should include focus on cyclist detection. To further improve safety for these vulnerable road users (VRUs), approaches such as sensor fusion and intent estimation should be investigated.
KW  - pedestrian detection
KW  - cyclist detection
KW  - deep learning
KW  - CNN
KW  - Fast R-CNN
KW  - Faster R-CNN
KW  - pose estimation
KW  - motion modelling
KW  - tracking
KW  - intent estimation
DO  - 10.3390/app9112335
ER  -
TY  - EJOU
AU  - Jung, Dae-Hyun
AU  - Kim, Hak-Jin
AU  - Kim, Hyoung S.
AU  - Choi, Jaeyoung
AU  - Kim, Jeong D.
AU  - Park, Soo H.
TI  - Fusion of Spectroscopy and Cobalt Electrochemistry Data for Estimating Phosphate Concentration in Hydroponic Solution
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 11
SN  - 1424-8220

AB  - Phosphate is a key element affecting plant growth. Therefore, the accurate determination of phosphate concentration in hydroponic nutrient solutions is essential for providing a balanced set of nutrients to plants within a suitable range. This study aimed to develop a data fusion approach for determining phosphate concentrations in a paprika nutrient solution. As a conventional multivariate analysis approach using spectral data, partial least squares regression (PLSR) and principal components regression (PCR) models were developed using 56 samples for calibration and 24 samples for evaluation. The R2 values of estimation models using PCR and PLSR ranged from 0.44 to 0.64. Furthermore, an estimation model using raw electromotive force (EMF) data from cobalt electrodes gave R2 values of 0.58–0.71. To improve the model performance, a data fusion method was developed to estimate phosphate concentration using near infrared (NIR) spectral and cobalt electrochemical data. Raw EMF data from cobalt electrodes and principle component values from the spectral data were combined. Results of calibration and evaluation tests using an artificial neural network estimation model showed that R2 = 0.90 and 0.89 and root mean square error (RMSE) = 96.70 and 119.50 mg/L, respectively. These values are sufficiently high for application to measuring phosphate concentration in hydroponic solutions.
KW  - phosphate sensing
KW  - Multi-sensor data fusion
KW  - hybrid sensor system
KW  - Feed-forward back-propagation ANN
DO  - 10.3390/s19112596
ER  -
TY  - EJOU
AU  - Wang, Yanyu
AU  - Zhang, Ke
AU  - Tang, Chunlan
AU  - Cao, Qiang
AU  - Tian, Yongchao
AU  - Zhu, Yan
AU  - Cao, Weixing
AU  - Liu, Xiaojun
TI  - Estimation of Rice Growth Parameters Based on Linear Mixed-Effect Model Using Multispectral Images from Fixed-Wing Unmanned Aerial Vehicles
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 11
SN  - 2072-4292

AB  - The accurate estimation of aboveground biomass (AGB) and leaf area index (LAI) is critical to characterize crop growth status and predict grain yield. Unmanned aerial vehicle (UAV) -based remote sensing has attracted significant interest due to its high flexibility and easiness of operation. The mixed effect model introduced in this study can capture secondary factors that cannot be captured by standard empirical relationships. The objective of this study was to explore the potential benefit of using a linear mixed-effect (LME) model and multispectral images from a fixed-wing UAV to estimate both AGB and LAI of rice. Field experiments were conducted over two consecutive years (2017&ndash;2018), that involved different N rates, planting patterns and rice cultivars. Images were collected by a compact multispectral camera mounted on a fixed-wing UAV during key rice growth stages. LME, simple regression (SR), artificial neural networks (ANN) and random forests (RF) models were developed relating growth parameters (AGB and LAI) to spectral information. Cultivar (C), growth stage (S) and planting pattern (P) were selected as candidates of random effects for the LME models due to their significant effects on rice growth. Compared to other regression models (SR, ANN and RF), the LME model improved the AGB estimation accuracy for all stage groups to varying degrees: the R2 increased by 0.14&ndash;0.35 and the RMSE decreased by 0.88&ndash;1.80 t ha&minus;1 for the whole season, the R2 increased by 0.07&ndash;0.15 and the RMSE decreased by 0.31&ndash;0.61 t ha&minus;1 for pre-heading stages and the R2 increased by 0.21&ndash;0.53 and the RMSE decreased by 0.72&ndash;1.52 t ha&minus;1 for post-heading stages. Further analysis suggested that the LME model also successfully predicted within the groups when the number of groups was suitable. More importantly, depending on the availability of C, S, P or combinations thereof, mixed effects could lead to an outperformance of baseline retrieval methods (SR, ANN or RF) due to the inclusion of secondary effects. Satisfactory results were also obtained for the LAI estimation while the superiority of the LME model was not as significant as that for AGB estimation. This study demonstrates that the LME model could accurately estimate rice AGB and LAI and fixed-wing UAVs are promising for the monitoring of the crop growth status over large-scale farmland.
KW  - aboveground biomass
KW  - leaf area index
KW  - vegetation index
KW  - linear mixed-effect model
KW  - UAV multispectral image
KW  - remote sensing
KW  - rice
DO  - 10.3390/rs11111371
ER  -
TY  - EJOU
AU  - Abdulridha, Jaafar
AU  - Batuman, Ozgur
AU  - Ampatzidis, Yiannis
TI  - UAV-Based Remote Sensing Technique to Detect Citrus Canker Disease Utilizing Hyperspectral Imaging and Machine Learning
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 11
SN  - 2072-4292

AB  - A remote sensing technique was developed to detect citrus canker in laboratory conditions and was verified in the grove by utilizing an unmanned aerial vehicle (UAV). In the laboratory, a hyperspectral (400&ndash;1000 nm) imaging system was utilized for the detection of citrus canker in several disease development stages (i.e., asymptomatic, early, and late symptoms) on Sugar Belle leaves and immature (green) fruit by using two classification methods: (i) radial basis function (RBF) and (ii) K nearest neighbor (KNN). The same imaging system mounted on an UAV was used to detect citrus canker on tree canopies in the orchard. The overall classification accuracy of the RBF was higher (94%, 96%, and 100%) than the KNN method (94%, 95%, and 96%) for detecting canker in leaves. Among the 31 studied vegetation indices, the water index (WI) and the Modified Chlorophyll Absorption in Reflectance Index (ARI and TCARI 1) more accurately detected canker in laboratory and in orchard conditions, respectively. Immature fruit was not a reliable tissue for early detection of canker. However, the proposed technique successfully distinguished the late stage canker-infected fruit with 92% classification accuracy. The UAV-based technique achieved 100% classification accuracy for identifying healthy and canker-infected trees.
KW  - citrus
KW  - canker
KW  - disease detection
KW  - hyperspectral imaging
KW  - neural networks
KW  - vegetation indices
DO  - 10.3390/rs11111373
ER  -
TY  - EJOU
AU  - Rostami, Mohammad
AU  - Kolouri, Soheil
AU  - Eaton, Eric
AU  - Kim, Kyungnam
TI  - Deep Transfer Learning for Few-Shot SAR Image Classification
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 11
SN  - 2072-4292

AB  - The reemergence of Deep Neural Networks (DNNs) has lead to high-performance supervised learning algorithms for the Electro-Optical (EO) domain classification and detection problems. This success is because generating huge labeled datasets has become possible using modern crowdsourcing labeling platforms such as Amazon&rsquo;s Mechanical Turk that recruit ordinary people to label data. Unlike the EO domain, labeling the Synthetic Aperture Radar (SAR) domain data can be much more challenging, and for various reasons, using crowdsourcing platforms is not feasible for labeling the SAR domain data. As a result, training deep networks using supervised learning is more challenging in the SAR domain. In the paper, we present a new framework to train a deep neural network for classifying Synthetic Aperture Radar (SAR) images by eliminating the need for a huge labeled dataset. Our idea is based on transferring knowledge from a related EO domain problem, where labeled data are easy to obtain. We transfer knowledge from the EO domain through learning a shared invariant cross-domain embedding space that is also discriminative for classification. To this end, we train two deep encoders that are coupled through their last year to map data points from the EO and the SAR domains to the shared embedding space such that the distance between the distributions of the two domains is minimized in the latent embedding space. We use the Sliced Wasserstein Distance (SWD) to measure and minimize the distance between these two distributions and use a limited number of SAR label data points to match the distributions class-conditionally. As a result of this training procedure, a classifier trained from the embedding space to the label space using mostly the EO data would generalize well on the SAR domain. We provide a theoretical analysis to demonstrate why our approach is effective and validate our algorithm on the problem of ship classification in the SAR domain by comparing against several other competing learning approaches.
KW  - transfer learning
KW  - convolutional neural network
KW  - electro-optical imaging
KW  - Synthetic Aperture Radar (SAR) imaging
KW  - optimal transport metric
DO  - 10.3390/rs11111374
ER  -
TY  - EJOU
AU  - Abeysinghe, Tharindu
AU  - Simic Milas, Anita
AU  - Arend, Kristin
AU  - Hohman, Breann
AU  - Reil, Patrick
AU  - Gregory, Andrew
AU  - Vázquez-Ortega, Angélica
TI  - Mapping Invasive Phragmites australis in the Old Woman Creek Estuary Using UAV Remote Sensing and Machine Learning Classifiers
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 11
SN  - 2072-4292

AB  - Unmanned aerial vehicles (UAV) are increasingly used for spatiotemporal monitoring of invasive plants in coastal wetlands. Early identification of invasive species is necessary in planning, restoring, and managing wetlands. This study assessed the effectiveness of UAV technology to identify invasive Phragmites australis in the Old Woman Creek (OWC) estuary using machine learning (ML) algorithms: Neural network (NN), support vector machine (SVM), and k-nearest neighbor (kNN). The ML algorithms were compared with the parametric maximum likelihood classifier (MLC) using pixel- and object-based methods. Pixel-based NN was identified as the best classifier with an overall accuracy of 94.80% and the lowest error of omission of 1.59%, the outcome desirable for effective eradication of Phragmites. The results were reached combining Sequoia multispectral imagery (green, red, red edge, and near-infrared bands) combined with the canopy height model (CHM) acquired in the mid-growing season and normalized difference vegetation index (NDVI) acquired later in the season. The sensitivity analysis, using various vegetation indices, image texture, CHM, and principal components (PC), demonstrated the impact of various feature layers on the classifiers. The study emphasizes the necessity of a suitable sampling and cross-validation methods, as well as the importance of optimum classification parameters.
KW  - Phragmites australis
KW  - unmanned aerial vehicles
KW  - invasive
KW  - machine learning
KW  - object-based classifiers
DO  - 10.3390/rs11111380
ER  -
TY  - EJOU
AU  - Xin, Junfeng
AU  - Zhong, Jiabao
AU  - Yang, Fengru
AU  - Cui, Ying
AU  - Sheng, Jinlu
TI  - An Improved Genetic Algorithm for Path-Planning of Unmanned Surface Vehicle
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 11
SN  - 1424-8220

AB  - The genetic algorithm (GA) is an effective method to solve the path-planning problem and help realize the autonomous navigation for and control of unmanned surface vehicles. In order to overcome the inherent shortcomings of conventional GA such as population premature and slow convergence speed, this paper proposes the strategy of increasing the number of offsprings by using the multi-domain inversion. Meanwhile, a second fitness evaluation was conducted to eliminate undesirable offsprings and reserve the most advantageous individuals. The improvement could help enhance the capability of local search effectively and increase the probability of generating excellent individuals. Monte-Carlo simulations for five examples from the library for the travelling salesman problem were first conducted to assess the effectiveness of algorithms. Furthermore, the improved algorithms were applied to the navigation, guidance, and control system of an unmanned surface vehicle in a real maritime environment. Comparative study reveals that the algorithm with multi-domain inversion is superior with a desirable balance between the path length and time-cost, and has a shorter optimal path, a faster convergence speed, and better robustness than the others.
KW  - genetic algorithm
KW  - unmanned surface vehicle
KW  - path planning
KW  - multi-domain inversion
KW  - Monte-Carlo simulation
DO  - 10.3390/s19112640
ER  -
TY  - EJOU
AU  - Zhou, Chengquan
AU  - Ye, Hongbao
AU  - Xu, Zhifu
AU  - Hu, Jun
AU  - Shi, Xiaoyan
AU  - Hua, Shan
AU  - Yue, Jibo
AU  - Yang, Guijun
TI  - Estimating Maize-Leaf Coverage in Field Conditions by Applying a Machine Learning Algorithm to UAV Remote Sensing Images
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 11
SN  - 2076-3417

AB  - Leaf coverage is an indicator of plant growth rate and predicted yield, and thus it is crucial to plant-breeding research. Robust image segmentation of leaf coverage from remote-sensing images acquired by unmanned aerial vehicles (UAVs) in varying environments can be directly used for large-scale coverage estimation, and is a key component of high-throughput field phenotyping. We thus propose an image-segmentation method based on machine learning to extract relatively accurate coverage information from the orthophoto generated after preprocessing. The image analysis pipeline, including dataset augmenting, removing background, classifier training and noise reduction, generates a set of binary masks to obtain leaf coverage from the image. We compare the proposed method with three conventional methods (Hue-Saturation-Value, edge-detection-based algorithm, random forest) and a frontier deep-learning method called DeepLabv3+. The proposed method improves indicators such as Qseg, Sr, Es and mIOU by 15% to 30%. The experimental results show that this approach is less limited by radiation conditions, and that the protocol can easily be implemented for extensive sampling at low cost. As a result, with the proposed method, we recommend using red-green-blue (RGB)-based technology in addition to conventional equipment for acquiring the leaf coverage of agricultural crops.
KW  - machine learning
KW  - maize-leaf coverage
KW  - image segmentation
KW  - UAV remoting images
DO  - 10.3390/app9112389
ER  -
TY  - EJOU
AU  - Okeson, Trent J.
AU  - Barrett, Benjamin J.
AU  - Arce, Samuel
AU  - Vernon, Cory A.
AU  - Franke, Kevin W.
AU  - Hedengren, John D.
TI  - Achieving Tiered Model Quality in 3D Structure from Motion Models Using a Multi-Scale View-Planning Algorithm for Automated Targeted Inspection
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 12
SN  - 1424-8220

AB  - This study presents a novel multi-scale view-planning algorithm for automated targeted inspection using unmanned aircraft systems (UAS). In industrial inspection, it is important to collect the most relevant data to keep processing demands, both human and computational, to a minimum. This study investigates the viability of automated targeted multi-scale image acquisition for Structure from Motion (SfM)-based infrastructure modeling. A traditional view-planning approach for SfM is extended to a multi-scale approach, planning for targeted regions of high, medium, and low priority. The unmanned aerial vehicle (UAV) can traverse the entire aerial space and facilitates collection of an optimized set of views, both close to and far away from areas of interest. The test case for field validation is the Tibble Fork Dam in Utah. Using the targeted multi-scale flight planning, a UAV automatically flies a tiered inspection using less than 25% of the number of photos needed to model the entire dam at high-priority level. This results in approximately 75% reduced flight time and model processing load, while still maintaining high model accuracy where needed. Models display stepped improvement in visual clarity and SfM reconstruction integrity by priority level, with the higher priority regions more accurately modeling smaller and finer features. A resolution map of the final tiered model is included. While this study focuses on multi-scale view planning for optical sensors, the methods potentially extend to other remote sensors, such as aerial LiDAR.
KW  - structure from motion
KW  - unmanned aerial vehicles
KW  - dam inspection
KW  - automated inspection
KW  - Multi-Scale
KW  - view-planning
DO  - 10.3390/s19122703
ER  -
TY  - EJOU
AU  - Yao, Huang
AU  - Qin, Rongjun
AU  - Chen, Xiaoyu
TI  - Unmanned Aerial Vehicle for Remote Sensing Applications—A Review
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 12
SN  - 2072-4292

AB  - The unmanned aerial vehicle (UAV) sensors and platforms nowadays are being used in almost every application (e.g., agriculture, forestry, and mining) that needs observed information from the top or oblique views. While they intend to be a general remote sensing (RS) tool, the relevant RS data processing and analysis methods are still largely ad-hoc to applications. Although the obvious advantages of UAV data are their high spatial resolution and flexibility in acquisition and sensor integration, there is in general a lack of systematic analysis on how these characteristics alter solutions for typical RS tasks such as land-cover classification, change detection, and thematic mapping. For instance, the ultra-high-resolution data (less than 10 cm of Ground Sampling Distance (GSD)) bring more unwanted classes of objects (e.g., pedestrian and cars) in land-cover classification; the often available 3D data generated from photogrammetric images call for more advanced techniques for geometric and spectral analysis. In this paper, we perform a critical review on RS tasks that involve UAV data and their derived products as their main sources including raw perspective images, digital surface models, and orthophotos. In particular, we focus on solutions that address the &ldquo;new&rdquo; aspects of the UAV data including (1) ultra-high resolution; (2) availability of coherent geometric and spectral data; and (3) capability of simultaneously using multi-sensor data for fusion. Based on these solutions, we provide a brief summary of existing examples of UAV-based RS in agricultural, environmental, urban, and hazards assessment applications, etc., and by discussing their practical potentials, we share our views in their future research directions and draw conclusive remarks.
KW  - UAVs
KW  - remote sensing applications
KW  - data analysis
DO  - 10.3390/rs11121443
ER  -
TY  - EJOU
AU  - Wei, Lifei
AU  - Huang, Can
AU  - Zhong, Yanfei
AU  - Wang, Zhou
AU  - Hu, Xin
AU  - Lin, Liqun
TI  - Inland Waters Suspended Solids Concentration Retrieval Based on PSO-LSSVM for UAV-Borne Hyperspectral Remote Sensing Imagery
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 12
SN  - 2072-4292

AB  - Suspended solids concentration (SSC) is an important indicator of the degree of water pollution. However, when using an empirical or semi-empirical model adapted to some of the inland waters to estimate SSC on unmanned aerial vehicle (UAV)-borne hyperspectral images, the accuracy is often not sufficient. Thus, in this study, we attempted to use the particle swarm optimization (PSO) algorithm to find the optimal parameters of the least-squares support vector machine (LSSVM) model for the quantitative inversion of SSC. A reservoir and a polluted riverway were selected as the study areas. The spectral data of the 36-point and 29-point 400&ndash;900 nm wavelength range on the UAV-borne images were extracted. Compared with the semi-empirical model, the random forest (RF) algorithm and the competitive adaptive reweighted sampling (CARS) algorithm combined with partial least squares (PLS), the accuracy of the PSO-LSSVM algorithm in predicting the SSC was significantly improved. The training samples had a coefficient of determination (     R 2     ) of 0.98, a root mean square error (RMSE) of 0.68 mg/L, and a mean absolute percentage error (MAPE) of 12.66% at the reservoir. For the polluted riverway, PSO-LSSVM also performed well. Finally, the established SSC inversion model was applied to UAV-borne hyperspectral remote sensing (HRS) images. The results confirmed that the distribution of the predicted SSC was consistent with the observed results in the field, which proves that PSO-LSSVM is a feasible approach for the SSC inversion of UAV-borne HRS images.
KW  - unmanned aerial vehicle
KW  - hyperspectral imagery
KW  - suspended solids
KW  - particle swarm optimization
KW  - least-squares support vector machine
DO  - 10.3390/rs11121455
ER  -
TY  - EJOU
AU  - Munaye, Yirga Y.
AU  - Lin, Hsin-Piao
AU  - Adege, Abebe B.
AU  - Tarekegn, Getaneh B.
TI  - UAV Positioning for Throughput Maximization Using Deep Learning Approaches
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 12
SN  - 1424-8220

AB  - The use of unmanned aerial vehicles (UAVs) as a communication platform has great practical importance for future wireless networks, especially for on-demand deployment for temporary and emergency conditions. The user throughput estimation in a wireless system depends on the data traffic load and the available capacity to support that load. In UAV-assisted communication, the position of the UAV is one major factor that affects the capacity available to the data flows being served. This study applies multi-layer perceptron (MLP) and long short term memory (LSTM) approaches to determine the position of a UAV that maximizes the overall system performance and user throughput. To analyze and evaluate the system performance, we apply the hybrid of MLP-LSTM for classification regression tasks and K-means algorithms for automatic clustering of classes. The implementation of our work is done through TensorFlow packages. The performance of our proposed system is compared with other approaches to give accurate and novel results for both classification and regression tasks of the user throughput maximization and UAV positioning. According to the results, 98% of the user throughput maximization accuracy is correctly classified. Moreover, the UAV positioning provides accuracy levels of 94.73%, 98.33%, and 99.53% for original datasets (scenario 1), reduced features on the estimated values of user throughput at each grid point (scenario 2), and reduced feature datasets collected on different days and grid points achieved maximum throughput (scenario 3), respectively.
KW  - user throughput
KW  - maximization
KW  - UAV
KW  - positioning
KW  - deep learning (DL)
DO  - 10.3390/s19122775
ER  -
TY  - EJOU
AU  - Vanbrabant, Yasmin
AU  - Tits, Laurent
AU  - Delalieux, Stephanie
AU  - Pauly, Klaas
AU  - Verjans, Wim
AU  - Somers, Ben
TI  - Multitemporal Chlorophyll Mapping in Pome Fruit Orchards from Remotely Piloted Aircraft Systems
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 12
SN  - 2072-4292

AB  - Early and precise spatio-temporal monitoring of tree vitality is key for steering management decisions in pome fruit orchards. Spaceborne remote sensing instruments face a tradeoff between spatial and spectral resolution, while manned aircraft sensor-platform systems are very expensive. In order to address the shortcomings of these platforms, this study investigates the potential of Remotely Piloted Aircraft Systems (RPAS) to facilitate rapid, low cost, and flexible chlorophyll monitoring. Due to the complexity of orchard scenery a robust chlorophyll retrieval model on RPAS level has not yet been developed. In this study, specific focus therefore lies on evaluating the sensitivity of retrieval models to confounding factors. For this study, multispectral and hyperspectral imagery was collected over pome fruit orchards. Sensitivities of both univariate and multivariate retrieval models were demonstrated under different species, phenology, shade, and illumination scenes. Results illustrate that multivariate models have a significantly higher accuracy than univariate models as the former provide accuracies for the canopy chlorophyll content retrieval of R2 = 0.80 and Relative Root Mean Square Error (RRMSE) = 12% for the hyperspectral sensor. Random forest regression on multispectral imagery (R2 &gt; 0.9 for May, June, July, and August, and R2 = 0.5 for October) and hyperspectral imagery (0.6 &lt; R2 &lt; 0.9) led to satisfactory high and consistent accuracies for all months.
KW  - chlorophyll
KW  - fruit orchards
KW  - RPAS
KW  - multivariate
KW  - multispectral remote sensing
KW  - hyperspectral remote sensing
KW  - random forest
DO  - 10.3390/rs11121468
ER  -
TY  - EJOU
AU  - Zhang, Heng
AU  - Eziz, Anwar
AU  - Xiao, Jian
AU  - Tao, Shengli
AU  - Wang, Shaopeng
AU  - Tang, Zhiyao
AU  - Zhu, Jiangling
AU  - Fang, Jingyun
TI  - High-Resolution Vegetation Mapping Using eXtreme Gradient Boosting Based on Extensive Features
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 12
SN  - 2072-4292

AB  - Accurate mapping of vegetation is a premise for conserving, managing, and sustainably using vegetation resources, especially in conditions of intensive human activities and accelerating global changes. However, it is still challenging to produce high-resolution multiclass vegetation map in high accuracy, due to the incapacity of traditional mapping techniques in distinguishing mosaic vegetation classes with subtle differences and the paucity of fieldwork data. This study created a workflow by adopting a promising classifier, extreme gradient boosting (XGBoost), to produce accurate vegetation maps of two strikingly different cases (the Dzungarian Basin in China and New Zealand) based on extensive features and abundant vegetation data. For the Dzungarian Basin, a vegetation map with seven vegetation types, 17 subtypes, and 43 associations was produced with an overall accuracy of 0.907, 0.801, and 0.748, respectively. For New Zealand, a map of 10 habitats and a map of 41 vegetation classes were produced with 0.946, and 0.703 overall accuracy, respectively. The workflow incorporating simplified field survey procedures outperformed conventional field survey and remote sensing based methods in terms of accuracy and efficiency. In addition, it opens a possibility of building large-scale, high-resolution, and timely vegetation monitoring platforms for most terrestrial ecosystems worldwide with the aid of Google Earth Engine and citizen science programs.
KW  - vegetation mapping
KW  - XGBoost
KW  - simplified field survey
KW  - Dzungarian Basin
KW  - New Zealand
DO  - 10.3390/rs11121505
ER  -
TY  - EJOU
AU  - Cardenal, Javier
AU  - Fernández, Tomás
AU  - Pérez-García, José L.
AU  - Gómez-López, José M.
TI  - Measurement of Road Surface Deformation Using Images Captured from UAVs
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 12
SN  - 2072-4292

AB  - This paper presents a methodology for measuring road surface deformation due to terrain instability processes. The methodology is based on ultra-high resolution images acquired from unmanned aerial vehicles (UAVs). Flights are georeferenced by means of Structure from Motion (SfM) techniques. Dense point clouds, obtained using the multiple-view stereo (MVS) approach, are used to generate digital surface models (DSM) and high resolution orthophotographs (0.02 m GSD). The methodology has been applied to an unstable area located in La Guardia (Jaen, Southern Spain), where an active landslide was identified. This landslide affected some roads and accesses to a highway at the landslide foot. The detailed road deformation was monitored between 2012 and 2015 by means of eleven UAV flights of ultrahigh resolution covering an area of about 260 m × 90 m. The accuracy of the analysis has been established in 0.02 ± 0.01 m in XY and 0.04 ± 0.02 m in Z. Large deformations in the order of two meters were registered in the total period analyzed that resulted in maximum average rates of 0.62 m/month in the unstable area. Some boundary conditions were considered because of the low required flying height (&lt;50 m above ground level) in order to achieve a suitable image GSD, the fast landslide dynamic, continuous maintenance works on the affected roads and dramatic seasonal vegetation changes throughout the monitoring period. Finally, we have analyzed the relation of displacements to rainfalls in the area, finding a significant correlation between the two variables, as well as two different reactivation episodes.
KW  - road surface deformation
KW  - UAV images
KW  - SfM-MVS
KW  - monitoring points
DO  - 10.3390/rs11121507
ER  -
TY  - EJOU
AU  - Park, John Y.
AU  - Muller-Landau, Helene C.
AU  - Lichstein, Jeremy W.
AU  - Rifai, Sami W.
AU  - Dandois, Jonathan P.
AU  - Bohlman, Stephanie A.
TI  - Quantifying Leaf Phenology of Individual Trees and Species in a Tropical Forest Using Unmanned Aerial Vehicle (UAV) Images
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 13
SN  - 2072-4292

AB  - Tropical forests exhibit complex but poorly understood patterns of leaf phenology. Understanding species- and individual-level phenological patterns in tropical forests requires datasets covering large numbers of trees, which can be provided by Unmanned Aerial Vehicles (UAVs). In this paper, we test a workflow combining high-resolution RGB images (7 cm/pixel) acquired from UAVs with a machine learning algorithm to monitor tree and species leaf phenology in a tropical forest in Panama. We acquired images for 34 flight dates over a 12-month period. Crown boundaries were digitized in images and linked with forest inventory data to identify species. We evaluated predictions of leaf cover from different models that included up to 14 image features extracted for each crown on each date. The models were trained and tested with visual estimates of leaf cover from 2422 images from 85 crowns belonging to eight species spanning a range of phenological patterns. The best-performing model included both standard color metrics, as well as texture metrics that quantify within-crown variation, with r2 of 0.84 and mean absolute error (MAE) of 7.8% in 10-fold cross-validation. In contrast, the model based only on the widely-used Green Chromatic Coordinate (GCC) index performed relatively poorly (r2 = 0.52, MAE = 13.6%). These results highlight the utility of texture features for image analysis of tropical forest canopies, where illumination changes may diminish the utility of color indices, such as GCC. The algorithm successfully predicted both individual-tree and species patterns, with mean r2 of 0.82 and 0.89 and mean MAE of 8.1% and 6.0% for individual- and species-level analyses, respectively. Our study is the first to develop and test methods for landscape-scale UAV monitoring of individual trees and species in diverse tropical forests. Our analyses revealed undescribed patterns of high intraspecific variation and complex leaf cover changes for some species.
KW  - phenology
KW  - seasonality
KW  - drones
KW  - Unmanned Aerial Vehicles (UAV), texture features
KW  - tropical forest
KW  - species diversity
KW  - machine learning
KW  - near-surface remote-sensing
DO  - 10.3390/rs11131534
ER  -
TY  - EJOU
AU  - Buters, Todd
AU  - Belton, David
AU  - Cross, Adam
TI  - Seed and Seedling Detection Using Unmanned Aerial Vehicles and Automated Image Classification in the Monitoring of Ecological Recovery
T2  - Drones

PY  - 2019
VL  - 3
IS  - 3
SN  - 2504-446X

AB  - Monitoring is a crucial component of ecological recovery projects, yet it can be challenging to achieve at scale and during the formative stages of plant establishment. The monitoring of seeds and seedlings, which represent extremely vulnerable stages in the plant life cycle, is particularly challenging due to their diminutive size and lack of distinctive morphological characteristics. Counting and classifying seedlings to species level can be time-consuming and extremely difficult, and there is a need for technological approaches offering restoration practitioners with fine-resolution, rapid and scalable plant-based monitoring solutions. Unmanned aerial vehicles (UAVs) offer a novel approach to seed and seedling monitoring, as the combination of high-resolution sensors and low flight altitudes allow for the detection and monitoring of small objects, even in challenging terrain and in remote areas. This study utilized low-altitude UAV imagery and an automated object-based image analysis software to detect and count target seeds and seedlings from a matrix of non-target grasses across a variety of substrates reflective of local restoration substrates. Automated classification of target seeds and target seedlings was achieved at accuracies exceeding 90% and 80%, respectively, although the classification accuracy decreased with increasing flight altitude (i.e., decreasing image resolution) and increasing background surface complexity (increasing percentage cover of non-target grasses and substrate surface texture). Results represent the first empirical evidence that small objects such as seeds and seedlings can be classified from complex ecological backgrounds using automated processes from UAV-imagery with high levels of accuracy. We suggest that this novel application of UAV use in ecological monitoring offers restoration practitioners an excellent tool for rapid, reliable and non-destructive early restoration trajectory assessment.
KW  - ecological restoration
KW  - object-based image analysis
KW  - rehabilitation
KW  - remote sensing
KW  - monitoring
DO  - 10.3390/drones3030053
ER  -
TY  - EJOU
AU  - Koch, Tobias
AU  - Körner, Marco
AU  - Fraundorfer, Friedrich
TI  - Automatic and Semantically-Aware 3D UAV Flight Planning for Image-Based 3D Reconstruction
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 13
SN  - 2072-4292

AB  - Small-scaled unmanned aerial vehicles (UAVs) emerge as ideal image acquisition platforms due to their high maneuverability even in complex and tightly built environments. The acquired images can be utilized to generate high-quality 3D models using current multi-view stereo approaches. However, the quality of the resulting 3D model highly depends on the preceding flight plan which still requires human expert knowledge, especially in complex urban and hazardous environments. In terms of safe flight plans, practical considerations often define prohibited and restricted airspaces to be accessed with the vehicle. We propose a 3D UAV path planning framework designed for detailed and complete small-scaled 3D reconstructions considering the semantic properties of the environment allowing for user-specified restrictions on the airspace. The generated trajectories account for the desired model resolution and the demands on a successful photogrammetric reconstruction. We exploit semantics from an initial flight to extract the target object and to define restricted and prohibited airspaces which have to be avoided during the path planning process to ensure a safe and short UAV path, while still aiming to maximize the object reconstruction quality. The path planning problem is formulated as an orienteering problem and solved via discrete optimization exploiting submodularity and photogrammetrical relevant heuristics. An evaluation of our method on a customized synthetic scene and on outdoor experiments suggests the real-world capability of our methodology by providing feasible, short and safe flight plans for the generation of detailed 3D reconstruction models.
KW  - UAV
KW  - trajectory optimization
KW  - path planning
KW  - discrete optimization
KW  - 3D reconstruction
KW  - semantics
KW  - urban mapping
DO  - 10.3390/rs11131550
ER  -
TY  - EJOU
AU  - Zhang, Xin
AU  - Han, Liangxiu
AU  - Dong, Yingying
AU  - Shi, Yue
AU  - Huang, Wenjiang
AU  - Han, Lianghao
AU  - González-Moreno, Pablo
AU  - Ma, Huiqin
AU  - Ye, Huichun
AU  - Sobeih, Tam
TI  - A Deep Learning-Based Approach for Automated Yellow Rust Disease Detection from High-Resolution Hyperspectral UAV Images
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 13
SN  - 2072-4292

AB  - Yellow rust in winter wheat is a widespread and serious fungal disease, resulting in significant yield losses globally. Effective monitoring and accurate detection of yellow rust are crucial to ensure stable and reliable wheat production and food security. The existing standard methods often rely on manual inspection of disease symptoms in a small crop area by agronomists or trained surveyors. This is costly, time consuming and prone to error due to the subjectivity of surveyors. Recent advances in unmanned aerial vehicles (UAVs) mounted with hyperspectral image sensors have the potential to address these issues with low cost and high efficiency. This work proposed a new deep convolutional neural network (DCNN) based approach for automated crop disease detection using very high spatial resolution hyperspectral images captured with UAVs. The proposed model introduced multiple Inception-Resnet layers for feature extraction and was optimized to establish the most suitable depth and width of the network. Benefiting from the ability of convolution layers to handle three-dimensional data, the model used both spatial and spectral information for yellow rust detection. The model was calibrated with hyperspectral imagery collected by UAVs in five different dates across a whole crop cycle over a well-controlled field experiment with healthy and rust infected wheat plots. Its performance was compared across sampling dates and with random forest, a representative of traditional classification methods in which only spectral information was used. It was found that the method has high performance across all the growing cycle, particularly at late stages of the disease spread. The overall accuracy of the proposed model (0.85) was higher than that of the random forest classifier (0.77). These results showed that combining both spectral and spatial information is a suitable approach to improving the accuracy of crop disease detection with high resolution UAV hyperspectral images.
KW  - winter wheat
KW  - yellow rust
KW  - crop disease
KW  - unmanned aerial vehicle
KW  - hyperspectral
KW  - deep learning
KW  - classification
DO  - 10.3390/rs11131554
ER  -
TY  - EJOU
AU  - Nuijten, Rik J. G.
AU  - Kooistra, Lammert
AU  - De Deyn, Gerlinde B.
TI  - Using Unmanned Aerial Systems (UAS) and Object-Based Image Analysis (OBIA) for Measuring Plant-Soil Feedback Effects on Crop Productivity
T2  - Drones

PY  - 2019
VL  - 3
IS  - 3
SN  - 2504-446X

AB  - Unmanned aerial system (UAS) acquired high-resolution optical imagery and object-based image analysis (OBIA) techniques have the potential to provide spatial crop productivity information. In general, plant-soil feedback (PSF) field studies are time-consuming and laborious which constrain the scale at which these studies can be performed. Development of non-destructive methodologies is needed to enable research under actual field conditions and at realistic spatial and temporal scales. In this study, the influence of six winter cover crop (WCC) treatments (monocultures Raphanus sativus, Lolium perenne, Trifolium repens, Vicia sativa and two species mixtures) on the productivity of succeeding endive (Cichorium endivia) summer crop was investigated by estimating crop volume. A three-dimensional surface and terrain model were photogrammetrically reconstructed from UAS imagery, acquired on 1 July 2015 in Wageningen, the Netherlands. Multi-resolution image segmentation (MIRS) and template matching algorithms were used in an integrated workflow to detect individual crops (accuracy = 99.8%) and delineate C. endivia crop covered area (accuracy = 85.4%). Mean crop area (R = 0.61) and crop volume (R = 0.71) estimates had strong positive correlations with in situ measured dry biomass. Productivity differences resulting from the WCC treatments were greater for estimated crop volume in comparison to in situ biomass, the legacy of Raphanus was most beneficial for estimated crop volume. The perennial ryegrass L. perenne treatment resulted in a significantly lower production of C. endivia. The developed workflow has potential for PSF studies as well as precision farming due to its flexibility and scalability. Our findings provide insight into the potential of UAS for determining crop productivity on a large scale.
KW  - remote sensing
KW  - unmanned aerial systems
KW  - object-based image analysis
KW  - plant-soil feedback
KW  - plant productivity
KW  - template matching
KW  - segmentation
KW  - precision agriculture
DO  - 10.3390/drones3030054
ER  -
TY  - EJOU
AU  - Ryu, June-Woo
AU  - Pham, Quoc-Viet
AU  - Luan, Huynh N. T.
AU  - Hwang, Won-Joo
AU  - Kim, Jong-Deok
AU  - Lee, Jung-Tae
TI  - Multi-Access Edge Computing Empowered Heterogeneous Networks: A Novel Architecture and Potential Works
T2  - Symmetry

PY  - 2019
VL  - 11
IS  - 7
SN  - 2073-8994

AB  - One of the most promising approaches to address the mismatch between computation- intensive applications and computation-limited end devices is multi-access edge computing (MEC). To overcome the rapid increase in traffic volume and offload the traffic from macrocells, a massive number of small cells have been deployed, so-called heterogeneous networks (HetNets). Strongly motivated by the close integration of MEC and HetNets, in this paper, we propose an envisioned architecture of MEC-empowered HetNets, where both wireless and wired backhaul solutions are supported, flying base stations (BSs) can be equipped with MEC servers, and mobile users (MUs) need both communication and computation resources for their computationally heavy tasks. Subsequently, we provide the research progress summary of task offloading and resource allocation in the proposed MEC-empowered unmanned aerial vehicle (UAV)-assisted heterogeneous networks. We complete this article by spotlighting key challenges and open future directives for researches.
KW  - computation offloading
KW  - Internet of Things (IoT)
KW  - heterogeneous networks (HetNets)
KW  - multi-access edge computing (MEC)
KW  - non-orthogonal multiple access (NOMA)
KW  - resource allocation
KW  - unmanned aerial vehicles (UAV)
DO  - 10.3390/sym11070842
ER  -
TY  - EJOU
AU  - Kim, Dongil
AU  - Kang, Seokho
TI  - Effect of Irrelevant Variables on Faulty Wafer Detection in Semiconductor Manufacturing
T2  - Energies

PY  - 2019
VL  - 12
IS  - 13
SN  - 1996-1073

AB  - Machine learning has been applied successfully for faulty wafer detection tasks in semiconductor manufacturing. For the tasks, prediction models are built with prior data to predict the quality of future wafers as a function of their precedent process parameters and measurements. In real-world problems, it is common for the data to have a portion of input variables that are irrelevant to the prediction of an output variable. The inclusion of many irrelevant variables negatively affects the performance of prediction models. Typically, prediction models learned by different learning algorithms exhibit different sensitivities with regard to irrelevant variables. Algorithms with low sensitivities are preferred as a first trial for building prediction models, whereas a variable selection procedure is necessarily considered for highly sensitive algorithms. In this study, we investigate the effect of irrelevant variables on three well-known representative learning algorithms that can be applied to both classification and regression tasks: artificial neural network, decision tree (DT), and k-nearest neighbors (k-NN). We analyze the characteristics of these learning algorithms in the presence of irrelevant variables with different model complexity settings. An empirical analysis is performed using real-world datasets collected from a semiconductor manufacturer to examine how the number of irrelevant variables affects the behavior of prediction models trained with different learning algorithms and model complexity settings. The results indicate that the prediction accuracy of k-NN is highly degraded, whereas DT demonstrates the highest robustness in the presence of many irrelevant variables. In addition, a higher model complexity of learning algorithms leads to a higher sensitivity to irrelevant variables.
KW  - faulty wafer detection
KW  - semiconductor manufacturing
KW  - irrelevant variable
KW  - supervised learning
KW  - prediction model
DO  - 10.3390/en12132530
ER  -
TY  - EJOU
AU  - Zhang, Jianming
AU  - Lu, Chaoquan
AU  - Wang, Jin
AU  - Wang, Lei
AU  - Yue, Xiao-Guang
TI  - Concrete Cracks Detection Based on FCN with Dilated Convolution
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 13
SN  - 2076-3417

AB  - In civil engineering, the stability of concrete is of great significance to safety of people&rsquo;s life and property, so it is necessary to detect concrete damage effectively. In this paper, we treat crack detection on concrete surface as a semantic segmentation task that distinguishes background from crack at the pixel level. Inspired by Fully Convolutional Networks (FCN), we propose a full convolution network based on dilated convolution for concrete crack detection, which consists of an encoder and a decoder. Specifically, we first used the residual network to extract the feature maps of the input image, designed the dilated convolutions with different dilation rates to extract the feature maps of different receptive fields, and fused the extracted features from multiple branches. Then, we exploited the stacked deconvolution to do up-sampling operator in the fused feature maps. Finally, we used the SoftMax function to classify the feature maps at the pixel level. In order to verify the validity of the model, we introduced the commonly used evaluation indicators of semantic segmentation: Pixel Accuracy (PA), Mean Pixel Accuracy (MPA), Mean Intersection over Union (MIoU), and Frequency Weighted Intersection over Union (FWIoU). The experimental results show that the proposed model converges faster and has better generalization performance on the test set by introducing dilated convolutions with different dilation rates and a multi-branch fusion strategy. Our model has a PA of 96.84%, MPA of 92.55%, MIoU of 86.05% and FWIoU of 94.22% on the test set, which is superior to other models.
KW  - FCN
KW  - crack detection
KW  - residual network
KW  - dilated convolution
KW  - semantic segmentation
DO  - 10.3390/app9132686
ER  -
TY  - EJOU
AU  - Lee, SangSik
AU  - Jeong, YiNa
AU  - Son, SuRak
AU  - Lee, ByungKwan
TI  - A Self-Predictable Crop Yield Platform (SCYP) Based On Crop Diseases Using Deep Learning
T2  - Sustainability

PY  - 2019
VL  - 11
IS  - 13
SN  - 2071-1050

AB  - This paper proposes a self-predictable crop yield platform (SCYP) based on crop diseases using deep learning that collects weather information (temperature, humidity, sunshine, precipitation, etc.) and farm status information (harvest date, disease information, crop status, ground temperature, etc.), diagnoses crop diseases by using convolutional neural network (CNN), and predicts crop yield based on factors such as climate change, crop diseases, and others by using artificial neural network (ANN). The SCYP consists of an image preprocessing module (IPM) to determine crop diseases through the Google Vision API and image resizing, a crop disease diagnosis module (CDDM) based on CNN to diagnose the types and extent of crop diseases through photographs, and a crop yield prediction module (CYPM) based on ANN by using information of crop diseases, remaining time until harvest (based on the date), current temperature, humidity and precipitation (amount of snowfall) in the area, sunshine amount, ground temperature, atmospheric pressure, moisture evaporation in the ground, etc. Four experiments were conducted to verify the efficiency of the SCYP. In the CDMM, the accuracy and operation time of each model were measured using three neural network models: CNN, region-CNN(R-CNN), and you only look once (YOLO). In the CYPM, rectified linear unit (ReLU), Sigmoid, and Step activation functions were compared to measure ANN accuracy. The accuracy of CNN was about 3.5% higher than that of R-CNN and about 5.4% higher than that of YOLO. The operation time of CNN was about 37 s less than that of R-CNN and about 72 s less than that of YOLO. The CDDM had slightly less operation time, but in this paper, we prefer accuracy over operation time to diagnose crop diseases efficiently and accurately. When the activation function of the ANN used in the CYPM was ReLU, the accuracy of the ANN was 2% higher than that of Sigmoid and 7% higher than that of Step. The CYPM prediction was about 34% more accurate when using multiple diseases than when not using them. Therefore, the SCYP can predict farm yields more accurately than traditional methods.
KW  - crop disease diagnosis
KW  - yield prediction
KW  - CNN
KW  - ANN
KW  - image preprocessing
DO  - 10.3390/su11133637
ER  -
TY  - EJOU
AU  - Chen, Yang
AU  - Lee, Won S.
AU  - Gan, Hao
AU  - Peres, Natalia
AU  - Fraisse, Clyde
AU  - Zhang, Yanchao
AU  - He, Yong
TI  - Strawberry Yield Prediction Based on a Deep Neural Network Using High-Resolution Aerial Orthoimages
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 13
SN  - 2072-4292

AB  - Strawberry growers in Florida suffer from a lack of efficient and accurate yield forecasts for strawberries, which would allow them to allocate optimal labor and equipment, as well as other resources for harvesting, transportation, and marketing. Accurate estimation of the number of strawberry flowers and their distribution in a strawberry field is, therefore, imperative for predicting the coming strawberry yield. Usually, the number of flowers and their distribution are estimated manually, which is time-consuming, labor-intensive, and subjective. In this paper, we develop an automatic strawberry flower detection system for yield prediction with minimal labor and time costs. The system used a small unmanned aerial vehicle (UAV) (DJI Technology Co., Ltd., Shenzhen, China) equipped with an RGB (red, green, blue) camera to capture near-ground images of two varieties (Sensation and Radiance) at two different heights (2 m and 3 m) and built orthoimages of a 402 m2 strawberry field. The orthoimages were automatically processed using the Pix4D software and split into sequential pieces for deep learning detection. A faster region-based convolutional neural network (R-CNN), a state-of-the-art deep neural network model, was chosen for the detection and counting of the number of flowers, mature strawberries, and immature strawberries. The mean average precision (mAP) was 0.83 for all detected objects at 2 m heights and 0.72 for all detected objects at 3 m heights. We adopted this model to count strawberry flowers in November and December from 2 m aerial images and compared the results with a manual count. The average deep learning counting accuracy was 84.1% with average occlusion of 13.5%. Using this system could provide accurate counts of strawberry flowers, which can be used to forecast future yields and build distribution maps to help farmers observe the growth cycle of strawberry fields.
KW  - strawberry yield prediction
KW  - unmanned aerial vehicle
KW  - orthoimages
KW  - deep neural network
KW  - distribution map
DO  - 10.3390/rs11131584
ER  -
TY  - EJOU
AU  - Li, Yunwang
AU  - Dai, Sumei
AU  - Shi, Yong
AU  - Zhao, Lala
AU  - Ding, Minghua
TI  - Navigation Simulation of a Mecanum Wheel Mobile Robot Based on an Improved A* Algorithm in Unity3D
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 13
SN  - 1424-8220

AB  - Computer simulation is an effective means for the research of robot navigation algorithms. In order to implement real-time, three-dimensional, and visual navigation algorithm simulation, a method of algorithm simulation based on secondary development of Unity3D is proposed. With this method, a virtual robot prototype can be created quickly with the imported 3D robot model, virtual joints, and virtual sensors, and then the navigation simulation can be carried out using the virtual prototype with the algorithm script in the virtual environment. Firstly, the scripts of the virtual revolute joint, virtual LiDAR sensors, and terrain environment are written. Secondly, the A* algorithm is improved for navigation in unknown 3D space. Thirdly, taking the Mecanum wheel mobile robot as an example, the 3D robot model is imported into Unity3D, and the virtual joint, sensor, and navigation algorithm scripts are added to the model. Then, the navigation is simulated in static and dynamic environments using a virtual prototype. Finally, the navigation tests of the physical robot are carried out in the physical environment, and the test trajectory is compared with the simulation trajectory. The simulation and test results validate the algorithm simulation method based on the redevelopment of Unity3d, showing that it is feasible, efficient, and flexible.
KW  - navigation simulation
KW  - path planning
KW  - improved A* algorithm
KW  - Unity3D
KW  - Mecanum wheel robot
DO  - 10.3390/s19132976
ER  -
TY  - EJOU
AU  - Dong, Yu
AU  - Yan, Huimin
AU  - Wang, Na
AU  - Huang, Mei
AU  - Hu, Yunfeng
TI  - Automatic Identification of Shrub-Encroached Grassland in the Mongolian Plateau Based on UAS Remote Sensing
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 13
SN  - 2072-4292

AB  - Recently, the increasing shrub-encroached grassland in the Mongolian Plateau partly indicates grassland quality decline and degradation. Accurate shrub identification and regional difference analysis in shrub-encroached grassland are significant for ecological degradation research. Object-oriented filter (OOF) and digital surface model (DSM)-digital terrain model (DTM) analyses were combined to establish a high-accuracy automatic shrub identification algorithm (CODA), which made full use of remote sensing products by unmanned aircraft systems (UASs). The results show that: (1) The overall accuracy of CODA in the Grain for Green test area is 89.96%, which is higher than that of OOF (84.52%) and DSM-DTM (78.44%), mainly due to the effective elimination of interference factors (such as shrub-like highland, well-grown grassland in terrain-depression area, etc.) by CODA. (2) The accuracy (87.5%) of CODA in the typical steppe test area is lower than that (92.5%) in the desert steppe test area, which may be related to the higher community structure complexity of typical steppe. Besides, the shrub density is smaller, and the regional difference is more massive in the typical steppe test area. (3) The ground sampling distance for best CODA accuracy in the Grain for Green test area is about 15 cm, while it is below 3 cm in the typical and desert steppe test area.
KW  - object-oriented filter
KW  - digital orthophoto map
KW  - digital surface model
KW  - excess green minus excess red (ExG-ExR)
KW  - Hough circles
DO  - 10.3390/rs11131623
ER  -
TY  - EJOU
AU  - Jalil, Bushra
AU  - Leone, Giuseppe R.
AU  - Martinelli, Massimo
AU  - Moroni, Davide
AU  - Pascali, Maria A.
AU  - Berton, Andrea
TI  - Fault Detection in Power Equipment via an Unmanned Aerial System Using Multi Modal Data
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 13
SN  - 1424-8220

AB  - The power transmission lines are the link between power plants and the points of consumption, through substations. Most importantly, the assessment of damaged aerial power lines and rusted conductors is of extreme importance for public safety; hence, power lines and associated components must be periodically inspected to ensure a continuous supply and to identify any fault and defect. To achieve these objectives, recently, Unmanned Aerial Vehicles (UAVs) have been widely used; in fact, they provide a safe way to bring sensors close to the power transmission lines and their associated components without halting the equipment during the inspection, and reducing operational cost and risk. In this work, a drone, equipped with multi-modal sensors, captures images in the visible and infrared domain and transmits them to the ground station. We used state-of-the-art computer vision methods to highlight expected faults (i.e., hot spots) or damaged components of the electrical infrastructure (i.e., damaged insulators). Infrared imaging, which is invariant to large scale and illumination changes in the real operating environment, supported the identification of faults in power transmission lines; while a neural network is adapted and trained to detect and classify insulators from an optical video stream. We demonstrate our approach on data captured by a drone in Parma, Italy.
KW  - image analysis
KW  - RGB images
KW  - infrared images
KW  - wire detection
KW  - unmanned aerial vehicles
KW  - object detection
KW  - neural networks
DO  - 10.3390/s19133014
ER  -
TY  - EJOU
AU  - Roldán, Juan J.
AU  - Díaz-Maroto, Víctor
AU  - Real, Javier
AU  - Palafox, Pablo R.
AU  - Valente, João
AU  - Garzón, Mario
AU  - Barrientos, Antonio
TI  - Press Start to Play: Classifying Multi-Robot Operators and Predicting Their Strategies through a Videogame
T2  - Robotics

PY  - 2019
VL  - 8
IS  - 3
SN  - 2218-6581

AB  - One of the active challenges in multi-robot missions is related to managing operator workload and situational awareness. Currently, the operators are trained to use interfaces, but in the near future this can be turned inside out: the interfaces will adapt to operators so as to facilitate their tasks. To this end, the interfaces should manage models of operators and adapt the information to their states and preferences. This work proposes a videogame-based approach to classify operator behavior and predict their actions in order to improve teleoperated multi-robot missions. First, groups of operators are generated according to their strategies by means of clustering algorithms. Second, the operators&rsquo; strategies are predicted, taking into account their models. Multiple information sources and modeling methods are used to determine the approach that maximizes the mission goal. The results demonstrate that predictions based on previous data from single operators increase the probability of success in teleoperated multi-robot missions by 19%, whereas predictions based on operator clusters increase this probability of success by 28%.
KW  - robotics
KW  - multi-robot mission
KW  - operator
KW  - modeling, clustering
KW  - prediction
KW  - adaptive interface
KW  - situational awareness
KW  - workload
DO  - 10.3390/robotics8030053
ER  -
TY  - EJOU
AU  - Fuentes, Sigfredo
AU  - Chacon, Gabriela
AU  - Torrico, Damir D.
AU  - Zarate, Andrea
AU  - Gonzalez Viejo, Claudia
TI  - Spatial Variability of Aroma Profiles of Cocoa Trees Obtained through Computer Vision and Machine Learning Modelling: A Cover Photography and High Spatial Remote Sensing Application
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 14
SN  - 1424-8220

AB  - Cocoa is an important commodity crop, not only to produce chocolate, one of the most complex products from the sensory perspective, but one that commonly grows in developing countries close to the tropics. This paper presents novel techniques applied using cover photography and a novel computer application (VitiCanopy) to assess the canopy architecture of cocoa trees in a commercial plantation in Queensland, Australia. From the cocoa trees monitored, pod samples were collected, fermented, dried, and ground to obtain the aroma profile per tree using gas chromatography. The canopy architecture data were used as inputs in an artificial neural network (ANN) algorithm, with the aroma profile, considering six main aromas, as targets. The ANN model rendered high accuracy (correlation coefficient (R) = 0.82; mean squared error (MSE) = 0.09) with no overfitting. The model was then applied to an aerial image of the whole cocoa field studied to produce canopy vigor, and aroma profile maps up to the tree-by-tree scale. The tool developed could significantly aid the canopy management practices in cocoa trees, which have a direct effect on cocoa quality.
KW  - leaf area index
KW  - cocoa beans
KW  - volatile compounds
KW  - artificial neural networks
KW  - VitiCanopy app
DO  - 10.3390/s19143054
ER  -
TY  - EJOU
AU  - Holman, Fenner H.
AU  - Riche, Andrew B.
AU  - Castle, March
AU  - Wooster, Martin J.
AU  - Hawkesford, Malcolm J.
TI  - Radiometric Calibration of ‘Commercial off the Shelf’ Cameras for UAV-Based High-Resolution Temporal Crop Phenotyping of Reflectance and NDVI
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 14
SN  - 2072-4292

AB  - Vegetation indices, such as the Normalised Difference Vegetation Index (NDVI), are common metrics used for measuring traits of interest in crop phenotyping. However, traditional measurements of these indices are often influenced by multiple confounding factors such as canopy cover and reflectance of underlying soil, visible in canopy gaps. Digital cameras mounted to Unmanned Aerial Vehicles offer the spatial resolution to investigate these confounding factors, however incomplete methods for radiometric calibration into reflectance units limits how the data can be applied to phenotyping. In this study, we assess the applicability of very high spatial resolution (1 cm) UAV-based imagery taken with commercial off the shelf (COTS) digital cameras for both deriving calibrated reflectance imagery, and isolating vegetation canopy reflectance from that of the underlying soil. We present new methods for successfully normalising COTS camera imagery for exposure and solar irradiance effects, generating multispectral (RGB-NIR) orthomosaics of our target field-based wheat crop trial. Validation against measurements from a ground spectrometer showed good results for reflectance (R2 &ge; 0.6) and NDVI (R2 &ge; 0.88). Application of imagery collected through the growing season and masked using the Excess Green Red index was used to assess the impact of canopy cover on NDVI measurements. Results showed the impact of canopy cover artificially reducing plot NDVI values in the early season, where canopy development is low.
KW  - Unmanned Aerial Vehicle
KW  - reflectance
KW  - radiometric calibration
KW  - NDVI
KW  - digital cameras
KW  - canopy reflectance
DO  - 10.3390/rs11141657
ER  -
TY  - EJOU
AU  - Nyandwi, Emmanuel
AU  - Koeva, Mila
AU  - Kohli, Divyani
AU  - Bennett, Rohan
TI  - Comparing Human Versus Machine-Driven Cadastral Boundary Feature Extraction
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 14
SN  - 2072-4292

AB  - The objective to fast-track the mapping and registration of large numbers of unrecorded land rights globally has led to the experimental application of Artificial Intelligence in the domain of land administration, and specifically the application of automated visual cognition techniques for cadastral mapping tasks. In this research, we applied and compared the ability of rule-based systems within Object-Based Image Analysis (OBIA), as opposed to human analysis, to extract visible cadastral boundaries from very high-resolution World View-2 images, in both rural and urban settings. From our experiments, machine-based techniques were able to automatically delineate a good proportion of rural parcels with explicit polygons where the correctness of the automatically extracted boundaries was 47.4% against 74.24% for humans and the completeness of 45% for the machine compared to 70.4% for humans. On the contrary, in the urban area, automatic results were counterintuitive: even though urban plots and buildings are clearly marked with visible features such as fences, roads and tacitly perceptible to eyes, automation resulted in geometrically and topologically poorly structured data. Thus, these could neither be geometrically compared with human digitisation, nor actual cadastral data from the field. The results of this study provide an updated snapshot with regards to the performance of contemporary machine-driven feature extraction techniques compared to conventional manual digitising. In our methodology, using an iterative approach of segmentation and classification, we demonstrated how to overcome the weaknesses of having undesirable segments due to intra-parcel and inter-parcel variability, when using segmentation approaches for cadastral feature delineation. We also demonstrated how we can easily implement a geometric comparison framework within the Esri&rsquo;s ArcGIS software environment and firmly believe the developed methodology can be reproduced.
KW  - cadastral intelligence
KW  - manual digitisation
KW  - expert parameterisation
KW  - land administration
KW  - land management
KW  - automatic feature extraction
KW  - Object-Based Image Analysis
DO  - 10.3390/rs11141662
ER  -
TY  - EJOU
AU  - Bui, Xuan-Nam
AU  - Lee, Chang W.
AU  - Nguyen, Hoang
AU  - Bui, Hoang-Bac
AU  - Long, Nguyen Q.
AU  - Le, Qui-Thao
AU  - Nguyen, Van-Duc
AU  - Nguyen, Ngoc-Bich
AU  - Moayedi, Hossein
TI  - Estimating PM10 Concentration from Drilling Operations in Open-Pit Mines Using an Assembly of SVR and PSO
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 14
SN  - 2076-3417

AB  - Dust is one of the components causing heavy environmental pollution in open-pit mines, especially PM10. Some pathologies related to the lung, respiratory system, and occupational diseases have been identified due to the effects of PM10 in open-pit mines. Therefore, the prediction and control of PM10 concentration in the production process are necessary for environmental and health protection. In this study, PM10 concentration from drilling operations in the Coc Sau open-pit coal mine (Vietnam) was investigated and considered through a database including 245 datasets collected. A novel hybrid artificial intelligence model was developed based on support vector regression (SVR) and a swarm optimization algorithm (i.e., particle swarm optimization (PSO)), namely PSO-SVR, for estimating PM10 concentration from drilling operations at the mine. Polynomial (P), radial basis function (RBF), and linear (L) kernel functions were considered and applied to the development of the PSO-SVR models in the present study, abbreviated as PSO-SVR-P, PSO-SVR-RBF, and PSO-SVR-L. Also, three benchmark artificial intelligence techniques, such as k-nearest neighbors (KNN), random forest (RF), and classification and regression trees (CART), were applied and developed for estimating PM10 concentration and then compared with the PSO-SVR models. Root-mean-squared error (RMSE) and determination coefficient (R2) were used as the statistical criteria for evaluating the performance of the developed models. The results exhibited that the PSO algorithm had an essential role in the optimization of the hyper-parameters of the SVR models. The PSO-SVR models (i.e., PSO-SVR-L, PSO-SVR-P, and PSO-SVR-RBF) had higher performance levels than the other models (i.e., RF, CART, and KNN) with an RMSE of 0.040, 0.042, and 0.043; and R2 of 0.954, 0.948, and 0.946; for the PSO-SVR-L, PSO-SVR-P, and PSO-SVR-RBF models, respectively. Of these PSO-SVR models, the PSO-SVR-L model was the most dominant model with an RMSE of 0.040 and R2 of 0.954. The remaining three benchmark models (i.e., RF, CART, and KNN) yielded a more unsatisfactory performance with an RMSE of 0.060, 0.052, and 0.067; and R2 of 0.894, 0.924, and 0.867, for the RF, CART, and KNN models, respectively. Furthermore, the findings of this study demonstrated that the density of rock mass, moisture content, and the penetration rate of the drill were essential parameters on the PM10 concentration caused by drilling operations in open-pit mines.
KW  - meta-heuristic algorithm
KW  - PM10 concentration
KW  - drilling operation
KW  - artificial intelligence
KW  - open-pit coal mine
DO  - 10.3390/app9142806
ER  -
TY  - EJOU
AU  - Peng, Yahui
AU  - Liu, Xiaochen
AU  - Shen, Chong
AU  - Huang, Haoqian
AU  - Zhao, Donghua
AU  - Cao, Huiliang
AU  - Guo, Xiaoting
TI  - An Improved Optical Flow Algorithm Based on Mask-R-CNN and K-Means for Velocity Calculation
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 14
SN  - 2076-3417

AB  - Aiming at enhancing the accuracy and reliability of velocity calculation in vision navigation, an improved method is proposed in this paper. The method integrates Mask-R-CNN (Mask Region-based Convolutional Neural Network) and K-Means with the pyramid Lucas Kanade algorithm in order to reduce the harmful effect of moving objects on velocity calculation. Firstly, Mask-R-CNN is used to recognize the objects which have motions relative to the ground and covers them with masks to enhance the similarity between pixels and to reduce the impacts of the noisy moving pixels. Then, the pyramid Lucas Kanade algorithm is used to calculate the optical flow value. Finally, the value is clustered by the K-Means algorithm to abandon the outliers, and vehicle velocity is calculated by the processed optical flow. The prominent advantages of the proposed algorithm are (i) decreasing the bad impacts to velocity calculation, due to the objects which have relative motions; (ii) obtaining the correct optical flow sets and velocity calculation outputs with less fluctuation; and (iii) the applicability enhancement of the optical flow algorithm in complex navigation environment. The proposed algorithm is tested by actual experiments. Results with superior precision and reliability show the feasibility and effectiveness of the proposed method for vehicle velocity calculation in vision navigation system.
KW  - velocity calculation
KW  - optical flow
KW  - pyramid LK
KW  - Mask-R-CNN
KW  - clustering algorithm
DO  - 10.3390/app9142808
ER  -
TY  - EJOU
AU  - Zhou, Chengquan
AU  - Ye, Hongbao
AU  - Hu, Jun
AU  - Shi, Xiaoyan
AU  - Hua, Shan
AU  - Yue, Jibo
AU  - Xu, Zhifu
AU  - Yang, Guijun
TI  - Automated Counting of Rice Panicle by Applying Deep Learning Model to Images from Unmanned Aerial Vehicle Platform
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 14
SN  - 1424-8220

AB  - The number of panicles per unit area is a common indicator of rice yield and is of great significance to yield estimation, breeding, and phenotype analysis. Traditional counting methods have various drawbacks, such as long delay times and high subjectivity, and they are easily perturbed by noise. To improve the accuracy of rice detection and counting in the field, we developed and implemented a panicle detection and counting system that is based on improved region-based fully convolutional networks, and we use the system to automate rice-phenotype measurements. The field experiments were conducted in target areas to train and test the system and used a rotor light unmanned aerial vehicle equipped with a high-definition RGB camera to collect images. The trained model achieved a precision of 0.868 on a held-out test set, which demonstrates the feasibility of this approach. The algorithm can deal with the irregular edge of the rice panicle, the significantly different appearance between the different varieties and growing periods, the interference due to color overlapping between panicle and leaves, and the variations in illumination intensity and shading effects in the field. The result is more accurate and efficient recognition of rice-panicles, which facilitates rice breeding. Overall, the approach of training deep learning models on increasingly large and publicly available image datasets presents a clear path toward smartphone-assisted crop disease diagnosis on a global scale.
KW  - rice panicle counting
KW  - UAV platform
KW  - deep learning
KW  - yield estimation
DO  - 10.3390/s19143106
ER  -
TY  - EJOU
AU  - Fu, Yongyong
AU  - Ye, Ziran
AU  - Deng, Jinsong
AU  - Zheng, Xinyu
AU  - Huang, Yibo
AU  - Yang, Wu
AU  - Wang, Yaohua
AU  - Wang, Ke
TI  - Finer Resolution Mapping of Marine Aquaculture Areas Using WorldView-2 Imagery and a Hierarchical Cascade Convolutional Neural Network
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 14
SN  - 2072-4292

AB  - Marine aquaculture plays an important role in seafood supplement, economic development, and coastal ecosystem service provision. The precise delineation of marine aquaculture areas from high spatial resolution (HSR) imagery is vital for the sustainable development and management of coastal marine resources. However, various sizes and detailed structures of marine objects make it difficult for accurate mapping from HSR images by using conventional methods. Therefore, this study attempts to extract marine aquaculture areas by using an automatic labeling method based on the convolutional neural network (CNN), i.e., an end-to-end hierarchical cascade network (HCNet). Specifically, for marine objects of various sizes, we propose to improve the classification performance by utilizing multi-scale contextual information. Technically, based on the output of a CNN encoder, we employ atrous convolutions to capture multi-scale contextual information and aggregate them in a hierarchical cascade way. Meanwhile, for marine objects with detailed structures, we propose to refine the detailed information gradually by using a series of long-span connections with fine resolution features from the shallow layers. In addition, to decrease the semantic gaps between features in different levels, we propose to refine the feature space (i.e., channel and spatial dimensions) using an attention-based module. Experimental results show that our proposed HCNet can effectively identify and distinguish different kinds of marine aquaculture, with 98% of overall accuracy. It also achieves better classification performance compared with object-based support vector machine and state-of-the-art CNN-based methods, such as FCN-32s, U-Net, and DeeplabV2. Our developed method lays a solid foundation for the intelligent monitoring and management of coastal marine resources.
KW  - marine aquaculture areas
KW  - WorldView-2 imagery
KW  - fully convolutional network (FCN)
KW  - land-use and land-cover (LULC) mapping
DO  - 10.3390/rs11141678
ER  -
TY  - EJOU
AU  - Farooq, Adnan
AU  - Jia, Xiuping
AU  - Hu, Jiankun
AU  - Zhou, Jun
TI  - Multi-Resolution Weed Classification via Convolutional Neural Network and Superpixel Based Local Binary Pattern Using Remote Sensing Images
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 14
SN  - 2072-4292

AB  - Automatic weed detection and classification faces the challenges of large intraclass variation and high spectral similarity to other vegetation. With the availability of new high-resolution remote sensing data from various platforms and sensors, it is possible to capture both spectral and spatial characteristics of weed species at multiple scales. Effective multi-resolution feature learning is then desirable to extract distinctive intensity, texture and shape features of each category of weed to enhance the weed separability. We propose a feature extraction method using a Convolutional Neural Network (CNN) and superpixel based Local Binary Pattern (LBP). Both middle and high level spatial features are learned using the CNN. Local texture features from superpixel-based LBP are extracted, and are also used as input to Support Vector Machines (SVM) for weed classification. Experimental results on the hyperspectral and remote sensing datasets verify the effectiveness of the proposed method, and show that it outperforms several feature extraction approaches.
KW  - hyperspectral images
KW  - weed mapping
KW  - multi-resolution
KW  - local binary pattern (LBP)
KW  - convolutional neural network (CNN)
DO  - 10.3390/rs11141692
ER  -
TY  - EJOU
AU  - Cao, Shuang
AU  - Yu, Yongtao
AU  - Guan, Haiyan
AU  - Peng, Daifeng
AU  - Yan, Wanqian
TI  - Affine-Function Transformation-Based Object Matching for Vehicle Detection from Unmanned Aerial Vehicle Imagery
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 14
SN  - 2072-4292

AB  - Vehicle detection from remote sensing images plays a significant role in transportation related applications. However, the scale variations, orientation variations, illumination variations, and partial occlusions of vehicles, as well as the image qualities, bring great challenges for accurate vehicle detection. In this paper, we present an affine-function transformation-based object matching framework for vehicle detection from unmanned aerial vehicle (UAV) images. First, meaningful and non-redundant patches are generated through a superpixel segmentation strategy. Then, the affine-function transformation-based object matching framework is applied to a vehicle template and each of the patches for vehicle existence estimation. Finally, vehicles are detected and located after matching cost thresholding, vehicle location estimation, and multiple response elimination. Quantitative evaluations on two UAV image datasets show that the proposed method achieves an average completeness, correctness, quality, and F1-measure of 0.909, 0.969, 0.883, and 0.938, respectively. Comparative studies also demonstrate that the proposed method achieves compatible performance with the Faster R-CNN and outperforms the other eight existing methods in accurately detecting vehicles of various conditions.
KW  - vehicle detection
KW  - object matching
KW  - superpixel segmentation
KW  - unmanned aerial vehicle
KW  - remote sensing imagery
DO  - 10.3390/rs11141708
ER  -
TY  - EJOU
AU  - Jozdani, Shahab E.
AU  - Johnson, Brian A.
AU  - Chen, Dongmei
TI  - Comparing Deep Neural Networks, Ensemble Classifiers, and Support Vector Machine Algorithms for Object-Based Urban Land Use/Land Cover Classification
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 14
SN  - 2072-4292

AB  - With the advent of high-spatial resolution (HSR) satellite imagery, urban land use/land cover (LULC) mapping has become one of the most popular applications in remote sensing. Due to the importance of context information (e.g., size/shape/texture) for classifying urban LULC features, Geographic Object-Based Image Analysis (GEOBIA) techniques are commonly employed for mapping urban areas. Regardless of adopting a pixel- or object-based framework, the selection of a suitable classifier is of critical importance for urban mapping. The popularity of deep learning (DL) (or deep neural networks (DNNs)) for image classification has recently skyrocketed, but it is still arguable if, or to what extent, DL methods can outperform other state-of-the art ensemble and/or Support Vector Machines (SVM) algorithms in the context of urban LULC classification using GEOBIA. In this study, we carried out an experimental comparison among different architectures of DNNs (i.e., regular deep multilayer perceptron (MLP), regular autoencoder (RAE), sparse, autoencoder (SAE), variational autoencoder (AE), convolutional neural networks (CNN)), common ensemble algorithms (Random Forests (RF), Bagging Trees (BT), Gradient Boosting Trees (GB), and Extreme Gradient Boosting (XGB)), and SVM to investigate their potential for urban mapping using a GEOBIA approach. We tested the classifiers on two RS images (with spatial resolutions of 30 cm and 50 cm). Based on our experiments, we drew three main conclusions: First, we found that the MLP model was the most accurate classifier. Second, unsupervised pretraining with the use of autoencoders led to no improvement in the classification result. In addition, the small difference in the classification accuracies of MLP from those of other models like SVM, GB, and XGB classifiers demonstrated that other state-of-the-art machine learning classifiers are still versatile enough to handle mapping of complex landscapes. Finally, the experiments showed that the integration of CNN and GEOBIA could not lead to more accurate results than the other classifiers applied.
KW  - remote sensing
KW  - high-spatial resolution imagery
KW  - deep learning
KW  - GEOBIA
KW  - land use/cover classification
DO  - 10.3390/rs11141713
ER  -
TY  - EJOU
AU  - Kim, Whui
AU  - Jung, Woo-Sung
AU  - Choi, Hyun K.
TI  - Lightweight Driver Monitoring System Based on Multi-Task Mobilenets
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 14
SN  - 1424-8220

AB  - Research on driver status recognition has been actively conducted to reduce fatal crashes caused by the driver&rsquo;s distraction and drowsiness. As in many other research areas, deep-learning-based algorithms are showing excellent performance for driver status recognition. However, despite decades of research in the driver status recognition area, the visual image-based driver monitoring system has not been widely used in the automobile industry. This is because the system requires high-performance processors, as well as has a hierarchical structure in which each procedure is affected by an inaccuracy from the previous procedure. To avoid using a hierarchical structure, we propose a method using Mobilenets without the functions of face detection and tracking and show this method is enabled to recognize facial behaviors that indicate the driver&rsquo;s distraction. However, frames per second processed by Mobilenets with a Raspberry pi, one of the single-board computers, is not enough to recognize the driver status. To alleviate this problem, we propose a lightweight driver monitoring system using a resource sharing device in a vehicle (e.g., a driver&rsquo;s mobile phone). The proposed system is based on Multi-Task Mobilenets (MT-Mobilenets), which consists of the Mobilenets&rsquo; base and multi-task classifier. The three Softmax regressions of the multi-task classifier help one Mobilenets base recognize facial behaviors related to the driver status, such as distraction, fatigue, and drowsiness. The proposed system based on MT-Mobilenets improved the accuracy of the driver status recognition with Raspberry Pi by using one additional device.
KW  - lightweight
KW  - driver assistance
KW  - drowsiness
KW  - fatigue
KW  - distraction
KW  - PERCLOS
KW  - ECT
KW  - ECD
KW  - single-board computer
KW  - SBC
KW  - Raspberry pi
DO  - 10.3390/s19143200
ER  -
TY  - EJOU
AU  - Tao, Jiadong
AU  - Yin, Zhong
AU  - Liu, Lei
AU  - Tian, Ying
AU  - Sun, Zhanquan
AU  - Zhang, Jianhua
TI  - Individual-Specific Classification of Mental Workload Levels Via an Ensemble Heterogeneous Extreme Learning Machine for EEG Modeling
T2  - Symmetry

PY  - 2019
VL  - 11
IS  - 7
SN  - 2073-8994

AB  - In a human&ndash;machine cooperation system, assessing the mental workload (MW) of the human operator is quite crucial to maintaining safe operation conditions. Among various MW indicators, electroencephalography (EEG) signals are particularly attractive because of their high temporal resolution and sensitivity to the occupation of working memory. However, the individual difference of the EEG feature distribution may impair the machine-learning based MW classifier. In this paper, we employed a fast-training neural network, extreme learning machine (ELM), as the basis to build an individual-specific classifier ensemble to recognize binary MW. To improve the diversity of the classification committee, heterogeneous member classifiers were adopted by fusing multiple ELMs and Bayesian models. Specifically, a deep network structure was applied in each weak model aiming at finding informative EEG feature representations. The structure of hyper-parameters of the proposed heterogeneous ensemble ELM (HE-ELM) was then identified and then its performance was compared against several competitive MW classifiers. We found that the HE-ELM model was superior for improving the individual-specific accuracy of MW assessments.
KW  - electroencephalography
KW  - mental workload
KW  - extreme learning machine
KW  - ensemble learning
DO  - 10.3390/sym11070944
ER  -
TY  - EJOU
AU  - Escobar Villanueva, Jairo R.
AU  - Iglesias Martínez, Luis
AU  - Pérez Montiel, Jhonny I.
TI  - DEM Generation from Fixed-Wing UAV Imaging and LiDAR-Derived Ground Control Points for Flood Estimations
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 14
SN  - 1424-8220

AB  - Geospatial products, such as digital elevation models (DEMs), are important topographic tools for tackling local flood studies. This study investigates the contribution of LiDAR elevation data in DEM generation based on fixed-wing unmanned aerial vehicle (UAV) imaging for flood applications. More specifically, it assesses the accuracy of UAV-derived DEMs using the proposed LiDAR-derived control point (LCP) method in a Structure-from-Motion photogrammetry processing. Also, the flood estimates (volume and area) of the UAV terrain products are compared with a LiDAR-based reference. The applied LCP-georeferencing method achieves an accuracy comparable with other studies. In addition, it has the advantage of using semi-automatic terrain data classification and is readily applicable in flood studies. Lastly, it proves the complementarity between LiDAR and UAV photogrammetry at the local level.
KW  - UAV
KW  - fixed-wing
KW  - LiDAR
KW  - ground control point
KW  - DEM
KW  - accuracy
KW  - floods
DO  - 10.3390/s19143205
ER  -
TY  - EJOU
AU  - Iannace, Gino
AU  - Ciaburro, Giuseppe
AU  - Trematerra, Amelia
TI  - Fault Diagnosis for UAV Blades Using Artificial Neural Network
T2  - Robotics

PY  - 2019
VL  - 8
IS  - 3
SN  - 2218-6581

AB  - In recent years, unmanned aerial vehicles (UAVs) have been used in several fields including, for example, archaeology, cargo transport, conservation, healthcare, filmmaking, hobbies and recreational use. UAVs are aircraft characterized by the absence of a human pilot on board. The extensive use of these devices has highlighted maintenance problems with regard to the propellers, which represent the source of propulsion of the aircraft. A defect in the propellers of a drone can cause the aircraft to fall to the ground and its consequent destruction, and it also constitutes a safety problem for objects and people that are in the range of action of the aircraft. In this study, the measurements of the noise emitted by a UAV were used to build a classification model to detect unbalanced blades in a UAV propeller. To simulate the fault condition, two strips of paper tape were applied to the upper surface of a blade. The paper tape created a substantial modification of the aerodynamics of the blade, and this modification characterized the noise produced by the blade in its rotation. Then, a model based on artificial neural network algorithms was built to detect unbalanced blades in a UAV propeller. This model showed high accuracy (0.9763), indicating a high number of correct detections and suggests the adoption of this tool to verify the operating conditions of a UAV. The test must be performed indoors; from the measurements of the noise produced by the UAV it is possible to identify an imbalance in the propeller blade.
KW  - quadcopter UAV
KW  - artificial neural network
KW  - fault diagnosis
KW  - acoustic measurements
KW  - unbalanced propeller
DO  - 10.3390/robotics8030059
ER  -
TY  - EJOU
AU  - Zhou, Sanzhang
AU  - Kang, Feng
AU  - Li, Wenbin
AU  - Kan, Jiangming
AU  - Zheng, Yongjun
AU  - He, Guojian
TI  - Extracting Diameter at Breast Height with a Handheld Mobile LiDAR System in an Outdoor Environment
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 14
SN  - 1424-8220

AB  - Mobile laser scanning (MLS) is widely used in the mapping of forest environments. It has become important for extracting the parameters of forest trees using the generated environmental map. In this study, a three-dimensional point cloud map of a forest area was generated by using the Velodyne VLP-16 LiDAR system, so as to extract the diameter at breast height (DBH) of individual trees. The Velodyne VLP-16 LiDAR system and inertial measurement units (IMU) were used to construct a mobile measurement platform for generating 3D point cloud maps for forest areas. The 3D point cloud map in the forest area was processed offline, and the ground point cloud was removed by the random sample consensus (RANSAC) algorithm. The trees in the experimental area were segmented by the European clustering algorithm, and the DBH component of the tree point cloud was extracted and projected onto a 2D plane, fitting the DBH of the trees using the RANSAC algorithm in the plane. A three-dimensional point cloud map of 71 trees was generated in the experimental area, and estimated the DBH. The mean and variance of the absolute error were 0.43 cm and 0.50, respectively. The relative error of the whole was 2.27%, the corresponding variance was 15.09, and the root mean square error (RMSE) was 0.70 cm. The experimental results were good and met the requirements of forestry mapping, and the application value and significance were presented.
KW  - mobile laser scanning
KW  - 3D point cloud map
KW  - diameter at breast height
DO  - 10.3390/s19143212
ER  -
TY  - EJOU
AU  - Jakovljevic, Gordana
AU  - Govedarica, Miro
AU  - Alvarez-Taboada, Flor
AU  - Pajic, Vladimir
TI  - Accuracy Assessment of Deep Learning Based Classification of LiDAR and UAV Points Clouds for DTM Creation and Flood Risk Mapping
T2  - Geosciences

PY  - 2019
VL  - 9
IS  - 7
SN  - 2076-3263

AB  - Digital elevation model (DEM) has been frequently used for the reduction and management of flood risk. Various classification methods have been developed to extract DEM from point clouds. However, the accuracy and computational efficiency need to be improved. The objectives of this study were as follows: (1) to determine the suitability of a new method to produce DEM from unmanned aerial vehicle (UAV) and light detection and ranging (LiDAR) data, using a raw point cloud classification and ground point filtering based on deep learning and neural networks (NN); (2) to test the convenience of rebalancing datasets for point cloud classification; (3) to evaluate the effect of the land cover class on the algorithm performance and the elevation accuracy; and (4) to assess the usability of the LiDAR and UAV structure from motion (SfM) DEM in flood risk mapping. In this paper, a new method of raw point cloud classification and ground point filtering based on deep learning using NN is proposed and tested on LiDAR and UAV data. The NN was trained on approximately 6 million points from which local and global geometric features and intensity data were extracted. Pixel-by-pixel accuracy assessment and visual inspection confirmed that filtering point clouds based on deep learning using NN is an appropriate technique for ground classification and producing DEM, as for the test and validation areas, both ground and non-ground classes achieved high recall (&gt;0.70) and high precision values (&gt;0.85), which showed that the two classes were well handled by the model. The type of method used for balancing the original dataset did not have a significant influence in the algorithm accuracy, and it was suggested not to use any of them unless the distribution of the generated and real data set will remain the same. Furthermore, the comparisons between true data and LiDAR and a UAV structure from motion (UAV SfM) point clouds were analyzed, as well as the derived DEM. The root mean square error (RMSE) and the mean average error (MAE) of the DEM were 0.25 m and 0.05 m, respectively, for LiDAR data, and 0.59 m and &ndash;0.28 m, respectively, for UAV data. For all land cover classes, the UAV DEM overestimated the elevation, whereas the LIDAR DEM underestimated it. The accuracy was not significantly different in the LiDAR DEM for the different vegetation classes, while for the UAV DEM, the RMSE increased with the height of the vegetation class. The comparison of the inundation areas derived from true LiDAR and UAV data for different water levels showed that in all cases, the largest differences were obtained for the lowest water level tested, while they performed best for very high water levels. Overall, the approach presented in this work produced DEM from LiDAR and UAV data with the required accuracy for flood mapping according to European Flood Directive standards. Although LiDAR is the recommended technology for point cloud acquisition, a suitable alternative is also UAV SfM in hilly areas.
KW  - DEM
KW  - NN
KW  - deep learning
KW  - classification
KW  - LIDAR
KW  - UAV
KW  - SfM
KW  - point cloud
DO  - 10.3390/geosciences9070323
ER  -
TY  - EJOU
AU  - Cao, Mingwei
AU  - Jia, Wei
AU  - Lv, Zhihan
AU  - Zheng, Liping
AU  - Liu, Xiaoping
TI  - Superpixel-Based Feature Tracking for Structure from Motion
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 15
SN  - 2076-3417

AB  - Feature tracking in image collections significantly affects the efficiency and accuracy of Structure from Motion (SFM). Insufficient correspondences may result in disconnected structures and incomplete components, while the redundant correspondences containing incorrect ones may yield to folded and superimposed structures. In this paper, we present a Superpixel-based feature tracking method for structure from motion. In the proposed method, we first propose to use a joint approach to detect local keypoints and compute descriptors. Second, the superpixel-based approach is used to generate labels for the input image. Third, we combine the Speed Up Robust Feature and binary test in the generated label regions to produce a set of combined descriptors for the detected keypoints. Fourth, the locality-sensitive hash (LSH)-based k nearest neighboring matching (KNN) is utilized to produce feature correspondences, and then the ratio test approach is used to remove outliers from the previous matching collection. Finally, we conduct comprehensive experiments on several challenging benchmarking datasets including highly ambiguous and duplicated scenes. Experimental results show that the proposed method gets better performances with respect to the state of the art methods.
KW  - feature tracking
KW  - superpixel
KW  - structure from motion
KW  - three-dimensional reconstruction
KW  - local feature
KW  - multi-view stereo
DO  - 10.3390/app9152961
ER  -
TY  - EJOU
AU  - Li, Songyang
AU  - Yuan, Fei
AU  - Ata-UI-Karim, Syed T.
AU  - Zheng, Hengbiao
AU  - Cheng, Tao
AU  - Liu, Xiaojun
AU  - Tian, Yongchao
AU  - Zhu, Yan
AU  - Cao, Weixing
AU  - Cao, Qiang
TI  - Combining Color Indices and Textures of UAV-Based Digital Imagery for Rice LAI Estimation
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 15
SN  - 2072-4292

AB  - Leaf area index (LAI) is a fundamental indicator of plant growth status in agronomic and environmental studies. Due to rapid advances in unmanned aerial vehicle (UAV) and sensor technologies, UAV-based remote sensing is emerging as a promising solution for monitoring crop LAI with great flexibility and applicability. This study aimed to determine the feasibility of combining color and texture information derived from UAV-based digital images for estimating LAI of rice (Oryza sativa L.). Rice field trials were conducted at two sites using different nitrogen application rates, varieties, and transplanting methods during 2016 to 2017. Digital images were collected using a consumer-grade UAV after sampling at key growth stages of tillering, stem elongation, panicle initiation and booting. Vegetation color indices (CIs) and grey level co-occurrence matrix-based textures were extracted from mosaicked UAV ortho-images for each plot. As a solution of using indices composed by two different textures, normalized difference texture indices (NDTIs) were calculated by two randomly selected textures. The relationships between rice LAIs and each calculated index were then compared using simple linear regression. Multivariate regression models with different input sets were further used to test the potential of combining CIs with various textures for rice LAI estimation. The results revealed that the visible atmospherically resistant index (VARI) based on three visible bands and the NDTI based on the mean textures derived from the red and green bands were the best for LAI retrieval in the CI and NDTI groups, respectively. Independent accuracy assessment showed that random forest (RF) exhibited the best predictive performance when combining CI and texture inputs (R2 = 0.84, RMSE = 0.87, MAE = 0.69). This study introduces a promising solution of combining color indices and textures from UAV-based digital imagery for rice LAI estimation. Future studies are needed on finding the best operation mode, suitable ground resolution, and optimal predictive methods for practical applications.
KW  - leaf area index (LAI)
KW  - UAV RGB imagery
KW  - color index
KW  - texture
KW  - rice
DO  - 10.3390/rs11151763
ER  -
TY  - EJOU
AU  - Dayananda, Supriya
AU  - Astor, Thomas
AU  - Wijesingha, Jayan
AU  - Chickadibburahalli Thimappa, Subbarayappa
AU  - Dimba Chowdappa, Hanumanthappa
AU  - Mudalagiriyappa
AU  - Nidamanuri, Rama R.
AU  - Nautiyal, Sunil
AU  - Wachendorf, Michael
TI  - Multi-Temporal Monsoon Crop Biomass Estimation Using Hyperspectral Imaging
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 15
SN  - 2072-4292

AB  - Hyperspectral remote sensing is considered to be an effective tool in crop monitoring and estimation of biomass. Many of the previous approaches are from single year or single date measurements, even though the complete crop growth with multiple years would be required for an appropriate estimation of biomass. The aim of this study was to estimate the fresh matter biomass (FMB) by terrestrial hyperspectral imaging of the three crops (lablab, maize and finger millet) under different levels of nitrogen fertiliser and water supply. Further, the importance of the different spectral regions for the estimation of FMB was assessed. The study was conducted in two experimental layouts (rainfed (R) and irrigated (I)) at the University of Agricultural Sciences, Bengaluru, India. Spectral images and the FMB were collected over three years (2016&ndash;2018) during the growing season of the crops. Random forest regression method was applied to build FMB models. R&sup2; validation (R&sup2;val) and relative root mean square error prediction (rRMSEP) was used to evaluate the FMB models. The Generalised model (combination of R and I data) performed better for lablab (R&sup2;val = 0.53, rRMSEP = 13.9%), maize (R&sup2;val = 0.53, rRMSEP = 18.7%) and finger millet (R&sup2;val = 0.46, rRMSEP = 18%) than the separate FMB models for R and I. In the best derived model, the most important variables contributing to the estimation of biomass were in the wavelength ranges of 546&ndash;910 nm (lablab), 750&ndash;794 nm (maize) and 686&ndash;814 nm (finger millet). The deviation of predicted and measured FMB did not differ much among the different levels of N and water supply. However, there was a trend of overestimation at the initial stage and underestimation at the later stages of crop growth.
KW  - Cash crops
KW  - Hyperspectral imaging
KW  - Biomass prediction
KW  - Machine learning
DO  - 10.3390/rs11151771
ER  -
TY  - EJOU
AU  - Salhaoui, Marouane
AU  - Guerrero-González, Antonio
AU  - Arioua, Mounir
AU  - Ortiz, Francisco J.
AU  - El Oualkadi, Ahmed
AU  - Torregrosa, Carlos L.
TI  - Smart Industrial IoT Monitoring and Control System Based on UAV and Cloud Computing Applied to a Concrete Plant
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 15
SN  - 1424-8220

AB  - Unmanned aerial vehicles (UAVs) are now considered one of the best remote sensing techniques for gathering data over large areas. They are now being used in the industry sector as sensing tools for proactively solving or preventing many issues, besides quantifying production and helping to make decisions. UAVs are a highly consistent technological platform for efficient and cost-effective data collection and event monitoring. The industrial Internet of things (IIoT) sends data from systems that monitor and control the physical world to data processing systems that cloud computing has shown to be important tools for meeting processing requirements. In fog computing, the IoT gateway links different objects to the internet. It can operate as a joint interface for different networks and support different communication protocols. A great deal of effort has been put into developing UAVs and multi-UAV systems. This paper introduces a smart IIoT monitoring and control system based on an unmanned aerial vehicle that uses cloud computing services and exploits fog computing as the bridge between IIoT layers. Its novelty lies in the fact that the UAV is automatically integrated into an industrial control system through an IoT gateway platform, while UAV photos are systematically and instantly computed and analyzed in the cloud. Visual supervision of the plant by drones and cloud services is integrated in real-time into the control loop of the industrial control system. As a proof of concept, the platform was used in a case study in an industrial concrete plant. The results obtained clearly illustrate the feasibility of the proposed platform in providing a reliable and efficient system for UAV remote control to improve product quality and reduce waste. For this, we studied the communication latency between the different IIoT layers in different IoT gateways.
KW  - UAVs
KW  - drones
KW  - industry 4.0
KW  - concrete plant
KW  - IoT protocols
KW  - IoT gateway
KW  - image recognition
KW  - cloud computing
KW  - network latency
KW  - end-to-end delay
DO  - 10.3390/s19153316
ER  -
TY  - EJOU
AU  - Ataee, Mohammad S.
AU  - Maghsoudi, Yasser
AU  - Latifi, Hooman
AU  - Fadaie, Farhad
TI  - Improving Estimation Accuracy of Growing Stock by Multi-Frequency SAR and Multi-Spectral Data over Iran’s Heterogeneously-Structured Broadleaf Hyrcanian Forests
T2  - Forests

PY  - 2019
VL  - 10
IS  - 8
SN  - 1999-4907

AB  - Via providing various ecosystem services, the old-growth Hyrcanian forests play a crucial role in the environment and anthropogenic aspects of Iran and beyond. The amount of growing stock volume (GSV) is a forest biophysical parameter with great importance in issues like economy, environmental protection, and adaptation to climate change. Thus, accurate and unbiased estimation of GSV is also crucial to be pursued across the Hyrcanian. Our goal was to investigate the potential of ALOS-2 and Sentinel-1&rsquo;s polarimetric features in combination with Sentinel-2 multi-spectral features for the GSV estimation in a portion of heterogeneously-structured and mountainous Hyrcanian forests. We used five different kernels by the support vector regression (nu-SVR) for the GSV estimation. Because each kernel differently models the parameters, we separately selected features for each kernel by a binary genetic algorithm (GA). We simultaneously optimized R2 and RMSE in a suggested GA fitness function. We calculated R2, RMSE to evaluate the models. We additionally calculated the standard deviation of validation metrics to estimate the model&rsquo;s stability. Also for models over-fitting or under-fitting analysis, we used mean difference (MD) index. The results suggested the use of polynomial kernel as the final model. Despite multiple methodical challenges raised from the composition and structure of the study site, we conclude that the combined use of polarimetric features (both dual and full) with spectral bands and indices can improve the GSV estimation over mixed broadleaf forests. This was partially supported by the use of proposed evaluation criterion within the GA, which helped to avoid the curse of dimensionality for the applied SVR and lowest over estimation or under estimation.
KW  - GSV
KW  - nu SVR
KW  - uneven-aged mountainous
KW  - polarimetery
KW  - multi-spectral
KW  - optimization
DO  - 10.3390/f10080641
ER  -
TY  - EJOU
AU  - Fan, Guangpeng
AU  - Chen, Feixiang
AU  - Li, Yan
AU  - Liu, Binbin
AU  - Fan, Xu
TI  - Development and Testing of a New Ground Measurement Tool to Assist in Forest GIS Surveys
T2  - Forests

PY  - 2019
VL  - 10
IS  - 8
SN  - 1999-4907

AB  - In present forest surveys, some problems occur because of the cost and time required when using external tools to acquire tree measurement. Therefore, it is of great importance to develop a new cost-saving and time-saving ground measurement method implemented in a forest geographic information system (GIS) survey. To obtain a better solution, this paper presents the design and implementation of a new ground measurement tool in which mobile devices play a very important role. Based on terrestrial photogrammetry, location-based services (LBS), and computer vision, the tool assists forest GIS surveys in obtaining important forest structure factors such as tree position, diameter at breast height (DBH), tree height, and tree species. This paper selected two plots to verify the accuracy of the ground measurement tool. Experiments show that the root mean square error (RMSE) of the position coordinates of the trees was 0.222 m and 0.229 m, respectively, and the relative root mean square error (rRMSE) was close to 0. The rRMSE of the DBH measurement was 10.17% and 13.38%, and the relative Bias (rBias) of the DBH measurement was &minus;0.88% and &minus;2.41%. The rRMSE of tree height measurement was 6.74% and 6.69%, and the rBias of tree height measurement was &minus;1.69% and &minus;1.27%, which conforms to the forest investigation requirements. In addition, workers usually make visual observations of trees and then combine their personal knowledge or experience to identify tree species, which may lead to the situations when they cannot distinguish tree species due to insufficient knowledge or experience. Based on MobileNets, a lightweight convolutional neural network designed for mobile phone, a model was trained to assist workers in identifying tree species. The dataset was collected from some forest parks in Beijing. The accuracy of the tree species recognition model was 94.02% on a test dataset and 93.21% on a test dataset in the mobile phone. This provides an effective reference for workers to identify tree species and can assist in artificial identification of tree species. Experiments show that this solution using the ground measurement tool saves time and cost for forest resources GIS surveys.
KW  - forest GIS surveys
KW  - terrestrial photogrammetry
KW  - LBS
KW  - MobileNets
KW  - measurement tool
DO  - 10.3390/f10080643
ER  -
TY  - EJOU
AU  - Fuentes, Sigfredo
AU  - Tongson, Eden J.
AU  - De Bei, Roberta
AU  - Gonzalez Viejo, Claudia
AU  - Ristic, Renata
AU  - Tyerman, Stephen
AU  - Wilkinson, Kerry
TI  - Non-Invasive Tools to Detect Smoke Contamination in Grapevine Canopies, Berries and Wine: A Remote Sensing and Machine Learning Modeling Approach
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 15
SN  - 1424-8220

AB  - Bushfires are becoming more frequent and intensive due to changing climate. Those that occur close to vineyards can cause smoke contamination of grapevines and grapes, which can affect wines, producing smoke-taint. At present, there are no available practical in-field tools available for detection of smoke contamination or taint in berries. This research proposes a non-invasive/in-field detection system for smoke contamination in grapevine canopies based on predictable changes in stomatal conductance patterns based on infrared thermal image analysis and machine learning modeling based on pattern recognition. A second model was also proposed to quantify levels of smoke-taint related compounds as targets in berries and wines using near-infrared spectroscopy (NIR) as inputs for machine learning fitting modeling. Results showed that the pattern recognition model to detect smoke contamination from canopies had 96% accuracy. The second model to predict smoke taint compounds in berries and wine fit the NIR data with a correlation coefficient (R) of 0.97 and with no indication of overfitting. These methods can offer grape growers quick, affordable, accurate, non-destructive in-field screening tools to assist in vineyard management practices to minimize smoke taint in wines with in-field applications using smartphones and unmanned aerial systems (UAS).
KW  - bushfires
KW  - infrared thermography
KW  - near-infrared spectroscopy
KW  - smoke taint
KW  - artificial intelligence
DO  - 10.3390/s19153335
ER  -
TY  - EJOU
AU  - Böhler, Jonas E.
AU  - Schaepman, Michael E.
AU  - Kneubühler, Mathias
TI  - Optimal Timing Assessment for Crop Separation Using Multispectral Unmanned Aerial Vehicle (UAV) Data and Textural Features
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 15
SN  - 2072-4292

AB  - The separation of crop types is essential for many agricultural applications, particularly when within-season information is required. Generally, remote sensing may provide timely information with varying accuracy over the growing season, but in small structured agricultural areas, a very high spatial resolution may be needed that exceeds current satellite capabilities. This paper presents an experiment using spectral and textural features of NIR-red-green-blue (NIR-RGB) bands data sets acquired with an unmanned aerial vehicle (UAV). The study area is located in the Swiss Plateau, which has highly fragmented and small structured agricultural fields. The observations took place between May 5 and September 29, 2015 over 11 days. The analyses are based on a random forest (RF) approach, predicting crop separation metrics of all analyzed crops. Three temporal windows of observations based on accumulated growing degree days (AGDD) were identified: an early temporal window (515&ndash;1232 AGDD, 5 May&ndash;17 June 2015) with an average accuracy (AA) of 70&ndash;75%; a mid-season window (1362&ndash;2016 AGDD, 25 June&ndash;22 July 2015) with an AA of around 80%; and a late window (2626&ndash;3238 AGDD, 21 August&ndash;29 September 2015) with an AA of &lt;65%. Therefore, crop separation is most promising in the mid-season window, and an additional NIR band increases the accuracy significantly. However, discrimination of winter crops is most effective in the early window, adding further observational requirements to the first window.
KW  - crop type separation
KW  - temporal window
KW  - small structured agricultural area
KW  - uncalibrated consumer-grade camera
KW  - unmanned aerial vehicle (UAV)
KW  - very high resolution (VHR)
KW  - random forest (RF) classifier
KW  - spectral and textural features
DO  - 10.3390/rs11151780
ER  -
TY  - EJOU
AU  - Konecny, Jaromir
AU  - Kromer, Pavel
AU  - Prauzek, Michal
AU  - Musilek, Petr
TI  - Scan Matching by Cross-Correlation and Differential Evolution
T2  - Electronics

PY  - 2019
VL  - 8
IS  - 8
SN  - 2079-9292

AB  - Scan matching is an important task, solved in the context of many high-level problems including pose estimation, indoor localization, simultaneous localization and mapping and others. Methods that are accurate and adaptive and at the same time computationally efficient are required to enable location-based services in autonomous mobile devices. Such devices usually have a wide range of high-resolution sensors but only a limited processing power and constrained energy supply. This work introduces a novel high-level scan matching strategy that uses a combination of two advanced algorithms recently used in this field: cross-correlation and differential evolution. The cross-correlation between two laser range scans is used as an efficient measure of scan alignment and the differential evolution algorithm is used to search for the parameters of a transformation that aligns the scans. The proposed method was experimentally validated and showed good ability to match laser range scans taken shortly after each other and an excellent ability to match laser range scans taken with longer time intervals between them.
KW  - scan matching
KW  - indoor localization
KW  - differential evolution
KW  - cross-correlation
KW  - robotics
DO  - 10.3390/electronics8080856
ER  -
TY  - EJOU
AU  - Dash, Jonathan P.
AU  - Watt, Michael S.
AU  - Paul, Thomas S. H.
AU  - Morgenroth, Justin
AU  - Pearse, Grant D.
TI  - Early Detection of Invasive Exotic Trees Using UAV and Manned Aircraft Multispectral and LiDAR Data
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 15
SN  - 2072-4292

AB  - Exotic conifers can provide significant ecosystem services, but in some environments, they have become invasive and threaten indigenous ecosystems. In New Zealand, this phenomenon is of considerable concern as the area occupied by invasive exotic trees is large and increasing rapidly. Remote sensing methods offer a potential means of identifying and monitoring land infested by these trees, enabling managers to efficiently allocate resources for their control. In this study, we sought to develop methods for remote detection of exotic invasive trees, namely Pinus sylvestris and P. ponderosa. Critically, the study aimed to detect these species prior to the onset of maturity and coning as this is important for preventing further spread. In the study environment in New Zealand&rsquo;s South Island, these species reach maturity and begin bearing cones at a young age. As such, detection of these smaller individuals requires specialist methods and very high-resolution remote sensing data. We examined the efficacy of classifiers developed using two machine learning algorithms with multispectral and laser scanning data collected from two platforms&mdash;manned aircraft and unmanned aerial vehicles (UAV). The study focused on a localized conifer invasion originating from a multi-species pine shelter belt in a grassland environment. This environment provided a useful means of defining the detection thresholds of the methods and technologies employed. An extensive field dataset including over 17,000 trees (height range = 1 cm to 476 cm) was used as an independent validation dataset for the detection methods developed. We found that data from both platforms and using both logistic regression and random forests for classification provided highly accurate (kappa     &lt; 0.996    ) detection of invasive conifers. Our analysis showed that the data from both UAV and manned aircraft was useful for detecting trees down to 1 m in height and therefore shorter than 99.3% of the coning individuals in the study dataset. We also explored the relative contribution of both multispectral and airborne laser scanning (ALS) data in the detection of invasive trees through fitting classification models with different combinations of predictors and found that the most useful models included data from both sensors. However, the combination of ALS and multispectral data did not significantly improve classification accuracy. We believe that this was due to the simplistic vegetation and terrain structure in the study site that resulted in uncomplicated separability of invasive conifers from other vegetation. This study provides valuable new knowledge of the efficacy of detecting invasive conifers prior to the onset of coning using high-resolution data from UAV and manned aircraft. This will be an important tool in managing the spread of these important invasive plants.
KW  - bio-security
KW  - LiDAR
KW  - invasive plants
KW  - random forest
KW  - logistic regression
KW  - drones
KW  - RPAS
KW  - invasion monitoring
KW  - invasive alien plants
KW  - multispectral
DO  - 10.3390/rs11151812
ER  -
TY  - EJOU
AU  - Choi, In H.
AU  - Son, Ju A.
AU  - Koo, Ja B.
AU  - Yoon, Young G.
AU  - Oh, Tae K.
TI  - Damage Assessment of Porcelain Insulators through Principal Component Analysis Associated with Frequency Response Signals
T2  - Applied Sciences

PY  - 2019
VL  - 9
IS  - 15
SN  - 2076-3417

AB  - More than 55% of porcelain insulators installed throughout Korea have exceeded their service life. Hence, utilities are extremely interested in determining the robustness of insulators in their systems. In this study, the identification of the peak ranges in the main natural modes by frequency response analysis, the principal component analysis (PCA) method by feature extraction in the time and frequency domains for the damage detection of porcelain insulators are investigated; among these, the PCA method, which utilizes frequency response data, is proposed for defect classification. The 67 porcelain insulators are secured as specimens from 154 kV transmission towers installed in various parts of Korea; their main materials are cristobalite and alumina. In these specimens, it is observed that the three types of damage, such as porcelain damage, cap damage, and internal damage, are those that are typically found in actual sites. Accordingly, the use of two eigenvectors (moments of real value and moments of imaginary value) considerably aids in the analysis of principal components. With the frequency response data, the material and damage types are found to be distinguishable. The classification accuracy is increased by including the third largest eigenvector (area of real value) in three-dimensional analysis. By employing frequency response data, the PCA method provides useful information for assessing the integrity of porcelain insulators; it may be used as basis for future machine learning applications.
KW  - porcelain insulator
KW  - frequency response analysis
KW  - feature extraction
KW  - principal component analysis
KW  - damage detection
KW  - defect classification
DO  - 10.3390/app9153150
ER  -
TY  - EJOU
AU  - Iizuka, Kotaro
AU  - Kato, Tsuyoshi
AU  - Silsigia, Sisva
AU  - Soufiningrum, Alifia Y.
AU  - Kozan, Osamu
TI  - Estimating and Examining the Sensitivity of Different Vegetation Indices to Fractions of Vegetation Cover at Different Scaling Grids for Early Stage Acacia Plantation Forests Using a Fixed-Wing UAS
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 15
SN  - 2072-4292

AB  - Understanding the information on land conditions and especially green vegetation cover is important for monitoring ecosystem dynamics. The fraction of vegetation cover (FVC) is a key variable that can be used to observe vegetation cover trends. Conventionally, satellite data are utilized to compute these variables, although computations in regions such as the tropics can limit the amount of available observation information due to frequent cloud coverage. Unmanned aerial systems (UASs) have become increasingly prominent in recent research and can remotely sense using the same methods as satellites but at a lower altitude. UASs are not limited by clouds and have a much higher resolution. This study utilizes a UAS to determine the emerging trends for FVC estimates at an industrial plantation site in Indonesia, which utilizes fast-growing Acacia trees that can rapidly change the land conditions. First, the UAS was utilized to collect high-resolution RGB imagery and multispectral images for the study area. The data were used to develop general land use/land cover (LULC) information for the site. Multispectral data were converted to various vegetation indices, and within the determined resolution grid (5, 10, 30 and 60 m), the fraction of each LULC type was analyzed for its correlation between the different vegetation indices (Vis). Finally, a simple empirical model was developed to estimate the FVC from the UAS data. The results show the correlation between the FVC (acacias) and different Vis ranging from R2 = 0.66&ndash;0.74, 0.76&ndash;0.8, 0.84&ndash;0.89 and 0.93&ndash;0.94 for 5, 10, 30 and 60 m grid resolutions, respectively. This study indicates that UAS-based FVC estimations can be used for observing fast-growing acacia trees at a fine scale resolution, which may assist current restoration programs in Indonesia.
KW  - UAS
KW  - UAV
KW  - vegetation cover
KW  - multispectral
KW  - land cover
KW  - forest
KW  - Acacia
KW  - Indonesia
KW  - tropics
DO  - 10.3390/rs11151816
ER  -
TY  - EJOU
AU  - Cao, Chen
AU  - Chen, Jianping
AU  - Zhang, Wen
AU  - Xu, Peihua
AU  - Zheng, Lianjing
AU  - Zhu, Chun
TI  - Geospatial Analysis of Mass-Wasting Susceptibility of Four Small Catchments in Mountainous Area of Miyun County, Beijing
T2  - International Journal of Environmental Research and Public Health

PY  - 2019
VL  - 16
IS  - 15
SN  - 1660-4601

AB  - Driven by the pull of gravity, mass-wasting comprises all of the sedimentary processes related to remobilization of sediments deposited on slopes, including creep, sliding, slumping, flow, and fall. It is vital to conduct mass-wasting susceptibility mapping, with the aim of providing decision makers with management advice. The current study presents two individual data mining methods&mdash;the frequency ratio (FR) and information value model (IVM) methods&mdash;to map mass-wasting susceptibility in four catchments in Miyun County, Beijing, China. To achieve this goal, nine influence factors and a mass-wasting inventory map were used and produced, respectively. In this study, 71 mass-wasting locations were investigated in the field. Of these hazard locations, 70% of them were randomly selected to build the model, and the remaining 30% of the hazard locations were used for validation. Finally, a receiver operating characteristic (ROC) curve was used to assess the mass-wasting susceptibility maps produced by the above-mentioned models. Results show that the FR had a higher concordance and spatial differentiation, with respective values of 0.902 (area under the success rate) and 0.883 (area under the prediction rate), while the IVM had lower values of 0.865 (area under the success rate) and 0.855 (area under the prediction rate). Both proposed methodologies are useful for general planning and evaluation purposes, and they are shown to be reasonable models. Slopes of 6&ndash;21&deg; were the most common thresholds that controlled occurrence of mass-wasting. Farmland terraces were mainly composed of gravel, mud, and clay, which are more prone to mass-wasting. Mass-wasting susceptibility mapping is feasible and potentially highly valuable. It could provide useful information in support of environmental health policies.
KW  - mass-wasting susceptibility
KW  - catchment management
KW  - frequency ratio
KW  - information value
KW  - farmland terraces
DO  - 10.3390/ijerph16152801
ER  -
TY  - EJOU
AU  - Askari, Mohammad S.
AU  - McCarthy, Timothy
AU  - Magee, Aidan
AU  - Murphy, Darren J.
TI  - Evaluation of Grass Quality under Different Soil Management Scenarios Using Remote Sensing Techniques
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 15
SN  - 2072-4292

AB  - Hyperspectral and multispectral imagery have been demonstrated to have a considerable potential for near real-time monitoring and mapping of grass quality indicators. The objective of this study was to evaluate the efficiency of remote sensing techniques for quantification of aboveground grass biomass (BM) and crude protein (CP) in a temperate European climate such as Ireland. The experiment was conducted on 64 plots and 53 paddocks with varying quantities of nitrogen applied. Hyperspectral imagery (HSI) and multispectral imagery (MSI) were analyzed to develop the prediction models. The MSI data used in this study were captured using an unmanned aircraft vehicle (UAV) and the satellite Sentinel-2, while the HSI data were obtained using a handheld hyperspectral camera. The prediction models were developed using partial least squares regression (PLSR) and stepwise multi-linear regression (MLR). Eventually, the spatial distribution of grass biomass over plots and paddocks was mapped to assess the within-field variability of grass quality metrics. An excellent accuracy was achieved for the prediction of BM and CP using HSI (RPD &gt; 2.5 and R2 &gt; 0.8), and a good accuracy was obtained via MSI-UAV (2 &lt; RPD &lt; 2.5 and R2 &gt; 0.7) for the grass quality indicators. The accuracy of the models calculated using MSI-Sentinel-2 was reasonable for BM prediction and insufficient for CP estimation. The red-edge range of the wavelengths showed the maximum impact on the predictability of grass BM, and the NIR range had the greatest influence on the estimation of grass CP. Both the PLSR and MLR techniques were found to be sufficiently robust for spectral modelling of aboveground BM and CP. The PLSR yielded a slightly better model than MLR. This study suggested that remote sensing techniques can be used as a rapid and reliable approach for near real-time quantitative assessment of fresh grass quality under a temperate European climate.
KW  - hyperspectral
KW  - multispectral
KW  - fertilization
KW  - grass biomass
KW  - crude protein
DO  - 10.3390/rs11151835
ER  -
TY  - EJOU
AU  - Brinkhoff, James
AU  - Dunn, Brian W.
AU  - Robson, Andrew J.
AU  - Dunn, Tina S.
AU  - Dehaan, Remy L.
TI  - Modeling Mid-Season Rice Nitrogen Uptake Using Multispectral Satellite Data
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 15
SN  - 2072-4292

AB  - Mid-season nitrogen (N) application in rice crops can maximize yield and profitability. This requires accurate and efficient methods of determining rice N uptake in order to prescribe optimal N amounts for topdressing. This study aims to determine the accuracy of using remotely sensed multispectral data from satellites to predict N uptake of rice at the panicle initiation (PI) growth stage, with a view to providing optimum variable-rate N topdressing prescriptions without needing physical sampling. Field experiments over 4 years, 4&ndash;6 N rates, 4 varieties and 2 sites were conducted, with at least 3 replicates of each plot. One WorldView satellite image for each year was acquired, close to the date of PI. Numerous single- and multi-variable models were investigated. Among single-variable models, the square of the NDRE vegetation index was shown to be a good predictor of N uptake (R     2     = 0.75, RMSE = 22.8 kg/ha for data pooled from all years and experiments). For multi-variable models, Lasso regularization was used to ensure an interpretable and compact model was chosen and to avoid over fitting. Combinations of remotely sensed reflectances and spectral indexes as well as variety, climate and management data as input variables for model training achieved R     2    &lt; 0.9 and RMSE &lt; 15 kg/ha for the pooled data set. The ability of remotely sensed data to predict N uptake in new seasons where no physical sample data has yet been obtained was tested. A methodology to extract models that generalize well to new seasons was developed, avoiding model overfitting. Lasso regularization selected four or less input variables, and yielded R     2     of better than 0.67 and RMSE better than 27.4 kg/ha over four test seasons that weren&rsquo;t used to train the models.
KW  - rice
KW  - nitrogen management
KW  - remote sensing
KW  - multispectral imagery
KW  - reflectance index
KW  - multiple variable linear regression
KW  - Lasso model
DO  - 10.3390/rs11151837
ER  -
TY  - EJOU
AU  - Lay, Usman S.
AU  - Pradhan, Biswajeet
AU  - Yusoff, Zainuddin B.
AU  - Abdallah, Ahmad F.
AU  - Aryal, Jagannath
AU  - Park, Hyuck-Jin
TI  - Data Mining and Statistical Approaches in Debris-Flow Susceptibility Modelling Using Airborne LiDAR Data
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 16
SN  - 1424-8220

AB  - Cameron Highland is a popular tourist hub in the mountainous area of Peninsular Malaysia. Most communities in this area suffer frequent incidence of debris flow, especially during monsoon seasons. Despite the loss of lives and properties recorded annually from debris flow, most studies in the region concentrate on landslides and flood susceptibilities. In this study, debris-flow susceptibility prediction was carried out using two data mining techniques; Multivariate Adaptive Regression Splines (MARS) and Support Vector Regression (SVR) models. The existing inventory of debris-flow events (640 points) were selected for training 70% (448) and validation 30% (192). Twelve conditioning factors namely; elevation, plan-curvature, slope angle, total curvature, slope aspect, Stream Transport Index (STI), profile curvature, roughness index, Stream Catchment Area (SCA), Stream Power Index (SPI), Topographic Wetness Index (TWI) and Topographic Position Index (TPI) were selected from Light Detection and Ranging (LiDAR)-derived Digital Elevation Model (DEM) data. Multi-collinearity was checked using Information Factor, Cramer&rsquo;s V, and Gini Index to identify the relative importance of conditioning factors. The susceptibility models were produced and categorized into five classes; not-susceptible, low, moderate, high and very-high classes. Models performances were evaluated using success and prediction rates where the area under the curve (AUC) showed a higher performance of MARS (93% and 83%) over SVR (76% and 72%). The result of this study will be important in contingency hazards and risks management plans to reduce the loss of lives and properties in the area.
KW  - debris flows
KW  - susceptibility
KW  - machine learning
KW  - MARS
KW  - SVR
KW  - LiDAR
KW  - GIS
KW  - remote sensing
DO  - 10.3390/s19163451
ER  -
TY  - EJOU
AU  - KAPLAN, Gordana
AU  - AVDAN, Ugur
TI  - Evaluating Sentinel-2 Red-Edge Bands for Wetland Classification
T2  - Proceedings

PY  - 2019
VL  - 18
IS  - 1
SN  - 2504-3900

AB  - Due to the high spatial heterogeneity and temporal variability, wetlands are one of the most difficult ecosystems to observe using remote sensing data. With the additional Sentinel-2 vegetation red-edge bands, an improvement of the vegetated classes classification is expected. In order to investigate the influence of the Sentinel-2 red-edge bands, in this paper we evaluate two classification scenarios over wetland classes. The first scenario excludes the red-edge bands, while in the second scenario all red-edge bands are included in the classification dataset where two different wetland classes&mdash;intensive vegetated wetland classes such as swamps and partially decayed vegetated wetland areas such as bogs&mdash;are classified using a support vector machine (SVM) learning classifier. The classes are defined using high-resolution images from an Unmanned Aerial Vehicle (UAV) obtained on the same date with the passing of the Sentinel-2 satellite over the study area. As expected, the results show a significant improvement of the intensive vegetated wetlands, with more than 30% in both user and producer accuracy, while no significant changes are noted in the partially decayed vegetated wetlands. For future studies, we recommend evaluating the influence of the Sentinel radar data over wetland areas.
KW  - wetlands
KW  - red-edge
KW  - classification
KW  - support vector machine
KW  - Sentinel-2
DO  - 10.3390/ECRS-3-06184
ER  -
TY  - EJOU
AU  - Strimbu, Bogdan M.
AU  - Qi, Chu
AU  - Sessions, John
TI  - Accurate Geo-Referencing of Trees with No or Inaccurate Terrestrial Location Devices
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 16
SN  - 2072-4292

AB  - Accurate and precise location of trees from data acquired under-the-canopy is challenging and time-consuming. However, current forestry practices would benefit tremendously from the knowledge of tree coordinates, particularly when the information used to position them is acquired with inexpensive sensors. Therefore, the objective of our study is to geo-reference trees using point clouds created from the images acquired below canopy. We developed a procedure that uses the coordinates of the trees seen from above canopy to position the same trees seen below canopy. To geo-reference the trees from above canopy we captured images with an unmanned aerial vehicle. We reconstructed the trunk with photogrammetric point clouds built with a structure&ndash;from&ndash;motion procedure from images recorded in a circular pattern at multiple locations throughout the stand. We matched the trees segmented from below canopy with the trees extracted from above canopy using a non-rigid point-matching algorithm. To ensure accuracy, we reduced the number of matching trees by dividing the trees segmented from above using a grid with 50 m cells. Our procedure was implemented on a 7.1 ha Douglas-fir stand from Oregon USA. The proposed procedure is relatively fast, as approximately 600 trees were mapped in approximately 1 min. The procedure is sensitive to the point density, directly impacting tree location, as differences larger than 2 m between the coordinates of the tree top and the bottom part of the stem could lead to matching errors larger than 1 m. Furthermore, the larger the number of trees to be matched the higher the accuracy is, which could allow for misalignment errors larger than 2 m between the locations of the trees segmented from above and below.
KW  - unmanned aerial vehicle
KW  - structure from motion
KW  - photogrammetric point clouds
KW  - tree segmentation
KW  - point-matching
DO  - 10.3390/rs11161877
ER  -
TY  - EJOU
AU  - Kiala, Zolo
AU  - Mutanga, Onisimo
AU  - Odindi, John
AU  - Peerbhay, Kabir
TI  - Feature Selection on Sentinel-2 Multispectral Imagery for Mapping a Landscape Infested by Parthenium Weed
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 16
SN  - 2072-4292

AB  - In the recent past, the volume of spatial datasets has significantly increased. This is attributed to, among other factors, higher sensor temporal resolutions of the recently launched satellites. The increased data, combined with the computation and possible derivation of a large number of indices, may lead to high multi-collinearity and redundant features that compromise the performance of classifiers. Using dimension reduction algorithms, a subset of these features can be selected, hence increasing their predictive potential. In this regard, an investigation into the application of feature selection techniques on multi-temporal multispectral datasets such as Sentinel-2 is valuable in vegetation mapping. In this study, ten feature selection methods belonging to five groups (Similarity-based, statistical-based, Sparse learning based, Information theoretical based, and wrappers methods) were compared based on f-score and data size for mapping a landscape infested by the Parthenium weed (Parthenium hysterophorus). Overall, results showed that ReliefF (a Similarity-based approach) was the best performing feature selection method as demonstrated by the high f-score values of Parthenium weed and a small size of optimal features selected. Although svm-b (a wrapper method) yielded the highest accuracies, the size of optimal subset of selected features was quite large. Results also showed that data size affects the performance of feature selection algorithms, except for statistically-based methods such as Gini-index and F-score and svm-b. Findings in this study provide a guidance on the application of feature selection methods for accurate mapping of invasive plant species in general and Parthenium weed, in particular, using new multispectral imagery with high temporal resolution.
KW  - feature selection
KW  - Parthenium weed
KW  - Sentinel-2
DO  - 10.3390/rs11161892
ER  -
TY  - EJOU
AU  - Gage, Karla L.
AU  - Schwartz-Lazaro, Lauren M.
TI  - Shifting the Paradigm: An Ecological Systems Approach to Weed Management
T2  - Agriculture

PY  - 2019
VL  - 9
IS  - 8
SN  - 2077-0472

AB  - Weeds have been historically, and are still today, the primary and most economically important pest in agriculture. Several selection pressures associated with weed management, such as an overreliance on herbicides, have promoted the rapid evolution of herbicide-resistant weeds. Integrated Weed Management (IWM) is promoted as an ecological systems approach, through the combination of biological, chemical, cultural, ecological, and mechanical control methods. The concept of a systems approach is defined as managing weeds by combining practice and knowledge with the goals of increasing yield and minimizing economic loss, minimizing risks to human health and the environment, and reducing energy requirements and off-target impacts. The reliance on herbicides in modern cropping systems has shifted the management focus from requiring intimate knowledge of biology, ecology, and ecological systems to herbicide chemistry, mixes, and rotations, application technology, and herbicide-tolerant crop traits. Here, an ecological systems approach is considered, examining new trends and technologies in relation to IWM and weed ecology. Prevention of spread, seedbank management, crop rotations, tillage, cover crops, competitive cultivars, biological weed control, and future solutions in concept-only are presented, and knowledge gaps are identified where research advancements may be possible. An ecological systems approach will provide improved stewardship of new herbicide technologies and reduce herbicide resistance evolution through diversification of selection pressures. Agroecological interactions should be studied in light of new, developing weed control technologies. The science of weed management needs to refocus on the foundations of weed biology and ecology to enable an ecological systems approach and promote agricultural sustainability.
KW  - biotechnology
KW  - cover crops
KW  - harvest weed seed control
KW  - herbicide resistance
KW  - IWM
KW  - Integrated Weed Management
KW  - precision agriculture
KW  - soil seedbank
KW  - weed ecology
DO  - 10.3390/agriculture9080179
ER  -
TY  - EJOU
AU  - Lygouras, Eleftherios
AU  - Santavas, Nicholas
AU  - Taitzoglou, Anastasios
AU  - Tarchanidis, Konstantinos
AU  - Mitropoulos, Athanasios
AU  - Gasteratos, Antonios
TI  - Unsupervised Human Detection with an Embedded Vision System on a Fully Autonomous UAV for Search and Rescue Operations
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 16
SN  - 1424-8220

AB  - Unmanned aerial vehicles (UAVs) play a primary role in a plethora of technical and scientific fields owing to their wide range of applications. In particular, the provision of emergency services during the occurrence of a crisis event is a vital application domain where such aerial robots can contribute, sending out valuable assistance to both distressed humans and rescue teams. Bearing in mind that time constraints constitute a crucial parameter in search and rescue (SAR) missions, the punctual and precise detection of humans in peril is of paramount importance. The paper in hand deals with real-time human detection onboard a fully autonomous rescue UAV. Using deep learning techniques, the implemented embedded system was capable of detecting open water swimmers. This allowed the UAV to provide assistance accurately in a fully unsupervised manner, thus enhancing first responder operational capabilities. The novelty of the proposed system is the combination of global navigation satellite system (GNSS) techniques and computer vision algorithms for both precise human detection and rescue apparatus release. Details about hardware configuration as well as the system&rsquo;s performance evaluation are fully discussed.
KW  - unmanned aerial vehicles (UAVs)
KW  - search and rescue (SAR) missions
KW  - human detection
KW  - deep learning
DO  - 10.3390/s19163542
ER  -
TY  - EJOU
AU  - Jawak, Shridhar D.
AU  - Luis, Alvarinho J.
AU  - Fretwell, Peter T.
AU  - Convey, Peter
AU  - Durairajan, Udhayaraj A.
TI  - Semiautomated Detection and Mapping of Vegetation Distribution in the Antarctic Environment Using Spatial-Spectral Characteristics of WorldView-2 Imagery
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 16
SN  - 2072-4292

AB  - Effective monitoring of changes in the geographic distribution of cryospheric vegetation requires high-resolution and accurate baseline maps. The rationale of the present study is to compare multiple feature extraction approaches to remotely mapping vegetation in Antarctica, assessing which give the greatest accuracy and reproducibility relative to those currently available. This study provides precise, high-resolution, and refined baseline information on vegetation distribution as is required to enable future spatiotemporal change analyses of the vegetation in Antarctica. We designed and implemented a semiautomated customized normalized difference vegetation index (NDVI) approach for extracting cryospheric vegetation by incorporating very high resolution (VHR) 8-band WorldView-2 (WV-2) satellite data. The viability of state-of-the-art target detection, spectral processing/matching, and pixel-wise supervised classification feature extraction techniques are compared with the customized NDVI approach devised in this study. An extensive quantitative and comparative assessment was made by evaluating four semiautomatic feature extraction approaches consisting of 16 feature extraction standalone methods (four customized NDVI plus 12 existing methods) for mapping vegetation on Fisher Island and Stornes Peninsula in the Larsemann Hills, situated on continental east Antarctica. The results indicated that the customized NDVI approach achieved superior performance (average bias error ranged from ~6.44 &plusmn; 1.34% to ~11.55 &plusmn; 1.34%) and highest statistical stability in terms of performance when compared with existing feature extraction approaches. Overall, the accuracy analysis of the vegetation mapping relative to manually digitized reference data (supplemented by validation with ground truthing) indicated that the 16 semi-automatic mapping methods representing four general feature extraction approaches extracted vegetated area from Fisher Island and Stornes Peninsula totalling between 2.38 and 3.72 km2 (2.85 &plusmn; 0.10 km2 on average) with bias values ranging from 3.49 to 31.39% (average 12.81 &plusmn; 1.88%) and average root mean square error (RMSE) of 0.41 km2 (14.73 &plusmn; 1.88%). Further, the robustness of the analyses and results were endorsed by a cross-validation experiment conducted to map vegetation from the Schirmacher Oasis, East Antarctica. Based on the robust comparative analysis of these 16 methods, vegetation maps of the Larsemann Hills and Schirmacher Oasis were derived by ensemble merging of the five top-performing methods (Mixture Tuned Matched Filtering, Matched Filtering, Matched Filtering/Spectral Angle Mapper Ratio, NDVI-2, and NDVI-4). This study is the first of its kind to detect and map sparse and isolated vegetated patches (with smallest area of 0.25 m2) in East Antarctica using VHR data and to use ensemble merging of feature extraction methods, and provides access to an important indicator for environmental change.
KW  - semi-automated classification
KW  - customized NDVI
KW  - Antarctic vegetation
KW  - spectral processing
KW  - feature extraction
KW  - Worldview-2 data
DO  - 10.3390/rs11161909
ER  -
TY  - EJOU
AU  - Li, Qingyu
AU  - Dai, Keren
AU  - Wang, Xiaofeng
AU  - Zhang, Yu
AU  - Zhang, He
AU  - Jiang, Defu
TI  - Low-Complexity Failed Element Diagnosis for Radar-Communication mmWave Antenna Array with Low SNR
T2  - Electronics

PY  - 2019
VL  - 8
IS  - 8
SN  - 2079-9292

AB  - The millimeter-wave (mmWave) antenna array plays an important role in the excellent performance of wireless sensors networks (WSN) or unmanned aerial vehicle (UAV) clusters. However, the array elements are easily damaged in its harsh working environment but hard to be repaired or exchanged timely, resulting in a serious decline in the beamforming performance. Thus, accurate self-diagnosis of the failed elements is of great importance. In previous studies, there are still significant difficulties for large-scale arrays under extremely low SNR. In this paper, a diagnosis algorithm with low complexity and high reliability for the failed elements is proposed, which is based on a joint decision of communication signal and sensing echoes. Compared with the previous studies, the complexity of the algorithm is reduced by the construction of low-dimensional feature vectors for classification, the decoupling of the degree of arrival (DOA) estimation and the failed pattern diagnosis, with the help of the sub-array division. Simulation results show that, under an ultra-low SNR of &minus;12.5 dB for communication signals and &minus;16 dB for sensing echoes, an accurate self-diagnosis with a block error rate lower than 8% can be realized. The study in this paper will effectively promote the long-term and reliable operation of the mmWave antenna array in WSN, UAV clusters and other similar fields.
KW  - mmWave antenna array
KW  - failed elements diagnisis
KW  - joint radar-communication system
KW  - low complexity
KW  - low SNR
DO  - 10.3390/electronics8080904
ER  -
TY  - EJOU
AU  - Santos, Anderson A.
AU  - Marcato Junior, José
AU  - Araújo, Márcio S.
AU  - Di Martini, David R.
AU  - Tetila, Everton C.
AU  - Siqueira, Henrique L.
AU  - Aoki, Camila
AU  - Eltner, Anette
AU  - Matsubara, Edson T.
AU  - Pistori, Hemerson
AU  - Feitosa, Raul Q.
AU  - Liesenberg, Veraldo
AU  - Gonçalves, Wesley N.
TI  - Assessment of CNN-Based Methods for Individual Tree Detection on Images Captured by RGB Cameras Attached to UAVs
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 16
SN  - 1424-8220

AB  - Detection and classification of tree species from remote sensing data were performed using mainly multispectral and hyperspectral images and Light Detection And Ranging (LiDAR) data. Despite the comparatively lower cost and higher spatial resolution, few studies focused on images captured by Red-Green-Blue (RGB) sensors. Besides, the recent years have witnessed an impressive progress of deep learning methods for object detection. Motivated by this scenario, we proposed and evaluated the usage of Convolutional Neural Network (CNN)-based methods combined with Unmanned Aerial Vehicle (UAV) high spatial resolution RGB imagery for the detection of law protected tree species. Three state-of-the-art object detection methods were evaluated: Faster Region-based Convolutional Neural Network (Faster R-CNN), YOLOv3 and RetinaNet. A dataset was built to assess the selected methods, comprising 392 RBG images captured from August 2018 to February 2019, over a forested urban area in midwest Brazil. The target object is an important tree species threatened by extinction known as Dipteryx alata Vogel (Fabaceae). The experimental analysis delivered average precision around 92% with an associated processing times below 30 miliseconds.
KW  - object-detection
KW  - deep learning
KW  - remote sensing
DO  - 10.3390/s19163595
ER  -
TY  - EJOU
AU  - Prudnikova, Elena
AU  - Savin, Igor
AU  - Vindeker, Gretelerika
AU  - Grubina, Praskovia
AU  - Shishkonakova, Ekaterina
AU  - Sharychev, David
TI  - Influence of Soil Background on Spectral Reflectance of Winter Wheat Crop Canopy
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 16
SN  - 2072-4292

AB  - The spectral reflectance of crop canopy is a spectral mixture, which includes soil background as one of the components. However, as soil is characterized by substantial spatial variability and temporal dynamics, its contribution to the spectral reflectance of crops will also vary. The aim of the research was to determine the impact of soil background on spectral reflectance of crop canopy in visible and near-infrared parts of the spectrum at different stages of crop development and how the soil type factor and the dynamics of soil surface affect vegetation indices calculated for crop assessment. The study was conducted on three test plots with winter wheat located in the Tula region of Russia and occupied by three contrasting types of soil. During field trips, information was collected on the spectral reflectance of winter wheat crop canopy, winter wheat leaves, weeds and open soil surface for three phenological phases (tillering, shooting stage, milky ripeness). The assessment of the soil contribution to the spectral reflectance of winter wheat crop canopy was based on a linear spectral mixture model constructed from field data. This showed that the soil background effect is most pronounced in the regions of 350&ndash;500 nm and 620&ndash;690 nm. In the shooting stage, the contribution of the soil prevails in the 620&ndash;690 nm range of the spectrum and the phase of milky ripeness in the region of 350&ndash;500 nm. The minimum contribution at all stages of winter wheat development was observed at wavelengths longer than 750 nm. The degree of soil influence varies with soil type. Analysis of variance showed that normalized difference vegetation index (NDVI) was least affected by soil type factor, the influence of which was about 30%&ndash;50%, depending on the stage of winter wheat development. The influence of soil type on soil-adjusted vegetation index (SAVI) and enhanced vegetation index (EVI2) was approximately equal and varied from 60% (shooting phase) to 80% (tillering phase). According to the discriminant analysis, the ability of vegetation indices calculated for winter wheat crop canopy to distinguish between winter wheat crops growing on different soil types changed from the classification accuracy of 94.1% (EVI2) in the tillering stage to 75% (EVI2 and SAVI) in the shooting stage to 82.6% in the milky ripeness stage (EVI2, SAVI, NDVI). The range of the sensitivity of the vegetation indices to the soil background depended on soil type. The indices showed the greatest sensitivity on gray forest soil when the wheat was in the phase of milky ripeness, and on leached chernozem when the wheat was in the tillering phase. The observed patterns can be used to develop vegetation indices, invariant to second-type soil variations caused by soil type factor, which can be applied for the remote assessment of the state of winter wheat crops.
KW  - spectral reflectance
KW  - triticum aestivum
KW  - arable soils
KW  - winter wheat
KW  - NDVI
KW  - EVI2
KW  - SAVI
DO  - 10.3390/rs11161932
ER  -
TY  - EJOU
AU  - Roberts, John
AU  - Koeser, Andrew
AU  - Abd-Elrahman, Amr
AU  - Wilkinson, Benjamin
AU  - Hansen, Gail
AU  - Landry, Shawn
AU  - Perez, Ali
TI  - Mobile Terrestrial Photogrammetry for Street Tree Mapping and Measurements
T2  - Forests

PY  - 2019
VL  - 10
IS  - 8
SN  - 1999-4907

AB  - Urban forests are often heavily populated by street trees along right-of-ways (ROW), and monitoring efforts can enhance municipal tree management. Terrestrial photogrammetric techniques have been used to measure tree biometry, but have typically used images from various angles around individual trees or forest plots to capture the entire stem while also utilizing local coordinate systems (i.e., non-georeferenced data). We proposed the mobile collection of georeferenced imagery along 100 m sections of urban roadway to create photogrammetric point cloud datasets suitable for measuring stem diameters and attaining positional x and y coordinates of street trees. In a comparison between stationary and mobile photogrammetry, diameter measurements of urban street trees (N = 88) showed a slightly lower error (RMSE = 8.02%) relative to non-mobile stem measurements (RMSE = 10.37%). Tree Y-coordinates throughout urban sites for mobile photogrammetric data showed a lower standard deviation of 1.70 m relative to 2.38 m for a handheld GPS, which was similar for X-coordinates where photogrammetry and handheld GPS coordinates showed standard deviations of 1.59 m and the handheld GPS 2.36 m, respectively&mdash;suggesting higher precision for the mobile photogrammetric models. The mobile photogrammetric system used in this study to create georeferenced models for measuring stem diameters and mapping tree positions can also be potentially expanded for more wide-scale applications related to tree inventory and monitoring of roadside infrastructure.
KW  - urban forestry
KW  - tree inventory
KW  - trunk diameter
KW  - point cloud
KW  - green infrastructure
DO  - 10.3390/f10080701
ER  -
TY  - EJOU
AU  - Du, Jinyang
AU  - Watts, Jennifer D.
AU  - Jiang, Lingmei
AU  - Lu, Hui
AU  - Cheng, Xiao
AU  - Duguay, Claude
AU  - Farina, Mary
AU  - Qiu, Yubao
AU  - Kim, Youngwook
AU  - Kimball, John S.
AU  - Tarolli, Paolo
TI  - Remote Sensing of Environmental Changes in Cold Regions: Methods, Achievements and Challenges
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 16
SN  - 2072-4292

AB  - Cold regions, including high-latitude and high-altitude landscapes, are experiencing profound environmental changes driven by global warming. With the advance of earth observation technology, remote sensing has become increasingly important for detecting, monitoring, and understanding environmental changes over vast and remote regions. This paper provides an overview of recent achievements, challenges, and opportunities for land remote sensing of cold regions by (a) summarizing the physical principles and methods in remote sensing of selected key variables related to ice, snow, permafrost, water bodies, and vegetation; (b) highlighting recent environmental nonstationarity occurring in the Arctic, Tibetan Plateau, and Antarctica as detected from satellite observations; (c) discussing the limits of available remote sensing data and approaches for regional monitoring; and (d) exploring new opportunities from next-generation satellite missions and emerging methods for accurate, timely, and multi-scale mapping of cold regions.
KW  - remote sensing
KW  - cryosphere
KW  - climate change
KW  - northern high latitudes
KW  - Antarctica
KW  - Tibetan Plateau
DO  - 10.3390/rs11161952
ER  -
TY  - EJOU
AU  - Liu, Chunting
AU  - Jia, Guozhu
TI  - Industrial Big Data and Computational Sustainability: Multi-Method Comparison Driven by High-Dimensional Data for Improving Reliability and Sustainability of Complex Systems
T2  - Sustainability

PY  - 2019
VL  - 11
IS  - 17
SN  - 2071-1050

AB  - Sustainable development is of great significance. The emerging research on data-driven computational sustainability has become an effective way to solve this problem. This paper presents a fault diagnosis and prediction framework for complex systems based on multi-dimensional data and multi-method comparison, aimed at improving the reliability and sustainability of the system by selecting methods with relatively superior performance. This study took the avionics system in the industrial field as an example. Based on the literature research on typical fault modes and fault diagnosis requirements of avionics systems, three popular high-dimensional data-driven fault diagnosis methods&mdash;support vector machine, convolutional neural network, and long- and short-term memory neural network&mdash;were comprehensively analyzed and compared. Finally, the actual bearing failure data were used for programming in order to verify and compare various methods and the process of selecting the superior method driven by high-dimensional data was fully demonstrated. We attempt to provide a sustainable development idea that continuously explores multi-method integration and comparison, aimed at improving the calculation efficiency and accuracy of reliability assessments, optimizing system performance, and ultimately achieving the goal of long-term improvement of system reliability and sustainability.
KW  - industrial big data
KW  - computational sustainability
KW  - multi-method comparison
KW  - reliability and sustainability
KW  - high-dimensional data
DO  - 10.3390/su11174557
ER  -
TY  - EJOU
AU  - Joung, Jingon
AU  - Lee, Han L.
AU  - Zhao, Jian
AU  - Kang, Xin
TI  - Power Control Method for Energy Efficient Buffer-Aided Relay Systems
T2  - Energies

PY  - 2019
VL  - 12
IS  - 17
SN  - 1996-1073

AB  - In this paper, a power control method is proposed for a buffer-aided relay node (RN) to enhance the energy efficiency of the RN system. By virtue of a buffer, the RN can reserve the data at the buffer when the the channel gain between an RN and a destination node (DN) is weaker than that between SN and RN. The RN then opportunistically forward the reserved data in the buffer according to channel condition between the RN and the DN. By exploiting the buffer, RN reduces transmit power when it reduces the transmit data rate and reserve the data in the buffer. Therefore, without any total throughput reduction, the power consumption of RN can be reduced, resulting in the energy efficiency (EE) improvement of the RN system. Furthermore, for the power control, we devise a simple power control method based on a two-dimensional surface fitting model of an optimal transmit power of RN. The proposed RN power control method is readily and locally implementable at the RN, and it can significantly improve EE of the RN compared to the fixed power control method and the spectral efficiency based method as verified by the rigorous numerical results.
KW  - UAV
KW  - relay
KW  - cooperative communications
KW  - buffer
KW  - power control
KW  - energy efficiency
DO  - 10.3390/en12173234
ER  -
TY  - EJOU
AU  - Wu, Ruidong
AU  - Liu, Bing
AU  - Fu, Jiafeng
AU  - Xu, Mingzhu
AU  - Fu, Ping
AU  - Li, Junbao
TI  - Research and Implementation of ε-SVR Training Method Based on FPGA
T2  - Electronics

PY  - 2019
VL  - 8
IS  - 9
SN  - 2079-9292

AB  - Online training of Support Vector Regression (SVR) in the field of machine learning is a computationally complex algorithm. Due to the need for multiple iterative processing in training, SVR training is usually implemented on computer, and the existing training methods cannot be directly implemented on Field-Programmable Gate Array (FPGA), which restricts the application range. This paper reconstructs the training framework and implementation without precision loss to reduce the total latency required for matrix update, reducing time consumption by 90%. A general &epsilon;-SVR training system with low latency is implemented on Zynq platform. Taking the regression of samples in two-dimensional as an example, the maximum acceleration ratio is 27.014&times; compared with microcontroller platform and the energy consumption is 12.449% of microcontroller. From the experiments for the University of California, Riverside (UCR) time series data set. The regression results obtain excellent regression effects. The minimum coefficient of determination is 0.996, and running time is less than 30 ms, which can meet the requirements of different applications for real-time regression.
KW  - training method
KW  - Field-Programmable Gate Array (FPGA)
KW  - Support Vector Regression (SVR)
KW  - Zynq
DO  - 10.3390/electronics8090919
ER  -
TY  - EJOU
AU  - Lu, Bing
AU  - He, Yuhong
TI  - Evaluating Empirical Regression, Machine Learning, and Radiative Transfer Modelling for Estimating Vegetation Chlorophyll Content Using Bi-Seasonal Hyperspectral Images
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 17
SN  - 2072-4292

AB  - Different types of methods have been developed to retrieve vegetation attributes from remote sensing data, including conventional empirical regressions (i.e., linear regression (LR)), advanced empirical regressions (e.g., multivariable linear regression (MLR), partial least square regression (PLSR)), machine learning (e.g., random forest regression (RFR), decision tree regression (DTR)), and radiative transfer modelling (RTM, e.g., PROSAIL). Given that each algorithm has its own strengths and weaknesses, it is essential to compare them and evaluate their effectiveness. Previous studies have mainly used single-date multispectral imagery or ground-based hyperspectral reflectance data for evaluating the models, while multi-seasonal hyperspectral images have been rarely used. Extensive spectral and spatial information in hyperspectral images, as well as temporal variations of landscapes, potentially influence the model performance. In this research, LR, PLSR, RFR, and PROSAIL, representing different types of methods, were evaluated for estimating vegetation chlorophyll content from bi-seasonal hyperspectral images (i.e., a middle- and a late-growing season image, respectively). Results show that the PLSR and RFR generally performed better than LR and PROSAIL. RFR achieved the highest accuracy for both images. This research provides insights on the effectiveness of different models for estimating vegetation chlorophyll content using hyperspectral images, aiming to support future vegetation monitoring research.
KW  - vegetation properties
KW  - empirical regression
KW  - machine learning
KW  - radiative transfer modelling
KW  - hyperspectral
KW  - chlorophyll content
DO  - 10.3390/rs11171979
ER  -
TY  - EJOU
AU  - Feng, Xiaoxue
AU  - Li, Peijun
TI  - A Tree Species Mapping Method from UAV Images over Urban Area Using Similarity in Tree-Crown Object Histograms
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 17
SN  - 2072-4292

AB  - Timely and accurate information about spatial distribution of tree species in urban areas provides crucial data for sustainable urban development, management and planning. Very high spatial resolution data collected by sensors onboard Unmanned Aerial Vehicles (UAV) systems provide rich data sources for mapping tree species. This paper proposes a method of tree species mapping from UAV images over urban areas using similarity in tree-crown object histograms and a simple thresholding method. Tree-crown objects are first extracted and used as processing units in subsequent steps. Tree-crown object histograms of multiple features, i.e., spectral and height related features, are generated to quantify within-object variability. A specific tree species is extracted by comparing similarity in histogram between a target tree-crown object and reference objects. The proposed method is evaluated in mapping four different tree species using UAV multispectral ortho-images and derived Digital Surface Model (DSM) data collected in Shanghai urban area, by comparing with an existing method. The results demonstrate that the proposed method outperforms the comparative method for all four tree species, with improvements of 0.61&ndash;5.81% in overall accuracy. The proposed method provides a simple and effective way of mapping tree species over urban area.
KW  - UAV
KW  - DSM
KW  - object histogram
KW  - VBSD
KW  - tree species
KW  - urban area
DO  - 10.3390/rs11171982
ER  -
TY  - EJOU
AU  - Khoufi, Ines
AU  - Laouiti, Anis
AU  - Adjih, Cedric
TI  - A Survey of Recent Extended Variants of the Traveling Salesman and Vehicle Routing Problems for Unmanned Aerial Vehicles
T2  - Drones

PY  - 2019
VL  - 3
IS  - 3
SN  - 2504-446X

AB  - The use of Unmanned Aerial Vehicles (UAVs) is rapidly growing in popularity. Initially introduced for military purposes, over the past few years, UAVs and related technologies have successfully transitioned to a whole new range of civilian applications such as delivery, logistics, surveillance, entertainment, and so forth. They have opened new possibilities such as allowing operation in otherwise difficult or hazardous areas, for instance. For all applications, one foremost concern is the selection of the paths and trajectories of UAVs, and at the same time, UAVs control comes with many challenges, as they have limited energy, limited load capacity and are vulnerable to difficult weather conditions. Generally, efficiently operating a drone can be mathematically formalized as a path optimization problem under some constraints. This shares some commonalities with similar problems that have been extensively studied in the context of urban vehicles and it is only natural that the recent literature has extended the latter to fit aerial vehicle constraints. The knowledge of such problems, their formulation, the resolution methods proposed—through the variants induced specifically by UAVs features—are of interest for practitioners for any UAV application. Hence, in this study, we propose a review of existing literature devoted to such UAV path optimization problems, focusing specifically on the sub-class of problems that consider the mobility on a macroscopic scale. These are related to the two existing general classic ones—the Traveling Salesman Problem and the Vehicle Routing Problem. We analyze the recent literature that adapted the problems to the UAV context, provide an extensive classification and taxonomy of their problems and their formulation and also give a synthetic overview of the resolution techniques, performance metrics and obtained numerical results.
KW  - UAVs
KW  - optimization problems
KW  - TSP
KW  - VRP
DO  - 10.3390/drones3030066
ER  -
TY  - EJOU
AU  - Maharjan, Sajana
AU  - Qamer, Faisal M.
AU  - Matin, Mir
AU  - Joshi, Govinda
AU  - Bhuchar, Sanjeev
TI  - Integrating Modelling and Expert Knowledge for Evaluating Current and Future Scenario of Large Cardamom Crop in Eastern Nepal
T2  - Agronomy

PY  - 2019
VL  - 9
IS  - 9
SN  - 2073-4395

AB  - Large Cardamom (Amomum subulatum Roxb.) is one of the most valuable cash crop of the Himalayan mountain region including Nepal, India, and Bhutan. Nepal is the world&rsquo;s largest producer of the crop while the Taplejung district contributes a 30%&ndash;40% share in Nepal&rsquo;s total production. Large cardamom is an herbaceous perennial crop usually grown under the shade of the Uttis tree in very specialized bioclimatic conditions. In recent years, a decline in cardamom production has been observed which is being attributed to climate-related indicators. To understand the current dynamics of this under-canopy herbaceous crop distribution and its future potential under climate change, a combination of modelling, remote sensing, and expert knowledge is applied for the assessment. The results suggest that currently, Uttis tree cover is 10,735 ha in the district, while 50% (5198 ha) of this cover has a large cardamom crop underneath. When existing cultivation is compared with modelled suitable areas, it is observed that the cultivatable area has not yet reached its full potential. In a future climate scenario, the current habitat will be negatively affected, where mid elevations will remain stable while lower and higher elevation will become infeasible for the crop. Future changes are closely related to temperature and precipitation which are steadily changing in Nepal over time.
KW  - large cardamom
KW  - remote sensing
KW  - species modelling
KW  - habitat assessment
KW  - climate change
DO  - 10.3390/agronomy9090481
ER  -
TY  - EJOU
AU  - Yang, Qinchen
AU  - Liu, Man
AU  - Zhang, Zhitao
AU  - Yang, Shuqin
AU  - Ning, Jifeng
AU  - Han, Wenting
TI  - Mapping Plastic Mulched Farmland for High Resolution Images of Unmanned Aerial Vehicle Using Deep Semantic Segmentation
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 17
SN  - 2072-4292

AB  - With increasing consumption, plastic mulch benefits agriculture by promoting crop quality and yield, but the environmental and soil pollution is becoming increasingly serious. Therefore, research on the monitoring of plastic mulched farmland (PMF) has received increasing attention. Plastic mulched farmland in unmanned aerial vehicle (UAV) remote images due to the high resolution, shows a prominent spatial pattern, which brings difficulties to the task of monitoring PMF. In this paper, through a comparison between two deep semantic segmentation methods, SegNet and fully convolutional networks (FCN), and a traditional classification method, Support Vector Machine (SVM), we propose an end-to-end deep-learning method aimed at accurately recognizing PMF for UAV remote sensing images from Hetao Irrigation District, Inner Mongolia, China. After experiments with single-band, three-band and six-band image data, we found that deep semantic segmentation models built via single-band data which only use the texture pattern of PMF can identify it well; for example, SegNet reaching the highest accuracy of 88.68% in a 900 nm band. Furthermore, with three visual bands and six-band data (3 visible bands and 3 near-infrared bands), deep semantic segmentation models combining the texture and spectral features further improve the accuracy of PMF identification, whereas six-band data obtains an optimal performance for FCN and SegNet. In addition, deep semantic segmentation methods, FCN and SegNet, due to their strong feature extraction capability and direct pixel classification, clearly outperform the traditional SVM method in precision and speed. Among three classification methods, SegNet model built on three-band and six-band data obtains the optimal average accuracy of 89.62% and 90.6%, respectively. Therefore, the proposed deep semantic segmentation model, when tested against the traditional classification method, provides a promising path for mapping PMF in UAV remote sensing images.
KW  - plastic mulched farmland
KW  - fully convolutional networks
KW  - unmanned aerial vehicle remote sensing image
KW  - deep semantic segmentation
DO  - 10.3390/rs11172008
ER  -
TY  - EJOU
AU  - Groh, Till
AU  - Blöthe, Jan H.
TI  - Rock Glacier Kinematics in the Kaunertal, Ötztal Alps, Austria
T2  - Geosciences

PY  - 2019
VL  - 9
IS  - 9
SN  - 2076-3263

AB  - The quantification of rock glacier kinematics on a regional basis has gained increasing importance in recent years. Here, we applied an image tracking approach on high-resolution aerial imagery to infer surface kinematics of 129 mapped rock glaciers in the Kaunertal, Austrian Alps. We find significant surface movement for 30 features with mean velocities falling between 0.11 and 0.29 m yr&minus;1 and a maximum of 1.7 m yr&minus;1. Local analysis and comparison to earlier studies reveals significant increases in rock glacier velocities in the study area. From the rock glacier inventory and high-resolution digital topography, we computed a series of morphometric parameters to analyze potential controls on rock glacier creep and to predict rock glacier activity using random forests and logistic regression models. The results point towards a stronger dependence of velocities on parameters describing general inclination, potentially acting as proxies for internal rock glacier properties, while activity states seem to be regulated mainly by rock glacier dimensions and topoclimate. Using a parameter subset, we successfully separated active from inactive rock glaciers with accuracies of up to 77.5%, indicating a promising approach to predict rock glacier activity solely relying on parameters that can be derived from regionally available data sets.
KW  - rock glaciers
KW  - surface kinematics
KW  - feature tracking
KW  - morphometry
KW  - logistic regression
KW  - random forests
KW  - Austrian Alps
DO  - 10.3390/geosciences9090373
ER  -
TY  - EJOU
AU  - Geraeds, Marlein
AU  - van Emmerik, Tim
AU  - de Vries, Robin
AU  - bin Ab Razak, Mohd S.
TI  - Riverine Plastic Litter Monitoring Using Unmanned Aerial Vehicles (UAVs)
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 17
SN  - 2072-4292

AB  - Plastic debris has become an abundant pollutant in marine, coastal and riverine environments, posing a large threat to aquatic life. Effective measures to mitigate and prevent marine plastic pollution require a thorough understanding of its origin and eventual fate. Several models have estimated that land-based sources are the main source of marine plastic pollution, although field data to substantiate these estimates remain limited. Current methodologies to measure riverine plastic transport require the availability of infrastructure and accessible riverbanks, but, to obtain measurements on a higher spatial and temporal scale, new monitoring methods are required. This paper presents a new methodology for quantifying riverine plastic debris using Unmanned Aerial Vehicles (UAVs), including a first application on Klang River, Malaysia. Additional plastic measurements were done in parallel with the UAV-based approach to make comparisons between the two methods. The spatiotemporal distribution of the plastics obtained with both methods show similar patterns and variations. With this, we show that UAV-based monitoring methods are a promising alternative for currently available approaches for monitoring riverine plastic transport, especially in remote and inaccessible areas.
KW  - unmanned aerial vehicles
KW  - hydrology
KW  - marine plastic
KW  - plastic litter
KW  - rivers
DO  - 10.3390/rs11172045
ER  -
TY  - EJOU
AU  - Ghorbanzadeh, Omid
AU  - Meena, Sansar R.
AU  - Blaschke, Thomas
AU  - Aryal, Jagannath
TI  - UAV-Based Slope Failure Detection Using Deep-Learning Convolutional Neural Networks
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 17
SN  - 2072-4292

AB  - Slope failures occur when parts of a slope collapse abruptly under the influence of gravity, often triggered by a rainfall event or earthquake. The resulting slope failures often cause problems in mountainous or hilly regions, and the detection of slope failure is therefore an important topic for research. Most of the methods currently used for mapping and modelling slope failures rely on classification algorithms or feature extraction, but the spatial complexity of slope failures, the uncertainties inherent in expert knowledge, and problems in transferability, all combine to inhibit slope failure detection. In an attempt to overcome some of these problems we have analyzed the potential of deep learning convolutional neural networks (CNNs) for slope failure detection, in an area along a road section in the northern Himalayas, India. We used optical data from unmanned aerial vehicles (UAVs) over two separate study areas. Different CNN designs were used to produce eight different slope failure distribution maps, which were then compared with manually extracted slope failure polygons using different accuracy assessment metrics such as the precision, F-score, and mean intersection-over-union (mIOU). A slope failure inventory data set was produced for each of the study areas using a frequency-area distribution (FAD). The CNN approach that was found to perform best (precision accuracy assessment of almost 90% precision, F-score 85%, mIOU 74%) was one that used a window size of 64 &times; 64 pixels for the sample patches, and included slope data as an additional input layer. The additional information from the slope data helped to discriminate between slope failure areas and roads, which had similar spectral characteristics in the optical imagery. We concluded that the effectiveness of CNNs for slope failure detection was strongly dependent on their design (i.e., the window size selected for the sample patch, the data used, and the training strategies), but that CNNs are currently only designed by trial and error. While CNNs can be powerful tools, such trial and error strategies make it difficult to explain why a particular pooling or layer numbering works better than any other.
KW  - landslide
KW  - unmanned aerial vehicle (UAV)
KW  - deep learning
KW  - frequency area distribution (FAD)
KW  - mean intersection-over-union (mIOU)
KW  - sample patches selection
DO  - 10.3390/rs11172046
ER  -
TY  - EJOU
AU  - Li, Kexin
AU  - Wang, Jun
AU  - Qi, Dawei
TI  - An Intelligent Warning Method for Diagnosing Underwater Structural Damage
T2  - Algorithms

PY  - 2019
VL  - 12
IS  - 9
SN  - 1999-4893

AB  - A number of intelligent warning techniques have been implemented for detecting underwater infrastructure diagnosis to partially replace human-conducted on-site inspections. However, the extensively varying real-world situation (e.g., the adverse environmental conditions, the limited sample space, and the complex defect types) can lead to challenges to the wide adoption of intelligent warning techniques. To overcome these challenges, this paper proposed an intelligent algorithm combing gray level co-occurrence matrix (GLCM) with self-organization map (SOM) for accurate diagnosis of the underwater structural damage. In order to optimize the generative criterion for GLCM construction, a triangle algorithm was proposed based on orthogonal experiments. The constructed GLCM were utilized to evaluate the texture features of the regions of interest (ROI) of micro-injury images of underwater structures and extracted damage image texture characteristic parameters. The digital feature screening (DFS) method was used to obtain the most relevant features as the input for the SOM network. According to the unique topology information of the SOM network, the classification result, recognition efficiency, parameters, such as the network layer number, hidden layer node, and learning step, were optimized. The robustness and adaptability of the proposed approach were tested on underwater structure images through the DFS method. The results showed that the proposed method revealed quite better performances and can diagnose structure damage in underwater realistic situations.
KW  - structural health monitoring
KW  - digital image processing
KW  - damage
KW  - gray level co-occurrence matrix
KW  - self-organization map
DO  - 10.3390/a12090183
ER  -
TY  - EJOU
AU  - Revill, Andrew
AU  - Florence, Anna
AU  - MacArthur, Alasdair
AU  - Hoad, Stephen P.
AU  - Rees, Robert M.
AU  - Williams, Mathew
TI  - The Value of Sentinel-2 Spectral Bands for the Assessment of Winter Wheat Growth and Development
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 17
SN  - 2072-4292

AB  - Leaf Area Index (LAI) and chlorophyll content are strongly related to plant development and productivity. Spatial and temporal estimates of these variables are essential for efficient and precise crop management. The availability of open-access data from the European Space Agency’s (ESA) Sentinel-2 satellite—delivering global coverage with an average 5-day revisit frequency at a spatial resolution of up to 10 metres—could provide estimates of these variables at unprecedented (i.e., sub-field) resolution. Using synthetic data, past research has demonstrated the potential of Sentinel-2 for estimating crop variables. Nonetheless, research involving a robust analysis of the Sentinel-2 bands for supporting agricultural applications is limited. We evaluated the potential of Sentinel-2 data for retrieving winter wheat LAI, leaf chlorophyll content (LCC) and canopy chlorophyll content (CCC). In coordination with destructive and non-destructive ground measurements, we acquired multispectral data from an Unmanned Aerial Vehicle (UAV)-mounted sensor measuring key Sentinel-2 spectral bands (443 to 865 nm). We applied Gaussian processes regression (GPR) machine learning to determine the most informative Sentinel-2 bands for retrieving each of the variables. We further evaluated the GPR model performance when propagating observation uncertainty. When applying the best-performing GPR models without propagating uncertainty, the retrievals had a high agreement with ground measurements—the mean R2 and normalised root-mean-square error (NRMSE) were 0.89 and 8.8%, respectively. When propagating uncertainty, the mean R2 and NRMSE were 0.82 and 11.9%, respectively. When accounting for measurement uncertainty in the estimation of LAI and CCC, the number of most informative Sentinel-2 bands was reduced from four to only two—the red-edge (705 nm) and near-infrared (865 nm) bands. This research demonstrates the value of the Sentinel-2 spectral characteristics for retrieving critical variables that can support more sustainable crop management practices.
KW  - Sentinel-2 spectral analysis
KW  - Gaussian processes regression
KW  - machine learning
KW  - red-edge band
KW  - winter wheat assessment
KW  - vegetation parameter retrieval
DO  - 10.3390/rs11172050
ER  -
TY  - EJOU
AU  - Shafi, Uferah
AU  - Mumtaz, Rafia
AU  - García-Nieto, José
AU  - Hassan, Syed A.
AU  - Zaidi, Syed A.
AU  - Iqbal, Naveed
TI  - Precision Agriculture Techniques and Practices: From Considerations to Applications
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 17
SN  - 1424-8220

AB  - Internet of Things (IoT)-based automation of agricultural events can change the agriculture sector from being static and manual to dynamic and smart, leading to enhanced production with reduced human efforts. Precision Agriculture (PA) along with Wireless Sensor Network (WSN) are the main drivers of automation in the agriculture domain. PA uses specific sensors and software to ensure that the crops receive exactly what they need to optimize productivity and sustainability. PA includes retrieving real data about the conditions of soil, crops and weather from the sensors deployed in the fields. High-resolution images of crops are obtained from satellite or air-borne platforms (manned or unmanned), which are further processed to extract information used to provide future decisions. In this paper, a review of near and remote sensor networks in the agriculture domain is presented along with several considerations and challenges. This survey includes wireless communication technologies, sensors, and wireless nodes used to assess the environmental behaviour, the platforms used to obtain spectral images of crops, the common vegetation indices used to analyse spectral images and applications of WSN in agriculture. As a proof of concept, we present a case study showing how WSN-based PA system can be implemented. We propose an IoT-based smart solution for crop health monitoring, which is comprised of two modules. The first module is a wireless sensor network-based system to monitor real-time crop health status. The second module uses a low altitude remote sensing platform to obtain multi-spectral imagery, which is further processed to classify healthy and unhealthy crops. We also highlight the results obtained using a case study and list the challenges and future directions based on our work.
KW  - smart agriculture
KW  - precision agriculture
KW  - vegetation index
KW  - Internet of Things
DO  - 10.3390/s19173796
ER  -
TY  - EJOU
AU  - Tilly, Nora
AU  - Bareth, Georg
TI  - Estimating Nitrogen from Structural Crop Traits at Field Scale—A Novel Approach Versus Spectral Vegetation Indices
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 17
SN  - 2072-4292

AB  - A sufficient nitrogen (N) supply is mandatory for healthy crop growth, but negative consequences of N losses into the environment are known. Hence, deeply understanding and monitoring crop growth for an optimized N management is advisable. In this context, remote sensing facilitates the capturing of crop traits. While several studies on estimating biomass from spectral and structural data can be found, N is so far only estimated from spectral features. It is well known that N is negatively related to dry biomass, which, in turn, can be estimated from crop height. Based on this indirect link, the present study aims at estimating N concentration at field scale in a two-step model: first, using crop height to estimate biomass, and second, using the modeled biomass to estimate N concentration. For comparison, N concentration was estimated from spectral data. The data was captured on a spring barley field experiment in two growing seasons. Crop surface height was measured with a terrestrial laser scanner, seven vegetation indices were calculated from field spectrometer measurements, and dry biomass and N concentration were destructively sampled. In the validation, better results were obtained with the models based on structural data (R2 &lt; 0.85) than on spectral data (R2 &lt; 0.70). A brief look at the N concentration of different plant organs showed stronger dependencies on structural data (R2: 0.40&ndash;0.81) than on spectral data (R2: 0.18&ndash;0.68). Overall, this first study shows the potential of crop-specific across‑season two-step models based on structural data for estimating crop N concentration at field scale. The validity of the models for in-season estimations requires further research.
KW  - terrestrial laser scanning
KW  - spectrometer
KW  - plant height
KW  - vegetation indices
KW  - biomass
KW  - nitrogen concentration
KW  - precision agriculture
DO  - 10.3390/rs11172066
ER  -
TY  - EJOU
AU  - Zhou, Jing
AU  - Yungbluth, Dennis
AU  - Vong, Chin N.
AU  - Scaboo, Andrew
AU  - Zhou, Jianfeng
TI  - Estimation of the Maturity Date of Soybean Breeding Lines Using UAV-Based Multispectral Imagery
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 18
SN  - 2072-4292

AB  - Physiological maturity date is a critical parameter for the selection of breeding lines in soybean breeding programs. The conventional method to estimate the maturity dates of breeding lines uses visual ratings based on pod senescence by experts, which is subjective by human estimation, labor-intensive and time-consuming. Unmanned aerial vehicle (UAV)-based phenotyping systems provide a high-throughput and powerful tool of capturing crop traits using remote sensing, image processing and machine learning technologies. The goal of this study was to investigate the potential of predicting maturity dates of soybean breeding lines using UAV-based multispectral imagery. Maturity dates of 326 soybean breeding lines were taken using visual ratings from the beginning maturity stage (R7) to full maturity stage (R8), and the aerial multispectral images were taken during this period on 27 August, 14 September and 27 September, 2018. One hundred and thirty features were extracted from the five-band multispectral images. The maturity dates of the soybean lines were predicted and evaluated using partial least square regression (PLSR) models with 10-fold cross-validation. Twenty image features with importance to the estimation were selected and their changing rates between each two of the data collection days were calculated. The best prediction (R2 = 0.81, RMSE = 1.4 days) was made by the PLSR model using image features taken on 14 September and their changing rates between 14 September and 27 September with five components, leading to the conclusion that the UAV-based multispectral imagery is promising and practical in estimating maturity dates of soybean breeding lines.
KW  - machine learning
KW  - maturity date
KW  - multispectral image
KW  - soybean breeding
KW  - UAV-based phenotyping
DO  - 10.3390/rs11182075
ER  -
TY  - EJOU
AU  - Fan, Shurui
AU  - Li, Zirui
AU  - Xia, Kewen
AU  - Hao, Dongxia
TI  - Quantitative and Qualitative Analysis of Multicomponent Gas Using Sensor Array
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 18
SN  - 1424-8220

AB  - The gas sensor array has long been a major tool for measuring gas due to its high sensitivity, quick response, and low power consumption. This goal, however, faces a difficult challenge because of the cross-sensitivity of the gas sensor. This paper presents a novel gas mixture analysis method for gas sensor array applications. The features extracted from the raw data utilizing principal component analysis (PCA) were used to complete random forest (RF) modeling, which enabled qualitative identification. Support vector regression (SVR), optimized by the particle swarm optimization (PSO) algorithm, was used to select hyperparameters C and &gamma; to establish the optimal regression model for the purpose of quantitative analysis. Utilizing the dataset, we evaluated the effectiveness of our approach. Compared with logistic regression (LR) and support vector machine (SVM), the average recognition rate of PCA combined with RF was the highest (97%). The fitting effect of SVR optimized by PSO for gas concentration was better than that of SVR and solved the problem of hyperparameters selection.
KW  - gas sensor array
KW  - cross-sensitivity
KW  - PCA
KW  - random forest
KW  - particle swarm optimization
DO  - 10.3390/s19183917
ER  -
TY  - EJOU
AU  - Hillman, Samuel
AU  - Wallace, Luke
AU  - Reinke, Karin
AU  - Hally, Bryan
AU  - Jones, Simon
AU  - Saldias, Daisy S.
TI  - A Method for Validating the Structural Completeness of Understory Vegetation Models Captured with 3D Remote Sensing
T2  - Remote Sensing

PY  - 2019
VL  - 11
IS  - 18
SN  - 2072-4292

AB  - Characteristics describing below canopy vegetation are important for a range of forest ecosystem applications including wildlife habitat, fuel hazard and fire behaviour modelling, understanding forest recovery after disturbance and competition dynamics. Such applications all rely on accurate measures of vegetation structure. Inherent in this is the assumption or ability to demonstrate measurement accuracy. 3D point clouds are being increasingly used to describe vegetated environments, however limited research has been conducted to validate the information content of terrestrial point clouds of understory vegetation. This paper describes the design and use of a field frame to co-register point intercept measurements with point cloud data to act as a validation source. Validation results show high correlation of point matching in forests with understory vegetation elements with large mass and/or surface area, typically consisting of broad leaves, twigs and bark 0.02 m diameter or greater in size (SfM, MCC 0.51&ndash;0.66; TLS, MCC 0.37&ndash;0.47). In contrast, complex environments with understory vegetation elements with low mass and low surface area showed lower correlations between validation measurements and point clouds (SfM, MCC 0.40 and 0.42; TLS, MCC 0.25 and 0.16). The results of this study demonstrate that the validation frame provides a suitable method for comparing the relative performance of different point cloud generation processes.
KW  - structure from motion
KW  - terrestrial laser scanning
KW  - validation
KW  - 3D remote sensing
KW  - vegetation structure
KW  - biomass
KW  - forest measurement
DO  - 10.3390/rs11182118
ER  -
TY  - EJOU
AU  - Liu, Xiaolei
AU  - Liu, Liansheng
AU  - Wang, Lulu
AU  - Guo, Qing
AU  - Peng, Xiyuan
TI  - Performance Sensing Data Prediction for an Aircraft Auxiliary Power Unit Using the Optimized Extreme Learning Machine
T2  - Sensors

PY  - 2019
VL  - 19
IS  - 18
SN  - 1424-8220

AB  - The aircraft auxiliary power unit (APU) is responsible for environmental control in the cabin and the main engines starting the aircraft. The prediction of its performance sensing data is significant for condition-based maintenance. As a complex system, its performance sensing data have a typically nonlinear feature. In order to monitor this process, a model with strong nonlinear fitting ability needs to be formulated. A neural network has advantages of solving a nonlinear problem. Compared with the traditional back propagation neural network algorithm, an extreme learning machine (ELM) has features of a faster learning speed and better generalization performance. To enhance the training of the neural network with a back propagation algorithm, an ELM is employed to predict the performance sensing data of the APU in this study. However, the randomly generated weights and thresholds of the ELM often may result in unstable prediction results. To address this problem, a restricted Boltzmann machine (RBM) is utilized to optimize the ELM. In this way, a stable performance parameter prediction model of the APU can be obtained and better performance parameter prediction results can be achieved. The proposed method is evaluated by the real APU sensing data of China Southern Airlines Company Limited Shenyang Maintenance Base. Experimental results show that the optimized ELM with an RBM is more stable and can obtain more accurate prediction results.
KW  - auxiliary power unit
KW  - improved neural network
KW  - stable prediction
KW  - performance sensing data prediction
DO  - 10.3390/s19183935
ER  -
